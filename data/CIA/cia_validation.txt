Named entity recognition (NER) is a fundamental task in natural language processing .
Recent works treat named entity recognition as a reading comprehension task, constructing type-specific queries manually to extract entities .
This paradigm suffers from three issues .
First, type-specific queries can only extract one type of entities per inference, which is inefficient .
Second, the extraction for different types of entities is isolated, ignoring the dependencies between them .
Third, query construction relies on external knowledge and is difficult to apply to realistic scenarios with hundreds of entity types .
To deal with them, we propose Parallel Instance Query Network (PIQN), which sets up global and learnable instance queries to extract entities from a sentence in a parallel manner .
Each instance query predicts one entity, and by feeding all instance queries simultaneously, we can query all entities in parallel .
Instead of being constructed from external knowledge, instance queries can learn their different query semantics during training .
For training the model, we treat label assignment as a one-to-many Linear Assignment Problem (LAP) and dynamically assign gold entities to instance queries with minimal assignment cost .
Experiments on both nested and flat NER datasets demonstrate that our proposed method outperforms previous state-of-the-art models .
Typical generative dialogue models utilize the dialogue history to generate the response .
However, since one dialogue utterance can often be appropriately answered by multiple distinct responses, generating a desired response solely based on the historical information is not easy .
Intuitively, if the chatbot can foresee in advance what the user would talk about (i.e., the dialogue future) after receiving its response, it could possibly provide a more informative response .
Accordingly, we propose a novel dialogue generation framework named ProphetChat that utilizes the simulated dialogue futures in the inference phase to enhance response generation .
To enable the chatbot to foresee the dialogue future, we design a beam-search-like roll-out strategy for dialogue future simulation using a typical dialogue generation model and a dialogue selector .
With the simulated futures, we then utilize the ensemble of a history-to-response generator and a future-to-response generator to jointly generate a more informative response .
Experiments on two popular open-domain dialogue datasets demonstrate that ProphetChat can generate better responses over strong baselines, which validates the advantages of incorporating the simulated dialogue futures .
Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question answering (QA) model that leverages passage retrieval with a pre-trained transformer and pushed the state of the art on single-hop QA .
However, the complexity of multi-hop QA hinders the effectiveness of the generative QA approach .
In this work, we propose a simple generative approach (PathFid) that extends the task beyond just answer generation by explicitly modeling the reasoning process to resolve the answer for multi-hop questions .
By linearizing the hierarchical reasoning path of supporting passages, their key sentences, and finally the factoid answer, we cast the problem as a single sequence prediction task .
To facilitate complex reasoning with multiple clues, we further extend the unified flat representation of multiple input documents by encoding cross-passage interactions .
Our extensive experiments demonstrate that PathFid leads to strong performance gains on two multi-hop QA datasets: HotpotQA and IIRC .
Besides the performance gains, PathFid is more interpretable, which in turn yields answers that are more faithfully grounded to the supporting passages and facts compared to the baseline Fid model .
Multilingual pre-trained models are able to zero-shot transfer knowledge from rich-resource to low-resource languages in machine reading comprehension (MRC) .
However, inherent linguistic discrepancies in different languages could make answer spans predicted by zero-shot transfer violate syntactic constraints of the target language .
In this paper, we propose a novel multilingual MRC framework equipped with a Siamese Semantic Disentanglement Model (S2DM) to disassociate semantics from syntax in representations learned by multilingual pre-trained models .
To explicitly transfer only semantic knowledge to the target language, we propose two groups of losses tailored for semantic and syntactic encoding and disentanglement .
Experimental results on three multilingual MRC datasets (i.e., XQuAD, MLQA, and TyDi QA) demonstrate the effectiveness of our proposed approach over models based on mBERT and XLM-100 .
Transferring the knowledge to a small model through distillation has raised great interest in recent years .
Prevailing methods transfer the knowledge derived from mono-granularity language units (e.g., token-level or sample-level), which is not enough to represent the rich semantics of a text and may lose some vital knowledge .
Besides, these methods form the knowledge as individual representations or their simple dependencies, neglecting abundant structural relations among intermediate representations .
To overcome the problems, we present a novel knowledge distillation framework that gathers intermediate representations from multiple semantic granularities (e.g., tokens, spans and samples) and forms the knowledge as more sophisticated structural relations specified as the pair-wise interactions and the triplet-wise geometric angles based on multi-granularity representations .
Moreover, we propose distilling the well-organized multi-granularity structural knowledge to the student hierarchically across layers .
Experimental results on GLUE benchmark demonstrate that our method outperforms advanced distillation methods .
Human-like biases and undesired social stereotypes exist in large pretrained language models .
Given the wide adoption of these models in real-world applications, mitigating such biases has become an emerging and important task .
In this paper, we propose an automatic method to mitigate the biases in pretrained language models .
Different from previous debiasing work that uses external corpora to fine-tune the pretrained models, we instead directly probe the biases encoded in pretrained models through prompts .
Specifically, we propose a variant of the beam search method to automatically search for biased prompts such that the cloze-style completions are the most different with respect to different demographic groups .
Given the identified biased prompts, we then propose a distribution alignment loss to mitigate the biases .
Experiment results on standard datasets and metrics show that our proposed Auto-Debias approach can significantly reduce biases, including gender and racial bias, in pretrained language models such as BERT, RoBERTa and ALBERT .
Moreover, the improvement in fairness does not decrease the language models’ understanding abilities, as shown using the GLUE benchmark .
Most dialog systems posit that users have figured out clear and specific goals before starting an interaction .
For example, users have determined the departure, the destination, and the travel time for booking a flight .
However, in many scenarios, limited by experience and knowledge, users may know what they need, but still struggle to figure out clear and specific goals by determining all the necessary slots .
In this paper, we identify this challenge, and make a step forward by collecting a new human-to-human mixed-type dialog corpus .
It contains 5k dialog sessions and 168k utterances for 4 dialog types and 5 domains .
Within each session, an agent first provides user-goal-related knowledge to help figure out clear and specific goals, and then help achieve them .
Furthermore, we propose a mixed-type dialog model with a novel Prompt-based continual learning mechanism .
Specifically, the mechanism enables the model to continually strengthen its ability on any specific type by utilizing existing dialog corpora effectively .
Supervised parsing models have achieved impressive results on in-domain texts .
However, their performances drop drastically on out-of-domain texts due to the data distribution shift .
The shared-private model has shown its promising advantages for alleviating this problem via feature separation, whereas prior works pay more attention to enhance shared features but neglect the in-depth relevance of specific ones .
To address this issue, we for the first time apply a dynamic matching network on the shared-private model for semi-supervised cross-domain dependency parsing .
Meanwhile, considering the scarcity of target-domain labeled data, we leverage unlabeled data from two aspects, i.e., designing a new training strategy to improve the capability of the dynamic matching network and fine-tuning BERT to obtain domain-related contextualized representations .
Experiments on benchmark datasets show that our proposed model consistently outperforms various baselines, leading to new state-of-the-art results on all domains .
Detailed analysis on different matching strategies demonstrates that it is essential to learn suitable matching weights to emphasize useful features and ignore useless or even harmful ones .
Besides, our proposed model can be directly extended to multi-source domain adaptation and achieves best performances among various baselines, further verifying the effectiveness and robustness .
Given the prevalence of pre-trained contextualized representations in today’s NLP, there have been many efforts to understand what information they contain, and why they seem to be universally successful .
The most common approach to use these representations involves fine-tuning them for an end task .
Yet, how fine-tuning changes the underlying embedding space is less studied .
In this work, we study the English BERT family and use two probing techniques to analyze how fine-tuning changes the space .
We hypothesize that fine-tuning affects classification performance by increasing the distances between examples associated with different labels .
We confirm this hypothesis with carefully designed experiments on five different NLP tasks .
Via these experiments, we also discover an exception to the prevailing wisdom that “fine-tuning always improves performance” .
Finally, by comparing the representations before and after fine-tuning, we discover that fine-tuning does not introduce arbitrary changes to representations; instead, it adjusts the representations to downstream tasks while largely preserving the original spatial structure of the data points .
Training dense passage representations via contrastive learning has been shown effective for Open-Domain Passage Retrieval (ODPR) .
Existing studies focus on further optimizing by improving negative sampling strategy or extra pretraining .
However, these studies keep unknown in capturing passage with internal representation conflicts from improper modeling granularity .
Specifically, under our observation that a passage can be organized by multiple semantically different sentences, modeling such a passage as a unified dense vector is not optimal .
This work thus presents a refined model on the basis of a smaller granularity, contextual sentences, to alleviate the concerned conflicts .
In detail, we introduce an in-passage negative sampling strategy to encourage a diverse generation of sentence representations within the same passage .
Experiments on three benchmark datasets verify the efficacy of our method, especially on datasets where conflicts are severe .
Extensive experiments further present good transferability of our method across datasets .
Transformers have been shown to be able to perform deductive reasoning on a logical rulebase containing rules and statements written in natural language .
Recent works show that such models can also produce the reasoning steps (i.e., the proof graph) that emulate the model’s logical reasoning process .
Currently, these black-box models generate both the proof graph and intermediate inferences within the same model and thus may be unfaithful .
In this work, we frame the deductive logical reasoning task by defining three modular components: rule selection, fact selection, and knowledge composition .
The rule and fact selection steps select the candidate rule and facts to be used and then the knowledge composition combines them to generate new inferences .
This ensures model faithfulness by assured causal relation from the proof step to the inference reasoning .
To test our framework, we propose FaiRR (Faithful and Robust Reasoner) where the above three components are independently modeled by transformers .
We observe that FaiRR is robust to novel language perturbations, and is faster at inference than previous works on existing reasoning datasets .
Additionally, in contrast to black-box generative models, the errors made by FaiRR are more interpretable due to the modular approach .
Tables are often created with hierarchies, but existing works on table reasoning mainly focus on flat tables and neglect hierarchical tables .
Hierarchical tables challenge numerical reasoning by complex hierarchical indexing, as well as implicit relationships of calculation and semantics .
We present a new dataset, HiTab, to study question answering (QA) and natural language generation (NLG) over hierarchical tables .
HiTab is a cross-domain dataset constructed from a wealth of statistical reports and Wikipedia pages, and has unique characteristics: (1) nearly all tables are hierarchical, and (2) QA pairs are not proposed by annotators from scratch, but are revised from real and meaningful sentences authored by analysts .
(3) to reveal complex numerical reasoning in statistical reports, we provide fine-grained annotations of quantity and entity alignment .
Experiments suggest that this HiTab presents a strong challenge for existing baselines and a valuable benchmark for future research .
Targeting hierarchical structure, we devise a hierarchy-aware logical form for symbolic reasoning over tables, which shows high effectiveness .
Targeting table reasoning, we leverage entity and quantity alignment to explore partially supervised training in QA and conditional generation in NLG, and largely reduce spurious predictions in QA and produce better descriptions in NLG .
Huge volumes of patient queries are daily generated on online health forums, rendering manual doctor allocation a labor-intensive task .
To better help patients, this paper studies a novel task of doctor recommendation to enable automatic pairing of a patient to a doctor with relevant expertise .
While most prior work in recommendation focuses on modeling target users from their past behavior, we can only rely on the limited words in a query to infer a patient’s needs for privacy reasons .
For doctor modeling, we study the joint effects of their profiles and previous dialogues with other patients and explore their interactions via self-learning .
The learned doctor embeddings are further employed to estimate their capabilities of handling a patient query with a multi-head attention mechanism .
For experiments, a large-scale dataset is collected from Chunyu Yisheng, a Chinese online health forum, where our model exhibits the state-of-the-art results, outperforming baselines only consider profiles and past dialogues to characterize a doctor .
A desirable dialog system should be able to continually learn new skills without forgetting old ones, and thereby adapt to new domains or tasks in its life cycle .
However, continually training a model often leads to a well-known catastrophic forgetting issue .
In this paper, we present Continual Prompt Tuning, a parameter-efficient framework that not only avoids forgetting but also enables knowledge transfer between tasks .
To avoid forgetting, we only learn and store a few prompt tokens’ embeddings for each task while freezing the backbone pre-trained model .
To achieve bi-directional knowledge transfer among tasks, we propose several techniques (continual prompt initialization, query fusion, and memory replay) to transfer knowledge from preceding tasks and a memory-guided technique to transfer knowledge from subsequent tasks .
Extensive experiments demonstrate the effectiveness and efficiency of our proposed method on continual learning for dialog state tracking, compared with state-of-the-art baselines .
Images are often more significant than only the pixels to human eyes, as we can infer, associate, and reason with contextual information from other sources to establish a more complete picture .
For example, in Figure 1, we can find a way to identify the news articles related to the picture through segment-wise understandings of the signs, the buildings, the crowds, and more .
This reasoning could provide the time and place the image was taken, which will help us in subsequent tasks, such as automatic storyline construction, correction of image source in intended effect photographs, and upper-stream processing such as image clustering for certain location or time.In this work, we formulate this problem and introduce TARA: a dataset with 16k images with their associated news, time, and location, automatically extracted from New York Times, and an additional 61k examples as distant supervision from WIT .
On top of the extractions, we present a crowdsourced subset in which we believe it is possible to find the images’ spatio-temporal information for evaluation purpose .
We show that there exists a 70% gap between a state-of-the-art joint model and human performance, which is slightly filled by our proposed model that uses segment-wise reasoning, motivating higher-level vision-language joint models that can conduct open-ended reasoning with world knowledge.The data and code are publicly available at https://github.com/zeyofu/TARA .
Tables store rich numerical data, but numerical reasoning over tables is still a challenge .
In this paper, we find that the spreadsheet formula, a commonly used language to perform computations on numerical values in spreadsheets, is a valuable supervision for numerical reasoning in tables .
Considering large amounts of spreadsheets available on the web, we propose FORTAP, the first exploration to leverage spreadsheet formulas for table pretraining .
Two novel self-supervised pretraining objectives are derived from formulas, numerical reference prediction (NRP) and numerical calculation prediction (NCP) .
While our proposed objectives are generic for encoders, to better capture spreadsheet table layouts and structures, FORTAP is built upon TUTA, the first transformer-based method for spreadsheet table pretraining with tree attention .
FORTAP outperforms state-of-the-art methods by large margins on three representative datasets of formula prediction, question answering, and cell type classification, showing the great potential of leveraging formulas for table pretraining .
Information integration from different modalities is an active area of research .
Human beings and, in general, biological neural systems are quite adept at using a multitude of signals from different sensory perceptive fields to interact with the environment and each other .
Recent work in deep fusion models via neural networks has led to substantial improvements over unimodal approaches in areas like speech recognition, emotion recognition and analysis, captioning and image description .
However, such research has mostly focused on architectural changes allowing for fusion of different modalities while keeping the model complexity manageable.Inspired by neuroscientific ideas about multisensory integration and processing, we investigate the effect of introducing neural dependencies in the loss functions .
Experiments on multimodal sentiment analysis tasks with different models show that our approach provides a consistent performance boost .
Procedural Multimodal Documents (PMDs) organize textual instructions and corresponding images step by step .
Comprehending PMDs and inducing their representations for the downstream reasoning tasks is designated as Procedural MultiModal Machine Comprehension (M3C) .
In this study, we approach Procedural M3C at a fine-grained level (compared with existing explorations at a document or sentence level), that is, entity .
With delicate consideration, we model entity both in its temporal and cross-modal relation and propose a novel Temporal-Modal Entity Graph (TMEG) .
Specifically, graph structure is formulated to capture textual and visual entities and trace their temporal-modal evolution .
In addition, a graph aggregation module is introduced to conduct graph encoding and reasoning .
Comprehensive experiments across three Procedural M3C tasks are conducted on a traditional dataset RecipeQA and our new dataset CraftQA, which can better evaluate the generalization of TMEG .
Pre-trained sequence-to-sequence language models have led to widespread success in many natural language generation tasks .
However, there has been relatively less work on analyzing their ability to generate structured outputs such as graphs .
Unlike natural language, graphs have distinct structural and semantic properties in the context of a downstream NLP task, e.g., generating a graph that is connected and acyclic can be attributed to its structural constraints, while the semantics of a graph can refer to how meaningfully an edge represents the relation between two node concepts .
In this work, we study pre-trained language models that generate explanation graphs in an end-to-end manner and analyze their ability to learn the structural constraints and semantics of such graphs .
We first show that with limited supervision, pre-trained language models often generate graphs that either violate these constraints or are semantically incoherent .
Since curating large amount of human-annotated graphs is expensive and tedious, we propose simple yet effective ways of graph perturbations via node and edge edit operations that lead to structurally and semantically positive and negative graphs .
Next, we leverage these graphs in different contrastive learning models with Max-Margin and InfoNCE losses .
Our methods lead to significant improvements in both structural and semantic accuracy of explanation graphs and also generalize to other similar graph generation tasks .
Lastly, we show that human errors are the best negatives for contrastive learning and also that automatically generating more such human-like negative graphs can lead to further improvements .
Opinion summarization is the task of automatically generating summaries that encapsulate information expressed in multiple user reviews .
We present Semantic Autoencoder (SemAE) to perform extractive opinion summarization in an unsupervised manner .
SemAE uses dictionary learning to implicitly capture semantic information from the review text and learns a latent representation of each sentence over semantic units .
Our extractive summarization algorithm leverages the representations to identify representative opinions among hundreds of reviews .
SemAE is also able to perform controllable summarization to generate aspect-specific summaries using only a few samples .
We report strong performance on SPACE and AMAZON datasets and perform experiments to investigate the functioning of our model .
Lexical substitution is the task of generating meaningful substitutes for a word in a given textual context .
Contextual word embedding models have achieved state-of-the-art results in the lexical substitution task by relying on contextual information extracted from the replaced word within the sentence .
However, such models do not take into account structured knowledge that exists in external lexical databases.We introduce LexSubCon, an end-to-end lexical substitution framework based on contextual embedding models that can identify highly-accurate substitute candidates .
This is achieved by combining contextual information with knowledge from structured lexical resources .
Our approach involves: (i) introducing a novel mix-up embedding strategy to the target word’s embedding through linearly interpolating the pair of the target input embedding and the average embedding of its probable synonyms; (ii) considering the similarity of the sentence-definition embeddings of the target word and its proposed candidates; and, (iii) calculating the effect of each substitution on the semantics of the sentence through a fine-tuned sentence similarity model .
Our experiments show that LexSubCon outperforms previous state-of-the-art methods by at least 2% over all the official lexical substitution metrics on LS07 and CoInCo benchmark datasets that are widely used for lexical substitution tasks .
Implicit knowledge, such as common sense, is key to fluid human conversations .
Current neural response generation (RG) models are trained to generate responses directly, omitting unstated implicit knowledge .
In this paper, we present Think-Before-Speaking (TBS), a generative approach to first externalize implicit commonsense knowledge (think) and use this knowledge to generate responses (speak) .
We argue that externalizing implicit knowledge allows more efficient learning, produces more informative responses, and enables more explainable models .
We analyze different choices to collect knowledge-aligned dialogues, represent implicit knowledge, and transition between knowledge and dialogues .
Empirical results show TBS models outperform end-to-end and knowledge-augmented RG baselines on most automatic metrics and generate more informative, specific, and commonsense-following responses, as evaluated by human annotators .
TBS also generates knowledge that makes sense and is relevant to the dialogue around 85% of the time .
In this work, we propose a flow-adapter architecture for unsupervised NMT .
It leverages normalizing flows to explicitly model the distributions of sentence-level latent representations, which are subsequently used in conjunction with the attention mechanism for the translation task .
The primary novelties of our model are: (a) capturing language-specific sentence representations separately for each language using normalizing flows and (b) using a simple transformation of these latent representations for translating from one language to another .
This architecture allows for unsupervised training of each language independently .
While there is prior work on latent variables for supervised MT, to the best of our knowledge, this is the first work that uses latent variables and normalizing flows for unsupervised MT .
We obtain competitive results on several unsupervised MT benchmarks .
Sentence compression reduces the length of text by removing non-essential content while preserving important facts and grammaticality .
Unsupervised objective driven methods for sentence compression can be used to create customized models without the need for ground-truth training data, while allowing flexibility in the objective function(s) that are used for learning and inference .
Recent unsupervised sentence compression approaches use custom objectives to guide discrete search; however, guided search is expensive at inference time .
In this work, we explore the use of reinforcement learning to train effective sentence compression models that are also fast when generating predictions .
In particular, we cast the task as binary sequence labelling and fine-tune a pre-trained transformer using a simple policy gradient approach .
Our approach outperforms other unsupervised models while also being more efficient at inference time .
Machine reading comprehension is a heavily-studied research and test field for evaluating new pre-trained language models (PrLMs) and fine-tuning strategies, and recent studies have enriched the pre-trained language models with syntactic, semantic and other linguistic information to improve the performance of the models .
In this paper, we imitate the human reading process in connecting the anaphoric expressions and explicitly leverage the coreference information of the entities to enhance the word embeddings from the pre-trained language model, in order to highlight the coreference mentions of the entities that must be identified for coreference-intensive question answering in QUOREF, a relatively new dataset that is specifically designed to evaluate the coreference-related performance of a model .
We use two strategies to fine-tune a pre-trained language model, namely, placing an additional encoder layer after a pre-trained language model to focus on the coreference mentions or constructing a relational graph convolutional network to model the coreference relations .
We demonstrate that the explicit incorporation of coreference information in the fine-tuning stage performs better than the incorporation of the coreference information in pre-training a language model .
We contribute a new dataset for the task of automated fact checking and an evaluation of state of the art algorithms .
The dataset includes claims (from speeches, interviews, social media and news articles), review articles published by professional fact checkers and premise articles used by those professional fact checkers to support their review and verify the veracity of the claims .
An important challenge in the use of premise articles is the identification of relevant passages that will help to infer the veracity of a claim .
We show that transferring a dense passage retrieval model trained with review articles improves the retrieval quality of passages in premise articles .
We report results for the prediction of claim veracity by inference from premise articles .
Fast and reliable evaluation metrics are key to R&D progress .
While traditional natural language generation metrics are fast, they are not very reliable .
Conversely, new metrics based on large pretrained language models are much more reliable, but require significant computational resources .
In this paper, we propose FrugalScore, an approach to learn a fixed, low cost version of any expensive NLG metric, while retaining most of its original performance .
Experiments with BERTScore and MoverScore on summarization and translation show that FrugalScore is on par with the original metrics (and sometimes better), while having several orders of magnitude less parameters and running several times faster .
On average over all learned metrics, tasks, and variants, FrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35 times less parameters than the original metrics .
We make our trained metrics publicly available, to benefit the entire NLP community and in particular researchers and practitioners with limited resources .
We propose Composition Sampling, a simple but effective method to generate diverse outputs for conditional generation of higher quality compared to previous stochastic decoding strategies .
It builds on recently proposed plan-based neural generation models (FROST, Narayan et al, 2021) that are trained to first create a composition of the output and then generate by conditioning on it and the input .
Our approach avoids text degeneration by first sampling a composition in the form of an entity chain and then using beam search to generate the best possible text grounded to this entity chain .
Experiments on summarization (CNN/DailyMail and XSum) and question generation (SQuAD), using existing and newly proposed automaticmetrics together with human-based evaluation, demonstrate that Composition Sampling is currently the best available decoding strategy for generating diverse meaningful outputs .
Synthesizing QA pairs with a question generator (QG) on the target domain has become a popular approach for domain adaptation of question answering (QA) models .
Since synthetic questions are often noisy in practice, existing work adapts scores from a pretrained QA (or QG) model as criteria to select high-quality questions .
However, these scores do not directly serve the ultimate goal of improving QA performance on the target domain .
In this paper, we introduce a novel idea of training a question value estimator (QVE) that directly estimates the usefulness of synthetic questions for improving the target-domain QA performance .
By conducting comprehensive experiments, we show that the synthetic questions selected by QVE can help achieve better target-domain QA performance, in comparison with existing techniques .
We additionally show that by using such questions and only around 15% of the human annotations on the target domain, we can achieve comparable performance to the fully-supervised baselines .
Class-based language models (LMs) have been long devised to address context sparsity in n-gram LMs .
In this study, we revisit this approach in the context of neural LMs .
We hypothesize that class-based prediction leads to an implicit context aggregation for similar words and thus can improve generalization for rare words .
We map words that have a common WordNet hypernym to the same class and train large neural LMs by gradually annealing from predicting the class to token prediction during training .
Empirically, this curriculum learning strategy consistently improves perplexity over various large, highly-performant state-of-the-art Transformer-based models on two datasets, WikiText-103 and ARXIV .
Our analysis shows that the performance improvement is achieved without sacrificing performance on rare words .
Finally, we document other attempts that failed to yield empirical gains, and discuss future directions for the adoption of class-based LMs on a larger scale .
Easy access, variety of content, and fast widespread interactions are some of the reasons making social media increasingly popular .
However, this rise has also enabled the propagation of fake news, text published by news sources with an intent to spread misinformation and sway beliefs .
Detecting it is an important and challenging problem to prevent large scale misinformation and maintain a healthy society .
We view fake news detection as reasoning over the relations between sources, articles they publish, and engaging users on social media in a graph framework .
After embedding this information, we formulate inference operators which augment the graph edges by revealing unobserved interactions between its elements, such as similarity between documents’ contents and users’ engagement patterns .
Our experiments over two challenging fake news detection tasks show that using inference operators leads to a better understanding of the social media framework enabling fake news spread, resulting in improved performance .
Knowledge base (KB) embeddings have been shown to contain gender biases .
In this paper, we study two questions regarding these biases: how to quantify them, and how to trace their origins in KB? Specifically, first, we develop two novel bias measures respectively for a group of person entities and an individual person entity .
Evidence of their validity is observed by comparison with real-world census data .
Second, we use the influence function to inspect the contribution of each triple in KB to the overall group bias .
To exemplify the potential applications of our study, we also present two strategies (by adding and removing KB triples) to mitigate gender biases in KB embeddings .
South Asia is home to a plethora of languages, many of which severely lack access to new language technologies .
This linguistic diversity also results in a research environment conducive to the study of comparative, contact, and historical linguistics–fields which necessitate the gathering of extensive data from many languages .
We claim that data scatteredness (rather than scarcity) is the primary obstacle in the development of South Asian language technology, and suggest that the study of language history is uniquely aligned with surmounting this obstacle .
We review recent developments in and at the intersection of South Asian NLP and historical-comparative linguistics, describing our and others’ current efforts in this area .
We also offer new strategies towards breaking the data barrier .
Despite recent progress in abstractive summarization, systems still suffer from faithfulness errors .
While prior work has proposed models that improve faithfulness, it is unclear whether the improvement comes from an increased level of extractiveness of the model outputs as one naive way to improve faithfulness is to make summarization models more extractive .
In this work, we present a framework for evaluating the effective faithfulness of summarization systems, by generating a faithfulness-abstractiveness trade-off curve that serves as a control at different operating points on the abstractiveness spectrum .
We then show that the Maximum Likelihood Estimation (MLE) baseline as well as recently proposed methods for improving faithfulness, fail to consistently improve over the control at the same level of abstractiveness .
Finally, we learn a selector to identify the most faithful and abstractive summary for a given document, and show that this system can attain higher faithfulness scores in human evaluations while being more abstractive than the baseline system on two datasets .
Moreover, we show that our system is able to achieve a better faithfulness-abstractiveness trade-off than the control at the same level of abstractiveness .
Languages are continuously undergoing changes, and the mechanisms that underlie these changes are still a matter of debate .
In this work, we approach language evolution through the lens of causality in order to model not only how various distributional factors associate with language change, but how they causally affect it .
In particular, we study slang, which is an informal language that is typically restricted to a specific group or social setting .
We analyze the semantic change and frequency shift of slang words and compare them to those of standard, nonslang words .
With causal discovery and causal inference techniques, we measure the effect that word type (slang/nonslang) has on both semantic change and frequency shift, as well as its relationship to frequency, polysemy and part of speech .
Our analysis provides some new insights in the study of language change, e.g., we show that slang words undergo less semantic change but tend to have larger frequency shifts over time .
Model-based, reference-free evaluation metricshave been proposed as a fast and cost-effectiveapproach to evaluate Natural Language Generation(NLG) systems .
Despite promising recentresults, we find evidence that reference-freeevaluation metrics of summarization and dialoggeneration may be relying on spuriouscorrelations with measures such as word overlap,perplexity, and length .
We further observethat for text summarization, these metrics havehigh error rates when ranking current state-ofthe-art abstractive summarization systems .
Wedemonstrate that these errors can be mitigatedby explicitly designing evaluation metrics toavoid spurious features in reference-free evaluation .
Semantic parsers map natural language utterances into meaning representations (e.g., programs) .
Such models are typically bottlenecked by the paucity of training data due to the required laborious annotation efforts .
Recent studies have performed zero-shot learning by synthesizing training examples of canonical utterances and programs from a grammar, and further paraphrasing these utterances to improve linguistic diversity .
However, such synthetic examples cannot fully capture patterns in real data .
In this paper we analyze zero-shot parsers through the lenses of the language and logical gaps (Herzig and Berant, 2019), which quantify the discrepancy of language and programmatic patterns between the canonical examples and real-world user-issued ones .
We propose bridging these gaps using improved grammars, stronger paraphrasers, and efficient learning methods using canonical examples that most likely reflect real user intents .
Our model achieves strong performance on two semantic parsing benchmarks (Scholar, Geo) with zero labeled data .
Machine Translation Quality Estimation (QE) aims to build predictive models to assess the quality of machine-generated translations in the absence of reference translations .
While state-of-the-art QE models have been shown to achieve good results, they over-rely on features that do not have a causal impact on the quality of a translation .
In particular, there appears to be a partial input bias, i.e., a tendency to assign high-quality scores to translations that are fluent and grammatically correct, even though they do not preserve the meaning of the source .
We analyse the partial input bias in further detail and evaluate four approaches to use auxiliary tasks for bias mitigation .
Two approaches use additional data to inform and support the main task, while the other two are adversarial, actively discouraging the model from learning the bias .
We compare the methods with respect to their ability to reduce the partial input bias while maintaining the overall performance .
We find that training a multitask architecture with an auxiliary binary classification task that utilises additional augmented data best achieves the desired effects and generalises well to different languages and quality metrics .
In this work, we describe a method to jointly pre-train speech and text in an encoder-decoder modeling framework for speech translation and recognition .
The proposed method utilizes multi-task learning to integrate four self-supervised and supervised subtasks for cross modality learning .
A self-supervised speech subtask, which leverages unlabelled speech data, and a (self-)supervised text to text subtask, which makes use of abundant text training data, take up the majority of the pre-training time .
Two auxiliary supervised speech tasks are included to unify speech and text modeling space .
Detailed analysis reveals learning interference among subtasks .
In order to alleviate the subtask interference, two pre-training configurations are proposed for speech translation and speech recognition respectively .
Our experiments show the proposed method can effectively fuse speech and text information into one model .
It achieves between 1.7 and 2.3 BLEU improvement above the state of the art on the MuST-C speech translation dataset and comparable WERs to wav2vec 2.0 on the Librispeech speech recognition task .
Pretrained multilingual models enable zero-shot learning even for unseen languages, and that performance can be further improved via adaptation prior to finetuning .
However, it is unclear how the number of pretraining languages influences a model’s zero-shot learning for languages unseen during pretraining .
To fill this gap, we ask the following research questions: (1) How does the number of pretraining languages influence zero-shot performance on unseen target languages? (2) Does the answer to that question change with model adaptation? (3) Do the findings for our first question change if the languages used for pretraining are all related? Our experiments on pretraining with related languages indicate that choosing a diverse set of languages is crucial .
Without model adaptation, surprisingly, increasing the number of pretraining languages yields better results up to adding related languages, after which performance plateaus.In contrast, with model adaptation via continued pretraining, pretraining on a larger number of languages often gives further improvement, suggesting that model adaptation is crucial to exploit additional pretraining languages .
The growing size of neural language models has led to increased attention in model compression .
The two predominant approaches are pruning, which gradually removes weights from a pre-trained model, and distillation, which trains a smaller compact model to match a larger one .
Pruning methods can significantly reduce the model size but hardly achieve large speedups as distillation .
However, distillation methods require large amounts of unlabeled data and are expensive to train .
In this work, we propose a task-specific structured pruning method CoFi (Coarse- and Fine-grained Pruning), which delivers highly parallelizable subnetworks and matches the distillation methods in both accuracy and latency, without resorting to any unlabeled data .
Our key insight is to jointly prune coarse-grained (e.g., layers) and fine-grained (e.g., heads and hidden units) modules, which controls the pruning decision of each parameter with masks of different granularity .
We also devise a layerwise distillation strategy to transfer knowledge from unpruned to pruned models during optimization .
Our experiments on GLUE and SQuAD datasets show that CoFi yields models with over 10X speedups with a small accuracy drop, showing its effectiveness and efficiency compared to previous pruning and distillation approaches .
More than 43% of the languages spoken in the world are endangered, and language loss currently occurs at an accelerated rate because of globalization and neocolonialism .
Saving and revitalizing endangered languages has become very important for maintaining the cultural diversity on our planet .
In this work, we focus on discussing how NLP can help revitalize endangered languages .
We first suggest three principles that may help NLP practitioners to foster mutual understanding and collaboration with language communities, and we discuss three ways in which NLP can potentially assist in language education .
We then take Cherokee, a severely-endangered Native American language, as a case study .
After reviewing the language’s history, linguistic features, and existing resources, we (in collaboration with Cherokee community members) arrive at a few meaningful ways NLP practitioners can collaborate with community partners .
We suggest two approaches to enrich the Cherokee language’s resources with machine-in-the-loop processing, and discuss several NLP tools that people from the Cherokee community have shown interest in .
We hope that our work serves not only to inform the NLP community about Cherokee, but also to provide inspiration for future work on endangered languages in general .
The IMPRESSIONS section of a radiology report about an imaging study is a summary of the radiologist’s reasoning and conclusions, and it also aids the referring physician in confirming or excluding certain diagnoses .
A cascade of tasks are required to automatically generate an abstractive summary of the typical information-rich radiology report .
These tasks include acquisition of salient content from the report and generation of a concise, easily consumable IMPRESSIONS section .
Prior research on radiology report summarization has focused on single-step end-to-end models – which subsume the task of salient content acquisition .
To fully explore the cascade structure and explainability of radiology report summarization, we introduce two innovations .
First, we design a two-step approach: extractive summarization followed by abstractive summarization .
Second, we additionally break down the extractive part into two independent tasks: extraction of salient (1) sentences and (2) keywords .
Experiments on English radiology reports from two clinical sites show our novel approach leads to a more precise summary compared to single-step and to two-step-with-single-extractive-process baselines with an overall improvement in F1 score of 3-4% .
Standard conversational semantic parsing maps a complete user utterance into an executable program, after which the program is executed to respond to the user .
This could be slow when the program contains expensive function calls .
We investigate the opportunity to reduce latency by predicting and executing function calls while the user is still speaking .
We introduce the task of online semantic parsing for this purpose, with a formal latency reduction metric inspired by simultaneous machine translation .
We propose a general framework with first a learned prefix-to-program prediction module, and then a simple yet effective thresholding heuristic for subprogram selection for early execution .
Experiments on the SMCalFlow and TreeDST datasets show our approach achieves large latency reduction with good parsing quality, with a 30%–65% latency reduction depending on function execution time and allowed cost .
The enrichment of tabular datasets using external sources has gained significant attention in recent years .
Existing solutions, however, either ignore external unstructured data completely or devise dataset-specific solutions .
In this study we proposed Few-Shot Transformer based Enrichment (FeSTE), a generic and robust framework for the enrichment of tabular datasets using unstructured data .
By training over multiple datasets, our approach is able to develop generic models that can be applied to additional datasets with minimal training (i.e., few-shot) .
Our approach is based on an adaptation of BERT, for which we present a novel fine-tuning approach that reformulates the tuples of the datasets as sentences .
Our evaluation, conducted on 17 datasets, shows that FeSTE is able to generate high quality features and significantly outperform existing fine-tuning solutions .
Text summarization helps readers capture salient information from documents, news, interviews, and meetings .
However, most state-of-the-art pretrained language models (LM) are unable to efficiently process long text for many summarization tasks .
In this paper, we propose SummN, a simple, flexible, and effective multi-stage framework for input texts that are longer than the maximum context length of typical pretrained LMs .
SummN first splits the data samples and generates a coarse summary in multiple stages and then produces the final fine-grained summary based on it .
Our framework can process input text of arbitrary length by adjusting the number of stages while keeping the LM input size fixed .
Moreover, it can deal with both single-source documents and dialogues, and it can be used on top of different backbone abstractive summarization models .
To the best of our knowledge, SummN is the first multi-stage split-then-summarize framework for long input summarization .
Our experiments demonstrate that SummN outperforms previous state-of-the-art methods by improving ROUGE scores on three long meeting summarization datasets AMI, ICSI, and QMSum, two long TV series datasets from SummScreen, and a long document summarization dataset GovReport .
Our data and code are available at https://github.com/psunlpgroup/Summ-N .
The retriever-reader framework is popular for open-domain question answering (ODQA) due to its ability to use explicit knowledge.Although prior work has sought to increase the knowledge coverage by incorporating structured knowledge beyond text, accessing heterogeneous knowledge sources through a unified interface remains an open question .
While data-to-text generation has the potential to serve as a universal interface for data and text, its feasibility for downstream tasks remains largely unknown .
In this work, we bridge this gap and use the data-to-text method as a means for encoding structured knowledge for open-domain question answering .
Specifically, we propose a verbalizer-retriever-reader framework for ODQA over data and text where verbalized tables from Wikipedia and graphs from Wikidata are used as augmented knowledge sources .
We show that our Unified Data and Text QA, UDT-QA, can effectively benefit from the expanded knowledge index, leading to large gains over text-only baselines .
Notably, our approach sets the single-model state-of-the-art on Natural Questions .
Furthermore, our analyses indicate that verbalized knowledge is preferred for answer reasoning for both adapted and hot-swap settings .
Round-trip Machine Translation (MT) is a popular choice for paraphrase generation, which leverages readily available parallel corpora for supervision .
In this paper, we formalize the implicit similarity function induced by this approach, and show that it is susceptible to non-paraphrase pairs sharing a single ambiguous translation .
Based on these insights, we design an alternative similarity metric that mitigates this issue by requiring the entire translation distribution to match, and implement a relaxation of it through the Information Bottleneck method .
Our approach incorporates an adversarial term into MT training in order to learn representations that encode as much information about the reference translation as possible, while keeping as little information about the input as possible .
Paraphrases can be generated by decoding back to the source from this representation, without having to generate pivot translations .
In addition to being more principled and efficient than round-trip MT, our approach offers an adjustable parameter to control the fidelity-diversity trade-off, and obtains better results in our experiments .
Over the last few years, there has been a move towards data curation for multilingual task-oriented dialogue (ToD) systems that can serve people speaking different languages .
However, existing multilingual ToD datasets either have a limited coverage of languages due to the high cost of data curation, or ignore the fact that dialogue entities barely exist in countries speaking these languages .
To tackle these limitations, we introduce a novel data curation method that generates GlobalWoZ — a large-scale multilingual ToD dataset globalized from an English ToD dataset for three unexplored use cases of multilingual ToD systems .
Our method is based on translating dialogue templates and filling them with local entities in the target-language countries .
Besides, we extend the coverage of target languages to 20 languages .
We will release our dataset and a set of strong baselines to encourage research on multilingual ToD systems for real use cases .
Since the development and wide use of pretrained language models (PLMs), several approaches have been applied to boost their performance on downstream tasks in specific domains, such as biomedical or scientific domains .
Additional pre-training with in-domain texts is the most common approach for providing domain-specific knowledge to PLMs .
However, these pre-training methods require considerable in-domain data and training resources and a longer training time .
Moreover, the training must be re-performed whenever a new PLM emerges .
In this study, we propose a domain knowledge transferring (DoKTra) framework for PLMs without additional in-domain pretraining .
Specifically, we extract the domain knowledge from an existing in-domain pretrained language model and transfer it to other PLMs by applying knowledge distillation .
In particular, we employ activation boundary distillation, which focuses on the activation of hidden neurons .
We also apply an entropy regularization term in both teacher training and distillation to encourage the model to generate reliable output probabilities, and thus aid the distillation .
By applying the proposed DoKTra framework to downstream tasks in the biomedical, clinical, and financial domains, our student models can retain a high percentage of teacher performance and even outperform the teachers in certain tasks .
Our code is available at https://github.com/DMCB-GIST/DoKTra .
Deep NLP models have been shown to be brittle to input perturbations .
Recent work has shown that data augmentation using counterfactuals — i.e .
minimally perturbed inputs — can help ameliorate this weakness .
We focus on the task of creating counterfactuals for question answering, which presents unique challenges related to world knowledge, semantic diversity, and answerability .
To address these challenges, we develop a Retrieve-Generate-Filter(RGF) technique to create counterfactual evaluation and training data with minimal human supervision .
Using an open-domain QA framework and question generation model trained on original task data, we create counterfactuals that are fluent, semantically diverse, and automatically labeled .
Data augmentation with RGF counterfactuals improves performance on out-of-domain and challenging evaluation sets over and above existing methods, in both the reading comprehension and open-domain QA settings .
Moreover, we find that RGF data leads to significant improvements in a model’s robustness to local perturbations .
Transformer-based models have achieved state-of-the-art performance on short-input summarization .
However, they still struggle with summarizing longer text .
In this paper, we present DYLE, a novel dynamic latent extraction approach for abstractive long-input summarization .
DYLE jointly trains an extractor and a generator and treats the extracted text snippets as the latent variable, allowing dynamic snippet-level attention weights during decoding .
To provide adequate supervision, we propose simple yet effective heuristics for oracle extraction as well as a consistency loss term, which encourages the extractor to approximate the averaged dynamic weights predicted by the generator .
We evaluate our method on different long-document and long-dialogue summarization tasks: GovReport, QMSum, and arXiv .
Experiment results show that DYLE outperforms all existing methods on GovReport and QMSum, with gains up to 6.1 ROUGE, while yielding strong results on arXiv .
Further analysis shows that the proposed dynamic weights provide interpretability of our generation process .
Natural language processing for sign language video—including tasks like recognition, translation, and search—is crucial for making artificial intelligence technologies accessible to deaf individuals, and is gaining research interest in recent years .
In this paper, we address the problem of searching for fingerspelled keywords or key phrases in raw sign language videos .
This is an important task since significant content in sign language is often conveyed via fingerspelling, and to our knowledge the task has not been studied before .
We propose an end-to-end model for this task, FSS-Net, that jointly detects fingerspelling and matches it to a text sequence .
Our experiments, done on a large public dataset of ASL fingerspelling in the wild, show the importance of fingerspelling detection as a component of a search and retrieval model .
Our model significantly outperforms baseline methods adapted from prior work on related tasks .
We present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making .
We formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions .
We describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level sub-tasks, using only a small number of seed annotations to ground language in action .
In trained models, natural language commands index a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals .
We evaluate this approach in the ALFRED household simulation environment, providing natural language annotations for only 10% of demonstrations .
It achieves performance comparable state-of-the-art models on ALFRED success rate, outperforming several recent methods with access to ground-truth plans during training and evaluation .
A language-independent representation of meaning is one of the most coveted dreams in Natural Language Understanding .
With this goal in mind, several formalisms have been proposed as frameworks for meaning representation in Semantic Parsing .
And yet, the dependencies these formalisms share with respect to language-specific repositories of knowledge make the objective of closing the gap between high- and low-resourced languages hard to accomplish .
In this paper, we present the BabelNet Meaning Representation (BMR), an interlingual formalism that abstracts away from language-specific constraints by taking advantage of the multilingual semantic resources of BabelNet and VerbAtlas .
We describe the rationale behind the creation of BMR and put forward BMR 1.0, a dataset labeled entirely according to the new formalism .
Moreover, we show how BMR is able to outperform previous formalisms thanks to its fully-semantic framing, which enables top-notch multilingual parsing and generation .
We release the code at https://github.com/SapienzaNLP/bmr .
Personalized language models are designed and trained to capture language patterns specific to individual users .
This makes them more accurate at predicting what a user will write .
However, when a new user joins a platform and not enough text is available, it is harder to build effective personalized language models .
We propose a solution for this problem, using a model trained on users that are similar to a new user .
In this paper, we explore strategies for finding the similarity between new users and existing ones and methods for using the data from existing users who are a good match .
We further explore the trade-off between available data for new users and how well their language can be modeled .
It has been shown that machine translation models usually generate poor translations for named entities that are infrequent in the training corpus .
Earlier named entity translation methods mainly focus on phonetic transliteration, which ignores the sentence context for translation and is limited in domain and language coverage .
To address this limitation, we propose DEEP, a DEnoising Entity Pre-training method that leverages large amounts of monolingual data and a knowledge base to improve named entity translation accuracy within sentences .
Besides, we investigate a multi-task learning strategy that finetunes a pre-trained neural machine translation model on both entity-augmented monolingual data and parallel data to further improve entity translation .
Experimental results on three language pairs demonstrate that DEEP results in significant improvements over strong denoising auto-encoding baselines, with a gain of up to 1.3 BLEU and up to 9.2 entity accuracy points for English-Russian translation .
With the increasing popularity of posting multimodal messages online, many recent studies have been carried out utilizing both textual and visual information for multi-modal sarcasm detection .
In this paper, we investigate multi-modal sarcasm detection from a novel perspective by constructing a cross-modal graph for each instance to explicitly draw the ironic relations between textual and visual modalities .
Specifically, we first detect the objects paired with descriptions of the image modality, enabling the learning of important visual information .
Then, the descriptions of the objects are served as a bridge to determine the importance of the association between the objects of image modality and the contextual words of text modality, so as to build a cross-modal graph for each multi-modal instance .
Furthermore, we devise a cross-modal graph convolutional network to make sense of the incongruity relations between modalities for multi-modal sarcasm detection .
Extensive experimental results and in-depth analysis show that our model achieves state-of-the-art performance in multi-modal sarcasm detection .
Fine-tuning the entire set of parameters of a large pretrained model has become the mainstream approach for transfer learning .
To increase its efficiency and prevent catastrophic forgetting and interference, techniques like adapters and sparse fine-tuning have been developed .
Adapters are modular, as they can be combined to adapt a model towards different facets of knowledge (e.g., dedicated language and/or task adapters) .
Sparse fine-tuning is expressive, as it controls the behavior of all model components .
In this work, we introduce a new fine-tuning method with both these desirable properties .
In particular, we learn sparse, real-valued masks based on a simple variant of the Lottery Ticket Hypothesis .
Task-specific masks are obtained from annotated data in a source language, and language-specific masks from masked language modeling in a target language .
Both these masks can then be composed with the pretrained model .
Unlike adapter-based fine-tuning, this method neither increases the number of parameters at inference time nor alters the original model architecture .
Most importantly, it outperforms adapters in zero-shot cross-lingual transfer by a large margin in a series of multilingual benchmarks, including Universal Dependencies, MasakhaNER, and AmericasNLI .
Based on an in-depth analysis, we additionally find that sparsity is crucial to prevent both 1) interference between the fine-tunings to be composed and 2) overfitting .
We release the code and models at https://github.com/cambridgeltl/composable-sft .
Crowdsourcing has emerged as a popular approach for collecting annotated data to train supervised machine learning models .
However, annotator bias can lead to defective annotations .
Though there are a few works investigating individual annotator bias, the group effects in annotators are largely overlooked .
In this work, we reveal that annotators within the same demographic group tend to show consistent group bias in annotation tasks and thus we conduct an initial study on annotator group bias .
We first empirically verify the existence of annotator group bias in various real-world crowdsourcing datasets .
Then, we develop a novel probabilistic graphical framework GroupAnno to capture annotator group bias with an extended Expectation Maximization (EM) algorithm .
We conduct experiments on both synthetic and real-world datasets .
Experimental results demonstrate the effectiveness of our model in modeling annotator group bias in label aggregation and model learning over competitive baselines .
Gender bias is largely recognized as a problematic phenomenon affecting language technologies, with recent studies underscoring that it might surface differently across languages .
However, most of current evaluation practices adopt a word-level focus on a narrow set of occupational nouns under synthetic conditions .
Such protocols overlook key features of grammatical gender languages, which are characterized by morphosyntactic chains of gender agreement, marked on a variety of lexical items and parts-of-speech (POS) .
To overcome this limitation, we enrich the natural, gender-sensitive MuST-SHE corpus (Bentivogli et al., 2020) with two new linguistic annotation layers (POS and agreement chains), and explore to what extent different lexical categories and agreement phenomena are impacted by gender skews .
Focusing on speech translation, we conduct a multifaceted evaluation on three language directions (English-French/Italian/Spanish), with models trained on varying amounts of data and different word segmentation techniques .
By shedding light on model behaviours, gender bias, and its detection at several levels of granularity, our findings emphasize the value of dedicated analyses beyond aggregated overall results .
Open-domain questions are likely to be open-ended and ambiguous, leading to multiple valid answers .
Existing approaches typically adopt the rerank-then-read framework, where a reader reads top-ranking evidence to predict answers .
According to our empirical analysis, this framework faces three problems: first, to leverage a large reader under a memory constraint, the reranker should select only a few relevant passages to cover diverse answers, while balancing relevance and diversity is non-trivial; second, the small reading budget prevents the reader from accessing valuable retrieved evidence filtered out by the reranker; third, when using a generative reader to predict answers all at once based on all selected evidence, whether a valid answer will be predicted also pathologically depends on evidence of some other valid answer(s) .
To address these issues, we propose to answer open-domain multi-answer questions with a recall-then-verify framework, which separates the reasoning process of each answer so that we can make better use of retrieved evidence while also leveraging large models under the same memory constraint .
Our framework achieves state-of-the-art results on two multi-answer datasets, and predicts significantly more gold answers than a rerank-then-read system that uses an oracle reranker .
Pre-trained contextual representations have led to dramatic performance improvements on a range of downstream tasks .
Such performance improvements have motivated researchers to quantify and understand the linguistic information encoded in these representations .
In general, researchers quantify the amount of linguistic information through probing, an endeavor which consists of training a supervised model to predict a linguistic property directly from the contextual representations .
Unfortunately, this definition of probing has been subject to extensive criticism in the literature, and has been observed to lead to paradoxical and counter-intuitive results .
In the theoretical portion of this paper, we take the position that the goal of probing ought to be measuring the amount of inductive bias that the representations encode on a specific task .
We further describe a Bayesian framework that operationalizes this goal and allows us to quantify the representations’ inductive bias .
In the empirical portion of the paper, we apply our framework to a variety of NLP tasks .
Our results suggest that our proposed framework alleviates many previous problems found in probing .
Moreover, we are able to offer concrete evidence that—for some tasks—fastText can offer a better inductive bias than BERT .
Structured pruning has been extensively studied on monolingual pre-trained language models and is yet to be fully evaluated on their multilingual counterparts .
This work investigates three aspects of structured pruning on multilingual pre-trained language models: settings, algorithms, and efficiency .
Experiments on nine downstream tasks show several counter-intuitive phenomena: for settings, individually pruning for each language does not induce a better result; for algorithms, the simplest method performs the best; for efficiency, a fast model does not imply that it is also small .
To facilitate the comparison on all sparsity levels, we present Dynamic Sparsification, a simple approach that allows training the model once and adapting to different model sizes at inference .
We hope this work fills the gap in the study of structured pruning on multilingual pre-trained models and sheds light on future research .
Deep learning (DL) techniques involving fine-tuning large numbers of model parameters have delivered impressive performance on the task of discriminating between language produced by cognitively healthy individuals, and those with Alzheimer’s disease (AD) .
However, questions remain about their ability to generalize beyond the small reference sets that are publicly available for research .
As an alternative to fitting model parameters directly, we propose a novel method by which a Transformer DL model (GPT-2) pre-trained on general English text is paired with an artificially degraded version of itself (GPT-D), to compute the ratio between these two models’ perplexities on language from cognitively healthy and impaired individuals .
This technique approaches state-of-the-art performance on text data from a widely used “Cookie Theft” picture description task, and unlike established alternatives also generalizes well to spontaneous conversations .
Furthermore, GPT-D generates text with characteristics known to be associated with AD, demonstrating the induction of dementia-related linguistic anomalies .
Our study is a step toward better understanding of the relationships between the inner workings of generative neural language models, the language that they produce, and the deleterious effects of dementia on human speech and language characteristics .
Recent work has shown pre-trained language models capture social biases from the large amounts of text they are trained on .
This has attracted attention to developing techniques that mitigate such biases .
In this work, we perform an empirical survey of five recently proposed bias mitigation techniques: Counterfactual Data Augmentation (CDA), Dropout, Iterative Nullspace Projection, Self-Debias, and SentenceDebias .
We quantify the effectiveness of each technique using three intrinsic bias benchmarks while also measuring the impact of these techniques on a model’s language modeling ability, as well as its performance on downstream NLU tasks .
We experimentally find that: (1) Self-Debias is the strongest debiasing technique, obtaining improved scores on all bias benchmarks; (2) Current debiasing techniques perform less consistently when mitigating non-gender biases; And (3) improvements on bias benchmarks such as StereoSet and CrowS-Pairs by using debiasing strategies are often accompanied by a decrease in language modeling ability, making it difficult to determine whether the bias mitigation was effective .
While GPT has become the de-facto method for text generation tasks, its application to pinyin input method remains unexplored.In this work, we make the first exploration to leverage Chinese GPT for pinyin input method.We find that a frozen GPT achieves state-of-the-art performance on perfect pinyin.However, the performance drops dramatically when the input includes abbreviated pinyin.A reason is that an abbreviated pinyin can be mapped to many perfect pinyin, which links to even larger number of Chinese characters.We mitigate this issue with two strategies,including enriching the context with pinyin and optimizing the training process to help distinguish homophones .
To further facilitate the evaluation of pinyin input method, we create a dataset consisting of 270K instances from fifteen domains.Results show that our approach improves the performance on abbreviated pinyin across all domains.Model analysis demonstrates that both strategiescontribute to the performance boost .
Cross-lingual natural language inference (XNLI) is a fundamental task in cross-lingual natural language understanding .
Recently this task is commonly addressed by pre-trained cross-lingual language models .
Existing methods usually enhance pre-trained language models with additional data, such as annotated parallel corpora .
These additional data, however, are rare in practice, especially for low-resource languages .
Inspired by recent promising results achieved by prompt-learning, this paper proposes a novel prompt-learning based framework for enhancing XNLI .
It reformulates the XNLI problem to a masked language modeling problem by constructing cloze-style questions through cross-lingual templates .
To enforce correspondence between different languages, the framework augments a new question for every question using a sampled template in another language and then introduces a consistency loss to make the answer probability distribution obtained from the new question as similar as possible with the corresponding distribution obtained from the original question .
Experimental results on two benchmark datasets demonstrate that XNLI models enhanced by our proposed framework significantly outperform original ones under both the full-shot and few-shot cross-lingual transfer settings .
Sense embedding learning methods learn different embeddings for the different senses of an ambiguous word .
One sense of an ambiguous word might be socially biased while its other senses remain unbiased .
In comparison to the numerous prior work evaluating the social biases in pretrained word embeddings, the biases in sense embeddings have been relatively understudied .
We create a benchmark dataset for evaluating the social biases in sense embeddings and propose novel sense-specific bias evaluation measures .
We conduct an extensive evaluation of multiple static and contextualised sense embeddings for various types of social biases using the proposed measures .
Our experimental results show that even in cases where no biases are found at word-level, there still exist worrying levels of social biases at sense-level, which are often ignored by the word-level bias evaluation measures .
We consider the problem of generating natural language given a communicative goal and a world description .
We ask the question: is it possible to combine complementary meaning representations to scale a goal-directed NLG system without losing expressiveness? In particular, we consider using two meaning representations, one based on logical semantics and the other based on distributional semantics .
We build upon an existing goal-directed generation system, S-STRUCT, which models sentence generation as planning in a Markov decision process .
We develop a hybrid approach, which uses distributional semantics to quickly and imprecisely add the main elements of the sentence and then uses first-order logic based semantics to more slowly add the precise details .
We find that our hybrid method allows S-STRUCT’s generation to scale significantly better in early phases of generation and that the hybrid can often generate sentences with the same quality as S-STRUCT in substantially less time .
However, we also observe and give insight into cases where the imprecision in distributional semantics leads to generation that is not as good as using pure logical semantics .
Clinical trials offer a fundamental opportunity to discover new treatments and advance the medical knowledge .
However, the uncertainty of the outcome of a trial can lead to unforeseen costs and setbacks .
In this study, we propose a new method to predict the effectiveness of an intervention in a clinical trial .
Our method relies on generating an informative summary from multiple documents available in the literature about the intervention under study .
Specifically, our method first gathers all the abstracts of PubMed articles related to the intervention .
Then, an evidence sentence, which conveys information about the effectiveness of the intervention, is extracted automatically from each abstract .
Based on the set of evidence sentences extracted from the abstracts, a short summary about the intervention is constructed .
Finally, the produced summaries are used to train a BERT-based classifier, in order to infer the effectiveness of an intervention .
To evaluate our proposed method, we introduce a new dataset which is a collection of clinical trials together with their associated PubMed articles .
Our experiments, demonstrate the effectiveness of producing short informative summaries and using them to predict the effectiveness of an intervention .
Interactive neural machine translation (INMT) is able to guarantee high-quality translations by taking human interactions into account .
Existing IMT systems relying on lexical constrained decoding (LCD) enable humans to translate in a flexible translation order beyond the left-to-right .
However, they typically suffer from two significant limitations in translation efficiency and quality due to the reliance on LCD .
In this work, we propose a novel BiTIIMT system, Bilingual Text-Infilling for Interactive Neural Machine Translation .
The key idea to BiTIIMT is Bilingual Text-infilling (BiTI) which aims to fill missing segments in a manually revised translation for a given source sentence .
We propose a simple yet effective solution by casting this task as a sequence-to-sequence task .
In this way, our system performs decoding without explicit constraints and makes full use of revised words for better translation prediction .
Experiment results show that BiTiIMT performs significantly better and faster than state-of-the-art LCD-based IMT on three translation tasks .
In this study, we investigate robustness against covariate drift in spoken language understanding (SLU) .
Covariate drift can occur in SLUwhen there is a drift between training and testing regarding what users request or how they request it .
To study this we propose a method that exploits natural variations in data to create a covariate drift in SLU datasets .
Experiments show that a state-of-the-art BERT-based model suffers performance loss under this drift .
To mitigate the performance loss, we investigate distributionally robust optimization (DRO) for finetuning BERT-based models .
We discuss some recent DRO methods, propose two new variants and empirically show that DRO improves robustness under drift .
Chinese pre-trained language models usually exploit contextual character information to learn representations, while ignoring the linguistics knowledge, e.g., word and sentence information .
Hence, we propose a task-free enhancement module termed as Heterogeneous Linguistics Graph (HLG) to enhance Chinese pre-trained language models by integrating linguistics knowledge .
Specifically, we construct a hierarchical heterogeneous graph to model the characteristics linguistics structure of Chinese language, and conduct a graph-based method to summarize and concretize information on different granularities of Chinese linguistics hierarchies.Experimental results demonstrate our model has the ability to improve the performance of vanilla BERT, BERTwwm and ERNIE 1.0 on 6 natural language processing tasks with 10 benchmark datasets .
Further, the detailed experimental analyses have proven that this kind of modelization achieves more improvements compared with previous strong baseline MWA .
Meanwhile, our model introduces far fewer parameters (about half of MWA) and the training/inference speed is about 7x faster than MWA .
Fine-grained Entity Typing (FET) has made great progress based on distant supervision but still suffers from label noise .
Existing FET noise learning methods rely on prediction distributions in an instance-independent manner, which causes the problem of confirmation bias .
In this work, we propose a clustering-based loss correction framework named Feature Cluster Loss Correction (FCLC), to address these two problems .
FCLC first train a coarse backbone model as a feature extractor and noise estimator .
Loss correction is then applied to each feature cluster, learning directly from the noisy labels .
Experimental results on three public datasets show that FCLC achieves the best performance over existing competitive systems .
Auxiliary experiments further demonstrate that FCLC is stable to hyperparameters and it does help mitigate confirmation bias .
We also find that in the extreme case of no clean data, the FCLC framework still achieves competitive performance .
The robustness of Text-to-SQL parsers against adversarial perturbations plays a crucial role in delivering highly reliable applications .
Previous studies along this line primarily focused on perturbations in the natural language question side, neglecting the variability of tables .
Motivated by this, we propose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to measure robustness of Text-to-SQL models .
Following this proposition, we curate ADVETA, the first robustness evaluation benchmark featuring natural and realistic ATPs .
All tested state-of-the-art models experience dramatic performance drops on ADVETA, revealing significant room of improvement .
To defense against ATP, we build a systematic adversarial training example generation framework tailored for better contextualization of tabular data .
Experiments show that our approach brings models best robustness improvement against ATP, while also substantially boost model robustness against NL-side perturbations .
We will release ADVETA and code to facilitate future research .
Neural networks tend to gradually forget the previously learned knowledge when learning multiple tasks sequentially from dynamic data distributions .
This problem is called catastrophic forgetting, which is a fundamental challenge in the continual learning of neural networks .
In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training .
Neural networks, especially neural machine translation models, suffer from catastrophic forgetting even if they learn from a static training set .
To be specific, the final model pays imbalanced attention to training samples, where recently exposed samples attract more attention than earlier samples .
The underlying cause is that training samples do not get balanced training in each model update, so we name this problem imbalanced training .
To alleviate this problem, we propose Complementary Online Knowledge Distillation (COKD), which uses dynamically updated teacher models trained on specific data orders to iteratively provide complementary knowledge to the student model .
Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems .
Human languages are full of metaphorical expressions .
Metaphors help people understand the world by connecting new concepts and domains to more familiar ones .
Large pre-trained language models (PLMs) are therefore assumed to encode metaphorical knowledge useful for NLP systems .
In this paper, we investigate this hypothesis for PLMs, by probing metaphoricity information in their encodings, and by measuring the cross-lingual and cross-dataset generalization of this information .
We present studies in multiple metaphor detection datasets and in four languages (i.e., English, Spanish, Russian, and Farsi) .
Our extensive experiments suggest that contextual representations in PLMs do encode metaphorical knowledge, and mostly in their middle layers .
The knowledge is transferable between languages and datasets, especially when the annotation is consistent across training and testing sets .
Our findings give helpful insights for both cognitive and NLP scientists .
Dependency trees have been intensively used with graph neural networks for aspect-based sentiment classification .
Though being effective, such methods rely on external dependency parsers, which can be unavailable for low-resource languages or perform worse in low-resource domains .
In addition, dependency trees are also not optimized for aspect-based sentiment classification .
In this paper, we propose an aspect-specific and language-agnostic discrete latent opinion tree model as an alternative structure to explicit dependency trees .
To ease the learning of complicated structured latent variables, we build a connection between aspect-to-context attention scores and syntactic distances, inducing trees from the attention scores .
Results on six English benchmarks and one Chinese dataset show that our model can achieve competitive performance and interpretability .
Thanks to the strong representation power of neural encoders, neural chart-based parsers have achieved highly competitive performance by using local features .
Recently, it has been shown that non-local features in CRF structures lead to improvements .
In this paper, we investigate injecting non-local features into the training process of a local span-based parser, by predicting constituent n-gram non-local patterns and ensuring consistency between non-local patterns and local constituents .
Results show that our simple method gives better results than the self-attentive parser on both PTB and CTB .
Besides, our method achieves state-of-the-art BERT-based performance on PTB (95.92 F1) and strong performance on CTB (92.31 F1) .
Our parser also outperforms the self-attentive parser in multi-lingual and zero-shot cross-domain settings .
In this paper, we firstly empirically find that existing models struggle to handle hard mentions due to their insufficient contexts, which consequently limits their overall typing performance .
To this end, we propose to exploit sibling mentions for enhancing the mention representations.Specifically, we present two different metrics for sibling selection and employ an attentive graph neural network to aggregate information from sibling mentions .
The proposed graph model is scalable in that unseen test mentions are allowed to be added as new nodes for inference.Exhaustive experiments demonstrate the effectiveness of our sibling learning strategy, where our model outperforms ten strong baselines .
Moreover, our experiments indeed prove the superiority of sibling mentions in helping clarify the types for hard mentions .
The goal of the cross-lingual summarization (CLS) is to convert a document in one language (e.g., English) to a summary in another one (e.g., Chinese) .
The CLS task is essentially the combination of machine translation (MT) and monolingual summarization (MS), and thus there exists the hierarchical relationship between MT&MS and CLS .
Existing studies on CLS mainly focus on utilizing pipeline methods or jointly training an end-to-end model through an auxiliary MT or MS objective .
However, it is very challenging for the model to directly conduct CLS as it requires both the abilities to translate and summarize .
To address this issue, we propose a hierarchical model for the CLS task, based on the conditional variational auto-encoder .
The hierarchical model contains two kinds of latent variables at the local and global levels, respectively .
At the local level, there are two latent variables, one for translation and the other for summarization .
As for the global level, there is another latent variable for cross-lingual summarization conditioned on the two local-level variables .
Experiments on two language directions (English-Chinese) verify the effectiveness and superiority of the proposed approach .
In addition, we show that our model is able to generate better cross-lingual summaries than comparison models in the few-shot setting .
In conversational question answering (CQA), the task of question rewriting (QR) in context aims to rewrite a context-dependent question into an equivalent self-contained question that gives the same answer .
In this paper, we are interested in the robustness of a QR system to questions varying in rewriting hardness or difficulty .
Since there is a lack of questions classified based on their rewriting hardness, we first propose a heuristic method to automatically classify questions into subsets of varying hardness, by measuring the discrepancy between a question and its rewrite .
To find out what makes questions hard or easy for rewriting, we then conduct a human evaluation to annotate the rewriting hardness of questions .
Finally, to enhance the robustness of QR systems to questions of varying hardness, we propose a novel learning framework for QR that first trains a QR model independently on each subset of questions of a certain level of hardness, then combines these QR models as one joint model for inference .
Experimental results on two datasets show that our framework improves the overall performance compared to the baselines .
AI technologies for Natural Languages have made tremendous progress recently .
However, commensurate progress has not been made on Sign Languages, in particular, in recognizing signs as individual words or as complete sentences .
We introduce OpenHands, a library where we take four key ideas from the NLP community for low-resource languages and apply them to sign languages for word-level recognition .
First, we propose using pose extracted through pretrained models as the standard modality of data in this work to reduce training time and enable efficient inference, and we release standardized pose datasets for different existing sign language datasets .
Second, we train and release checkpoints of 4 pose-based isolated sign language recognition models across 6 languages (American, Argentinian, Chinese, Greek, Indian, and Turkish), providing baselines and ready checkpoints for deployment .
Third, to address the lack of labelled data, we propose self-supervised pretraining on unlabelled data .
We curate and release the largest pose-based pretraining dataset on Indian Sign Language (Indian-SL) .
Fourth, we compare different pretraining strategies and for the first time establish that pretraining is effective for sign language recognition by demonstrating (a) improved fine-tuning performance especially in low-resource settings, and (b) high crosslingual transfer from Indian-SL to few other sign languages .
We open-source all models and datasets in OpenHands with a hope that it makes research in sign languages reproducible and more accessible .
In recent years, researchers tend to pre-train ever-larger language models to explore the upper limit of deep models .
However, large language model pre-training costs intensive computational resources, and most of the models are trained from scratch without reusing the existing pre-trained models, which is wasteful .
In this paper, we propose bert2BERT, which can effectively transfer the knowledge of an existing smaller pre-trained model to a large model through parameter initialization and significantly improve the pre-training efficiency of the large model .
Specifically, we extend the previous function-preserving method proposed in computer vision on the Transformer-based language model, and further improve it by proposing a novel method, advanced knowledge for large model’s initialization .
In addition, a two-stage learning method is proposed to further accelerate the pre-training .
We conduct extensive experiments on representative PLMs (e.g., BERT and GPT) and demonstrate that (1) our method can save a significant amount of training cost compared with baselines including learning from scratch, StackBERT and MSLT; (2) our method is generic and applicable to different types of pre-trained models .
In particular, bert2BERT saves about 45% and 47% computational cost of pre-training BERT\rm BASE and GPT\rm BASE by reusing the models of almost their half sizes .
As an important task in sentiment analysis, Multimodal Aspect-Based Sentiment Analysis (MABSA) has attracted increasing attention inrecent years .
However, previous approaches either (i) use separately pre-trained visual and textual models, which ignore the crossmodalalignment or (ii) use vision-language models pre-trained with general pre-training tasks, which are inadequate to identify fine-grainedaspects, opinions, and their alignments across modalities .
To tackle these limitations, we propose a task-specific Vision-LanguagePre-training framework for MABSA (VLP-MABSA), which is a unified multimodal encoder-decoder architecture for all the pretrainingand downstream tasks .
We further design three types of task-specific pre-training tasks from the language, vision, and multimodalmodalities, respectively .
Experimental results show that our approach generally outperforms the state-of-the-art approaches on three MABSA subtasks .
Further analysis demonstrates the effectiveness of each pre-training task .
The source code is publicly released at https://github.com/NUSTM/VLP-MABSA .
Hedges have an important role in the management of rapport .
In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges .
We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature .
Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret .
We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach .
k-Nearest-Neighbor Machine Translation (kNN-MT) has been recently proposed as a non-parametric solution for domain adaptation in neural machine translation (NMT) .
It aims to alleviate the performance degradation of advanced MT systems in translating out-of-domain sentences by coordinating with an additional token-level feature-based retrieval module constructed from in-domain data .
Previous studies (Khandelwal et al., 2021; Zheng et al., 2021) have already demonstrated that non-parametric NMT is even superior to models fine-tuned on out-of-domain data .
In spite of this success, kNN retrieval is at the expense of high latency, in particular for large datastores .
To make it practical, in this paper, we explore a more efficient kNN-MT and propose to use clustering to improve the retrieval efficiency .
Concretely, we first propose a cluster-based Compact Network for feature reduction in a contrastive learning manner to compress context features into 90+% lower dimensional vectors .
We then suggest a cluster-based pruning solution to filter out 10% 40% redundant nodes in large datastores while retaining translation quality .
Our proposed methods achieve better or comparable performance while reducing up to 57% inference latency against the advanced non-parametric MT model on several machine translation benchmarks .
Experimental results indicate that the proposed methods maintain the most useful information of the original datastore and the Compact Network shows good generalization on unseen domains .
Codes are available at https://github.com/tjunlp-lab/PCKMT .
We propose a new method for projective dependency parsing based on headed spans .
In a projective dependency tree, the largest subtree rooted at each word covers a contiguous sequence (i.e., a span) in the surface order .
We call such a span marked by a root word headed span .
A projective dependency tree can be represented as a collection of headed spans .
We decompose the score of a dependency tree into the scores of the headed spans and design a novel O(n3) dynamic programming algorithm to enable global training and exact inference .
Our model achieves state-of-the-art or competitive results on PTB, CTB, and UD .
This work explores techniques to predict Part-of-Speech (PoS) tags from neural signals measured at millisecond resolution with electroencephalography (EEG) during text reading .
We first show that information about word length, frequency and word class is encoded by the brain at different post-stimulus latencies .
We then demonstrate that pre-training on averaged EEG data and data augmentation techniques boost PoS decoding accuracy for single EEG trials .
Finally, applying optimised temporally-resolved decoding techniques we show that Transformers substantially outperform linear-SVMs on PoS tagging of unigram and bigram data .
Recent works on Lottery Ticket Hypothesis have shown that pre-trained language models (PLMs) contain smaller matching subnetworks(winning tickets) which are capable of reaching accuracy comparable to the original models .
However, these tickets are proved to be notrobust to adversarial examples, and even worse than their PLM counterparts .
To address this problem, we propose a novel method based on learning binary weight masks to identify robust tickets hidden in the original PLMs .
Since the loss is not differentiable for the binary mask, we assign the hard concrete distribution to the masks and encourage their sparsity using a smoothing approximation of L0 regularization.Furthermore, we design an adversarial loss objective to guide the search for robust tickets and ensure that the tickets perform well bothin accuracy and robustness .
Experimental results show the significant improvement of the proposed method over previous work on adversarial robustness evaluation .
Tuning pre-trained language models (PLMs) with task-specific prompts has been a promising approach for text classification .
Particularly, previous studies suggest that prompt-tuning has remarkable superiority in the low-data scenario over the generic fine-tuning methods with extra classifiers .
The core idea of prompt-tuning is to insert text pieces, i.e., template, to the input and transform a classification problem into a masked language modeling problem, where a crucial step is to construct a projection, i.e., verbalizer, between a label space and a label word space .
A verbalizer is usually handcrafted or searched by gradient descent, which may lack coverage and bring considerable bias and high variances to the results .
In this work, we focus on incorporating external knowledge into the verbalizer, forming a knowledgeable prompttuning (KPT), to improve and stabilize prompttuning .
Specifically, we expand the label word space of the verbalizer using external knowledge bases (KBs) and refine the expanded label word space with the PLM itself before predicting with the expanded label word space .
Extensive experiments on zero and few-shot text classification tasks demonstrate the effectiveness of knowledgeable prompt-tuning .
Fine-grained entity typing (FGET) aims to classify named entity mentions into fine-grained entity types, which is meaningful for entity-related NLP tasks .
For FGET, a key challenge is the low-resource problem — the complex entity type hierarchy makes it difficult to manually label data .
Especially for those languages other than English, human-labeled data is extremely scarce .
In this paper, we propose a cross-lingual contrastive learning framework to learn FGET models for low-resource languages .
Specifically, we use multi-lingual pre-trained language models (PLMs) as the backbone to transfer the typing knowledge from high-resource languages (such as English) to low-resource languages (such as Chinese) .
Furthermore, we introduce entity-pair-oriented heuristic rules as well as machine translation to obtain cross-lingual distantly-supervised data, and apply cross-lingual contrastive learning on the distantly-supervised data to enhance the backbone PLMs .
Experimental results show that by applying our framework, we can easily learn effective FGET models for low-resource languages, even without any language-specific human-labeled data .
Our code is also available at https://github.com/thunlp/CrossET .
Data augmentation is an effective solution to data scarcity in low-resource scenarios .
However, when applied to token-level tasks such as NER, data augmentation methods often suffer from token-label misalignment, which leads to unsatsifactory performance .
In this work, we propose Masked Entity Language Modeling (MELM) as a novel data augmentation framework for low-resource NER .
To alleviate the token-label misalignment issue, we explicitly inject NER labels into sentence context, and thus the fine-tuned MELM is able to predict masked entity tokens by explicitly conditioning on their labels .
Thereby, MELM generates high-quality augmented data with novel entities, which provides rich entity regularity knowledge and boosts NER performance .
When training data from multiple languages are available, we also integrate MELM with code-mixing for further improvement .
We demonstrate the effectiveness of MELM on monolingual, cross-lingual and multilingual NER across various low-resource levels .
Experimental results show that our MELM consistently outperforms the baseline methods .
Learning representations of words in a continuous space is perhaps the most fundamental task in NLP, however words interact in ways much richer than vector dot product similarity can provide .
Many relationships between words can be expressed set-theoretically, for example, adjective-noun compounds (eg .
“red cars”⊆“cars”) and homographs (eg .
“tongue”∩“body” should be similar to “mouth”, while “tongue”∩“language” should be similar to “dialect”) have natural set-theoretic interpretations .
Box embeddings are a novel region-based representation which provide the capability to perform these set-theoretic operations .
In this work, we provide a fuzzy-set interpretation of box embeddings, and learn box representations of words using a set-theoretic training objective .
We demonstrate improved performance on various word similarity tasks, particularly on less common words, and perform a quantitative and qualitative analysis exploring the additional unique expressivity provided by Word2Box .
Traditionally, a debate usually requires a manual preparation process, including reading plenty of articles, selecting the claims, identifying the stances of the claims, seeking the evidence for the claims, etc .
As the AI debate attracts more attention these years, it is worth exploring the methods to automate the tedious process involved in the debating system .
In this work, we introduce a comprehensive and large dataset named IAM, which can be applied to a series of argument mining tasks, including claim extraction, stance classification, evidence extraction, etc .
Our dataset is collected from over 1k articles related to 123 topics .
Near 70k sentences in the dataset are fully annotated based on their argument properties (e.g., claims, stances, evidence, etc.) .
We further propose two new integrated argument mining tasks associated with the debate preparation process: (1) claim extraction with stance classification (CESC) and (2) claim-evidence pair extraction (CEPE) .
We adopt a pipeline approach and an end-to-end method for each integrated task separately .
Promising experimental results are reported to show the values and challenges of our proposed tasks, and motivate future research on argument mining .
Despite recent progress of pre-trained language models on generating fluent text, existing methods still suffer from incoherence problems in long-form text generation tasks that require proper content control and planning to form a coherent high-level logical flow .
In this work, we propose PLANET, a novel generation framework leveraging autoregressive self-attention mechanism to conduct content planning and surface realization dynamically .
To guide the generation of output sentences, our framework enriches the Transformer decoder with latent representations to maintain sentence-level semantic plans grounded by bag-of-words .
Moreover, we introduce a new coherence-based contrastive learning objective to further improve the coherence of output .
Extensive experiments are conducted on two challenging long-form text generation tasks including counterargument generation and opinion article generation .
Both automatic and human evaluations show that our method significantly outperforms strong baselines and generates more coherent texts with richer contents .
Existing reference-free metrics have obvious limitations for evaluating controlled text generation models .
Unsupervised metrics can only provide a task-agnostic evaluation result which correlates weakly with human judgments, whereas supervised ones may overfit task-specific data with poor generalization ability to other datasets .
In this paper, we propose an unsupervised reference-free metric called CTRLEval, which evaluates controlled text generation from different aspects by formulating each aspect into multiple text infilling tasks .
On top of these tasks, the metric assembles the generation probabilities from a pre-trained language model without any model training .
Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities .
In dialogue state tracking, dialogue history is a crucial material, and its utilization varies between different models .
However, no matter how the dialogue history is used, each existing model uses its own consistent dialogue history during the entire state tracking process, regardless of which slot is updated .
Apparently, it requires different dialogue history to update different slots in different turns .
Therefore, using consistent dialogue contents may lead to insufficient or redundant information for different slots, which affects the overall performance .
To address this problem, we devise DiCoS-DST to dynamically select the relevant dialogue contents corresponding to each slot for state updating .
Specifically, it first retrieves turn-level utterances of dialogue history and evaluates their relevance to the slot from a combination of three perspectives: (1) its explicit connection to the slot name; (2) its relevance to the current turn dialogue; (3) Implicit Mention Oriented Reasoning .
Then these perspectives are combined to yield a decision, and only the selected dialogue contents are fed into State Generator, which explicitly minimizes the distracting information passed to the downstream state prediction .
Experimental results show that our approach achieves new state-of-the-art performance on MultiWOZ 2.1 and MultiWOZ 2.2, and achieves superior performance on multiple mainstream benchmark datasets (including Sim-M, Sim-R, and DSTC2) .
Finetuning large pre-trained language models with a task-specific head has advanced the state-of-the-art on many natural language understanding benchmarks .
However, models with a task-specific head require a lot of training data, making them susceptible to learning and exploiting dataset-specific superficial cues that do not generalize to other datasets.Prompting has reduced the data requirement by reusing the language model head and formatting the task input to match the pre-training objective .
Therefore, it is expected that few-shot prompt-based models do not exploit superficial cues.This paper presents an empirical examination of whether few-shot prompt-based models also exploit superficial cues.Analyzing few-shot prompt-based models on MNLI, SNLI, HANS, and COPA has revealed that prompt-based models also exploit superficial cues .
While the models perform well on instances with superficial cues, they often underperform or only marginally outperform random accuracy on instances without superficial cues .
Confidence estimation aims to quantify the confidence of the model prediction, providing an expectation of success .
A well-calibrated confidence estimate enables accurate failure prediction and proper risk measurement when given noisy samples and out-of-distribution data in real-world settings .
However, this task remains a severe challenge for neural machine translation (NMT), where probabilities from softmax distribution fail to describe when the model is probably mistaken .
To address this problem, we propose an unsupervised confidence estimate learning jointly with the training of the NMT model .
We explain confidence as how many hints the NMT model needs to make a correct prediction, and more hints indicate low confidence .
Specifically, the NMT model is given the option to ask for hints to improve translation accuracy at the cost of some slight penalty .
Then, we approximate their level of confidence by counting the number of hints the model uses .
We demonstrate that our learned confidence estimate achieves high accuracy on extensive sentence/word-level quality estimation tasks .
Analytical results verify that our confidence estimate can correctly assess underlying risk in two real-world scenarios: (1) discovering noisy samples and (2) detecting out-of-domain data .
We further propose a novel confidence-based instance-specific label smoothing approach based on our learned confidence estimate, which outperforms standard label smoothing .
Spatial commonsense, the knowledge about spatial position and relationship between objects (like the relative size of a lion and a girl, and the position of a boy relative to a bicycle when cycling), is an important part of commonsense knowledge .
Although pretrained language models (PLMs) succeed in many NLP tasks, they are shown to be ineffective in spatial commonsense reasoning .
Starting from the observation that images are more likely to exhibit spatial commonsense than texts, we explore whether models with visual signals learn more spatial commonsense than text-based PLMs .
We propose a spatial commonsense benchmark that focuses on the relative scales of objects, and the positional relationship between people and objects under different actions.We probe PLMs and models with visual signals, including vision-language pretrained models and image synthesis models, on this benchmark, and find that image synthesis models are more capable of learning accurate and consistent spatial knowledge than other models .
The spatial knowledge from image synthesis models also helps in natural language understanding tasks that require spatial commonsense .
Token-level adaptive training approaches can alleviate the token imbalance problem and thus improve neural machine translation, through re-weighting the losses of different target tokens based on specific statistical metrics (e.g., token frequency or mutual information) .
Given that standard translation models make predictions on the condition of previous target contexts, we argue that the above statistical metrics ignore target context information and may assign inappropriate weights to target tokens .
While one possible solution is to directly take target contexts into these statistical metrics, the target-context-aware statistical computing is extremely expensive, and the corresponding storage overhead is unrealistic .
To solve the above issues, we propose a target-context-aware metric, named conditional bilingual mutual information (CBMI), which makes it feasible to supplement target context information for statistical metrics .
Particularly, our CBMI can be formalized as the log quotient of the translation model probability and language model probability by decomposing the conditional joint distribution .
Thus CBMI can be efficiently calculated during model training without any pre-specific statistical calculations and large storage overhead .
Furthermore, we propose an effective adaptive training approach based on both the token- and sentence-level CBMI .
Experimental results on WMT14 English-German and WMT19 Chinese-English tasks show our approach can significantly outperform the Transformer baseline and other related methods .
Recently, a lot of research has been carried out to improve the efficiency of Transformer .
Among them, the sparse pattern-based method is an important branch of efficient Transformers .
However, some existing sparse methods usually use fixed patterns to select words, without considering similarities between words .
Other sparse methods use clustering patterns to select words, but the clustering process is separate from the training process of the target task, which causes a decrease in effectiveness .
To address these limitations, we design a neural clustering method, which can be seamlessly integrated into the Self-Attention Mechanism in Transformer .
The clustering task and the target task are jointly trained and optimized to benefit each other, leading to significant effectiveness improvement .
In addition, our method groups the words with strong dependencies into the same cluster and performs the attention mechanism for each cluster independently, which improves the efficiency .
We verified our method on machine translation, text classification, natural language inference, and text matching tasks .
Experimental results show that our method outperforms two typical sparse attention methods, Reformer and Routing Transformer while having a comparable or even better time and memory efficiency .
Constituency parsing and nested named entity recognition (NER) are similar tasks since they both aim to predict a collection of nested and non-crossing spans .
In this work, we cast nested NER to constituency parsing and propose a novel pointing mechanism for bottom-up parsing to tackle both tasks .
The key idea is based on the observation that if we traverse a constituency tree in post-order, i.e., visiting a parent after its children, then two consecutively visited spans would share a boundary .
Our model tracks the shared boundaries and predicts the next boundary at each step by leveraging a pointer network .
As a result, it needs only linear steps to parse and thus is efficient .
It also maintains a parsing configuration for structural consistency, i.e., always outputting valid trees .
Experimentally, our model achieves the state-of-the-art performance on PTB among all BERT-based models (96.01 F1 score) and competitive performance on CTB7 in constituency parsing; and it also achieves strong performance on three benchmark datasets of nested NER: ACE2004, ACE2005, and GENIA .
Our code will be available at https://github.com/xxxxx .
Knowledge distillation (KD) is the preliminary step for training non-autoregressive translation (NAT) models, which eases the training of NAT models at the cost of losing important information for translating low-frequency words .
In this work, we provide an appealing alternative for NAT – monolingual KD, which trains NAT student on external monolingual data with AT teacher trained on the original bilingual data .
Monolingual KD is able to transfer both the knowledge of the original bilingual data (implicitly encoded in the trained AT teacher model) and that of the new monolingual data to the NAT student model .
Extensive experiments on eight WMT benchmarks over two advanced NAT models show that monolingual KD consistently outperforms the standard KD by improving low-frequency word translation, without introducing any computational cost .
Monolingual KD enjoys desirable expandability, which can be further enhanced (when given more computational budget) by combining with the standard KD, a reverse monolingual KD, or enlarging the scale of monolingual data .
Extensive analyses demonstrate that these techniques can be used together profitably to further recall the useful information lost in the standard KD .
Encouragingly, combining with standard KD, our approach achieves 30.4 and 34.1 BLEU points on the WMT14 English-German and German-English datasets, respectively .
Our code and trained models are freely available at https://github.com/alphadl/RLFW-NAT.mono .
Higher-order methods for dependency parsing can partially but not fully address the issue that edges in dependency trees should be constructed at the text span/subtree level rather than word level .
In this paper, we propose a new method for dependency parsing to address this issue .
The proposed method constructs dependency trees by directly modeling span-span (in other words, subtree-subtree) relations .
It consists of two modules: the text span proposal module which proposes candidate text spans, each of which represents a subtree in the dependency tree denoted by (root, start, end); and the span linking module, which constructs links between proposed spans .
We use the machine reading comprehension (MRC) framework as the backbone to formalize the span linking module, where one span is used as query to extract the text span/subtree it should be linked to .
The proposed method has the following merits: (1) it addresses the fundamental problem that edges in a dependency tree should be constructed between subtrees; (2) the MRC framework allows the method to retrieve missing spans in the span proposal stage, which leads to higher recall for eligible spans .
Extensive experiments on the PTB, CTB and Universal Dependencies (UD) benchmarks demonstrate the effectiveness of the proposed method .
The code is available at https://github.com/ShannonAI/mrc-for-dependency-parsing .
Cross-domain sentiment analysis has achieved promising results with the help of pre-trained language models .
As GPT-3 appears, prompt tuning has been widely explored to enable better semantic modeling in many natural language processing tasks .
However, directly using a fixed predefined template for cross-domain research cannot model different distributions of the \operatorname{[MASK]} token in different domains, thus making underuse of the prompt tuning technique .
In this paper, we propose a novel Adversarial Soft Prompt Tuning method (AdSPT) to better model cross-domain sentiment analysis .
On the one hand, AdSPT adopts separate soft prompts instead of hard templates to learn different vectors for different domains, thus alleviating the domain discrepancy of the \operatorname{[MASK]} token in the masked language modeling task .
On the other hand, AdSPT uses a novel domain adversarial training strategy to learn domain-invariant representations between each source domain and the target domain .
Experiments on a publicly available sentiment analysis dataset show that our model achieves the new state-of-the-art results for both single-source domain adaptation and multi-source domain adaptation .
Automated scientific fact checking is difficult due to the complexity of scientific language and a lack of significant amounts of training data, as annotation requires domain expertise .
To address this challenge, we propose scientific claim generation, the task of generating one or more atomic and verifiable claims from scientific sentences, and demonstrate its usefulness in zero-shot fact checking for biomedical claims .
We propose CLAIMGEN-BART, a new supervised method for generating claims supported by the literature, as well as KBIN, a novel method for generating claim negations .
Additionally, we adapt an existing unsupervised entity-centric method of claim generation to biomedical claims, which we call CLAIMGEN-ENTITY .
Experiments on zero-shot fact checking demonstrate that both CLAIMGEN-ENTITY and CLAIMGEN-BART, coupled with KBIN, achieve up to 90% performance of fully supervised models trained on manually annotated claims and evidence .
A rigorous evaluation study demonstrates significant improvement in generated claim and negation quality over existing baselines .
Simultaneous machine translation (SiMT) outputs translation while reading source sentence and hence requires a policy to decide whether to wait for the next source word (READ) or generate a target word (WRITE), the actions of which form a read/write path .
Although the read/write path is essential to SiMT performance, no direct supervision is given to the path in the existing methods .
In this paper, we propose a method of dual-path SiMT which introduces duality constraints to direct the read/write path .
According to duality constraints, the read/write path in source-to-target and target-to-source SiMT models can be mapped to each other .
As a result, the two SiMT models can be optimized jointly by forcing their read/write paths to satisfy the mapping .
Experiments on En-Vi and De-En tasks show that our method can outperform strong baselines under all latency .
Local models for Entity Disambiguation (ED) have today become extremely powerful, in most part thanks to the advent of large pre-trained language models .
However, despite their significant performance achievements, most of these approaches frame ED through classification formulations that have intrinsic limitations, both computationally and from a modeling perspective .
In contrast with this trend, here we propose ExtEnD, a novel local formulation for ED where we frame this task as a text extraction problem, and present two Transformer-based architectures that implement it .
Based on experiments in and out of domain, and training over two different data regimes, we find our approach surpasses all its competitors in terms of both data efficiency and raw performance .
ExtEnD outperforms its alternatives by as few as 6 F1 points on the more constrained of the two data regimes and, when moving to the other higher-resourced regime, sets a new state of the art on 4 out of 4 benchmarks under consideration, with average improvements of 0.7 F1 points overall and 1.1 F1 points out of domain .
In addition, to gain better insights from our results, we also perform a fine-grained evaluation of our performances on different classes of label frequency, along with an ablation study of our architectural choices and an error analysis .
We release our code and models for research purposes at https://github.com/SapienzaNLP/extend .
We propose a generative model of paraphrase generation, that encourages syntactic diversity by conditioning on an explicit syntactic sketch .
We introduce Hierarchical Refinement Quantized Variational Autoencoders (HRQ-VAE), a method for learning decompositions of dense encodings as a sequence of discrete latent variables that make iterative refinements of increasing granularity .
This hierarchy of codes is learned through end-to-end training, and represents fine-to-coarse grained information about the input .
We use HRQ-VAE to encode the syntactic form of an input sentence as a path through the hierarchy, allowing us to more easily predict syntactic sketches at test time .
Extensive experiments, including a human evaluation, confirm that HRQ-VAE learns a hierarchical representation of the input space, and generates paraphrases of higher quality than previous systems .
Progress with supervised Open Information Extraction (OpenIE) has been primarily limited to English due to the scarcity of training data in other languages .
In this paper, we explore techniques to automatically convert English text for training OpenIE systems in other languages .
We introduce the Alignment-Augmented Constrained Translation (AACTrans) model to translate English sentences and their corresponding extractions consistently with each other — with no changes to vocabulary or semantic meaning which may result from independent translations .
Using the data generated with AACTrans, we train a novel two-stage generative OpenIE model, which we call Gen2OIE, that outputs for each sentence: 1) relations in the first stage and 2) all extractions containing the relation in the second stage .
Gen2OIE increases relation coverage using a training data transformation technique that is generalizable to multiple languages, in contrast to existing models that use an English-specific training loss .
Evaluations on 5 languages — Spanish, Portuguese, Chinese, Hindi and Telugu — show that the Gen2OIE with AACTrans data outperforms prior systems by a margin of 6-25% in F1 .
We study a new problem setting of information extraction (IE), referred to as text-to-table .
In text-to-table, given a text, one creates a table or several tables expressing the main content of the text, while the model is learned from text-table pair data .
The problem setting differs from those of the existing methods for IE .
First, the extraction can be carried out from long texts to large tables with complex structures .
Second, the extraction is entirely data-driven, and there is no need to explicitly define the schemas .
As far as we know, there has been no previous work that studies the problem .
In this work, we formalize text-to-table as a sequence-to-sequence (seq2seq) problem .
We first employ a seq2seq model fine-tuned from a pre-trained language model to perform the task .
We also develop a new method within the seq2seq approach, exploiting two additional techniques in table generation: table constraint and table relation embeddings .
We consider text-to-table as an inverse problem of the well-studied table-to-text, and make use of four existing table-to-text datasets in our experiments on text-to-table .
Experimental results show that the vanilla seq2seq model can outperform the baseline methods of using relation extraction and named entity extraction .
The results also show that our method can further boost the performances of the vanilla seq2seq model .
We further discuss the main challenges of the proposed task .
The code and data are available at https://github.com/shirley-wu/text_to_table .
Code search is to search reusable code snippets from source code corpus based on natural languages queries .
Deep learning-based methods on code search have shown promising results .
However, previous methods focus on retrieval accuracy, but lacked attention to the efficiency of the retrieval process .
We propose a novel method CoSHC to accelerate code search with deep hashing and code classification, aiming to perform efficient code search without sacrificing too much accuracy .
To evaluate the effectiveness of CoSHC, we apply our methodon five code search models .
Extensive experimental results indicate that compared with previous code search baselines, CoSHC can save more than 90% of retrieval time meanwhile preserving at least 99% of retrieval accuracy .
Role-oriented dialogue summarization is to generate summaries for different roles in the dialogue, e.g., merchants and consumers .
Existing methods handle this task by summarizing each role’s content separately and thus are prone to ignore the information from other roles .
However, we believe that other roles’ content could benefit the quality of summaries, such as the omitted information mentioned by other roles .
Therefore, we propose a novel role interaction enhanced method for role-oriented dialogue summarization .
It adopts cross attention and decoder self-attention interactions to interactively acquire other roles’ critical information .
The cross attention interaction aims to select other roles’ critical dialogue utterances, while the decoder self-attention interaction aims to obtain key information from other roles’ summaries .
Experimental results have shown that our proposed method significantly outperforms strong baselines on two public role-oriented dialogue summarization datasets .
Extensive analyses have demonstrated that other roles’ content could help generate summaries with more complete semantics and correct topic structures .
Generating new events given context with correlated ones plays a crucial role in many event-centric reasoning tasks .
Existing works either limit their scope to specific scenarios or overlook event-level correlations .
In this paper, we propose to pre-train a general Correlation-aware context-to-Event Transformer (ClarET) for event-centric reasoning .
To achieve this, we propose three novel event-centric objectives, i.e., whole event recovering, contrastive event-correlation encoding and prompt-based event locating, which highlight event-level correlations with effective training .
The proposed ClarET is applicable to a wide range of event-centric reasoning scenarios, considering its versatility of (i) event-correlation types (e.g., causal, temporal, contrast), (ii) application formulations (i.e., generation and classification), and (iii) reasoning types (e.g., abductive, counterfactual and ending reasoning) .
Empirical fine-tuning results, as well as zero- and few-shot learning, on 9 benchmarks (5 generation and 4 classification tasks covering 4 reasoning types with diverse event correlations), verify its effectiveness and generalization ability .
Neural Machine Translation (NMT) systems exhibit problematic biases, such as stereotypical gender bias in the translation of occupation terms into languages with grammatical gender .
In this paper we describe a new source of bias prevalent in NMT systems, relating to translations of sentences containing person names .
To correctly translate such sentences, a NMT system needs to determine the gender of the name .
We show that leading systems are particularly poor at this task, especially for female given names .
This bias is deeper than given name gender: we show that the translation of terms with ambiguous sentiment can also be affected by person names, and the same holds true for proper nouns denoting race .
To mitigate these biases we propose a simple but effective data augmentation method based on randomly switching entities during translation, which effectively eliminates the problem without any effect on translation quality .
In this paper, we present a substantial step in better understanding the SOTA sequence-to-sequence (Seq2Seq) pretraining for neural machine translation (NMT) .
We focus on studying the impact of the jointly pretrained decoder, which is the main difference between Seq2Seq pretraining and previous encoder-based pretraining approaches for NMT .
By carefully designing experiments on three language pairs, we find that Seq2Seq pretraining is a double-edged sword: On one hand, it helps NMT models to produce more diverse translations and reduce adequacy-related translation errors .
On the other hand, the discrepancies between Seq2Seq pretraining and NMT finetuning limit the translation quality (i.e., domain discrepancy) and induce the over-estimation issue (i.e., objective discrepancy) .
Based on these observations, we further propose simple and effective strategies, named in-domain pretraining and input adaptation to remedy the domain and objective discrepancies, respectively .
Experimental results on several language pairs show that our approach can consistently improve both translation performance and model robustness upon Seq2Seq pretraining .
Multimodal machine translation and textual chat translation have received considerable attention in recent years .
Although the conversation in its natural form is usually multimodal, there still lacks work on multimodal machine translation in conversations .
In this work, we introduce a new task named Multimodal Chat Translation (MCT), aiming to generate more accurate translations with the help of the associated dialogue history and visual context .
To this end, we firstly construct a Multimodal Sentiment Chat Translation Dataset (MSCTD) containing 142,871 English-Chinese utterance pairs in 14,762 bilingual dialogues .
Each utterance pair, corresponding to the visual context that reflects the current conversational scene, is annotated with a sentiment label .
Then, we benchmark the task by establishing multiple baseline systems that incorporate multimodal and sentiment features for MCT .
Preliminary experiments on two language directions (English-Chinese) verify the potential of contextual and multimodal information fusion and the positive impact of sentiment on the MCT task .
Additionally, we provide a new benchmark on multimodal dialogue sentiment analysis with the constructed MSCTD .
Our work can facilitate researches on both multimodal chat translation and multimodal dialogue sentiment analysis .
When working with textual data, a natural application of disentangled representations is the fair classification where the goal is to make predictions without being biased (or influenced) by sensible attributes that may be present in the data (e.g., age, gender or race) .
Dominant approaches to disentangle a sensitive attribute from textual representations rely on learning simultaneously a penalization term that involves either an adversary loss (e.g., a discriminator) or an information measure (e.g., mutual information) .
However, these methods require the training of a deep neural network with several parameter updates for each update of the representation model .
As a matter of fact, the resulting nested optimization loop is both times consuming, adding complexity to the optimization dynamic, and requires a fine hyperparameter selection (e.g., learning rates, architecture) .
In this work, we introduce a family of regularizers for learning disentangled representations that do not require training .
These regularizers are based on statistical measures of similarity between the conditional probability distributions with respect to the sensible attributes .
Our novel regularizers do not require additional training, are faster and do not involve additional tuning while achieving better results both when combined with pretrained and randomly initialized text encoders .
Recent years have witnessed the emergence of a variety of post-hoc interpretations that aim to uncover how natural language processing (NLP) models make predictions .
Despite the surge of new interpretation methods, it remains an open problem how to define and quantitatively measure the faithfulness of interpretations, i.e., to what extent interpretations reflect the reasoning process by a model .
We propose two new criteria, sensitivity and stability, that provide complementary notions of faithfulness to the existed removal-based criteria .
Our results show that the conclusion for how faithful interpretations are could vary substantially based on different notions .
Motivated by the desiderata of sensitivity and stability, we introduce a new class of interpretation methods that adopt techniques from adversarial robustness .
Empirical results show that our proposed methods are effective under the new criteria and overcome limitations of gradient-based methods on removal-based criteria .
Besides text classification, we also apply interpretation methods and metrics to dependency parsing .
Our results shed light on understanding the diverse set of interpretations .
Solving crossword puzzles requires diverse reasoning capabilities, access to a vast amount of knowledge about language and the world, and the ability to satisfy the constraints imposed by the structure of the puzzle .
In this work, we introduce solving crossword puzzles as a new natural language understanding task .
We release a corpus of crossword puzzles collected from the New York Times daily crossword spanning 25 years and comprised of a total of around nine thousand puzzles .
These puzzles include a diverse set of clues: historic, factual, word meaning, synonyms/antonyms, fill-in-the-blank, abbreviations, prefixes/suffixes, wordplay, and cross-lingual, as well as clues that depend on the answers to other clues .
We separately release the clue-answer pairs from these puzzles as an open-domain question answering dataset containing over half a million unique clue-answer pairs .
For the question answering task, our baselines include several sequence-to-sequence and retrieval-based generative models .
We also introduce a non-parametric constraint satisfaction baseline for solving the entire crossword puzzle .
Finally, we propose an evaluation framework which consists of several complementary performance metrics .
Natural language processing models often exploit spurious correlations between task-independent features and labels in datasets to perform well only within the distributions they are trained on, while not generalising to different task distributions .
We propose to tackle this problem by generating a debiased version of a dataset, which can then be used to train a debiased, off-the-shelf model, by simply replacing its training data .
Our approach consists of 1) a method for training data generators to generate high-quality, label-consistent data samples; and 2) a filtering mechanism for removing data points that contribute to spurious correlations, measured in terms of z-statistics .
We generate debiased versions of the SNLI and MNLI datasets, and we evaluate on a large suite of debiased, out-of-distribution, and adversarial test sets .
Results show that models trained on our debiased datasets generalise better than those trained on the original datasets in all settings .
On the majority of the datasets, our method outperforms or performs comparably to previous state-of-the-art debiasing strategies, and when combined with an orthogonal technique, product-of-experts, it improves further and outperforms previous best results of SNLI-hard and MNLI-hard .
Due to high data demands of current methods, attention to zero-shot cross-lingual spoken language understanding (SLU) has grown, as such approaches greatly reduce human annotation effort .
However, existing models solely rely on shared parameters, which can only perform implicit alignment across languages .
We present Global-Local Contrastive Learning Framework (GL-CLeF) to address this shortcoming .
Specifically, we employ contrastive learning, leveraging bilingual dictionaries to construct multilingual views of the same utterance, then encourage their representations to be more similar than negative example pairs, which achieves to explicitly align representations of similar sentences across languages .
In addition, a key step in GL-CLeF is a proposed Local and Global component, which achieves a fine-grained cross-lingual transfer (i.e., sentence-level Local intent transfer, token-level Local slot transfer, and semantic-level Global transfer across intent and slot) .
Experiments on MultiATIS++ show that GL-CLeF achieves the best performance and successfully pulls representations of similar sentences across languages closer .
Recent advances in prompt-based learning have shown strong results on few-shot text classification by using cloze-style templates.Similar attempts have been made on named entity recognition (NER) which manually design templates to predict entity types for every text span in a sentence .
However, such methods may suffer from error propagation induced by entity span detection, high cost due to enumeration of all possible text spans, and omission of inter-dependencies among token labels in a sentence .
Here we present a simple demonstration-based learning method for NER, which lets the input be prefaced by task demonstrations for in-context learning .
We perform a systematic study on demonstration strategy regarding what to include (entity examples, with or without surrounding context), how to select the examples, and what templates to use .
Results on in-domain learning and domain adaptation show that the model’s performance in low-resource settings can be largely improved with a suitable demonstration strategy (e.g., a 4-17% improvement on 25 train instances) .
We also find that good demonstration can save many labeled examples and consistency in demonstration contributes to better performance .
Currently, masked language modeling (e.g., BERT) is the prime choice to learn contextualized representations .
Due to the pervasiveness, it naturally raises an interesting question: how do masked language models (MLMs) learn contextual representations? In this work, we analyze the learning dynamics of MLMs and find that it adopts sampled embeddings as anchors to estimate and inject contextual semantics to representations, which limits the efficiency and effectiveness of MLMs .
To address these problems, we propose TACO, a simple yet effective representation learning approach to directly model global semantics .
To be specific, TACO extracts and aligns contextual semantics hidden in contextualized representations to encourage models to attend global semantics when generating contextualized representations .
Experiments on the GLUE benchmark show that TACO achieves up to 5x speedup and up to 1.2 points average improvement over MLM .
While hyper-parameters (HPs) are important for knowledge graph (KG) learning, existing methods fail to search them efficiently .
To solve this problem, we first analyze the properties of different HPs and measure the transfer ability from small subgraph to the full graph .
Based on the analysis, we propose an efficient two-stage search algorithm KGTuner, which efficiently explores HP configurations on small subgraph at the first stage and transfers the top-performed configurations for fine-tuning on the large full graph at the second stage .
Experiments show that our method can consistently find better HPs than the baseline algorithms within the same time budget, which achieves 9.1% average relative improvement for four embedding models on the large-scale KGs in open graph benchmark .
Our code is released in https://github .
com/AutoML-Research/KGTuner .
News events are often associated with quantities (e.g., the number of COVID-19 patients or the number of arrests in a protest), and it is often important to extract their type, time, and location from unstructured text in order to analyze these quantity events .
This paper thus formulates the NLP problem of spatiotemporal quantity extraction, and proposes the first meta-framework for solving it .
This meta-framework contains a formalism that decomposes the problem into several information extraction tasks, a shareable crowdsourcing pipeline, and transformer-based baseline models .
We demonstrate the meta-framework in three domains—the COVID-19 pandemic, Black Lives Matter protests, and 2020 California wildfires—to show that the formalism is general and extensible, the crowdsourcing pipeline facilitates fast and high-quality data annotation, and the baseline system can handle spatiotemporal quantity extraction well enough to be practically useful .
We release all resources for future research on this topic at https://github.com/steqe .
Pre-trained language models are still far from human performance in tasks that need understanding of properties (e.g .
appearance, measurable quantity) and affordances of everyday objects in the real world since the text lacks such information due to reporting bias.In this work, we study whether integrating visual knowledge into a language model can fill the gap.We investigate two types of knowledge transfer: (1) text knowledge transfer using image captions that may contain enriched visual knowledge and (2) cross-modal knowledge transfer using both images and captions with vision-language training objectives.On 5 downstream tasks that may need visual knowledge to solve the problem, we perform extensive empirical comparisons over the presented objectives.Our experiments show that visual knowledge transfer can improve performance in both low-resource and fully supervised settings .
Large pre-trained vision-language (VL) models can learn a new task with a handful of examples and generalize to a new task without fine-tuning.However, these VL models are hard to deploy for real-world applications due to their impractically huge sizes and slow inference speed.To solve this limitation, we study prompt-based low-resource learning of VL tasks with our proposed method, FewVLM, relatively smaller than recent few-shot learners.For FewVLM, we pre-train a sequence-to-sequence transformer model with prefix language modeling (PrefixLM) and masked language modeling (MaskedLM).Furthermore, we analyze the effect of diverse prompts for few-shot tasks.Experimental results on VQA show that FewVLM with prompt-based learning outperforms Frozen which is 31x larger than FewVLM by 18.2% point and achieves comparable results to a 246x larger model, PICa.In our analysis, we observe that (1) prompts significantly affect zero-shot performance but marginally affect few-shot performance, (2) models with noisy prompts learn as quickly as hand-crafted prompts given larger training data, and (3) MaskedLM helps VQA tasks while PrefixLM boosts captioning performance .
Our code is publicly available at https://github.com/woojeongjin/FewVLM .
Existing continual relation learning (CRL) methods rely on plenty of labeled training data for learning a new task, which can be hard to acquire in real scenario as getting large and representative labeled data is often expensive and time-consuming .
It is therefore necessary for the model to learn novel relational patterns with very few labeled data while avoiding catastrophic forgetting of previous task knowledge .
In this paper, we formulate this challenging yet practical problem as continual few-shot relation learning (CFRL) .
Based on the finding that learning for new emerging few-shot tasks often results in feature distributions that are incompatible with previous tasks’ learned distributions, we propose a novel method based on embedding space regularization and data augmentation .
Our method generalizes to new few-shot tasks and avoids catastrophic forgetting of previous tasks by enforcing extra constraints on the relational embeddings and by adding extra relevant data in a self-supervised manner .
With extensive experiments we demonstrate that our method can significantly outperform previous state-of-the-art methods in CFRL task settings .
Coreference resolution over semantic graphs like AMRs aims to group the graph nodes that represent the same entity .
This is a crucial step for making document-level formal semantic representations .
With annotated data on AMR coreference resolution, deep learning approaches have recently shown great potential for this task, yet they are usually data hunger and annotations are costly .
We propose a general pretraining method using variational graph autoencoder (VGAE) for AMR coreference resolution, which can leverage any general AMR corpus and even automatically parsed AMR data .
Experiments on benchmarks show that the pretraining approach achieves performance gains of up to 6% absolute F1 points .
Moreover, our model significantly improves on the previous state-of-the-art model by up to 11% F1 .
Recent works of opinion expression identification (OEI) rely heavily on the quality and scale of the manually-constructed training corpus, which could be extremely difficult to satisfy .
Crowdsourcing is one practical solution for this problem, aiming to create a large-scale but quality-unguaranteed corpus .
In this work, we investigate Chinese OEI with extremely-noisy crowdsourcing annotations, constructing a dataset at a very low cost .
Following Zhang el al .
(2021), we train the annotator-adapter model by regarding all annotations as gold-standard in terms of crowd annotators, and test the model by using a synthetic expert, which is a mixture of all annotators .
As this annotator-mixture for testing is never modeled explicitly in the training phase, we propose to generate synthetic training samples by a pertinent mixup strategy to make the training and testing highly consistent .
The simulation experiments on our constructed dataset show that crowdsourcing is highly promising for OEI, and our proposed annotator-mixup can further enhance the crowdsourcing modeling .
Knowledge graph embedding (KGE) models represent each entity and relation of a knowledge graph (KG) with low-dimensional embedding vectors .
These methods have recently been applied to KG link prediction and question answering over incomplete KGs (KGQA) .
KGEs typically create an embedding for each entity in the graph, which results in large model sizes on real-world graphs with millions of entities .
For downstream tasks these atomic entity representations often need to be integrated into a multi stage pipeline, limiting their utility .
We show that an off-the-shelf encoder-decoder Transformer model can serve as a scalable and versatile KGE model obtaining state-of-the-art results for KG link prediction and incomplete KG question answering .
We achieve this by posing KG link prediction as a sequence-to-sequence task and exchange the triple scoring approach taken by prior KGE methods with autoregressive decoding .
Such a simple but powerful method reduces the model size up to 98% compared to conventional KGE models while keeping inference time tractable .
After finetuning this model on the task of KGQA over incomplete KGs, our approach outperforms baselines on multiple large-scale datasets without extensive hyperparameter tuning .
Human communication is a collaborative process .
Speakers, on top of conveying their own intent, adjust the content and language expressions by taking the listeners into account, including their knowledge background, personalities, and physical capabilities .
Towards building AI agents with similar abilities in language communication, we propose a novel rational reasoning framework, Pragmatic Rational Speaker (PRS), where the speaker attempts to learn the speaker-listener disparity and adjust the speech accordingly, by adding a light-weighted disparity adjustment layer into working memory on top of speaker’s long-term memory system .
By fixing the long-term memory, the PRS only needs to update its working memory to learn and adapt to different types of listeners .
To validate our framework, we create a dataset that simulates different types of speaker-listener disparities in the context of referential games .
Our empirical results demonstrate that the PRS is able to shift its output towards the language that listeners are able to understand, significantly improve the collaborative task outcome, and learn the disparity more efficiently than joint training .
Recent research demonstrates the effectiveness of using fine-tuned language models (LM) for dense retrieval .
However, dense retrievers are hard to train, typically requiring heavily engineered fine-tuning pipelines to realize their full potential .
In this paper, we identify and address two underlying problems of dense retrievers: i) fragility to training data noise and ii) requiring large batches to robustly learn the embedding space .
We use the recently proposed Condenser pre-training architecture, which learns to condense information into the dense vector through LM pre-training .
On top of it, we propose coCondenser, which adds an unsupervised corpus-level contrastive loss to warm up the passage embedding space .
Experiments on MS-MARCO, Natural Question, and Trivia QA datasets show that coCondenser removes the need for heavy data engineering such as augmentation, synthesis, or filtering, and the need for large batch training .
It shows comparable performance to RocketQA, a state-of-the-art, heavily engineered system, using simple small batch fine-tuning .
Responsing with image has been recognized as an important capability for an intelligent conversational agent .
Yet existing works only focus on exploring the multimodal dialogue models which depend on retrieval-based methods, but neglecting generation methods .
To fill in the gaps, we first present a new task: multimodal dialogue response generation (MDRG) - given the dialogue history, one model needs to generate a text sequence or an image as response .
Learning such a MDRG model often requires multimodal dialogues containing both texts and images which are difficult to obtain .
Motivated by the challenge in practice, we consider MDRG under a natural assumption that only limited training examples are available .
In such a low-resource setting, we devise a novel conversational agent, Divter, in order to isolate parameters that depend on multimodal dialogues from the entire generation model .
By this means, the major part of the model can be learned from a large number of text-only dialogues and text-image pairs respectively, then the whole parameters can be well fitted using the limited training examples .
Extensive experiments demonstrate our method achieves state-of-the-art results in both automatic and human evaluation, and can generate informative text and high-resolution image responses .
Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably .
The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge .
The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC’s performance .
To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (CAKE) framework to automatically extract commonsense from factual triples with entity concepts .
The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction .
Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques .
Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results .
Most dominant neural machine translation (NMT) models are restricted to make predictions only according to the local context of preceding words in a left-to-right manner .
Although many previous studies try to incorporate global information into NMT models, there still exist limitations on how to effectively exploit bidirectional global context .
In this paper, we propose a Confidence Based Bidirectional Global Context Aware (CBBGCA) training framework for NMT, where the NMT model is jointly trained with an auxiliary conditional masked language model (CMLM) .
The training consists of two stages: (1) multi-task joint training; (2) confidence based knowledge distillation .
At the first stage, by sharing encoder parameters, the NMT model is additionally supervised by the signal from the CMLM decoder that contains bidirectional global contexts .
Moreover, at the second stage, using the CMLM as teacher, we further pertinently incorporate bidirectional global context to the NMT model on its unconfidently-predicted target words via knowledge distillation .
Experimental results show that our proposed CBBGCA training framework significantly improves the NMT model by +1.02, +1.30 and +0.57 BLEU scores on three large-scale translation datasets, namely WMT’14 English-to-German, WMT’19 Chinese-to-English and WMT’14 English-to-French, respectively .
Abstractive summarization models are commonly trained using maximum likelihood estimation, which assumes a deterministic (one-point) target distribution in which an ideal model will assign all the probability mass to the reference summary .
This assumption may lead to performance degradation during inference, where the model needs to compare several system-generated (candidate) summaries that have deviated from the reference summary .
To address this problem, we propose a novel training paradigm which assumes a non-deterministic distribution so that different candidate summaries are assigned probability mass according to their quality .
Our method achieves a new state-of-the-art result on the CNN/DailyMail (47.78 ROUGE-1) and XSum (49.07 ROUGE-1) datasets .
Further analysis also shows that our model can estimate probabilities of candidate summaries that are more correlated with their level of quality .
In sequence modeling, certain tokens are usually less ambiguous than others, and representations of these tokens require fewer refinements for disambiguation .
However, given the nature of attention-based models like Transformer and UT (universal transformer), all tokens are equally processed towards depth .
Inspired by the equilibrium phenomenon, we present a lazy transition, a mechanism to adjust the significance of iterative refinements for each token representation .
Our lazy transition is deployed on top of UT to build LT (lazy transformer), where all tokens are processed unequally towards depth .
Eventually, LT is encouraged to oscillate around a relaxed equilibrium .
Our experiments show that LT outperforms baseline models on several tasks of machine translation, pre-training, Learning to Execute, and LAMBADA .
We propose fill-in-the-blanks as a video understanding evaluation framework and introduce FIBER – a novel dataset consisting of 28,000 videos and descriptions in support of this evaluation framework .
The fill-in-the-blanks setting tests a model’s understanding of a video by requiring it to predict a masked noun phrase in the caption of the video, given the video and the surrounding text .
The FIBER benchmark does not share the weaknesses of the current state-of-the-art language-informed video understanding tasks, namely: (1) video question answering using multiple-choice questions, where models perform relatively well because they exploit linguistic biases in the task formulation, thus making our framework challenging for the current state-of-the-art systems to solve; and (2) video captioning, which relies on an open-ended evaluation framework that is often inaccurate because system answers may be perceived as incorrect if they differ in form from the ground truth .
The FIBER dataset and our code are available at https://lit.eecs.umich.edu/fiber/ .
Currently, Medical Subject Headings (MeSH) are manually assigned to every biomedical article published and subsequently recorded in the PubMed database to facilitate retrieving relevant information .
With the rapid growth of the PubMed database, large-scale biomedical document indexing becomes increasingly important .
MeSH indexing is a challenging task for machine learning, as it needs to assign multiple labels to each article from an extremely large hierachically organized collection .
To address this challenge, we propose KenMeSH, an end-to-end model that combines new text features and a dynamic knowledge-enhanced mask attention that integrates document features with MeSH label hierarchy and journal correlation features to index MeSH terms .
Experimental results show the proposed method achieves state-of-the-art performance on a number of measures .
Effective question-asking is a crucial component of a successful conversational chatbot .
It could help the bots manifest empathy and render the interaction more engaging by demonstrating attention to the speaker’s emotions .
However, current dialog generation approaches do not model this subtle emotion regulation technique due to the lack of a taxonomy of questions and their purpose in social chitchat .
To address this gap, we have developed an empathetic question taxonomy (EQT), with special attention paid to questions’ ability to capture communicative acts and their emotion-regulation intents .
We further design a crowd-sourcing task to annotate a large subset of the EmpatheticDialogues dataset with the established labels .
We use the crowd-annotated data to develop automatic labeling tools and produce labels for the whole dataset .
Finally, we employ information visualization techniques to summarize co-occurrences of question acts and intents and their role in regulating interlocutor’s emotion .
These results reveal important question-asking strategies in social dialogs .
The EQT classification scheme can facilitate computational analysis of questions in datasets .
More importantly, it can inform future efforts in empathetic question generation using neural or hybrid methods .
Aspect Sentiment Triplet Extraction (ASTE) is an emerging sentiment analysis task .
Most of the existing studies focus on devising a new tagging scheme that enables the model to extract the sentiment triplets in an end-to-end fashion .
However, these methods ignore the relations between words for ASTE task .
In this paper, we propose an Enhanced Multi-Channel Graph Convolutional Network model (EMC-GCN) to fully utilize the relations between words .
Specifically, we first define ten types of relations for ASTE task, and then adopt a biaffine attention module to embed these relations as an adjacent tensor between words in a sentence .
After that, our EMC-GCN transforms the sentence into a multi-channel graph by treating words and the relation adjacent tensor as nodes and edges, respectively .
Thus, relation-aware node representations can be learnt .
Furthermore, we consider diverse linguistic features to enhance our EMC-GCN model .
Finally, we design an effective refining strategy on EMC-GCN for word-pair representation refinement, which considers the implicit results of aspect and opinion extraction when determining whether word pairs match or not .
Extensive experimental results on the benchmark datasets demonstrate that the effectiveness and robustness of our proposed model, which outperforms state-of-the-art methods significantly .
We present ProtoTEx, a novel white-box NLP classification architecture based on prototype networks (Li et al., 2018) .
ProtoTEx faithfully explains model decisions based on prototype tensors that encode latent clusters of training examples .
At inference time, classification decisions are based on the distances between the input text and the prototype tensors, explained via the training examples most similar to the most influential prototypes .
We also describe a novel interleaved training algorithm that effectively handles classes characterized by ProtoTEx indicative features .
On a propaganda detection task, ProtoTEx accuracy matches BART-large and exceeds BERTlarge with the added benefit of providing faithful explanations .
A user study also shows that prototype-based explanations help non-experts to better recognize propaganda in online news .
Procedures are inherently hierarchical .
To “make videos”, one may need to “purchase a camera”, which in turn may require one to “set a budget” .
While such hierarchical knowledge is critical for reasoning about complex procedures, most existing work has treated procedures as shallow structures without modeling the parent-child relation .
In this work, we attempt to construct an open-domain hierarchical knowledge-base (KB) of procedures based on wikiHow, a website containing more than 110k instructional articles, each documenting the steps to carry out a complex procedure .
To this end, we develop a simple and efficient method that links steps (e.g., “purchase a camera”) in an article to other articles with similar goals (e.g., “how to choose a camera”), recursively constructing the KB .
Our method significantly outperforms several strong baselines according to automatic evaluation, human judgment, and application to downstream tasks such as instructional video retrieval .
In contrast to recent advances focusing on high-level representation learning across modalities, in this work we present a self-supervised learning framework that is able to learn a representation that captures finer levels of granularity across different modalities such as concepts or events represented by visual objects or spoken words .
Our framework relies on a discretized embedding space created via vector quantization that is shared across different modalities .
Beyond the shared embedding space, we propose a Cross-Modal Code Matching objective that forces the representations from different views (modalities) to have a similar distribution over the discrete embedding space such that cross-modal objects/actions localization can be performed without direct supervision .
We show that the proposed discretized multi-modal fine-grained representation (e.g., pixel/word/frame) can complement high-level summary representations (e.g., video/sentence/waveform) for improved performance on cross-modal retrieval tasks .
We also observe that the discretized representation uses individual clusters to represent the same semantic concept across modalities .
Representations of events described in text are important for various tasks .
In this work, we present SWCC: a Simultaneous Weakly supervised Contrastive learning and Clustering framework for event representation learning .
SWCC learns event representations by making better use of co-occurrence information of events .
Specifically, we introduce a weakly supervised contrastive learning method that allows us to consider multiple positives and multiple negatives, and a prototype-based clustering method that avoids semantically related events being pulled apart .
For model training, SWCC learns representations by simultaneously performing weakly supervised contrastive learning and prototype-based clustering .
Experimental results show that SWCC outperforms other baselines on Hard Similarity and Transitive Sentence Similarity tasks .
In addition, a thorough analysis of the prototype-based clustering method demonstrates that the learned prototype vectors are able to implicitly capture various relations between events .
We examine the effects of contrastive visual semantic pretraining by comparing the geometry and semantic properties of contextualized English language representations formed by GPT-2 and CLIP, a zero-shot multimodal image classifier which adapts the GPT-2 architecture to encode image captions .
We find that contrastive visual semantic pretraining significantly mitigates the anisotropy found in contextualized word embeddings from GPT-2, such that the intra-layer self-similarity (mean pairwise cosine similarity) of CLIP word embeddings is under .25 in all layers, compared to greater than .95 in the top layer of GPT-2 .
CLIP word embeddings outperform GPT-2 on word-level semantic intrinsic evaluation tasks, and achieve a new corpus-based state of the art for the RG65 evaluation, at .88 .
CLIP also forms fine-grained semantic representations of sentences, and obtains Spearman’s 𝜌 = .73 on the SemEval-2017 Semantic Textual Similarity Benchmark with no fine-tuning, compared to no greater than 𝜌 = .45 in any layer of GPT-2 .
Finally, intra-layer self-similarity of CLIP sentence embeddings decreases as the layer index increases, finishing at .25 in the top layer, while the self-similarity of GPT-2 sentence embeddings formed using the EOS token increases layer-over-layer and never falls below .97 .
Our results indicate that high anisotropy is not an inevitable consequence of contextualization, and that visual semantic pretraining is beneficial not only for ordering visual representations, but also for encoding useful semantic representations of language, both on the word level and the sentence level .
The mainstream machine learning paradigms for NLP often work with two underlying presumptions .
First, the target task is predefined and static; a system merely needs to learn to solve it exclusively .
Second, the supervision of a task mainly comes from a set of labeled examples .
A question arises: how to build a system that can keep learning new tasks from their instructions?This work defines a new learning paradigm ConTinTin (Continual Learning from Task Instructions), in which a system should learn a sequence of new tasks one by one, each task is explained by a piece of textual instruction .
The system is required to (i) generate the expected outputs of a new task by learning from its instruction, (ii) transfer the knowledge acquired from upstream tasks to help solve downstream tasks (i.e., forward-transfer), and (iii) retain or even improve the performance on earlier tasks after learning new tasks (i.e., backward-transfer) .
This new problem is studied on a stream of more than 60 tasks, each equipped with an instruction .
Technically, our method InstructionSpeak contains two strategies that make full use of task instructions to improve forward-transfer and backward-transfer: one is to learn from negative outputs, the other is to re-visit instructions of previous tasks .
To our knowledge, this is the first time to study ConTinTin in NLP .
In addition to the problem formulation and our promising approach, this work also contributes to providing rich analyses for the community to better understand this novel learning problem .
We present the Berkeley Crossword Solver, a state-of-the-art approach for automatically solving crossword puzzles .
Our system works by generating answer candidates for each crossword clue using neural question answering models and then combines loopy belief propagation with local search to find full puzzle solutions .
Compared to existing approaches, our system improves exact puzzle accuracy from 57% to 82% on crosswords from The New York Times and obtains 99.9% letter accuracy on themeless puzzles .
Our system also won first place at the top human crossword tournament, which marks the first time that a computer program has surpassed human performance at this event .
To facilitate research on question answering and crossword solving, we analyze our system’s remaining errors and release a dataset of over six million question-answer pairs .
We present an incremental syntactic representation that consists of assigning a single discrete label to each word in a sentence, where the label is predicted using strictly incremental processing of a prefix of the sentence, and the sequence of labels for a sentence fully determines a parse tree .
Our goal is to induce a syntactic representation that commits to syntactic choices only as they are incrementally revealed by the input, in contrast with standard representations that must make output choices such as attachments speculatively and later throw out conflicting analyses .
Our learned representations achieve 93.72 F1 on the Penn Treebank with as few as 5 bits per word, and at 8 bits per word they achieve 94.97 F1, which is comparable with other state of the art parsing models when using the same pre-trained embeddings .
We also provide an analysis of the representations learned by our system, investigating properties such as the interpretable syntactic features captured by the system and mechanisms for deferred resolution of syntactic ambiguities .
In this paper, we study the effect of commonsense and domain knowledge while generating responses in counseling conversations using retrieval and generative methods for knowledge integration .
We propose a pipeline that collects domain knowledge through web mining, and show that retrieval from both domain-specific and commonsense knowledge bases improves the quality of generated responses .
We also present a model that incorporates knowledge generated by COMET using soft positional encoding and masked self-attention.We show that both retrieved and COMET-generated knowledge improve the system’s performance as measured by automatic metrics and also by human evaluation .
Lastly, we present a comparative study on the types of knowledge encoded by our system showing that causal and intentional relationships benefit the generation task more than other types of commonsense relations .
Even to a simple and short news headline, readers react in a multitude of ways: cognitively (e.g .
inferring the writer’s intent), emotionally (e.g .
feeling distrust), and behaviorally (e.g .
sharing the news with their friends) .
Such reactions are instantaneous and yet complex, as they rely on factors that go beyond interpreting factual content of news.We propose Misinfo Reaction Frames (MRF), a pragmatic formalism for modeling how readers might react to a news headline .
In contrast to categorical schema, our free-text dimensions provide a more nuanced way of understanding intent beyond being benign or malicious .
We also introduce a Misinfo Reaction Frames corpus, a crowdsourced dataset of reactions to over 25k news headlines focusing on global crises: the Covid-19 pandemic, climate change, and cancer .
Empirical results confirm that it is indeed possible for neural models to predict the prominent patterns of readers’ reactions to previously unseen news headlines .
Additionally, our user study shows that displaying machine-generated MRF implications alongside news headlines to readers can increase their trust in real news while decreasing their trust in misinformation .
Our work demonstrates the feasibility and importance of pragmatic inferences on news headlines to help enhance AI-guided misinformation detection and mitigation .
Real-world natural language processing (NLP) models need to be continually updated to fix the prediction errors in out-of-distribution (OOD) data streams while overcoming catastrophic forgetting .
However, existing continual learning (CL) problem setups cannot cover such a realistic and complex scenario .
In response to this, we propose a new CL problem formulation dubbed continual model refinement (CMR) .
Compared to prior CL settings, CMR is more practical and introduces unique challenges (boundary-agnostic and non-stationary distribution shift, diverse mixtures of multiple OOD data clusters, error-centric streams, etc.) .
We extend several existing CL approaches to the CMR setting and evaluate them extensively .
For benchmarking and analysis, we propose a general sampling algorithm to obtain dynamic OOD data streams with controllable non-stationarity, as well as a suite of metrics measuring various aspects of online performance .
Our experiments and detailed analysis reveal the promise and challenges of the CMR problem, supporting that studying CMR in dynamic OOD streams can benefit the longevity of deployed NLP models in production .
A limitation of current neural dialog models is that they tend to suffer from a lack of specificity and informativeness in generated responses, primarily due to dependence on training data that covers a limited variety of scenarios and conveys limited knowledge .
One way to alleviate this issue is to extract relevant knowledge from external sources at decoding time and incorporate it into the dialog response .
In this paper, we propose a post-hoc knowledge-injection technique where we first retrieve a diverse set of relevant knowledge snippets conditioned on both the dialog history and an initial response from an existing dialog model .
We construct multiple candidate responses, individually injecting each retrieved snippet into the initial response using a gradient-based decoding method, and then select the final response with an unsupervised ranking step .
Our experiments in goal-oriented and knowledge-grounded dialog settings demonstrate that human annotators judge the outputs from the proposed method to be more engaging and informative compared to responses from prior dialog systems .
We further show that knowledge-augmentation promotes success in achieving conversational goals in both experimental settings .
It remains an open question whether incorporating external knowledge benefits commonsense reasoning while maintaining the flexibility of pretrained sequence models .
To investigate this question, we develop generated knowledge prompting, which consists of generating knowledge from a language model, then providing the knowledge as additional input when answering a question .
Our method does not require task-specific supervision for knowledge integration, or access to a structured knowledge base, yet it improves performance of large-scale, state-of-the-art models on four commonsense reasoning tasks, achieving state-of-the-art results on numerical commonsense (NumerSense), general commonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks .
Generated knowledge prompting highlights large-scale language models as flexible sources of external knowledge for improving commonsense reasoning.Our code is available at github.com/liujch1998/GKP .
Retrieval-based methods have been shown to be effective in NLP tasks via introducing external knowledge .
However, the indexing and retrieving of large-scale corpora bring considerable computational cost .
Surprisingly, we found that REtrieving from the traINing datA (REINA) only can lead to significant gains on multiple NLG and NLU tasks .
We retrieve the labeled training instances most similar to the input text and then concatenate them with the input to feed into the model to generate the output .
Experimental results show that this simple method can achieve significantly better performance on a variety of NLU and NLG tasks, including summarization, machine translation, language modeling, and question answering tasks .
For instance, our proposed method achieved state-of-the-art results on XSum, BigPatent, and CommonsenseQA .
Our code is released, https://github.com/microsoft/REINA  .
Existing pre-trained transformer analysis works usually focus only on one or two model families at a time, overlooking the variability of the architecture and pre-training objectives .
In our work, we utilize the oLMpics bench- mark and psycholinguistic probing datasets for a diverse set of 29 models including T5, BART, and ALBERT .
Additionally, we adapt the oLMpics zero-shot setup for autoregres- sive models and evaluate GPT networks of different sizes .
Our findings show that none of these models can resolve compositional questions in a zero-shot fashion, suggesting that this skill is not learnable using existing pre-training objectives .
Furthermore, we find that global model decisions such as architecture, directionality, size of the dataset, and pre-training objective are not predictive of a model’s linguistic capabilities .
Controlled text perturbation is useful for evaluating and improving model generalizability .
However, current techniques rely on training a model for every target perturbation, which is expensive and hard to generalize .
We present Tailor, a semantically-controlled text generation system .
Tailor builds on a pretrained seq2seq model and produces textual outputs conditioned on control codes derived from semantic representations .
We craft a set of operations to modify the control codes, which in turn steer generation towards targeted attributes .
These operations can be further composed into higher-level ones, allowing for flexible perturbation strategies .
We demonstrate the effectiveness of these perturbations in multiple applications .
First, we use Tailor to automatically create high-quality contrast sets for four distinct natural language processing (NLP) tasks .
These contrast sets contain fewer spurious artifacts and are complementary to manually annotated ones in their lexical diversity .
Second, we show that Tailor perturbations can improve model generalization through data augmentation .
Perturbing just ∼2% of training data leads to a 5.8-point gain on an NLI challenge set measuring reliance on syntactic heuristics .
We propose a benchmark to measure whether a language model is truthful in generating answers to questions .
The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics .
We crafted questions that some humans would answer falsely due to a false belief or misconception .
To perform well, models must avoid generating false answers learned from imitating human texts .
We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model .
The best model was truthful on 58% of questions, while human performance was 94% .
Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans .
The largest models were generally the least truthful .
This contrasts with other NLP tasks, where performance improves with model size .
However, this result is expected if false answers are learned from the training distribution .
We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web .
Current approaches to testing and debugging NLP models rely on highly variable human creativity and extensive labor, or only work for a very restrictive class of bugs .
We present AdaTest, a process which uses large scale language models (LMs) in partnership with human feedback to automatically write unit tests highlighting bugs in a target model .
Such bugs are then addressed through an iterative text-fix-retest loop, inspired by traditional software development .
In experiments with expert and non-expert users and commercial / research models for 8 different tasks, AdaTest makes users 5-10x more effective at finding bugs than current approaches, and helps users effectively fix bugs without adding new bugs .
When pre-trained contextualized embedding-based models developed for unstructured data are adapted for structured tabular data, they perform admirably .
However, recent probing studies show that these models use spurious correlations, and often predict inference labels by focusing on false evidence or ignoring it altogether .
To study this issue, we introduce the task of Trustworthy Tabular Reasoning, where a model needs to extract evidence to be used for reasoning, in addition to predicting the label .
As a case study, we propose a two-stage sequential prediction approach, which includes an evidence extraction and an inference stage .
First, we crowdsource evidence row labels and develop several unsupervised and supervised evidence extraction strategies for InfoTabS, a tabular NLI benchmark .
Our evidence extraction strategy outperforms earlier baselines .
On the downstream tabular inference task, using only the automatically extracted evidence as the premise, our approach outperforms prior benchmarks .
The composition of richly-inflected words in morphologically complex languages can be a challenge for language learners developing literacy .
Accordingly, Lane and Bird (2020) proposed a finite state approach which maps prefixes in a language to a set of possible completions up to the next morpheme boundary, for the incremental building of complex words .
In this work, we develop an approach to morph-based auto-completion based on a finite state morphological analyzer of Plains Cree (nêhiyawêwin), showing the portability of the concept to a much larger, more complete morphological transducer .
Additionally, we propose and compare various novel ranking strategies on the morph auto-complete output .
The best weighting scheme ranks the target completion in the top 10 results in 64.9% of queries, and in the top 50 in 73.9% of queries .
Semantic parsing is the task of producing structured meaning representations for natural language sentences .
Recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e .
to handle examples that require recombining known knowledge in novel settings .
In this work, we show that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence .
To this end we propose LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph .
The strongly-supervised LAGr algorithm requires aligned graphs as inputs, whereas weakly-supervised LAGr infers alignments for originally unaligned target graphs using approximate maximum-a-posteriori inference .
Experiments demonstrate that LAGr achieves significant improvements in systematic generalization upon the baseline seq2seq parsers in both strongly- and weakly-supervised settings .
Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate .
Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language.To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups .
We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model .
Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text .
We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language .
We also find that 94.5% of toxic examples are labeled as hate speech by human annotators .
Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially .
We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset .
We present a direct speech-to-speech translation (S2ST) model that translates speech from one language to speech in another language without relying on intermediate text generation .
We tackle the problem by first applying a self-supervised discrete speech encoder on the target speech and then training a sequence-to-sequence speech-to-unit translation (S2UT) model to predict the discrete representations of the target speech .
When target text transcripts are available, we design a joint speech and text training framework that enables the model to generate dual modality output (speech and text) simultaneously in the same inference pass .
Experiments on the Fisher Spanish-English dataset show that the proposed framework yields improvement of 6.7 BLEU compared with a baseline direct S2ST model that predicts spectrogram features .
When trained without any text transcripts, our model performance is comparable to models that predict spectrograms and are trained with text supervision, showing the potential of our system for translation between unwritten languages .
State-of-the-art abstractive summarization systems often generate hallucinations; i.e., content that is not directly inferable from the source text .
Despite being assumed to be incorrect, we find that much hallucinated content is actually consistent with world knowledge, which we call factual hallucinations .
Including these factual hallucinations in a summary can be beneficial because they provide useful background information .
In this work, we propose a novel detection approach that separates factual from non-factual hallucinations of entities .
Our method is based on an entity’s prior and posterior probabilities according to pre-trained and finetuned masked language models, respectively .
Empirical results suggest that our method vastly outperforms two baselines in both accuracy and F1 scores and has a strong correlation with human judgments on factuality classification tasks.Furthermore, we use our method as a reward signal to train a summarization system using an off-line reinforcement learning (RL) algorithm that can significantly improve the factuality of generated summaries while maintaining the level of abstractiveness .
Controllable summarization aims to provide summaries that take into account user-specified aspects and preferences to better assist them with their information need, as opposed to the standard summarization setup which build a single generic summary of a document.We introduce a human-annotated data set EntSUM for controllable summarization with a focus on named entities as the aspects to control.We conduct an extensive quantitative analysis to motivate the task of entity-centric summarization and show that existing methods for controllable summarization fail to generate entity-centric summaries .
We propose extensions to state-of-the-art summarization approaches that achieve substantially better results on our data set .
Our analysis and results show the challenging nature of this task and of the proposed data set .
User language data can contain highly sensitive personal content .
As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data .
In this work we propose SentDP, pure local differential privacy at the sentence level for a single user document .
We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high (768) dimensional, general 𝜖-SentDP document embeddings .
This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding 𝜖-indistinguishable .
Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP .
As language technologies become more ubiquitous, there are increasing efforts towards expanding the language diversity and coverage of natural language processing (NLP) systems .
Arguably, the most important factor influencing the quality of modern NLP systems is data availability .
In this work, we study the geographical representativeness of NLP datasets, aiming to quantify if and by how much do NLP datasets match the expected needs of the language speakers .
In doing so, we use entity recognition and linking systems, also making important observations about their cross-lingual consistency and giving suggestions for more robust evaluation .
Last, we explore some geographical and economic factors that may explain the observed dataset distributions .
Knowledge of difficulty level of questions helps a teacher in several ways, such as estimating students’ potential quickly by asking carefully selected questions and improving quality of examination by modifying trivial and hard questions .
Can we extract such benefits of instance difficulty in Natural Language Processing? To this end, we conduct Instance-Level Difficulty Analysis of Evaluation data (ILDAE) in a large-scale setup of 23 datasets and demonstrate its five novel applications: 1) conducting efficient-yet-accurate evaluations with fewer instances saving computational cost and time, 2) improving quality of existing evaluation datasets by repairing erroneous and trivial instances, 3) selecting the best model based on application requirements, 4) analyzing dataset characteristics for guiding future data creation, 5) estimating Out-of-Domain performance reliably .
Comprehensive experiments for these applications lead to several interesting results, such as evaluation using just 5% instances (selected via ILDAE) achieves as high as 0.93 Kendall correlation with evaluation using complete dataset and computing weighted accuracy using difficulty scores leads to 5.2% higher correlation with Out-of-Domain performance .
We release the difficulty scores and hope our work will encourage research in this important yet understudied field of leveraging instance difficulty in evaluations .
The ability to integrate context, including perceptual and temporal cues, plays a pivotal role in grounding the meaning of a linguistic utterance .
In order to measure to what extent current vision-and-language models master this ability, we devise a new multimodal challenge, Image Retrieval from Contextual Descriptions (ImageCoDe) .
In particular, models are tasked with retrieving the correct image from a set of 10 minimally contrastive candidates based on a contextual description.As such, each description contains only the details that help distinguish between images.Because of this, descriptions tend to be complex in terms of syntax and discourse and require drawing pragmatic inferences .
Images are sourced from both static pictures and video frames.We benchmark several state-of-the-art models, including both cross-encoders such as ViLBERT and bi-encoders such as CLIP, on ImageCoDe.Our results reveal that these models dramatically lag behind human performance: the best variant achieves an accuracy of 20.9 on video frames and 59.4 on static pictures, compared with 90.8 in humans.Furthermore, we experiment with new model variants that are better equipped to incorporate visual and temporal context into their representations, which achieve modest gains .
Our hope is that ImageCoDE will foster progress in grounded language understanding by encouraging models to focus on fine-grained visual differences .
Molecular representation learning plays an essential role in cheminformatics .
Recently, language model-based approaches have gained popularity as an alternative to traditional expert-designed features to encode molecules .
However, these approaches only utilize a single molecular language for representation learning .
Motivated by the fact that a given molecule can be described using different languages such as Simplified Molecular Line Entry System (SMILES), The International Union of Pure and Applied Chemistry (IUPAC), and The IUPAC International Chemical Identifier (InChI), we propose a multilingual molecular embedding generation approach called MM-Deacon (multilingual molecular domain embedding analysis via contrastive learning) .
MM-Deacon is pre-trained using SMILES and IUPAC as two different languages on large-scale molecules .
We evaluated the robustness of our method on seven molecular property prediction tasks from MoleculeNet benchmark, zero-shot cross-lingual retrieval, and a drug-drug interaction prediction task .
Transformer-based models are the modern work horses for neural machine translation (NMT), reaching state of the art across several benchmarks .
Despite their impressive accuracy, we observe a systemic and rudimentary class of errors made by current state-of-the-art NMT models with regards to translating from a language that doesn’t mark gender on nouns into others that do .
We find that even when the surrounding context provides unambiguous evidence of the appropriate grammatical gender marking, no tested model was able to accurately gender occupation nouns systematically .
We release an evaluation scheme and dataset for measuring the ability of NMT models to translate gender morphology correctly in unambiguous contexts across syntactically diverse sentences .
Our dataset translates from an English source into 20 languages from several different language families .
With the availability of this dataset, our hope is that the NMT community can iterate on solutions for this class of especially egregious errors .
Humans (e.g., crowdworkers) have a remarkable ability in solving different tasks, by simply reading textual instructions that define them and looking at a few examples .
Despite the success of the conventional supervised learning on individual datasets, such models often struggle with generalization across tasks (e.g., a question-answering system cannot solve classification tasks) .
A long-standing challenge in AI is to build a model that learns a new task by understanding the human-readable instructions that define it .
To study this, we introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs) .
The instructions are obtained from crowdsourcing instructions used to create existing NLP datasets and mapped to a unified schema .
Using this meta-dataset, we measure cross-task generalization by training models on seen tasks and measuring generalization to the remaining unseen ones .
We adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output .
Our results indicate that models benefit from instructions when evaluated in terms of generalization to unseen tasks (19% better for models utilizing instructions) .
These models, however, are far behind an estimated performance upperbound indicating significant room for more progress in this direction .
State-of-the-art NLP systems represent inputs with word embeddings, but these are brittle when faced with Out-of-Vocabulary (OOV) words.To address this issue, we follow the principle of mimick-like models to generate vectors for unseen words, by learning the behavior of pre-trained embeddings using only the surface form of words.We present a simple contrastive learning framework, LOVE, which extends the word representation of an existing pre-trained language model (such as BERT) and makes it robust to OOV with few additional parameters.Extensive evaluations demonstrate that our lightweight model achieves similar or even better performances than prior competitors, both on original datasets and on corrupted variants .
Moreover, it can be used in a plug-and-play fashion with FastText and BERT, where it significantly improves their robustness .
Given the ubiquitous nature of numbers in text, reasoning with numbers to perform simple calculations is an important skill of AI systems .
While many datasets and models have been developed to this end, state-of-the-art AI systems are brittle; failing to perform the underlying mathematical reasoning when they appear in a slightly different scenario .
Drawing inspiration from GLUE that was proposed in the context of natural language understanding, we propose NumGLUE, a multi-task benchmark that evaluates the performance of AI systems on eight different tasks, that at their core require simple arithmetic understanding .
We show that this benchmark is far from being solved with neural models including state-of-the-art large-scale language models performing significantly worse than humans (lower by 46.4 %) .
Further, NumGLUE promotes sharing knowledge across tasks, especially those with limited training data as evidenced by the superior performance (average gain of 3.4 % on each task) when a model is jointly trained on all the tasks as opposed to task-specific modeling .
Finally, we hope that NumGLUE will encourage systems that perform robust and general arithmetic reasoning within language, a first step towards being able to perform more complex mathematical reasoning .
A few large, homogenous, pre-trained models undergird many machine learning systems — and often, these models contain harmful stereotypes learned from the internet .
We investigate the bias transfer hypothesis: the theory that social biases (such as stereotypes) internalized by large language models during pre-training transfer into harmful task-specific behavior after fine-tuning .
For two classification tasks, we find that reducing intrinsic bias with controlled interventions before fine-tuning does little to mitigate the classifier’s discriminatory behavior after fine-tuning .
Regression analysis suggests that downstream disparities are better explained by biases in the fine-tuning dataset .
Still, pre-training plays a role: simple alterations to co-occurrence rates in the fine-tuning dataset are ineffective when the model has been pre-trained .
Our results encourage practitioners to focus more on dataset quality and context-specific harms .
A dialogue response is malevolent if it is grounded in negative emotions, inappropriate behavior, or an unethical value basis in terms of content and dialogue acts .
The detection of malevolent dialogue responses is attracting growing interest .
Current research on detecting dialogue malevolence has limitations in terms of datasets and methods .
First, available dialogue datasets related to malevolence are labeled with a single category, but in practice assigning a single category to each utterance may not be appropriate as some malevolent utterances belong to multiple labels .
Second, current methods for detecting dialogue malevolence neglect label correlation .
Therefore, we propose the task of multi-label dialogue malevolence detection and crowdsource a multi-label dataset, multi-label dialogue malevolence detection (MDMD) for evaluation .
We also propose a multi-label malevolence detection model, multi-faceted label correlation enhanced CRF (MCRF), with two label correlation mechanisms, label correlation in taxonomy (LCT) and label correlation in context (LCC) .
Experiments on MDMD show that our method outperforms the best performing baseline by a large margin, i.e., 16.1%, 11.9%, 12.0%, and 6.1% on precision, recall, F1, and Jaccard score, respectively .
Long-form answers, consisting of multiple sentences, can provide nuanced and comprehensive answers to a broader set of questions .
To better understand this complex and understudied task, we study the functional structure of long-form answers collected from three datasets, ELI5, WebGPT and Natural Questions .
Our main goal is to understand how humans organize information to craft complex answers .
We develop an ontology of six sentence-level functional roles for long-form answers, and annotate 3.9k sentences in 640 answer paragraphs .
Different answer collection methods manifest in different discourse structures .
We further analyze model-generated answers – finding that annotators agree less with each other when annotating model-generated answers compared to annotating human-written answers .
Our annotated data enables training a strong classifier that can be used for automatic analysis .
We hope our work can inspire future research on discourse-level modeling and evaluation of long-form QA systems .
Writing is, by nature, a strategic, adaptive, and, more importantly, an iterative process .
A crucial part of writing is editing and revising the text .
Previous works on text revision have focused on defining edit intention taxonomies within a single domain or developing computational models with a single level of edit granularity, such as sentence-level edits, which differ from human’s revision cycles .
This work describes IteraTeR: the first large-scale, multi-domain, edit-intention annotated corpus of iteratively revised text .
In particular, IteraTeR is collected based on a new framework to comprehensively model the iterative text revisions that generalizes to a variety of domains, edit intentions, revision depths, and granularities .
When we incorporate our annotated edit intentions, both generative and action-based text revision models significantly improve automatic evaluations .
Through our work, we better understand the text revision process, making vital connections between edit intentions and writing quality, enabling the creation of diverse corpora to support computational modeling of iterative text revisions .
Several studies have reported the inability of Transformer models to generalize compositionally, a key type of generalization in many NLP tasks such as semantic parsing .
In this paper we explore the design space of Transformer models showing that the inductive biases given to the model by several design decisions significantly impact compositional generalization .
We identified Transformer configurations that generalize compositionally significantly better than previously reported in the literature in many compositional tasks .
We achieve state-of-the-art results in a semantic parsing compositional generalization benchmark (COGS), and a string edit operation composition benchmark (PCFG) .
Unlike literal expressions, idioms’ meanings do not directly follow from their parts, posing a challenge for neural machine translation (NMT) .
NMT models are often unable to translate idioms accurately and over-generate compositional, literal translations .
In this work, we investigate whether the non-compositionality of idioms is reflected in the mechanics of the dominant NMT model, Transformer, by analysing the hidden states and attention patterns for models with English as source language and one of seven European languages as target language.When Transformer emits a non-literal translation - i.e .
identifies the expression as idiomatic - the encoder processes idioms more strongly as single lexical units compared to literal expressions .
This manifests in idioms’ parts being grouped through attention and in reduced interaction between idioms and their context.In the decoder’s cross-attention, figurative inputs result in reduced attention on source-side tokens .
These results suggest that Transformer’s tendency to process idioms as compositional expressions contributes to literal translations of idioms .
We describe a Question Answering (QA) dataset that contains complex questions with conditional answers, i.e .
the answers are only applicable when certain conditions apply .
We call this dataset ConditionalQA .
In addition to conditional answers, the dataset also features:(1) long context documents with information that is related in logically complex ways;(2) multi-hop questions that require compositional logical reasoning;(3) a combination of extractive questions, yes/no questions, questions with multiple answers, and not-answerable questions;(4) questions asked without knowing the answers.We show that ConditionalQA is challenging for many of the existing QA models, especially in selecting answer conditions .
We believe that this dataset will motivate further research in answering complex questions over long documents .
Current methods for few-shot fine-tuning of pretrained masked language models (PLMs) require carefully engineered prompts and verbalizers for each new task to convert examples into a cloze-format that the PLM can score .
In this work, we propose Perfect, a simple and efficient method for few-shot fine-tuning of PLMs without relying on any such handcrafting, which is highly effective given as few as 32 data points .
Perfect makes two key design choices: First, we show that manually engineered task prompts can be replaced with task-specific adapters that enable sample-efficient fine-tuning and reduce memory and storage costs by roughly factors of 5 and 100, respectively .
Second, instead of using handcrafted verbalizers, we learn new multi-token label embeddings during fine-tuning, which are not tied to the model vocabulary and which allow us to avoid complex auto-regressive decoding .
These embeddings are not only learnable from limited data but also enable nearly 100x faster training and inference .
Experiments on a wide range of few shot NLP tasks demonstrate that Perfect, while being simple and efficient, also outperforms existing state-of-the-art few-shot learning methods .
Our code is publicly available at https://github.com/rabeehk/perfect .
Continual learning is essential for real-world deployment when there is a need to quickly adapt the model to new tasks without forgetting knowledge of old tasks .
Existing work on continual sequence generation either always reuses existing parameters to learn new tasks, which is vulnerable to catastrophic forgetting on dissimilar tasks, or blindly adds new parameters for every new task, which could prevent knowledge sharing between similar tasks .
To get the best of both worlds, in this work, we propose continual sequence generation with adaptive compositional modules to adaptively add modules in transformer architectures and compose both old and new modules for new tasks .
We also incorporate pseudo experience replay to facilitate knowledge transfer in those shared modules .
Experiment results on various sequences of generation tasks show that our framework can adaptively add modules or reuse modules based on task similarity, outperforming state-of-the-art baselines in terms of both performance and parameter efficiency .
We make our code public at https://github.com/GT-SALT/Adaptive-Compositional-Modules .
While pretrained language models achieve excellent performance on natural language understanding benchmarks, they tend to rely on spurious correlations and generalize poorly to out-of-distribution (OOD) data .
Recent work has explored using counterfactually-augmented data (CAD)—data generated by minimally perturbing examples to flip the ground-truth label—to identify robust features that are invariant under distribution shift .
However, empirical results using CAD during training for OOD generalization have been mixed .
To explain this discrepancy, through a toy theoretical example and empirical analysis on two crowdsourced CAD datasets, we show that: (a) while features perturbed in CAD are indeed robust features, it may prevent the model from learning unperturbed robust features; and (b) CAD may exacerbate existing spurious correlations in the data .
Our results thus show that the lack of perturbation diversity limits CAD’s effectiveness on OOD generalization, calling for innovative crowdsourcing procedures to elicit diverse perturbation of examples .
Sentiment transfer is one popular example of a text style transfer task, where the goal is to reverse the sentiment polarity of a text .
With a sentiment reversal comes also a reversal in meaning .
We introduce a different but related task called positive reframing in which we neutralize a negative point of view and generate a more positive perspective for the author without contradicting the original meaning .
Our insistence on meaning preservation makes positive reframing a challenging and semantically rich task .
To facilitate rapid progress, we introduce a large-scale benchmark, Positive Psychology Frames, with 8,349 sentence pairs and 12,755 structured annotations to explain positive reframing in terms of six theoretically-motivated reframing strategies .
Then we evaluate a set of state-of-the-art text style transfer models, and conclude by discussing key challenges and directions for future work .
English Natural Language Understanding (NLU) systems have achieved great performances and even outperformed humans on benchmarks like GLUE and SuperGLUE .
However, these benchmarks contain only textbook Standard American English (SAE) .
Other dialects have been largely overlooked in the NLP community .
This leads to biased and inequitable NLU systems that serve only a sub-population of speakers .
To understand disparities in current models and to facilitate more dialect-competent NLU systems, we introduce the VernAcular Language Understanding Evaluation (VALUE) benchmark, a challenging variant of GLUE that we created with a set of lexical and morphosyntactic transformation rules .
In this initial release (V.1), we construct rules for 11 features of African American Vernacular English (AAVE), and we recruit fluent AAVE speakers to validate each feature transformation via linguistic acceptability judgments in a participatory design manner .
Experiments show that these new dialectal features can lead to a drop in model performance .
We study the task of toxic spans detection, which concerns the detection of the spans that make a text toxic, when detecting such spans is possible .
We introduce a dataset for this task, ToxicSpans, which we release publicly .
By experimenting with several methods, we show that sequence labeling models perform best, but methods that add generic rationale extraction mechanisms on top of classifiers trained to predict if a post is toxic or not are also surprisingly promising .
Finally, we use ToxicSpans and systems trained on it, to provide further analysis of state-of-the-art toxic to non-toxic transfer systems, as well as of human performance on that latter task .
Our work highlights challenges in finer toxicity detection and mitigation .
Sequence modeling has demonstrated state-of-the-art performance on natural language and document understanding tasks .
However, it is challenging to correctly serialize tokens in form-like documents in practice due to their variety of layout patterns .
We propose FormNet, a structure-aware sequence model to mitigate the suboptimal serialization of forms .
First, we design Rich Attention that leverages the spatial relationship between tokens in a form for more precise attention score calculation .
Second, we construct Super-Tokens for each word by embedding representations from their neighboring tokens through graph convolutions .
FormNet therefore explicitly recovers local syntactic information that may have been lost during serialization .
In experiments, FormNet outperforms existing methods with a more compact model size and less pre-training data, establishing new state-of-the-art performance on CORD, FUNSD and Payment benchmarks .
Conversational agents have come increasingly closer to human competence in open-domain dialogue settings; however, such models can reflect insensitive, hurtful, or entirely incoherent viewpoints that erode a user’s trust in the moral integrity of the system .
Moral deviations are difficult to mitigate because moral judgments are not universal, and there may be multiple competing judgments that apply to a situation simultaneously .
In this work, we introduce a new resource, not to authoritatively resolve moral ambiguities, but instead to facilitate systematic understanding of the intuitions, values and moral judgments reflected in the utterances of dialogue systems .
The Moral Integrity Corpus, MIC, is such a resource, which captures the moral assumptions of 38k prompt-reply pairs, using 99k distinct Rules of Thumb (RoTs) .
Each RoT reflects a particular moral conviction that can explain why a chatbot’s reply may appear acceptable or problematic .
We further organize RoTs with a set of 9 moral and social attributes and benchmark performance for attribute classification .
Most importantly, we show that current neural language models can automatically generate new RoTs that reasonably describe previously unseen interactions, but they still struggle with certain scenarios .
Our findings suggest that MIC will be a useful resource for understanding and language models’ implicit moral assumptions and flexibly benchmarking the integrity of conversational agents .
To download the data, see https://github.com/GT-SALT/mic .
Transformer-based models generally allocate the same amount of computation for each token in a given sequence .
We develop a simple but effective “token dropping” method to accelerate the pretraining of transformer models, such as BERT, without degrading its performance on downstream tasks .
In particular, we drop unimportant tokens starting from an intermediate layer in the model to make the model focus on important tokens more efficiently if with limited computational resource .
The dropped tokens are later picked up by the last layer of the model so that the model still produces full-length sequences .
We leverage the already built-in masked language modeling (MLM) loss to identify unimportant tokens with practically no computational overhead .
In our experiments, this simple approach reduces the pretraining cost of BERT by 25% while achieving similar overall fine-tuning performance on standard downstream tasks .
Fact-checking is an essential tool to mitigate the spread of misinformation and disinformation .
We introduce the task of fact-checking in dialogue, which is a relatively unexplored area .
We construct DialFact, a testing benchmark dataset of 22,245 annotated conversational claims, paired with pieces of evidence from Wikipedia .
There are three sub-tasks in DialFact: 1) Verifiable claim detection task distinguishes whether a response carries verifiable factual information; 2) Evidence retrieval task retrieves the most relevant Wikipedia snippets as evidence; 3) Claim verification task predicts a dialogue response to be supported, refuted, or not enough information .
We found that existing fact-checking models trained on non-dialogue data like FEVER fail to perform well on our task, and thus, we propose a simple yet data-efficient solution to effectively improve fact-checking performance in dialogue .
We point out unique challenges in DialFact such as handling the colloquialisms, coreferences, and retrieval ambiguities in the error analysis to shed light on future research in this direction .
This work connects language model adaptation with concepts of machine learning theory .
We consider a training setup with a large out-of-domain set and a small in-domain set .
We derive how the benefit of training a model on either set depends on the size of the sets and the distance between their underlying distributions .
We analyze how out-of-domain pre-training before in-domain fine-tuning achieves better generalization than either solution independently .
Finally, we present how adaptation techniques based on data selection, such as importance sampling, intelligent data selection and influence functions, can be presented in a common framework which highlights their similarity and also their subtle differences .
Aligning with ACL 2022 special Theme on “Language Diversity: from Low Resource to Endangered Languages”, we discuss the major linguistic and sociopolitical challenges facing development of NLP technologies for African languages .
Situating African languages in a typological framework, we discuss how the particulars of these languages can be harnessed .
To facilitate future research, we also highlight current efforts, communities, venues, datasets, and tools .
Our main objective is to motivate and advocate for an Afrocentric approach to technology development .
With this in mind, we recommend what technologies to build and how to build, evaluate, and deploy them based on the needs of local African communities .
In this paper, we investigate improvements to the GEC sequence tagging architecture with a focus on ensembling of recent cutting-edge Transformer-based encoders in Large configurations .
We encourage ensembling models by majority votes on span-level edits because this approach is tolerant to the model architecture and vocabulary size .
Our best ensemble achieves a new SOTA result with an F0.5 score of 76.05 on BEA-2019 (test), even without pre-training on synthetic datasets .
In addition, we perform knowledge distillation with a trained ensemble to generate new synthetic training datasets, “Troy-Blogs” and “Troy-1BW” .
Our best single sequence tagging model that is pretrained on the generated Troy- datasets in combination with the publicly available synthetic PIE dataset achieves a near-SOTA result with an F0.5 score of 73.21 on BEA-2019 (test) .
The code, datasets, and trained models are publicly available .
Natural language processing (NLP) models trained on people-generated data can be unreliable because, without any constraints, they can learn from spurious correlations that are not relevant to the task .
We hypothesize that enriching models with speaker information in a controlled, educated way can guide them to pick up on relevant inductive biases .
For the speaker-driven task of predicting code-switching points in English–Spanish bilingual dialogues, we show that adding sociolinguistically-grounded speaker features as prepended prompts significantly improves accuracy .
We find that by adding influential phrases to the input, speaker-informed models learn useful and explainable linguistic information .
To our knowledge, we are the first to incorporate speaker characteristics in a neural model for code-switching, and more generally, take a step towards developing transparent, personalized models that use speaker information in a controlled way .
This work presents a new resource for borrowing identification and analyzes the performance and errors of several models on this task .
We introduce a new annotated corpus of Spanish newswire rich in unassimilated lexical borrowings—words from one language that are introduced into another without orthographic adaptation—and use it to evaluate how several sequence labeling models (CRF, BiLSTM-CRF, and Transformer-based models) perform .
The corpus contains 370,000 tokens and is larger, more borrowing-dense, OOV-rich, and topic-varied than previous corpora available for this task .
Our results show that a BiLSTM-CRF model fed with subword embeddings along with either Transformer-based embeddings pretrained on codeswitched data or a combination of contextualized word embeddings outperforms results obtained by a multilingual BERT-based model .
The performance of deep learning models in NLP and other fields of machine learning has led to a rise in their popularity, and so the need for explanations of these models becomes paramount .
Attention has been seen as a solution to increase performance, while providing some explanations .
However, a debate has started to cast doubt on the explanatory power of attention in neural networks .
Although the debate has created a vast literature thanks to contributions from various areas, the lack of communication is becoming more and more tangible .
In this paper, we provide a clear overview of the insights on the debate by critically confronting works from these different areas .
This holistic vision can be of great interest for future works in all the communities concerned by this debate .
We sum up the main challenges spotted in these areas, and we conclude by discussing the most promising future avenues on attention as an explanation .
Knowledge-grounded conversation (KGC) shows great potential in building an engaging and knowledgeable chatbot, and knowledge selection is a key ingredient in it .
However, previous methods for knowledge selection only concentrate on the relevance between knowledge and dialogue context, ignoring the fact that age, hobby, education and life experience of an interlocutor have a major effect on his or her personal preference over external knowledge .
Without taking the personalization issue into account, it is difficult for existing dialogue systems to select the proper knowledge and generate persona-consistent responses.In this work, we introduce personal memory into knowledge selection in KGC to address the personalization issue .
We propose a variational method to model the underlying relationship between one’s personal memory and his or her selection of knowledge, and devise a learning scheme in which the forward mapping from personal memory to knowledge and its inverse mapping is included in a closed loop so that they could teach each other .
Experiment results show that our methods outperform existing KGC methods significantly on both automatic evaluation and human evaluation .
In data-to-text (D2T) generation, training on in-domain data leads to overfitting to the data representation and repeating training data noise .
We examine how to avoid finetuning pretrained language models (PLMs) on D2T generation datasets while still taking advantage of surface realization capabilities of PLMs .
Inspired by pipeline approaches, we propose to generate text by transforming single-item descriptions with a sequence of modules trained on general-domain text-based operations: ordering, aggregation, and paragraph compression .
We train PLMs for performing these operations on a synthetic corpus WikiFluent which we build from English Wikipedia .
Our experiments on two major triple-to-text datasets—WebNLG and E2E—show that our approach enables D2T generation from RDF triples in zero-shot settings .
Languages are classified as low-resource when they lack the quantity of data necessary for training statistical and machine learning tools and models .
Causes of resource scarcity vary but can include poor access to technology for developing these resources, a relatively small population of speakers, or a lack of urgency for collecting such resources in bilingual populations where the second language is high-resource .
As a result, the languages described as low-resource in the literature are as different as Finnish on the one hand, with millions of speakers using it in every imaginable domain, and Seneca, with only a small-handful of fluent speakers using the language primarily in a restricted domain .
While issues stemming from the lack of resources necessary to train models unite this disparate group of languages, many other issues cut across the divide between widely-spoken low-resource languages and endangered languages .
In this position paper, we discuss the unique technological, cultural, practical, and ethical challenges that researchers and indigenous speech community members face when working together to develop language technology to support endangered language documentation and revitalization .
We report the perspectives of language teachers, Master Speakers and elders from indigenous communities, as well as the point of view of academics .
We describe an ongoing fruitful collaboration and make recommendations for future partnerships between academic researchers and language community stakeholders .
Bragging is a speech act employed with the goal of constructing a favorable self-image through positive statements about oneself .
It is widespread in daily communication and especially popular in social media, where users aim to build a positive image of their persona directly or indirectly .
In this paper, we present the first large scale study of bragging in computational linguistics, building on previous research in linguistics and pragmatics .
To facilitate this, we introduce a new publicly available data set of tweets annotated for bragging and their types .
We empirically evaluate different transformer-based models injected with linguistic information in (a) binary bragging classification, i.e., if tweets contain bragging statements or not; and (b) multi-class bragging type prediction including not bragging .
Our results show that our models can predict bragging with macro F1 up to 72.42 and 35.95 in the binary and multi-class classification tasks respectively .
Finally, we present an extensive linguistic and error analysis of bragging prediction to guide future research on this topic .
Document-level information extraction (IE) tasks have recently begun to be revisited in earnest using the end-to-end neural network techniques that have been successful on their sentence-level IE counterparts .
Evaluation of the approaches, however, has been limited in a number of dimensions .
In particular, the precision/recall/F1 scores typically reported provide few insights on the range of errors the models make .
We build on the work of Kummerfeld and Klein (2013) to propose a transformation-based framework for automating error analysis in document-level event and (N-ary) relation extraction .
We employ our framework to compare two state-of-the-art document-level template-filling approaches on datasets from three domains; and then, to gauge progress in IE since its inception 30 years ago, vs .
four systems from the MUC-4 (1992) evaluation .
Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability .
It models the meaning of a word as a binary classifier rather than a numerical vector .
In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data .
We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus .
On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome .
While large language models have shown exciting progress on several NLP benchmarks, evaluating their ability for complex analogical reasoning remains under-explored .
Here, we introduce a high-quality crowdsourced dataset of narratives for employing proverbs in context as a benchmark for abstract language understanding .
The dataset provides fine-grained annotation of aligned spans between proverbs and narratives, and contains minimal lexical overlaps between narratives and proverbs, ensuring that models need to go beyond surface-level reasoning to succeed .
We explore three tasks: (1) proverb recommendation and alignment prediction, (2) narrative generation for a given proverb and topic, and (3) identifying narratives with similar motifs .
Our experiments show that neural language models struggle on these tasks compared to humans, and these tasks pose multiple learning challenges .
Charts are commonly used for exploring data and communicating insights .
Generating natural language summaries from charts can be very helpful for people in inferring key insights that would otherwise require a lot of cognitive and perceptual efforts .
We present Chart-to-text, a large-scale benchmark with two datasets and a total of 44,096 charts covering a wide range of topics and chart types .
We explain the dataset construction process and analyze the datasets .
We also introduce a number of state-of-the-art neural models as baselines that utilize image captioning and data-to-text generation techniques to tackle two problem variations: one assumes the underlying data table of the chart is available while the other needs to extract data from chart images .
Our analysis with automatic and human evaluation shows that while our best models usually generate fluent summaries and yield reasonable BLEU scores, they also suffer from hallucinations and factual errors as well as difficulties in correctly explaining complex patterns and trends in charts .
Idioms are unlike most phrases in two important ways .
First, words in an idiom have non-canonical meanings .
Second, the non-canonical meanings of words in an idiom are contingent on the presence of other words in the idiom .
Linguistic theories differ on whether these properties depend on one another, as well as whether special theoretical machinery is needed to accommodate idioms .
We define two measures that correspond to the properties above, and we show that idioms fall at the expected intersection of the two dimensions, but that the dimensions themselves are not correlated .
Our results suggest that introducing special machinery to handle idioms may not be warranted .
Graph neural networks have triggered a resurgence of graph-based text classification methods, defining today’s state of the art .
We show that a wide multi-layer perceptron (MLP) using a Bag-of-Words (BoW) outperforms the recent graph-based models TextGCN and HeteGCN in an inductive text classification setting and is comparable with HyperGAT .
Moreover, we fine-tune a sequence-based BERT and a lightweight DistilBERT model, which both outperform all state-of-the-art models .
These results question the importance of synthetic graphs used in modern text classifiers .
In terms of efficiency, DistilBERT is still twice as large as our BoW-based wide MLP, while graph-based models like TextGCN require setting up an 𝒪(N2) graph, where N is the vocabulary plus corpus size .
Finally, since Transformers need to compute 𝒪(L2) attention weights with sequence length L, the MLP models show higher training and inference speeds on datasets with long sequences .
We introduce ParaBLEU, a paraphrase representation learning model and evaluation metric for text generation .
Unlike previous approaches, ParaBLEU learns to understand paraphrasis using generative conditioning as a pretraining objective .
ParaBLEU correlates more strongly with human judgements than existing metrics, obtaining new state-of-the-art results on the 2017 WMT Metrics Shared Task .
We show that our model is robust to data scarcity, exceeding previous state-of-the-art performance using only 50% of the available training data and surpassing BLEU, ROUGE and METEOR with only 40 labelled examples .
Finally, we demonstrate that ParaBLEU can be used to conditionally generate novel paraphrases from a single demonstration, which we use to confirm our hypothesis that it learns abstract, generalized paraphrase representations .
Research in stance detection has so far focused on models which leverage purely textual input .
In this paper, we investigate the integration of textual and financial signals for stance detection in the financial domain .
Specifically, we propose a robust multi-task neural architecture that combines textual input with high-frequency intra-day time series from stock market prices .
Moreover, we extend wt–wt, an existing stance detection dataset which collects tweets discussing Mergers and Acquisitions operations, with the relevant financial signal .
Importantly, the obtained dataset aligns with Stander, an existing news stance detection dataset, thus resulting in a unique multimodal, multi-genre stance detection resource .
We show experimentally and through detailed result analysis that our stance detection system benefits from financial information, and achieves state-of-the-art results on the wt–wt dataset: this demonstrates that the combination of multiple input signals is effective for cross-target stance detection, and opens interesting research directions for future work .
Multilingual neural machine translation models are trained to maximize the likelihood of a mix of examples drawn from multiple language pairs .
The dominant inductive bias applied to these models is a shared vocabulary and a shared set of parameters across languages; the inputs and labels corresponding to examples drawn from different language pairs might still reside in distinct sub-spaces .
In this paper, we introduce multilingual crossover encoder-decoder (mXEncDec) to fuse language pairs at an instance level .
Our approach interpolates instances from different language pairs into joint ‘crossover examples’ in order to encourage sharing input and output spaces across languages .
To ensure better fusion of examples in multilingual settings, we propose several techniques to improve example interpolation across dissimilar languages under heavy data imbalance .
Experiments on a large-scale WMT multilingual dataset demonstrate that our approach significantly improves quality on English-to-Many, Many-to-English and zero-shot translation tasks (from +0.5 BLEU up to +5.5 BLEU points) .
Results on code-switching sets demonstrate the capability of our approach to improve model generalization to out-of-distribution multilingual examples .
We also conduct qualitative and quantitative representation comparisons to analyze the advantages of our approach at the representation level .
Word identification from continuous input is typically viewed as a segmentation task .
Experiments with human adults suggest that familiarity with syntactic structures in their native language also influences word identification in artificial languages; however, the relation between syntactic processing and word identification is yet unclear .
This work takes one step forward by exploring a radically different approach of word identification, in which segmentation of a continuous input is viewed as a process isomorphic to unsupervised constituency parsing .
Besides formalizing the approach, this study reports simulations of human experiments with DIORA (Drozdov et al., 2020), a neural unsupervised constituency parser .
Results show that this model can reproduce human behavior in word identification experiments, suggesting that this is a viable approach to study word identification and its relation to syntactic processing .
The social impact of natural language processing and its applications has received increasing attention .
In this position paper, we focus on the problem of safety for end-to-end conversational AI .
We survey the problem landscape therein, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects .
We then empirically assess the extent to which current tools can measure these effects and current systems display them .
We release these tools as part of a “first aid kit” (SafetyKit) to quickly assess apparent safety concerns .
Our results show that, while current tools are able to provide an estimate of the relative safety of systems in various settings, they still have several shortcomings .
We suggest several future directions and discuss ethical considerations .
Recent work in cross-lingual semantic parsing has successfully applied machine translation to localize parsers to new languages .
However, these advances assume access to high-quality machine translation systems and word alignment tools .
We remove these assumptions and study cross-lingual semantic parsing as a zero-shot problem, without parallel data (i.e., utterance-logical form pairs) for new languages .
We propose a multi-task encoder-decoder model to transfer parsing knowledge to additional languages using only English-logical form paired data and in-domain natural language corpora in each new language .
Our model encourages language-agnostic encodings by jointly optimizing for logical-form generation with auxiliary objectives designed for cross-lingual latent representation alignment .
Our parser performs significantly above translation-based baselines and, in some cases, competes with the supervised upper-bound .
Obtaining human-like performance in NLP is often argued to require compositional generalisation .
Whether neural networks exhibit this ability is usually studied by training models on highly compositional synthetic data .
However, compositionality in natural language is much more complex than the rigid, arithmetic-like version such data adheres to, and artificial compositionality tests thus do not allow us to determine how neural models deal with more realistic forms of compositionality .
In this work, we re-instantiate three compositionality tests from the literature and reformulate them for neural machine translation (NMT).Our results highlight that: i) unfavourably, models trained on more data are more compositional; ii) models are sometimes less compositional than expected, but sometimes more, exemplifying that different levels of compositionality are required, and models are not always able to modulate between them correctly; iii) some of the non-compositional behaviours are mistakes, whereas others reflect the natural variation in data .
Apart from an empirical study, our work is a call to action: we should rethink the evaluation of compositionality in neural networks and develop benchmarks using real data to evaluate compositionality on natural language, where composing meaning is not as straightforward as doing the math .
Document-level neural machine translation (DocNMT) achieves coherent translations by incorporating cross-sentence context .
However, for most language pairs there’s a shortage of parallel documents, although parallel sentences are readily available .
In this paper, we study whether and how contextual modeling in DocNMT is transferable via multilingual modeling .
We focus on the scenario of zero-shot transfer from teacher languages with document level data to student languages with no documents but sentence level data, and for the first time treat document-level translation as a transfer learning problem .
Using simple concatenation-based DocNMT, we explore the effect of 3 factors on the transfer: the number of teacher languages with document level data, the balance between document and sentence level data at training, and the data condition of parallel documents (genuine vs .
back-translated) .
Our experiments on Europarl-7 and IWSLT-10 show the feasibility of multilingual transfer for DocNMT, particularly on document-specific metrics .
We observe that more teacher languages and adequate data balance both contribute to better transfer quality .
Surprisingly, the transfer is less sensitive to the data condition, where multilingual DocNMT delivers decent performance with either back-translated or genuine document pairs .
Cross-lingual retrieval aims to retrieve relevant text across languages .
Current methods typically achieve cross-lingual retrieval by learning language-agnostic text representations in word or sentence level .
However, how to learn phrase representations for cross-lingual phrase retrieval is still an open problem .
In this paper, we propose , a cross-lingual phrase retriever that extracts phrase representations from unlabeled example sentences .
Moreover, we create a large-scale cross-lingual phrase retrieval dataset, which contains 65K bilingual phrase pairs and 4.2M example sentences in 8 English-centric language pairs .
Experimental results show that outperforms state-of-the-art baselines which utilize word-level or sentence-level representations .
also shows impressive zero-shot transferability that enables the model to perform retrieval in an unseen language pair during training .
Our dataset, code, and trained models are publicly available at github.com/cwszz/XPR/ .
Data-to-text generation focuses on generating fluent natural language responses from structured meaning representations (MRs) .
Such representations are compositional and it is costly to collect responses for all possible combinations of atomic meaning schemata, thereby necessitating few-shot generalization to novel MRs .
In this work, we systematically study the compositional generalization of the state-of-the-art T5 models in few-shot data-to-text tasks .
We show that T5 models fail to generalize to unseen MRs, and we propose a template-based input representation that considerably improves the model’s generalization capability .
To further improve the model’s performance, we propose an approach based on self-training using fine-tuned BLEURT for pseudo-response selection .
On the commonly-used SGD and Weather benchmarks, the proposed self-training approach improves tree accuracy by 46%+ and reduces the slot error rates by 73%+ over the strong T5 baselines in few-shot settings .
The rapid development of conversational assistants accelerates the study on conversational question answering (QA) .
However, the existing conversational QA systems usually answer users’ questions with a single knowledge source, e.g., paragraphs or a knowledge graph, but overlook the important visual cues, let alone multiple knowledge sources of different modalities .
In this paper, we hence define a novel research task, i.e., multimodal conversational question answering (MMCoQA), aiming to answer users’ questions with multimodal knowledge sources via multi-turn conversations .
This new task brings a series of research challenges, including but not limited to priority, consistency, and complementarity of multimodal knowledge .
To facilitate the data-driven approaches in this area, we construct the first multimodal conversational QA dataset, named MMConvQA .
Questions are fully annotated with not only natural language answers but also the corresponding evidence and valuable decontextualized self-contained questions .
Meanwhile, we introduce an end-to-end baseline model, which divides this complex research task into question understanding, multi-modal evidence retrieval, and answer extraction .
Moreover, we report a set of benchmarking results, and the results indicate that there is ample room for improvement .
The state-of-the-art model for structured sentiment analysis casts the task as a dependency parsing problem, which has some limitations: (1) The label proportions for span prediction and span relation prediction are imbalanced .
(2) The span lengths of sentiment tuple components may be very large in this task, which will further exacerbates the imbalance problem .
(3) Two nodes in a dependency graph cannot have multiple arcs, therefore some overlapped sentiment tuples cannot be recognized .
In this work, we propose nichetargeting solutions for these issues .
First, we introduce a novel labeling strategy, which contains two sets of token pair labels, namely essential label set and whole label set .
The essential label set consists of the basic labels for this task, which are relatively balanced and applied in the prediction layer .
The whole label set includes rich labels to help our model capture various token relations, which are applied in the hidden layer to softly influence our model .
Moreover, we also propose an effective model to well collaborate with our labeling strategy, which is equipped with the graph attention networks to iteratively refine token representations, and the adaptive multi-label classifier to dynamically predict multiple relations between token pairs .
We perform extensive experiments on 5 benchmark datasets in four languages .
Experimental results show that our model outperforms previous SOTA models by a large margin .
This paper focuses on the Data Augmentation for low-resource Natural Language Understanding (NLU) tasks .
We propose Prompt-based Data Augmentation model (PromDA) which only trains small-scale Soft Prompt (i.e., a set of trainable vectors) in the frozen Pre-trained Language Models (PLMs) .
This avoids human effort in collecting unlabeled in-domain data and maintains the quality of generated synthetic data .
In addition, PromDA generates synthetic data via two different views and filters out the low-quality data using NLU models .
Experiments on four benchmarks show that synthetic data produced by PromDA successfully boost up the performance of NLU models which consistently outperform several competitive baseline models, including a state-of-the-art semi-supervised model using unlabeled in-domain data .
The synthetic data from PromDA are also complementary with unlabeled in-domain data .
The NLU models can be further improved when they are combined for training .
There is mounting evidence that existing neural network models, in particular the very popular sequence-to-sequence architecture, struggle to systematically generalize to unseen compositions of seen components .
We demonstrate that one of the reasons hindering compositional generalization relates to representations being entangled .
We propose an extension to sequence-to-sequence models which encourage disentanglement by adaptively re-encoding (at each time step) the source input .
Specifically, we condition the source representations on the newly decoded target context which makes it easier for the encoder to exploit specialized information for each prediction rather than capturing it all in a single forward pass .
Experimental results on semantic parsing and machine translation empirically show that our proposal delivers more disentangled representations and better generalization .
Pre-trained language models (PLMs) have shown great potentials in natural language processing (NLP) including rhetorical structure theory (RST) discourse parsing.Current PLMs are obtained by sentence-level pre-training, which is different from the basic processing unit, i.e .
element discourse unit (EDU).To this end, we propose a second-stage EDU-level pre-training approach in this work, which presents two novel tasks to learn effective EDU representations continually based on well pre-trained language models.Concretely, the two tasks are (1) next EDU prediction (NEP) and (2) discourse marker prediction (DMP).We take a state-of-the-art transition-based neural parser as baseline, and adopt it with a light bi-gram EDU modification to effectively explore the EDU-level pre-trained EDU representation.Experimental results on a benckmark dataset show that our method is highly effective,leading a 2.1-point improvement in F1-score.All codes and pre-trained models will be released publicly to facilitate future studies .
Knowledge graph completion (KGC) aims to reason over known facts and infer the missing links .
Text-based methods such as KGBERT (Yao et al., 2019) learn entity representations from natural language descriptions, and have the potential for inductive KGC .
However, the performance of text-based methods still largely lag behind graph embedding-based methods like TransE (Bordes et al., 2013) and RotatE (Sun et al., 2019b) .
In this paper, we identify that the key issue is efficient contrastive learning .
To improve the learning efficiency, we introduce three types of negatives: in-batch negatives, pre-batch negatives, and self-negatives which act as a simple form of hard negatives .
Combined with InfoNCE loss, our proposed model SimKGC can substantially outperform embedding-based methods on several benchmark datasets .
In terms of mean reciprocal rank (MRR), we advance the state-of-the-art by +19% on WN18RR, +6.8% on the Wikidata5M transductive setting, and +22% on the Wikidata5M inductive setting .
Thorough analyses are conducted to gain insights into each component .
Our code is available at https://github.com/intfloat/SimKGC  .
Learned self-attention functions in state-of-the-art NLP models often correlate with human attention .
We investigate whether self-attention in large-scale pre-trained language models is as predictive of human eye fixation patterns during task-reading as classical cognitive models of human attention .
We compare attention functions across two task-specific reading datasets for sentiment analysis and relation extraction .
We find the predictiveness of large-scale pre-trained self-attention for human attention depends on ‘what is in the tail’, e.g., the syntactic nature of rare contexts.Further, we observe that task-specific fine-tuning does not increase the correlation with human task-specific reading .
Through an input reduction experiment we give complementary insights on the sparsity and fidelity trade-off, showing that lower-entropy attention vectors are more faithful .
Laws and their interpretations, legal arguments and agreements are typically expressed in writing, leading to the production of vast corpora of legal text .
Their analysis, which is at the center of legal practice, becomes increasingly elaborate as these collections grow in size .
Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors .
Their usefulness, however, largely depends on whether current state-of-the-art models can generalize across various tasks in the legal domain .
To answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way .
We also provide an evaluation and analysis of several generic and legal-oriented models demonstrating that the latter consistently offer performance improvements across multiple tasks .
Lexical ambiguity poses one of the greatest challenges in the field of Machine Translation .
Over the last few decades, multiple efforts have been undertaken to investigate incorrect translations caused by the polysemous nature of words .
Within this body of research, some studies have posited that models pick up semantic biases existing in the training data, thus producing translation errors .
In this paper, we present DiBiMT, the first entirely manually-curated evaluation benchmark which enables an extensive study of semantic biases in Machine Translation of nominal and verbal words in five different language combinations, namely, English and one or other of the following languages: Chinese, German, Italian, Russian and Spanish .
Furthermore, we test state-of-the-art Machine Translation systems, both commercial and non-commercial ones, against our new test bed and provide a thorough statistical and linguistic analysis of the results .
We release DiBiMT at https://nlp.uniroma1.it/dibimt as a closed benchmark with a public leaderboard .
Word translation or bilingual lexicon induction (BLI) is a key cross-lingual task, aiming to bridge the lexical gap between different languages .
In this work, we propose a robust and effective two-stage contrastive learning framework for the BLI task .
At Stage C1, we propose to refine standard cross-lingual linear maps between static word embeddings (WEs) via a contrastive learning objective; we also show how to integrate it into the self-learning procedure for even more refined cross-lingual maps .
In Stage C2, we conduct BLI-oriented contrastive fine-tuning of mBERT, unlocking its word translation capability .
We also show that static WEs induced from the ‘C2-tuned’ mBERT complement static WEs from Stage C1 .
Comprehensive experiments on standard BLI datasets for diverse languages and different experimental setups demonstrate substantial gains achieved by our framework .
While the BLI method from Stage C1 already yields substantial gains over all state-of-the-art BLI methods in our comparison, even stronger improvements are met with the full two-stage framework: e.g., we report gains for 112/112 BLI setups, spanning 28 language pairs .
Neural Chat Translation (NCT) aims to translate conversational text into different languages .
Existing methods mainly focus on modeling the bilingual dialogue characteristics (e.g., coherence) to improve chat translation via multi-task learning on small-scale chat translation data .
Although the NCT models have achieved impressive success, it is still far from satisfactory due to insufficient chat translation data and simple joint training manners .
To address the above issues, we propose a scheduled multi-task learning framework for NCT .
Specifically, we devise a three-stage training framework to incorporate the large-scale in-domain chat translation data into training by adding a second pre-training stage between the original pre-training and fine-tuning stages .
Further, we investigate where and how to schedule the dialogue-related auxiliary tasks in multiple training stages to effectively enhance the main chat translation task .
Extensive experiments on four language directions (English-Chinese and English-German) verify the effectiveness and superiority of the proposed approach .
Additionally, we will make the large-scale in-domain paired bilingual dialogue dataset publicly available for the research community .
We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks .
Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area) .
In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities .
Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP .
Podcasts have shown a recent rise in popularity .
Summarization of podcasts is of practical benefit to both content providers and consumers .
It helps people quickly decide whether they will listen to a podcast and/or reduces the cognitive load of content providers to write summaries .
Nevertheless, podcast summarization faces significant challenges including factual inconsistencies of summaries with respect to the inputs .
The problem is exacerbated by speech disfluencies and recognition errors in transcripts of spoken language .
In this paper, we explore a novel abstractive summarization method to alleviate these issues .
Our approach learns to produce an abstractive summary while grounding summary segments in specific regions of the transcript to allow for full inspection of summary details .
We conduct a series of analyses of the proposed approach on a large podcast dataset and show that the approach can achieve promising results .
Grounded summaries bring clear benefits in locating the summary and transcript segments that contain inconsistent information, and hence improve summarization quality in terms of automatic and human evaluation .
Publicly traded companies are required to submit periodic reports with eXtensive Business Reporting Language (XBRL) word-level tags .
Manually tagging the reports is tedious and costly .
We, therefore, introduce XBRL tagging as a new entity extraction task for the financial domain and release FiNER-139, a dataset of 1.1M sentences with gold XBRL tags .
Unlike typical entity extraction datasets, FiNER-139 uses a much larger label set of 139 entity types .
Most annotated tokens are numeric, with the correct tag per token depending mostly on context, rather than the token itself .
We show that subword fragmentation of numeric expressions harms BERT’s performance, allowing word-level BILSTMs to perform better .
To improve BERT’s performance, we propose two simple and effective solutions that replace numeric expressions with pseudo-tokens reflecting original token shapes and numeric magnitudes .
We also experiment with FIN-BERT, an existing BERT model for the financial domain, and release our own BERT (SEC-BERT), pre-trained on financial filings, which performs best .
Through data and error analysis, we finally identify possible limitations to inspire future work on XBRL tagging .
Contrastive learning has achieved impressive success in generation tasks to militate the “exposure bias” problem and discriminatively exploit the different quality of references .
Existing works mostly focus on contrastive learning on the instance-level without discriminating the contribution of each word, while keywords are the gist of the text and dominant the constrained mapping relationships .
Hence, in this work, we propose a hierarchical contrastive learning mechanism, which can unify hybrid granularities semantic meaning in the input text .
Concretely, we first propose a keyword graph via contrastive correlations of positive-negative pairs to iteratively polish the keyword representations .
Then, we construct intra-contrasts within instance-level and keyword-level, where we assume words are sampled nodes from a sentence distribution .
Finally, to bridge the gap between independent contrast levels and tackle the common contrast vanishing problem, we propose an inter-contrast mechanism that measures the discrepancy between contrastive keyword nodes respectively to the instance distribution .
Experiments demonstrate that our model outperforms competitive baselines on paraphrasing, dialogue generation, and storytelling tasks .
In this paper, we propose a neural model EPT-X (Expression-Pointer Transformer with Explanations), which utilizes natural language explanations to solve an algebraic word problem .
To enhance the explainability of the encoding process of a neural model, EPT-X adopts the concepts of plausibility and faithfulness which are drawn from math word problem solving strategies by humans .
A plausible explanation is one that includes contextual information for the numbers and variables that appear in a given math word problem .
A faithful explanation is one that accurately represents the reasoning process behind the model’s solution equation .
The EPT-X model yields an average baseline performance of 69.59% on our PEN dataset and produces explanations with quality that is comparable to human output .
The contribution of this work is two-fold .
(1) EPT-X model: An explainable neural model that sets a baseline for algebraic word problem solving task, in terms of model’s correctness, plausibility, and faithfulness .
(2) New dataset: We release a novel dataset PEN (Problems with Explanations for Numbers), which expands the existing datasets by attaching explanations to each number/variable .
This paper studies the (often implicit) human values behind natural language arguments, such as to have freedom of thought or to be broadminded .
Values are commonly accepted answers to why some option is desirable in the ethical sense and are thus essential both in real-world argumentation and theoretical argumentation frameworks .
However, their large variety has been a major obstacle to modeling them in argument mining .
To overcome this obstacle, we contribute an operationalization of human values, namely a multi-level taxonomy with 54 values that is in line with psychological research .
Moreover, we provide a dataset of 5270 arguments from four geographical cultures, manually annotated for human values .
First experiments with the automatic classification of human values are promising, with F1-scores up to 0.81 and 0.25 on average .
Intrinsic evaluations of OIE systems are carried out either manually—with human evaluators judging the correctness of extractions—or automatically, on standardized benchmarks .
The latter, while much more cost-effective, is less reliable, primarily because of the incompleteness of the existing OIE benchmarks: the ground truth extractions do not include all acceptable variants of the same fact, leading to unreliable assessment of the models’ performance .
Moreover, the existing OIE benchmarks are available for English only .
In this work, we introduce BenchIE: a benchmark and evaluation framework for comprehensive evaluation of OIE systems for English, Chinese, and German .
In contrast to existing OIE benchmarks, BenchIE is fact-based, i.e., it takes into account informational equivalence of extractions: our gold standard consists of fact synsets, clusters in which we exhaustively list all acceptable surface forms of the same fact .
Moreover, having in mind common downstream applications for OIE, we make BenchIE multi-faceted; i.e., we create benchmark variants that focus on different facets of OIE evaluation, e.g., compactness or minimality of extractions .
We benchmark several state-of-the-art OIE systems using BenchIE and demonstrate that these systems are significantly less effective than indicated by existing OIE benchmarks .
We make BenchIE (data and evaluation code) publicly available .
Training Transformer-based models demands a large amount of data, while obtaining aligned and labelled data in multimodality is rather cost-demanding, especially for audio-visual speech recognition (AVSR) .
Thus it makes a lot of sense to make use of unlabelled unimodal data .
On the other side, although the effectiveness of large-scale self-supervised learning is well established in both audio and visual modalities, how to integrate those pre-trained models into a multimodal scenario remains underexplored .
In this work, we successfully leverage unimodal self-supervised learning to promote the multimodal AVSR .
In particular, audio and visual front-ends are trained on large-scale unimodal datasets, then we integrate components of both front-ends into a larger multimodal framework which learns to recognize parallel audio-visual data into characters through a combination of CTC and seq2seq decoding .
We show that both components inherited from unimodal self-supervised learning cooperate well, resulting in that the multimodal framework yields competitive results through fine-tuning .
Our model is experimentally validated on both word-level and sentence-level tasks .
Especially, even without an external language model, our proposed model raises the state-of-the-art performances on the widely accepted Lip Reading Sentences 2 (LRS2) dataset by a large margin, with a relative improvement of 30% .
Sequence-to-sequence neural networks have recently achieved great success in abstractive summarization, especially through fine-tuning large pre-trained language models on the downstream dataset .
These models are typically decoded with beam search to generate a unique summary .
However, the search space is very large, and with the exposure bias, such decoding is not optimal .
In this paper, we show that it is possible to directly train a second-stage model performing re-ranking on a set of summary candidates .
Our mixture-of-experts SummaReranker learns to select a better candidate and consistently improves the performance of the base model .
With a base PEGASUS, we push ROUGE scores by 5.44% on CNN- DailyMail (47.16 ROUGE-1), 1.31% on XSum (48.12 ROUGE-1) and 9.34% on Reddit TIFU (29.83 ROUGE-1), reaching a new state-of-the-art .
Our code and checkpoints will be available at https://github.com/ntunlp/SummaReranker .
The ability to sequence unordered events is evidence of comprehension and reasoning about real world tasks/procedures .
It is essential for applications such as task planning and multi-source instruction summarization.It often requires thorough understanding of temporal common sense and multimodal information, since these procedures are often conveyed by a combination of texts and images.While humans are capable of reasoning about and sequencing unordered procedural instructions, the extent to which the current machine learning methods possess such capability is still an open question.In this work, we benchmark models’ capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from online instructional manuals and collecting comprehensive human annotations.We find current state-of-the-art models not only perform significantly worse than humans but also seem incapable of efficiently utilizing multimodal information.To improve machines’ performance on multimodal event sequencing, we propose sequence-aware pretraining techniques exploiting the sequential alignment properties of both texts and images, resulting in > 5% improvements on perfect match ratio .
Fake news detection is crucial for preventing the dissemination of misinformation on social media .
To differentiate fake news from real ones, existing methods observe the language patterns of the news post and “zoom in” to verify its content with knowledge sources or check its readers’ replies .
However, these methods neglect the information in the external news environment where a fake news post is created and disseminated .
The news environment represents recent mainstream media opinion and public attention, which is an important inspiration of fake news fabrication because fake news is often designed to ride the wave of popular events and catch public attention with unexpected novel content for greater exposure and spread .
To capture the environmental signals of news posts, we “zoom out” to observe the news environment and propose the News Environment Perception Framework (NEP) .
For each post, we construct its macro and micro news environment from recent mainstream news .
Then we design a popularity-oriented and a novelty-oriented module to perceive useful signals and further assist final prediction .
Experiments on our newly built datasets show that the NEP can efficiently improve the performance of basic fake news detectors .
Multi-encoder models are a broad family of context-aware neural machine translation systems that aim to improve translation quality by encoding document-level contextual information alongside the current sentence .
The context encoding is undertaken by contextual parameters, trained on document-level data .
In this work, we discuss the difficulty of training these parameters effectively, due to the sparsity of the words in need of context (i.e., the training signal), and their relevant context .
We propose to pre-train the contextual parameters over split sentence pairs, which makes an efficient use of the available data for two reasons .
Firstly, it increases the contextual training signal by breaking intra-sentential syntactic relations, and thus pushing the model to search the context for disambiguating clues more frequently .
Secondly, it eases the retrieval of relevant context, since context segments become shorter .
We propose four different splitting methods, and evaluate our approach with BLEU and contrastive test sets .
Results show that it consistently improves learning of contextual parameters, both in low and high resource settings .
Event detection (ED) is a critical subtask of event extraction that seeks to identify event triggers of certain types in texts.Despite significant advances in ED, existing methods typically follow a “one model fits all types” approach, which sees no differences between event types and often results in a quite skewed performance.Finding the causes of skewed performance is crucial for the robustness of an ED model, but to date there has been little exploration of this problem.This research examines the issue in depth and presents a new concept termed trigger salience attribution, which can explicitly quantify the underlying patterns of events .
On this foundation, we develop a new training mechanism for ED, which can distinguish between trigger-dependent and context-dependent types and achieve promising performance on two benchmarks.Finally, by highlighting many distinct characteristics of trigger-dependent and context-dependent types, our work may promote more research into this problem .
In the field of sentiment analysis, several studies have highlighted that a single sentence may express multiple, sometimes contrasting, sentiments and emotions, each with its own experiencer, target and/or cause .
To this end, over the past few years researchers have started to collect and annotate data manually, in order to investigate the capabilities of automatic systems not only to distinguish between emotions, but also to capture their semantic constituents .
However, currently available gold datasets are heterogeneous in size, domain, format, splits, emotion categories and role labels, making comparisons across different works difficult and hampering progress in the area .
In this paper, we tackle this issue and present a unified evaluation framework focused on Semantic Role Labeling for Emotions (SRL4E), in which we unify several datasets tagged with emotions and semantic roles by using a common labeling scheme .
We use SRL4E as a benchmark to evaluate how modern pretrained language models perform and analyze where we currently stand in this task, hoping to provide the tools to facilitate studies in this complex area .
In linguistics, there are two main perspectives on negation: a semantic and a pragmatic view .
So far, research in NLP on negation has almost exclusively adhered to the semantic view .
In this article, we adopt the pragmatic paradigm to conduct a study of negation understanding focusing on transformer-based PLMs .
Our results differ from previous, semantics-based studies and therefore help to contribute a more comprehensive – and, given the results, much more optimistic – picture of the PLMs’ negation understanding .
Thanks to the effectiveness and wide availability of modern pretrained language models (PLMs), recently proposed approaches have achieved remarkable results in dependency- and span-based, multilingual and cross-lingual Semantic Role Labeling (SRL) .
These results have prompted researchers to investigate the inner workings of modern PLMs with the aim of understanding how, where, and to what extent they encode information about SRL .
In this paper, we follow this line of research and probe for predicate argument structures in PLMs .
Our study shows that PLMs do encode semantic structures directly into the contextualized representation of a predicate, and also provides insights into the correlation between predicate senses and their structures, the degree of transferability between nominal and verbal structures, and how such structures are encoded across languages .
Finally, we look at the practical implications of such insights and demonstrate the benefits of embedding predicate argument structure information into an SRL model .
We present a study on leveraging multilingual pre-trained generative language models for zero-shot cross-lingual event argument extraction (EAE) .
By formulating EAE as a language generation task, our method effectively encodes event structures and captures the dependencies between arguments .
We design language-agnostic templates to represent the event argument structures, which are compatible with any language, hence facilitating the cross-lingual transfer .
Our proposed model finetunes multilingual pre-trained generative language models to generate sentences that fill in the language-agnostic template with arguments extracted from the input passage .
The model is trained on source languages and is then directly applied to target languages for event argument extraction .
Experiments demonstrate that the proposed model outperforms the current state-of-the-art models on zero-shot cross-lingual EAE .
Comprehensive studies and error analyses are presented to better understand the advantages and the current limitations of using generative language models for zero-shot cross-lingual transfer EAE .
Identifying changes in individuals’ behaviour and mood, as observed via content shared on online platforms, is increasingly gaining importance .
Most research to-date on this topic focuses on either: (a) identifying individuals at risk or with a certain mental health condition given a batch of posts or (b) providing equivalent labels at the post level .
A disadvantage of such work is the lack of a strong temporal component and the inability to make longitudinal assessments following an individual’s trajectory and allowing timely interventions .
Here we define a new task, that of identifying moments of change in individuals on the basis of their shared content online .
The changes we consider are sudden shifts in mood (switches) or gradual mood progression (escalations) .
We have created detailed guidelines for capturing moments of change and a corpus of 500 manually annotated user timelines (18.7K posts) .
We have developed a variety of baseline models drawing inspiration from related tasks and show that the best performance is obtained through context aware sequential modelling .
We also introduce new metrics for capturing rare events in temporal windows .
Pre-trained language models have been recently shown to benefit task-oriented dialogue (TOD) systems .
Despite their success, existing methods often formulate this task as a cascaded generation problem which can lead to error accumulation across different sub-tasks and greater data annotation overhead .
In this study, we present PPTOD, a unified plug-and-play model for task-oriented dialogue .
In addition, we introduce a new dialogue multi-task pre-training strategy that allows the model to learn the primary TOD task completion skills from heterogeneous dialog corpora .
We extensively test our model on three benchmark TOD tasks, including end-to-end dialogue modelling, dialogue state tracking, and intent classification .
Experimental results show that PPTOD achieves new state of the art on all evaluated tasks in both high-resource and low-resource scenarios .
Furthermore, comparisons against previous SOTA methods show that the responses generated by PPTOD are more factually correct and semantically coherent as judged by human annotators .
The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians .
Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention .
With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information) .
Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings .
To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation .
In detail, for each input findings, it is encoded by a text encoder and a graph is constructed through its entities and dependency tree .
Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph .
Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words) .
The experimental results on two datasets, OpenI and MIMIC-CXR, confirm the effectiveness of our proposed method, where the state-of-the-art results are achieved .
Formality style transfer (FST) is a task that involves paraphrasing an informal sentence into a formal one without altering its meaning .
To address the data-scarcity problem of existing parallel datasets, previous studies tend to adopt a cycle-reconstruction scheme to utilize additional unlabeled data, where the FST model mainly benefits from target-side unlabeled sentences .
In this work, we propose a simple yet effective semi-supervised framework to better utilize source-side unlabeled sentences based on consistency training .
Specifically, our approach augments pseudo-parallel data obtained from a source-side informal sentence by enforcing the model to generate similar outputs for its perturbed version .
Moreover, we empirically examined the effects of various data perturbation methods and propose effective data filtering strategies to improve our framework .
Experimental results on the GYAFC benchmark demonstrate that our approach can achieve state-of-the-art results, even with less than 40% of the parallel data .
Multilingual pre-trained language models, such as mBERT and XLM-R, have shown impressive cross-lingual ability .
Surprisingly, both of them use multilingual masked language model (MLM) without any cross-lingual supervision or aligned data .
Despite the encouraging results, we still lack a clear understanding of why cross-lingual ability could emerge from multilingual MLM .
In our work, we argue that cross-language ability comes from the commonality between languages .
Specifically, we study three language properties: constituent order, composition and word co-occurrence .
First, we create an artificial language by modifying property in source language .
Then we study the contribution of modified property through the change of cross-language transfer results on target language .
We conduct experiments on six languages and two cross-lingual NLP tasks (textual entailment, sentence retrieval) .
Our main conclusion is that the contribution of constituent order and word co-occurrence is limited, while the composition is more crucial to the success of cross-linguistic transfer .
Word sense disambiguation (WSD) is a crucial problem in the natural language processing (NLP) community .
Current methods achieve decent performance by utilizing supervised learning and large pre-trained language models .
However, the imbalanced training dataset leads to poor performance on rare senses and zero-shot senses .
There are more training instances and senses for words with top frequency ranks than those with low frequency ranks in the training dataset .
We investigate the statistical relation between word frequency rank and word sense number distribution .
Based on the relation, we propose a Z-reweighting method on the word level to adjust the training on the imbalanced dataset .
The experiments show that the Z-reweighting strategy achieves performance gain on the standard English all words WSD benchmark .
Moreover, the strategy can help models generalize better on rare and zero-shot senses .
With state-of-the-art systems having finally attained estimated human performance, Word Sense Disambiguation (WSD) has now joined the array of Natural Language Processing tasks that have seemingly been solved, thanks to the vast amounts of knowledge encoded into Transformer-based pre-trained language models .
And yet, if we look below the surface of raw figures, it is easy to realize that current approaches still make trivial mistakes that a human would never make .
In this work, we provide evidence showing why the F1 score metric should not simply be taken at face value and present an exhaustive analysis of the errors that seven of the most representative state-of-the-art systems for English all-words WSD make on traditional evaluation benchmarks.In addition, we produce and release a collection of test sets featuring (a) an amended version of the standard evaluation benchmark that fixes its lexical and semantic inaccuracies, (b) 42D, a challenge set devised to assess the resilience of systems with respect to least frequent word senses and senses not seen at training time, and (c) hardEN, a challenge set made up solely of instances which none of the investigated state-of-the-art systems can solve .
We make all of the test sets and model predictions available to the research community at https://github.com/SapienzaNLP/wsd-hard-benchmark .
We present a word-sense induction method based on pre-trained masked language models (MLMs), which can cheaply scale to large vocabularies and large corpora .
The result is a corpus which is sense-tagged according to a corpus-derived sense inventory and where each sense is associated with indicative words .
Evaluation on English Wikipedia that was sense-tagged using our method shows that both the induced senses, and the per-instance sense assignment, are of high quality even compared to WSD methods, such as Babelfy .
Furthermore, by training a static word embeddings algorithm on the sense-tagged corpus, we obtain high-quality static senseful embeddings .
These outperform existing senseful embeddings methods on the WiC dataset and on a new outlier detection dataset we developed .
The data driven nature of the algorithm allows to induce corpora-specific senses, which may not appear in standard sense inventories, as we demonstrate using a case study on the scientific domain .
Synthetic translations have been used for a wide range of NLP tasks primarily as a means of data augmentation .
This work explores, instead, how synthetic translations can be used to revise potentially imperfect reference translations in mined bitext .
We find that synthetic samples can improve bitext quality without any additional bilingual supervision when they replace the originals based on a semantic equivalence classifier that helps mitigate NMT noise .
The improved quality of the revised bitext is confirmed intrinsically via human evaluation and extrinsically through bilingual induction and MT tasks .
Recent work has identified properties of pretrained self-attention models that mirror those of dependency parse structures .
In particular, some self-attention heads correspond well to individual dependency types .
Inspired by these developments, we propose a new competitive mechanism that encourages these attention heads to model different dependency relations .
We introduce a new model, the Unsupervised Dependency Graph Network (UDGN), that can induce dependency structures from raw corpora and the masked language modeling task .
Experiment results show that UDGN achieves very strong unsupervised dependency parsing performance without gold POS tags and any other external information .
The competitive gated heads show a strong correlation with human-annotated dependency types .
Furthermore, the UDGN can also achieve competitive performance on masked language modeling and sentence textual similarity tasks .
Multimodal Entity Linking (MEL) which aims at linking mentions with multimodal contexts to the referent entities from a knowledge base (e.g., Wikipedia), is an essential task for many multimodal applications .
Although much attention has been paid to MEL, the shortcomings of existing MEL datasets including limited contextual topics and entity types, simplified mention ambiguity, and restricted availability, have caused great obstacles to the research and application of MEL .
In this paper, we present WikiDiverse, a high-quality human-annotated MEL dataset with diversified contextual topics and entity types from Wikinews, which uses Wikipedia as the corresponding knowledge base .
A well-tailored annotation procedure is adopted to ensure the quality of the dataset .
Based on WikiDiverse, a sequence of well-designed MEL models with intra-modality and inter-modality attentions are implemented, which utilize the visual information of images more adequately than existing MEL models do .
Extensive experimental analyses are conducted to investigate the contributions of different modalities in terms of MEL, facilitating the future research on this task .
Knowledge probing is crucial for understanding the knowledge transfer mechanism behind the pre-trained language models (PLMs) .
Despite the growing progress of probing knowledge for PLMs in the general domain, specialised areas such as the biomedical domain are vastly under-explored .
To facilitate this, we release a well-curated biomedical knowledge probing benchmark, MedLAMA, constructed based on the Unified Medical Language System (UMLS) Metathesaurus .
We test a wide spectrum of state-of-the-art PLMs and probing approaches on our benchmark, reaching at most 3% of acc@10 .
While highlighting various sources of domain-specific challenges that amount to this underwhelming performance, we illustrate that the underlying PLMs have a higher potential for probing tasks .
To achieve this, we propose Contrastive-Probe, a novel self-supervised contrastive probing approach, that adjusts the underlying PLMs without using any probing data .
While Contrastive-Probe pushes the acc@10 to 28%, the performance gap still remains notable .
Our human expert evaluation suggests that the probing performance of our Contrastive-Probe is still under-estimated as UMLS still does not include the full spectrum of factual knowledge .
We hope MedLAMA and Contrastive-Probe facilitate further developments of more suited probing techniques for this domain .
Our code and dataset are publicly available at https://github.com/cambridgeltl/medlama .
Transformer-based pre-trained models, such as BERT, have shown extraordinary success in achieving state-of-the-art results in many natural language processing applications .
However, deploying these models can be prohibitively costly, as the standard self-attention mechanism of the Transformer suffers from quadratic computational cost in the input sequence length .
To confront this, we propose FCA, a fine- and coarse-granularity hybrid self-attention that reduces the computation cost through progressively shortening the computational sequence length in self-attention .
Specifically, FCA conducts an attention-based scoring strategy to determine the informativeness of tokens at each layer .
Then, the informative tokens serve as the fine-granularity computing units in self-attention and the uninformative tokens are replaced with one or several clusters as the coarse-granularity computing units in self-attention .
Experiments on the standard GLUE benchmark show that BERT with FCA achieves 2x reduction in FLOPs over original BERT with <1% loss in accuracy .
We show that FCA offers a significantly better trade-off between accuracy and FLOPs compared to prior methods .
The increasing size of generative Pre-trained Language Models (PLMs) have greatly increased the demand for model compression .
Despite various methods to compress BERT or its variants, there are few attempts to compress generative PLMs, and the underlying difficulty remains unclear .
In this paper, we compress generative PLMs by quantization .
We find that previous quantization methods fail on generative tasks due to the homogeneous word embeddings caused by reduced capacity and the varied distribution of weights .
Correspondingly, we propose a token-level contrastive distillation to learn distinguishable word embeddings, and a module-wise dynamic scaling to make quantizers adaptive to different modules .
Empirical results on various tasks show that our proposed method outperforms the state-of-the-art compression methods on generative PLMs by a clear margin .
With comparable performance with the full-precision models, we achieve 14.4x and 13.4x compression rate on GPT-2 and BART, respectively .
Vision-language navigation (VLN) is a challenging task due to its large searching space in the environment .
To address this problem, previous works have proposed some methods of fine-tuning a large model that pretrained on large-scale datasets .
However, the conventional fine-tuning methods require extra human-labeled navigation data and lack self-exploration capabilities in environments, which hinders their generalization of unseen scenes .
To improve the ability of fast cross-domain adaptation, we propose Prompt-based Environmental Self-exploration (ProbES), which can self-explore the environments by sampling trajectories and automatically generates structured instructions via a large-scale cross-modal pretrained model (CLIP) .
Our method fully utilizes the knowledge learned from CLIP to build an in-domain dataset by self-exploration without human labeling .
Unlike the conventional approach of fine-tuning, we introduce prompt tuning to achieve fast adaptation for language embeddings, which substantially improves the learning efficiency by leveraging prior knowledge .
By automatically synthesizing trajectory-instruction pairs in any environment without human supervision and instruction prompt tuning, our model can adapt to diverse vision-language navigation tasks, including VLN and REVERIE .
Both qualitative and quantitative results show that our ProbES significantly improves the generalization ability of the navigation model .
Dialog response generation in open domain is an important research topic where the main challenge is to generate relevant and diverse responses .
In this paper, we propose a new dialog pre-training framework called DialogVED, which introduces continuous latent variables into the enhanced encoder-decoder pre-training framework to increase the relevance and diversity of responses .
With the help of a large dialog corpus (Reddit), we pre-train the model using the following 4 tasks, used in training language models (LMs) and Variational Autoencoders (VAEs) literature: 1) masked language model; 2) response generation; 3) bag-of-words prediction; and 4) KL divergence reduction .
We also add additional parameters to model the turn structure in dialogs to improve the performance of the pre-trained model .
We conduct experiments on PersonaChat, DailyDialog, and DSTC7-AVSD benchmarks for response generation .
Experimental results show that our model achieves the new state-of-the-art results on all these datasets .
We study the problem of coarse-grained response selection in retrieval-based dialogue systems .
The problem is equally important with fine-grained response selection, but is less explored in existing literature .
In this paper, we propose a Contextual Fine-to-Coarse (CFC) distilled model for coarse-grained response selection in open-domain conversations .
In our CFC model, dense representations of query, candidate contexts and responses is learned based on the multi-tower architecture using contextual matching, and richer knowledge learned from the one-tower architecture (fine-grained) is distilled into the multi-tower architecture (coarse-grained) to enhance the performance of the retriever .
To evaluate the performance of the proposed model, we construct two new datasets based on the Reddit comments dump and Twitter corpus .
Extensive experimental results on the two datasets show that the proposed method achieves huge improvement over all evaluation metrics compared with traditional baseline methods .
Summarizing biomedical discovery from genomics data using natural languages is an essential step in biomedical research but is mostly done manually .
Here, we introduce Textomics, a novel dataset of genomics data description, which contains 22,273 pairs of genomics data matrices and their summaries .
Each summary is written by the researchers who generated the data and associated with a scientific paper .
Based on this dataset, we study two novel tasks: generating textual summary from a genomics data matrix and vice versa .
Inspired by the successful applications of k nearest neighbors in modeling genomics data, we propose a kNN-Vec2Text model to address these tasks and observe substantial improvement on our dataset .
We further illustrate how Textomics can be used to advance other applications, including evaluating scientific paper embeddings and generating masked templates for scientific paper understanding .
Textomics serves as the first benchmark for generating textual summaries for genomics data and we envision it will be broadly applied to other biomedical and natural language processing applications .
Learning high-quality sentence representations is a fundamental problem of natural language processing which could benefit a wide range of downstream tasks .
Though the BERT-like pre-trained language models have achieved great success, using their sentence representations directly often results in poor performance on the semantic textual similarity task .
Recently, several contrastive learning methods have been proposed for learning sentence representations and have shown promising results .
However, most of them focus on the constitution of positive and negative representation pairs and pay little attention to the training objective like NT-Xent, which is not sufficient enough to acquire the discriminating power and is unable to model the partial order of semantics between sentences .
So in this paper, we propose a new method ArcCSE, with training objectives designed to enhance the pairwise discriminative power and model the entailment relation of triplet sentences .
We conduct extensive experiments which demonstrate that our approach outperforms the previous state-of-the-art on diverse sentence related tasks, including STS and SentEval .
Recent entity and relation extraction works focus on investigating how to obtain a better span representation from the pre-trained encoder .
However, a major limitation of existing works is that they ignore the interrelation between spans (pairs) .
In this work, we propose a novel span representation approach, named Packed Levitated Markers (PL-Marker), to consider the interrelation between the spans (pairs) by strategically packing the markers in the encoder .
In particular, we propose a neighborhood-oriented packing strategy, which considers the neighbor spans integrally to better model the entity boundary information .
Furthermore, for those more complicated span pair classification tasks, we design a subject-oriented packing strategy, which packs each subject and all its objects to model the interrelation between the same-subject span pairs .
The experimental results show that, with the enhanced marker feature, our model advances baselines on six NER benchmarks, and obtains a 4.1%-4.3% strict relation F1 improvement with higher speed over previous state-of-the-art models on ACE04 and ACE05 .
Our code and models are publicly available at https://github.com/thunlp/PL-Marker .
We study the interpretability issue of task-oriented dialogue systems in this paper .
Previously, most neural-based task-oriented dialogue systems employ an implicit reasoning strategy that makes the model predictions uninterpretable to humans .
To obtain a transparent reasoning process, we introduce neuro-symbolic to perform explicit reasoning that justifies model decisions by reasoning chains .
Since deriving reasoning chains requires multi-hop reasoning for task-oriented dialogues, existing neuro-symbolic approaches would induce error propagation due to the one-phase design .
To overcome this, we propose a two-phase approach that consists of a hypothesis generator and a reasoner .
We first obtain multiple hypotheses, i.e., potential operations to perform the desired task, through the hypothesis generator .
Each hypothesis is then verified by the reasoner, and the valid one is selected to conduct the final prediction .
The whole system is trained by exploiting raw textual dialogues without using any reasoning chain annotations .
Experimental studies on two public benchmark datasets demonstrate that the proposed approach not only achieves better results, but also introduces an interpretable decision process .
There has been a growing interest in developing machine learning (ML) models for code summarization tasks, e.g., comment generation and method naming .
Despite substantial increase in the effectiveness of ML models, the evaluation methodologies, i.e., the way people split datasets into training, validation, and test sets, were not well studied .
Specifically, no prior work on code summarization considered the timestamps of code and comments during evaluation .
This may lead to evaluations that are inconsistent with the intended use cases .
In this paper, we introduce the time-segmented evaluation methodology, which is novel to the code summarization research community, and compare it with the mixed-project and cross-project methodologies that have been commonly used .
Each methodology can be mapped to some use cases, and the time-segmented methodology should be adopted in the evaluation of ML models for code summarization .
To assess the impact of methodologies, we collect a dataset of (code, comment) pairs with timestamps to train and evaluate several recent ML models for code summarization .
Our experiments show that different methodologies lead to conflicting evaluation results .
We invite the community to expand the set of methodologies used in evaluations .
Current Open-Domain Question Answering (ODQA) models typically include a retrieving module and a reading module, where the retriever selects potentially relevant passages from open-source documents for a given question, and the reader produces an answer based on the retrieved passages .
The recently proposed Fusion-in-Decoder (FiD) framework is a representative example, which is built on top of a dense passage retriever and a generative reader, achieving the state-of-the-art performance .
In this paper we further improve the FiD approach by introducing a knowledge-enhanced version, namely KG-FiD .
Our new model uses a knowledge graph to establish the structural relationship among the retrieved passages, and a graph neural network (GNN) to re-rank the passages and select only a top few for further processing .
Our experiments on common ODQA benchmark datasets (Natural Questions and TriviaQA) demonstrate that KG-FiD can achieve comparable or better performance in answer prediction than FiD, with less than 40% of the computation cost .
Social media is a breeding ground for threat narratives and related conspiracy theories .
In these, an outside group threatens the integrity of an inside group, leading to the emergence of sharply defined group identities: Insiders – agents with whom the authors identify and Outsiders – agents who threaten the insiders .
Inferring the members of these groups constitutes a challenging new NLP task: (i) Information is distributed over many poorly-constructed posts; (ii) Threats and threat agents are highly contextual, with the same post potentially having multiple agents assigned to membership in either group; (iii) An agent’s identity is often implicit and transitive; and (iv) Phrases used to imply Outsider status often do not follow common negative sentiment patterns .
To address these challenges, we define a novel Insider-Outsider classification task .
Because we are not aware of any appropriate existing datasets or attendant models, we introduce a labeled dataset (CT5K) and design a model (NP2IO) to address this task .
NP2IO leverages pretrained language modeling to classify Insiders and Outsiders .
NP2IO is shown to be robust, generalizing to noun phrases not seen during training, and exceeding the performance of non-trivial baseline models by 20% .
Most low resource language technology development is premised on the need to collect data for training statistical models .
When we follow the typical process of recording and transcribing text for small Indigenous languages, we hit up against the so-called “transcription bottleneck.” Therefore it is worth exploring new ways of engaging with speakers which generate data while avoiding the transcription bottleneck .
We have deployed a prototype app for speakers to use for confirming system guesses in an approach to transcription based on word spotting .
However, in the process of testing the app we encountered many new problems for engagement with speakers .
This paper presents a close-up study of the process of deploying data capture technology on the ground in an Australian Aboriginal community .
We reflect on our interactions with participants and draw lessons that apply to anyone seeking to develop methods for language data collection in an Indigenous community .
Multi-hop reading comprehension requires an ability to reason across multiple documents .
On the one hand, deep learning approaches only implicitly encode query-related information into distributed embeddings which fail to uncover the discrete relational reasoning process to infer the correct answer .
On the other hand, logic-based approaches provide interpretable rules to infer the target answer, but mostly work on structured data where entities and relations are well-defined .
In this paper, we propose a deep-learning based inductive logic reasoning method that firstly extracts query-related (candidate-related) information, and then conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation .
The reasoning process is accomplished via attentive memories with novel differentiable logic operators .
To demonstrate the effectiveness of our model, we evaluate it on two reading comprehension datasets, namely WikiHop and MedHop .
This paper addresses the problem of dialogue reasoning with contextualized commonsense inference .
We curate CICERO, a dataset of dyadic conversations with five types of utterance-level reasoning-based inferences: cause, subsequent event, prerequisite, motivation, and emotional reaction .
The dataset contains 53,105 of such inferences from 5,672 dialogues .
We use this dataset to solve relevant generative and discriminative tasks: generation of cause and subsequent event; generation of prerequisite, motivation, and listener’s emotional reaction; and selection of plausible alternatives .
Our results ascertain the value of such dialogue-centric commonsense knowledge datasets .
It is our hope that CICERO will open new research avenues into commonsense-based dialogue reasoning .
Interpretable methods to reveal the internal reasoning processes behind machine learning models have attracted increasing attention in recent years .
To quantify the extent to which the identified interpretations truly reflect the intrinsic decision-making mechanisms, various faithfulness evaluation metrics have been proposed .
However, we find that different faithfulness metrics show conflicting preferences when comparing different interpretations .
Motivated by this observation, we aim to conduct a comprehensive and comparative study of the widely adopted faithfulness metrics .
In particular, we introduce two assessment dimensions, namely diagnosticity and complexity .
Diagnosticity refers to the degree to which the faithfulness metric favors relatively faithful interpretations over randomly generated ones, and complexity is measured by the average number of model forward passes .
According to the experimental results, we find that sufficiency and comprehensiveness metrics have higher diagnosticity and lower complexity than the other faithfulness metrics .
There has been growing interest in parameter-efficient methods to apply pre-trained language models to downstream tasks .
Building on the Prompt Tuning approach of Lester et al .
(2021), which learns task-specific soft prompts to condition a frozen pre-trained model to perform different tasks, we propose a novel prompt-based transfer learning approach called SPoT: Soft Prompt Transfer .
SPoT first learns a prompt on one or more source tasks and then uses it to initialize the prompt for a target task .
We show that SPoT significantly boosts the performance of Prompt Tuning across many tasks .
More remarkably, across all model sizes, SPoT matches or outperforms standard Model Tuning (which fine-tunes all model parameters) on the SuperGLUE benchmark, while using up to 27,000× fewer task-specific parameters .
To understand where SPoT is most effective, we conduct a large-scale study on task transferability with 26 NLP tasks in 160 combinations, and demonstrate that many tasks can benefit each other via prompt transfer .
Finally, we propose an efficient retrieval approach that interprets task prompts as task embeddings to identify similar tasks and predict the most transferable source tasks for a novel target task .
Selecting an appropriate pre-trained model (PTM) for a specific downstream task typically requires significant efforts of fine-tuning .
To accelerate this process, researchers propose feature-based model selection (FMS) methods, which assess PTMs’ transferability to a specific task in a fast way without fine-tuning .
In this work, we argue that current FMS methods are vulnerable, as the assessment mainly relies on the static features extracted from PTMs .
However, such features are derived without training PTMs on downstream tasks, and are not necessarily reliable indicators for the PTM’s transferability .
To validate our viewpoints, we design two methods to evaluate the robustness of FMS: (1) model disguise attack, which post-trains an inferior PTM with a contrastive objective, and (2) evaluation data selection, which selects a subset of the data points for FMS evaluation based on K-means clustering .
Experimental results prove that both methods can successfully make FMS mistakenly judge the transferability of PTMs .
Moreover, we find that these two methods can further be combined with the backdoor attack to misguide the FMS to select poisoned models .
To the best of our knowledge, this is the first work to demonstrate the defects of current FMS algorithms and evaluate their potential security risks .
By identifying previously unseen risks of FMS, our study indicates new directions for improving the robustness of FMS .
Generating educational questions of fairytales or storybooks is vital for improving children’s literacy ability .
However, it is challenging to generate questions that capture the interesting aspects of a fairytale story with educational meaningfulness .
In this paper, we propose a novel question generation method that first learns the question type distribution of an input story paragraph, and then summarizes salient events which can be used to generate high-cognitive-demand questions .
To train the event-centric summarizer, we finetune a pre-trained transformer-based sequence-to-sequence model using silver samples composed by educational question-answer pairs .
On a newly proposed educational question-answering dataset FairytaleQA, we show good performance of our method on both automatic and human evaluation metrics .
Our work indicates the necessity of decomposing question type distribution learning and event-centric summary generation for educational question generation .
Recently, various response generation models for two-party conversations have achieved impressive improvements, but less effort has been paid to multi-party conversations (MPCs) which are more practical and complicated .
Compared with a two-party conversation where a dialogue context is a sequence of utterances, building a response generation model for MPCs is more challenging, since there exist complicated context structures and the generated responses heavily rely on both interlocutors (i.e., speaker and addressee) and history utterances .
To address these challenges, we present HeterMPC, a heterogeneous graph-based neural network for response generation in MPCs which models the semantics of utterances and interlocutors simultaneously with two types of nodes in a graph .
Besides, we also design six types of meta relations with node-edge-type-dependent parameters to characterize the heterogeneous interactions within the graph .
Through multi-hop updating, HeterMPC can adequately utilize the structural knowledge of conversations for response generation .
Experimental results on the Ubuntu Internet Relay Chat (IRC) channel benchmark show that HeterMPC outperforms various baseline models for response generation in MPCs .
Although multi-document summarisation (MDS) of the biomedical literature is a highly valuable task that has recently attracted substantial interest, evaluation of the quality of biomedical summaries lacks consistency and transparency .
In this paper, we examine the summaries generated by two current models in order to understand the deficiencies of existing evaluation approaches in the context of the challenges that arise in the MDS task .
Based on this analysis, we propose a new approach to human evaluation and identify several challenges that must be overcome to develop effective biomedical MDS systems .
Multi-document summarization (MDS) has made significant progress in recent years, in part facilitated by the availability of new, dedicated datasets and capacious language models .
However, a standing limitation of these models is that they are trained against limited references and with plain maximum-likelihood objectives .
As for many other generative tasks, reinforcement learning (RL) offers the potential to improve the training of MDS models; yet, it requires a carefully-designed reward that can ensure appropriate leverage of both the reference summaries and the input documents .
For this reason, in this paper we propose fine-tuning an MDS baseline with a reward that balances a reference-based metric such as ROUGE with coverage of the input documents .
To implement the approach, we utilize RELAX (Grathwohl et al., 2018), a contemporary gradient estimator which is both low-variance and unbiased, and we fine-tune the baseline in a few-shot style for both stability and computational efficiency .
Experimental results over the Multi-News and WCEP MDS datasets show significant improvements of up to +0.95 pp average ROUGE score and +3.17 pp METEOR score over the baseline, and competitive results with the literature .
In addition, they show that the coverage of the input documents is increased, and evenly across all documents .
The Out-of-Domain (OOD) intent classification is a basic and challenging task for dialogue systems .
Previous methods commonly restrict the region (in feature space) of In-domain (IND) intent features to be compact or simply-connected implicitly, which assumes no OOD intents reside, to learn discriminative semantic features .
Then the distribution of the IND intent features is often assumed to obey a hypothetical distribution (Gaussian mostly) and samples outside this distribution are regarded as OOD samples .
In this paper, we start from the nature of OOD intent classification and explore its optimization objective .
We further propose a simple yet effective method, named KNN-contrastive learning .
Our approach utilizes k-nearest neighbors (KNN) of IND intents to learn discriminative semantic features that are more conducive to OOD detection.Notably, the density-based novelty detection algorithm is so well-grounded in the essence of our method that it is reasonable to use it as the OOD detection algorithm without making any requirements for the feature distribution.Extensive experiments on four public datasets show that our approach can not only enhance the OOD detection performance substantially but also improve the IND intent classification while requiring no restrictions on feature distribution .
Program understanding is a fundamental task in program language processing .
Despite the success, existing works fail to take human behaviors as reference in understanding programs .
In this paper, we consider human behaviors and propose the PGNN-EK model that consists of two main components .
On the one hand, inspired by the “divide-and-conquer” reading behaviors of humans, we present a partitioning-based graph neural network model PGNN on the upgraded AST of codes .
On the other hand, to characterize human behaviors of resorting to other resources to help code comprehension, we transform raw codes with external knowledge and apply pre-training techniques for information extraction .
Finally, we combine the two embeddings generated from the two components to output code embeddings .
We conduct extensive experiments to show the superior performance of PGNN-EK on the code summarization and code clone detection tasks .
In particular, to show the generalization ability of our model, we release a new dataset that is more challenging for code clone detection and could advance the development of the community .
Our codes and data are publicly available at https://github.com/RecklessRonan/PGNN-EK .
Despite significant interest in developing general purpose fact checking models, it is challenging to construct a large-scale fact verification dataset with realistic real-world claims .
Existing claims are either authored by crowdworkers, thereby introducing subtle biases thatare difficult to control for, or manually verified by professional fact checkers, causing them to be expensive and limited in scale .
In this paper, we construct a large-scale challenging fact verification dataset called FAVIQ, consisting of 188k claims derived from an existing corpus of ambiguous information-seeking questions .
The ambiguities in the questions enable automatically constructing true and false claims that reflect user confusions (e.g., the year of the movie being filmed vs .
being released) .
Claims in FAVIQ are verified to be natural, contain little lexical bias, and require a complete understanding of the evidence for verification .
Our experiments show that the state-of-the-art models are far from solving our new task .
Moreover, training on our data helps in professional fact-checking, outperforming models trained on the widely used dataset FEVER or in-domain data by up to 17% absolute .
Altogether, our data will serve as a challenging benchmark for natural language understanding and support future progress in professional fact checking .
We study learning from user feedback for extractive question answering by simulating feedback using supervised data .
We cast the problem as contextual bandit learning, and analyze the characteristics of several learning scenarios with focus on reducing data annotation .
We show that systems initially trained on few examples can dramatically improve given feedback from users on model-predicted answers, and that one can use existing datasets to deploy systems in new domains without any annotation effort, but instead improving the system on-the-fly via user feedback .
Despite recent improvements in open-domain dialogue models, state of the art models are trained and evaluated on short conversations with little context .
In contrast, the long-term conversation setting has hardly been studied .
In this work we collect and release a human-human dataset consisting of multiple chat sessions whereby the speaking partners learn about each other’s interests and discuss the things they have learnt from past sessions .
We show how existing models trained on existing datasets perform poorly in this long-term conversation setting in both automatic and human evaluations, and we study long-context models that can perform much better .
In particular, we find retrieval-augmented methods and methods with an ability to summarize and recall previous conversations outperform the standard encoder-decoder architectures currently considered state of the art .
Training a referring expression comprehension (ReC) model for a new visual domain requires collecting referring expressions, and potentially corresponding bounding boxes, for images in the domain .
While large-scale pre-trained models are useful for image classification across domains, it remains unclear if they can be applied in a zero-shot manner to more complex tasks like ReC .
We present ReCLIP, a simple but strong zero-shot baseline that repurposes CLIP, a state-of-the-art large-scale model, for ReC .
Motivated by the close connection between ReC and CLIP’s contrastive pre-training objective, the first component of ReCLIP is a region-scoring method that isolates object proposals via cropping and blurring, and passes them to CLIP .
However, through controlled experiments on a synthetic dataset, we find that CLIP is largely incapable of performing spatial reasoning off-the-shelf .
We reduce the gap between zero-shot baselines from prior work and supervised models by as much as 29% on RefCOCOg, and on RefGTA (video game imagery), ReCLIP’s relative improvement over supervised ReC models trained on real images is 8% .
We consider event extraction in a generative manner with template-based conditional generation.Although there is a rising trend of casting the task of event extraction as a sequence generation problem with prompts, these generation-based methods have two significant challenges, including using suboptimal prompts and static event type information.In this paper, we propose a generative template-based event extraction method with dynamic prefix (GTEE-DynPref) by integrating context information with type-specific prefixes to learn a context-specific prefix for each context.Experimental results show that our model achieves competitive results with the state-of-the-art classification-based model OneIE on ACE 2005 and achieves the best performances on ERE.Additionally, our model is proven to be portable to new types of events effectively .
Building huge and highly capable language models has been a trend in the past years .
Despite their great performance, they incur high computational cost .
A common solution is to apply model compression or choose light-weight architectures, which often need a separate fixed-size model for each desirable computational budget, and may lose performance in case of heavy compression .
This paper proposes an effective dynamic inference approach, called E-LANG, which distributes the inference between large accurate Super-models and light-weight Swift models .
To this end, a decision making module routes the inputs to Super or Swift models based on the energy characteristics of the representations in the latent space .
This method is easily adoptable and architecture agnostic .
As such, it can be applied to black-box pre-trained models without a need for architectural manipulations, reassembling of modules, or re-training .
Unlike existing methods that are only applicable to encoder-only backbones and classification tasks, our method also works for encoder-decoder structures and sequence-to-sequence tasks such as translation .
The E-LANG performance is verified through a set of experiments with T5 and BERT backbones on GLUE, SuperGLUE, and WMT .
In particular, we outperform T5-11B with an average computations speed-up of 3.3X on GLUE and 2.9X on SuperGLUE .
We also achieve BERT-based SOTA on GLUE with 3.2X less computations .
Code and demo are available in supplementary materials .
We introduce PRIMERA, a pre-trained model for multi-document representation with a focus on summarization that reduces the need for dataset-specific architectures and large amounts of fine-tuning labeled data .
PRIMERA uses our newly proposed pre-training objective designed to teach the model to connect and aggregate information across documents .
It also uses efficient encoder-decoder transformers to simplify the processing of concatenated input documents .
With extensive experiments on 6 multi-document summarization datasets from 3 different domains on zero-shot, few-shot and full-supervised settings, PRIMERA outperforms current state-of-the-art dataset-specific and pre-trained models on most of these settings with large margins .
Extracting informative arguments of events from news articles is a challenging problem in information extraction, which requires a global contextual understanding of each document .
While recent work on document-level extraction has gone beyond single-sentence and increased the cross-sentence inference capability of end-to-end models, they are still restricted by certain input sequence length constraints and usually ignore the global context between events .
To tackle this issue, we introduce a new global neural generation-based framework for document-level event argument extraction by constructing a document memory store to record the contextual event information and leveraging it to implicitly and explicitly help with decoding of arguments for later events .
Empirical results show that our framework outperforms prior methods substantially and it is more robust to adversarially annotated examples with our constrained decoding design .
There is a growing interest in the combined use of NLP and machine learning methods to predict gaze patterns during naturalistic reading .
While promising results have been obtained through the use of transformer-based language models, little work has been undertaken to relate the performance of such models to general text characteristics .
In this paper we report on experiments with two eye-tracking corpora of naturalistic reading and two language models (BERT and GPT-2) .
In all experiments, we test effects of a broad spectrum of features for predicting human reading behavior that fall into five categories (syntactic complexity, lexical richness, register-based multiword combinations, readability and psycholinguistic word properties) .
Our experiments show that both the features included and the architecture of the transformer-based language models play a role in predicting multiple eye-tracking measures during naturalistic reading .
We also report the results of experiments aimed at determining the relative importance of features from different groups using SP-LIME .
Recent work in multilingual machine translation (MMT) has focused on the potential of positive transfer between languages, particularly cases where higher-resourced languages can benefit lower-resourced ones .
While training an MMT model, the supervision signals learned from one language pair can be transferred to the other via the tokens shared by multiple source languages .
However, the transfer is inhibited when the token overlap among source languages is small, which manifests naturally when languages use different writing systems .
In this paper, we tackle inhibited transfer by augmenting the training data with alternative signals that unify different writing systems, such as phonetic, romanized, and transliterated input .
We test these signals on Indic and Turkic languages, two language families where the writing systems differ but languages still share common features .
Our results indicate that a straightforward multi-source self-ensemble – training a model on a mixture of various signals and ensembling the outputs of the same model fed with different signals during inference, outperforms strong ensemble baselines by 1.3 BLEU points on both language families .
Further, we find that incorporating alternative inputs via self-ensemble can be particularly effective when training set is small, leading to +5 BLEU when only 5% of the total training data is accessible .
Finally, our analysis demonstrates that including alternative signals yields more consistency and translates named entities more accurately, which is crucial for increased factuality of automated systems .
Multi-modal techniques offer significant untapped potential to unlock improved NLP technology for local languages .
However, many advances in language model pre-training are focused on text, a fact that only increases systematic inequalities in the performance of NLP tasks across the world’s languages .
In this work, we propose a multi-modal approach to train language models using whatever text and/or audio data might be available in a language .
Initial experiments using Swahili and Kinyarwanda data suggest the viability of the approach for downstream Named Entity Recognition (NER) tasks, with models pre-trained on phone data showing an improvement of up to 6% F1-score above models that are trained from scratch .
Preprocessing and training code will be uploaded to https://github.com/sil-ai/phone-it-in .
We introduce a noisy channel approach for language model prompting in few-shot text classification .
Instead of computing the likelihood of the label given the input (referred as direct models), channel models compute the conditional probability of the input given the label, and are thereby required to explain every word in the input .
We use channel models for recently proposed few-shot learning methods with no or very limited updates to the language model parameters, via either in-context demonstration or prompt tuning .
Our experiments show that, for both methods, channel models significantly outperform their direct counterparts, which we attribute to their stability, i.e., lower variance and higher worst-case accuracy .
We also present extensive ablations that provide recommendations for when to use channel prompt tuning instead of other competitive models (e.g., direct head tuning): channel prompt tuning is preferred when the number of training examples is small, labels in the training data are imbalanced, or generalization to unseen labels is required .
We show that unsupervised sequence-segmentation performance can be transferred to extremely low-resource languages by pre-training a Masked Segmental Language Model (Downey et al., 2021) multilingually .
Further, we show that this transfer can be achieved by training over a collection of low-resource languages that are typologically similar (but phylogenetically unrelated) to the target language .
In our experiments, we transfer from a collection of 10 Indigenous American languages (AmericasNLP, Mager et al., 2021) to K’iche’, a Mayan language .
We compare our multilingual model to a monolingual (from-scratch) baseline, as well as a model pre-trained on Quechua only .
We show that the multilingual pre-trained approach yields consistent segmentation quality across target dataset sizes, exceeding the monolingual baseline in 6/10 experimental settings .
Our model yields especially strong results at small target sizes, including a zero-shot performance of 20.6 F1 .
These results have promising implications for low-resource NLP pipelines involving human-like linguistic units, such as the sparse transcription framework proposed by Bird (2020) .
Pre-trained language models such as BERT have been successful at tackling many natural language processing tasks .
However, the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages .
Even given a morphological analyzer, naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compositionality and expressing word-relative syntactic regularities .
We address these challenges by proposing a simple yet effective two-tier BERT architecture that leverages a morphological analyzer and explicitly represents morphological compositionality.Despite the success of BERT, most of its evaluations have been conducted on high-resource languages, obscuring its applicability on low-resource languages .
We evaluate our proposed method on the low-resource morphologically rich Kinyarwanda language, naming the proposed model architecture KinyaBERT .
A robust set of experimental results reveal that KinyaBERT outperforms solid baselines by 2% in F1 score on a named entity recognition task and by 4.3% in average score of a machine-translated GLUE benchmark .
KinyaBERT fine-tuning has better convergence and achieves more robust results on multiple tasks even in the presence of translation noise .
A well-calibrated neural model produces confidence (probability outputs) closely approximated by the expected accuracy .
While prior studies have shown that mixup training as a data augmentation technique can improve model calibration on image classification tasks, little is known about using mixup for model calibration on natural language understanding (NLU) tasks .
In this paper, we explore mixup for model calibration on several NLU tasks and propose a novel mixup strategy for pre-trained language models that improves model calibration further .
Our proposed mixup is guided by both the Area Under the Margin (AUM) statistic (Pleiss et al., 2020) and the saliency map of each sample (Simonyan et al., 2013) .
Moreover, we combine our mixup strategy with model miscalibration correction techniques (i.e., label smoothing and temperature scaling) and provide detailed analyses of their impact on our proposed mixup .
We focus on systematically designing experiments on three NLU tasks: natural language inference, paraphrase detection, and commonsense reasoning .
Our method achieves the lowest expected calibration error compared to strong baselines on both in-domain and out-of-domain test samples while maintaining competitive accuracy .
Natural language inference (NLI) has been widely used as a task to train and evaluate models for language understanding .
However, the ability of NLI models to perform inferences requiring understanding of figurative language such as idioms and metaphors remains understudied .
We introduce the IMPLI (Idiomatic and Metaphoric Paired Language Inference) dataset, an English dataset consisting of paired sentences spanning idioms and metaphors .
We develop novel methods to generate 24k semiautomatic pairs as well as manually creating 1.8k gold pairs .
We use IMPLI to evaluate NLI models based on RoBERTa fine-tuned on the widely used MNLI dataset .
We then show that while they can reliably detect entailment relationship between figurative phrases with their literal counterparts, they perform poorly on similarly structured examples where pairs are designed to be non-entailing .
This suggests the limits of current NLI models with regard to understanding figurative language and this dataset serves as a benchmark for future improvements in this direction .
This paper introduces QAConv, a new question answering (QA) dataset that uses conversations as a knowledge source .
We focus on informative conversations, including business emails, panel discussions, and work channels .
Unlike open-domain and task-oriented dialogues, these conversations are usually long, complex, asynchronous, and involve strong domain knowledge .
In total, we collect 34,608 QA pairs from 10,259 selected conversations with both human-written and machine-generated questions .
We use a question generator and a dialogue summarizer as auxiliary tools to collect and recommend questions .
The dataset has two testing scenarios: chunk mode and full mode, depending on whether the grounded partial conversation is provided or retrieved .
Experimental results show that state-of-the-art pretrained QA systems have limited zero-shot performance and tend to predict our questions as unanswerable .
Our dataset provides a new training and evaluation testbed to facilitate QA on conversations research .
Knowledge bases (KBs) contain plenty of structured world and commonsense knowledge .
As such, they often complement distributional text-based information and facilitate various downstream tasks .
Since their manual construction is resource- and time-intensive, recent efforts have tried leveraging large pretrained language models (PLMs) to generate additional monolingual knowledge facts for KBs .
However, such methods have not been attempted for building and enriching multilingual KBs .
Besides wider application, such multilingual KBs can provide richer combined knowledge than monolingual (e.g., English) KBs .
Knowledge expressed in different languages may be complementary and unequally distributed: this implies that the knowledge available in high-resource languages can be transferred to low-resource ones .
To achieve this, it is crucial to represent multilingual knowledge in a shared/unified space .
To this end, we propose a unified representation model, Prix-LM, for multilingual KB construction and completion .
We leverage two types of knowledge, monolingual triples and cross-lingual links, extracted from existing multilingual KBs, and tune a multilingual language encoder XLM-R via a causal language modeling objective .
Prix-LM integrates useful multilingual and KB-based factual knowledge into a single model .
Experiments on standard entity-related tasks, such as link prediction in multiple languages, cross-lingual entity linking and bilingual lexicon induction, demonstrate its effectiveness, with gains reported over strong task-specialised baselines .
We introduce a data-driven approach to generating derivation trees from meaning representation graphs with probabilistic synchronous hyperedge replacement grammar (PSHRG) .
SHRG has been used to produce meaning representation graphs from texts and syntax trees, but little is known about its viability on the reverse .
In particular, we experiment on Dependency Minimal Recursion Semantics (DMRS) and adapt PSHRG as a formalism that approximates the semantic composition of DMRS graphs and simultaneously recovers the derivations that license the DMRS graphs .
Consistent results are obtained as evaluated on a collection of annotated corpora .
This work reveals the ability of PSHRG in formalizing a syntax–semantics interface, modelling compositional graph-to-tree translations, and channelling explainability to surface realization .
AI systems embodied in the physical world face a fundamental challenge of partial observability; operating with only a limited view and knowledge of the environment .
This creates challenges when AI systems try to reason about language and its relationship with the environment: objects referred to through language (e.g .
giving many instructions) are not immediately visible .
Actions by the AI system may be required to bring these objects in view .
A good benchmark to study this challenge is Dynamic Referring Expression Recognition (dRER) task, where the goal is to find a target location by dynamically adjusting the field of view (FoV) in a partially observed 360 scenes .
In this paper, we introduce HOLM, Hallucinating Objects with Language Models, to address the challenge of partial observability .
HOLM uses large pre-trained language models (LMs) to infer object hallucinations for the unobserved part of the environment .
Our core intuition is that if a pair of objects co-appear in an environment frequently, our usage of language should reflect this fact about the world .
Based on this intuition, we prompt language models to extract knowledge about object affinities which gives us a proxy for spatial relationships of objects .
Our experiments show that HOLM performs better than the state-of-the-art approaches on two datasets for dRER; allowing to study generalization for both indoor and outdoor settings .
Massively Multilingual Transformer based Language Models have been observed to be surprisingly effective on zero-shot transfer across languages, though the performance varies from language to language depending on the pivot language(s) used for fine-tuning .
In this work, we build upon some of the existing techniques for predicting the zero-shot performance on a task, by modeling it as a multi-task learning problem .
We jointly train predictive models for different tasks which helps us build more accurate predictors for tasks where we have test data in very few languages to measure the actual performance of the model .
Our approach also lends us the ability to perform a much more robust feature selection, and identify a common set of features that influence zero-shot performance across a variety of tasks .
Transformers are unable to model long-term memories effectively, since the amount of computation they need to perform grows with the context length .
While variations of efficient transformers have been proposed, they all have a finite memory capacity and are forced to drop old information .
In this paper, we propose the ∞-former, which extends the vanilla transformer with an unbounded long-term memory .
By making use of a continuous-space attention mechanism to attend over the long-term memory, the ∞-former’s attention complexity becomes independent of the context length, trading off memory length with precision.In order to control where precision is more important, ∞-former maintains “sticky memories,” being able to model arbitrarily long contexts while keeping the computation budget fixed.Experiments on a synthetic sorting task, language modeling, and document grounded dialogue generation demonstrate the ∞-former’s ability to retain information from long sequences .
Natural language processing (NLP) systems have become a central technology in communication, education, medicine, artificial intelligence, and many other domains of research and development .
    "URL": "https://doi.org/10.1145/3411764.3445172"
  },
  {
    "id": "10.1145/3411764.3445385",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jacobs",
        "given": "Maia"
      },
      {
        "family": "He",
        "given": "Jeffrey"
      },
      {
        "family": "F. Pradier",
        "given": "Melanie"
      },
      {
        "family": "Lam",
        "given": "Barbara"
      },
      {
        "family": "Ahn",
        "given": "Andrew C."
      },
      {
        "family": "McCoy",
        "given": "Thomas H."
      },
      {
        "family": "Perlis",
        "given": "Roy H."
      },
      {
        "family": "Doshi-Velez",
        "given": "Finale"
      },
      {
        "family": "Gajos",
        "given": "Krzysztof Z."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Major depressive disorder is a debilitating disease affecting 264 million people worldwide. While many antidepressant medications are available, few clinical guidelines support choosing among them. Decision support tools (DSTs) embodying machine learning models may help improve the treatment selection process, but often fail in clinical practice due to poor system integration. We use an iterative, co-design process to investigate clinicians\u2019 perceptions of using DSTs in antidepressant treatment decisions. We identify ways in which DSTs need to engage with the healthcare sociotechnical system, including clinical processes, patient preferences, resource constraints, and domain knowledge. Our results suggest that clinical DSTs should be designed as multi-user systems that support patient-provider collaboration and offer on-demand explanations that address discrepancies between predictions and current standards of care. Through this work, we demonstrate how current trends in explainable AI may be inappropriate for clinical environments and consider paths towards designing these tools for real-world medical systems.",
    "call-number": "10.1145/3411764.3445385",
    "collection-number": "659",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445385",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "major depressive disorder, decision support tools, healthcare",
    "number": "Article 659",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing AI for Trust and Collaboration in Time-Constrained Medical Decisions: A Sociotechnical Lens",
    "URL": "https://doi.org/10.1145/3411764.3445385"
  },
  {
    "id": "10.1145/3411764.3445120",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Seo",
        "given": "Woosuk"
      },
      {
        "family": "Buyuktur",
        "given": "Ayse G."
      },
      {
        "family": "Verma",
        "given": "Sanya"
      },
      {
        "family": "Kim",
        "given": "Hyeryoung"
      },
      {
        "family": "Choi",
        "given": "Sung Won"
      },
      {
        "family": "Sedig",
        "given": "Laura"
      },
      {
        "family": "Park",
        "given": "Sun Young"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Effective patient-provider communication is critical to promote patient satisfaction, encourage patient involvement in care, and improve health outcomes. Although prior HCI works aim to enhance the dyadic communication by improving patients\u2019 communication skills, little is known about healthcare providers\u2019 communication work to facilitate effective communication with their child patients. Through semi-structured interviews with 10 healthcare providers and clinic observations, our study identified four strategies that providers used in their communication with patients: building rapport, developing familiarity with care settings, respecting patients\u2019 communication modes and preferences, and delegating small decision-making and directing questions to patients. Based on these strategies, we discuss three key elements that providers value and work toward to achieve effective communication in pediatric care practice. Our study also uncovers the detailed process of how the providers develop their strategies to tailor their communication to the patients\u2019 specific needs and preferences, and we describe design opportunities for communication technology.",
    "call-number": "10.1145/3411764.3445120",
    "collection-number": "660",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445120",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "communication, child patients, pediatric care, healthcare provider",
    "number": "Article 660",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Learning from Healthcare Providers\u2019 Strategies: Designing Technology to Support Effective Child Patient-Provider Communication",
    "URL": "https://doi.org/10.1145/3411764.3445120"
  },
  {
    "id": "10.1145/3411764.3445663",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Akinsiku",
        "given": "Adegboyega"
      },
      {
        "family": "Avellino",
        "given": "Ignacio"
      },
      {
        "family": "Graham",
        "given": "Yasmin"
      },
      {
        "family": "Mentis",
        "given": "Helena M."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Telerehabilitation systems for stroke survivors have been predominantly designed to measure and quantify movement in order to guide and encourage rehabilitation regular exercises at home. We set out to study what aspect of the movement data was essential, to better inform sensor design. We investigated face-to-face stroke rehabilitation sessions through a series of interviews and observations involving 16 stroke rehabilitation specialists including physiatrists, physical therapists, and occupational therapists. We found that specialists are not solely interested in movement data, and that experiential information about stroke survivors\u2019 lived experience plays an essential role in specialists interpreting movement data and creating a rehabilitation plan. We argue for a reconceptualization in stroke telerehabilitation that is more inclusive of non-movement data, and present design implications to better account for experiential information in telerehabilitation systems.",
    "call-number": "10.1145/3411764.3445663",
    "collection-number": "661",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445663",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Therapy, Physical medicine and rehabilitation, Stroke, Telerehabilitation",
    "number": "Article 661",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "It\u2019s Not Just the Movement: Experiential Information Needed for Stroke Telerehabilitation",
    "URL": "https://doi.org/10.1145/3411764.3445663"
  },
  {
    "id": "10.1145/3411764.3445576",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gasques",
        "given": "Danilo"
      },
      {
        "family": "Johnson",
        "given": "Janet G."
      },
      {
        "family": "Sharkey",
        "given": "Tommy"
      },
      {
        "family": "Feng",
        "given": "Yuanyuan"
      },
      {
        "family": "Wang",
        "given": "Ru"
      },
      {
        "family": "Xu",
        "given": "Zhuoqun Robin"
      },
      {
        "family": "Zavala",
        "given": "Enrique"
      },
      {
        "family": "Zhang",
        "given": "Yifei"
      },
      {
        "family": "Xie",
        "given": "Wanze"
      },
      {
        "family": "Zhang",
        "given": "Xinming"
      },
      {
        "family": "Davis",
        "given": "Konrad"
      },
      {
        "family": "Yip",
        "given": "Michael"
      },
      {
        "family": "Weibel",
        "given": "Nadir"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Traumatic injuries require timely intervention, but medical expertise is not always available at the patient\u2019s location. Despite recent advances in telecommunications, surgeons still have limited tools to remotely help inexperienced surgeons. Mixed Reality hints at a future where remote collaborators work side-by-side as if co-located; however, we still do not know how current technology can improve remote surgical collaboration. Through role-playing and iterative-prototyping, we identify collaboration practices used by expert surgeons to aid novice surgeons as well as technical requirements to facilitate these practices. We then introduce ARTEMIS, an AR-VR collaboration system that supports these key practices. Through an observational study with two expert surgeons and five novice surgeons operating on cadavers, we find that ARTEMIS supports remote surgical mentoring of novices through synchronous point, draw, and look affordances and asynchronous video clips. Most participants found that ARTEMIS facilitates collaboration despite existing technology limitations explored in this paper.",
    "call-number": "10.1145/3411764.3445576",
    "collection-number": "662",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445576",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Telementoring, Augmented Reality, Surgery, Mixed Reality, Virtual Reality, Collaboration",
    "number": "Article 662",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ARTEMIS: A Collaborative Mixed-Reality System for Immersive Surgical Telementoring",
    "URL": "https://doi.org/10.1145/3411764.3445576"
  },
  {
    "id": "10.1145/3411764.3445692",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nisser",
        "given": "Martin"
      },
      {
        "family": "Liao",
        "given": "Christina Chen"
      },
      {
        "family": "Chai",
        "given": "Yuchen"
      },
      {
        "family": "Adhikari",
        "given": "Aradhana"
      },
      {
        "family": "Hodges",
        "given": "Steve"
      },
      {
        "family": "Mueller",
        "given": "Stefanie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "LaserFactory is an integrated fabrication process that augments a commercially available fabrication machine to support the manufacture of fully functioning devices without human intervention. In addition to creating 2D and 3D mechanical structures, LaserFactory creates conductive circuit traces with arbitrary geometries, picks-and-places electronic and electromechanical components, and solders them in place. To enable this functionality, we make four contributions. First, we build a hardware add-on to the laser cutter head that can deposit silver circuit traces and assemble components. Second, we develop a new method to cure dispensed silver using a CO2 laser. Third, we build a motion-based signaling method that allows our system to be readily integrated with commercial laser cutters. Finally, we provide a design and visualization tool for making functional devices with LaserFactory. Having described the LaserFactory system, we demonstrate how it is used to fabricate devices such as a fully functioning quadcopter and a sensor-equipped wristband. Our evaluation shows that LaserFactory can assemble a variety of differently sized components (up to 65g), that these can be connected by narrow traces (down to 0.75mm) that become highly conductive after laser soldering (3.2\u03a9/m), and that our acceleration-based sensing scheme works reliably (to 99.5% accuracy).",
    "call-number": "10.1145/3411764.3445692",
    "collection-number": "663",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445692",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "printed electronics, robotics, personal fabrication, Human-computer interaction, rapid prototyping",
    "number": "Article 663",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "LaserFactory: A Laser Cutter-based Electromechanical Assembly and Fabrication Platform to Make Functional Devices & Robots",
    "URL": "https://doi.org/10.1145/3411764.3445692"
  },
  {
    "id": "10.1145/3411764.3445345",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sethapakdi",
        "given": "Ticha"
      },
      {
        "family": "Anderson",
        "given": "Daniel"
      },
      {
        "family": "Sy",
        "given": "Adrian Reginald Chua"
      },
      {
        "family": "Mueller",
        "given": "Stefanie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Designers of machine-cut objects must often consider whether and how their design can be fabricated with their available materials. In contrast to tools that support preparing finished designs for fabrication, we investigate shortening the feedback loop between design creation and fabrication preparation. To this end, we present Fabricaide, a fabrication-aware tool that interleaves the processes of creating and preparing designs for fabrication. By providing live feedback on how parts should be placed onto material sheets, analyzing how much material is consumed, and alerting users when designs are infeasible, Fabricaide enables users to proactively tailor their design to their available material. Fabricaide achieves this with a custom packing algorithm that arranges parts onto material sheets at interactive speeds. Our qualitative user study shows how Fabricaide can support different workflows, encourage material-conscious design practices, and provide insights on how to further improve similar interfaces in the future.",
    "call-number": "10.1145/3411764.3445345",
    "collection-number": "664",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445345",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "personal fabrication, laser cutting",
    "number": "Article 664",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Fabricaide: Fabrication-Aware Design for 2D Cutting Machines",
    "URL": "https://doi.org/10.1145/3411764.3445345"
  },
  {
    "id": "10.1145/3411764.3445391",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wessely",
        "given": "Michael"
      },
      {
        "family": "Jin",
        "given": "Yuhua"
      },
      {
        "family": "Nuengsigkapian",
        "given": "Cattalyya"
      },
      {
        "family": "Kashapov",
        "given": "Aleksei"
      },
      {
        "family": "Qamar",
        "given": "Isabel P. S."
      },
      {
        "family": "Tsetserukou",
        "given": "Dzmitry"
      },
      {
        "family": "Mueller",
        "given": "Stefanie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "ChromoUpdate is a texture transfer system for fast design iteration. For the early stages of design, ChromoUpdate provides a fast grayscale preview that enables a texture to be transferred in under one minute. Once designers are satisfied with the grayscale texture, ChromoUpdate supports designers in coloring the texture by transitioning individual pixels directly to a desired target color. Finally, if designers need to make a change to the color texture already transferred, ChromoUpdate can quickly transition individual pixels from one color to a new target color. ChromoUpdate accomplishes this by (1)\u00a0using a UV projector rather than a UV LED, which enables pixels to be saturated individually rather than resetting the entire texture to black, and (2)\u00a0providing two new texture transfer algorithms that allow for fast grayscale previews and color-to-color transitions. Our evaluation shows a significant increase in texture transfer speed for both the grayscale preview (89%) and color-to-color updates (11%).",
    "call-number": "10.1145/3411764.3445391",
    "collection-number": "666",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445391",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "photochromic dyes., programmable textures, personal fabrication",
    "number": "Article 666",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ChromoUpdate: Fast Design Iteration of Photochromic Color Textures Using Grayscale Previews and Local Color Updates",
    "URL": "https://doi.org/10.1145/3411764.3445391"
  },
  {
    "id": "10.1145/3411764.3445422",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Strasnick",
        "given": "Evan"
      },
      {
        "family": "Agrawala",
        "given": "Maneesh"
      },
      {
        "family": "Follmer",
        "given": "Sean"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Simulation offers many advantages when designing analog circuits. Designers can explore alternatives quickly, without added cost or risk of hardware faults. However, it is challenging to use simulation as an aid during interactive debugging of physical circuits, due to difficulties in comparing simulated analyses with hardware measurements. Designers must continually configure simulations to match the state of the physical circuit (e.g. capturing sensor inputs), and must manually rework the hardware to replicate changes or analyses performed in simulation. We propose techniques leveraging instrumentation and programmable test hardware to create a tight coupling between a physical circuit and its simulated model. Bridging these representations helps designers to compare simulated and measured behaviors, and to quickly perform analytical techniques on hardware (e.g. parameter-response analysis) that are typically cumbersome outside of simulation. We implement these techniques in a prototype and show how it aids in efficiently debugging a variety of analog circuits.",
    "call-number": "10.1145/3411764.3445422",
    "collection-number": "667",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445422",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "debugging, PCB, simulation, analysis, testing, circuit",
    "number": "Article 667",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Coupling Simulation and Hardware for Interactive Circuit Debugging",
    "URL": "https://doi.org/10.1145/3411764.3445422"
  },
  {
    "id": "10.1145/3411764.3445780",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Luo",
        "given": "Yiyue"
      },
      {
        "family": "Wu",
        "given": "Kui"
      },
      {
        "family": "Palacios",
        "given": "Tom\u00e1s"
      },
      {
        "family": "Matusik",
        "given": "Wojciech"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "With the recent interest in wearable electronics and smart garments, digital fabrication of sensing and interactive textiles is in increasing demand. Recently, advances in digital machine knitting offer opportunities for the programmable, rapid fabrication of soft, breathable textiles. In this paper, we present KnitUI, a novel, accessible machine-knitted user interface based on resistive pressure sensing. Employing conductive yarns and various machine knitting techniques, we computationally design and automatically fabricate the double-layered resistive sensing structures as well as the coupled conductive connection traces with minimal manual post-processing. We present an interactive design interface for users to customize KnitUI\u2019s colors, sizes, positions, and shapes. After investigating design parameters for the optimized sensing and interactive performance, we demonstrate KnitUI as a portable, deformable, washable, and customizable interactive and sensing platform. It obtains diverse applications, including wearable user interfaces, tactile sensing wearables, and artificial robot skin.",
    "call-number": "10.1145/3411764.3445780",
    "collection-number": "668",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445780",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "stitch meshes, Machine knitting, smart textiles, wearable device",
    "number": "Article 668",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "KnitUI: Fabricating Interactive and Sensing Textiles with Machine Knitting",
    "URL": "https://doi.org/10.1145/3411764.3445780"
  },
  {
    "id": "10.1145/3411764.3445469",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hong",
        "given": "Freddie"
      },
      {
        "family": "Myant",
        "given": "Connor"
      },
      {
        "family": "Boyle",
        "given": "David E"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Fabricating 3D printed electronics using desktop printers has become more accessible with recent developments in conductive thermoplastic filaments. Because of their high resistance and difficulties in printing traces in vertical directions, most applications are restricted to capacitive sensing. In this paper, we introduce Thermoformed Circuit Board (TCB), a novel approach that employs the thermoformability of the 3D printed plastics to construct various double-sided, rigid and highly conductive freeform circuit boards that can withstand high current applications through copper electroplating. To illustrate the capability of the TCB, we showcase a range of examples with various shapes, electrical characteristics and interaction mechanisms. We also demonstrate a new design tool extension to an existing CAD environment that allows users to parametrically draw the substrate and conductive trace, and export 3D printable files. TCB is an inexpensive and highly accessible fabrication technique intended to broaden HCI researcher participation.",
    "call-number": "10.1145/3411764.3445469",
    "collection-number": "669",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445469",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "3D printed electronics, hybrid additive manufacturing, conductive filament",
    "number": "Article 669",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Thermoformed Circuit Boards: Fabrication of highly conductive freeform 3D printed circuit boards with heat bending",
    "URL": "https://doi.org/10.1145/3411764.3445469"
  },
  {
    "id": "10.1145/3411764.3445690",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chang",
        "given": "Ruei-Che"
      },
      {
        "family": "Wang",
        "given": "Wen-Ping"
      },
      {
        "family": "Chiang",
        "given": "Chi-Huan"
      },
      {
        "family": "Wu",
        "given": "Te-Yen"
      },
      {
        "family": "Xu",
        "given": "Zheer"
      },
      {
        "family": "Luo",
        "given": "Justin"
      },
      {
        "family": "Chen",
        "given": "Bing-Yu"
      },
      {
        "family": "Yang",
        "given": "Xing-Dong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "In this paper, we propose the designs for low cost and 3D-printable add-on components to adapt existing breadboards, circuit components and electronics tools for blind or low vision (BLV) users. Through an initial user study, we identified several barriers to entry for beginners with BLV in electronics and circuit prototyping. These barriers guided the design and development of our add-on components. We focused on developing adaptations that provide additional information about the specific component pins and breadboard holes, modify tools to make them easier to use for users with BLV, and expand non-visual feedback (e.g., audio, tactile) for tasks that require vision. Through a second user study, we demonstrated that our adaptations can effectively overcome the accessibility barriers in breadboard circuit prototyping for users with BLV.",
    "call-number": "10.1145/3411764.3445690",
    "collection-number": "670",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445690",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Education Tools, Tangible User Interfaces, Accessibility, Universal Design, Circuit Prototyping",
    "number": "Article 670",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AccessibleCircuits: Adaptive Add-On Circuit Components for People with Blindness or Low Vision",
    "URL": "https://doi.org/10.1145/3411764.3445690"
  },
  {
    "id": "10.1145/3411764.3445229",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ko",
        "given": "Donghyeon"
      },
      {
        "family": "Yim",
        "given": "Jee Bin"
      },
      {
        "family": "Lee",
        "given": "Yujin"
      },
      {
        "family": "Pyun",
        "given": "Jaehoon"
      },
      {
        "family": "Lee",
        "given": "Woohun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "In this paper, we present a metamaterial structure called thermoformable cells, TF-Cells, to enrich thermoforming for post-print modification. So far, thermoforming is limitedly applied for modifying a 3D printed object due to its low thermal conductivity. TF-Cells consists of beam arrays that affluently pass hot air and have high heat transference. Through heating the embedded TF-Cells of the printed object, users can modify not only the deeper area of the object surface but also its form factor. With a series of technical experiments, we investigated TF-Cells\u2019 thermoformability, depending on their structure\u2019s parameters, orientations, and heating conditions. Next, we present a series of compound cells consisting of TF-Cells and solid structure to adjust stiffness or reduce undesirable shape deformation. Adapting the results from the experiments, we built a simple tool for embedding TF-Cells into a 3D model. Using the tool, we implemented examples under contexts of mechanical fitting, ergonomic fitting, and aesthetic tuning.",
    "call-number": "10.1145/3411764.3445229",
    "collection-number": "671",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445229",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "fabrication, metamaterial, hands-on deformation, thermoforming, 3D printing",
    "number": "Article 671",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing Metamaterial Cells to Enrich Thermoforming 3D Printed Object for Post-Print Modification",
    "URL": "https://doi.org/10.1145/3411764.3445229"
  },
  {
    "id": "10.1145/3411764.3445453",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Roumen",
        "given": "Thijs"
      },
      {
        "family": "Kommana",
        "given": "Yannis"
      },
      {
        "family": "Apel",
        "given": "Ingo"
      },
      {
        "family": "Lempert",
        "given": "Conrad"
      },
      {
        "family": "Brand",
        "given": "Markus"
      },
      {
        "family": "Brendel",
        "given": "Erik"
      },
      {
        "family": "Seidel",
        "given": "Laurenz"
      },
      {
        "family": "Rambold",
        "given": "Lukas"
      },
      {
        "family": "Goedecken",
        "given": "Carl"
      },
      {
        "family": "Crenzin",
        "given": "Pascal"
      },
      {
        "family": "Hurdelhey",
        "given": "Ben"
      },
      {
        "family": "Abdullah",
        "given": "Muhammad"
      },
      {
        "family": "Baudisch",
        "given": "Patrick"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "We present Assembler3 a software tool that allows users to perform 3D parametric manipulations on 2D laser cutting plans. Assembler3 achieves this by semi-automatically converting 2D laser cutting plans to 3D, where users modify their models using available 3D tools (kyub), before converting them back to 2D. In our user study, this workflow allowed users to modify models 10x faster than using the traditional approach of editing 2D cutting plans directly. Assembler3 converts models to 3D in 5 steps: (1) plate detection, (2) joint detection, (3) material thickness detection, (4) joint matching based on hashed joint \"signatures\", and (5) interactive reconstruction. In our technical evaluation, Assembler3 was able to reconstruct 100 of 105 models. Once 3D-reconstructed, we expect users to store and share their models in 3D, which can simplify collaboration and thereby empower the laser cutting community to create models of higher complexity.",
    "call-number": "10.1145/3411764.3445453",
    "collection-number": "672",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445453",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "reuse, laser cutting, remixing, personal fabrication",
    "number": "Article 672",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Assembler3: 3D Reconstruction of Laser-Cut Models",
    "URL": "https://doi.org/10.1145/3411764.3445453"
  },
  {
    "id": "10.1145/3411764.3445466",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Abdullah",
        "given": "Muhammad"
      },
      {
        "family": "Taraz",
        "given": "Martin"
      },
      {
        "family": "Kommana",
        "given": "Yannis"
      },
      {
        "family": "Katakura",
        "given": "Shohei"
      },
      {
        "family": "Kovacs",
        "given": "Robert"
      },
      {
        "family": "Shigeyama",
        "given": "Jotaro"
      },
      {
        "family": "Roumen",
        "given": "Thijs"
      },
      {
        "family": "Baudisch",
        "given": "Patrick"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "We present fastForce, a software tool that detects structural flaws in laser cut 3D models and fixes them by introducing additional plates into the model, thereby making models up to 52x stronger. By focusing on a specific type of structural issue, i.e., poorly connected sub-structures in closed box structures, fastForce achieves real-time performance (106x faster than finite element analysis, in the specific case of the wheelbarrow from Figure 1). This allows fastForce to fix structural issues continuously in the background, while users stay focused on editing their models and without ever becoming aware of any structural issues.In our study, six of seven participants inadvertently introduced severe structural flaws into the guitar stands they designed. Similarly, we found 286 of 402 relevant models in the kyub [1] model library to contain such flaws. We integrated fastForce into a 3D editor for lasercutting (kyub) and found that even with high plate counts fastForce achieves real-time performance.",
    "call-number": "10.1145/3411764.3445466",
    "collection-number": "673",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445466",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "lasercutting, structural reinforcement, Personal fabrication, structural analysis",
    "number": "Article 673",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FastForce: Real-Time Reinforcement of Laser-Cut Structures",
    "URL": "https://doi.org/10.1145/3411764.3445466"
  },
  {
    "id": "10.1145/3411764.3445666",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Signer",
        "given": "Madlaina"
      },
      {
        "family": "Ion",
        "given": "Alexandra"
      },
      {
        "family": "Sorkine-Hornung",
        "given": "Olga"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "We propose a novel design of engineered, structured materials that leverages fast fabrication technologies, pushing them towards mass-fabrication. Specifically, our metamaterial is designed to be laser cut, to approximate the volumetric shape and allow for locally varying compliance. Traditional mechanical metamaterials consist of intricate cells arranged on a 3-dimensional grid, limiting them to 3D\u00a0printing\u2014which is slow. Our metamaterial is designed for laser cutting, which is drastically faster. Our structures are best described as ruffled strips of thin sheet material, such as paper, plastics, metals, etc. Users can interactively define the ruffles\u2019 anisotropic stiffness directions and local density. Our computational design tool assists users by automatically optimizing the ruffle to fill the shape\u2019s volume, and exporting the flat ruffle design ready for cutting. We demonstrate how such ruffled metamaterials can be utilized for, e.g., custom toys with locally varying compliance, custom packaging material, or lightweight formwork for architectural shells.",
    "call-number": "10.1145/3411764.3445666",
    "collection-number": "674",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445666",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Fabrication, Laser cutting, Shape modeling, Computational design, Developable surfaces, Metamaterials",
    "number": "Article 674",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Developable Metamaterials: Mass-fabricable Metamaterials by Laser-Cutting Elastic Structures",
    "URL": "https://doi.org/10.1145/3411764.3445666"
  },
  {
    "id": "10.1145/3411764.3445334",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Obiorah",
        "given": "Mmachi God'sglory"
      },
      {
        "family": "Hammerman",
        "given": "James K. L."
      },
      {
        "family": "Rother",
        "given": "Becky"
      },
      {
        "family": "Granger",
        "given": "Will"
      },
      {
        "family": "West",
        "given": "Haley Margaret"
      },
      {
        "family": "Horn",
        "given": "Michael"
      },
      {
        "family": "Trouille",
        "given": "Laura"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Scientists have long sought to engage public audiences in research through citizen science projects such as biological surveys or distributed data collection. Recent online platforms have expanded the scope of what people-powered research can mean. Science museums are unique cultural institutions that translate scientific discovery for public audiences, while conducting research of their own. This makes museums compelling sites for engaging audiences directly in scientific research, but there are associated challenges as well. This project engages public audiences in contributing to real research as part of their visit to a museum. We present the design and evaluation of U!Scientist, an interactive multi-person tabletop exhibit based on the online Zooniverse project, Galaxy Zoo. We installed U!Scientist in a planetarium and collected video, computer logs, naturalistic observations, and surveys with visitors. Our findings demonstrate the potential of exhibits to engage new audiences in collaborative scientific discussions as part of people-powered research.",
    "call-number": "10.1145/3411764.3445334",
    "collection-number": "675",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445334",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "museums, Citizen science, interactive tabletop displays",
    "number": "Article 675",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "U!Scientist: Designing for People-Powered Research in Museums",
    "URL": "https://doi.org/10.1145/3411764.3445334"
  },
  {
    "id": "10.1145/3411764.3445490",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bu",
        "given": "Yaohua"
      },
      {
        "family": "Ma",
        "given": "Tianyi"
      },
      {
        "family": "Li",
        "given": "Weijun"
      },
      {
        "family": "Zhou",
        "given": "Hang"
      },
      {
        "family": "Jia",
        "given": "Jia"
      },
      {
        "family": "Chen",
        "given": "Shengqi"
      },
      {
        "family": "Xu",
        "given": "Kaiyuan"
      },
      {
        "family": "Shi",
        "given": "Dachuan"
      },
      {
        "family": "Wu",
        "given": "Haozhe"
      },
      {
        "family": "Yang",
        "given": "Zhihan"
      },
      {
        "family": "Li",
        "given": "Kun"
      },
      {
        "family": "Wu",
        "given": "Zhiyong"
      },
      {
        "family": "Shi",
        "given": "Yuanchun"
      },
      {
        "family": "Lu",
        "given": "Xiaobo"
      },
      {
        "family": "Liu",
        "given": "Ziwei"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Second language (L2) English learners often find it difficult to improve their pronunciations due to the lack of expressive and personalized corrective feedback. In this paper, we present Pronunciation Teacher\u00a0(PTeacher), a Computer-Aided Pronunciation Training (CAPT) system that provides personalized exaggerated audio-visual corrective feedback for mispronunciations. Though the effectiveness of exaggerated feedback has been demonstrated, it is still unclear how to define the appropriate degrees of exaggeration when interacting with individual learners. To fill in this gap, we interview 100 L2 English learners and 22 professional native teachers to understand their needs and experiences. Three critical metrics are proposed for both learners and teachers to identify the best exaggeration levels in both audio and visual modalities. Additionally, we incorporate the personalized dynamic feedback mechanism given the English proficiency of learners. Based on the obtained insights, a comprehensive interactive pronunciation training course is designed to help L2 learners rectify mispronunciations in a more perceptible, understandable, and discriminative manner. Extensive user studies demonstrate that our system significantly promotes the learners\u2019 learning efficiency.",
    "call-number": "10.1145/3411764.3445490",
    "collection-number": "676",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445490",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Audio-Visual Corrective Feedback, Exaggerated feedback, Computer-Aided Pronunciation Training System, Language Learning",
    "number": "Article 676",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PTeacher: a Computer-Aided Personalized Pronunciation Training System with Exaggerated Audio-Visual Corrective Feedback",
    "URL": "https://doi.org/10.1145/3411764.3445490"
  },
  {
    "id": "10.1145/3411764.3445554",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Shang"
      },
      {
        "family": "Walker",
        "given": "Erin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Previous research has demonstrated the benefits of applying comparative strategies while learning from informational texts, where students identify key concepts and then attempt to establish relationships between those concepts. Concept mapping is one activity that can prompt students to use comparative strategies, but not all students benefit from this activity without support. This work presents an intelligent tutoring system for concept mapping that facilitates the development of comparative strategies through diagnostic feedback that responds to the quality of students\u2019 concept mapping process and map correctness. The novelty of the system lies in the combination of outcome-based feedback methods typical in concept mapping with adaptive process-based evaluation. In a lab study with 46 college students, we evaluate the effect of this combined adaptive support compared to solely process-based support and no support. Results suggested that the combined feedback approach showed promise at improving students\u2019 use of comparative strategies and learning outcomes.",
    "call-number": "10.1145/3411764.3445554",
    "collection-number": "677",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445554",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "reading comprehension, intelligent learning environments, concept mapping, comparative strategies",
    "number": "Article 677",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Providing Adaptive Feedback in Concept Mapping to Improve Reading Comprehension",
    "URL": "https://doi.org/10.1145/3411764.3445554"
  },
  {
    "id": "10.1145/3411764.3445226",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ali",
        "given": "Safinah"
      },
      {
        "family": "DiPaola",
        "given": "Daniella"
      },
      {
        "family": "Lee",
        "given": "Irene"
      },
      {
        "family": "Hong",
        "given": "Jenna"
      },
      {
        "family": "Breazeal",
        "given": "Cynthia"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Applications of generative models such as Generative Adversarial Networks (GANs) have made their way to social media platforms that children frequently interact with. While GANs are associated with ethical implications pertaining to children, such as the generation of Deepfakes, there are negligible efforts to educate middle school children about generative AI. In this work, we present a generative models learning trajectory (LT), educational materials, and interactive activities for young learners with a focus on GANs, creation and application of machine-generated media, and its ethical implications. The activities were deployed in four online workshops with 72 students (grades 5-9). We found that these materials enabled children to gain an understanding of what generative models are, their technical components and potential applications, and benefits and harms, while reflecting on their ethical implications. Learning from our findings, we propose an improved learning trajectory for complex socio-technical systems.",
    "call-number": "10.1145/3411764.3445226",
    "collection-number": "678",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445226",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Generative Adversarial Networks, Generative Machine Learning, Artificial Intelligence, AI Education",
    "number": "Article 678",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Generative Models with Middle School Students",
    "URL": "https://doi.org/10.1145/3411764.3445226"
  },
  {
    "id": "10.1145/3411764.3445190",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Reza",
        "given": "Mohi"
      },
      {
        "family": "Yoon",
        "given": "Dongwook"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Shadowing, i.e., listening to recorded native speech and simultaneously vocalizing the words, is a popular language-learning technique that is known to improve listening skills. However, despite strong evidence for its efficacy as a listening exercise, existing shadowing systems do not adequately support listening-focused practice, especially in self-regulated learning environments with no external feedback. To bridge this gap, we introduce Computer-Assisted Shadowing Trainer (CAST), a shadowing system that makes self-regulation easy and effective through four novel design elements \u2014 (i) in-the-moment highlights for tracking and visualizing progress, (ii) contextual blurring for inducing self-reflection on misheard words, (iii) self-listening comparators for post-practice self-evaluation, and (iv) adjustable pause-handles for self-paced practice. We base CAST on a formative user study (N=15) that provides fresh empirical grounds on the needs and challenges of shadowers. We validate our design through a summative evaluation (N=12) that shows learners can successfully self-regulate their shadowing practice with CAST while retaining focus on listening.",
    "call-number": "10.1145/3411764.3445190",
    "collection-number": "679",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445190",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "multimedia learning, audio and speech interfaces, self-regulated learning, computer-assisted language learning, speech shadowing",
    "number": "Article 679",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing CAST: A Computer-Assisted Shadowing Trainer for Self-Regulated Foreign Language Listening Practice",
    "URL": "https://doi.org/10.1145/3411764.3445190"
  },
  {
    "id": "10.1145/3411764.3445809",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bosch",
        "given": "Nigel"
      },
      {
        "family": "Zhang",
        "given": "Yingbin"
      },
      {
        "family": "Paquette",
        "given": "Luc"
      },
      {
        "family": "Baker",
        "given": "Ryan"
      },
      {
        "family": "Ocumpaugh",
        "given": "Jaclyn"
      },
      {
        "family": "Biswas",
        "given": "Gautam"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Students in computerized learning environments often direct their own learning processes, which requires metacognitive awareness of what should be learned next. We investigated a novel method of measuring verbalized metacognition by applying natural language processing (NLP) to transcripts of interviews conducted in a classroom with 99 middle school students who were using a computerized learning environment. We iteratively adapted the NLP method for the linguistic characteristics of these interviews, then applied it to study three research questions regarding the relationships between verbalized metacognition and measures of 1) learning, 2) confusion, and 3) metacognitive problem-solving strategies. Verbalized metacognition was not directly related to learning, but was related to confusion and metacognitive problem-solving strategies. Results also suggested that interviews themselves may improve learning by encouraging metacognition. We discuss implications for designing computerized environments that support self-regulated learning through metacognition.",
    "call-number": "10.1145/3411764.3445809",
    "collection-number": "680",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445809",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Affect, Confusion, Metacognition, Self-regulated learning",
    "number": "Article 680",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Students\u2019 Verbalized Metacognition During Computerized Learning",
    "URL": "https://doi.org/10.1145/3411764.3445809"
  },
  {
    "id": "10.1145/3411764.3445424",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hsu",
        "given": "Silas"
      },
      {
        "family": "Li",
        "given": "Tiffany Wenting"
      },
      {
        "family": "Zhang",
        "given": "Zhilin"
      },
      {
        "family": "Fowler",
        "given": "Max"
      },
      {
        "family": "Zilles",
        "given": "Craig"
      },
      {
        "family": "Karahalios",
        "given": "Karrie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Deployment of AI assessment tools in education is widespread, but work on students\u2019 interactions and attitudes towards imperfect autograders is comparatively lacking. This paper presents students\u2019 perceptions surrounding a \u223c 90% accurate automated short-answer grader that determined homework and exam credit in a college-level computer science course. Using surveys and interviews, we investigated students\u2019 knowledge about the autograder and their attitudes. We observed that misalignment between folk theories about how the autograder worked and how it actually worked could lead to suboptimal answer construction strategies. Students overestimated the autograder\u2019s probability of marking correct answers as wrong, and estimates of this probability were associated with dissatisfaction and perceptions of unfairness. Many participants expressed a need for additional instruction on how to cater to the autograder. From these findings, we propose guidelines for incorporating imperfect short answer autograders into classroom in a manner that is considerate of students\u2019 needs.",
    "call-number": "10.1145/3411764.3445424",
    "collection-number": "681",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445424",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "code reading, autograder, folk theories, human-AI interaction, imperfect AI, EiPE, perception and acceptance of AI, ASAG, computer science education",
    "number": "Article 681",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Attitudes Surrounding an Imperfect AI Autograder",
    "URL": "https://doi.org/10.1145/3411764.3445424"
  },
  {
    "id": "10.1145/3411764.3445294",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Haotian"
      },
      {
        "family": "Xu",
        "given": "Min"
      },
      {
        "family": "Wang",
        "given": "Yong"
      },
      {
        "family": "Wei",
        "given": "Huan"
      },
      {
        "family": "Qu",
        "given": "Huamin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Online exams have become widely used to evaluate students\u2019 performance in mastering knowledge in recent years, especially during the pandemic of COVID-19. However, it is challenging to conduct proctoring for online exams due to the lack of face-to-face interaction. Also, prior research has shown that online exams are more vulnerable to various cheating behaviors, which can damage their credibility. This paper presents a novel visual analytics approach to facilitate the proctoring of online exams by analyzing the exam video records and mouse movement data of each student. Specifically, we detect and visualize suspected head and mouse movements of students in three levels of detail, which provides course instructors and teachers with convenient, efficient and reliable proctoring for online exams. Our extensive evaluations, including usage scenarios, a carefully-designed user study and expert interviews, demonstrate the effectiveness and usability of our approach.",
    "call-number": "10.1145/3411764.3445294",
    "collection-number": "682",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445294",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Online proctoring, visual analytics, mouse movement, head pose estimation",
    "number": "Article 682",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Visual Analytics Approach to Facilitate the Proctoring of Online Exams",
    "URL": "https://doi.org/10.1145/3411764.3445294"
  },
  {
    "id": "10.1145/3411764.3445781",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wambsganss",
        "given": "Thiemo"
      },
      {
        "family": "Kueng",
        "given": "Tobias"
      },
      {
        "family": "Soellner",
        "given": "Matthias"
      },
      {
        "family": "Leimeister",
        "given": "Jan Marco"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Techniques from Natural-Language-Processing offer the opportunities to design new dialog-based forms of human-computer interaction as well as to analyze the argumentation quality of texts. This can be leveraged to provide students with adaptive tutoring when doing a persuasive writing exercise. To test if individual tutoring for students\u2019 argumentation will help them to write more convincing texts, we developed ArgueTutor, a conversational agent that tutors students with adaptive argumentation feedback in their learning journey. We compared ArgueTutor with 55 students to a traditional writing tool. We found students using ArgueTutor wrote more convincing texts with a better quality of argumentation compared to the ones using the alternative approach. The measured level of enjoyment and ease of use provides promising results to use our tool in traditional learning settings. Our results indicate that dialog-based learning applications combined with NLP text feedback have a beneficial use to foster better writing skills of students.",
    "call-number": "10.1145/3411764.3445781",
    "collection-number": "683",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445781",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "adaptive learning, educational applications, pedagogical conversational agents, argumentation learning",
    "number": "Article 683",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ArgueTutor: An Adaptive Dialog-Based Learning System for Argumentation Skills",
    "URL": "https://doi.org/10.1145/3411764.3445781"
  },
  {
    "id": "10.1145/3411764.3445144",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Odili Uchidiuno",
        "given": "Judith"
      },
      {
        "family": "Hammer",
        "given": "Jessica"
      },
      {
        "family": "Koedinger",
        "given": "Ken"
      },
      {
        "family": "Ogan",
        "given": "Amy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Adaptive Collaborative Learning Support (ACLS) systems improve collaboration and learning for students over individual work or collaboration with non-adaptive support. However, many ACLS systems are ill-suited for rural contexts where students often need multiple kinds of support to complete tasks, may speak languages unsupported by the system, and require more than pre-assigned tutor-tutee student pairs for more equitable learning. We designed an intervention that fosters more equitable help-seeking by automatically detecting student struggles and prompts them to seek help from specific peers that can help. We conducted a mixed-methods experimental study with 98 K-3 students in a rural village in Tanzania over a one-month period, evaluating how the system affects student interactions, system engagement, and student learning. Our intervention increased student interactions by almost 4 times compared to the control condition, increased domain knowledge interactions, and propelled students to engage in more cognitively challenging activities.",
    "call-number": "10.1145/3411764.3445144",
    "collection-number": "684",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445144",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "number": "Article 684",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Fostering Equitable Help-Seeking for K-3 Students in Low Income and Rural Contexts",
    "URL": "https://doi.org/10.1145/3411764.3445144"
  },
  {
    "id": "10.1145/3411764.3445204",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ghaiumy Anaraky",
        "given": "Reza"
      },
      {
        "family": "Byrne",
        "given": "Kaileigh Angela"
      },
      {
        "family": "Wisniewski",
        "given": "Pamela J."
      },
      {
        "family": "Page",
        "given": "Xinru"
      },
      {
        "family": "Knijnenburg",
        "given": "Bart"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "To understand the underlying process of users\u2019 information disclosure decisions, scholars often use either the privacy calculus framework or refer to heuristic shortcuts. It is unclear whether the decision process varies by age. Therefore, using these common frameworks, we conducted a web-based experiment with 94 participants, who were younger (ages 19-22) or older (65+) adults, to understand how perceived app trust, sensitivity of the data, and benefits of disclosure influence users disclosure decisions. Younger adults were more likely to change their perception of data sensitivity based on trust, while older adults were more likely to disclose information based on perceived benefits of disclosure. These results suggest older adults made more rationally calculated decisions than younger adults, who made heuristic decisions based on app trust. Our findings negate the mainstream narrative that older adults are less privacy-conscious than younger adults; instead, older adults weigh the benefits and risks of information disclosure.",
    "call-number": "10.1145/3411764.3445204",
    "collection-number": "686",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445204",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "affect heuristics, Information privacy, young adults, older adults, privacy calculus",
    "number": "Article 686",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "To Disclose or Not to Disclose: Examining the Privacy Decision-Making Processes of Older vs. Younger Adults",
    "URL": "https://doi.org/10.1145/3411764.3445204"
  },
  {
    "id": "10.1145/3411764.3445333",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sun",
        "given": "Kaiwen"
      },
      {
        "family": "Sugatan",
        "given": "Carlo"
      },
      {
        "family": "Afnan",
        "given": "Tanisha"
      },
      {
        "family": "Simon",
        "given": "Hayley"
      },
      {
        "family": "Gelman",
        "given": "Susan A."
      },
      {
        "family": "Radesky",
        "given": "Jenny"
      },
      {
        "family": "Schaub",
        "given": "Florian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "As children become frequent digital technology users, concerns about their digital privacy are increasing. To better understand how young children conceptualize data processing and digital privacy risks, we interviewed 26 children, 4 to 10 years old, from families with higher educational attainment recruited in a college town. Our child participants construed apps\u2019 and services\u2019 data collection and storage practices in terms of their benefits, both to themselves and for user safety, and characterized both data tracking and privacy violations as interpersonal rather than considering automated processes or companies as privacy threats. We identify four factors shaping these mental models and privacy risk perceptions: (1) surface-level visual cues, (2) past digital interactions involving data collection, (3) age and cognitive development, and (4) privacy-related experiences in non-digital contexts. We discuss our findings\u2019 design, educational, and public policy implications toward better supporting children in identifying and reasoning about digital privacy risks.",
    "call-number": "10.1145/3411764.3445333",
    "collection-number": "687",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445333",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Data Processing., Children, Digital Privacy",
    "number": "Article 687",
    "number-of-pages": "34",
    "page": "1\u201334",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cThey See You\u2019re a Girl if You Pick a Pink Robot with a Skirt\u201d: A Qualitative Study of How Children Conceptualize Data Processing and Digital Privacy Risks",
    "URL": "https://doi.org/10.1145/3411764.3445333"
  },
  {
    "id": "10.1145/3411764.3445224",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Maqsood",
        "given": "Sana"
      },
      {
        "family": "Chiasson",
        "given": "Sonia"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Teachers play a key role in educating children about digital security and privacy. They are often at the forefront, witnessing incidents, dealing with the consequences, and helping children handle the technology-related risks. However, little is reported about teachers\u2019 lived classroom experiences and their challenges in this regard. We conducted semi-structured interviews with 21 Canadian elementary school teachers to understand the risks teachers witness children aged 10\u201313 facing on digital media, teachers\u2019 mitigation strategies, and how prepared teachers are to help children. Our results show that teachers regularly help children deal with digital risks outside of teaching official curriculum, ranging from minor privacy violations to severe cases of cyberbullying. Most issues reported by teachers were the result of typical behaviours which became risky because they took place over digital media. We use the results to highlight implications for how elementary schools address digital security and privacy.",
    "call-number": "10.1145/3411764.3445224",
    "collection-number": "688",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445224",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "teachers, children, security and privacy risks, digital literacy",
    "number": "Article 688",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cThey think it\u2019s totally fine to talk to somebody on the internet they don\u2019t know\u201d: Teachers\u2019 perceptions and mitigation strategies of tweens\u2019 online risks",
    "URL": "https://doi.org/10.1145/3411764.3445224"
  },
  {
    "id": "10.1145/3411764.3445105",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Doolani",
        "given": "Jayesh"
      },
      {
        "family": "Wright",
        "given": "Matthew"
      },
      {
        "family": "Setty",
        "given": "Rajesh"
      },
      {
        "family": "Haque",
        "given": "S M Taiabul"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "In this work, we design and evaluate LociMotion, a training interface to learn a strong authentication secret in a single session. LociMotion automatically takes a random password with twelve lowercase letters (56-bit entropy) to generate the training interface. It first leverages users\u2019 spatial and visual (declarative) memory by showing them a video clip based on the method of loci, and then consolidates the learning process by having them play a computer game that leverages their motor (procedural) memory. The results of a memorability study with 300 participants showed that LociMotion had a significantly higher recall success rate than a control condition. A second study with 200 participants demonstrated the effectiveness of LociMotion over a period of time (99%, 96%, and 81% recall success rates after 1, 4, and 18 days, respectively). LociMotion offers an alternative to the spaced repetition technique, as it does not require dozens of training sessions.",
    "call-number": "10.1145/3411764.3445105",
    "collection-number": "689",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445105",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "system-assigned passwords, Authentication, usable security, memorability",
    "number": "Article 689",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "LociMotion: Towards Learning a Strong Authentication Secret in a Single Session",
    "URL": "https://doi.org/10.1145/3411764.3445105"
  },
  {
    "id": "10.1145/3411764.3445386",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Koushki",
        "given": "Masoud Mehrabi"
      },
      {
        "family": "Obada-Obieh",
        "given": "Borke"
      },
      {
        "family": "Huh",
        "given": "Jun Ho"
      },
      {
        "family": "Beznosov",
        "given": "Konstantin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Implicit authentication (IA) has recently become a popular approach for providing physical security on smartphones. It relies on behavioral traits (e.g., gait patterns) for user identification, instead of biometric data or knowledge of a PIN. However, it is not yet known whether users can understand the semantics of this technology well enough to use it properly. We bridge this knowledge gap by evaluating how Android\u2019s Smart Lock (SL), which is the first widely deployed IA solution on smartphones, is understood by its users. We conducted a qualitative user study (N=26) and an online survey (N=331). The results suggest that users often have difficulty understanding SL semantics, leaving them unable to judge when their phone would be (un)locked. We found that various aspects of SL, such as its capabilities and its authentication factors, are confusing for the users. We also found that depth of smartphone adoption is a significant antecedent of SL comprehension.",
    "call-number": "10.1145/3411764.3445386",
    "collection-number": "690",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445386",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Smartphone Unlocking, Implicit Authentication, Mental Models, Smart Lock, Active Authentication",
    "number": "Article 690",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "On Smartphone Users\u2019 Difficulty with Understanding Implicit Authentication",
    "URL": "https://doi.org/10.1145/3411764.3445386"
  },
  {
    "id": "10.1145/3411764.3445616",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tahaei",
        "given": "Mohammad"
      },
      {
        "family": "Vaniea",
        "given": "Kami"
      },
      {
        "family": "Beznosov",
        "given": "Konstantin (Kosta)"
      },
      {
        "family": "Wolters",
        "given": "Maria K"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Static analysis tools (SATs) have the potential to assist developers in finding and fixing vulnerabilities in the early stages of software development, requiring them to be able to understand and act on tools\u2019 notifications. To understand how helpful such SAT guidance is to developers, we ran an online experiment (N=132) where participants were shown four vulnerable code samples (SQL injection, hard-coded credentials, encryption, and logging sensitive data) along with SAT guidance, and asked to indicate the appropriate fix. Participants had a positive attitude towards both SAT notifications and particularly liked the example solutions and vulnerable code. Seeing SAT notifications also led to more detailed open-ended answers and slightly improved code correction answers. Still, most SAT (SpotBugs 67%, SonarQube 86%) and Control (96%) participants answered at least one code-correction question incorrectly. Prior software development experience, perceived vulnerability severity, and answer confidence all positively impacted answer accuracy.",
    "call-number": "10.1145/3411764.3445616",
    "collection-number": "691",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445616",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "security notifications, usable security, static analysis tools, software developers",
    "number": "Article 691",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Security Notifications in Static Analysis Tools: Developers\u2019 Attitudes, Comprehension, and Ability to Act on Them",
    "URL": "https://doi.org/10.1145/3411764.3445616"
  },
  {
    "id": "10.1145/3411764.3445679",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Abramova",
        "given": "Svetlana"
      },
      {
        "family": "Voskobojnikov",
        "given": "Artemij"
      },
      {
        "family": "Beznosov",
        "given": "Konstantin"
      },
      {
        "family": "B\u00f6hme",
        "given": "Rainer"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Crypto-assets are unique in tying financial wealth to the secrecy of private keys. Prior empirical work has attempted to study end-user security from both technical and organizational perspectives. However, the link between individuals\u2019 risk perceptions and security behavior was often obscured by the heterogeneity of the subjects in small samples. This paper contributes quantitative results from a survey of 395 crypto-asset users recruited by a novel combination of deep and broad sampling. The analysis accounts for heterogeneity with a new typology that partitions the sample in three robust clusters \u2013 cypherpunks, hodlers, and rookies \u2013 using five psychometric constructs. The constructs originate from established behavioral theories with items purposefully adapted to the domain. We demonstrate the utility of this typology in better understanding users\u2019 characteristics and security behaviors. These insights inform the design of crypto-asset solutions, guide risk communication, and suggest directions for future digital currencies.",
    "call-number": "10.1145/3411764.3445679",
    "collection-number": "692",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445679",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "security, cluster analysis, user behavior, Crypto-asset",
    "number": "Article 692",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Bits Under the Mattress: Understanding Different Risk Perceptions and Security Behaviors of Crypto-Asset Users",
    "URL": "https://doi.org/10.1145/3411764.3445679"
  },
  {
    "id": "10.1145/3411764.3445768",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tahaei",
        "given": "Mohammad"
      },
      {
        "family": "Frik",
        "given": "Alisa"
      },
      {
        "family": "Vaniea",
        "given": "Kami"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Software development teams are responsible for making and implementing software design decisions that directly impact end-user privacy, a challenging task to do well. Privacy Champions\u2014people who strongly care about advocating privacy\u2014play a useful role in supporting privacy-respecting development cultures. To understand their motivations, challenges, and strategies for protecting end-user privacy, we conducted 12 interviews with Privacy Champions in software development teams. We find that common barriers to implementing privacy in software design include: negative privacy culture, internal prioritisation tensions, limited tool support, unclear evaluation metrics, and technical complexity. To promote privacy, Privacy Champions regularly use informal discussions, management support, communication among stakeholders, and documentation and guidelines. They perceive code reviews and practical training as more instructive than general privacy awareness and on-boarding training. Our study is a first step towards understanding how Privacy Champions work to improve their organisation\u2019s privacy approaches and improve the privacy of end-user products.",
    "call-number": "10.1145/3411764.3445768",
    "collection-number": "693",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445768",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "software development, privacy champions, user privacy",
    "number": "Article 693",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Privacy Champions in Software Teams: Understanding\u00a0Their\u00a0Motivations,\u00a0Strategies,\u00a0and\u00a0Challenges",
    "URL": "https://doi.org/10.1145/3411764.3445768"
  },
  {
    "id": "10.1145/3411764.3445164",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fassl",
        "given": "Matthias"
      },
      {
        "family": "Gr\u00f6ber",
        "given": "Lea Theresa"
      },
      {
        "family": "Krombholz",
        "given": "Katharina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Security technology often follows a systems design approach that focuses on components instead of users. As a result, the users\u2019 needs and values are not sufficiently addressed, which has implications on security usability. In this paper, we report our lessons learned from applying a user-centered security design process to a well-understood security usability challenge, namely key authentication in secure instant messaging. Users rarely perform these key authentication ceremonies, which makes their end-to-end encrypted communication vulnerable. Our approach includes collaborative design workshops, an expert evaluation, iterative storyboard prototyping, and an online evaluation. While we could not demonstrate that our design approach resulted in improved usability or user experience, we found that user-centered prototypes can increase the users\u2019 comprehension of security implications. Hence, prototypes based on users\u2019 intuitions, needs, and values are useful starting points for approaching long-standing security challenges. Applying complementary design approaches may improve usability and user experience further.",
    "call-number": "10.1145/3411764.3445164",
    "collection-number": "694",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445164",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Authentication, Usability, Man-in-the-Middle (MitM), Instant Messaging, User-Centered Design",
    "number": "Article 694",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring User-Centered Security Design for Usable Authentication Ceremonies",
    "URL": "https://doi.org/10.1145/3411764.3445164"
  },
  {
    "id": "10.1145/3411764.3445574",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Althobaiti",
        "given": "Kholoud"
      },
      {
        "family": "Meng",
        "given": "Nicole"
      },
      {
        "family": "Vaniea",
        "given": "Kami"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Judging the safety of a URL is something that even security experts struggle to do accurately without additional information. In this work, we aim to make experts\u2019 tools accessible to non-experts and assist general users in judging the safety of URLs by providing them with a usable report based on the information professionals use. We designed the report by iterating with 8 focus groups made up of end users, HCI experts, and security experts to ensure that the report was usable as well as accurately interpreted the information. We also conducted an online evaluation with 153 participants to compare different report-length options. We find that the longer comprehensive report allows users to accurately judge URL safety (93% accurate) and that summaries still provide benefit (83% accurate) compared to domain highlighting (65% accurate).",
    "call-number": "10.1145/3411764.3445574",
    "collection-number": "695",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445574",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "real-time learning, phishing awareness, Phishing, decision support, security education, URL reading, usable privacy and security",
    "number": "Article 695",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "I Don\u2019t Need an Expert! Making URL Phishing Features Human Comprehensible",
    "URL": "https://doi.org/10.1145/3411764.3445574"
  },
  {
    "id": "10.1145/3411764.3446862",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gr\u00f6ber",
        "given": "Lea Theresa"
      },
      {
        "family": "Fassl",
        "given": "Matthias"
      },
      {
        "family": "Gupta",
        "given": "Abhilash"
      },
      {
        "family": "Krombholz",
        "given": "Katharina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Modern cars include a vast array of computer systems designed to remove the burden on drivers and enhance safety. As cars are evolving towards autonomy and taking over control, e.g. in the form of autopilots, it becomes harder for drivers to pinpoint the root causes of a car\u2019s malfunctioning. Drivers may need additional information to assess these ambiguous situations correctly. However, it is yet unclear which information is relevant and helpful to drivers in such situations. Hence, we conducted a mixed-methods online survey (N = 60) on Amazon MTurk where we exposed participants to two security- and safety-critical situations with one of three different explanations. We applied Thematic and Correspondence Analysis to understand which factors in these situations moderate drivers\u2019 information demand. We identified a fundamental information demand across scenarios that is expanded by error-specific information types. Moreover, we found that it is necessary to communicate error sources, since drivers might not be able to identify them correctly otherwise. Thereby, malicious intrusions are typically perceived as more critical than technical malfunctions.",
    "call-number": "10.1145/3411764.3446862",
    "collection-number": "696",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3446862",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "modern cars, intelligibility",
    "number": "Article 696",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Car Drivers\u2019 Information Demand after Safety and Security Critical Incidents",
    "URL": "https://doi.org/10.1145/3411764.3446862"
  },
  {
    "id": "10.1145/3411764.3445432",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Dakuo"
      },
      {
        "family": "Wang",
        "given": "Liuping"
      },
      {
        "family": "Zhang",
        "given": "Zhan"
      },
      {
        "family": "Wang",
        "given": "Ding"
      },
      {
        "family": "Zhu",
        "given": "Haiyi"
      },
      {
        "family": "Gao",
        "given": "Yvonne"
      },
      {
        "family": "Fan",
        "given": "Xiangmin"
      },
      {
        "family": "Tian",
        "given": "Feng"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Artificial intelligence (AI) technology has been increasingly used in the implementation of advanced Clinical Decision Support Systems (CDSS). Research demonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical decision making scenarios. However, post-adoption user perception and experience remain understudied, especially in developing countries. Through observations and interviews with 22 clinicians from 6 rural clinics in China, this paper reports the various tensions between the design of an AI-CDSS system (\u201cBrilliant Doctor\u201d) and the rural clinical context, such as the misalignment with local context and workflow, the technical limitations and usability barriers, as well as issues related to transparency and trustworthiness of AI-CDSS. Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as \u201ca doctor\u2019s AI assistant\u201d to realize a Human-AI Collaboration future in clinical settings. Finally we draw on our findings to discuss implications for designing AI-CDSS interventions for rural clinical contexts in developing countries.",
    "call-number": "10.1145/3411764.3445432",
    "collection-number": "697",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445432",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Implementation, Collaborative AI, Human AI Collaboration, Human AI Interaction, China, Trust AI, Developing Country, Clinical Decision Making, Rural Clinic, CDSS, Workflow, Decision Making, AI, Future of Work, Healthcare, AI Deployment",
    "number": "Article 697",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cBrilliant AI Doctor\u201d in Rural Clinics: Challenges in AI-Powered Clinical Decision Support System Deployment",
    "URL": "https://doi.org/10.1145/3411764.3445432"
  },
  {
    "id": "10.1145/3411764.3445418",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "O'Leary",
        "given": "Teresa K."
      },
      {
        "family": "Stowell",
        "given": "Elizabeth"
      },
      {
        "family": "Hoffman",
        "given": "Jessica A."
      },
      {
        "family": "Paasche-Orlow",
        "given": "Michael"
      },
      {
        "family": "Bickmore",
        "given": "Timothy"
      },
      {
        "family": "Parker",
        "given": "Andrea G."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Churches have historically played an important role in Black American communities, catalyzing the pursuit of aims such as social justice, community organization, and health promotion. However, researchers have rarely examined how technology can support an assets-based approach to these efforts, nor the implications of race, traditions, and history when creating such systems. Addressing this gap, we conducted research with two predominantly Black churches to explore health promotion design opportunities. We used photovoice, a research method where participants led their own data collection and analysis. Participants provided nuanced descriptions of the racial and ethnic identities of their communities, and how church history and aspirations for the future impacted these identities. Our findings characterize tensions between tradition and \u2018modernization,\u2019 implications for technology design, and the need for a temporal approach to understanding communities. We conclude with broader implications for studying the intersection of race and religion in community technology design.",
    "call-number": "10.1145/3411764.3445418",
    "collection-number": "698",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445418",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "religion, Community HCI, assets-based approach, race, technospiritual practices, photovoice, HCI",
    "number": "Article 698",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Examining the Intersections of Race, Religion & Community Technologies: A Photovoice Study",
    "URL": "https://doi.org/10.1145/3411764.3445418"
  },
  {
    "id": "10.1145/3411764.3445261",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Michelle Seng Ah"
      },
      {
        "family": "Singh",
        "given": "Jat"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "With the surge in literature focusing on the assessment and mitigation of unfair outcomes in algorithms, several open source \u2018fairness toolkits\u2019 recently emerged to make such methods widely accessible. However, little studied are the differences in approach and capabilities of existing fairness toolkits, and their fit-for-purpose in commercial contexts. Towards this, this paper identifies the gaps between the existing open source fairness toolkit capabilities and the industry practitioners\u2019 needs. Specifically, we undertake a comparative assessment of the strengths and weaknesses of six prominent open source fairness toolkits, and investigate the current landscape and gaps in fairness toolkits through an exploratory focus group, a semi-structured interview, and an anonymous survey of data science/machine learning (ML) practitioners. We identify several gaps between the toolkits\u2019 capabilities and practitioner needs, highlighting areas requiring attention and future directions towards tooling that better support \u2018fairness in practice.\u2019",
    "call-number": "10.1145/3411764.3445261",
    "collection-number": "699",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445261",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "fairness, bias, algorithm auditing, fairness toolkits, bias detection, bias mitigation, algorithmic fairness, open source toolkits",
    "number": "Article 699",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Landscape and Gaps in Open Source Fairness Toolkits",
    "URL": "https://doi.org/10.1145/3411764.3445261"
  },
  {
    "id": "10.1145/3411764.3445630",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Batool",
        "given": "Amna"
      },
      {
        "family": "Toyama",
        "given": "Kentaro"
      },
      {
        "family": "Veinot",
        "given": "Tiffany"
      },
      {
        "family": "Fatima",
        "given": "Beenish"
      },
      {
        "family": "Naseem",
        "given": "Mustafa"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Front-line workers in global development are often responsible for data collection and record-keeping about their own work. The authenticity of such data and the role of mid-level supervisors, however, remains understudied. We report on the case of immunization in Pakistan, where, through interviews with 30 mid-level vaccination managers in Punjab district, we find that data falsification by vaccinators is common, though not necessarily rampant. Because of an intricate protocol for record-keeping, supervisors can detect data falsification, and we find they have devised an array of methods, broadly classifiable into four types: triangulation, supplementary data collection, anomaly detection, and interrogation. We also find that the strategies that supervisors use to detect falsification seem linked to their style of management, with authoritarian supervisors preferring supplementary data collection and spot checks, while supportive supervisors use triangulation. Our findings lead to recommendations for designing technologies intended to monitor and manage front-line data.",
    "call-number": "10.1145/3411764.3445630",
    "collection-number": "700",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445630",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Healthcare, Technology, Mid-level Managers, Supervisors, Data Falsification, Developing Countries, Immunization, Front-line Workers, Supportive Supervision",
    "number": "Article 700",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Detecting Data Falsification by Front-line Development Workers: A Case Study of Vaccination in Pakistan",
    "URL": "https://doi.org/10.1145/3411764.3445630"
  },
  {
    "id": "10.1145/3411764.3445420",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Okolo",
        "given": "Chinasa T."
      },
      {
        "family": "Kamath",
        "given": "Srujana"
      },
      {
        "family": "Dell",
        "given": "Nicola"
      },
      {
        "family": "Vashistha",
        "given": "Aditya"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Recent advances in Artificial Intelligence (AI) suggest that AI applications could transform healthcare delivery in the Global South. However, as researchers and technology companies rush to develop AI applications that aid the health of marginalized communities, it is critical to consider the needs and perceptions of the community health workers (CHWs) who will have to integrate these AI applications into the essential healthcare services they provide to rural communities. We describe a qualitative study examining CHWs\u2019 perceptions of an AI application for automated disease diagnosis. Drawing on data from 21 interviews with CHWs in rural India, we characterize (1) CHWs\u2019 knowledge, perceptions, and understandings of AI; and (2) the benefits and challenges that CHWs anticipate as AI applications are integrated into their workflows, including their opinions on automation of their work, possible misdiagnosis and errors, data access and surveillance issues, security and privacy challenges, and questions concerning trust. We conclude by discussing the implications of our work for HCI and AI research in low-resource environments.",
    "call-number": "10.1145/3411764.3445420",
    "collection-number": "701",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445420",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Artificial Intelligence, AI, mHealth, ICTD, HCI4D, Community health worker, CHW",
    "number": "Article 701",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt cannot do all of my work\u201d: Community Health Worker Perceptions of AI-Enabled Mobile Health Applications in Rural India",
    "URL": "https://doi.org/10.1145/3411764.3445420"
  },
  {
    "id": "10.1145/3411764.3445489",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Park",
        "given": "Joonyoung"
      },
      {
        "family": "Lee",
        "given": "Hyunsoo"
      },
      {
        "family": "Park",
        "given": "Sangkeun"
      },
      {
        "family": "Chung",
        "given": "Kyong-Mee"
      },
      {
        "family": "Lee",
        "given": "Uichin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "User-driven intervention tools such as self-tracking help users to self-regulate problematic smartphone usage. These tools basically assume active user engagement, but prior studies warned a lack of user engagement over time. This paper proposes GoldenTime, a mobile app that promotes self-regulated usage behavior via system-driven proactive timeboxing and micro-financial incentives framed as gain or loss for behavioral reinforcement. We conducted a large-scale user study (n = 210) to explore how our proactive timeboxing and micro-financial incentives influence users\u2019 smartphone usage behaviors. Our findings show that GoldenTime\u2019s timeboxing based micro-financial incentives are effective in self-regulating smartphone usage, and incentive framing has a significant impact on user behavior. We provide practical design guidelines for persuasive technology design related to promoting digital wellbeing.",
    "call-number": "10.1145/3411764.3445489",
    "collection-number": "702",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445489",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Smartphone Intervention, Self-regulation, Digital Wellbeing, Financial incentive, Timeboxing",
    "number": "Article 702",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "GoldenTime: Exploring System-Driven Timeboxing and Micro-Financial Incentives for Self-Regulated Phone Use",
    "URL": "https://doi.org/10.1145/3411764.3445489"
  },
  {
    "id": "10.1145/3411764.3445619",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Oyebode",
        "given": "Oladapo"
      },
      {
        "family": "Ndulue",
        "given": "Chinenye"
      },
      {
        "family": "Mulchandani",
        "given": "Dinesh"
      },
      {
        "family": "A. Zamil Adib",
        "given": "Ashfaq"
      },
      {
        "family": "Alhasani",
        "given": "Mona"
      },
      {
        "family": "Orji",
        "given": "Rita"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Persuasive systems (PS) are effective at motivating behaviour change using various persuasive strategies. Research shows that tailoring these systems increases their effectiveness. However, there is little knowledge on how PS can be tailored to people's Stages of Change (SoC). We conduct a large-scale study of 568 participants to investigate how individuals at different SoC respond to various strategies. We also explore why the strategies motivate behaviour change using the ARCS motivation model. Our results show that people's SoC plays a significant role in the perceived persuasiveness of different strategies and that the strategies motivate for different reasons. For instance, people at the precontemplation stage tend to be strongly motivated by self-monitoring strategy because it raises their consciousness or self-awareness. Our work is the first to link research on the theory of SoC with the theory of motivation and Persuasive Systems Design (PSD) model to develop practical guidelines to inform the tailoring of persuasive systems.",
    "call-number": "10.1145/3411764.3445619",
    "collection-number": "703",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445619",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Motivation, Behaviour change theory, Personalization, Behaviour change, Persuasive strategies, Design implications, Behaviour change system, Stage of change, Persuasive system, Health and Wellness, Risky health behaviour, Tailoring",
    "number": "Article 703",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Tailoring Persuasive and Behaviour Change Systems Based on Stages of Change and Motivation",
    "URL": "https://doi.org/10.1145/3411764.3445619"
  },
  {
    "id": "10.1145/3411764.3445332",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Charmaraman",
        "given": "Linda"
      },
      {
        "family": "Grevet Delcourt",
        "given": "Catherine"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Many 10-14 year olds are at the early stages of using social media, habits they develop on popular platforms can have lasting effects on their socio-emotional wellbeing. We led a remote innovation workshop with 23 middle schoolers on digital wellbeing, identity exploration, and computational concepts related to social computing. This workshop was a unique opportunity to reflect on emergent habits, discuss them with peers, and imagine oneself as an ICT innovator. Resulting themes related to participants\u2019 social wellbeing online included a) sense of belonging to communities of interest, friends, and family, b) self-care and social support strategies involving managing risks, control, and empathy, and c) experimentation while building self-confidence and bravely exploring audience reactions. Participants iteratively designed and tested a sandbox social network website, resulting in Social Sketch. Reflecting on our study, we describe the process for conceptualizing Social Sketch, and challenges in social media innovation with teenagers.",
    "call-number": "10.1145/3411764.3445332",
    "collection-number": "704",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445332",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "teenagers, ICT, social media, prototyping, wellness, adolescence, cooperative inquiry, wellbeing",
    "number": "Article 704",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Prototyping for Social Wellbeing with Early Social Media Users: Belonging, Experimentation, and Self-Care",
    "URL": "https://doi.org/10.1145/3411764.3445332"
  },
  {
    "id": "10.1145/3411764.3445141",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Johnson",
        "given": "Britney"
      },
      {
        "family": "Rydal Shapiro",
        "given": "Ben"
      },
      {
        "family": "DiSalvo",
        "given": "Betsy"
      },
      {
        "family": "Rothschild",
        "given": "Annabel"
      },
      {
        "family": "DiSalvo",
        "given": "Carl"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "In this paper, we describe and analyze a workshop developed for a work training program called DataWorks. In this workshop, data workers chose a topic of their interest, sourced and processed data on that topic, and used that data to create presentations. Drawing from discourses of data literacy; epistemic agency and lived experience; and critical race theory, we analyze the workshops\u2019 activities and outcomes. Through this analysis, three themes emerge: the tensions between epistemic agency and the context of work, encountering the ordinariness of racism through data work, and understanding the personal as communal and intersectional. Finally, critical race theory also prompts us to consider the very notions of data literacy that undergird our workshop activities. From this analysis, we offer a series of suggestions for approaching designing data literacy activities, taking into account critical race theory.",
    "call-number": "10.1145/3411764.3445141",
    "collection-number": "706",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445141",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "number": "Article 706",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Approaches to Data Literacy Through a Critical Race Theory Perspective",
    "URL": "https://doi.org/10.1145/3411764.3445141"
  },
  {
    "id": "10.1145/3411764.3445154",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sultana",
        "given": "Sharifa"
      },
      {
        "family": "Deb",
        "given": "Mitrasree"
      },
      {
        "family": "Bhattacharjee",
        "given": "Ananya"
      },
      {
        "family": "Hasan",
        "given": "Shaid"
      },
      {
        "family": "Alam",
        "given": "S.M.Raihanul"
      },
      {
        "family": "Chakraborty",
        "given": "Trishna"
      },
      {
        "family": "Roy",
        "given": "Prianka"
      },
      {
        "family": "Ahmed",
        "given": "Samira Fairuz"
      },
      {
        "family": "Moitra",
        "given": "Aparna"
      },
      {
        "family": "Amin",
        "given": "M Ashraful"
      },
      {
        "family": "Islam",
        "given": "A.K.M. Najmul"
      },
      {
        "family": "Ahmed",
        "given": "Syed Ishtiaque"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Women in the global south often seek justice to their online harassment through unveiling the harassers and the screenshots of their sent harassment texts and visual contents before the relevant authorities. Nevertheless, such evidence is often challenged for their authenticity. Our survey (n=91) and interview (n=43) with Bangladeshi online gender harassment victims revealed the depth of the problem, and we set design goals to collect evidence from Facebook Messenger with ensured authenticity. Building on the \u2018shame-based model\u2019 of gender justice [12], we designed \u2018Unmochon\u2019, a tool that captures authentic evidence and shares with victims\u2019 intended group. Our user-study (n=48) revealed that diminishing authenticity problem may still leave the victim and online gender justice entangled with mob-sentiment, hegemonic legal consciousness, and several privacy aspects. Our findings open up a new discussion on how HCI-design should address online gender justice in such a complex social setting.",
    "call-number": "10.1145/3411764.3445154",
    "collection-number": "707",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445154",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Solidarity, Shame, Social Media, Online Sexual Harassment, Messenger, Image Authenticity, Feminism, Facebook, Unmochon, Transformative Justice, Bangladesh",
    "number": "Article 707",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u2018Unmochon\u2019: A Tool to Combat Online Sexual Harassment over Facebook Messenger",
    "URL": "https://doi.org/10.1145/3411764.3445154"
  },
  {
    "id": "10.1145/3411764.3445611",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bellini",
        "given": "Rosanna"
      },
      {
        "family": "Wilson",
        "given": "Alexander"
      },
      {
        "family": "David Smeddinck",
        "given": "Jan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "There is growing evidence that digital peer-support networks can have a positive influence on behaviour change and wellbeing outcomes for people who harm themselves and others. However, making and sustaining such networks are subject to ethical and pragmatic challenges, particularly for perpetrators of domestic violence whom pose unique risks when brought together. In this work we report on a ten-month study where we worked with six support workers and eighteen perpetrators in the design and deployment of Fragments of the Past; a socio-material system that connects audio messages with tangible artefacts. We share how crafting digitally-augmented artefacts - \u2018fragments\u2019 - of experiences of desisting from violence can translate messages for motivation and rapport between peers, without subjecting the process to risks inherent with direct inter-personal communication. These insights provide the basis for practical considerations for future network design with challenging populations.",
    "call-number": "10.1145/3411764.3445611",
    "collection-number": "708",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445611",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Social Care, Domestic Violence, Intimate Partner Violence, Violence Prevention, Peer Support Networks, Digital Civics",
    "number": "Article 708",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Fragments of the Past: Curating Peer Support with Perpetrators of Domestic Violence",
    "URL": "https://doi.org/10.1145/3411764.3445611"
  },
  {
    "id": "10.1145/3411764.3445464",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Reichherzer",
        "given": "Carolin"
      },
      {
        "family": "Cunningham",
        "given": "Andrew"
      },
      {
        "family": "Coleman",
        "given": "Tracey"
      },
      {
        "family": "Cao",
        "given": "Ruochen"
      },
      {
        "family": "McManus",
        "given": "Kurt"
      },
      {
        "family": "Sheppard",
        "given": "Dion"
      },
      {
        "family": "Kohler",
        "given": "Mark"
      },
      {
        "family": "Billinghurst",
        "given": "Mark"
      },
      {
        "family": "Thomas",
        "given": "Bruce H"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "This paper investigates the use of immersive virtual reconstructions as an aid for jurors during a courtroom trial. The findings of a between-participant user study on memory and decision-making are presented in the context of viewing a simulated hit-run-death scenario. Participants listened to the opening statement of a prosecutor and a defence attorney before viewing the crime scene in Virtual Reality (VR) or as still images. We compare the effects on cognition and usability of using VR over images presented on a screen. We found several significant improvements, including that VR led to more consistent decision-making among participants. This shows that VR could provide a promising solution for the court to present crime scenes when site visitations are not possible.",
    "call-number": "10.1145/3411764.3445464",
    "collection-number": "709",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445464",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "3D Reconstruction, crime scene, Virtual Reality, jury, interactive virtual environment, spatial memory",
    "number": "Article 709",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Bringing the Jury to the Scene of the Crime: Memory and Decision-Making in a Simulated Crime Scene",
    "URL": "https://doi.org/10.1145/3411764.3445464"
  },
  {
    "id": "10.1145/3411764.3445694",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rahman",
        "given": "Rifat"
      },
      {
        "family": "Rahman",
        "given": "Md. Rishadur"
      },
      {
        "family": "Tripto",
        "given": "Nafis Irtiza"
      },
      {
        "family": "Ali",
        "given": "Mohammed Eunus"
      },
      {
        "family": "Apon",
        "given": "Sajid Hasan"
      },
      {
        "family": "Shahriyar",
        "given": "Rifat"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Traditional face-to-face health consultation-based systems largely failed to attract teenagers to get reproductive and sexual health supports from doctors and practitioners in Bangladesh as \u2018sex\u2019 or \u2018adolescent\u2019 related issues are considered social taboos and are rarely discussed openly with anyone. This has damaging implications for the physiological and mental well-being of a large group of people. In this paper, we study chatbot\u2019s effectiveness to assist adolescents in seeking reproductive and sexual health supports by analyzing the responses from 256 participants, including adolescents and medical personnel from six different regions of Bangladesh. We prototype an interactive chatbot, namely AdolescentBot, and analyzed users\u2019 communication patterns, feelings, and contexts of use as the first point of support for getting adolescence related health advice. Our analysis finds that a chatbot can satisfy most of the users\u2019 queries, and the majority of the queries are associated with wrong-beliefs. Finally, we discuss ethical and societal issues with chatbot usage and recommend a set of design propositions for the AdolescentBot.",
    "call-number": "10.1145/3411764.3445694",
    "collection-number": "710",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445694",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Chatbot, HCI4D, Adolescent health, Bangladesh",
    "number": "Article 710",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AdolescentBot: Understanding Opportunities for Chatbots in Combating Adolescent Sexual and Reproductive Health Problems in Bangladesh",
    "URL": "https://doi.org/10.1145/3411764.3445694"
  },
  {
    "id": "10.1145/3411764.3445542",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Esterwood",
        "given": "Connor"
      },
      {
        "family": "Essenmacher",
        "given": "Kyle"
      },
      {
        "family": "Yang",
        "given": "Han"
      },
      {
        "family": "Zeng",
        "given": "Fanpan"
      },
      {
        "family": "Robert",
        "given": "Lionel Peter"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Human personality has been identified as a predictor of robot acceptance in the human\u2013robot interaction (HRI) literature. Despite this, the HRI literature has provided mixed support for this assertion. To better understand the relationship between human personality and robot acceptance, this paper conducts a meta-analysis of 26 studies. Results found a positive relationship between human personality and robot acceptance. However, this relationship varied greatly by the specific personality trait along with the study sample\u2019s age, gender diversity, task, and global region. This meta-analysis also identified gaps in the literature. Namely, additional studies are needed that investigate both the big five personality traits and other personality traits, examine a more diverse age range, and utilize samples from previously unexamined regions of the globe.",
    "call-number": "10.1145/3411764.3445542",
    "collection-number": "711",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445542",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Robot Acceptance, Trust, Personality, Individual Differences, Social Presence, Enjoyment, Adaptability, Human-Robot Interaction, Sociability, Anxiety, HRI, Meta-Analysis",
    "number": "Article 711",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Meta-Analysis of Human Personality and Robot Acceptance in Human-Robot Interaction",
    "URL": "https://doi.org/10.1145/3411764.3445542"
  },
  {
    "id": "10.1145/3411764.3445270",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hwang",
        "given": "Angel Hsing-Chi"
      },
      {
        "family": "Won",
        "given": "Andrea Stevenson"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "The present study investigates how human subjects collaborate with a computer-mediated chatbot in creative idea generation tasks. In three text-based between-group studies, we tested whether the perceived identity (i.e., whether a partner was believed to be a bot or as a human) or conversational style (human or robotic) of a teammate would moderate the outcomes of participants\u2019 creative production. In Study 1, participants worked with either a chatbot or a human confederate. In Study 2, all participants worked with a human teammate but were informed that their partner was either a human or a chatbot. Conversely, all participants worked with a chatbot in Study 3, but their partner was described as either a chatbot or a human. We investigated differences in idea generation outcomes and found that participants consistently contributed more ideas and ideas of higher quality when they perceived their teamworking partner to be a bot. Furthermore, when the conversational style of the partner was robotic, participants with high anxiety in group communication reported greater creative self-efficacy in task performance. Finally, whether the perceived dominance of a partner and the pressure to come up with ideas during the task mediated positive outcomes of idea generation depended on whether the conversational style of the bot partner was robot- or human-like. Based on our findings, we discussed implications for future design of artificial agents as active team players in collaboration tasks.",
    "call-number": "10.1145/3411764.3445270",
    "collection-number": "712",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445270",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "creativity, teamworking, idea generation, chatbot, social facilitation",
    "number": "Article 712",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "IdeaBot: Investigating Social Facilitation in Human-Machine Team Creativity",
    "URL": "https://doi.org/10.1145/3411764.3445270"
  },
  {
    "id": "10.1145/3411764.3445366",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lam",
        "given": "Kevin C."
      },
      {
        "family": "Gutwin",
        "given": "Carl"
      },
      {
        "family": "Klarkowski",
        "given": "Madison"
      },
      {
        "family": "Cockburn",
        "given": "Andy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Input mechanisms can produce noisy signals that computers must interpret, and this interpretation can misconstrue the user\u2019s intention. Researchers have studied how interpretation errors can affect users\u2019 task performance, but little is known about how these errors affect learning, and whether they help or hinder the transition to expertise. Previous findings suggest that increasing the user\u2019s attention can facilitate learning, so frequent interpretation errors may increase attention and learning; alternatively, however, interpretation errors may negatively interfere with skill development. To explore these potentially important effects, we conducted studies where participants learned commands with various rates of artificially injected interpretation errors. Our results showed that higher rates of interpretation error led to worse memory retention, higher completion times, higher occurrences of user error (beyond those injected by the system), and greater perceived effort. These findings indicate that when input mechanisms must interpret the user\u2019s input, interpretation errors cause problems for user learning.",
    "call-number": "10.1145/3411764.3445366",
    "collection-number": "713",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445366",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "input techniques, expertise development, memory-based retrieval",
    "number": "Article 713",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Effects of System Interpretation Errors on Learning New Input Mechanisms",
    "URL": "https://doi.org/10.1145/3411764.3445366"
  },
  {
    "id": "10.1145/3411764.3445725",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Roy",
        "given": "Quentin"
      },
      {
        "family": "Berlioux",
        "given": "S\u00e9bastien"
      },
      {
        "family": "Casiez",
        "given": "G\u00e9ry"
      },
      {
        "family": "Vogel",
        "given": "Daniel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Suggesting words to complete a given sequence of characters is a common feature of typing interfaces. Yet, previous studies have not found a clear benefit, some even finding it detrimental. We report on the first study to control for two important factors, word suggestion accuracy and typing efficiency. Our accuracy factor is enabled by a new methodology that builds on standard metrics of word suggestions. Typing efficiency is based on device type. Results show word suggestions are used less often in a desktop condition, with little difference between tablet and phone conditions. Very accurate suggestions do not improve entry speed on desktop, but do on tablet and phone. Based on our findings, we discuss implications for the design of automation features in typing systems.",
    "call-number": "10.1145/3411764.3445725",
    "collection-number": "714",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445725",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "text-entry, word prediction",
    "number": "Article 714",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Typing Efficiency and Suggestion Accuracy Influence the Benefits and Adoption of Word Suggestions",
    "URL": "https://doi.org/10.1145/3411764.3445725"
  },
  {
    "id": "10.1145/3411764.3445284",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Minha"
      },
      {
        "family": "Ruijten",
        "given": "Peter"
      },
      {
        "family": "Frank",
        "given": "Lily"
      },
      {
        "family": "de Kort",
        "given": "Yvonne"
      },
      {
        "family": "IJsselsteijn",
        "given": "Wijnand"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "As robots may take a greater part in our moral decision-making processes, whether people hold them accountable for moral harm becomes critical to explore. Blame and punishment signify moral accountability, often involving emotions. We quantitatively looked into people\u2019s willingness to blame or punish an emotional vs. non-emotional robot that admits to its wrongdoing. Studies 1 and 2 (online video interaction) showed that people may punish a robot due to its lack of perceived emotional capacity than its perceived agency. Study 3 (in the lab) demonstrated that people were neither willing to blame nor punish the robot. Punishing non-emotional robots seems more likely than blaming them, yet punishment towards robots is more likely to arise online than offline. We reflect on if and why victimized humans (and those who care for them) may seek out retributive justice against robot scapegoats when there are no humans to hold accountable for moral harm.",
    "call-number": "10.1145/3411764.3445284",
    "collection-number": "715",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445284",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "morality, human-robot interaction, Blame, robots, retributive justice, retribution gap, responsibility gap, punishment",
    "number": "Article 715",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "People May Punish, But Not Blame Robots",
    "URL": "https://doi.org/10.1145/3411764.3445284"
  },
  {
    "id": "10.1145/3411764.3445495",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Herdel",
        "given": "Viviane"
      },
      {
        "family": "Kuzminykh",
        "given": "Anastasia"
      },
      {
        "family": "Hildebrandt",
        "given": "Andrea"
      },
      {
        "family": "Cauchard",
        "given": "Jessica R."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Drones are rapidly populating human spaces, yet little is known about how these flying robots are perceived and understood by humans. Recent works suggested that their acceptance is predicated upon their sociability. This paper explores the use of facial expressions to represent emotions on social drones. We leveraged design practices from ground robotics and created a set of rendered robotic faces that convey basic emotions. We evaluated individuals\u2019 response to these emotional facial expressions on drones in two empirical studies (N = 98, N = 98). Our results demonstrate that individuals accurately recognize five drone emotional expressions, as well as make sense of intensities within emotion categories. We describe how participants were emotionally affected by the drone, showed empathy towards it, and created narratives to interpret its emotions. As a consequence, we formulate design recommendations for social drones and discuss methodological insights on the use of static versus dynamic stimuli in affective robotics studies.",
    "call-number": "10.1145/3411764.3445495",
    "collection-number": "716",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445495",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Emotion Recognition, Anthropomorphism, Affective Computing, UAV., Robot, Human-Drone Interaction, Facial Expressions",
    "number": "Article 716",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Drone in Love: Emotional Perception of Facial Expressions on Flying Robots",
    "URL": "https://doi.org/10.1145/3411764.3445495"
  },
  {
    "id": "10.1145/3411764.3445561",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Park",
        "given": "Soomi"
      },
      {
        "family": "Healey",
        "given": "Patrick G. T."
      },
      {
        "family": "Kaniadakis",
        "given": "Antonios"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Social interaction is the most complex challenge in daily life. Inevitably, social robots will encounter interactions that are outside their competence. This raises a basic design question: how can robots fail gracefully in social interaction? The characteristic human response to social failure is embarrassment. Usefully, embarrassment signals both recognition of a problem and typically enlists sympathy and assistance to resolve it. This could enhance robot acceptability and provides an opportunity for interactive learning. Using a speculative design approach we explore how, when and why robots might communicate embarrassment. A series of specially developed cultural probes, scenario development and low-fidelity prototyping exercises suggest that: embarrassment is relevant for managing a diverse range of social scenarios, impacts on both humanoid and non-humanoid robot design, and highlights the critical importance of understanding interactional context. We conclude that embarrassment is fundamental to competent social functioning and provides a potentially fertile area for interaction design.",
    "call-number": "10.1145/3411764.3445561",
    "collection-number": "717",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445561",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Cultural Probes, Affective Robotics, Symbolic Interactionism, Speculative Design, Human-Robot Interactions, Embarrassment, Design Workshop",
    "number": "Article 717",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Should Robots Blush?",
    "URL": "https://doi.org/10.1145/3411764.3445561"
  },
  {
    "id": "10.1145/3411764.3445770",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Salovaara",
        "given": "Antti"
      },
      {
        "family": "Bellucci",
        "given": "Andrea"
      },
      {
        "family": "Vianello",
        "given": "Andrea"
      },
      {
        "family": "Jacucci",
        "given": "Giulio"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "End-user-programmable smart-home toolkits have engendered excitement in recent years. However, modern homes already cater quite well to users\u2019 needs, and genuinely new needs for smart-home automation seldom arise. Acknowledging this challenging starting point, we conducted a six-week in-the-wild study of smart-home toolkits with four carefully recruited technology-savvy families. Interleaved with free toolkit use in the home were several creativity workshops to facilitate ideation and programming. We evaluated use experiences at the end of the six weeks. Even with extensive facilitation, families faced difficulties in identifying needs for smart-home automation, except for social needs that emerged in all the families. We present analysis of those needs and discuss how end-user-programmable toolkits could better engage with both those household members who design new automated functions and those who merely \u2018use\u2019 them.",
    "call-number": "10.1145/3411764.3445770",
    "collection-number": "718",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445770",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "smart homes, internet of things, end-user programming, in-the-wild study, trigger\u2013action programming, appropriation",
    "number": "Article 718",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Programmable Smart Home Toolkits Should Better Address Households\u2019 Social Needs",
    "URL": "https://doi.org/10.1145/3411764.3445770"
  },
  {
    "id": "10.1145/3411764.3445299",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wo\u017aniak",
        "given": "Pawe\u0142 W."
      },
      {
        "family": "Karolus",
        "given": "Jakob"
      },
      {
        "family": "Lang",
        "given": "Florian"
      },
      {
        "family": "Eckerth",
        "given": "Caroline"
      },
      {
        "family": "Sch\u00f6ning",
        "given": "Johannes"
      },
      {
        "family": "Rogers",
        "given": "Yvonne"
      },
      {
        "family": "Niess",
        "given": "Jasmin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Interactive technologies are getting closer to our bodies and permeate the infrastructure of our homes. While such technologies offer many benefits, they can also cause an initial feeling of unease in users. It is important for Human-Computer Interaction to manage first impressions and avoid designing technologies that appear creepy. To that end, we developed the Perceived Creepiness of Technology Scale (PCTS), which measures how creepy a technology appears to a user in an initial encounter with a new artefact. The scale was developed based on past work on creepiness and a set of ten focus groups conducted with users from diverse backgrounds. We followed a structured process of analytically developing and validating the scale. The PCTS is designed to enable designers and researchers to quickly compare interactive technologies and ensure that they do not design technologies that produce initial feelings of creepiness in users.",
    "call-number": "10.1145/3411764.3445299",
    "collection-number": "719",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445299",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "evaluation, perceived creepiness of technology scale, creepy, first impression, questionnaire, scale, creepiness",
    "number": "Article 719",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Creepy Technology:What Is It and How Do You Measure It?",
    "URL": "https://doi.org/10.1145/3411764.3445299"
  },
  {
    "id": "10.1145/3411764.3445483",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jokinen",
        "given": "Jussi"
      },
      {
        "family": "Acharya",
        "given": "Aditya"
      },
      {
        "family": "Uzair",
        "given": "Mohammad"
      },
      {
        "family": "Jiang",
        "given": "Xinhui"
      },
      {
        "family": "Oulasvirta",
        "given": "Antti"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Traditionally, touchscreen typing has been studied in terms of motor performance. However, recent research has exposed a decisive role of visual attention being shared between the keyboard and the text area. Strategies for this are known to adapt to the task, design, and user. In this paper, we propose a unifying account of touchscreen typing, regarding it as optimal supervisory control. Under this theory, rules for controlling visuo-motor resources are learned via exploration in pursuit of maximal typing performance. The paper outlines the control problem and explains how visual and motor limitations affect it. We then present a model, implemented via reinforcement learning, that simulates co-ordination of eye and finger movements. Comparison with human data affirms that the model creates realistic finger- and eye-movement patterns and shows human-like adaptation. We demonstrate the model\u2019s utility for interface development in evaluating touchscreen keyboard designs.",
    "call-number": "10.1145/3411764.3445483",
    "collection-number": "720",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445483",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "rational adaptation, computational modelling, touchscreen typing",
    "number": "Article 720",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Touchscreen Typing As Optimal Supervisory Control",
    "URL": "https://doi.org/10.1145/3411764.3445483"
  },
  {
    "id": "10.1145/3411764.3445577",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cho",
        "given": "Youngjun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Continuous assessment of task difficulty and mental workload is essential in improving the usability and accessibility of interactive systems. Eye tracking data has often been investigated to achieve this ability, with reports on the limited role of standard blink metrics. Here, we propose a new approach to the analysis of eye-blink responses for automated estimation of task difficulty. The core module is a time-frequency representation of eye-blink, which aims to capture the richness of information reflected on blinking. In our first study, we show that this method significantly improves the sensitivity to task difficulty. We then demonstrate how to form a framework where the represented patterns are analyzed with multi-dimensional Long Short-Term Memory recurrent neural networks for their non-linear mapping onto difficulty-related parameters. This framework outperformed other methods that used hand-engineered features. This approach works with any built-in camera, without requiring specialized devices. We conclude by discussing how Rethinking Eye-blink can benefit real-world applications.",
    "call-number": "10.1145/3411764.3445577",
    "collection-number": "721",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445577",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Mental Workload Assessment, Physiological Computing, Physiological Representation, Eye-blink, Task Difficulty, Eye-blink Spectrogram",
    "number": "Article 721",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Rethinking Eye-blink: Assessing Task Difficulty through Physiological Representation of Spontaneous Blinking",
    "URL": "https://doi.org/10.1145/3411764.3445577"
  },
  {
    "id": "10.1145/3411764.3445675",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shin",
        "given": "Jae-eun"
      },
      {
        "family": "Yoon",
        "given": "Boram"
      },
      {
        "family": "Kim",
        "given": "Dooyoung"
      },
      {
        "family": "Woo",
        "given": "Woontack"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Space-adaptive algorithms aim to effectively align the virtual with the real to provide immersive user experiences for Augmented Reality(AR) content across various physical spaces. While such measures are reliant on real spatial features, efforts to understand those features from the user\u2019s perspective and reflect them in designing adaptive augmented spaces have been lacking. For this, we compared factors of narrative experience in six spatial conditions during the gameplay of Fragments, a space-adaptive AR detective game. Configured by size and furniture layout, each condition afforded disparate degrees of traversability and visibility. Results show that whereas centered furniture clusters are suitable for higher presence in sufficiently large rooms, the same layout leads to lower narrative engagement. Based on our findings, we suggest guidelines that can enhance the effects of space adaptivity by considering how users perceive and navigate augmented space generated from different physical environments.",
    "call-number": "10.1145/3411764.3445675",
    "collection-number": "722",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445675",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Augmented Reality, Head Mounted Displays, narrative experience, storytelling, space adaptivity, spatial affordance, spatial mapping",
    "number": "Article 722",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A User-Oriented Approach to Space-Adaptive Augmentation: The Effects of Spatial Affordance on Narrative Experience in an Augmented Reality Detective Game",
    "URL": "https://doi.org/10.1145/3411764.3445675"
  },
  {
    "id": "10.1145/3411764.3445476",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Williams",
        "given": "Thomas J."
      },
      {
        "family": "Jones",
        "given": "Simon L."
      },
      {
        "family": "Lutteroth",
        "given": "Christof"
      },
      {
        "family": "Dekoninck",
        "given": "Elies"
      },
      {
        "family": "Boyd",
        "given": "Hazel C"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Older adults can benefit from technologies that help them to complete everyday tasks. However, they are an often-under-represented population in augmented reality (AR) research. We present the results of a study in which people aged 50 years or older were asked to perform actions by interpreting visual AR prompts in a lab setting. Our results show that users were less successful at completing actions when using ARROW and HIGHLIGHT augmentations than when using ghosted OBJECT or GHOSTHAND augmentations. We found that user confidence in performing actions varied according to action and augmentation type. Users preferred combined AUDIO+TEXT prompts (our control condition) overall, but the GHOSTHAND was the most preferred visual prompt. We discuss reasons for these differences and provide insight for developers of AR content for older adults. Our work provides the first comparative study of AR with older adults in a non-industrial context.",
    "call-number": "10.1145/3411764.3445476",
    "collection-number": "723",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445476",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "prompting tools, augmented reality, older adults, task prompting",
    "number": "Article 723",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Augmented Reality and Older Adults: A Comparison of Prompting Types",
    "URL": "https://doi.org/10.1145/3411764.3445476"
  },
  {
    "id": "10.1145/3411764.3445557",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Robertson",
        "given": "Ronald E"
      },
      {
        "family": "Olteanu",
        "given": "Alexandra"
      },
      {
        "family": "Diaz",
        "given": "Fernando"
      },
      {
        "family": "Shokouhi",
        "given": "Milad"
      },
      {
        "family": "Bailey",
        "given": "Peter"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "In email interfaces, providing users with reply suggestions may simplify or accelerate correspondence. While the \u201csuccess\u201d of such systems is typically quantified using the number of suggestions selected by users, this ignores the impact of social context, which can change how suggestions are perceived. To address this, we developed a mixed-methods framework involving qualitative interviews and crowdsourced experiments to characterize problematic email reply suggestions. Our interviews revealed issues with over-positive, dissonant, cultural, and gender-assuming replies, as well as contextual politeness. In our experiments, crowdworkers assessed email scenarios that we generated and systematically controlled, showing that contextual factors like social ties and the presence of salutations impacts users\u2019 perceptions of email correspondence. These assessments created a novel dataset of human-authored corrections for problematic email replies. Our study highlights the social complexity of providing suggestions for email correspondence, raising issues that may apply to all social messaging systems.",
    "call-number": "10.1145/3411764.3445557",
    "collection-number": "724",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445557",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "algorithm auditing, AI-MC, smart reply, email, AI-assisted writing, smart compose, CMC",
    "number": "Article 724",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Can\u2019t Reply with That\u201d: Characterizing Problematic Email Reply Suggestions",
    "URL": "https://doi.org/10.1145/3411764.3445557"
  },
  {
    "id": "10.1145/3411764.3445618",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Palani",
        "given": "Srishti"
      },
      {
        "family": "Ding",
        "given": "Zijian"
      },
      {
        "family": "Nguyen",
        "given": "Austin"
      },
      {
        "family": "Chuang",
        "given": "Andrew"
      },
      {
        "family": "MacNeil",
        "given": "Stephen"
      },
      {
        "family": "Dow",
        "given": "Steven P."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "When exploring a new domain through web search, people often struggle to articulate queries because they lack domain-specific language and well-defined informational goals. Perhaps search tools rely too much on the query to understand what a searcher wants. Towards expanding this contextual understanding of a user during exploratory search, we introduce a novel system, CoNotate, which offers query suggestions based on analyzing the searcher\u2019s notes and previous searches for patterns and gaps in information. To evaluate this approach, we conducted a within-subjects study where participants (n=38) conducted exploratory searches using a baseline system (standard web search) and the CoNotate system. The CoNotate approach helped searchers issue significantly more queries, and discover more terminology than standard web search. This work demonstrates how search can leverage user-generated content to help people get started when exploring complex, multi-faceted information spaces.",
    "call-number": "10.1145/3411764.3445618",
    "collection-number": "726",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445618",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Context Mining, Query Suggestions, Exploratory Search, Note-taking",
    "number": "Article 726",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CoNotate: Suggesting Queries Based on Notes Promotes Knowledge Discovery",
    "URL": "https://doi.org/10.1145/3411764.3445618"
  },
  {
    "id": "10.1145/3411764.3445434",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kang",
        "given": "DaYe"
      },
      {
        "family": "Ho",
        "given": "Tony"
      },
      {
        "family": "Marquardt",
        "given": "Nicolai"
      },
      {
        "family": "Mutlu",
        "given": "Bilge"
      },
      {
        "family": "Bianchi",
        "given": "Andrea"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Computational notebooks help data analysts analyze and visualize datasets, and share analysis procedures and outputs. However, notebooks typically combine code (e.g., Python scripts), notes, and outputs (e.g., tables, graphs). The combination of disparate materials is known to hinder the comprehension of notebooks, making it difficult for analysts to collaborate with other analysts unfamiliar with the dataset. To mitigate this problem, we introduce ToonNote, a JupyterLab extension that enables the conversion of notebooks into \u201cdata comics.\u201d ToonNote provides a simplified view of a Jupyter notebook, highlighting the most important results while supporting interactive and free exploration of the dataset. This paper presents the results of a formative study that motivated the system, its implementation, and an evaluation with 12 users, demonstrating the effectiveness of the produced comics. We discuss how our findings inform the future design of interfaces for computational notebooks and features to support diverse collaborators.",
    "call-number": "10.1145/3411764.3445434",
    "collection-number": "727",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445434",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "data summarization, multi-level interface, data comics, computational notebooks",
    "number": "Article 727",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ToonNote: Improving Communication in Computational Notebooks Using Interactive Data Comics",
    "URL": "https://doi.org/10.1145/3411764.3445434"
  },
  {
    "id": "10.1145/3411764.3445398",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Arevalo Arboleda",
        "given": "Stephanie"
      },
      {
        "family": "R\u00fccker",
        "given": "Franziska"
      },
      {
        "family": "Dierks",
        "given": "Tim"
      },
      {
        "family": "Gerken",
        "given": "Jens"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Teleoperating industrial manipulators in co-located spaces can be challenging. Facilitating robot teleoperation by providing additional visual information about the environment and the robot affordances using augmented reality (AR), can improve task performance in manipulation and grasping. In this paper, we present two designs of augmented visual cues, that aim to enhance the visual space of the robot operator through hints about the position of the robot gripper in the workspace and in relation to the target. These visual cues aim to improve the distance perception and thus, the task performance. We evaluate both designs against a baseline in an experiment where participants teleoperate a robotic arm to perform pick-and-place tasks. Our results show performance improvements in different levels, reflecting in objective and subjective measures with trade-offs in terms of time, accuracy, and participants\u2019 views of teleoperation. These findings show the potential of AR not only in teleoperation, but in understanding the human-robot workspace.",
    "call-number": "10.1145/3411764.3445398",
    "collection-number": "728",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445398",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "human-robot interaction, augmented reality, robot teleoperation, visual cues",
    "number": "Article 728",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Assisting Manipulation and Grasping in Robot Teleoperation with Augmented Reality Visual Cues",
    "URL": "https://doi.org/10.1145/3411764.3445398"
  },
  {
    "id": "10.1145/3411764.3445327",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Min Htike",
        "given": "Hein"
      },
      {
        "family": "H. Margrain",
        "given": "Tom"
      },
      {
        "family": "Lai",
        "given": "Yu-Kun"
      },
      {
        "family": "Eslambolchilar",
        "given": "Parisa"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "People with low vision experience reduced mobility that affects their physical and mental wellbeing. With augmented reality (AR) glasses, there are new opportunities to provide visual and auditory information that can improve mobility for this vulnerable group. Current research into AR-based mobility aids has focused mainly on the technical aspects, and less emphasis has been placed on understanding the usability and suitability of these aids in people with various levels of visual impairment. In this paper, we present the results of qualitative interviews with 18 participants using HoloLens v1 and eight prototype augmentations to understand how these enhancements are perceived by people with low vision and how these aids should be adjusted to suit their needs. Our results suggested that participants with moderate vision loss could potentially perceive the most benefit from glasses and underlined the importance of extensive customizability to accommodate the needs of a highly varied low vision population.",
    "call-number": "10.1145/3411764.3445327",
    "collection-number": "729",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445327",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "augmented reality, mobility aids, low vision, vision enhancement",
    "number": "Article 729",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Augmented Reality Glasses as an Orientation and Mobility Aid for People with Low Vision: a Feasibility Study of Experiences and Requirements",
    "URL": "https://doi.org/10.1145/3411764.3445327"
  },
  {
    "id": "10.1145/3411764.3445597",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rixen",
        "given": "Jan Ole"
      },
      {
        "family": "Hirzle",
        "given": "Teresa"
      },
      {
        "family": "Colley",
        "given": "Mark"
      },
      {
        "family": "Etzel",
        "given": "Yannick"
      },
      {
        "family": "Rukzio",
        "given": "Enrico"
      },
      {
        "family": "Gugenheimer",
        "given": "Jan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Augmented Reality (AR) glasses equip users with the tools to modify the visual appearance of their surrounding environment. This might severely impact interpersonal communication, as the conversational partners will no longer share the same visual perception of reality. Grounded in color-in-context theory, we present a potential AR application scenario in which users can modify the color of the environment to achieve subconscious benefits. In a consecutive online survey (N=64), we measured the user\u2019s comfort, acceptance of altering and being altered, and how it is impacted by being able to perceive or not perceive the alteration. We identified significant differences depending on (1) who or what is the target of the alteration, (2) which body part is altered, and (3) which relationship the conversational partners share. In light of our quantitative and qualitative findings, we discuss ethical and practical implications for future devices and applications that employ visual alterations.",
    "call-number": "10.1145/3411764.3445597",
    "collection-number": "730",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445597",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "social acceptability, Augmented Reality, interpersonal communication, color-in-context, visual alterations",
    "number": "Article 730",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Augmented Visual Alterations in Interpersonal Communication",
    "URL": "https://doi.org/10.1145/3411764.3445597"
  },
  {
    "id": "10.1145/3411764.3445493",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dudley",
        "given": "John J."
      },
      {
        "family": "Jacques",
        "given": "Jason T."
      },
      {
        "family": "Kristensson",
        "given": "Per Ola"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Augmented Reality (AR) can deliver engaging user experiences that seamlessly meld virtual content with the physical environment. However, building such experiences is challenging due to the developer\u2019s inability to assess how uncontrolled deployment contexts may influence the user experience. To address this issue, we demonstrate a method for rapidly conducting AR experiments and real-world data collection in the user\u2019s own physical environment using a privacy-conscious mobile web application. The approach leverages the large number of distinct user contexts accessible through crowdsourcing to efficiently source diverse context and perceptual preference data. The insights gathered through this method complement emerging design guidance and sample-limited lab-based studies. The utility of the method is illustrated by re-examining the design challenge of adapting AR text content to the user\u2019s environment. Finally, we demonstrate how gathered design insight can be operationalized to provide adaptive text content functionality in an AR headset.",
    "call-number": "10.1145/3411764.3445493",
    "collection-number": "731",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445493",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Augmented Reality, Crowdsourcing, Privacy",
    "number": "Article 731",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Crowdsourcing Design Guidance for Contextual Adaptation of Text Content in Augmented Reality",
    "URL": "https://doi.org/10.1145/3411764.3445493"
  },
  {
    "id": "10.1145/3411764.3445372",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Buschek",
        "given": "Daniel"
      },
      {
        "family": "Z\u00fcrn",
        "given": "Martin"
      },
      {
        "family": "Eiband",
        "given": "Malin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "We present an in-depth analysis of the impact of multi-word suggestion choices from a neural language model on user behaviour regarding input and text composition in email writing. Our study for the first time compares different numbers of parallel suggestions, and use by native and non-native English writers, to explore a trade-off of \u201cefficiency vs ideation\u201d, emerging from recent literature. We built a text editor prototype with a neural language model (GPT-2), refined in a prestudy with 30 people. In an online study (N=156), people composed emails in four conditions (0/1/3/6 parallel suggestions). Our results reveal (1) benefits for ideation, and costs for efficiency, when suggesting multiple phrases; (2) that non-native speakers benefit more from more suggestions; and (3) further insights into behaviour patterns. We discuss implications for research, the design of interactive suggestion systems, and the vision of supporting writers with AI instead of replacing them.",
    "call-number": "10.1145/3411764.3445372",
    "collection-number": "732",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445372",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "deep learning, Text entry, text suggestions, language model, dataset, typing, neural network",
    "number": "Article 732",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Impact of Multiple Parallel Phrase Suggestions on Email Input and Composition Behaviour of Native and Non-Native English Writers",
    "URL": "https://doi.org/10.1145/3411764.3445372"
  },
  {
    "id": "10.1145/3411764.3445509",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gorman",
        "given": "Benjamin M."
      },
      {
        "family": "Crabb",
        "given": "Michael"
      },
      {
        "family": "Armstrong",
        "given": "Michael"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Subtitles can help improve the understanding of media content. People enable subtitles based on individual characteristics (e.g., language or hearing ability), viewing environment, or media context (e.g., drama, quiz show). However, some people find that subtitles can be distracting and that they negatively impact their viewing experience. We explore the challenges and opportunities surrounding interaction with real-time personalisation of subtitled content. To understand how people currently interact with subtitles, we first conducted an online questionnaire with 102 participants. We used our findings to elicit requirements for a new approach called Adaptive Subtitles that allows the viewer to alter which speakers have subtitles displayed in real-time. We evaluated our approach with 19 participants to understand the interaction trade-offs and challenges within real-time adaptations of subtitled media. Our evaluation findings suggest that granular controls and structured onboarding allow viewers to make informed trade-offs when adapting media content, leading to improved viewing experiences.",
    "call-number": "10.1145/3411764.3445509",
    "collection-number": "733",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445509",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Captions, Adaptive-Interfaces, Media, Closed-captions, Subtitles",
    "number": "Article 733",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Adaptive Subtitles: Preferences and Trade-Offs in Real-Time Media Adaption",
    "URL": "https://doi.org/10.1145/3411764.3445509"
  },
  {
    "id": "10.1145/3411764.3445343",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yu",
        "given": "Difeng"
      },
      {
        "family": "Lu",
        "given": "Xueshi"
      },
      {
        "family": "Shi",
        "given": "Rongkai"
      },
      {
        "family": "Liang",
        "given": "Hai-Ning"
      },
      {
        "family": "Dingler",
        "given": "Tilman"
      },
      {
        "family": "Velloso",
        "given": "Eduardo"
      },
      {
        "family": "Goncalves",
        "given": "Jorge"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "This paper investigates integration, coordination, and transition strategies of gaze and hand input for 3D object manipulation in VR. Specifically, this work aims to understand whether incorporating gaze input can benefit VR object manipulation tasks, and how it should be combined with hand input for improved usability and efficiency. We designed four gaze-supported techniques that leverage different combination strategies for object manipulation and evaluated them in two user studies. Overall, we show that gaze did not offer significant performance benefits for transforming objects in the primary working space, where all objects were located in front of the user and within the arm-reach distance, but can be useful for a larger environment with distant targets. We further offer insights regarding combination strategies of gaze and hand input, and derive implications that can help guide the design of future VR systems that incorporate gaze input for 3D object manipulation.",
    "call-number": "10.1145/3411764.3445343",
    "collection-number": "734",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445343",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "gaze input, multimodal interface, 3D object manipulation",
    "number": "Article 734",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Gaze-Supported 3D Object Manipulation in Virtual Reality",
    "URL": "https://doi.org/10.1145/3411764.3445343"
  },
  {
    "id": "10.1145/3411764.3445352",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Yuntao"
      },
      {
        "family": "Yu",
        "given": "Ao"
      },
      {
        "family": "Yi",
        "given": "Xin"
      },
      {
        "family": "Zhang",
        "given": "Yuanwei"
      },
      {
        "family": "Chatterjee",
        "given": "Ishan"
      },
      {
        "family": "Patel",
        "given": "Shwetak"
      },
      {
        "family": "Shi",
        "given": "Yuanchun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "QWERTY is the primary smartphone text input keyboard configuration. However, insertion and substitution errors caused by hand tremors, often experienced by users with Parkinson\u2019s disease, can severely affect typing efficiency and user experience. In this paper, we investigated Parkinson\u2019s users\u2019 typing behavior on smartphones. In particular, we identified and compared the typing characteristics generated by users with and without Parkinson\u2019s symptoms. We then proposed an elastic probabilistic model for input prediction. By incorporating both spatial and temporal features, this model generalized the classical statistical decoding algorithm to correct insertion, substitution and omission errors, while maintaining direct physical interpretation. User study results confirmed that the proposed algorithm outperformed baseline techniques: users reached 22.8 WPM typing speed with a significantly lower error rate and higher user-perceived performance and preference. We concluded that our method could effectively improve the text entry experience on smartphones for users with Parkinson\u2019s disease.",
    "call-number": "10.1145/3411764.3445352",
    "collection-number": "735",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445352",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Parkinson\u2019s disease, statistical decoding, QWERTY keyboard, touch model, text entry",
    "number": "Article 735",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Facilitating Text Entry on Smartphones with QWERTY Keyboard for Users with Parkinson\u2019s Disease",
    "URL": "https://doi.org/10.1145/3411764.3445352"
  },
  {
    "id": "10.1145/3411764.3445099",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Teng",
        "given": "Shan-Yuan"
      },
      {
        "family": "Li",
        "given": "Pengyu"
      },
      {
        "family": "Nith",
        "given": "Romain"
      },
      {
        "family": "Fonseca",
        "given": "Joshua"
      },
      {
        "family": "Lopes",
        "given": "Pedro"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "We propose a nail-mounted foldable haptic device that provides tactile feedback to mixed reality (MR) environments by pressing against the user's fingerpad when a user touches a virtual object. What is novel in our device is that it quickly tucks away when the user interacts with real-world objects. Its design allows it to fold back on top of the user's nail when not in use, keeping the user's fingerpad free to, for instance, manipulate handheld tools and other objects while in MR. To achieve this, we engineered a wireless and self-contained haptic device, which measures 24\u00d724\u00d741\u00a0mm and weighs 9.5\u00a0g. Furthermore, our foldable end-effector also features a linear resonant actuator, allowing it to render not only touch contacts (i.e., pressure) but also textures (i.e., vibrations). We demonstrate how our device renders contacts with MR surfaces, buttons, low- and high-frequency textures. In our first user study, we found that participants perceived our device to be more realistic than a previous haptic device that also leaves the fingerpad free (i.e., fingernail vibration). In our second user study, we investigated the participants\u2019 experience while using our device in a real-world task that involved physical objects. We found that our device allowed participants to use the same finger to manipulate handheld tools, small objects, and even feel textures and liquids, without much hindrance to their dexterity, while feeling haptic feedback when touching MR interfaces.",
    "call-number": "10.1145/3411764.3445099",
    "collection-number": "736",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445099",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Haptics, Mixed Reality, Wearable",
    "number": "Article 736",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Touch&Fold: A Foldable Haptic Actuator for Rendering Touch in Mixed Reality",
    "URL": "https://doi.org/10.1145/3411764.3445099"
  },
  {
    "id": "10.1145/3411764.3445546",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Veras",
        "given": "Rafael"
      },
      {
        "family": "Singh",
        "given": "Gaganpreet"
      },
      {
        "family": "Farhadi-Niaki",
        "given": "Farzin"
      },
      {
        "family": "Udhani",
        "given": "Ritesh"
      },
      {
        "family": "Patekar",
        "given": "Parth Pradeep"
      },
      {
        "family": "Zhou",
        "given": "Wei"
      },
      {
        "family": "Irani",
        "given": "Pourang"
      },
      {
        "family": "Li",
        "given": "Wei"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "We designed a mid-air input space for restful interactions on the couch. We observed people gesturing in various postures on a couch and found that posture affects the choice of arm motions when no constraints are imposed by a system. Study participants that sat with the arm rested were more likely to use the forearm and wrist, as opposed to the whole arm. We investigate how a spherical input space, where forearm angles are mapped to screen coordinates, can facilitate restful mid-air input in multiple postures. We present two controlled studies. In the first, we examine how a spherical space compares with a planar space in an elbow-anchored setup, with a shoulder-level input space as baseline. In the second, we examine the performance of a spherical input space in four common couch postures that set unique constraints to the arm. We observe that a spherical model that captures forearm movement facilitates comfortable input across different seated postures.",
    "call-number": "10.1145/3411764.3445546",
    "collection-number": "737",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445546",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Restful Input, Mid-air Gestures, Variable-posture Gestures, Comfort, Mid-air Gesture Fatigue, Elbow-anchored Input",
    "number": "Article 737",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Elbow-Anchored Interaction: Designing Restful Mid-Air Input",
    "URL": "https://doi.org/10.1145/3411764.3445546"
  },
  {
    "id": "10.1145/3411764.3445539",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Wanyu"
      },
      {
        "family": "Dementyev",
        "given": "Artem"
      },
      {
        "family": "Schwarz",
        "given": "Diemo"
      },
      {
        "family": "Flety",
        "given": "Emmanuel"
      },
      {
        "family": "Mackay",
        "given": "Wendy E."
      },
      {
        "family": "Beaudouin-Lafon",
        "given": "Michel"
      },
      {
        "family": "Bevilacqua",
        "given": "Frederic"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Aerial hoops are circular, hanging devices for both acrobatic exercise and artistic performance that let us explore the role of interactive sonification in physical activity. We present SonicHoop, an augmented aerial hoop that generates auditory feedback via capacitive touch sensing, thus becoming a digital musical instrument that performers can play with their bodies. We compare three sonification strategies through a structured observation study with two professional aerial hoop performers. Results show that SonicHoop fundamentally changes their perception and choreographic processes: instead of translating music into movement, they search for bodily expressions that compose music. Different sound designs affect their movement differently, and auditory feedback, regardless of type of sound, improves movement quality. We discuss opportunities for using SonicHoop as an aerial hoop training tool, as a digital musical instrument, and as a creative object; as well as using interactive sonification in other acrobatic practices to explore full-body vertical interaction.",
    "call-number": "10.1145/3411764.3445539",
    "collection-number": "738",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445539",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "sound, Interactive sonification, capacitive sensing, auditory feedback, aerial hoop",
    "number": "Article 738",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SonicHoop: Using Interactive Sonification to Support Aerial Hoop Practices",
    "URL": "https://doi.org/10.1145/3411764.3445539"
  },
  {
    "id": "10.1145/3411764.3445297",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ahn",
        "given": "Sunggeun"
      },
      {
        "family": "Santosa",
        "given": "Stephanie"
      },
      {
        "family": "Parent",
        "given": "Mark"
      },
      {
        "family": "Wigdor",
        "given": "Daniel"
      },
      {
        "family": "Grossman",
        "given": "Tovi"
      },
      {
        "family": "Giordano",
        "given": "Marcello"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "This work explores the design of marking menus for gaze-based AR/VR menu selection by expert and novice users. It first identifies and explains the challenges inherent in ocular motor control and current eye tracking hardware, including overshooting, incorrect selections, and false activations. Through three empirical studies, we optimized and validated design parameters to mitigate these errors while reducing completion time, task load, and eye fatigue. Based on the findings from these studies, we derived a set of design guidelines to support gaze-based marking menus in AR/VR. To overcome the overshoot errors found with eye-based expert marking menu behaviour, we developed StickyPie, a marking menu technique that enables scale-independent marking input by estimating saccade landing positions. An evaluation of StickyPie revealed that StickyPie was easier to learn than the traditional technique (i.e., RegularPie) and was 10% more efficient after 3 sessions.",
    "call-number": "10.1145/3411764.3445297",
    "collection-number": "739",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445297",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "head-worn display, eye gaze input, AR/VR, marking menu",
    "number": "Article 739",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "StickyPie: A Gaze-Based, Scale-Invariant Marking Menu Optimized for AR/VR",
    "URL": "https://doi.org/10.1145/3411764.3445297"
  },
  {
    "id": "10.1145/3411764.3445697",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sidenmark",
        "given": "Ludwig"
      },
      {
        "family": "Potts",
        "given": "Dominic"
      },
      {
        "family": "Bapisch",
        "given": "Bill"
      },
      {
        "family": "Gellersen",
        "given": "Hans"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Eye gaze and head movement are attractive for hands-free 3D interaction in head-mounted displays, but existing interfaces afford only limited control. Radi-Eye is a novel pop-up radial interface designed to maximise expressiveness with input from only the eyes and head. Radi-Eye provides widgets for discrete and continuous input and scales to support larger feature sets. Widgets can be selected with Look & Cross, using gaze for pre-selection followed by head-crossing as trigger and for manipulation. The technique leverages natural eye-head coordination where eye and head move at an offset unless explicitly brought into alignment, enabling interaction without risk of unintended input. We explore Radi-Eye in three augmented and virtual reality applications, and evaluate the effect of radial interface scale and orientation on performance with Look & Cross. The results show that Radi-Eye provides users with fast and accurate input while opening up a new design space for hands-free fluid interaction.",
    "call-number": "10.1145/3411764.3445697",
    "collection-number": "740",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445697",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Gaze interaction, Augmented Reality, Eye tracking, Eye-Head Coordination, Virtual Reality, Radial Interface",
    "number": "Article 740",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Radi-Eye: Hands-Free Radial Interfaces for 3D Interaction using Gaze-Activated Head-Crossing",
    "URL": "https://doi.org/10.1145/3411764.3445697"
  },
  {
    "id": "10.1145/3411764.3445501",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hedeshy",
        "given": "Ramin"
      },
      {
        "family": "Kumar",
        "given": "Chandan"
      },
      {
        "family": "Menges",
        "given": "Raphael"
      },
      {
        "family": "Staab",
        "given": "Steffen"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Text entry by gaze is a useful means of hands-free interaction that is applicable in settings where dictation suffers from poor voice recognition or where spoken words and sentences jeopardize privacy or confidentiality. However, text entry by gaze still shows inferior performance and it quickly exhausts its users. We introduce text entry by gaze and hum as a novel hands-free text entry. We review related literature to converge to word-level text entry by analysis of gaze paths that are temporally constrained by humming. We develop and evaluate two design choices: \u201cHumHum\u201d and \u201cHummer.\u201d The first method requires short hums to indicate the start and end of a word. The second method interprets one continuous humming as an indication of the start and end of a word. In an experiment with 12 participants, Hummer achieved a commendable text entry rate of 20.45 words per minute, and outperformed HumHum and the gaze-only method EyeSwipe in both quantitative and qualitative measures.",
    "call-number": "10.1145/3411764.3445501",
    "collection-number": "741",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445501",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "hands-free interaction, eye typing, humming, swipe, eye tracking",
    "number": "Article 741",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Hummer: Text Entry by Gaze and Hum",
    "URL": "https://doi.org/10.1145/3411764.3445501"
  },
  {
    "id": "10.1145/3411764.3445324",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Pereira",
        "given": "Monica"
      },
      {
        "family": "Hone",
        "given": "Kate"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "There have been promising studies that show a potential of providing social signal feedback to improve communication skills. However, these studies have primarily focused on unimodal methods of feedback. In addition to this, studies do not assess whether skills are maintained after a given time. With a sample size of 22 this paper investigates whether multimodal social signal feedback is an effective method of improving communication in the context of media interviews. A pre-post experimental evaluation of media skills training intervention is presented which compares standard feedback with augmented feedback based on automated recognition of multimodal social signals. Results revealed significantly different training effects between the two conditions. However, the initial experiment study failed to show significant differences in human judgement of performance. A 6-month follow-up study revealed human judgement ratings were higher for the experiment group. This study suggests that augmented selective multimodal social signal feedback is an effective method for communication skills training.",
    "call-number": "10.1145/3411764.3445324",
    "collection-number": "742",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445324",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "Off-the-shelf emotion recognition technology, Media interviews, Social Signals, Communication skills training",
    "number": "Article 742",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Communication Skills Training Intervention Based on Automated Recognition of Nonverbal Signals",
    "URL": "https://doi.org/10.1145/3411764.3445324"
  },
  {
    "id": "10.1145/3411764.3445205",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "R\u00f6ddiger",
        "given": "Tobias"
      },
      {
        "family": "Clarke",
        "given": "Christopher"
      },
      {
        "family": "Wolffram",
        "given": "Daniel"
      },
      {
        "family": "Budde",
        "given": "Matthias"
      },
      {
        "family": "Beigl",
        "given": "Michael"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "We explore how discreet input can be provided using the tensor tympani - a small muscle in the middle ear that some people can voluntarily contract to induce a dull rumbling sound. We investigate the prevalence and ability to control the muscle through an online questionnaire (N=192) in which 43.2% of respondents reported the ability to \u201cear rumble\u201d. Data collected from participants (N=16) shows how in-ear barometry can be used to detect voluntary tensor tympani contraction in the sealed ear canal. This data was used to train a classifier based on three simple ear rumble \u201cgestures\u201d which achieved 95% accuracy. Finally, we evaluate the use of ear rumbling for interaction, grounded in three manual, dual-task application scenarios (N=8). This highlights the applicability of EarRumble as a low-effort and discreet eyes- and hands-free interaction technique that users found \u201cmagical\u201d and \u201calmost telepathic\u201d.",
    "call-number": "10.1145/3411764.3445205",
    "collection-number": "743",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445205",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "tensor tympani muscle, hearables, subtle gestures, earables, in-ear barometry, discreet interaction",
    "number": "Article 743",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "EarRumble: Discreet Hands- and Eyes-Free Input by Voluntary Tensor Tympani Muscle Contraction",
    "URL": "https://doi.org/10.1145/3411764.3445205"
  },
  {
    "id": "10.1145/3411764.3445197",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sharma",
        "given": "Adwait"
      },
      {
        "family": "Hedderich",
        "given": "Michael A."
      },
      {
        "family": "Bhardwaj",
        "given": "Divyanshu"
      },
      {
        "family": "Fruchard",
        "given": "Bruno"
      },
      {
        "family": "McIntosh",
        "given": "Jess"
      },
      {
        "family": "Nittala",
        "given": "Aditya Shekhar"
      },
      {
        "family": "Klakow",
        "given": "Dietrich"
      },
      {
        "family": "Ashbrook",
        "given": "Daniel"
      },
      {
        "family": "Steimle",
        "given": "J\u00fcrgen"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Using microgestures, prior work has successfully enabled gestural interactions while holding objects. Yet, these existing methods are prone to false activations caused by natural finger movements while holding or manipulating the object. We address this issue with SoloFinger, a novel concept that allows design of microgestures that are robust against movements that naturally occur during primary activities. Using a data-driven approach, we establish that single-finger movements are rare in everyday hand-object actions and infer a single-finger input technique resilient to false activation. We demonstrate this concept\u2019s robustness using a white-box classifier on a pre-existing dataset comprising 36 everyday hand-object actions. Our findings validate that simple SoloFinger gestures can relieve the need for complex finger configurations or delimiting gestures and that SoloFinger is applicable to diverse hand-object actions. Finally, we demonstrate SoloFinger\u2019s high performance on commodity hardware using random forest classifiers.",
    "call-number": "10.1145/3411764.3445197",
    "collection-number": "744",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445197",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "microgesture, everyday objects, grasping, false activation",
    "number": "Article 744",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SoloFinger: Robust Microgestures while Grasping Everyday Objects",
    "URL": "https://doi.org/10.1145/3411764.3445197"
  },
  {
    "id": "10.1145/3411764.3445595",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Marky",
        "given": "Karola"
      },
      {
        "family": "Wei\u00df",
        "given": "Andreas"
      },
      {
        "family": "Matviienko",
        "given": "Andrii"
      },
      {
        "family": "Brandherm",
        "given": "Florian"
      },
      {
        "family": "Wolf",
        "given": "Sebastian"
      },
      {
        "family": "Schmitz",
        "given": "Martin"
      },
      {
        "family": "Krell",
        "given": "Florian"
      },
      {
        "family": "M\u00fcller",
        "given": "Florian"
      },
      {
        "family": "M\u00fchlh\u00e4user",
        "given": "Max"
      },
      {
        "family": "Kosch",
        "given": "Thomas"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2021,
          5,
          6
        ]
      ]
    },
    "abstract": "Learning a musical instrument requires regular exercise. However, students are often on their own during their practice sessions due to the limited time with their teachers, which increases the likelihood of mislearning playing techniques. To address this issue, we present Let\u2019s Frets - a modular guitar learning system that provides visual indicators and capturing of finger positions on a 3D-printed capacitive guitar fretboard. We based the design of Let\u2019s Frets on requirements collected through in-depth interviews with professional guitarists and teachers. In a user study (N=24), we evaluated the feedback modules of Let\u2019s Frets against fretboard charts. Our results show that visual indicators require the least time to realize new finger positions while a combination of visual indicators and position capturing yielded the highest playing accuracy. We conclude how Let\u2019s Frets enables independent practice sessions that can be translated to other musical instruments.",
    "call-number": "10.1145/3411764.3445595",
    "collection-number": "746",
    "collection-title": "CHI '21",
    "container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3411764.3445595",
    "event-place": "Yokohama, Japan",
    "ISBN": "9781450380966",
    "keyword": "capacitive sensing, musical instruments, support setup",
    "number": "Article 746",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Let\u2019s Frets! Assisting Guitar Students During Practice via Capacitive Sensing",
    "URL": "https://doi.org/10.1145/3411764.3445595"
  },
  {
    "id": "10.1145/3491102.3517552",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhao",
        "given": "Xuan"
      },
      {
        "family": "Fan",
        "given": "Mingming"
      },
      {
        "family": "Han",
        "given": "Teng"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent research proposed eyelid gestures for people with upper-body motor impairments (UMI) to interact with smartphones without finger touch. However, such eyelid gestures were designed by researchers. It remains unknown what eyelid gestures people with UMI would want and be able to perform. Moreover, other above-the-neck body parts (e.g., mouth, head) could be used to form more gestures. We conducted a user study in which 17 people with UMI designed above-the-neck gestures for 26 common commands on smartphones. We collected a total of 442 user-defined gestures involving the eyes, the mouth, and the head. Participants were more likely to make gestures with their eyes and preferred gestures that were simple, easy-to-remember, and less likely to draw attention from others. We further conducted a survey (N=24) to validate the usability and acceptance of these user-defined gestures. Results show that user-defined gestures were acceptable to both people with and without motor impairments.",
    "call-number": "10.1145/3491102.3517552",
    "collection-number": "1",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517552",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "user-defined gestures, gesture elicitation, above-the-neck gestures, people with motor impairments",
    "number": "Article 1",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Don\u2019t Want People to Look At Me Differently\u201d: Designing User-Defined Above-the-Neck Gestures for People with Upper Body Motor Impairments",
    "URL": "https://doi.org/10.1145/3491102.3517552"
  },
  {
    "id": "10.1145/3491102.3501964",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Vatavu",
        "given": "Radu-Daniel"
      },
      {
        "family": "Ungurean",
        "given": "Ovidiu-Ciprian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We examine touchscreen stroke-gestures and mid-air motion-gestures articulated by users with upper-body motor impairments with devices worn on the wrist, finger, and head. We analyze users\u2019 gesture input performance in terms of production time, articulation consistency, and kinematic measures, and contrast the performance of users with upper-body motor impairments with that of a control group of users without impairments. Our results, from two datasets of 7,290 stroke-gestures and 3,809 motion-gestures collected from 28 participants, reveal that users with upper-body motor impairments take twice as much time to produce stroke-gestures on wearable touchscreens compared to users without impairments, but articulate motion-gestures equally fast and with similar acceleration. We interpret our findings in the context of ability-based design and propose ten implications for accessible gesture input with upper-body wearables for users with upper-body motor impairments.",
    "call-number": "10.1145/3491102.3501964",
    "collection-number": "2",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501964",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "smartglasses, Motor impairments, accessible input, gesture input, wearables., smart rings, smartwatches",
    "number": "Article 2",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Gesture Input Articulation with Upper-Body Wearables for Users with Upper-Body Motor Impairments",
    "URL": "https://doi.org/10.1145/3491102.3501964"
  },
  {
    "id": "10.1145/3491102.3517658",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Motahar",
        "given": "Tamanna"
      },
      {
        "family": "Ghosh",
        "given": "Isha"
      },
      {
        "family": "Wiese",
        "given": "Jason"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Individuals with spinal cord injury (SCI) need to perform numerous self-care behaviors, some very frequently. Pressure reliefs (PRs), which prevent life-threatening pressure ulcers (PUs), are one such behavior. We conducted a qualitative study with seven individuals with severe SCI\u2014who depend on power wheelchairs\u2014to explore their current PR behavior and the potential for technology to facilitate PR adherence. While our participants were highly motivated to perform PRs because of prior PUs, we found that their understanding of how and when to perform a PR differed by individual, and that while they sometimes forgot to perform PR, in other cases contextual factors made it difficult to perform a PR. Our findings provide insight into the complexity of this design space, identify design considerations for designing technology to facilitate these behaviors, and demonstrate the opportunity for personal informatics to be more inclusive by supporting the needs of this population.",
    "call-number": "10.1145/3491102.3517658",
    "collection-number": "3",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517658",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Self-Care, Pressure Relief, Assistive Technologies, Spinal Cord Injury",
    "number": "Article 3",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Identifying factors that inhibit self-care behavior among individuals with severe spinal cord injury",
    "URL": "https://doi.org/10.1145/3491102.3517658"
  },
  {
    "id": "10.1145/3491102.3517458",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wentzel",
        "given": "Johann"
      },
      {
        "family": "Junuzovic",
        "given": "Sasa"
      },
      {
        "family": "Devine",
        "given": "James"
      },
      {
        "family": "Porter",
        "given": "John"
      },
      {
        "family": "Mott",
        "given": "Martez"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People with limited mobility often use multiple devices when interacting with computing systems, but little is known about the impact these multi-modal configurations have on daily computing use. A deeper understanding of the practices, preferences, obstacles, and workarounds associated with accessible multi-modal input can uncover opportunities to create more accessible computer applications and hardware. We explored how people with limited mobility use multi-modality through a three-part investigation grounded in the context of video games. First, we surveyed 43 people to learn about their preferred devices and configurations. Next, we conducted semi-structured interviews with 14 participants to understand their experiences and challenges with using, configuring, and discovering input setups. Lastly, we performed a systematic review of 74 YouTube videos to illustrate and categorize input setups and adaptations in-situ. We conclude with a discussion on how our findings can inform future accessibility research for current and emerging computing technologies.",
    "call-number": "10.1145/3491102.3517458",
    "collection-number": "4",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517458",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 4",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding How People with Limited Mobility Use Multi-Modal Input",
    "URL": "https://doi.org/10.1145/3491102.3517458"
  },
  {
    "id": "10.1145/3491102.3501931",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Tae Soo"
      },
      {
        "family": "Choi",
        "given": "DaEun"
      },
      {
        "family": "Choi",
        "given": "Yoonseo"
      },
      {
        "family": "Kim",
        "given": "Juho"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "End-users can potentially style and customize websites by editing them through in-browser developer tools. Unfortunately, end-users lack the knowledge needed to translate high-level styling goals into low-level code edits. We present Stylette, a browser extension that enables users to change the style of websites by expressing goals in natural language. By interpreting the user\u2019s goal with a large language model and extracting suggestions from our dataset of 1.7 million web components, Stylette generates a palette of CSS properties and values that the user can apply to reach their goal. A comparative study (N=40) showed that Stylette lowered the learning curve, helping participants perform styling changes 35% faster than those using developer tools. By presenting various alternatives for a single goal, the tool helped participants familiarize themselves with CSS through experimentation. Beyond CSS, our work can be expanded to help novices quickly grasp complex software or programming languages.",
    "call-number": "10.1145/3491102.3501931",
    "collection-number": "5",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501931",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "End-User Programming, Natural Language Interface, Web Design, Machine Learning",
    "number": "Article 5",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Stylette: Styling the Web with Natural Language",
    "URL": "https://doi.org/10.1145/3491102.3501931"
  },
  {
    "id": "10.1145/3491102.3501839",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Arakawa",
        "given": "Riku"
      },
      {
        "family": "Yakura",
        "given": "Hiromu"
      },
      {
        "family": "Kobayashi",
        "given": "Sosuke"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We demonstrate that recent natural language processing (NLP) techniques introduce a new paradigm of vocabulary learning that benefits from both micro and usage-based learning by generating and presenting the usages of foreign words based on the learner\u2019s context. Then, without allocating dedicated time for studying, the user can become familiarized with how the words are used by seeing the example usages during daily activities, such as Web browsing. To achieve this, we introduce VocabEncounter, a vocabulary-learning system that suitably encapsulates the given words into materials the user is reading in near real time by leveraging recent NLP techniques. After confirming the system\u2019s human-comparable quality of generating translated phrases by involving crowdworkers, we conducted a series of user studies, which demonstrated its effectiveness on learning vocabulary and its favorable experiences. Our work shows how NLP-based generation techniques can transform our daily activities into a field for vocabulary learning.",
    "call-number": "10.1145/3491102.3501839",
    "collection-number": "6",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501839",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "natural language processing, vocabulary learning, neural mechanical translation",
    "number": "Article 6",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "VocabEncounter: NMT-powered Vocabulary Learning by Presenting Computer-Generated Usages of Foreign Words into Users\u2019 Daily Lives",
    "URL": "https://doi.org/10.1145/3491102.3501839"
  },
  {
    "id": "10.1145/3491102.3501902",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Louie",
        "given": "Ryan"
      },
      {
        "family": "Gergle",
        "given": "Darren"
      },
      {
        "family": "Zhang",
        "given": "Haoqi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Context-aware applications have the potential to act opportunistically to facilitate human experiences and activities, from reminding us of places to perform personal activities, to identifying coincidental moments to engage in digitally-mediated shared experiences. However, despite the availability of context-detectors and programming frameworks for defining how such applications should trigger, designers lack support for expressing their human concepts of a situation and the experiences and activities they afford (e.g., situations to toss a frisbee) when context-features are made available at the level of locations (e.g., parks). This paper introduces Affinder, a block-based programming environment that supports constructing concept expressions that effectively translate their conceptions of a situation into a machine representation using available context features. During pilot testing, we discovered three bridging challenges that arise when expressing situations that cannot be encoded directly by a single context-feature. To overcome these bridging challenges, Affinder provides designers (1) an unlimited vocabulary search for discovering features they may have forgotten; (2) prompts for reflecting and expanding their concepts of a situation and ideas for foraging for context-features; and (3) simulation and repair tools for identifying and resolving issues with the precision of concept expressions on real use-cases. In a comparison study, we found that Affinder\u2019s core functions helped designers stretch their concepts of how to express a situation, find relevant context-features matching their concepts, and recognize when the concept expression operated differently than intended on real-world cases. These results show that Affinder and tools that support bridging can improve a designer\u2019s ability to express their concepts of a human situation into detectable machine representations\u2014thus pushing the boundaries of how computing systems support our activities in the world.",
    "call-number": "10.1145/3491102.3501902",
    "collection-number": "7",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501902",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "block-based programming, context-aware programming, context-features, bridging challenges, design fixation, expressing concepts of situations",
    "number": "Article 7",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Affinder: Expressing Concepts of Situations that Afford Activities using Context-Detectors",
    "URL": "https://doi.org/10.1145/3491102.3501902"
  },
  {
    "id": "10.1145/3491102.3517610",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cimolino",
        "given": "Gabriele"
      },
      {
        "family": "Graham",
        "given": "T.C. Nicholas"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Shared control is an emerging interaction paradigm in which a human and an AI partner collaboratively control a system. Shared control unifies human and artificial intelligence, making the human\u2019s interactions with computers more accessible, safe, precise, effective, creative, and playful. This form of interaction has independently emerged in contexts as varied as mobility assistance, driving, surgery, and digital games. These domains each have their own problems, terminology, and design philosophies. Without a common language for describing interactions in shared control, it is difficult for designers working in one domain to share their knowledge with designers working in another. To address this problem, we present a dimension space for shared control, based on a survey of 55 shared control systems from six different problem domains. This design space analysis tool enables designers to classify existing systems, make comparisons between them, identify higher-level design patterns, and imagine solutions to novel problems.",
    "call-number": "10.1145/3491102.3517610",
    "collection-number": "8",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517610",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Design Space Analysis, Shared Control, Human-Machine Cooperation",
    "number": "Article 8",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Two Heads Are Better Than One: A Dimension Space for Unifying Human and Artificial Intelligence in Shared Control",
    "URL": "https://doi.org/10.1145/3491102.3517610"
  },
  {
    "id": "10.1145/3491102.3517649",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jasim",
        "given": "Mahmood"
      },
      {
        "family": "Collins",
        "given": "Christopher"
      },
      {
        "family": "Sarvghad",
        "given": "Ali"
      },
      {
        "family": "Mahyar",
        "given": "Narges"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this study, we investigate how supporting serendipitous discovery and analysis of online product reviews can encourage readers to explore reviews more comprehensively prior to making purchase decisions. We propose two interventions \u2014 Exploration Metrics that can help readers understand and track their exploration patterns through visual indicators and a Bias Mitigation Model that intends to maximize knowledge discovery by suggesting sentiment and semantically diverse reviews. We designed, developed, and evaluated a text analytics system called Serendyze, where we integrated these interventions. We asked 100 crowd workers to use Serendyze to make purchase decisions based on product reviews. Our evaluation suggests that exploration metrics enabled readers to efficiently cover more reviews in a balanced way, and suggestions from the bias mitigation model influenced readers to make confident data-driven decisions. We discuss the role of user agency and trust in text-level analysis systems and their applicability in domains beyond review exploration.",
    "call-number": "10.1145/3491102.3517649",
    "collection-number": "9",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517649",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "product review exploration, bias mitigation model, serendipity",
    "number": "Article 9",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting Serendipitous Discovery and Balanced Analysis of Online Product Reviews with Interaction-Driven Metrics and Bias-Mitigating Suggestions",
    "URL": "https://doi.org/10.1145/3491102.3517649"
  },
  {
    "id": "10.1145/3491102.3501965",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Boggust",
        "given": "Angie"
      },
      {
        "family": "Hoover",
        "given": "Benjamin"
      },
      {
        "family": "Satyanarayan",
        "given": "Arvind"
      },
      {
        "family": "Strobelt",
        "given": "Hendrik"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Saliency methods\u00a0\u2014\u00a0techniques to identify the importance of input features on a model\u2019s output\u00a0\u2014\u00a0are a common step in understanding neural network behavior. However, interpreting saliency requires tedious manual inspection to identify and aggregate patterns in model behavior, resulting in ad hoc or cherry-picked analysis. To address these concerns, we present Shared Interest: metrics for comparing model reasoning (via saliency) to human reasoning (via ground truth annotations). By providing quantitative descriptors, Shared Interest enables ranking, sorting, and aggregating inputs, thereby facilitating large-scale systematic analysis of model behavior. We use Shared Interest to identify eight recurring patterns in model behavior, such as cases where contextual features or a subset of ground truth features are most important to the model. Working with representative real-world users, we show how Shared Interest can be used to decide if a model is trustworthy, uncover issues missed in manual analyses, and enable interactive probing.",
    "call-number": "10.1145/3491102.3501965",
    "collection-number": "10",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501965",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "saliency methods, interpretability, machine learning, human-computer interaction",
    "number": "Article 10",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Shared Interest: Measuring Human-AI Alignment to Identify Recurring Patterns in Model Behavior",
    "URL": "https://doi.org/10.1145/3491102.3501965"
  },
  {
    "id": "10.1145/3491102.3501862",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Grace",
        "given": "Kazjon"
      },
      {
        "family": "Finch",
        "given": "Elanor"
      },
      {
        "family": "Gulbransen-Diaz",
        "given": "Natalia"
      },
      {
        "family": "Henderson",
        "given": "Hamish"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Choosing what to eat requires navigating a large volume of information and various competing factors. While recommendation systems are an effective approach to assist users with this culinary decision-making, they typically prioritise similarity to a query or user profile to give relevant results. This can expose users to an increasingly narrow band of phenomena, which could compromise dietary diversity, a factor in dietary quality. We designed Q-Chef, which combines a recipe recommendation system with a personalised model of surprise, and conducted a study to identify if surprise-eliciting recipes affect food decisions. Our study utilises a rigorous thematic analysis with over 40 participants to explore how computational models of surprise influence recipe choice. We also explored how these factors differed when people were presented with \u201csurprising-yet-tasty\u201d recipes, as opposed to just \u201ctasty\u201d recipes, and identified that being presented with surprising choices is more likely to elicit situational interest and prompt reflection on choices. We conclude with a set of suggestions for the design of future surprise-eliciting recipe systems.",
    "call-number": "10.1145/3491102.3501862",
    "collection-number": "11",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501862",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mixed methods, curiosity, recommender systems, food, surprise",
    "number": "Article 11",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Q-Chef: The impact of surprise-eliciting systems on food-related decision-making",
    "URL": "https://doi.org/10.1145/3491102.3501862"
  },
  {
    "id": "10.1145/3491102.3517434",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hope",
        "given": "Tom"
      },
      {
        "family": "Tamari",
        "given": "Ronen"
      },
      {
        "family": "Hershcovich",
        "given": "Daniel"
      },
      {
        "family": "Kang",
        "given": "Hyeonsu B"
      },
      {
        "family": "Chan",
        "given": "Joel"
      },
      {
        "family": "Kittur",
        "given": "Aniket"
      },
      {
        "family": "Shahaf",
        "given": "Dafna"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Large repositories of products, patents and scientific papers offer an opportunity for building systems that scour millions of ideas and help users discover inspirations. However, idea descriptions are typically in the form of unstructured text, lacking key structure that is required for supporting creative innovation interactions. Prior work has explored idea representations that were either limited in expressivity, required significant manual effort from users, or dependent on curated knowledge bases with poor coverage. We explore a novel representation that automatically breaks up products into fine-grained functional aspects capturing the purposes and mechanisms of ideas, and use it to support important creative innovation interactions: functional search for ideas, and exploration of the design space around a focal problem by viewing related problem perspectives pooled from across many products. In user studies, our approach boosts the quality of creative search and inspirations, substantially outperforming strong baselines by 50-60%.",
    "call-number": "10.1145/3491102.3517434",
    "collection-number": "12",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517434",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 12",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Scaling Creative Inspiration with Fine-Grained Functional Aspects of Ideas",
    "URL": "https://doi.org/10.1145/3491102.3517434"
  },
  {
    "id": "10.1145/3491102.3501925",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yan",
        "given": "Zihan"
      },
      {
        "family": "Wu",
        "given": "Yufei"
      },
      {
        "family": "Zhang",
        "given": "Yang"
      },
      {
        "family": "Chen",
        "given": "Xiang 'Anthony'"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Often, emotional disorders are overlooked due to their lack of awareness, resulting in potential mental issues. Recent advances in sensing and inference technology provide a viable path to wearable facial-expression-based emotion recognition. However, most prior work has explored only laboratory settings and few platforms are geared towards end-users in everyday lives or provide personalized emotional suggestions to promote self-regulation. We present EmoGlass, an end-to-end wearable platform that consists of emotion detection glasses and an accompanying mobile application. Our single-camera-mounted glasses can detect seven facial expressions based on partial face images. We conducted a three-day out-of-lab study (N=15) to evaluate the performance of EmoGlass. We iterated on the design of the EmoGlass application for effective self-monitoring and awareness of users\u2019 daily emotional states. We report quantitative and qualitative findings, based on which we discuss design recommendations for future work on sensing and enhancing awareness of emotional health.",
    "call-number": "10.1145/3491102.3501925",
    "collection-number": "13",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501925",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Mobile health, Emotion sensing, Facial expression detection, Mental health, Wearable",
    "number": "Article 13",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "EmoGlass: an End-to-End AI-Enabled Wearable Platform for Enhancing Self-Awareness of Emotional Health",
    "URL": "https://doi.org/10.1145/3491102.3501925"
  },
  {
    "id": "10.1145/3491102.3501866",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Angie"
      },
      {
        "family": "Boltz",
        "given": "Alexander"
      },
      {
        "family": "Wang",
        "given": "Chun Wei"
      },
      {
        "family": "Lee",
        "given": "Min Kyung"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Prior research has studied the detrimental impact of algorithmic management on gig workers and strategies that workers devise in response. However, little work has investigated alternative platform designs to promote worker well-being, particularly from workers\u2019 own perspectives. We use a participatory design approach wherein workers explore their algorithmic imaginaries to co-design interventions that center their lived experiences, preferences, and well-being in algorithmic management. Our interview and participatory design sessions highlight how various design dimensions of algorithmic management, including information asymmetries and unfair, manipulative incentives, hurt worker well-being. Workers generate designs to address these issues while considering competing interests of the platforms, customers, and themselves, such as information translucency, incentives co-configured by workers and platforms, worker-centered data-driven insights for well-being, and collective driver data sharing. Our work offers a case study that responds to a call for designing worker-centered digital work and contributes to emerging literature on algorithmic work.",
    "call-number": "10.1145/3491102.3501866",
    "collection-number": "14",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501866",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "worker-centered work design, Algorithmic management, participatory design, worker well-being, gig work",
    "number": "Article 14",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Algorithmic Management Reimagined For Workers and By Workers: Centering Worker Well-Being in Gig Work",
    "URL": "https://doi.org/10.1145/3491102.3501866"
  },
  {
    "id": "10.1145/3491102.3517708",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kotturi",
        "given": "Yasmine"
      },
      {
        "family": "Johnson",
        "given": "Herman T"
      },
      {
        "family": "Skirpan",
        "given": "Michael"
      },
      {
        "family": "Fox",
        "given": "Sarah E"
      },
      {
        "family": "Bigham",
        "given": "Jeffrey P"
      },
      {
        "family": "Pavel",
        "given": "Amy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Even entrepreneurs whose businesses are not technological (e.g., handmade goods) need to be able to use a wide range of computing technologies in order to achieve their business goals. In this paper, we follow a participatory action research approach and collaborate with various stakeholders at an entrepreneurial co-working space to design \u201cTech Help Desk\u201d, an on-going technical service for entrepreneurs. Our model for technical assistance is strategic, in how it is designed to fit the context of local entrepreneurs, and responsive, in how it prioritizes emergent needs. From our engagements with 19 entrepreneurs and support personnel, we reflect on the challenges with existing technology support for non-technological entrepreneurs. Our work highlights the importance of ensuring technological support services can adapt based on entrepreneurs\u2019 ever-evolving priorities, preferences and constraints. Furthermore, we find technological support services should maintain broad technical support for entrepreneurs\u2019 long tail of computing challenges.",
    "call-number": "10.1145/3491102.3517708",
    "collection-number": "15",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517708",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "entrepreneurship, technical assistance, small business, community engagement, action research",
    "number": "Article 15",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Tech Help Desk: Support for Local Entrepreneurs Addressing the Long Tail of Computing Challenges",
    "URL": "https://doi.org/10.1145/3491102.3517708"
  },
  {
    "id": "10.1145/3491102.3502049",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lustig",
        "given": "Caitlin"
      },
      {
        "family": "Konrad",
        "given": "Artie"
      },
      {
        "family": "Brubaker",
        "given": "Jed R."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "It is difficult to design systems that honor the complex and often contradictory emotions that can be surfaced by sensitive encounters with recommender systems. To explore the design and ethical considerations in this space, we interviewed 20 people who had recently seen sensitive content through Facebook\u2019s Memories feature. Interviewees typically described how (1) expectedness, (2) context of viewing, and (3) what we describe as \u201caffective sense-making\u201d were important factors for how they perceived \u201cbittersweet\u201d content, a sensitizing concept from our interviews that we expand upon. To address these user needs, we pose provocations to support critical work in this area and we suggest that researchers and designers: (1) draw inspiration from no/low-technology artifacts, (2) use empirical research to identify contextual features that have negative impacts on users, and (3) conduct user studies on affective sense-making. CAUTION: This paper discusses difficult subject matter related to death and relationships.",
    "call-number": "10.1145/3491102.3502049",
    "collection-number": "16",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502049",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "breakup, death, social media, technology-mediated reflection",
    "number": "Article 16",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing for the Bittersweet: Improving Sensitive Experiences with Recommender Systems",
    "URL": "https://doi.org/10.1145/3491102.3502049"
  },
  {
    "id": "10.1145/3491102.3517492",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Simeone",
        "given": "Adalberto L."
      },
      {
        "family": "Cools",
        "given": "Robbe"
      },
      {
        "family": "Depuydt",
        "given": "Stan"
      },
      {
        "family": "Gomes",
        "given": "Jo\u00e3o Maria"
      },
      {
        "family": "Goris",
        "given": "Piet"
      },
      {
        "family": "Grocott",
        "given": "Joseph"
      },
      {
        "family": "Esteves",
        "given": "Augusto"
      },
      {
        "family": "Gerling",
        "given": "Kathrin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this paper we present Immersive Speculative Enactments (ISEs), a novel concept that extends conventional Speculative Enactments to Virtual Reality. Through ISEs, participants are immersed in a speculative world depicted by the designers and can engage with it in its truest envisioned form. We explore this concept via four scenarios with increasing technological uncertainty: a glimpse in the daily life of the parent of a newborn baby; a Mixed Reality experience supporting hybrid classrooms; two wearable devices that present a pet\u2019s emotional state and needs; and an enactment on the effect of communication delay across interplanetary distances. We discuss the concept of ISEs and contrast them to other forms of speculation, provide guidelines on how to design them, as well as reflecting on the challenges, limitations, and potential associated with the role of ISEs in the HCI discourse.",
    "call-number": "10.1145/3491102.3517492",
    "collection-number": "17",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517492",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Cross-Reality, Childcare, Speculative Enactments, Space Exploration., Quantified Pets, Design Fiction, Virtual Reality",
    "number": "Article 17",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Immersive Speculative Enactments: Bringing Future Scenarios and Technology to Life Using Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517492"
  },
  {
    "id": "10.1145/3491102.3501899",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Baughan",
        "given": "Amanda"
      },
      {
        "family": "Zhang",
        "given": "Mingrui Ray"
      },
      {
        "family": "Rao",
        "given": "Raveena"
      },
      {
        "family": "Lukoff",
        "given": "Kai"
      },
      {
        "family": "Schaadhardt",
        "given": "Anastasia"
      },
      {
        "family": "Butler",
        "given": "Lisa D."
      },
      {
        "family": "Hiniker",
        "given": "Alexis"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Many people have experienced mindlessly scrolling on social media. We investigated these experiences through the lens of normative dissociation: total cognitive absorption, characterized by diminished self-awareness and reduced sense of agency. To explore user experiences of normative dissociation and how design affects the likelihood of normative dissociation, we deployed Chirp, a custom Twitter client, to 43 U.S. participants. Experience sampling and interviews revealed that sometimes, becoming absorbed in normative dissociation on social media felt like a beneficial break. However, people also reported passively slipping into normative dissociation, such that they failed to absorb any content and were left feeling like they had wasted their time. We found that designed interventions\u2013including custom lists, reading history labels, time limit dialogs, and usage statistics\u2013reduced normative dissociation. Our findings demonstrate that interaction designs intended to capture attention likely do so by harnessing people\u2019s natural inclination to seek normative dissociation experiences. This suggests that normative dissociation may be a more productive framing than addiction for discussing social media overuse.",
    "call-number": "10.1145/3491102.3501899",
    "collection-number": "18",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501899",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design, social media addiction, social media, normative dissociation, dissociation",
    "number": "Article 18",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Don\u2019t Even Remember What I Read\u201d: How Design Influences Dissociation on Social Media",
    "URL": "https://doi.org/10.1145/3491102.3501899"
  },
  {
    "id": "10.1145/3491102.3502076",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gauthier",
        "given": "Robert P"
      },
      {
        "family": "Costello",
        "given": "Mary Jean"
      },
      {
        "family": "Wallace",
        "given": "James R"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recovery from addiction is a journey that requires a lifetime of support from a strong network of peers. Many people seek out this support through online communities, like those on Reddit. However, as these communities developed outside of existing aid groups and medical practice, it is unclear how they enable recovery. Their scale also limits researchers\u2019 ability to engage through traditional qualitative research methods. To study these groups, we performed a topic-guided thematic analysis that used machine-generated topic models to purposively sample from two recovery subreddits: r/stopdrinking and r/OpiatesRecovery. We show that these communities provide access to an experienced and accessible support group whose discussions include consequences, reflections, and celebrations, but that also play a distinct metacommunicative role in supporting formal treatment. We discuss how these communities can act as knowledge sources to improve in-person recovery support and medical practice, and how computational techniques can enable HCI researchers to study communities at scale.",
    "call-number": "10.1145/3491102.3502076",
    "collection-number": "20",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502076",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Reddit, thematic analysis, online communities, addiction, machine learning",
    "number": "Article 20",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Will Not Drink With You Today\u201d: A Topic-Guided Thematic Analysis of Addiction Recovery on Reddit",
    "URL": "https://doi.org/10.1145/3491102.3502076"
  },
  {
    "id": "10.1145/3491102.3517498",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bowie-DaBreo",
        "given": "Dionne"
      },
      {
        "family": "Sas",
        "given": "Corina"
      },
      {
        "family": "Iles-Smith",
        "given": "Heather"
      },
      {
        "family": "S\u00fcnram-Lea",
        "given": "Sandra"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Apps for depression can increase access to mental health care but concerns abound with disparities between academic development of apps and those available through app stores. Reviews highlighted ethical shortcomings of these self-management tools, with a need for greater insight into how ethical issues are experienced by users. We addressed these gaps by exploring user reviews of such apps to better understand user experiences and ethical issues. We conducted a thematic analysis of 2,217 user reviews sampled from 40 depression apps in Google Play and Apple App Store, totaling over 77,500 words. Users reported positive and negative experiences, with ethical implications evident in areas of benefits, adverse effects, access, usability and design, support, commercial models, autonomy, privacy, and transparency. We integrated our elements of ethically designed apps for depression and principles of nonmaleficence, beneficence, justice, autonomy, and virtue, and we conclude with implications for ethical design of apps for depression.",
    "call-number": "10.1145/3491102.3517498",
    "collection-number": "21",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517498",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Ethics, Mobile mental health, User experiences, Depression, User reviews",
    "number": "Article 21",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "User Perspectives and Ethical Experiences of Apps for Depression: A Qualitative Analysis of User Reviews",
    "URL": "https://doi.org/10.1145/3491102.3517498"
  },
  {
    "id": "10.1145/3491102.3501861",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wagener",
        "given": "Nadine"
      },
      {
        "family": "Niess",
        "given": "Jasmin"
      },
      {
        "family": "Rogers",
        "given": "Yvonne"
      },
      {
        "family": "Sch\u00f6ning",
        "given": "Johannes"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Immersive interactive technologies such as virtual reality (VR) have the potential to foster well-being. While VR applications have been successfully used to evoke positive emotions through the presetting of light, colour and scenery, the experiential potential of allowing users to independently create a virtual environment (VE) has not yet been sufficiently addressed. To that end, we explore how the autonomous design of a VE can affect emotional engagement and well-being. We present Mood Worlds \u2013 a VR application allowing users to visualise their emotions by self-creating a VE. In an exploratory evaluation (N=16), we found that Mood Worlds is an effective tool supporting emotional engagement. Additionally, we found that an autonomous creation process in VR increases positive emotions and well-being. Our work shows that VR can be an effective tool to visualise emotions, thereby increasing positive affect. We discuss opportunities and design requirements for VR as positive technology.",
    "call-number": "10.1145/3491102.3501861",
    "collection-number": "22",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501861",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Emotions, Well-being, Emotion Regulation, Virtual Reality, Happiness, Positive Technology",
    "number": "Article 22",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mood Worlds: A Virtual Environment for Autonomous Emotional Expression",
    "URL": "https://doi.org/10.1145/3491102.3501861"
  },
  {
    "id": "10.1145/3491102.3517676",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Reipschl\u00e4ger",
        "given": "Patrick"
      },
      {
        "family": "Brudy",
        "given": "Frederik"
      },
      {
        "family": "Dachselt",
        "given": "Raimund"
      },
      {
        "family": "Matejka",
        "given": "Justin"
      },
      {
        "family": "Fitzmaurice",
        "given": "George"
      },
      {
        "family": "Anderson",
        "given": "Fraser"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Analysis of human motion data can reveal valuable insights about the utilization of space and interaction of humans with their environment. To support this, we present AvatAR, an immersive analysis environment for the in-situ visualization of human motion data, that combines 3D trajectories with virtual avatars showing people\u2019s detailed movement and posture. Additionally, we describe how visualizations can be embedded directly into the environment, showing what a person looked at or what surfaces they touched, and how the avatar\u2019s body parts can be used to access and manipulate those visualizations. AvatAR combines an AR HMD with a tablet to provide both mid-air and touch interaction for system control, as well as an additional overview device to help users navigate the environment. We implemented a prototype and present several scenarios to show that AvatAR can enhance the analysis of human motion data by making data not only explorable, but experienceable.",
    "call-number": "10.1145/3491102.3517676",
    "collection-number": "23",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517676",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "analysing space utilization, human motion data, In-situ visualisation, augmented/mixed reality, motion analysis, Immersive Analytics",
    "number": "Article 23",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AvatAR: An Immersive Analysis Environment for Human Motion Data Combining Interactive 3D Avatars and Trajectories",
    "URL": "https://doi.org/10.1145/3491102.3517676"
  },
  {
    "id": "10.1145/3491102.3517550",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hubenschmid",
        "given": "Sebastian"
      },
      {
        "family": "Wieland",
        "given": "Jonathan"
      },
      {
        "family": "Fink",
        "given": "Daniel Immanuel"
      },
      {
        "family": "Batch",
        "given": "Andrea"
      },
      {
        "family": "Zagermann",
        "given": "Johannes"
      },
      {
        "family": "Elmqvist",
        "given": "Niklas"
      },
      {
        "family": "Reiterer",
        "given": "Harald"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The nascent field of mixed reality is seeing an ever-increasing need for user studies and field evaluation, which are particularly challenging given device heterogeneity, diversity of use, and mobile deployment. Immersive analytics tools have recently emerged to support such analysis in situ, yet the complexity of the data also warrants an ex-situ analysis using more traditional non-immersive visual analytics setups. To bridge the gap between both approaches, we introduce ReLive: a mixed-immersion visual analytics framework for exploring and analyzing mixed reality user studies. ReLive combines an in-situ virtual reality view with a complementary ex-situ desktop view. While the virtual reality view allows users to relive interactive spatial recordings replicating the original study, the synchronized desktop view provides a familiar interface for analyzing aggregated data. We validated our concepts in a two-step evaluation consisting of a design walkthrough and an empirical expert user study.",
    "call-number": "10.1145/3491102.3517550",
    "collection-number": "24",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517550",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "data visualization, visual analytics, virtual reality., Immersive analytics",
    "number": "Article 24",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ReLive: Bridging In-Situ and Ex-Situ Visual Analytics for Analyzing Mixed Reality User Studies",
    "URL": "https://doi.org/10.1145/3491102.3517550"
  },
  {
    "id": "10.1145/3491102.3501859",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Benjamin"
      },
      {
        "family": "Cordeil",
        "given": "Maxime"
      },
      {
        "family": "Prouzeau",
        "given": "Arnaud"
      },
      {
        "family": "Jenny",
        "given": "Bernhard"
      },
      {
        "family": "Dwyer",
        "given": "Tim"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As mixed-reality (MR) technologies become more mainstream, the delineation between data visualisations displayed on screens or other surfaces and those floating in space becomes increasingly blurred. Rather than the choice of using either a 2D surface or the 3D space for visualising data being a dichotomy, we argue that users should have the freedom to transform visualisations seamlessly between the two as needed. However, the design space for such transformations is large, and practically uncharted. To explore this, we first establish an overview of the different states that a data visualisation can take in MR, followed by how transformations between these states can facilitate common visualisation tasks. We then describe a design space of how these transformations function, in terms of the different stages throughout the transformation, and the user interactions and input parameters that affect it. This design space is then demonstrated with multiple exemplary techniques based in MR.",
    "call-number": "10.1145/3491102.3501859",
    "collection-number": "25",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501859",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "animated transitions, direct manipulation, mixed reality, Immersive Analytics, visualisation",
    "number": "Article 25",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Design Space For Data Visualisation Transformations Between 2D And 3D In Mixed-Reality Environments",
    "URL": "https://doi.org/10.1145/3491102.3501859"
  },
  {
    "id": "10.1145/3491102.3501841",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Eulzer",
        "given": "Pepe"
      },
      {
        "family": "Rockenfeller",
        "given": "Robert"
      },
      {
        "family": "Lawonn",
        "given": "Kai"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The helical axis is a common tool used in biomechanical modeling to parameterize the motion of rigid objects. It encodes an object\u2019s rotation around and translation along a unique axis. Visualizations of helical axes have helped to make kinematic data tangible. However, the analysis process often remains tedious, especially if complex motions are examined. We identify multiple key challenges: the absence of interactive tools for the computation and handling of helical axes, visual clutter in axis representations, and a lack of contextualization. We solve these issues by providing the first generalized framework for kinematic analysis with helical axes. Axis sets can be computed on-demand, interactively filtered, and explored in multiple coordinated views. We iteratively developed and evaluated the HAExplorer with active biomechanics researchers. Our results show that the techniques we introduce open up the possibility to analyze non-planar, compound, and interdependent motion data.",
    "call-number": "10.1145/3491102.3501841",
    "collection-number": "26",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501841",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "coordinated views, focus and context, biomechanics, helical axis, contextualization, screw axis",
    "number": "Article 26",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "HAExplorer: Understanding Interdependent Biomechanical Motions with Interactive Helical Axes",
    "URL": "https://doi.org/10.1145/3491102.3501841"
  },
  {
    "id": "10.1145/3491102.3501921",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Islam",
        "given": "Alaul"
      },
      {
        "family": "Aravind",
        "given": "Ranjini"
      },
      {
        "family": "Blascheck",
        "given": "Tanja"
      },
      {
        "family": "Bezerianos",
        "given": "Anastasia"
      },
      {
        "family": "Isenberg",
        "given": "Petra"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present the findings of four studies related to the visualization of sleep data on wearables with two form factors: smartwatches and fitness bands. Our goal was to understand the interests, preferences, and effectiveness of different sleep visualizations by form factor. In a survey, we showed that wearers were mostly interested in weekly sleep duration, and nightly sleep phase data. Visualizations of this data were generally preferred over purely text-based representations, and the preferred chart type for fitness bands, and smartwatches was often the same. In one in-person pilot study, and two crowdsourced studies, we then tested the effectiveness of the most preferred representations for different tasks, and found that participants performed simple tasks effectively on both form factors but more complex tasks benefited from the larger smartwatch size. Lastly, we reflect on our crowdsourced study methodology for testing the effectiveness of visualizations for wearables. Supplementary material is available at https://osf.io/yz8ar/.",
    "call-number": "10.1145/3491102.3501921",
    "collection-number": "27",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501921",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "smartphones, smartwatch, fitness trackers, glanceable visualization",
    "number": "Article 27",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Preferences and Effectiveness of Sleep Data Visualizations for Smartwatches and Fitness Bands",
    "URL": "https://doi.org/10.1145/3491102.3501921"
  },
  {
    "id": "10.1145/3491102.3517530",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lan",
        "given": "Xingyu"
      },
      {
        "family": "Wu",
        "given": "Yanqiu"
      },
      {
        "family": "Shi",
        "given": "Yang"
      },
      {
        "family": "Chen",
        "given": "Qing"
      },
      {
        "family": "Cao",
        "given": "Nan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent work has highlighted that emotion is key to the user experience with data stories. However, limited attention has been paid to negative emotions specifically. This work investigates the outcomes of negative emotions in the context of serious data stories and examines how they can be augmented by design methods from the perspectives of both storytellers and viewers. First, we conducted a workshop with 9 data story experts to understand the possible benefits of eliciting negative emotions in serious data stories and 19 potential design methods that contribute to negative emotions. Based on the findings from the workshop, we then conducted a lab study with 35 participants to explore the outcomes of eliciting negative emotions as well as the effectiveness of the design methods. The results indicated that negative emotions mainly facilitated contemplative experiences and long-term memory. Besides, the design methods showed varied effectiveness in augmenting negative emotions and being recalled.",
    "call-number": "10.1145/3491102.3517530",
    "collection-number": "28",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517530",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "data storytelling, affective design, user experience",
    "number": "Article 28",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Negative Emotions, Positive Outcomes? Exploring the Communication of Negativity in Serious Data Stories",
    "URL": "https://doi.org/10.1145/3491102.3517530"
  },
  {
    "id": "10.1145/3491102.3501972",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Setlur",
        "given": "Vidya"
      },
      {
        "family": "Tory",
        "given": "Melanie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Chatbots have garnered interest as conversational interfaces for a variety of tasks. While general design guidelines exist for chatbot interfaces, little work explores analytical chatbots that support conversing with data. We explore Gricean Maxims to help inform the basic design of effective conversational interaction. We also draw inspiration from natural language interfaces for data exploration to support ambiguity and intent handling. We ran Wizard of Oz studies with 30 participants to evaluate user expectations for text and voice chatbot design variants. Results identified preferences for intent interpretation and revealed variations in user expectations based on the interface affordances. We subsequently conducted an exploratory analysis of three analytical chatbot systems (text + chart, voice + chart, voice-only) that implement these preferred design variants. Empirical evidence from a second 30-participant study informs implications specific to data-driven conversation such as interpreting intent, data orientation, and establishing trust through appropriate system responses.",
    "call-number": "10.1145/3491102.3501972",
    "collection-number": "29",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501972",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "chatbots, ambiguity, visual analysis, refinement., repair, intent",
    "number": "Article 29",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How do you Converse with an Analytical Chatbot? Revisiting Gricean Maxims for Designing Analytical Conversational Behavior",
    "URL": "https://doi.org/10.1145/3491102.3501972"
  },
  {
    "id": "10.1145/3491102.3502010",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Koval",
        "given": "Morgane"
      },
      {
        "family": "Jansen",
        "given": "Yvonne"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Making time estimates, such as how long a given task might take, frequently leads to inaccurate predictions because of an optimistic bias. Previous attempts to alleviate this bias, including decomposing the task into smaller components and listing potential surprises, have not shown any major improvement. This article builds on the premise that these procedures may have failed because they involve compound probabilities and mixture distributions which are difficult to compute in one\u2019s head. We hypothesize that predictive visualizations of such distributions would facilitate the estimation of task durations. We conducted a crowdsourced study in which 145 participants provided different estimates of overall and sub-task durations and we used these to generate predictive visualizations of the resulting mixture distributions. We compared participants\u2019 initial estimates with their updated ones and found compelling evidence that predictive visualizations encourage less optimistic estimates.",
    "call-number": "10.1145/3491102.3502010",
    "collection-number": "30",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502010",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "predictive visualization, Planning fallacy",
    "number": "Article 30",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Do You See What You Mean? Using Predictive Visualizations to Reduce Optimism in Duration Estimates",
    "URL": "https://doi.org/10.1145/3491102.3502010"
  },
  {
    "id": "10.1145/3491102.3517675",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kekulluoglu",
        "given": "Dilara"
      },
      {
        "family": "Vaniea",
        "given": "Kami"
      },
      {
        "family": "Magdy",
        "given": "Walid"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Changing a Twitter account\u2019s privacy setting between public and protected changes the visibility of past tweets. By inspecting the privacy setting of more than 100K Twitter users over 3 months, we noticed that over 40% of those users changed their privacy setting at least once with around 16% changing it over 5 times. This observation motivated us to explore the reasons why people switch their privacy settings. We studied these switching phenomena quantitatively by comparing the tweeting behaviour of users when public vs protected, and qualitatively using two follow-up surveys (n=100, n=324) to understand potential reasoning behind the observed behaviours. Our quantitative analysis shows that users who switch privacy settings mention others and share hashtags more when their setting is public. Our surveys highlighted that users turn protected to share personal content and regulate boundaries while they turn public to interact with others in ways the protected setting prevents.",
    "call-number": "10.1145/3491102.3517675",
    "collection-number": "31",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517675",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Online Social Networks, Privacy, Privacy Settings, Security, Twitter",
    "number": "Article 31",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Privacy Switching Behaviour on Twitter",
    "URL": "https://doi.org/10.1145/3491102.3517675"
  },
  {
    "id": "10.1145/3491102.3517467",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wu",
        "given": "Yuxi"
      },
      {
        "family": "Edwards",
        "given": "W. Keith"
      },
      {
        "family": "Das",
        "given": "Sauvik"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People feel concerned, angry, and powerless when subjected to surveillance, data breaches and other privacy-violating experiences with institutions (PVEIs). Collective action may empower groups of people affected by a PVEI to jointly demand redress, but a necessary first step is for the collective to agree on demands. We designed a sensitizing prototype to explore how to shepherd a collective to generate a unified set of demands for redress in response to a triggering PVEI. We found that collectives can converge on high-priority concerns and demands for redress, and that many of their demands indicated preferences for broad reform. We then gathered a panel of security and privacy experts to react to the collective\u2019s demands. Experts were dismissive, preferring incremental measures that cleanly mapped onto existing legal structures. We argue this misalignment may help uphold the power chasm between data-harvesting institutions and the individuals whose personal data they monetize.",
    "call-number": "10.1145/3491102.3517467",
    "collection-number": "32",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517467",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "user privacy, collective action",
    "number": "Article 32",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cA Reasonable Thing to Ask For\u201d: Towards a Unified Voice in Privacy Collective Action",
    "URL": "https://doi.org/10.1145/3491102.3517467"
  },
  {
    "id": "10.1145/3491102.3517534",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Oesch",
        "given": "Sean"
      },
      {
        "family": "Ruoti",
        "given": "Scott"
      },
      {
        "family": "Simmons",
        "given": "James"
      },
      {
        "family": "Gautam",
        "given": "Anuj"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "There is limited information regarding how users employ password managers in the wild and why they use them in that manner. To address this knowledge gap, we conduct observational interviews with 32 password manager users. Using grounded theory, we identify four theories describing the processes and rationale behind participants\u2019 usage of password managers. We find that many users simultaneously use both a browser-based and a third-party manager, using each as a backup for the other, with this new paradigm having intriguing usability and security implications. Users also eschew generated passwords because these passwords are challenging to enter and remember when the manager is unavailable, necessitating new generators that create easy-to-enter and remember passwords. Additionally, the credential audits provided by most managers overwhelm users, limiting their utility and indicating a need for more proactive and streamlined notification systems. We also discuss mobile usage, adoption and promotion, and other related topics.",
    "call-number": "10.1145/3491102.3517534",
    "collection-number": "33",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517534",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "observational study, password manager, grounded theory",
    "number": "Article 33",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt Basically Started Using Me:\u201d An Observational Study of Password Manager Usage",
    "URL": "https://doi.org/10.1145/3491102.3517534"
  },
  {
    "id": "10.1145/3491102.3517688",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Windl",
        "given": "Maximiliane"
      },
      {
        "family": "Henze",
        "given": "Niels"
      },
      {
        "family": "Schmidt",
        "given": "Albrecht"
      },
      {
        "family": "Feger",
        "given": "Sebastian S."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Users avoid engaging with privacy policies because they are lengthy and complex, making it challenging to retrieve relevant information. In response, research proposed contextual privacy policies (CPPs) that embed relevant privacy information directly into their affiliated contexts. To date, CPPs are limited to concept showcases. This work evolves CPPs into a production tool that automatically extracts and displays concise policy information. We first evaluated the technical functionality on the US\u2019s 500 most visited websites with 59 participants. Based on our results, we further revised the tool to deploy it in the wild with 11 participants over ten days. We found that our tool is effective at embedding CPP information on websites. Moreover, we found that the tool\u2019s usage led to more reflective privacy behavior, making CPPs powerful in helping users understand the consequences of their online activities. We contribute design implications around CPP presentation to inform future systems design.",
    "call-number": "10.1145/3491102.3517688",
    "collection-number": "34",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517688",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "contextual privacy, privacy, online services, privacy policies",
    "number": "Article 34",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Automating Contextual Privacy Policies: Design and Evaluation of a Production Tool for Digital Consumer Privacy Awareness",
    "URL": "https://doi.org/10.1145/3491102.3517688"
  },
  {
    "id": "10.1145/3491102.3517520",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Yifang"
      },
      {
        "family": "Caine",
        "given": "Kelly"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People share photos on Social Networks Sites, but at the same time want to keep some photo content private. This tension between sharing and privacy has led researchers to try to solve this problem, but without considering users\u2019 needs. To fill this gap, we present a novel interface that expands privacy options beyond recipient-control (R). Our system can also flag sensitive content (C) and obfuscate (O) it (RCO). We then describe the results of a two-step experiment that compares RCO with two alternative interfaces - (R) which mimics existing SNS privacy options by providing recipient control, and a system that in addition to recipient control also flags sensitive content (RC). Results suggest RC performs worse than R regarding perceived privacy risks, willingness to share, and user experience. However, RCO, which provides obfuscation options, restores these metrics to the same levels as R. We conclude by providing insights on system implementation.",
    "call-number": "10.1145/3491102.3517520",
    "collection-number": "35",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517520",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "security, sensitive content, user experience, photo obfuscation, photo privacy, privacy",
    "number": "Article 35",
    "number-of-pages": "25",
    "page": "1\u201325",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Obfuscation Remedies Harms Arising from Content Flagging of Photos",
    "URL": "https://doi.org/10.1145/3491102.3517520"
  },
  {
    "id": "10.1145/3491102.3517497",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Schoop",
        "given": "Eldon"
      },
      {
        "family": "Zhou",
        "given": "Xin"
      },
      {
        "family": "Li",
        "given": "Gang"
      },
      {
        "family": "Chen",
        "given": "Zhourong"
      },
      {
        "family": "Hartmann",
        "given": "Bjoern"
      },
      {
        "family": "Li",
        "given": "Yang"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "UI designers often correct false affordances and improve the discoverability of features when users have trouble determining if elements are tappable. We contribute a novel system that models the perceived tappability of mobile UI elements with a vision-based deep neural network and helps provide design insights with dataset-level and instance-level explanations of model predictions. Our system retrieves designs from similar mobile UI examples from our dataset using the latent space of our model. We also contribute a novel use of an interpretability algorithm, XRAI, to generate a heatmap of UI elements that contribute to a given tappability prediction. Through several examples, we show how our system can help automate elements of UI usability analysis and provide insights for designers to iterate their designs. In addition, we share findings from an exploratory evaluation with professional designers to learn how AI-based tools can aid UI design and evaluation for tappability issues.",
    "call-number": "10.1145/3491102.3517497",
    "collection-number": "36",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517497",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Interpretability, Deep Learning, Mobile UIs, Explainable AI",
    "number": "Article 36",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Predicting and Explaining Mobile UI Tappability with Vision Modeling and Saliency Analysis",
    "URL": "https://doi.org/10.1145/3491102.3517497"
  },
  {
    "id": "10.1145/3491102.3517729",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Son",
        "given": "Kihoon"
      },
      {
        "family": "Kim",
        "given": "Kyungmin"
      },
      {
        "family": "Hyun",
        "given": "Kyung Hoon"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The Bayesian information gain (BIG) framework has garnered significant interest as an interaction method for predicting a user\u2019s intended target based on a user\u2019s input. However, the BIG framework is constrained to goal-oriented cases, which renders it difficult to support changing goal-oriented cases such as design exploration. During the design exploration process, the design direction is often undefined and may vary over time. The designer\u2019s mental model specifying the design direction is sequentially updated through the information-retrieval process. Therefore, tracking the change point of a user\u2019s goal is crucial for supporting an information exploration. We introduce the BIGexplore framework for changing goal-oriented cases. BIGexplore detects transitions in a user\u2019s browsing behavior as well as the user\u2019s next target. Furthermore, a user study on BIGexplore confirms that the computational cost is significantly reduced compared with the existing BIG framework, and it plausibly detects the point where the user changes goals.",
    "call-number": "10.1145/3491102.3517729",
    "collection-number": "37",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517729",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "information exploration, Bayesian information gain, design exploration, computational interaction, information retrieval",
    "number": "Article 37",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "BIGexplore: Bayesian Information Gain Framework for Information Exploration",
    "URL": "https://doi.org/10.1145/3491102.3517729"
  },
  {
    "id": "10.1145/3491102.3502023",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Moon",
        "given": "Hee-Seung"
      },
      {
        "family": "Do",
        "given": "Seungwon"
      },
      {
        "family": "Kim",
        "given": "Wonjae"
      },
      {
        "family": "Seo",
        "given": "Jiwon"
      },
      {
        "family": "Chang",
        "given": "Minsuk"
      },
      {
        "family": "Lee",
        "given": "Byungjoo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The simulation of user behavior with deep reinforcement learning agents has shown some recent success. However, the inverse problem, that is, inferring the free parameters of the simulator from observed user behaviors, remains challenging to solve. This is because the optimization of the new action policy of the simulated agent, which is required whenever the model parameters change, is computationally impractical. In this study, we introduce a network modulation technique that can obtain a generalized policy that immediately adapts to the given model parameters. Further, we demonstrate that the proposed technique improves the efficiency of user simulator-based inference by eliminating the need to obtain an action policy for novel model parameters. We validated our approach using the latest user simulator for point-and-click behavior. Consequently, we succeeded in inferring the user\u2019s cognitive parameters and intrinsic reward settings with less than 1/1000 computational power to those of existing methods.",
    "call-number": "10.1145/3491102.3502023",
    "collection-number": "38",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502023",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "inverse modeling, point-and-click, simulation model",
    "number": "Article 38",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Speeding up Inference with User Simulators through Policy Modulation",
    "URL": "https://doi.org/10.1145/3491102.3502023"
  },
  {
    "id": "10.1145/3491102.3501913",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Hyunchul"
      },
      {
        "family": "Hornb\u00e6k",
        "given": "Kasper"
      },
      {
        "family": "Lee",
        "given": "Byungjoo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "When giving input with a button, users follow one of two strategies: (1) react to the output from the computer or (2) proactively act in anticipation of the output from the computer. We propose a technique to quantify reactiveness and proactiveness to determine the degree and characteristics of each input strategy. The technique proposed in this study uses only screen recordings and does not require instrumentation beyond the input logs. The likelihood distribution of the time interval between the button inputs and system outputs, which is uniquely determined for each input strategy, is modeled. Then the probability that each observed input/output pair originates from a specific strategy is estimated along with the parameters of the corresponding likelihood distribution. In two empirical studies, we show how to use the technique to answer questions such as how to design animated transitions and how to predict a player\u2019s score in real-time games.",
    "call-number": "10.1145/3491102.3501913",
    "collection-number": "40",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501913",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Button input, temporal pointing, reaction, anticipation",
    "number": "Article 40",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Quantifying Proactive and Reactive Button Input",
    "URL": "https://doi.org/10.1145/3491102.3501913"
  },
  {
    "id": "10.1145/3491102.3517609",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bremer",
        "given": "Christina"
      },
      {
        "family": "Knowles",
        "given": "Bran"
      },
      {
        "family": "Friday",
        "given": "Adrian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "By CHI 2022, fifteen years will have passed since the emergence of Sustainable HCI (SHCI), which now constitutes an important subfield of HCI. In this paper, we draw on two SHCI corpora to ask: Has SHCI progressed? How has the field responded to prominent critiques? Have we identified and adopted constructive strategies for impacting environmental unsustainability? We further show the wide array of competencies SHCI researchers have been called to develop, and how this has been reflected in subsequent work. Our analysis identifies significant shifts in the SHCI landscape, toward research that is diverse and holistic, but also away from efforts to address the urgent climate crisis. We posit that SHCI has tended to take on far more than it could reasonably expect to deliver, and propose \u2018Green Policy informatics\u2019 as a pathway that enables SHCI to leverage a more traditional HCI skillset in addressing climate change.",
    "call-number": "10.1145/3491102.3517609",
    "collection-number": "41",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517609",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Climate Change, Sustainable HCI, Sustainability, Reflective HCI, Policy",
    "number": "Article 41",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Have We Taken On Too Much?: A Critical Review of the Sustainable HCI Landscape",
    "URL": "https://doi.org/10.1145/3491102.3517609"
  },
  {
    "id": "10.1145/3491102.3502043",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nepal",
        "given": "Subigya"
      },
      {
        "family": "Wang",
        "given": "Weichen"
      },
      {
        "family": "Vojdanovski",
        "given": "Vlado"
      },
      {
        "family": "Huckins",
        "given": "Jeremy F"
      },
      {
        "family": "daSilva",
        "given": "Alex"
      },
      {
        "family": "Meyer",
        "given": "Meghan"
      },
      {
        "family": "Campbell",
        "given": "Andrew"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The COVID-19 pandemic continues to affect the daily life of college students, impacting their social life, education, stress levels and overall mental well-being. We study and assess behavioral changes of N=180 undergraduate college students one year prior to the pandemic as a baseline and then during the first year of the pandemic using mobile phone sensing and behavioral inference. We observe that certain groups of students experience the pandemic very differently. Furthermore, we explore the association of self-reported COVID-19 concern with students\u2019 behavior and mental health. We find that heightened COVID-19 concern is correlated with increased depression, anxiety and stress. We evaluate the performance of different deep learning models to classify student COVID-19 concerns with an AUROC and F1 score of 0.70 and 0.71, respectively. Our study spans a two-year period and provides a number of important insights into the life of college students during this period.",
    "call-number": "10.1145/3491102.3502043",
    "collection-number": "42",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502043",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Pandemic, Mobile Sensing, Digital Phenotyping, Mental health, COVID-19",
    "number": "Article 42",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "COVID Student Study: A Year in the Life of College Students during the COVID-19 Pandemic Through the Lens of Mobile Phone Sensing",
    "URL": "https://doi.org/10.1145/3491102.3502043"
  },
  {
    "id": "10.1145/3491102.3517622",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Karusala",
        "given": "Naveena"
      },
      {
        "family": "Anderson",
        "given": "Richard"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "HCI is increasingly concerned with health information quality and spread of misinformation on social media. Despite many major platforms having been adopted across the world, the situated evaluation and sharing of health information is underexplored across diverse health systems and cultural and political contexts. Drawing on semi-structured interviews, we study the navigation of health information on social media in urban and rural South India, backdropped by plural knowledges around health and the specific politics and sociality of health and social media in this setting. We use Ivan Illich\u2019s concept of tools for conviviality [49] to distinguish between how people creatively use tools versus how tools manage and impose values on people\u2014participants aimed to use health information towards care beyond institutionalized healthcare, but insidious misinformation and information-sharing practices served to commodify, spark uncertainty in, and discipline caring behavior. We use our findings to expand understandings of the use of health information on social media and how positionality shapes how people are affected by and respond to misinformation. We also draw attention to the structural aspects of health misinformation in the Indian context and how the design of social media platforms might play a role in addressing it.",
    "call-number": "10.1145/3491102.3517622",
    "collection-number": "43",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517622",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "social media, misinformation, health information, India",
    "number": "Article 43",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Conviviality in NavigatingHealth Information on Social Media",
    "URL": "https://doi.org/10.1145/3491102.3517622"
  },
  {
    "id": "10.1145/3491102.3517697",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Glick",
        "given": "Peter"
      },
      {
        "family": "Clarke",
        "given": "Rachel E"
      },
      {
        "family": "Crivellaro",
        "given": "Clara"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The role of HCI in informal caregivers\u2019 lives has been a focus of research for some time. Yet to gain significance in HCI, are the implications of healthcare systems\u2019 transformation into a personalised care paradigm, where citizens gain choice and control over the delivery of their care. We provide a first HCI paper to examine self-directed care budgets for disabled citizens, where care funding is controlled by the individual. We explore how digital technology can assist citizens, promoting peer support to create meaningful, personalised healthcare infrastructures. This qualitative study contributes insights from interviews and focus groups with 24 disabled citizens, informal caregivers and healthcare officers, to provide understanding of their experiences and practices. These insights highlight relational care, invisible labour, power struggles with authorities and how citizens seek socio-technical capability. We contribute design implications for self-directed care budgets and HCI research concerned with developing technologies that support this population.",
    "call-number": "10.1145/3491102.3517697",
    "collection-number": "44",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517697",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "disability, self-directed care budgets, healthcare, Caregivers, Personal Health Budgets",
    "number": "Article 44",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Experiences of Self-Directed Care Budgets: Design Implications for Socio-Technical Interventions",
    "URL": "https://doi.org/10.1145/3491102.3517697"
  },
  {
    "id": "10.1145/3491102.3517683",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bartle",
        "given": "Vince"
      },
      {
        "family": "Lyu",
        "given": "Janice"
      },
      {
        "family": "El Shabazz-Thompson",
        "given": "Freesoul"
      },
      {
        "family": "Oh",
        "given": "Yunmin"
      },
      {
        "family": "Chen",
        "given": "Angela Anqi"
      },
      {
        "family": "Chang",
        "given": "Yu-Jan"
      },
      {
        "family": "Holstein",
        "given": "Kenneth"
      },
      {
        "family": "Dell",
        "given": "Nicola"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Home health aides are a vulnerable group of frontline caregivers who provide personal and medically-oriented care in patients\u2019 homes. Their work is difficult and unpredictable, involving a mix of physical and emotional labor as they adapt to patients\u2019 changing needs. Our paper presents an exploratory, qualitative study with 32 participants, that investigates design opportunities for Interactive Voice Assistants (IVAs) to support aides\u2019 essential care work. We explore challenges and opportunities for IVAs to (1) fill gaps in aides\u2019 access to information and care coordination, (2) assist with decision making and task completion, (3) advocate on behalf of aides, and (4) provide emotional support. We then discuss key implications of our work, including how materiality may impact perceived ownership and usage of IVAs, the need to carefully consider tensions around surveillance, accountability, data collection, and reporting, and the challenges of centering aides as essential workers in complex home health care contexts.",
    "call-number": "10.1145/3491102.3517683",
    "collection-number": "45",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517683",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "intelligent agent, Voice assistant, home health aides, home health care, AI, future of work., community health",
    "number": "Article 45",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cA Second Voice\u201d: Investigating Opportunities and Challenges for Interactive Voice Assistants to Support Home Health Aides",
    "URL": "https://doi.org/10.1145/3491102.3517683"
  },
  {
    "id": "10.1145/3491102.3517730",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Seunarine",
        "given": "Krishna"
      },
      {
        "family": "Kalarikalayil Raju",
        "given": "Dani"
      },
      {
        "family": "Thomas",
        "given": "Gethin"
      },
      {
        "family": "Thomas",
        "given": "Suzanne K"
      },
      {
        "family": "Pockett",
        "given": "Adam"
      },
      {
        "family": "Reitmaier",
        "given": "Thomas"
      },
      {
        "family": "Steer",
        "given": "Cameron"
      },
      {
        "family": "Owen",
        "given": "Tom"
      },
      {
        "family": "Meena",
        "given": "Yogesh Kumar"
      },
      {
        "family": "Robinson",
        "given": "Simon"
      },
      {
        "family": "Pearson",
        "given": "Jennifer"
      },
      {
        "family": "Carnie",
        "given": "Matt"
      },
      {
        "family": "Sahoo",
        "given": "Deepak Ranjan"
      },
      {
        "family": "Jones",
        "given": "Matt"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Many of us daily encounter shadow and reflected light patterns alongside macro-level changes in ambient light levels. These are caused by elements\u2014opaque objects, glass, mirrors, even clouds\u2014in our environment interfacing with sunlight or artificial indoor lighting. Inspired by these phenomena, we explored ways of creating digitally-supported displays that use light, shade and reflection for output and harness the energy they need to operate from the sun or indoor ambient light. Through a set of design workshops we developed exemplar devices: SolarPix, ShadMo and GlowBoard. We detail their function and implementation, as well as evidencing their technical viability. The designs were informed by material understandings from the Global North and Global South and demonstrated in a cross-cultural workshop run in parallel in India and South Africa where community co-designers reflected on their uses and value given lived experience of their communication practices and unreliable energy networks.",
    "call-number": "10.1145/3491102.3517730",
    "collection-number": "46",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517730",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "public displays., Sustainability, ambient devices / internet of things",
    "number": "Article 46",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Light-In-Light-Out (Li-Lo) Displays: Harvesting and Manipulating Light to Provide Novel Forms of Communication",
    "URL": "https://doi.org/10.1145/3491102.3517730"
  },
  {
    "id": "10.1145/3491102.3501926",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Deng",
        "given": "Jialin"
      },
      {
        "family": "Olivier",
        "given": "Patrick"
      },
      {
        "family": "Andres",
        "given": "Josh"
      },
      {
        "family": "Ellis",
        "given": "Kirsten"
      },
      {
        "family": "Wee",
        "given": "Ryan"
      },
      {
        "family": "Floyd Mueller",
        "given": "Florian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In recognition of food's significant experiential pleasures, culinary practitioners and designers are increasingly exploring novel combinations of computing technologies and food. However, despite much creative endeavors, proposals and prototypes have so far largely maintained a traditional divide, treating food and technology as separate entities. In contrast, we present a \u201cResearch through Design\u201d exploration of the notion of food as computational artifact: wherein food itself is the material of computation. We describe the Logic Bonbon, a dessert that can hydrodynamically regulate its flavor via a fluidic logic system. Through a study of experiencing the Logic Bonbon and reflection on our design practice, we offer a provisional account of how food as computational artifact can mediate new interactions through a novel approach to food-computation integration, that promotes an enriched future of Human-Food Interaction.",
    "call-number": "10.1145/3491102.3501926",
    "collection-number": "47",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501926",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Edible Fluidics, Food Design, Human-Food Interaction",
    "number": "Article 47",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Logic Bonbon: Exploring Food as Computational Artifact",
    "URL": "https://doi.org/10.1145/3491102.3501926"
  },
  {
    "id": "10.1145/3491102.3517663",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Horn",
        "given": "Melody"
      },
      {
        "family": "Traylor",
        "given": "Amy"
      },
      {
        "family": "Buechley",
        "given": "Leah"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Slab-based ceramics are constructed by rolling out flat sheets of clay, cutting out a pattern, and then folding the cut clay to build a three-dimensional design. Slabforge is an open-source web-based software application that supports slab-based ceramics. It enables users to design a range of simple 3D forms and then generate flat patterns and matching 3D-printable slump molds that support the construction of those forms. This paper discusses the development of the software in the context of our own ceramics practice and then describes the results of a study in which students in an introductory ceramics course used Slabforge to create tea sets. We use both of these experiences to motivate a critical reflection on the relationships between materials, craft, digital fabrication, and software, introducing three themes of friction that we encountered during the course of this project.",
    "call-number": "10.1145/3491102.3517663",
    "collection-number": "48",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517663",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Computational Design, Slab, Ceramics, Fabrication, Craft, Clay, Hybrid Craft, Design Software",
    "number": "Article 48",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Slabforge: Design Software for Slab-Based Ceramics",
    "URL": "https://doi.org/10.1145/3491102.3517663"
  },
  {
    "id": "10.1145/3491102.3501990",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Guanhong"
      },
      {
        "family": "Xu",
        "given": "Haiqing"
      },
      {
        "family": "Ding",
        "given": "Xianghua(Sharon)"
      },
      {
        "family": "Gao",
        "given": "Mingyue"
      },
      {
        "family": "Li",
        "given": "Bowen"
      },
      {
        "family": "Ruan",
        "given": "Fushen"
      },
      {
        "family": "Mi",
        "given": "Haipeng"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Fluid fiber, with fluid flowing in a tube, is an attractive material to flexibly and dynamically display digital information. While it has recently attracted attention from the HCI field, there is currently little knowledge about this material, limited to controlling the position of the droplets to present representational information like letters and numbers. To develop a broader and deepened understanding of this material and its potential for display design, we conducted a study based on a design workshop where art and design practitioners engaged in creation practice with a toolkit we designed and developed. The toolkit includes hardware components for controlling bubbles and droplets and a GUI design tool for arranging the fluid layout. Our research reveals the structural and expressive affordance of such a fluid fiber for displaying information, highlighting the unique value of fluidity as an intuitive form to express life, emotion, movement and changes.",
    "call-number": "10.1145/3491102.3501990",
    "collection-number": "49",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501990",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Participatory design, Affordance, Fluid Fiber, Fabrication, Toolkits, Dynamic display",
    "number": "Article 49",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dIt Puts Life into My Creations\u201d: Understanding Fluid Fiber as a Media for Expressive Display",
    "URL": "https://doi.org/10.1145/3491102.3501990"
  },
  {
    "id": "10.1145/3491102.3501943",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Windl",
        "given": "Maximiliane"
      },
      {
        "family": "Feger",
        "given": "Sebastian S."
      },
      {
        "family": "Zijlstra",
        "given": "Lara"
      },
      {
        "family": "Schmidt",
        "given": "Albrecht"
      },
      {
        "family": "Wozniak",
        "given": "Pawel W."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While systems that use Artificial Intelligence (AI) are increasingly becoming part of everyday technology use, we do not fully understand how AI changes design processes. A structured understanding of how designers work with AI is needed to improve the design process and educate future designers. To that end, we conducted interviews with designers who participated in projects which used AI. While past work focused on AI systems created by experienced designers, we focus on the perspectives of a diverse sample of interaction designers. Our results show that the design process of an interactive system is affected when AI is integrated and that design teams adapt their processes to accommodate AI. Based on our data, we contribute four approaches adopted by interaction designers working with AI: a priori, post-hoc, model-centric, and competence-centric. Our work contributes a pragmatic account of how design processes for AI systems are enacted.",
    "call-number": "10.1145/3491102.3501943",
    "collection-number": "50",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501943",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "artificial intelligence, design, data work, process",
    "number": "Article 50",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u2018It Is Not Always Discovery Time\u2019: Four Pragmatic Approaches in Designing AI Systems",
    "URL": "https://doi.org/10.1145/3491102.3501943"
  },
  {
    "id": "10.1145/3491102.3517672",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Park",
        "given": "Hyanghee"
      },
      {
        "family": "Ahn",
        "given": "Daehwan"
      },
      {
        "family": "Hosanagar",
        "given": "Kartik"
      },
      {
        "family": "Lee",
        "given": "Joonhwan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Enterprises have recently adopted AI to human resource management (HRM) to evaluate employees\u2019 work performance evaluation. However, in such an HRM context where multiple stakeholders are complexly intertwined with different incentives, it is problematic to design AI reflecting one stakeholder group's needs (e.g., enterprises, HR managers). Our research aims to investigate what tensions surrounding AI in HRM exist among stakeholders and explore design solutions to balance the tensions. By conducting stakeholder-centered participatory workshops with diverse stakeholders (including employees, employers/HR teams, and AI/business experts), we identified five major tensions: 1)\u00a0divergent perspectives on fairness, 2)\u00a0the accuracy of AI, 3)\u00a0the transparency of the algorithm and its decision process, 4)\u00a0the interpretability of algorithmic decisions, and 5)\u00a0the trade-off between productivity and inhumanity. We present stakeholder-centered design ideas for solutions to mitigate these tensions and further discuss how to promote harmony among various stakeholders at the workplace.",
    "call-number": "10.1145/3491102.3517672",
    "collection-number": "51",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517672",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Stakeholder-centered design, Explainable AI (XAI), Interpretability, Human Intervention, Fair and responsible AI, Future of work, Transparency, Algorithmic management, Artificial intelligence (AI), Human resource management",
    "number": "Article 51",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing Fair AI in Human Resource Management: Understanding Tensions Surrounding Algorithmic Evaluation and Envisioning Stakeholder-Centered Solutions",
    "URL": "https://doi.org/10.1145/3491102.3517672"
  },
  {
    "id": "10.1145/3491102.3517439",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kawakami",
        "given": "Anna"
      },
      {
        "family": "Sivaraman",
        "given": "Venkatesh"
      },
      {
        "family": "Cheng",
        "given": "Hao-Fei"
      },
      {
        "family": "Stapleton",
        "given": "Logan"
      },
      {
        "family": "Cheng",
        "given": "Yanghuidi"
      },
      {
        "family": "Qing",
        "given": "Diana"
      },
      {
        "family": "Perer",
        "given": "Adam"
      },
      {
        "family": "Wu",
        "given": "Zhiwei Steven"
      },
      {
        "family": "Zhu",
        "given": "Haiyi"
      },
      {
        "family": "Holstein",
        "given": "Kenneth"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "AI-based decision support tools (ADS) are increasingly used to augment human decision-making in high-stakes, social contexts. As public sector agencies begin to adopt ADS, it is critical that we understand workers\u2019 experiences with these systems in practice. In this paper, we present findings from a series of interviews and contextual inquiries at a child welfare agency, to understand how they currently make AI-assisted child maltreatment screening decisions. Overall, we observe how workers\u2019 reliance upon the ADS is guided by (1) their knowledge of rich, contextual information beyond what the AI model captures, (2) their beliefs about the ADS\u2019s capabilities and limitations relative to their own, (3) organizational pressures and incentives around the use of the ADS, and (4) awareness of misalignments between algorithmic predictions and their own decision-making objectives. Drawing upon these findings, we discuss design implications towards supporting more effective human-AI decision-making.",
    "call-number": "10.1145/3491102.3517439",
    "collection-number": "52",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517439",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "algorithm-assisted decision making, contextual inquiry, child welfare, decision support",
    "number": "Article 52",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support",
    "URL": "https://doi.org/10.1145/3491102.3517439"
  },
  {
    "id": "10.1145/3491102.3517615",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zheng",
        "given": "Chengbo"
      },
      {
        "family": "Wang",
        "given": "Dakuo"
      },
      {
        "family": "Wang",
        "given": "April Yi"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Creating presentation slides is a critical but time-consuming task for data scientists. While researchers have proposed many AI techniques to lift data scientists\u2019 burden on data preparation and model selection, few have targeted the presentation creation task. Based on the needs identified from a formative study, this paper presents NB2Slides, an AI system that facilitates users to compose presentations of their data science work. NB2Slides uses deep learning methods as well as example-based prompts to generate slides from computational notebooks, and take users\u2019 input (e.g., audience background) to structure the slides. NB2Slides also provides an interactive visualization that links the slides with the notebook to help users further edit the slides. A follow-up user evaluation with 12 data scientists shows that participants believed NB2Slides can improve efficiency and reduces the complexity of creating slides. Yet, participants questioned the future of full automation and suggested a human-AI collaboration paradigm.",
    "call-number": "10.1145/3491102.3517615",
    "collection-number": "53",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517615",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "computational notebook, slides generation",
    "number": "Article 53",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Telling Stories from Computational Notebooks: AI-Assisted Presentation Slides Creation for Presenting Data Science Work",
    "URL": "https://doi.org/10.1145/3491102.3517615"
  },
  {
    "id": "10.1145/3491102.3501999",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lai",
        "given": "Vivian"
      },
      {
        "family": "Carton",
        "given": "Samuel"
      },
      {
        "family": "Bhatnagar",
        "given": "Rajat"
      },
      {
        "family": "Liao",
        "given": "Q. Vera"
      },
      {
        "family": "Zhang",
        "given": "Yunfeng"
      },
      {
        "family": "Tan",
        "given": "Chenhao"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Despite impressive performance in many benchmark datasets, AI models can still make mistakes, especially among out-of-distribution examples. It remains an open question how such imperfect models can be used effectively in collaboration with humans. Prior work has focused on AI assistance that helps people make individual high-stakes decisions, which is not scalable for a large amount of relatively low-stakes decisions, e.g., moderating social media comments. Instead, we propose conditional delegation as an alternative paradigm for human-AI collaboration where humans create rules to indicate trustworthy regions of a model. Using content moderation as a testbed, we develop novel interfaces to assist humans in creating conditional delegation rules and conduct a randomized experiment with two datasets to simulate in-distribution and out-of-distribution scenarios. Our study demonstrates the promise of conditional delegation in improving model performance and provides insights into design for this novel paradigm, including the effect of AI explanations.",
    "call-number": "10.1145/3491102.3501999",
    "collection-number": "54",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501999",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 54",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Human-AI Collaboration via Conditional Delegation: A Case Study of Content Moderation",
    "URL": "https://doi.org/10.1145/3491102.3501999"
  },
  {
    "id": "10.1145/3491102.3517623",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Khemani",
        "given": "Krishika Haresh"
      },
      {
        "family": "Reeves",
        "given": "Stuart"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent HCI research has sought to develop guidelines\u2014\u2018heuristics\u2019, \u2018best practices\u2019, \u2018principles\u2019 and so on\u2014for voice user interfaces (VUI) to aid both practitioners and researchers in improving the quality of VUI-based design. However, limited research is available on how such design knowledge is conceptualised and used by industry practitioners. We present a small interview-based study conducted with 9 experienced VUI industry practitioners. Their concerns range from terminological challenges associated with VUI design knowledge, the role of codifications of such knowledge like design guidelines alongside their practical design work, through to their views on the value of \u2018harmonisation\u2019 of VUI design knowledge. Given the complex\u2014albeit preliminary\u2014picture that emerges, we argue for HCI's deeper consideration of how design knowledge meshes with the contingencies of practice, so that VUI design knowledge\u2014such as design guidelines developed in HCI\u2014delivers the most potential value for industry practice.",
    "call-number": "10.1145/3491102.3517623",
    "collection-number": "55",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517623",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "industry practitioners, voice user interfaces, Design guidelines",
    "number": "Article 55",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Unpacking Practitioners\u2019 Attitudes Towards Codifications of Design Knowledge for Voice User Interfaces",
    "URL": "https://doi.org/10.1145/3491102.3517623"
  },
  {
    "id": "10.1145/3491102.3502093",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Orii",
        "given": "Lisa"
      },
      {
        "family": "Ogawa",
        "given": "Nami"
      },
      {
        "family": "Hatada",
        "given": "Yuji"
      },
      {
        "family": "Narumi",
        "given": "Takuji"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Can you speak the way you desire without feeling the pressure to conform to standards of speaking? In this study, we investigated the impact of user-controlled voice manipulation and listening to recordings of model speakers on self-perceptions of voice and speech. Quantitative analysis showed that there was a significant improvement in the perceived confidence of tone by listening to model speakers, but there were no significant improvements due to voice manipulation. Qualitative analysis of interviews revealed that participants responded positively to the visual and auditory feedback provided by the voice manipulation software. The participants also evaluated the quality of model speakers to decide whether or not they wanted to refer to them for speech practice. Based on the results of these analyses, we summarized the design implications for a speech practice system that would allow further investigation of the impact of the system on self-perceptions of speech performance.",
    "call-number": "10.1145/3491102.3502093",
    "collection-number": "56",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502093",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "presentation training, voice manipulation, speech examples, self-perception, public speaking",
    "number": "Article 56",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing for Speech Practice Systems: How Do User-Controlled Voice Manipulation and Model Speakers Impact Self-Perceptions of Voice?",
    "URL": "https://doi.org/10.1145/3491102.3502093"
  },
  {
    "id": "10.1145/3491102.3517653",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jung",
        "given": "Ji-Youn"
      },
      {
        "family": "Qiu",
        "given": "Sihang"
      },
      {
        "family": "Bozzon",
        "given": "Alessandro"
      },
      {
        "family": "Gadiraju",
        "given": "Ujwal"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Conversational agents are being widely adopted across several domains to serve a variety of purposes ranging from providing intelligent assistance to companionship. Recent literature has shown that users develop intuitive folk theories and a metaphorical understanding of conversational agents (CAs) due to the lack of a mental model of the agents. However, investigation of metaphorical agent representation in the HCI community has mainly focused on the human level, despite non-human metaphors for agents being prevalent in the real world. We adopted Lakoff and Turner\u2019s \u2018Great Chain of Being\u2019 framework to systematically investigate the impact of using non-human metaphors to represent conversational agents on worker engagement in crowdsourcing marketplaces. We designed a text-based conversational agent that assists crowd workers in task execution. Through a between-subjects experimental study (N = 341), we explored how different human and non-human metaphors affect worker engagement, the perceived cognitive load of workers, intrinsic motivation, and their trust in the agents. Our findings bridge the gap of how users experience CAs with non-human metaphors in the context of conversational crowdsourcing.",
    "call-number": "10.1145/3491102.3517653",
    "collection-number": "57",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517653",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Trust, Crowdsourcing, Conceptual metaphors, Great chain of being, Engagement, Human-agent interaction, Human-AI interaction, Conversational agent",
    "number": "Article 57",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Great Chain of Agents: The Role of Metaphorical Representation of Agents in Conversational Crowdsourcing",
    "URL": "https://doi.org/10.1145/3491102.3517653"
  },
  {
    "id": "10.1145/3491102.3502036",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhao",
        "given": "Yaxi"
      },
      {
        "family": "Jaber",
        "given": "Razan"
      },
      {
        "family": "McMillan",
        "given": "Donald"
      },
      {
        "family": "Munteanu",
        "given": "Cosmin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Voice interaction has long been envisioned as enabling users to transform physical interaction into hands-free, such as allowing fine-grained control of instructional videos without physically disengaging from the task at hand. While significant engineering advances have brought us closer to this ideal, we do not fully understand the user requirements for voice interactions that should be supported in such contexts. This paper presents an ecologically-valid wizard-of-oz elicitation study exploring realistic user requirements for an ideal instructional video playback control while cooking. Through the analysis of the issued commands and performed actions during this non-linear and complex task, we identify (1) patterns of command formulation, (2) challenges for design, and (3) how task and voice-based commands are interwoven in real-life. We discuss implications for the design and research of voice interactions for navigating instructional videos while performing complex tasks.",
    "call-number": "10.1145/3491102.3502036",
    "collection-number": "58",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502036",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Voice-Based Navigation, Conversational Interaction, Non-Linear Instructional Video, Wizard-of-Oz",
    "number": "Article 58",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cRewind to the Jiggling Meat Part\u201d: Understanding Voice Control of Instructional Videos in Everyday Tasks",
    "URL": "https://doi.org/10.1145/3491102.3502036"
  },
  {
    "id": "10.1145/3491102.3517722",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Mingrui Ray"
      },
      {
        "family": "Lukoff",
        "given": "Kai"
      },
      {
        "family": "Rao",
        "given": "Raveena"
      },
      {
        "family": "Baughan",
        "given": "Amanda"
      },
      {
        "family": "Hiniker",
        "given": "Alexis"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Existing designs helping people manage their social media use include: 1) external supports that monitor and limit use; 2) internal supports that change the interface itself. Here, we design and deploy Chirp, a mobile Twitter client, to independently examine how users experience external and internal supports. To develop Chirp, we identified 16 features that influence users\u2019 sense of agency on Twitter through a survey of 129 participants and a design workshop. We then conducted a four-week within-subjects deployment with 31 participants. Our internal supports (including features to filter tweets and inform users when they have exhausted new content) significantly increased users\u2019 sense of agency, while our external supports (a usage dashboard and nudges to close the app) did not. Participants valued our internal supports and said that our external supports were for \u201cother people.\u201d Our findings suggest that design patterns promoting agency may serve users better than screen time tools.",
    "call-number": "10.1145/3491102.3517722",
    "collection-number": "60",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517722",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "twitter, mobile phone, social media, digital wellbeing, sense of agency",
    "number": "Article 60",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Monitoring Screen Time or Redesigning It? Two Approaches to Supporting Intentional Social Media Use",
    "URL": "https://doi.org/10.1145/3491102.3517722"
  },
  {
    "id": "10.1145/3491102.3501981",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Schmitz",
        "given": "Martin"
      },
      {
        "family": "G\u00fcnther",
        "given": "Sebastian"
      },
      {
        "family": "Sch\u00f6n",
        "given": "Dominik"
      },
      {
        "family": "M\u00fcller",
        "given": "Florian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "From zooming on smartphones and mid-air gestures to deformable user interfaces, thumb-index pinching grips are used in many interaction techniques. However, there is still a lack of systematic understanding of how the accuracy and efficiency of such grips are affected by various factors such as counterforce, grip span, and grip direction. Therefore, in this paper, we contribute an evaluation (N = 18) of thumb-index pinching performance in a visual targeting task using scales up to 75 items. As part of our findings, we conclude that the pinching interaction between the thumb and index finger is a promising modality also for one-dimensional input on higher scales. Furthermore, we discuss and outline implications for future user interfaces that benefit from pinching as an additional and complementary interaction modality.",
    "call-number": "10.1145/3491102.3501981",
    "collection-number": "61",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501981",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Input, Pinching, User Studies, Deformation, Mixed Reality, Thumb-to-finger",
    "number": "Article 61",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Squeezy-Feely: Investigating Lateral Thumb-Index Pinching as an Input Modality",
    "URL": "https://doi.org/10.1145/3491102.3501981"
  },
  {
    "id": "10.1145/3491102.3517638",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bergram",
        "given": "Kristoffer"
      },
      {
        "family": "Djokovic",
        "given": "Marija"
      },
      {
        "family": "Bezen\u00e7on",
        "given": "Val\u00e9ry"
      },
      {
        "family": "Holzer",
        "given": "Adrian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Research output related to digital nudging has increased ten-fold over the last five years. Nudging in the digital realm differs from its analog counterpart in important ways. For instance, online, choice architectures can be interconnected and personalized using real time data. In the face of this development, it is crucial to understand the current state of the literature and to map out possible research gaps. This paper addresses this issue and provides a systematic review of empirical studies where digital nudges have been evaluated. The systematic review covers 73 peer-reviewed papers containing 109 separate studies where 231 digital nudges have been evaluated. Our results lead to nine open research questions to be addressed in the future by the research community.",
    "call-number": "10.1145/3491102.3517638",
    "collection-number": "62",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517638",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "digital nudges, personalization, nudge patterns, digital nudging, choice architecture, interconnectedness, review",
    "number": "Article 62",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Digital Landscape of Nudging: A Systematic Literature Review of Empirical Research on Digital Nudges",
    "URL": "https://doi.org/10.1145/3491102.3517638"
  },
  {
    "id": "10.1145/3491102.3517692",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Axtell",
        "given": "Benett"
      },
      {
        "family": "Saryazdi",
        "given": "Raheleh"
      },
      {
        "family": "Munteanu",
        "given": "Cosmin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Interactions with our personal and family pictures are essential to continued social reminiscence, leading to long-term benefits, including reduced social isolation. Previous research has identified how designs of digital picture tools fall short of physical options specifically in terms of reminiscence. However, the relative prompting abilities of different digital interactions, including the types of memories prompted like external facts or person-centred memories, have not yet been explored. To investigate this, we present a controlled study of the memories prompted by three digital picture interactions (slideshow, gallery, and tabletop) on personal touchscreen devices. We find differences in how these tools and the interactions they support prompt reminiscence. In particular, gallery views prompt significantly fewer memories than either the tabletop or slideshow. Slideshows prompt significantly more external, factual memories, but not more person-centred memories, which are key to reminiscence. This has implications for the overall social usability of digital picture interactions.",
    "call-number": "10.1145/3491102.3517692",
    "collection-number": "63",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517692",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "digital storytelling, reminiscence, Digital picture interactions",
    "number": "Article 63",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design is Worth a Thousand Words: The Effect of Digital Interaction Design on Picture-Prompted Reminiscence",
    "URL": "https://doi.org/10.1145/3491102.3517692"
  },
  {
    "id": "10.1145/3491102.3517702",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yuan",
        "given": "Ye"
      },
      {
        "family": "Riche",
        "given": "Nathalie"
      },
      {
        "family": "Marquardt",
        "given": "Nicolai"
      },
      {
        "family": "Nicholas",
        "given": "Molly Jane"
      },
      {
        "family": "Seyed",
        "given": "Teddy"
      },
      {
        "family": "Romat",
        "given": "Hugo"
      },
      {
        "family": "Lee",
        "given": "Bongshin"
      },
      {
        "family": "Pahud",
        "given": "Michel"
      },
      {
        "family": "Goldstein",
        "given": "Jonathan"
      },
      {
        "family": "Vishkaie",
        "given": "Rojin"
      },
      {
        "family": "Holz",
        "given": "Christian"
      },
      {
        "family": "Hinckley",
        "given": "Ken"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "To better ground technical (systems) investigation and interaction design of cross-device experiences, we contribute an in-depth survey of existing multi-device practices, including fragmented workflows across devices and the way people physically organize and configure their workspaces to support such activity. Further, this survey documents a historically significant moment of transition to a new future of remote work, an existing trend dramatically accelerated by the abrupt switch to work-from-home (and having to contend with the demands of home-at-work) during the COVID-19 pandemic. We surveyed 97 participants, and collected photographs of home setups and open-ended answers to 50 questions categorized in 5 themes. We characterize the wide range of multi-device physical configurations and identify five usage patterns, including: partitioning tasks, integrating multi-device usage, cloning tasks to other devices, expanding tasks and inputs to multiple devices, and migrating between devices. Our analysis also sheds light on the benefits and challenges people face when their workflow is fragmented across multiple devices. These insights have implications for the design of multi-device experiences that support people\u2019s fragmented workflows.",
    "call-number": "10.1145/3491102.3517702",
    "collection-number": "64",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517702",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "cross-device computing, distributed user interfaces, multi-device",
    "number": "Article 64",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Multi-Device Usage Patterns: Physical Device Configurations and Fragmented Workflows",
    "URL": "https://doi.org/10.1145/3491102.3517702"
  },
  {
    "id": "10.1145/3491102.3517665",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Qian",
        "given": "Xun"
      },
      {
        "family": "He",
        "given": "Fengming"
      },
      {
        "family": "Hu",
        "given": "Xiyun"
      },
      {
        "family": "Wang",
        "given": "Tianyi"
      },
      {
        "family": "Ipsita",
        "given": "Ananya"
      },
      {
        "family": "Ramani",
        "given": "Karthik"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Augmented Reality (AR) experiences tightly associate virtual contents with environmental entities. However, the dissimilarity of different environments limits the adaptive AR content behaviors under large-scale deployment. We propose ScalAR, an integrated workflow enabling designers to author semantically adaptive AR experiences in Virtual Reality (VR). First, potential AR consumers collect local scenes with a semantic understanding technique. ScalAR then synthesizes numerous similar scenes. In VR, a designer authors the AR contents\u2019 semantic associations and validates the design while being immersed in the provided scenes. We adopt a decision-tree-based algorithm to fit the designer\u2019s demonstrations as a semantic adaptation model to deploy the authored AR experience in a physical scene. We further showcase two application scenarios authored by ScalAR and conduct a two-session user study where the quantitative results prove the accuracy of the AR content rendering and the qualitative results show the usability of ScalAR.",
    "call-number": "10.1145/3491102.3517665",
    "collection-number": "65",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517665",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Reality, Semantic Understanding, Immersive Authoring, Augmented Reality, Adaptation",
    "number": "Article 65",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ScalAR: Authoring Semantically Adaptive Augmented Reality Experiences in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517665"
  },
  {
    "id": "10.1145/3491102.3502070",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Arab",
        "given": "Maryam"
      },
      {
        "family": "LaToza",
        "given": "Thomas D."
      },
      {
        "family": "Liang",
        "given": "Jenny"
      },
      {
        "family": "Ko",
        "given": "Amy J."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In many domains, strategic knowledge is documented and shared through checklists and handbooks. In software engineering, however, developers rarely share strategic knowledge for approaching programming problems, in contrast to other artifacts and despite its importance to productivity and success. To understand barriers to sharing, we simulated a programming strategy knowledge-sharing platform, asking experienced developers to articulate a programming strategy and others to use these strategies while providing feedback. Throughout, we asked strategy authors and users to reflect on the challenges they faced. Our analysis revealed that developers could share strategic knowledge. However, they struggled in choosing a level of detail and understanding the diversity of the potential audience. While authors required substantial feedback, users struggled to give it and authors to interpret it. Our results suggest that sharing strategic knowledge differs from sharing code and raises challenging questions about how knowledge-sharing platforms should support search and feedback.",
    "call-number": "10.1145/3491102.3502070",
    "collection-number": "66",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502070",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Programming strategies, Knowledge sharing",
    "number": "Article 66",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An Exploratory Study of Sharing Strategic Programming Knowledge",
    "URL": "https://doi.org/10.1145/3491102.3502070"
  },
  {
    "id": "10.1145/3491102.3502042",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Gang"
      },
      {
        "family": "Baechler",
        "given": "Gilles"
      },
      {
        "family": "Tragut",
        "given": "Manuel"
      },
      {
        "family": "Li",
        "given": "Yang"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The layout of a mobile screen is a critical data source for UI design research and semantic understanding of the screen. However, UI layouts in existing datasets are often noisy, have mismatches with their visual representation, or consists of generic or app-specific types that are difficult to analyze and model. In this paper, we propose the CLAY pipeline that uses a deep learning approach for denoising UI layouts, allowing us to automatically improve existing mobile UI layout datasets at scale. Our pipeline takes both the screenshot and the raw UI layout, and annotates the raw layout by removing incorrect nodes and assigning a semantically meaningful type to each node. To experiment with our data-cleaning pipeline, we create the CLAY dataset of 59,555 human-annotated screen layouts, based on screenshots and raw layouts from Rico, a public mobile UI corpus. Our deep models achieve high accuracy with F1 scores of 82.7% for detecting layout objects that do not have a valid visual representation and 85.9% for recognizing object types, which significantly outperforms a heuristic baseline. Our work lays a foundation for creating large-scale high quality UI layout datasets for data-driven mobile UI research and reduces the need of manual labeling efforts that are prohibitively expensive.",
    "call-number": "10.1145/3491102.3502042",
    "collection-number": "67",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502042",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mobile UI layouts, neural networks, Graph Neural Networks, Convolutional Neural Networks, Transformers, Datasets",
    "number": "Article 67",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Learning to Denoise Raw Mobile UI Layouts for Improving Datasets at Scale",
    "URL": "https://doi.org/10.1145/3491102.3502042"
  },
  {
    "id": "10.1145/3491102.3501968",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Michael Xieyang"
      },
      {
        "family": "Kittur",
        "given": "Aniket"
      },
      {
        "family": "Myers",
        "given": "Brad A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Developers perform online sensemaking on a daily basis, such as researching and choosing libraries and APIs. Prior research has introduced tools that help developers capture information from various sources and organize it into structures useful for subsequent decision-making. However, it remains a laborious process for developers to manually identify and clip content, maintaining its provenance and synthesizing it with other content. In this work, we introduce a new system called Crystalline that automatically collects and organizes information into tabular structures as the user searches and browses the web. It leverages natural language processing to automatically group similar criteria together to reduce clutter, and uses passive behavioral signals such as mouse movement and dwell time to infer what information to collect and how to visualize and prioritize it. Our user study suggests that developers are able to create comparison tables about 20% faster with a 60% reduction in operational cost without sacrificing the quality of the tables.",
    "call-number": "10.1145/3491102.3501968",
    "collection-number": "68",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501968",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Sensemaking, Developer tools, Implicit signals, Behavior patterns, Decision making",
    "number": "Article 68",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Crystalline: Lowering the Cost for Developers to Collect and Organize Information for Decision Making",
    "URL": "https://doi.org/10.1145/3491102.3501968"
  },
  {
    "id": "10.1145/3491102.3502095",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Horvath",
        "given": "Amber"
      },
      {
        "family": "Liu",
        "given": "Michael Xieyang"
      },
      {
        "family": "Hendriksen",
        "given": "River"
      },
      {
        "family": "Shannon",
        "given": "Connor"
      },
      {
        "family": "Paterson",
        "given": "Emma"
      },
      {
        "family": "Jawad",
        "given": "Kazi"
      },
      {
        "family": "Macvean",
        "given": "Andrew"
      },
      {
        "family": "Myers",
        "given": "Brad A"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Modern software development requires developers to find and effectively utilize new APIs and their documentation, but documentation has many well-known issues. Despite this, developers eventually overcome these issues but have no way of sharing what they learned. We investigate sharing this documentation-specific information through annotations, which have advantages over developer forums as the information is contextualized, not disruptive, and is short, thus easy to author. Developers can also author annotations to support their own comprehension. In order to support the documentation usage behaviors we found, we built the Adamite annotation tool, which provides features such as multiple anchors, annotation types, and pinning. In our user study, we found that developers are able to create annotations that are useful to themselves and are able to utilize annotations created by other developers when learning a new API, with readers of the annotations completing 67% more of the task, on average, than the baseline.",
    "call-number": "10.1145/3491102.3502095",
    "collection-number": "69",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502095",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "documentation, Annotations, note taking, software engineering, application programming interfaces (APIs)",
    "number": "Article 69",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding How Programmers Can Use Annotations on Documentation",
    "URL": "https://doi.org/10.1145/3491102.3502095"
  },
  {
    "id": "10.1145/3491102.3517591",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yang",
        "given": "Wenjie"
      },
      {
        "family": "Wu",
        "given": "Zhiyang"
      },
      {
        "family": "Mok",
        "given": "Nga Yiu"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "During recent crises like COVID-19, microblogging platforms have become popular channels for affected people seeking assistance such as medical supplies and rescue operations from emergency responders and the public. Despite this common practice, the affordances of microblogging services for help-seeking during crises that needs immediate attention are not well understood. To fill this gap, we analyzed 8K posts from COVID-19 patients or caregivers requesting urgent medical assistance on Weibo, the largest microblogging site in China. Our mixed-methods analyses suggest that existing microblogging functions need to be improved in multiple aspects to sufficiently facilitate help-seeking in emergencies, including capabilities of search and tracking requests, ease of use, and privacy protection. We also find that people tend to stick to certain well-established functions for publishing requests, even after better alternatives emerge. These findings have implications for designing microblogging tools to better support help requesting and responding during crises.",
    "call-number": "10.1145/3491102.3517591",
    "collection-number": "70",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517591",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Crisis informatics, social media, disaster response, help-seeking, COVID-19",
    "number": "Article 70",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How to Save Lives with Microblogs? Lessons From the Usage of Weibo for Requests for Medical Assistance During COVID-19",
    "URL": "https://doi.org/10.1145/3491102.3517591"
  },
  {
    "id": "10.1145/3491102.3501900",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Holtz",
        "given": "David M"
      },
      {
        "family": "Scult",
        "given": "Liane"
      },
      {
        "family": "Suri",
        "given": "Siddharth"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Previous qualitative work has documented that platform workers place an immense importance on their reputation due to the use of algorithmic management by online labor platforms. We provide a general experimental method, which can be used across platforms and time, for numerically quantifying the intensity with which platform workers experience reputation system-based algorithmic management. Our method works via an experiment where workers choose between a monetary bonus or a positive review. We demonstrate this method by measuring the value that freelancers assigned to positive feedback on Upwork in June 2020. The median freelancer in our sample valued a single positive review at \u223c $49 USD. We also find that less experienced freelancers valued a positive review more highly than those with more experience. Qualitative data collected during the experiment indicates that many freelancers considered issues related to reputation system-based algorithmic management while choosing between the monetary reward and the positive review.",
    "call-number": "10.1145/3491102.3501900",
    "collection-number": "71",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501900",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "online labor market, reputation, algorithmic management, upwork, behavioral experiment, crowdsourcing",
    "number": "Article 71",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How Much Do Platform Workers Value Reviews? An Experimental Method",
    "URL": "https://doi.org/10.1145/3491102.3501900"
  },
  {
    "id": "10.1145/3491102.3517656",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Renney",
        "given": "Nathan"
      },
      {
        "family": "Gaster",
        "given": "Benedict"
      },
      {
        "family": "Mitchell",
        "given": "Tom"
      },
      {
        "family": "Renney",
        "given": "Harri"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Digital lutherie is a sub-domain of digital craft focused on creating digital musical instruments: high-performance devices for musical expression. It represents a nuanced and challenging area of human-computer interaction that is well established and mature, offering the opportunity to observe designers\u2019 work on highly demanding human-computer interfaces. This paper explores how and why digital luthiers choose their tools and how these tools relate to the challenges they face. Findings from 27 standardised open-ended interviews with prominent digital luthiers from commercial, research, independent and artistic backgrounds are analysed through reflexive thematic analysis. Our discussion explores their perspectives, finding that a process of pragmatic rationalisation and environmental influences play a significant role in tool selection. We also present how challenges faced by digital luthiers relate to social creativity and meta-design. These findings build upon the existing literature that examines the designer-tool relationship.",
    "call-number": "10.1145/3491102.3517656",
    "collection-number": "72",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517656",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Programming Languages, Design Tools, Design Practice, Digital Musical Instruments, Thematic Analysis, Digital Luthier, Qualitative",
    "number": "Article 72",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Studying How Digital Luthiers Choose Their Tools",
    "URL": "https://doi.org/10.1145/3491102.3517656"
  },
  {
    "id": "10.1145/3491102.3517716",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cooper",
        "given": "Ned"
      },
      {
        "family": "Horne",
        "given": "Tiffanie"
      },
      {
        "family": "Hayes",
        "given": "Gillian R"
      },
      {
        "family": "Heldreth",
        "given": "Courtney"
      },
      {
        "family": "Lahav",
        "given": "Michal"
      },
      {
        "family": "Holbrook",
        "given": "Jess"
      },
      {
        "family": "Wilcox",
        "given": "Lauren"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "HCI researchers have been gradually shifting attention from individual users to communities when engaging in research, design, and system development. However, our field has yet to establish a cohesive, systematic understanding of the challenges, benefits, and commitments of community-collaborative approaches to research. We conducted a systematic review and thematic analysis of 47 computing research papers discussing participatory research with communities for the development of technological artifacts and systems, published over the last two decades. From this review, we identified seven themes associated with the evolution of a project: from establishing community partnerships to sustaining results. Our findings suggest that several tensions characterize these projects, many of which relate to the power and position of researchers, and the computing research environment, relative to community partners. We discuss the implications of our findings and offer methodological proposals to guide HCI, and computing research more broadly, towards practices that center communities.",
    "call-number": "10.1145/3491102.3517716",
    "collection-number": "73",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517716",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Meta-Analysis/Literature Survey, Research Methods",
    "number": "Article 73",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Systematic Review and Thematic Analysis of Community-Collaborative Approaches to Computing Research",
    "URL": "https://doi.org/10.1145/3491102.3517716"
  },
  {
    "id": "10.1145/3491102.3517659",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shi",
        "given": "Chuhan"
      },
      {
        "family": "Jiang",
        "given": "Zhihan"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      },
      {
        "family": "Luo",
        "given": "Qiong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "It is challenging for customers to select appearance building products (e.g., skincare products, weight loss programs) that suit them personally as such products usually demonstrate efficacy only after long-term usage. Although e-retailers generally provide product descriptions or other customers\u2019 reviews, users often find it hard to relate to their own situations. In this work, we proposed a pipeline to display envisioned users\u2019 appearance after long-term use of appearance building products to deliver their efficacy on each individual visually. We selected skincare as a case and developed SkincareMirror which predicts skincare effects on users\u2019 facial images by analyzing product function labels, efficacy ratings, and skin models\u2019 images. The results of a between-subjects study (N=48) show that (1) SkincareMirror outperforms the baseline shopping site in terms of perceived usability, usefulness, user satisfaction and helps users select products faster; (2) SkincareMirror is especially effective to males and users with limited product domain knowledge.",
    "call-number": "10.1145/3491102.3517659",
    "collection-number": "74",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517659",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "virtual try-on, Appearance building products, decision-making, personalized visual aid",
    "number": "Article 74",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Personalized Visual Aid for Selections of Appearance Building Products with Long-term Effects",
    "URL": "https://doi.org/10.1145/3491102.3517659"
  },
  {
    "id": "10.1145/3491102.3502066",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nurgalieva",
        "given": "Leysan"
      },
      {
        "family": "Ryan",
        "given": "Seamus"
      },
      {
        "family": "Balaskas",
        "given": "Andreas"
      },
      {
        "family": "Lindqvist",
        "given": "Janne"
      },
      {
        "family": "Doherty",
        "given": "Gavin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The COVID-19 pandemic has led governments worldwide to introduce various measures restricting human activity and mobility. Along with the administration of COVID-19 vaccinations and rapid testing, socio-technological solutions such as digital COVID-19 certificates have been considered as a strategy to lessen these restrictions and allow the resumption of routine activities. Using a mixed-methods approach \u2013 a survey (n=1008) and 27 semi-structured interviews \u2013 this study explores the attitudes of residents in the Republic of Ireland towards the idea of introducing digital COVID-19 certificates. We examine the topics of acceptability, fairness, security and privacy of COVID-related personal data, and practical considerations for implementation. Our study reveals the conditional and contextual nature of the acceptability of digital certificates, identifying specific factors that affect it, associated data practices, and related public concerns and expectations of such technologies.",
    "call-number": "10.1145/3491102.3502066",
    "collection-number": "75",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502066",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "privacy, COVID-19, COVID certificate, security, fairness, digital health",
    "number": "Article 75",
    "number-of-pages": "28",
    "page": "1\u201328",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Public Views on Digital COVID-19 Certificates: a Mixed Methods User Study",
    "URL": "https://doi.org/10.1145/3491102.3502066"
  },
  {
    "id": "10.1145/3491102.3517703",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hall",
        "given": "Kaely"
      },
      {
        "family": "Yoo",
        "given": "Dong Whi"
      },
      {
        "family": "Zhang",
        "given": "Wenrui"
      },
      {
        "family": "Bin Morshed",
        "given": "Mehrab"
      },
      {
        "family": "Das Swain",
        "given": "Vedant"
      },
      {
        "family": "Abowd",
        "given": "Gregory D."
      },
      {
        "family": "De Choudhury",
        "given": "Munmun"
      },
      {
        "family": "Endert",
        "given": "Alex"
      },
      {
        "family": "Stasko",
        "given": "John"
      },
      {
        "family": "Kim",
        "given": "Jennifer G"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Contact tracers assist in containing the spread of highly infectious diseases such as COVID-19 by engaging community members who receive a positive test result in order to identify close contacts. Many contact tracers rely on community member\u2019s recall for those identifications, and face limitations such as unreliable memory. To investigate how technology can alleviate this challenge, we developed a visualization tool using de-identified location data sensed from campus WiFi and provided it to contact tracers during mock contact tracing calls. While the visualization allowed contact tracers to find and address inconsistencies due to gaps in community member\u2019s memory, it also introduced inconsistencies such as false-positive and false-negative reports due to imperfect data, and information sharing hesitancy. We suggest design implications for technologies that can better highlight and inform contact tracers of potential areas of inconsistencies, and further present discussion on using imperfect data in decision making.",
    "call-number": "10.1145/3491102.3517703",
    "collection-number": "76",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517703",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "contact tracing, visualization, WiFi data",
    "number": "Article 76",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting the Contact Tracing Process with WiFi Location Data: Opportunities and Challenges",
    "URL": "https://doi.org/10.1145/3491102.3517703"
  },
  {
    "id": "10.1145/3491102.3517595",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zakaria",
        "given": "Camellia"
      },
      {
        "family": "Foong",
        "given": "Pin Sym"
      },
      {
        "family": "Lim",
        "given": "Chang Siang"
      },
      {
        "family": "V. S. Pakianathan",
        "given": "Pavithren"
      },
      {
        "family": "Koh",
        "given": "Gerald Huat Choon"
      },
      {
        "family": "Perrault",
        "given": "Simon Tangi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Digital contact tracing can limit the spread of infectious diseases. Nevertheless, barriers remain to attain sufficient adoption. In this study, we investigate how willingness to participate in contact tracing is affected by two critical factors: the modes of data collection and the type of data collected. We conducted a scenario-based survey study among 220 respondents in the United States (U.S.) to understand their perceptions about contact tracing associated with automated and manual contact tracing methods. The findings indicate a promising use of smartphones and a combination of public health officials and medical health records as information sources. Through a quantitative analysis, we describe how different modalities and individual demographic factors may affect user compliance when participants are asked to provide four key information pieces for contact tracing.",
    "call-number": "10.1145/3491102.3517595",
    "collection-number": "77",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517595",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "contact tracing, willingness, pandemic, trust, public health",
    "number": "Article 77",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Does Mode of Digital Contact Tracing Affect User Willingness to Share Information? A Quantitative Study",
    "URL": "https://doi.org/10.1145/3491102.3517595"
  },
  {
    "id": "10.1145/3491102.3501889",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Yixuan"
      },
      {
        "family": "Suhaimi",
        "given": "Nurul"
      },
      {
        "family": "Yongsatianchot",
        "given": "Nutchanon"
      },
      {
        "family": "Gaggiano",
        "given": "Joseph D"
      },
      {
        "family": "Kim",
        "given": "Miso"
      },
      {
        "family": "Patel",
        "given": "Shivani A"
      },
      {
        "family": "Sun",
        "given": "Yifan"
      },
      {
        "family": "Marsella",
        "given": "Stacy"
      },
      {
        "family": "Griffin",
        "given": "Jacqueline"
      },
      {
        "family": "Parker",
        "given": "Andrea G"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "During crises like COVID-19, individuals are inundated with conflicting and time-sensitive information that drives a need for rapid assessment of the trustworthiness and reliability of information sources and platforms. This parallels evolutions in information infrastructures, ranging from social media to government data platforms. Distinct from current literature, which presumes a static relationship between the presence or absence of trust and people\u2019s behaviors, our mixed-methods research focuses on situated trust, or trust that is shaped by people\u2019s information-seeking and assessment practices through emerging information platforms (e.g., social media, crowdsourced systems, COVID data platforms). Our findings characterize the shifts in trustee (what/who people trust) from information on social media to the social media platform(s), how distrust manifests skepticism in issues of data discrepancy, the insufficient presentation of uncertainty, and how this trust and distrust shift over time. We highlight the deep challenges in existing information infrastructures that influence trust and distrust formation.",
    "call-number": "10.1145/3491102.3501889",
    "collection-number": "78",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501889",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "trust, information infrastructure, crisis informatics, misinformation, longitudinal research, COVID-19, social media, distrust, information behaviors, mixed methods",
    "number": "Article 78",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Shifting Trust: Examining How Trust and Distrust Emerge, Transform, and Collapse in COVID-19 Information Seeking",
    "URL": "https://doi.org/10.1145/3491102.3501889"
  },
  {
    "id": "10.1145/3491102.3502138",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fan",
        "given": "Arlen"
      },
      {
        "family": "Ma",
        "given": "Yuxin"
      },
      {
        "family": "Mancenido",
        "given": "Michelle"
      },
      {
        "family": "Maciejewski",
        "given": "Ross"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Deceptive visualizations are visualizations that, whether intentionally or not, lead the reader to an understanding of the data which varies from the actual data. Examples of deceptive visualizations can be found in every digital platform, and, despite their widespread use in the wild, there have been limited efforts to alert laypersons to common deceptive visualization practices. In this paper, we present a tool for annotating line charts in the wild that reads line chart images and outputs text and visual annotations to assess the line charts for distortions and help guide the reader towards an honest understanding of the chart data. We demonstrate the usefulness of our tool through a series of case studies on real-world charts. Finally, we perform a crowdsourced experiment to evaluate the ability of the proposed tool to educate readers about potentially deceptive visualization practices.",
    "call-number": "10.1145/3491102.3502138",
    "collection-number": "80",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502138",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "deceptive visualization, visual literacy, educational tools",
    "number": "Article 80",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Annotating Line Charts for Addressing Deception",
    "URL": "https://doi.org/10.1145/3491102.3502138"
  },
  {
    "id": "10.1145/3491102.3501939",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bae",
        "given": "S. Sandra"
      },
      {
        "family": "Zheng",
        "given": "Clement"
      },
      {
        "family": "West",
        "given": "Mary Etta"
      },
      {
        "family": "Do",
        "given": "Ellen Yi-Luen"
      },
      {
        "family": "Huron",
        "given": "Samuel"
      },
      {
        "family": "Szafir",
        "given": "Danielle Albers"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Designing a data physicalization requires a myriad of different considerations. Despite the cross-disciplinary nature of these considerations, research currently lacks a synthesis across the different communities data physicalization sits upon, including their approaches, theories, and even terminologies. To bridge these communities synergistically, we present a design space that describes and analyzes physicalizations according to three facets: context (end-user considerations), structure (the physical structure of the artifact), and interactions (interactions with both the artifact and data). We construct this design space through a systematic review of 47 physicalizations and analyze the interrelationships of key factors when designing a physicalization. This design space cross-pollinates knowledge from relevant HCI communities, providing a cohesive overview of what designers should consider when creating a data physicalization while suggesting new design possibilities. We analyze the design decisions present in current physicalizations, discuss emerging trends, and identify underlying open challenges.",
    "call-number": "10.1145/3491102.3501939",
    "collection-number": "81",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501939",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design, data visualization, design space, tangible user interface, data physicalization",
    "number": "Article 81",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Making Data Tangible: A Cross-disciplinary Design Space for Data Physicalization",
    "URL": "https://doi.org/10.1145/3491102.3501939"
  },
  {
    "id": "10.1145/3491102.3501952",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sauv\u00e9",
        "given": "Kim"
      },
      {
        "family": "Ramirez Gomez",
        "given": "Argenis"
      },
      {
        "family": "Houben",
        "given": "Steven"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Physicalizations represent data through their tangible and material properties. In contrast to screen-based visualizations, there is currently very limited understanding of how to label or annotate physicalizations to support people in interpreting the data encoded by the physicalization. Because of its spatiality, contextualization through labeling or annotation is crucial to communicate data across different orientations. In this paper, we study labeling approaches as part of the overall construction process of bar chart physicalizations. We designed a toolkit of physical tokens and paper data labels and asked 16 participants to construct and contextualize their own data physicalizations. We found that (i) the construction and contextualization of physicalizations is a highly intertwined process, (ii) data labels are integrated with physical constructs in the final design, and (iii) these are both influenced by orientation changes. We contribute with an understanding of the role of data labeling in the creation and contextualization of physicalizations.",
    "call-number": "10.1145/3491102.3501952",
    "collection-number": "82",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501952",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Constructive Visualization, Data Labels, Data Physicalization, Physical Visualization",
    "number": "Article 82",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Put a Label On It! Approaches for Constructing and Contextualizing Bar Chart Physicalizations",
    "URL": "https://doi.org/10.1145/3491102.3501952"
  },
  {
    "id": "10.1145/3491102.3517630",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Joyner",
        "given": "Shakila Cherise S"
      },
      {
        "family": "Riegelhuth",
        "given": "Amalia"
      },
      {
        "family": "Garrity",
        "given": "Kathleen"
      },
      {
        "family": "Kim",
        "given": "Yea-Seul"
      },
      {
        "family": "Kim",
        "given": "Nam Wook"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data visualizations are now widely used across many disciplines. However, many of them are not easily accessible for visually impaired people. In this work, we use three-staged mixed methods to understand the current practice of accessible visualization design for visually impaired people. We analyzed 95 visualizations from various venues to inspect how they are made inaccessible. To understand the rationale and context behind the design choices, we also conducted surveys with 144 practitioners in the U.S. and follow-up interviews with ten selected survey participants. Our findings include the difficulties of handling modern complex and interactive visualizations and the lack of accessibility support from visualization tools in addition to personal and organizational factors making it challenging to perform accessible design practices.",
    "call-number": "10.1145/3491102.3517630",
    "collection-number": "83",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517630",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "a11y, data visualization, visual impairment, inclusive design",
    "number": "Article 83",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Visualization Accessibility in the Wild: Challenges Faced by Visualization Designers",
    "URL": "https://doi.org/10.1145/3491102.3517630"
  },
  {
    "id": "10.1145/3491102.3517673",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yang",
        "given": "Yalong"
      },
      {
        "family": "Xia",
        "given": "Wenyu"
      },
      {
        "family": "Lekschas",
        "given": "Fritz"
      },
      {
        "family": "Nobre",
        "given": "Carolina"
      },
      {
        "family": "Kr\u00fcger",
        "given": "Robert"
      },
      {
        "family": "Pfister",
        "given": "Hanspeter"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Matrix visualizations are widely used to display large-scale network, tabular, set, or sequential data. They typically only encode a single value per cell, e.g., through color. However, this can greatly limit the visualizations\u2019 utility when exploring multivariate data, where each cell represents a data point with multiple values (referred to as details). Three well-established interaction approaches can be applicable in multivariate matrix visualizations (or MMV): focus+context, pan&zoom, and overview+detail. However, there is little empirical knowledge of how these approaches compare in exploring MMV. We report on two studies comparing them for locating, searching, and contextualizing details in MMV. We first compared four focus+context techniques and found that the fisheye lens overall outperformed the others. We then compared the fisheye lens, to pan&zoom and overview+detail. We found that pan&zoom was faster in locating and searching details, and as good as overview+detail in contextualizing details.",
    "call-number": "10.1145/3491102.3517673",
    "collection-number": "84",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517673",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "multivariate, overview+detail, focus+context, Multi-level navigation, matrix, pan&zoom",
    "number": "Article 84",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Pattern is in the Details: An Evaluation of Interaction Techniques for Locating, Searching, and Contextualizing Details in Multivariate Matrix Visualizations",
    "URL": "https://doi.org/10.1145/3491102.3517673"
  },
  {
    "id": "10.1145/3491102.3517712",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Xie",
        "given": "Laixin"
      },
      {
        "family": "Wu",
        "given": "Ziming"
      },
      {
        "family": "Xu",
        "given": "Peng"
      },
      {
        "family": "Li",
        "given": "Wei"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      },
      {
        "family": "Li",
        "given": "Quan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Massively multiplayer online role-playing games create virtual communities that support heterogeneous \u201csocial roles\u201d determined by gameplay interaction behaviors under a specific social context. For all social roles, formal roles are pre-defined, obvious, and explicitly ascribed to the people holding the roles, whereas informal roles are not well-defined and unspoken. Identifying the informal roles and understanding their subtle changes are critical to designing sociability mechanisms. However, it is nontrivial to understand the existence and evolution of such roles due to their loosely defined, interconvertible, and dynamic characteristics. We propose a visual analytics system, RoleSeer, to investigate informal roles from the perspectives of behavioral interactions and depict their dynamic interconversions and transitions. Two cases, experts\u2019 feedback, and a user study suggest that RoleSeer helps interpret the identified informal roles and explore the patterns behind role changes. We see our approach\u2019s potential in investigating informal roles in a broader range of social games.",
    "call-number": "10.1145/3491102.3517712",
    "collection-number": "85",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517712",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "social role, gameplay, social network, graph embedding",
    "number": "Article 85",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "RoleSeer: Understanding Informal Social Role Changes in MMORPGs via Visual Analytics",
    "URL": "https://doi.org/10.1145/3491102.3517712"
  },
  {
    "id": "10.1145/3491102.3501867",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mason",
        "given": "Liam"
      },
      {
        "family": "Gerling",
        "given": "Kathrin"
      },
      {
        "family": "Dickinson",
        "given": "Patrick"
      },
      {
        "family": "Holopainen",
        "given": "Jussi"
      },
      {
        "family": "Jacobs",
        "given": "Lisa"
      },
      {
        "family": "Hicks",
        "given": "Kieran"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Movement-based video games can provide engaging play experiences, and also have the potential to encourage physical activity. However, existing design guidelines for such games overwhelmingly focus on non-disabled players. Here, we explore wheelchair users\u2019 perspectives on movement-based games as an enjoyable play activity. We created eight game concepts as discussion points for semi-structured interviews (N=6) with wheelchair users, and used Interpretative Phenomenological Analysis to understand their perspectives on physical activity and play. Themes focus on independent access, challenges in social settings, and the need for comprehensive adaptation. We also conducted an online survey (N=21) using the same game concepts, and thematic analysis highlighted the importance of adequate challenge, and considerations around multiplayer experiences. Based on these findings, we re-contextualize and expand guidelines for movement-based games previously established by Mueller and Isbister to include disabled players, and suggest design strategies that take into account their perspectives on play.",
    "call-number": "10.1145/3491102.3501867",
    "collection-number": "86",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501867",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Game accessibility, game design, movement-based games",
    "number": "Article 86",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Including the Experiences of Physically Disabled Players in Mainstream Guidelines for Movement-Based Games",
    "URL": "https://doi.org/10.1145/3491102.3501867"
  },
  {
    "id": "10.1145/3491102.3517721",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Turakhia",
        "given": "Dishita G"
      },
      {
        "family": "Mueller",
        "given": "Stefanie"
      },
      {
        "family": "DesPortes",
        "given": "Kayla"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Integrating fabrication activities into existing video games provides opportunities for players to construct objects from their gameplay and bring the digital content into the physical world. In our prior work, we outlined a framework and developed a toolkit for integrating fabrication activities within existing digital games. Insights from our prior study highlighted the challenge of aligning fabrication mechanics with the existing game mechanics in order to strengthen the player aesthetics. In this paper, we address this challenge and build on our prior work by adding fabrication components to the Mechanics-Dynamics-Aesthetics (MDA) framework. We use this f-MDA framework to analyze the 47 fabrication events from the prior study. We list the new player-object aesthetics that emerge from integrating the existing game mechanics with fabrication mechanics. We identify connections between these emergent player-object aesthetics and the existing game mechanics. We discuss how designers can use this mapping to identify potential game mechanics for integrating with fabrication activities.",
    "call-number": "10.1145/3491102.3517721",
    "collection-number": "87",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517721",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "fabrication games, game design framework, physical fabrication",
    "number": "Article 87",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Identifying Game Mechanics for Integrating Fabrication Activities within Existing Digital Games",
    "URL": "https://doi.org/10.1145/3491102.3517721"
  },
  {
    "id": "10.1145/3491102.3517499",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ram",
        "given": "Ashwin"
      },
      {
        "family": "Zhao",
        "given": "Shengdong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Dynamically drawn content (e.g., handwritten text) in learning videos is believed to improve users\u2019 engagement and learning over static powerpoint-based ones. However, evidence from existing literature is inconclusive. With the emergence of Optical Head-Mounted Displays (OHMDs), recent work has shown that video learning can be adapted for on-the-go scenarios. To better understand the role of dynamic drawing, we decoupled dynamically drawn text into two factors (font style and motion of appearance) and studied their impact on learning performance under two usage scenarios (while seated with desktop and walking with OHMD). We found that although letter-traced text was more engaging for some users, most preferred learning with typeface text that displayed the entire word at once and achieved better recall (46.7% higher), regardless of the usage scenarios. Insights learned from the studies can better inform designers on how to present text in videos for ubiquitous access.",
    "call-number": "10.1145/3491102.3517499",
    "collection-number": "89",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517499",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Heads-up computing, Video learning, Dynamic drawing, OHMD, Text presentation styles, Mobile HCI, Smart-glasses",
    "number": "Article 89",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Does Dynamically Drawn Text Improve Learning? Investigating the Effect of Text Presentation Styles in Video Learning",
    "URL": "https://doi.org/10.1145/3491102.3517499"
  },
  {
    "id": "10.1145/3491102.3517735",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Semeraro",
        "given": "Alessandra"
      },
      {
        "family": "Turmo Vidal",
        "given": "Laia"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Instructional videos for physical training have gained popularity in recent years among sport and fitness practitioners, due to the proliferation of affordable and ubiquitous forms of online training. Yet, learning movement this way poses challenges: lack of feedback and personalised instructions, and having to rely on personal imitation capacity to learn movements. We address some of these challenges by exploring visual cues\u2019 potential to help people imitate movements from instructional videos. With a Research through Design approach, focused on strength training, we augmented an instructional video with different sets of visual cues: directional cues, body highlights, and metaphorical visualizations. We tested each set with ten practitioners over three recorded sessions, with follow-up interviews. Through thematic analysis, we derived insights on the effect of each set of cues for supporting movement learning. Finally, we generated design takeaways to inform future HCI work on visual cues for instructional training videos.",
    "call-number": "10.1145/3491102.3517735",
    "collection-number": "90",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517735",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Visual cues, fitness, video learning, physical training, sports, instructional videos, movement learning",
    "number": "Article 90",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Visualizing Instructions for Physical Training: Exploring Visual Cues to Support Movement Learning from Instructional Videos",
    "URL": "https://doi.org/10.1145/3491102.3517735"
  },
  {
    "id": "10.1145/3491102.3517468",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Huang",
        "given": "Kevin"
      },
      {
        "family": "Li",
        "given": "Jiannan"
      },
      {
        "family": "Sousa",
        "given": "Mauricio"
      },
      {
        "family": "Grossman",
        "given": "Tovi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "How-to videos are often shot using camera angles that may not be optimal for learning motor tasks, with a prevalent use of third-person perspective. We present immersivePOV, an approach to film how-to videos from an immersive first-person perspective using a head-mounted 360\u00b0 action camera. immersivePOV how-to videos can be viewed in a Virtual Reality headset, giving the viewer an eye-level viewpoint with three Degrees of Freedom. We evaluated our approach with two everyday motor tasks against a baseline first-person perspective and a third-person perspective. In a between-subjects study, participants were assigned to watch the task videos and then replicate the tasks. Results suggest that immersivePOV reduced perceived cognitive load and facilitated task learning. We discuss how immersivePOV can also streamline the video production process for content creators. Altogether, we conclude that immersivePOV is an effective approach to film how-to videos for learners and content creators alike.",
    "call-number": "10.1145/3491102.3517468",
    "collection-number": "91",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517468",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "POV, online learning, 360\u00b0 video, how-to video, YouTube",
    "number": "Article 91",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "immersivePOV: Filming How-To Videos with a Head-Mounted 360\u00b0 Action Camera",
    "URL": "https://doi.org/10.1145/3491102.3517468"
  },
  {
    "id": "10.1145/3491102.3502054",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Jeongyeon"
      },
      {
        "family": "Choi",
        "given": "Yubin"
      },
      {
        "family": "Xia",
        "given": "Meng"
      },
      {
        "family": "Kim",
        "given": "Juho"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Most video-based learning content is designed for desktops without considering mobile environments. We (1) investigate the gap between mobile learners\u2019 challenges and video engineers\u2019 considerations using mixed methods and (2) provide design guidelines for creating mobile-friendly MOOC videos. To uncover learners\u2019 challenges, we conducted a survey (n=134) and interviews (n=21), and evaluated the mobile adequacy of current MOOCs by analyzing 41,722 video frames from 101 video lectures. Interview results revealed low readability and situationally-induced impairments as major challenges. The content analysis showed a low guideline compliance rate for key design factors. We then interviewed 11 video production engineers to investigate design factors they mainly consider. The engineers mainly focus on the size and amount of content while lacking consideration for color, complex images, and situationally-induced impairments. Finally, we present and validate guidelines for designing mobile-friendly MOOCs, such as providing adaptive and customizable visual design and context-aware accessibility support.",
    "call-number": "10.1145/3491102.3502054",
    "collection-number": "92",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502054",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Content Design, MOOCs, Video-based Learning, Learning Difficulty, Mobile Learning",
    "number": "Article 92",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mobile-Friendly Content Design for MOOCs: Challenges, Requirements, and Design Opportunities",
    "URL": "https://doi.org/10.1145/3491102.3502054"
  },
  {
    "id": "10.1145/3491102.3517612",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Yu"
      },
      {
        "family": "Wang",
        "given": "Yun"
      },
      {
        "family": "Zhang",
        "given": "Haidong"
      },
      {
        "family": "Zhu",
        "given": "Bin"
      },
      {
        "family": "Chen",
        "given": "Siming"
      },
      {
        "family": "Zhang",
        "given": "Dongmei"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Labeled datasets are essential for supervised machine learning. Various data labeling tools have been built to collect labels in different usage scenarios. However, developing labeling tools is time-consuming, costly, and expertise-demanding on software development. In this paper, we propose a conceptual framework for data labeling and OneLabeler based on the conceptual framework to support easy building of labeling tools for diverse usage scenarios. The framework consists of common modules and states in labeling tools summarized through coding of existing tools. OneLabeler supports configuration and composition of common software modules through visual programming to build data labeling tools. A module can be a human, machine, or mixed computation procedure in data labeling. We demonstrate the expressiveness and utility of the system through ten example labeling tools built with OneLabeler. A user study with developers provides evidence that OneLabeler supports efficient building of diverse data labeling tools.",
    "call-number": "10.1145/3491102.3517612",
    "collection-number": "93",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517612",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "framework, data labeling, visual programming, toolkit, interactive machine learning",
    "number": "Article 93",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "OneLabeler: A Flexible System for Building Data Labeling Tools",
    "URL": "https://doi.org/10.1145/3491102.3517612"
  },
  {
    "id": "10.1145/3491102.3501923",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Saquib",
        "given": "Nazmus"
      },
      {
        "family": "Huq",
        "given": "Faria"
      },
      {
        "family": "Haque",
        "given": "Syed Arefinul"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Graph analytics is currently performed using a combination of code, symbolic algebra, and network visualizations. The analyst has to work with symbolic and abstract forms of data to construct and analyze graphs. We locate unique design opportunities at the intersection of computer vision and graph analytics, by utilizing visual variables extracted from images/videos and some direct manipulation and pen interaction techniques. We also summarize commonly used graph operations and graphical representations (graphs, simplicial complexes, hypergraphs), and map them to a few brushes and direct manipulation actions. The mapping enables us to visually construct and analyze a wide range of graphs on top of images, videos, and sketches. The design framework is implemented as a sketch-based notebook interface to demonstrate the design possibilities. User studies with scientists from various fields reveal innovative use cases for such an embodied interaction paradigm for graph analytics.",
    "call-number": "10.1145/3491102.3501923",
    "collection-number": "94",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501923",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "graph analytics, embodied mathematics",
    "number": "Article 94",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "graphiti: Sketch-based Graph Analytics for Images and Videos",
    "URL": "https://doi.org/10.1145/3491102.3501923"
  },
  {
    "id": "10.1145/3491102.3517485",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chen",
        "given": "Zhutian"
      },
      {
        "family": "Xia",
        "given": "Haijun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data documents play a central role in recording, presenting, and disseminating data. Despite the proliferation of applications and systems designed to support the analysis, visualization, and communication of data, writing data documents remains a laborious process, requiring a constant back-and-forth between data processing and writing tools. Interviews with eight professionals revealed that their workflows contained numerous tedious, repetitive, and error-prone operations. The key issue that we identified is the lack of persistent connection between text and data. Thus, we developed CrossData, a prototype that treats text-data connections as persistent, interactive, first-class objects. By automatically identifying, establishing, and leveraging text-data connections, CrossData enables rich interactions to assist in the authoring of data documents. An expert evaluation with eight users demonstrated the usefulness of CrossData, showing that it not only reduced the manual effort in writing data documents but also opened new possibilities to bridge the gap between data exploration and writing.",
    "call-number": "10.1145/3491102.3517485",
    "collection-number": "95",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517485",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Text-based Editing, Language-oriented Authoring, Data Document, Interactive Article, Natural Language Processing",
    "number": "Article 95",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CrossData: Leveraging Text-Data Connections for Authoring Data Documents",
    "URL": "https://doi.org/10.1145/3491102.3517485"
  },
  {
    "id": "10.1145/3491102.3502087",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Yoonjoo"
      },
      {
        "family": "Chung",
        "given": "John Joon Young"
      },
      {
        "family": "Kim",
        "given": "Tae Soo"
      },
      {
        "family": "Song",
        "given": "Jean Y"
      },
      {
        "family": "Kim",
        "given": "Juho"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online learners are hugely diverse with varying prior knowledge, but most instructional videos online are created to be one-size-fits-all. Thus, learners may struggle to understand the content by only watching the videos. Providing scaffolding prompts can help learners overcome these struggles through questions and hints that relate different concepts in the videos and elicit meaningful learning. However, serving diverse learners would require a spectrum of scaffolding prompts, which incurs high authoring effort. In this work, we introduce Promptiverse, an approach for generating diverse, multi-turn scaffolding prompts at scale, powered by numerous traversal paths over knowledge graphs. To facilitate the construction of the knowledge graphs, we propose a hybrid human-AI annotation tool, Grannotate. In our study (N=24), participants produced 40 times more on-par quality prompts with higher diversity, through Promptiverse and Grannotate, compared to hand-designed prompts. Promptiverse presents a model for creating diverse and adaptive learning experiences online.",
    "call-number": "10.1145/3491102.3502087",
    "collection-number": "96",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502087",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Scaffolding prompt, knowledge graph, human-AI hybrid annotation",
    "number": "Article 96",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Promptiverse: Scalable Generation of Scaffolding Prompts Through Human-AI Hybrid Knowledge Graph Annotation",
    "URL": "https://doi.org/10.1145/3491102.3502087"
  },
  {
    "id": "10.1145/3491102.3502123",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "April Yi"
      },
      {
        "family": "Epperson",
        "given": "Will"
      },
      {
        "family": "DeLine",
        "given": "Robert A"
      },
      {
        "family": "Drucker",
        "given": "Steven M."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data science is characterized by evolution: since data science is exploratory, results evolve from moment to moment; since it can be collaborative, results evolve as the work changes hands. While existing tools help data scientists track changes in code, they provide less support for understanding the iterative changes that the code produces in the data. We explore the idea of visualizing differences in datasets as a core feature of exploratory data analysis, a concept we call Diff in the Loop (DITL). We evaluated DITL in a user study with 16 professional data scientists and found it helped them understand the implications of their actions when manipulating data. We summarize these findings and discuss how the approach can be generalized to different data science workflows.",
    "call-number": "10.1145/3491102.3502123",
    "collection-number": "97",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502123",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "data comparison, data science programming, exploratory data analysis",
    "number": "Article 97",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Diff in the Loop: Supporting Data Comparison in Exploratory Data Analysis",
    "URL": "https://doi.org/10.1145/3491102.3502123"
  },
  {
    "id": "10.1145/3491102.3501901",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Oogjes",
        "given": "Doenja"
      },
      {
        "family": "Wakkary",
        "given": "Ron"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While much work is underway within the context of posthuman design, this research is often described from a dominantly human perspective. It rarely accounts for the creative capacities of nonhumans in design, such as materials, tools, and software. There is a need to further engage with posthuman theories conceptually, materially, and methodologically. We approach this challenge through Ron Wakkary's concept of repertoires: actions the human designer can take to increase participation of nonhumans in design research practice. This paper reports on potential repertoires' development by exploring three approaches from outside of HCI: describing the landscape, noticing, and translations. We use these methods to account for weaving events that the first author was engaged in. Through critical reflection of these accounts, we contribute three repertoires and an example of applying the theoretical framework of Designing Things.",
    "call-number": "10.1145/3491102.3501901",
    "collection-number": "98",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501901",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "designing things, weaving, posthuman design, more-than-human, posthumanism, repertoires, first-person, research through design, e-textiles",
    "number": "Article 98",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Weaving Stories: Toward Repertoires for Designing Things",
    "URL": "https://doi.org/10.1145/3491102.3501901"
  },
  {
    "id": "10.1145/3491102.3502007",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Song",
        "given": "Katherine W"
      },
      {
        "family": "Maheshwari",
        "given": "Aditi"
      },
      {
        "family": "Gallo",
        "given": "Eric M"
      },
      {
        "family": "Danielescu",
        "given": "Andreea"
      },
      {
        "family": "Paulos",
        "given": "Eric"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sustainability is critical to our planet and thus our designs. Within HCI, there is a tension between the desire to create interactive electronic systems and sustainability. In this paper, we present the design of an interactive system comprising components that are entirely decomposable. We leverage the inherent material properties of natural materials, such as paper, leaf skeletons, and chitosan, along with silver nanowires to create a new system capable of being electrically controlled as a portable heater. This new decomposable system, capable of wirelessly heating to >70\u00b0C, is flexible, lightweight, low-cost, and reusable, and it maintains its functionality over long periods of heating and multiple power cycles. We detail its design and present a series of use cases, from enabling a novel resealable packaging system to acting as a catalyst for shape-changing designs and beyond. Finally, we highlight the important decomposable property of the interactive system when it meets end-of-life.",
    "call-number": "10.1145/3491102.3502007",
    "collection-number": "100",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502007",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "biodegradation, sustainability, biodesign, decomposable materials, heating",
    "number": "Article 100",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Decomposable Interactive Systems: Design of a Backyard-Degradable Wireless Heating Interface",
    "URL": "https://doi.org/10.1145/3491102.3502007"
  },
  {
    "id": "10.1145/3491102.3501851",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Livio",
        "given": "Maya"
      },
      {
        "family": "Devendorf",
        "given": "Laura"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Given the ongoing environmental crisis and recent calls within HCI to engage with its cascading effects on the more-than-human world, this paper introduces the concept of the eco-technical interface as a critical zone at which designers can surface and subvert issues of multispecies relations such as nonhuman instrumentalization. The eco-technical interface represents the sites at which human, nonhuman, and technological interfaces overlap, ranging from remote sensing for conservation to smart devices for precision agriculture to community science platforms for species identification. Here, we highlight the pervasiveness of the eco-technical interface as a set of sites for further HCI inquiry, engage with the politics and instrumentalizing tendencies at three particular sites, and demonstrate tactics for cultivating attunement to, reflexively accounting for, and subverting instrumentalization in multispecies encounter.",
    "call-number": "10.1145/3491102.3501851",
    "collection-number": "101",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501851",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Instrumentalization, Poetic contextual inquiry, Multispecies design, Eco-technical interface, Noticing",
    "number": "Article 101",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Eco-Technical Interface: Attuning to the Instrumental",
    "URL": "https://doi.org/10.1145/3491102.3501851"
  },
  {
    "id": "10.1145/3491102.3517643",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wilkinson",
        "given": "Daricia"
      },
      {
        "family": "Knijnenburg",
        "given": "Bart"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Little is known about non-Western social media users\u2019 motivations for adopting behaviors that protect them against pervasive threats to their privacy, security, and personal well-being. Drawing on Rogers\u2019 Protection Motivation Theory (PMT), this survey study explores Caribbean people\u2019s (N=551) perceptions of safety threats and the factors contributing to their intention to adopt protective behaviors. Our analysis revealed that prior victimization was associated with increased perceptions of vulnerability and severity of harms, which, in turn, influenced elevated safety protection behaviors. For harassment-related harms in particular, participants\u2019 trust in social media sites increased their intention to adopt protective behaviors. We observe significant country-to-country differences, which we contextualize through interviews with experts throughout the region. Our findings provide a new understanding of users\u2019 mental models, behaviors, and attitudes with respect to online safety. We conclude by discussing theoretical and practical implications and outline opportunities for the design of inclusive and culturally-aware safety tools.",
    "call-number": "10.1145/3491102.3517643",
    "collection-number": "102",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517643",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "protection motivation theory, social media, survey, Caribbean, Online safety",
    "number": "Article 102",
    "number-of-pages": "25",
    "page": "1\u201325",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Many Islands, Many Problems: An Empirical Examination of Online Safety Behaviors in the Caribbean",
    "URL": "https://doi.org/10.1145/3491102.3517643"
  },
  {
    "id": "10.1145/3491102.3517446",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gamage",
        "given": "Dilrukshi"
      },
      {
        "family": "Ghasiya",
        "given": "Piyush"
      },
      {
        "family": "Bonagiri",
        "given": "Vamshi"
      },
      {
        "family": "Whiting",
        "given": "Mark E."
      },
      {
        "family": "Sasahara",
        "given": "Kazutoshi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Deepfakes are synthetic content generated using advanced deep learning and AI technologies. The advancement of technology has created opportunities for anyone to create and share deepfakes much easier. This may lead to societal concerns based on how communities engage with it. However, there is limited research available to understand how communities perceive deepfakes. We examined deepfake conversations on Reddit from 2018 to 2021\u2014including major topics and their temporal changes as well as implications of these conversations. Using a mixed-method approach\u2014topic modeling and qualitative coding, we found 6,638 posts and 86,425 comments discussing concerns of the believable nature of deepfakes and how platforms moderate them. We also found Reddit conversations to be pro-deepfake and building a community that supports creating and sharing deepfake artifacts and building a marketplace regardless of the consequences. Possible implications derived from qualitative codes indicate that deepfake conversations raise societal concerns. We propose that there are implications for Human Computer Interaction (HCI) to mitigate the harm created from deepfakes.",
    "call-number": "10.1145/3491102.3517446",
    "collection-number": "103",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517446",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "topic modeling, content analysis, deepfake, societal implication",
    "number": "Article 103",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Are Deepfakes Concerning? Analyzing Conversations of Deepfakes on Reddit and Exploring Societal Implications",
    "URL": "https://doi.org/10.1145/3491102.3517446"
  },
  {
    "id": "10.1145/3491102.3502032",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Griggio",
        "given": "Carla F."
      },
      {
        "family": "Nouwens",
        "given": "Midas"
      },
      {
        "family": "Klokmose",
        "given": "Clemens Nylandsted"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In January 2021, WhatsApp announced an update to their privacy policy, sparking an outcry that saw millions of users install other messaging apps such as Telegram and Signal. This presented a rare opportunity to study users\u2019 experiences when trying to leave the world\u2019s most popular communication app. We conducted surveys in February and May with 1525 WhatsApp users from Mexico, Spain, South Africa, and the United Kingdom. Over a quarter wanted to switch at least part of their communication to other apps, but 74% of them failed to do so. By May, 27% had increased their use of other apps, and only 16% used WhatsApp less. Beyond network effects, users struggled with making informed choices of alternative apps and with differences in their design and functionality. We suggest messaging interoperability as an approach to alleviate switching costs and discuss implications for HCI research and competition regulation of digital services.",
    "call-number": "10.1145/3491102.3502032",
    "collection-number": "104",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502032",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Privacy, Policy, Messaging Apps, Interoperability, Ecosystems of Communication Apps, Computer-Mediated Communication (CMC), Competition Regulation, WhatsApp",
    "number": "Article 104",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Caught in the Network: The Impact of WhatsApp\u2019s 2021 Privacy Policy Update on Users\u2019 Messaging App Ecosystems",
    "URL": "https://doi.org/10.1145/3491102.3502032"
  },
  {
    "id": "10.1145/3491102.3501883",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Naveed",
        "given": "Sheza"
      },
      {
        "family": "Naveed",
        "given": "Hamza"
      },
      {
        "family": "Javed",
        "given": "Mobin"
      },
      {
        "family": "Mustafa",
        "given": "Maryam"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We explore privacy perceptions, beliefs and practices of low-literate, low-income users in Pakistan, a patriarchal and religious context with a literacy rate of approx. 68% and where 59% of mobile users have less than 6 years of formal education. Through a qualitative study with 40 participants\u00a0(17 male and 23 female) we examine the cultural, religious, and familial structures that impact users perceptions, management, and control of their personal privacy. We reveal significant gendered differences in privacy understandings, privacy preserving practices and the access to privacy related knowledge. Our work also highlights the seminal impact religious beliefs have on men and women\u2019s understandings and management of privacy and the prolific use of after-market modified apps to support users specific privacy needs. The privacy concerns raised by our participants provide HCI researchers with valuable insights into designing privacy affordances for vulnerable and diverse populations beyond Western, educated, industrialized, rich and democratic contexts.",
    "call-number": "10.1145/3491102.3501883",
    "collection-number": "105",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501883",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "religion, patriarchy, privacy, South Asia, gender",
    "number": "Article 105",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dAsk this from the person who has private stuff\u201d: Privacy Perceptions, Behaviours and Beliefs Beyond W.E.I.R.D",
    "URL": "https://doi.org/10.1145/3491102.3501883"
  },
  {
    "id": "10.1145/3491102.3501947",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bowyer",
        "given": "Alex"
      },
      {
        "family": "Holt",
        "given": "Jack"
      },
      {
        "family": "Go Jefferies",
        "given": "Josephine"
      },
      {
        "family": "Wilson",
        "given": "Rob"
      },
      {
        "family": "Kirk",
        "given": "David"
      },
      {
        "family": "David Smeddinck",
        "given": "Jan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In our data-centric world, most services rely on collecting and using personal data. The EU's General Data Protection Regulation (GDPR) aims to enhance individuals\u2019 control over their data, but its practical impact is not well understood. We present a 10-participant study, where each participant filed 4-5 data access requests. Through interviews accompanying these requests and discussions scrutinising returned data, it appears that GDPR falls short of its goals due to non-compliance and low-quality responses. Participants found their hopes to understand providers\u2019 data practices or harness their own data unmet. This causes increased distrust without any subjective improvement in power, although more transparent providers do earn greater trust. We propose designing more effective, data-inclusive and open policies and data access systems to improve both customer relations and individual agency, and also that wider public use of GDPR rights could help with delivering accountability and motivating providers to improve data practices.",
    "call-number": "10.1145/3491102.3501947",
    "collection-number": "106",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501947",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "privacy, HDI, trust, data portability, digital rights, open data, information access, user empowerment, personal data, information literacy, GDPR, human-data interaction, participatory action research, data collection",
    "number": "Article 106",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Human-GDPR Interaction: Practical Experiences of Accessing Personal Data",
    "URL": "https://doi.org/10.1145/3491102.3501947"
  },
  {
    "id": "10.1145/3491102.3517704",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Goedicke",
        "given": "David"
      },
      {
        "family": "Bremers",
        "given": "Alexandra W.D."
      },
      {
        "family": "Lee",
        "given": "Sam"
      },
      {
        "family": "Bu",
        "given": "Fanjun"
      },
      {
        "family": "Yasuda",
        "given": "Hiroshi"
      },
      {
        "family": "Ju",
        "given": "Wendy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "High-fidelity driving simulators can act as testbeds for designing in-vehicle interfaces or validating the safety of novel driver assistance features. In this system paper, we develop and validate the safety of a mixed reality driving simulator system that enables us to superimpose virtual objects and events into the view of participants engaging in real-world driving in unmodified vehicles. To this end, we have validated the mixed reality system for basic driver cockpit and low-speed driving tasks, comparing the use of the system with non-headset and with the headset driving conditions, to ensure that participants behave and perform similarly using this system as they would otherwise. This paper outlines the operational procedures and protocols for using such systems for cockpit tasks (like using the parking brake, reading the instrument panel, and turn signaling) as well as basic low-speed driving exercises (such as steering around corners, weaving around obstacles, and stopping at a fixed line) in ways that are safe, effective, and lead to accurate, repeatable data collection about behavioral responses in real-world driving tasks.",
    "call-number": "10.1145/3491102.3517704",
    "collection-number": "107",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517704",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "XR, user studies, design, safety, automotive, mixed reality, driving simulation",
    "number": "Article 107",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "XR-OOM: MiXed Reality driving simulation with real cars for research and design",
    "URL": "https://doi.org/10.1145/3491102.3517704"
  },
  {
    "id": "10.1145/3491102.3502105",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ahuja",
        "given": "Karan"
      },
      {
        "family": "Shen",
        "given": "Vivian"
      },
      {
        "family": "Fang",
        "given": "Cathy Mengying"
      },
      {
        "family": "Riopelle",
        "given": "Nathan"
      },
      {
        "family": "Kong",
        "given": "Andy"
      },
      {
        "family": "Harrison",
        "given": "Chris"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present a new and practical method for capturing user body pose in virtual reality experiences: integrating cameras into handheld controllers, where batteries, computation and wireless communication already exist. By virtue of the hands operating in front of the user during many VR interactions, our controller-borne cameras can capture a superior view of the body for digitization. Our pipeline composites multiple camera views together, performs 3D body pose estimation, uses this data to control a rigged human model with inverse kinematics, and exposes the resulting user avatar to end user applications. We developed a series of demo applications illustrating the potential of our approach and more leg-centric interactions, such as balancing games and kicking soccer balls. We describe our proof-of-concept hardware and software, as well as results from our user study, which point to imminent feasibility.",
    "call-number": "10.1145/3491102.3502105",
    "collection-number": "108",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502105",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Pose Tracking, Virtual Reality, Motion Capture",
    "number": "Article 108",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ControllerPose: Inside-Out Body Capture with VR Controller Cameras",
    "URL": "https://doi.org/10.1145/3491102.3502105"
  },
  {
    "id": "10.1145/3491102.3517666",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yan",
        "given": "Yihui"
      },
      {
        "family": "Huang",
        "given": "Zezhe"
      },
      {
        "family": "Xudu",
        "given": "Feiyang"
      },
      {
        "family": "Yang",
        "given": "Zhice"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper presents Centaur, an input system that enables tangible interaction on displays, e.g., untouchable computer monitors. Centaur\u2019s tangibles are built from low-cost optical mouse sensors, or can alternatively be emulated by commercial optical mice already available. They are trackable when put on the display, rendering a real-time and high-precision tangible interface. Even for ordinary personal computers, enabling Centaur requires no new hardware and installation burden. Centaur\u2019s cost-effectiveness and wide availability open up new opportunities for tangible user interface (TUI) users and practitioners. Centaur\u2019s key innovation lies in its tracking method. It embeds high-frequency light signals into different portions of the display content as location beacons. When the tangibles are put on the screen, they are able to sense the light signals with their optical mouse sensors, and thus determine the locations accordingly. We develop four applications to showcase the potential usage of Centaur.",
    "call-number": "10.1145/3491102.3517666",
    "collection-number": "109",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517666",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Tangible, Visible Light Communication, Optical Mouse, Tabletop",
    "number": "Article 109",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Enabling Tangible Interaction on Non-touch Displays with Optical Mouse Sensor and Visible Light Communication",
    "URL": "https://doi.org/10.1145/3491102.3517666"
  },
  {
    "id": "10.1145/3491102.3502117",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Endow",
        "given": "Shreyosi"
      },
      {
        "family": "Rakib",
        "given": "Mohammad Abu Nasir"
      },
      {
        "family": "Srivastava",
        "given": "Anvay"
      },
      {
        "family": "Rastegarpouyani",
        "given": "Sara"
      },
      {
        "family": "Torres",
        "given": "Cesar"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Conductive thread is a common material in e-textile toolkits that allows practitioners to create connections between electronic components sewn on fabric. When powered, conductive threads are used as resistive heaters to activate thermochromic dyes or pigments on textiles to create interactive, aesthetic, and ambient textile displays. In this work, we introduce Embr, a creative framework for supporting hand-embroidered liquid crystal textile displays (LCTDs). This framework includes a characterization of conductive embroidery stitches, an expanded repertoire of thermal formgiving techniques, and a thread modeling tool used to simulate mechanical, thermal, and electrical behaviors of LCTDs. Through exemplar artifacts, we annotate a morphological design space of LCTDs and discuss the tensions and opportunities of satisfying the wider range of electrical, craft, cultural, aesthetic, and functional concerns inherent to e-textile practices.",
    "call-number": "10.1145/3491102.3502117",
    "collection-number": "110",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502117",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "e-textiles, craft, making",
    "number": "Article 110",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Embr: A Creative Framework for Hand Embroidered Liquid Crystal Textile Displays",
    "URL": "https://doi.org/10.1145/3491102.3502117"
  },
  {
    "id": "10.1145/3491102.3501927",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Jiannan"
      },
      {
        "family": "Sousa",
        "given": "Maur\u00edcio"
      },
      {
        "family": "Li",
        "given": "Chu"
      },
      {
        "family": "Liu",
        "given": "Jessie"
      },
      {
        "family": "Chen",
        "given": "Yan"
      },
      {
        "family": "Balakrishnan",
        "given": "Ravin"
      },
      {
        "family": "Grossman",
        "given": "Tovi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online synchronous tutoring allows for immediate engagement between instructors and audiences over distance. However, tutoring physical skills remains challenging because current telepresence approaches may not allow for adequate spatial awareness, viewpoint control of the demonstration activities scattered across an entire work area, and the instructor\u2019s sufficient awareness of the audience. We present Asteroids, a novel approach for tangible robotic telepresence, to enable workbench-scale physical embodiments of remote people and tangible interactions by the instructor. With Asteroids, the audience can actively control a swarm of mini-telepresence robots, change camera positions, and switch to other robots\u2019 viewpoints. Demonstrators can perceive the audiences\u2019 physical presence while using tangible manipulations to control the audience\u2019s viewpoints and presentation flow. We conducted an exploratory evaluation for Asteroids with 12 remote participants in a model-making tutorial scenario with an architectural expert demonstrator. Results suggest our unique features benefitted participants\u2019 engagement, sense of presence, and understanding.",
    "call-number": "10.1145/3491102.3501927",
    "collection-number": "111",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501927",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Collaboration, Physical Skill, Robots, Telepresence",
    "number": "Article 111",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ASTEROIDS: Exploring Swarms of Mini-Telepresence Robots for Physical Skill Demonstration",
    "URL": "https://doi.org/10.1145/3491102.3501927"
  },
  {
    "id": "10.1145/3491102.3501850",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chan",
        "given": "Liwei"
      },
      {
        "family": "Liao",
        "given": "Yi-Chi"
      },
      {
        "family": "Mo",
        "given": "George B"
      },
      {
        "family": "Dudley",
        "given": "John J"
      },
      {
        "family": "Cheng",
        "given": "Chun-Lien"
      },
      {
        "family": "Kristensson",
        "given": "Per Ola"
      },
      {
        "family": "Oulasvirta",
        "given": "Antti"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Designers reportedly struggle with design optimization tasks where they are asked to find a combination of design parameters that maximizes a given set of objectives. In HCI, design optimization problems are often exceedingly complex, involving multiple objectives and expensive empirical evaluations. Model-based computational design algorithms assist designers by generating design examples during design, however they assume a model of the interaction domain. Black box methods for assistance, on the other hand, can work with any design problem. However, virtually all empirical studies of this human-in-the-loop approach have been carried out by either researchers or end-users. The question stands out if such methods can help designers in realistic tasks. In this paper, we study Bayesian optimization as an algorithmic method to guide the design optimization process. It operates by proposing to a designer which design candidate to try next, given previous observations. We report observations from a comparative study with 40 novice designers who were tasked to optimize a complex 3D touch interaction technique. The optimizer helped designers explore larger proportions of the design space and arrive at a better solution, however they reported lower agency and expressiveness. Designers guided by an optimizer reported lower mental effort but also felt less creative and less in charge of the progress. We conclude that human-in-the-loop optimization can support novice designers in cases where agency is not critical.",
    "call-number": "10.1145/3491102.3501850",
    "collection-number": "112",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501850",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Touch, Interface Design, Bayesian Optimization, Human-in-the-loop Optimization, Haptics, Multi-objective Optimization",
    "number": "Article 112",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Positive and Negative Qualities of Human-in-the-Loop Optimization for Designing Interaction Techniques",
    "URL": "https://doi.org/10.1145/3491102.3501850"
  },
  {
    "id": "10.1145/3491102.3517734",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Erlei",
        "given": "Alexander"
      },
      {
        "family": "Das",
        "given": "Richeek"
      },
      {
        "family": "Meub",
        "given": "Lukas"
      },
      {
        "family": "Anand",
        "given": "Avishek"
      },
      {
        "family": "Gadiraju",
        "given": "Ujwal"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As algorithms are increasingly augmenting and substituting human decision-making, understanding how the introduction of computational agents changes the fundamentals of human behavior becomes vital. This pertains to not only users, but also those parties who face the consequences of an algorithmic decision. In a controlled experiment with 480 participants, we exploit an extended version of two-player ultimatum bargaining where responders choose to bargain with either another human, another human with an AI decision aid or an autonomous AI-system acting on behalf of a passive human proposer. Our results show strong responder preferences against the algorithm, as most responders opt for a human opponent and demand higher compensation to reach a contract with autonomous agents. To map these preferences to economic expectations, we elicit incentivized subject beliefs about their opponent\u2019s behavior. The majority of responders maximize their expected value when this is line with approaching the human proposer. In contrast, responders predicting income maximization for the autonomous AI-system overwhelmingly override economic self-interest to avoid the algorithm.",
    "call-number": "10.1145/3491102.3517734",
    "collection-number": "113",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517734",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Online Experiment, Human-AI Interaction, Ultimatum Bargaining, Market Interaction, AI system, Decision Support System",
    "number": "Article 113",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "For What It\u2019s Worth: Humans Overwrite Their Economic Self-interest to Avoid Bargaining With AI Systems",
    "URL": "https://doi.org/10.1145/3491102.3517734"
  },
  {
    "id": "10.1145/3491102.3517791",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Qiaoning"
      },
      {
        "family": "Lee",
        "given": "Matthew L"
      },
      {
        "family": "Carter",
        "given": "Scott"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People consider recommendations from AI systems in diverse domains ranging from recognizing tumors in medical images to deciding which shoes look cute with an outfit. Implicit in the decision process is the perceived expertise of the AI system. In this paper, we investigate how people trust and rely on an AI assistant that performs with different levels of expertise relative to the person, ranging from completely overlapping expertise to perfectly complementary expertise. Through a series of controlled online lab studies where participants identified objects with the help of an AI assistant, we demonstrate that participants were able to perceive when the assistant was an expert or non-expert within the same task and calibrate their reliance on the AI to improve team performance. We also demonstrate that communicating expertise through the linguistic properties of the explanation text was effective, where embracing language increased reliance and distancing language reduced reliance on AI.",
    "call-number": "10.1145/3491102.3517791",
    "collection-number": "114",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517791",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "trust, complementary expertise, human-AI teams, explainable AI",
    "number": "Article 114",
    "number-of-pages": "28",
    "page": "1\u201328",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "You Complete Me: Human-AI Teams and Complementary Expertise",
    "URL": "https://doi.org/10.1145/3491102.3517791"
  },
  {
    "id": "10.1145/3491102.3502004",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gordon",
        "given": "Mitchell L."
      },
      {
        "family": "Lam",
        "given": "Michelle S."
      },
      {
        "family": "Park",
        "given": "Joon Sung"
      },
      {
        "family": "Patel",
        "given": "Kayur"
      },
      {
        "family": "Hancock",
        "given": "Jeff"
      },
      {
        "family": "Hashimoto",
        "given": "Tatsunori"
      },
      {
        "family": "Bernstein",
        "given": "Michael S."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups\u2019 labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifier\u2019s prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators\u2019 models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent. A field evaluation finds that practitioners construct diverse juries that alter 14% of classification outcomes.",
    "call-number": "10.1145/3491102.3502004",
    "collection-number": "115",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502004",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 115",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Jury Learning: Integrating Dissenting Voices into Machine Learning Models",
    "URL": "https://doi.org/10.1145/3491102.3502004"
  },
  {
    "id": "10.1145/3491102.3501912",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Viswanathan",
        "given": "Sruthi"
      },
      {
        "family": "Omidvar-Tehrani",
        "given": "Behrooz"
      },
      {
        "family": "Renders",
        "given": "Jean-Michel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Is recommendation the new search? Recommender systems have shortened the search for information in everyday activities such as following the news, media, and shopping. In this paper, we address the challenges of capturing the situational needs of the user and linking them to the available datasets with the concept of Mindsets. Mindsets are categories such as \u201cI\u2019m hungry\u201d and \u201cSurprise me\u201d designed to lead the users to explicitly state their intent, control the recommended content, save time, get inspired, and gain shortcuts for a satisficing exploration of POI recommendations. In our methodology, we first compiled Mindsets with a card sorting workshop and a formative evaluation. Using the insights gathered from potential end users, we then quantified Mindsets by linking them to POI utility measures using approximated lexicographic multi-objective optimisation. Finally, we ran a summative evaluation of Mindsets and derived guidelines for designing novel categories for recommender systems.",
    "call-number": "10.1145/3491102.3501912",
    "collection-number": "116",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501912",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "POI recommendation, Category-based interface, Multi-objective optimisation., urban exploration, Mindsets, Satisficing, POI exploration",
    "number": "Article 116",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "What is Your Current Mindset?",
    "URL": "https://doi.org/10.1145/3491102.3501912"
  },
  {
    "id": "10.1145/3491102.3502129",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jicol",
        "given": "Crescent"
      },
      {
        "family": "Feltham",
        "given": "Julia"
      },
      {
        "family": "Yoon",
        "given": "Jinha"
      },
      {
        "family": "Proulx",
        "given": "Michael J"
      },
      {
        "family": "O'Neill",
        "given": "Eamonn"
      },
      {
        "family": "Lutteroth",
        "given": "Christof"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Street harassment is a widespread problem that can constrain people\u2019s freedom to enjoy public spaces safely, along with many other negative psychological impacts. However, very little research has looked at how immersive technology can help in addressing it. We conducted three studies to investigate the design decisions, ethical issues and efficacy of an immersive simulation of street harassment: an online design study (n=20), an interview study with experts working in the area (n=9), and a comparative lab study investigating design, ethics and efficacy (n=44). Our results deepen understanding of the design decisions that contribute to a realistic psychological experience, such as the effects of screen-based video vs passive VR vs interactive VR. They also highlight important ethical issues such as traumatisation and potential for victim blaming, and how they can be approached in an ethical manner. Finally, they provide insights into efficacy in terms of perceived usefulness, competence and empathy.",
    "call-number": "10.1145/3491102.3502129",
    "collection-number": "117",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502129",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "street harassment, ethics, virtual reality, design",
    "number": "Article 117",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing and Assessing a Virtual Reality Simulation to Build Resilience to Street Harassment",
    "URL": "https://doi.org/10.1145/3491102.3502129"
  },
  {
    "id": "10.1145/3491102.3502082",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Freeman",
        "given": "Guo"
      },
      {
        "family": "Maloney",
        "given": "Divine"
      },
      {
        "family": "Acena",
        "given": "Dane"
      },
      {
        "family": "Barwulor",
        "given": "Catherine"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The contemporary understanding of gender continues to highlight the complexity and variety of gender identities beyond a binary dichotomy regarding one\u2019s biological sex assigned at birth. The emergence and popularity of various online social spaces also makes the digital presentation of gender even more sophisticated. In this paper, we use non-cisgender as an umbrella term to describe diverse gender identities that do not match people\u2019s sex assigned at birth, including Transgender, Genderfluid, and Non-binary. We especially explore non-cisgender individuals\u2019 identity practices and their challenges in novel social Virtual Reality (VR) spaces where they can present, express, and experiment their identity in ways that traditional online social spaces cannot provide. We provide one of the first empirical evidence of how social VR platforms may introduce new and novel phenomena and practices of approaching diverse gender identities online. We also contribute to re-conceptualizing technology-supported identity practices by highlighting the role of (re)discovering the physical body online and informing the design of the emerging metaverse for supporting diverse gender identities in the future.",
    "call-number": "10.1145/3491102.3502082",
    "collection-number": "118",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502082",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "non-cisgender, social virtual reality, gender presentation online, embodied interaction",
    "number": "Article 118",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "(Re)discovering the Physical Body Online: Strategies and Challenges to Approach Non-Cisgender Identity in Social Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3502082"
  },
  {
    "id": "10.1145/3491102.3517742",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Saxena",
        "given": "Devansh"
      },
      {
        "family": "Moon",
        "given": "Seh Young"
      },
      {
        "family": "Shehata",
        "given": "Dahlia"
      },
      {
        "family": "Guha",
        "given": "Shion"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Caseworkers are trained to write detailed narratives about families in Child-Welfare (CW) which informs collaborative high-stakes decision-making. Unlike other administrative data, these narratives offer a more credible source of information with respect to workers\u2019 interactions with families as well as underscore the role of systemic factors in decision-making. SIGCHI researchers have emphasized the need to understand human discretion at the street-level to be able to design human-centered algorithms for the public sector. In this study, we conducted computational text analysis of casenotes at a child-welfare agency in the midwestern United States and highlight patterns of invisible street-level discretionary work and latent power structures that have direct implications for algorithm design. Casenotes offer a unique lens for policymakers and CW leadership towards understanding the experiences of on-the-ground caseworkers. As a result of this study, we highlight how street-level discretionary work needs to be supported by sociotechnical systems developed through worker-centered design. This study offers the first computational inspection of casenotes and introduces them to the SIGCHI community as a critical data source for studying complex sociotechnical systems.",
    "call-number": "10.1145/3491102.3517742",
    "collection-number": "120",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517742",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "invisible labor, topic modeling, child-welfare system, human discretion, worker-centered design, computational text analysis, casenotes",
    "number": "Article 120",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Unpacking Invisible Work Practices, Constraints, and Latent Power Relationships in Child Welfare through Casenote Analysis",
    "URL": "https://doi.org/10.1145/3491102.3517742"
  },
  {
    "id": "10.1145/3491102.3501879",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Thomas",
        "given": "Kurt"
      },
      {
        "family": "Kelley",
        "given": "Patrick Gage"
      },
      {
        "family": "Consolvo",
        "given": "Sunny"
      },
      {
        "family": "Samermit",
        "given": "Patrawat"
      },
      {
        "family": "Bursztein",
        "given": "Elie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Content creators\u2014social media personalities with large audiences on platforms like Instagram, TikTok, and YouTube\u2014face a heightened risk of online hate and harassment. We surveyed 135 creators to understand their personal experiences with attacks (including toxic comments, impersonation, stalking, and more), the coping practices they employ, and gaps they experience with existing solutions (such as moderation or reporting). We find that while a majority of creators view audience interactions favorably, nearly every creator could recall at least one incident of hate and harassment, and attacks are a regular occurrence for one in three creators. As a result of hate and harassment, creators report self-censoring their content and leaving platforms. Through their personal stories, their attitudes towards platform-provided tools, and their strategies for coping with attacks and harms, we inform the broader design space for how to better protect people online from hate and harassment.",
    "call-number": "10.1145/3491102.3501879",
    "collection-number": "121",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501879",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Security and privacy, hate, content moderation, harassment, creators",
    "number": "Article 121",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt\u2019s common and a part of being a content creator\u201d: Understanding How Creators Experience and Cope with Hate and Harassment Online",
    "URL": "https://doi.org/10.1145/3491102.3501879"
  },
  {
    "id": "10.1145/3491102.3517613",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Breen",
        "given": "Casey"
      },
      {
        "family": "Herley",
        "given": "Cormac"
      },
      {
        "family": "Redmiles",
        "given": "Elissa M."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We know surprisingly little about the prevalence and severity of cybercrime in the U.S. Yet, in order to prioritize the development and distribution of advice and technology to protect end users, we require empirical evidence regarding cybercrime. Measuring crime, including cybercrime, is a challenging problem that relies on a combination of direct crime reports to the government \u2013 which have known issues of under-reporting \u2013 and assessment via carefully-designed self-report surveys. We report on the first large-scale, nationally representative academic survey (n=11,953) of consumer cybercrime experiences in the U.S. Our analysis answers four research questions: (1) What is the prevalence and (2) the monetary impact of these cybercrimes we measure in the U.S.?, (3) Do inequities exist in victimization?, and (4) Can we improve cybercrime measurement by leveraging social-reporting techniques used to measure physical crime? Our analysis also offers insight toward improving future measurement of cybercrime and protecting users.",
    "call-number": "10.1145/3491102.3517613",
    "collection-number": "122",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517613",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "cybercrime, digitial inequity, network scale-up",
    "number": "Article 122",
    "number-of-pages": "41",
    "page": "1\u201341",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Large-Scale Measurement of Cybercrime Against Individuals",
    "URL": "https://doi.org/10.1145/3491102.3517613"
  },
  {
    "id": "10.1145/3491102.3502038",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tseng",
        "given": "Emily"
      },
      {
        "family": "Sabet",
        "given": "Mehrnaz"
      },
      {
        "family": "Bellini",
        "given": "Rosanna"
      },
      {
        "family": "Sodhi",
        "given": "Harkiran Kaur"
      },
      {
        "family": "Ristenpart",
        "given": "Thomas"
      },
      {
        "family": "Dell",
        "given": "Nicola"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Survivors of intimate partner violence (IPV) face complex threats to their digital privacy and security. Prior work has established protocols for directly helping them mitigate these harms; however, there remains a need for flexible and pluralistic systems that can support survivors\u2019 long-term needs. This paper describes the design and development of sociotechnical infrastructure that incorporates feminist notions of care to connect IPV survivors experiencing technology abuse with volunteer computer security consultants. We present findings from a mixed methods study that draws on data from an 8-month, real-world deployment, as well as interviews with 7 volunteer technology consultants and 18 IPV professionals. Our findings illuminate emergent challenges in safely and adaptively providing computer security advice as care. We discuss implications of these findings for feminist approaches to computer security and privacy, and provide broader lessons for interventions that aim to directly assist at-risk and marginalized people experiencing digital insecurity.",
    "call-number": "10.1145/3491102.3502038",
    "collection-number": "123",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502038",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "intimate partner violence, gender-based violence, computer security and privacy, care",
    "number": "Article 123",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Care Infrastructures for Digital Security in Intimate Partner Violence",
    "URL": "https://doi.org/10.1145/3491102.3502038"
  },
  {
    "id": "10.1145/3491102.3517444",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Spagnolli",
        "given": "Anna"
      },
      {
        "family": "Masotina",
        "given": "Mariavittoria"
      },
      {
        "family": "Scarcia",
        "given": "Annalorena"
      },
      {
        "family": "Zuffi",
        "given": "Beatrice"
      },
      {
        "family": "Gamberini",
        "given": "Luciano"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The possibility that common users are successfully recruited in cyberattacks represents a considerable vulnerability because it implies that citizens can legitimize cyberattacks instead of condemning them. We propose to adopt an argumentative approach to identify which premises allow such legitimization. To showcase this approach, we created four short narratives describing cyberattacks involving generic users and covering different motives for the attacks: profit, recreation, revenge, and ideology. A sample of 16 participants read the four narratives and was afterward interviewed to express their position on the attacks described. All interview transcripts were then analyzed with an argumentative approach, and 15 premises were found to account for the different positions taken. We describe the premises, their distribution across the four narratives, and discuss the implications of this approach for cybersecurity.",
    "call-number": "10.1145/3491102.3517444",
    "collection-number": "124",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517444",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Cybersecurity, Human factors, Argumentation, Persuasion, Cyber-attacks",
    "number": "Article 124",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How to get away with cyberattacks: An argumentative approach to cyberattacks\u2019 legitimization by common users",
    "URL": "https://doi.org/10.1145/3491102.3517444"
  },
  {
    "id": "10.1145/3491102.3517523",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kuznetsov",
        "given": "Andrew"
      },
      {
        "family": "Novotny",
        "given": "Margeigh"
      },
      {
        "family": "Klein",
        "given": "Jessica"
      },
      {
        "family": "Saez-Trumper",
        "given": "Diego"
      },
      {
        "family": "Kittur",
        "given": "Aniket"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The success of Wikipedia and other user-generated content communities has been driven by the openness of recruiting volunteers globally, but this openness has also led to a persistent lack of trust in its content. Despite several attempts at developing trust indicators to help readers more quickly and accurately assess the quality of content, challenges remain for practical deployment to general consumers. In this work we identify and address three key challenges: empirically determining which metrics from prior and existing community approaches most impact reader trust; 2) validating indicator placements and designs that are both compact yet noticed by readers; and 3) demonstrating that such indicators can not only lower trust but also increase perceived trust in the system when appropriate. By addressing these, we aim to provide a foundation for future tools that can practically increase trust in user generated content and the sociotechnical systems that generate and maintain them.",
    "call-number": "10.1145/3491102.3517523",
    "collection-number": "125",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517523",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Interfaces, User Trust, Wikipedia",
    "number": "Article 125",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Templates and Trust-o-meters: Towards a widely deployable indicator of trust in Wikipedia",
    "URL": "https://doi.org/10.1145/3491102.3517523"
  },
  {
    "id": "10.1145/3491102.3517442",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ringland",
        "given": "Kathryn E."
      },
      {
        "family": "Bhattacharya",
        "given": "Arpita"
      },
      {
        "family": "Weatherwax",
        "given": "Kevin"
      },
      {
        "family": "Eagle",
        "given": "Tessa"
      },
      {
        "family": "Wolf",
        "given": "Christine T."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Play is an essential part of the human experience and can be found throughout the lifespan. While play has long been of interest to the HCI community, research has often focused on the technologies supporting game play, the potential outcomes of play (e.g., skill-building, health improvements), or play among children. This paper explores what play looks like in online communities that are not specifically game-based and consist primarily of adults. From online ethnographic work of the ARMY (i.e., Adorable Representative M.C. for Youth), fandom of the South Korean musical group BTS, we explore how BTS and ARMY collaboratively construct a playful social environment using various social media platforms. A contribution of this work is to expand our conceptualization of how adults create playful places that are not specifically game-based and highlights the role of socio-technical systems in their community building.",
    "call-number": "10.1145/3491102.3517442",
    "collection-number": "126",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517442",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Live streaming, Creativity, Fandom, Play, Social media, Online communities",
    "number": "Article 126",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ARMY\u2019s Magic Shop: Understanding the Collaborative Construction of Playful Places in Online Communities",
    "URL": "https://doi.org/10.1145/3491102.3517442"
  },
  {
    "id": "10.1145/3491102.3502084",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dey",
        "given": "Sanorita"
      },
      {
        "family": "Duff",
        "given": "Brittany R.L."
      },
      {
        "family": "Karahalios",
        "given": "Karrie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In recent years, political crowdfunding campaigns have emerged through which politicians raise money to fund their election campaigns. Divisive issues discussed in these campaigns may not only motivate donations but also could have a broader priming effect on people\u2019s social opinions. In the U.S., more than one-third of the population with moderate opinions show a tendency to swing their opinion based on recent and more accessible events. In this paper, we ask: can such campaigns further prime people\u2019s responses to partisan topics, even when we discuss those topics in a non-political context? To answer this question, we analyzed the influence of exposure to a political candidate\u2019s crowdfunding campaign on responses to a subsequently seen, unrelated scientific topic that is not inherently political but is seen as partisan in the U.S. (climate change). We found that exposure to an attitude-inconsistent political candidate\u2019s crowdfunding campaign (a campaign that is counter to someone\u2019s existing political beliefs) can have a significant priming effect on subsequently seen politically charged topics. This effect may occur due to the activation of in-group identity by the candidate\u2019s partisan campaign. Guided by these findings, we investigated elements that can mitigate this self-categorization effect. We found that carefully designed content following framing techniques such as schema framing and threat/safety framing can mitigate people\u2019s sense of self-categorization toward non-political topics.",
    "call-number": "10.1145/3491102.3502084",
    "collection-number": "127",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502084",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "political crowdfunding, framing technique, charitable crowdfunding, priming effect",
    "number": "Article 127",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Re-imagining the Power of Priming and Framing Effects in the Context of Political Crowdfunding Campaigns",
    "URL": "https://doi.org/10.1145/3491102.3502084"
  },
  {
    "id": "10.1145/3491102.3501832",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Khatri",
        "given": "Sejal"
      },
      {
        "family": "Shaw",
        "given": "Aaron"
      },
      {
        "family": "Dasgupta",
        "given": "Sayamindu"
      },
      {
        "family": "Hill",
        "given": "Benjamin Mako"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Why do some peer production projects do a better job at engaging potential contributors than others? We address this question by comparing three Indian language Wikipedias, namely, Malayalam, Marathi, and Kannada. We found that although the three projects share goals, technological infrastructure, and a similar set of challenges, Malayalam Wikipedia\u2019s community engages language speakers in contributing at a much higher rate than the others. Drawing from a grounded theory analysis of interviews with 18 community participants from the three projects, we found that experience with participatory governance and free/open-source software in the Malayalam community supported high engagement of contributors. Counterintuitively, we found that financial resources intended to increase participation in the Marathi and Kannada communities hindered the growth of these communities. Our findings underscore the importance of social and cultural context in the trajectories of peer production communities.",
    "call-number": "10.1145/3491102.3501832",
    "collection-number": "128",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501832",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "social computing, Indian Wikipedias, Wikipedia, online communities, social embeddedness, community engagement, peer production, knowledge equity, underrepresented languages",
    "number": "Article 128",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The social embeddedness of peer production: A comparative qualitative analysis of three Indian language Wikipedia editions",
    "URL": "https://doi.org/10.1145/3491102.3501832"
  },
  {
    "id": "10.1145/3491102.3517526",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Belghith",
        "given": "Yasmine"
      },
      {
        "family": "Venkatagiri",
        "given": "Sukrit"
      },
      {
        "family": "Luther",
        "given": "Kurt"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online investigations are increasingly conducted by individuals with diverse skill levels and experiences, with mixed results. Novice investigations often result in vigilantism or doxxing, while expert investigations have greater success rates and fewer mishaps. Many of these experts are involved in a community of practice known as Open Source Intelligence (OSINT), with an ethos and set of techniques for conducting investigations using only publicly available data. Through semi-structured interviews with 14 expert OSINT investigators from nine different organizations, we examine the social dynamics of this community, including the collaboration and competition patterns that underlie their investigations. We also describe investigators\u2019 use of and challenges with existing OSINT tools, and implications for the design of social computing systems to better support crowdsourced investigations.",
    "call-number": "10.1145/3491102.3517526",
    "collection-number": "129",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517526",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "competition, experts, OSINT, crowdsourcing, investigation, collaboration, open source intelligence",
    "number": "Article 129",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Compete, Collaborate, Investigate: Exploring the Social Structures of Open Source Intelligence Investigations",
    "URL": "https://doi.org/10.1145/3491102.3517526"
  },
  {
    "id": "10.1145/3491102.3517689",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ye",
        "given": "Hui"
      },
      {
        "family": "Fu",
        "given": "Hongbo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Real-world IoT enhanced spaces involve diverse proximity- and gesture-based interactions between users and IoT devices/objects. Prototyping such interactions benefits various applications like the conceptual design of ubicomp space. AR (Augmented Reality) prototyping provides a flexible way to achieve early-stage designs by overlaying digital contents on real objects or environments. However, existing AR prototyping approaches have focused on prototyping AR experiences or context-aware interactions from the first-person view instead of full-body proxemic and gestural (pro-ges\u00a0for short) interactions of real users in the real world. In this work, we conducted interviews to figure out the challenges of prototyping pro-ges interactions in real-world IoT enhanced spaces. Based on the findings, we present ProGesAR, a mobile AR tool for prototyping pro-ges interactions of a subject in a real environment from a third-person view, and examining the prototyped interactions from both the first- and third- person views. Our interface supports the effects of virtual assets dynamically triggered by a single subject, with the triggering events based on four features: location, orientation, gesture, and distance. We conduct a preliminary study by inviting participants to prototype in a freeform manner using ProGesAR. The early-stage findings show that with ProGesAR, users can easily and quickly prototype their design ideas about pro-ges interactions.",
    "call-number": "10.1145/3491102.3517689",
    "collection-number": "130",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517689",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Gestural interaction, AR prototyping, Mobile augmented reality, Proxemic interaction",
    "number": "Article 130",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ProGesAR: Mobile AR Prototyping for Proxemic and Gestural Interactions with Real-world IoT Enhanced Spaces",
    "URL": "https://doi.org/10.1145/3491102.3517689"
  },
  {
    "id": "10.1145/3491102.3517636",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lunding",
        "given": "Mille Skovhus"
      },
      {
        "family": "Gr\u00f8nb\u00e6k",
        "given": "Jens Emil Sloth"
      },
      {
        "family": "Bilstrup",
        "given": "Karl-Emil Kj\u00e6r"
      },
      {
        "family": "S\u00f8rensen",
        "given": "Marie-Louise Stisen Kjerstein"
      },
      {
        "family": "Petersen",
        "given": "Marianne Graves"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "There is a growing focus on computational thinking (CT) in terms of supporting children\u2019s understanding of everyday technologies. But unlike other technologies, Augmented Reality (AR) has received limited attention. In this paper, we present ExposAR \u2013 a collaborative cross-device AR system enabling children to create, use, and reflect on AR technologies through the co-creation of a simple AR application. With ExposAR, we explore three core design principles: 1) reify computational concepts, 2) support collaborative cross-device authoring, and 3) incorporate the user\u2019s own world. These principles were developed through a co-design process with teachers and evaluated with 46 primary school students. We found that the collaborative authoring process with ExposAR supported students in understanding AR concepts and challenged their perspectives on AR. With these results, we bring AR to the CT agenda and contribute novel design principles for exposing the underlying mechanisms and implications of AR.",
    "call-number": "10.1145/3491102.3517636",
    "collection-number": "131",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517636",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Augmented reality, interactive learning system, education, computational thinking",
    "number": "Article 131",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ExposAR: Bringing Augmented Reality to the Computational Thinking Agenda through a Collaborative Authoring Tool",
    "URL": "https://doi.org/10.1145/3491102.3517636"
  },
  {
    "id": "10.1145/3491102.3502139",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rostami",
        "given": "Asreen"
      },
      {
        "family": "McMillan",
        "given": "Donald"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Performing with technology is a complex and challenging task. Artists who use novel technologies, such as Virtual Reality, have to develop strategies of monitoring, maintenance, and recovery from errors with as minimal impact on the ongoing performance as possible. In this paper we draw on two case studies of mixed-reality performances and document strategies of Stage Managing VR Performance, Choreographing for Cables, Consistency & Charging, Improvising Interventions, and Priming Participants. We discuss how these practices expose areas ripe with potential for tool development, and how they can also be used to inform the design of interaction with other technologies, such as the Internet of Things.",
    "call-number": "10.1145/3491102.3502139",
    "collection-number": "132",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502139",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Reality, Artistic Interaction, Mixed-reality performance",
    "number": "Article 132",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Normal Natural Troubles of Virtual Reality in Mixed-Reality Performances",
    "URL": "https://doi.org/10.1145/3491102.3502139"
  },
  {
    "id": "10.1145/3491102.3517677",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Pinyao"
      },
      {
        "family": "Stepanova",
        "given": "Ekaterina R."
      },
      {
        "family": "Kitson",
        "given": "Alexandra"
      },
      {
        "family": "Schiphorst",
        "given": "Thecla"
      },
      {
        "family": "Riecke",
        "given": "Bernhard E."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Flying dreams have the potential to evoke a feeling of empowerment (or self-efficacy, confidence in our ability to succeed) and self-transcendent experience (STE), which have been shown to contribute to an individual\u2019s overall well-being. However, these exceptional dreaming experiences remain difficult to induce at will. Inspired by the potential of Virtual Reality (VR) to support profound emotional experiences, we explored if a VR flying interface with more embodied self-motion cues could contribute to the benefits associated with flying dreams (i.e., STE and empowerment). Our results indicated that a flying interface with more self-motion cues indeed better supported STE and empowerment. We derived several design considerations: obscurity, extraordinary light and supportive setting. Our results contribute to the discourse around design guidelines for self-transcendence and empowerment in VR, which may further be applied to the improvement of mental well-being.",
    "call-number": "10.1145/3491102.3517677",
    "collection-number": "133",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517677",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "gravity imagery, Dreaming, transcendent dream, vection, self-transcendence, empowerment, flight simulation, virtual reality",
    "number": "Article 133",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Virtual Transcendent Dream: Empowering People through Embodied Flying in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517677"
  },
  {
    "id": "10.1145/3491102.3502133",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Angerbauer",
        "given": "Katrin"
      },
      {
        "family": "Rodrigues",
        "given": "Nils"
      },
      {
        "family": "Cutura",
        "given": "Rene"
      },
      {
        "family": "\u00d6ney",
        "given": "Seyda"
      },
      {
        "family": "Pathmanathan",
        "given": "Nelusa"
      },
      {
        "family": "Morariu",
        "given": "Cristina"
      },
      {
        "family": "Weiskopf",
        "given": "Daniel"
      },
      {
        "family": "Sedlmair",
        "given": "Michael"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present an exploratory study on the accessibility of images in publications when viewed with color vision deficiencies (CVDs). The study is based on 1,710 images sampled from a visualization dataset (VIS30K) over five years. We simulated four CVDs on each image. First, four researchers (one with a CVD) identified existing issues and helpful aspects in a subset of the images. Based on the resulting labels, 200 crowdworkers provided \u00a030,000 ratings on present CVD issues in the simulated images. We analyzed this data for correlations, clusters, trends, and free text comments to gain a first overview of paper figure accessibility. Overall, about 60\u00a0% of the images were rated accessible. Furthermore, our study indicates that accessibility issues are subjective and hard to detect. On a meta-level, we reflect on our study experience to point out challenges and opportunities of large-scale accessibility studies for future research directions.",
    "call-number": "10.1145/3491102.3502133",
    "collection-number": "134",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502133",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "crowdsourcing, visualization, accessibility, color vision deficiency",
    "number": "Article 134",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Accessibility for Color Vision Deficiencies: Challenges and Findings of a Large Scale Study on Paper Figures",
    "URL": "https://doi.org/10.1145/3491102.3502133"
  },
  {
    "id": "10.1145/3491102.3501928",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chen",
        "given": "Kun-Ting"
      },
      {
        "family": "Dwyer",
        "given": "Tim"
      },
      {
        "family": "Yang",
        "given": "Yalong"
      },
      {
        "family": "Bach",
        "given": "Benjamin"
      },
      {
        "family": "Marriott",
        "given": "Kim"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "There are many methods for projecting spherical maps onto the plane. Interactive versions of these projections allow the user to centre the region of interest. However, the effects of such interaction have not previously been evaluated. In a study with 120 participants we find interaction provides significantly more accurate area, direction and distance estimation in such projections. The surface of 3D sphere and torus topologies provides a continuous surface for uninterrupted network layout. But how best to project spherical network layouts to 2D screens has not been studied, nor have such spherical network projections been compared to torus projections. Using the most successful interactive sphere projections from our first study, we compare spherical, standard and toroidal layouts of networks for cluster and path following tasks with 96 participants, finding benefits for both spherical and toroidal layouts over standard network layouts in terms of accuracy for cluster understanding tasks.",
    "call-number": "10.1145/3491102.3501928",
    "collection-number": "135",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501928",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Geographic visualization, Graph visualization, Map projection, Crowdsourced study.",
    "number": "Article 135",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "GAN\u2019SDA Wrap: Geographic And Network Structured DAta on surfaces that Wrap around",
    "URL": "https://doi.org/10.1145/3491102.3501928"
  },
  {
    "id": "10.1145/3491102.3517445",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rae",
        "given": "Irene"
      },
      {
        "family": "Zhou",
        "given": "Feng"
      },
      {
        "family": "Bilsing",
        "given": "Martin"
      },
      {
        "family": "Bunge",
        "given": "Philipp"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "An extensive body of work in visual analytics has examined how users conduct analyses in scientific and academic settings, identifying and categorizing user goals and the actions they undertake to achieve them. However, most of this work has studied the analysis process in simulated or isolated environments, leading to a gap in connecting these findings to large-scale business (enterprise) contexts, where visual analysis is most needed to make sense of the large amounts of data being generated. In this work, we conducted digital \u201dfield\u201d observations to understand how users conduct visual analyses in an enterprise setting, where they operate within a large ecosystem of systems and people. From these observations, we identified four common objectives, six recurring visual investigation patterns, and five emergent themes. We also performed a quantitative analysis of logs over 2530 user sessions from a second visual analysis product to validate that our patterns were not product-specific.",
    "call-number": "10.1145/3491102.3517445",
    "collection-number": "136",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517445",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "information visualization, interaction, interaction techniques, visual interaction, visual analytics",
    "number": "Article 136",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Visual Investigation Patterns Through Digital \u201cField\u201d Observations",
    "URL": "https://doi.org/10.1145/3491102.3517445"
  },
  {
    "id": "10.1145/3491102.3501874",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Xiong",
        "given": "Cindy"
      },
      {
        "family": "Sarvghad",
        "given": "Ali"
      },
      {
        "family": "Goldstein",
        "given": "Daniel G"
      },
      {
        "family": "Hofman",
        "given": "Jake M"
      },
      {
        "family": "Demiralp",
        "given": "\u00c7agatay"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Icon arrays are graphical displays in which a subset of identical shapes are filled to convey probabilities. They are widely used for communicating probabilities to the general public. A primary design decision concerning icon arrays is how to fill and arrange these shapes. For example, a designer could fill the shapes from top to bottom or in a random fashion. We investigated the effect of different arrangements in icon arrays on probability perception. We showed participants icon arrays depicting probabilities between 0% and 100% in six different arrangements. Participants were more accurate in estimating probabilities when viewing the top, row, and diagonal arrangements, but they overestimated the proportions with the central arrangement and underestimated the proportions with the edge arrangement. They were biased to either overestimate or underestimate when viewing the random arrangement depending on the objective proportions, following a cyclical pattern consistent with existing findings in the psychophysics literature.",
    "call-number": "10.1145/3491102.3501874",
    "collection-number": "137",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501874",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Visualization of Probabilities, Proportions, Icon Arrays, Risk Visualization, Perception, Communication, Crowdsourcing, Bias",
    "number": "Article 137",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Perceptual Biases in Icon Arrays",
    "URL": "https://doi.org/10.1145/3491102.3501874"
  },
  {
    "id": "10.1145/3491102.3501893",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Panavas",
        "given": "Liudas"
      },
      {
        "family": "Worth",
        "given": "Amy E."
      },
      {
        "family": "Crnovrsanin",
        "given": "Tarik"
      },
      {
        "family": "Sathyamurthi",
        "given": "Tejas"
      },
      {
        "family": "Cordes",
        "given": "Sara"
      },
      {
        "family": "Borkin",
        "given": "Michelle A."
      },
      {
        "family": "Dunne",
        "given": "Cody"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data visualization is pervasive in the lives of children as they encounter graphs and charts in early education and online media. In spite of this prevalence, our guidelines and understanding of how children perceive graphs stem primarily from studies conducted with adults. Previous psychology and education research indicates that children\u2019s cognitive abilities are different from adults. Therefore, we conducted a classic graphical perception study on a population of children aged 8\u201312 enrolled in the Ivy After School Program in Boston, MA and adult computer science students enrolled in Northeastern University to determine how accurately participants judge differences in particular graphical encodings. We record the accuracy of participants\u2019 answers for five encodings most commonly used with quantitative data. The results of our controlled experiment show that children have remarkably similar graphical perception to adults, but are consistently less accurate at interpreting the visual encodings. We found similar effectiveness rankings, relative differences in error between the different encodings, and patterns of bias across encoding types. Based on our findings, we provide design guidelines and recommendations for creating visualizations for children. This paper and all supplemental materials are available at https://osf.io/ygrdv.",
    "call-number": "10.1145/3491102.3501893",
    "collection-number": "138",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501893",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Data Visualization, Visualization Literacy, Graphical Perception",
    "number": "Article 138",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Juvenile Graphical Perception: A Comparison between Children and Adults",
    "URL": "https://doi.org/10.1145/3491102.3501893"
  },
  {
    "id": "10.1145/3491102.3502107",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bowler",
        "given": "Ryan David"
      },
      {
        "family": "Bach",
        "given": "Benjamin"
      },
      {
        "family": "Pschetz",
        "given": "Larissa"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Digital calendars and other technologies for social event planning leave little space to communicate uncertainty regarding time, place or the ability to attend an event. However, narratives of certainty can be detrimental and lead to the marginalisation of those who find it hard to cope with rigid and strictly paced schedules, such as people with health conditions or caring responsibilities. In this paper, we explore uncertainty as the starting point and leading principle behind digital scheduling tools. We present Haze, a speculative tool and user interface, designed to gain insights on participants\u2019 perceptions of uncertainty-based scheduling scenarios. We report on two qualitative studies (total of 21 participants), which indicate that a change in perspective towards uncertainty can challenge moral assumptions around certainty, increase temporal empathy, and indeed support those who are particularly affected by uncertainty. These findings help shift and expand the repertoire of temporality and discuss moral and social responsibilities for design and HCI.",
    "call-number": "10.1145/3491102.3502107",
    "collection-number": "140",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502107",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "health, Uncertainty, Probes, Marginalisation, Communication, Chronic Fatigue Syndrome, Certainty",
    "number": "Article 140",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Uncertainty in Digital Scheduling, and The Wider Implications of Unrepresented Temporalities in HCI",
    "URL": "https://doi.org/10.1145/3491102.3502107"
  },
  {
    "id": "10.1145/3491102.3517545",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Minha"
      },
      {
        "family": "Park",
        "given": "Wonyoung"
      },
      {
        "family": "Lee",
        "given": "Sunok"
      },
      {
        "family": "Lee",
        "given": "Sangsu"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The COVID-19 pandemic has forced workers around the world to switch their working paradigms from on-site to video-mediated communication. Despite the advantages of videoconferencing, diverse circumstances have prevented people from focusing on their work. One of the most typical problems they face is that various surrounding factors distract them during their meetings. This study focuses on conditions in which remote workers are distracted by factors that disturb, interrupt, or restrict them during their meetings. We aim to explore the various problem situations and user needs. To understand users\u2019 pain points and needs, focus group interviews and participatory design workshops were conducted to learn about participants\u2019 troubled working experiences over the past two years and the solutions they expected. Our study provides a unified framework of distracting factors by which to understand causes of poor user experience and reveals valuable implications to improve videoconferencing experiences.",
    "call-number": "10.1145/3491102.3517545",
    "collection-number": "141",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517545",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Remote work, Videoconferencing, User experience, Distraction",
    "number": "Article 141",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Distracting Moments in Videoconferencing: A Look Back at the Pandemic Period",
    "URL": "https://doi.org/10.1145/3491102.3517545"
  },
  {
    "id": "10.1145/3491102.3501991",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cho",
        "given": "Janghee"
      },
      {
        "family": "Xu",
        "given": "Tian"
      },
      {
        "family": "Zimmermann-Niefield",
        "given": "Abigail"
      },
      {
        "family": "Voida",
        "given": "Stephen"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Personal informatics (PI) systems have been developed to support reflection. While reflection is considered an indispensable activity in PI use, how and when reflection occurs is still under-studied. In this paper, we present an analysis of the interactive features of 123 commercial PI apps, revealing that reflective practices are unevenly supported. The lack of features that encourage user-driven reflection, scaffolding for setting goals and configuring data collection and presentation, and consideration of wider implications stand to limit meaning-making and frustrate nuanced insight generation based on lived experiences. Based on our findings, we discuss how reflection is currently misrepresented in personal informatics tools, identify and characterize the gaps between theoretical research on reflection and interface features in current apps, and offer suggestions about how reflection could be better supported.",
    "call-number": "10.1145/3491102.3501991",
    "collection-number": "142",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501991",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "personal informatics, mobile apps, self-tracking, reflection, agency",
    "number": "Article 142",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Reflection in Theory and Reflection in Practice: An Exploration of the Gaps in Reflection Support among Personal Informatics Apps",
    "URL": "https://doi.org/10.1145/3491102.3501991"
  },
  {
    "id": "10.1145/3491102.3501973",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Elsden",
        "given": "Chris"
      },
      {
        "family": "Chatting",
        "given": "David"
      },
      {
        "family": "Duggan",
        "given": "Michael"
      },
      {
        "family": "Dwyer",
        "given": "Andrew Carl"
      },
      {
        "family": "Thornton",
        "given": "Pip"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper reports on Zoom Obscura \u2013 an artist-based design research project, responding to the ubiquity of video-conferencing as a technical and cultural phenomenon throughout the Covid-19 pandemic. As enterprise software, such as Zoom, rapidly came to mediate even the most personal and intimate interactions, we supported and collaborated with seven independent artists to explore technical and creative interventions in video-conferencing. Our call for participation sought critical interventions that would help users counter, and regain agency in regard to the various ways in which personal data is captured, transmitted and processed in video-conferencing tools. In this design study, we analyse post-hoc how each of the seven projects employed aspects of counterfunctional design to achieve these aims. Each project reveals different avenues and strategies for counterfunctionality in video-conferencing software, as well as opportunities to design critically towards interactions and experiences that challenge existing norms and expectations around these platforms.",
    "call-number": "10.1145/3491102.3501973",
    "collection-number": "143",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501973",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Covid-19, Video Conferencing, Zoom, Surveillance, Counterfunctional Design, Design Research",
    "number": "Article 143",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Zoom Obscura: Counterfunctional Design for Video-Conferencing",
    "URL": "https://doi.org/10.1145/3491102.3501973"
  },
  {
    "id": "10.1145/3491102.3517596",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Page",
        "given": "Xinru"
      },
      {
        "family": "Capener",
        "given": "Andrew"
      },
      {
        "family": "Cullen",
        "given": "Spring"
      },
      {
        "family": "Wang",
        "given": "Tao"
      },
      {
        "family": "Garfield",
        "given": "Monica"
      },
      {
        "family": "J. Wisniewski",
        "given": "Pamela"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Social media can facilitate numerous benefits, ranging from facilitating access to social, instrumental, financial, and other support, to professional development and civic participation. However, these benefits may not be generalizable to all users. Therefore, we conducted an ethnographic case study with eight Autistic young adults, ten staff members, and four parents to understand how Autistic users of social media engage with others, as well as any unintended consequences of use. We leveraged an affordances perspective to understand how Autistic young adults share and consume user-generated content, make connections, and engage in networked interactions with others via social media. We found that they often used a literal interpretation of digital affordances that sometimes led to negative consequences including physical harm, financial loss, social anxiety, feelings of exclusion, and inadvertently damaging their social relationships. We make recommendations for redesigning social media affordances to be more inclusive of neurodiverse users.",
    "call-number": "10.1145/3491102.3517596",
    "collection-number": "144",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517596",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Autistic Young Adults, Social Media, Affordances",
    "number": "Article 144",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Perceiving Affordances Differently: The Unintended Consequences When Young Autistic Adults Engage with Social Media",
    "URL": "https://doi.org/10.1145/3491102.3517596"
  },
  {
    "id": "10.1145/3491102.3501892",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Diamond",
        "given": "Lindsay Levkoff"
      },
      {
        "family": "Batan",
        "given": "Hande"
      },
      {
        "family": "Anderson",
        "given": "Jennings"
      },
      {
        "family": "Palen",
        "given": "Leysia"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Vaccine hesitancy has always been a public health concern, and anti-vaccine campaigns that proliferate disinformation have gained traction across the US in the last 25 years. The demographics of resistance are varied, with health, religious, and, increasingly, political concerns cited as reasons. With the COVID-19 pandemic igniting the fastest development of vaccines to date, mis- and disinformation about them have become inflammatory, with campaigning allegedly including racial targeting. Through a primarily qualitative investigation, this study inductively examines a large online vaccine discussion space that invokes references to the unethical Tuskegee Syphilis Study to understand how tactics of racial targeting of Black Americans might appear publicly. We find that such targeting is entangled with a genuine discussion about medical racism and vaccine hesitancy. Across 12 distinct voices that address race, medical racism, and vaccines, we discuss how mis- and disinformation sit alongside accurate information in a \u201cpolyvocal\u201d space.",
    "call-number": "10.1145/3491102.3501892",
    "collection-number": "145",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501892",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "COVID-19, Misinformation, Public Health, Disinformation, Social Media, Vaccines, Anti-Vaccine, Medical Racism, Pandemic",
    "number": "Article 145",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Polyvocality of Online COVID-19 Vaccine Narratives that Invoke Medical Racism",
    "URL": "https://doi.org/10.1145/3491102.3501892"
  },
  {
    "id": "10.1145/3491102.3517614",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Xiao",
        "given": "Sijia"
      },
      {
        "family": "Cheshire",
        "given": "Coye"
      },
      {
        "family": "Salehi",
        "given": "Niloufar"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online harm is a prevalent issue in adolescents\u2019 online lives. Restorative justice teaches us to focus on those who have been harmed, ask what their needs are, and engage in the offending party and community members to collectively address the harm. In this research, we conducted interviews and design activities with harmed adolescents to understand their needs to address online harm. They also identified the key stakeholders relevant to their needs, the desired outcomes, and the preferred timing to achieve them. We identified five central needs of harmed adolescents: sensemaking, emotional support and validation, safety, retribution, and transformation. We find that addressing the needs of those who are harmed online usually requires concerted efforts from multiple stakeholders online and offline. We conclude by discussing how platforms can implement design interventions to meet some of these needs.",
    "call-number": "10.1145/3491102.3517614",
    "collection-number": "146",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517614",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "online governance, content moderation, Online harassment, social media, survivors",
    "number": "Article 146",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Sensemaking, Support, Safety, Retribution, Transformation: A Restorative Justice Approach to Understanding Adolescents\u2019 Needs for Addressing Online Harm",
    "URL": "https://doi.org/10.1145/3491102.3517614"
  },
  {
    "id": "10.1145/3491102.3517561",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ruensuk",
        "given": "Mintra"
      },
      {
        "family": "Kim",
        "given": "Taewan"
      },
      {
        "family": "Hong",
        "given": "Hwajung"
      },
      {
        "family": "Oakley",
        "given": "Ian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Social Network Services (SNSs) evoke diverse affective experiences. While most are positive, many authors have documented both the negative emotions that can result from browsing SNS and their impact: Facebook depression is a common term for the more severe results. However, while the importance of the emotions experienced on SNSs is clear, methods to catalog them, and systems to detect them, are less well developed. Accordingly, this paper reports on two studies using a novel contextually triggered Experience Sampling Method to log surveys immediately after using Instagram, a popular image-based SNS, thus minimizing recall biases. The first study improves our understanding of the emotions experienced while using SNSs. It suggests that common negative experiences relate to appearance comparison and envy. The second study captures smartphone sensor data during Instagram sessions to detect these two emotions, ultimately achieving peak accuracies of 95.78% (binary appearance comparison) and 93.95% (binary envy).",
    "call-number": "10.1145/3491102.3517561",
    "collection-number": "147",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517561",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Smartphones, Social media, Experience sampling, Instagram, Affect detection",
    "number": "Article 147",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Sad or just jealous? Using Experience Sampling to Understand and Detect Negative Affective Experiences on Instagram",
    "URL": "https://doi.org/10.1145/3491102.3517561"
  },
  {
    "id": "10.1145/3491102.3501969",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ali",
        "given": "Shiza"
      },
      {
        "family": "Razi",
        "given": "Afsaneh"
      },
      {
        "family": "Kim",
        "given": "Seunghyun"
      },
      {
        "family": "Alsoubai",
        "given": "Ashwaq"
      },
      {
        "family": "Gracie",
        "given": "Joshua"
      },
      {
        "family": "De Choudhury",
        "given": "Munmun"
      },
      {
        "family": "Wisniewski",
        "given": "Pamela J."
      },
      {
        "family": "Stringhini",
        "given": "Gianluca"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We collected Instagram Direct Messages (DMs) from 100 adolescents and young adults (ages 13-21) who then flagged their own conversations as safe or unsafe. We performed a mixed-method analysis of the media files shared privately in these conversations to gain human-centered insights into the risky interactions experienced by youth. Unsafe conversations ranged from unwanted sexual solicitations to mental health related concerns, and images shared in unsafe conversations tended to be of people and convey negative emotions, while those shared in regular conversations more often conveyed positive emotions and contained objects. Further, unsafe conversations were significantly shorter, suggesting that youth disengaged when they felt unsafe. Our work uncovers salient characteristics of safe and unsafe media shared in private conversations and provides the foundation to develop automated systems for online risk detection and mitigation.",
    "call-number": "10.1145/3491102.3501969",
    "collection-number": "148",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501969",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "unsafe private conversations, Datasets, Adolescents, Image Analysis, Instagram, Teens",
    "number": "Article 148",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding the Digital Lives of Youth: Analyzing Media Shared within Safe Versus Unsafe Private Conversations on Instagram",
    "URL": "https://doi.org/10.1145/3491102.3501969"
  },
  {
    "id": "10.1145/3491102.3502016",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Garg",
        "given": "Radhika"
      },
      {
        "family": "Cui",
        "given": "Hua"
      },
      {
        "family": "Seligson",
        "given": "Spencer"
      },
      {
        "family": "Zhang",
        "given": "Bo"
      },
      {
        "family": "Porcheron",
        "given": "Martin"
      },
      {
        "family": "Clark",
        "given": "Leigh"
      },
      {
        "family": "Cowan",
        "given": "Benjamin R."
      },
      {
        "family": "Beneteau",
        "given": "Erin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Voice-based Conversational Agents (CAs) are increasingly being used by children. Through a review of 38 research papers, this work maps trends, themes, and methods of empirical research on children and CAs in HCI research over the last decade. A thematic analysis of the research found that work in this domain focuses on seven key topics: ascribing human-like qualities to CAs, CAs? support of children?s learning, the use and role of CAs in the home and family context, CAs? support of children?s play, children?s storytelling with CA, issues concerning the collection of information revealed by CAs, and CAs designed for children with differing abilities. Based on our findings, we identify the needs to account for children\u2019s intersectional identities and linguistic and cultural diversity and theories from multiple disciples in the design of CAs, develop heuristics for child-centric interaction with CAs, to investigate implications of CAs on social cognition and interpersonal relationships, and to examine and design for multi-party interactions with CAs for different domains and contexts.",
    "call-number": "10.1145/3491102.3502016",
    "collection-number": "149",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502016",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "family, virtual assistants, smart speakers, parents, voice interfaces, literature review, children, systematic literature review, voice agents, voice user interfaces, conversational agents",
    "number": "Article 149",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Last Decade of HCI Research on Children and Voice-based Conversational Agents",
    "URL": "https://doi.org/10.1145/3491102.3502016"
  },
  {
    "id": "10.1145/3491102.3517667",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nicholson",
        "given": "Rebecca"
      },
      {
        "family": "Bartindale",
        "given": "Tom"
      },
      {
        "family": "Kharrufa",
        "given": "Ahmed"
      },
      {
        "family": "Kirk",
        "given": "David"
      },
      {
        "family": "Walker-Gleaves",
        "given": "Caroline"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Educational technologies offer benefits in the classroom but there are barriers to their successful integration, including teachers\u2019 pedagogical beliefs and their skills and experience. Participatory Design (PD) approaches offer one way in which teachers can be directly involved in the design of classroom technologies, however PD processes alone fail to address the challenges of integrating technology within existing practices. In this paper we propose co-teaching as a novel form of co-design practice. We describe a two year longitudinal Co-Teaching project resulting in the development and use of three digital designs for the classroom. Using the TPACK model to guide our reflections we offer insights into the ways that co-teaching can support the design and integration of educational technologies. We suggest that co-teaching as a form of co-design practice offers a way to move teachers from passive adopters of technology to active participants in the design and integration of educational technologies.",
    "call-number": "10.1145/3491102.3517667",
    "collection-number": "150",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517667",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Co-Teaching, Participatory Design, Co-Design, Educational Technology",
    "number": "Article 150",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Participatory Design Goes to School: Co-Teaching as a Form of Co-Design for Educational Technology",
    "URL": "https://doi.org/10.1145/3491102.3517667"
  },
  {
    "id": "10.1145/3491102.3501955",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Christine P"
      },
      {
        "family": "Cagiltay",
        "given": "Bengisu"
      },
      {
        "family": "Mutlu",
        "given": "Bilge"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Social robots are increasingly introduced into children\u2019s lives as educational and social companions, yet little is known about how these products might best be introduced to their environments. The emergence of the \u201cunboxing\u201d phenomenon in media suggests that introduction is key to technology adoption where initial impressions are made. To better understand this phenomenon toward designing a positive unboxing experience in the context of social robots for children, we conducted three field studies with families of children aged 8 to 13: (1) an exploratory free-play activity (n = 12); (2) a co-design session (n = 11) that informed the development of a prototype box and a curated unboxing experience; and (3) a user study (n = 9) that evaluated children\u2019s experiences. Our findings suggest the unboxing experience of social robots can be improved through the design of a creative aesthetic experience that engages the child socially to guide initial interactions and foster a positive child-robot relationship.",
    "call-number": "10.1145/3491102.3501955",
    "collection-number": "151",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501955",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "experience design, social robots, child-robot interaction, Participatory design, unboxing",
    "number": "Article 151",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Unboxing Experience: Exploration and Design of Initial Interactions Between Children and Social Robots",
    "URL": "https://doi.org/10.1145/3491102.3501955"
  },
  {
    "id": "10.1145/3491102.3501979",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Woodward",
        "given": "Julia"
      },
      {
        "family": "Alemu",
        "given": "Feben"
      },
      {
        "family": "E. L\u00f3pez Adames",
        "given": "Natalia"
      },
      {
        "family": "Anthony",
        "given": "Lisa"
      },
      {
        "family": "C. Yip",
        "given": "Jason"
      },
      {
        "family": "Ruiz",
        "given": "Jaime"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Children are being presented with augmented reality (AR) in different contexts, such as education and gaming. However, little is known about how children conceptualize AR, especially AR headsets. Prior work has shown that children's interaction behaviors and expectations of technological devices can be quite different from adults\u2019. It is important to understand children's mental models of AR headsets to design more effective experiences for them. To elicit children's perceptions, we conducted four participatory design sessions with ten children on designing content for imaginary AR headsets. We found that children expect AR systems to be highly intelligent and to recognize and virtually transform surroundings to create immersive environments. Also, children are in favor of using these devices for difficult tasks but prefer to work on their own for easy tasks. Our work contributes new understanding on how children comprehend AR headsets and provides recommendations for designing future headsets for children.",
    "call-number": "10.1145/3491102.3501979",
    "collection-number": "152",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501979",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "participatory design, co-design, conceptual model, Augmented reality, children",
    "number": "Article 152",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt Would Be Cool to Get Stampeded by Dinosaurs\u201d: Analyzing Children's Conceptual Model of AR Headsets Through Co-Design",
    "URL": "https://doi.org/10.1145/3491102.3501979"
  },
  {
    "id": "10.1145/3491102.3502115",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zargham",
        "given": "Nima"
      },
      {
        "family": "Pfau",
        "given": "Johannes"
      },
      {
        "family": "Schnackenberg",
        "given": "Tobias"
      },
      {
        "family": "Malaka",
        "given": "Rainer"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Advances in speech recognition, language processing and natural interaction have led to an increased industrial and academic interest. While the robustness and usability of such systems are steadily increasing, speech-based systems are still susceptible to recognition errors. This makes intelligent error handling of utmost importance for the success of those systems. In this work, we integrated anticipatory error handling for a voice-controlled video game where the game would perform a locally optimized action in respect to goal completion and obstacle avoidance, when a command is not recognized. We evaluated the user experience of our approach versus traditional, repetition-based error handling (). Our results indicate that implementing anticipatory error handling can improve the usability of a system, if it follows the intention of the user. Otherwise, it impairs the user experience, even when deciding for technically optimal decisions.",
    "call-number": "10.1145/3491102.3502115",
    "collection-number": "153",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502115",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Voice User Interfaces, Voice Interaction, Game Design, Speech-Based Systems, Voice-Controlled Game, Error Handling",
    "number": "Article 153",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Didn\u2019t Catch That, But I\u2019ll Try My Best\u201d: Anticipatory Error Handling in a Voice Controlled Game",
    "URL": "https://doi.org/10.1145/3491102.3502115"
  },
  {
    "id": "10.1145/3491102.3517660",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Shengmei"
      },
      {
        "family": "Claypool",
        "given": "Mark"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Competitive first-person shooter games are played over a network, where latency can degrade player performance. To better understand latency\u2019s impact, a promising approach is to study how latency affects individual game actions, such as moving and shooting. While target selection (aiming and shooting at an opponent) is fairly well studied, navigation (moving an avatar into position) is not. This paper presents results from a 30-person user study that evaluates the impact of latency on first-person navigation using a custom \u201chide and seek\u201d game that isolates avatar movement in a manner intended to be similar to movement in a first-person shooter game. Analysis of the results shows latency has pronounced effects on player performance (score and seek positioning), with subjective opinions on Quality of Experience following suit.",
    "call-number": "10.1145/3491102.3517660",
    "collection-number": "154",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517660",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "navigation, skill, user study, gamer, FPS, lag",
    "number": "Article 154",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Impact of Latency on Navigation in a First-Person Perspective Game",
    "URL": "https://doi.org/10.1145/3491102.3517660"
  },
  {
    "id": "10.1145/3491102.3517685",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Poretski",
        "given": "Lev"
      },
      {
        "family": "Tang",
        "given": "Anthony"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Learnability is a core aspect of software usability. Video games are not an exception, as game designers need to teach players how to play their creations. We analyzed 40 contemporary video games to identify how video games approach learning experiences. We found that games have advanced far beyond using simple tutorials or demonstration screens and adopt a range of repeatable and reusable design strategies using visual cues to facilitate learning. We provide a detailed descriptive framework of these design strategies, elucidating how and when they can be used, and describing how the visual cues are used to build them. Our research can be useful for both general HCI researchers and practitioners seeking to tap into the rich ideas from video game learnability design looking for practical solutions for their work.",
    "call-number": "10.1145/3491102.3517685",
    "collection-number": "155",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517685",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "visual cues, design strategies, learnability, Video games",
    "number": "Article 155",
    "number-of-pages": "26",
    "page": "1\u201326",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Press A to Jump: Design Strategies for Video Game Learnability",
    "URL": "https://doi.org/10.1145/3491102.3517685"
  },
  {
    "id": "10.1145/3491102.3502025",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gundry",
        "given": "David"
      },
      {
        "family": "Deterding",
        "given": "Sebastian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Games have become a popular way of collecting human subject data, based on the premise that they are more engaging than surveys or experiments, but generate equally valid data. However, this premise has not been empirically tested. In response, we designed a game for eliciting linguistic data following Intrinsic Elicitation \u2013 a design approach aiming to minimise validity threats in data collection games \u2013 and compared it to an equivalent linguistics experiment as control. In a preregistered study and replication (n=96 and n=136), using two different ways of operationalising accuracy, the game generated substantially more enjoyment (d=.70,.73) and substantially less accurate data (d=-.68, -.40) \u2013 though still more accurate than random responding. We conclude that for certain data types data collection games may present a serious trade-off between participant enjoyment and data quality, identify possible causes of lower data quality for future research, reflect on our design approach, and urge games HCI researchers to use careful controls where appropriate.",
    "call-number": "10.1145/3491102.3502025",
    "collection-number": "156",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502025",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Applied Games, Human Computation Games, Games with a Purpose, Validity, Crowdsourcing Games, Human Subject Data",
    "number": "Article 156",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Trading Accuracy for Enjoyment? Data Quality and Player Experience in Data Collection Games",
    "URL": "https://doi.org/10.1145/3491102.3502025"
  },
  {
    "id": "10.1145/3491102.3517642",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yin",
        "given": "Michael"
      },
      {
        "family": "Xiao",
        "given": "Robert"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Random Reward Mechanisms (RRMs) in video games are systems in which rewards are issued probabilistically upon certain trigger conditions, such as completing gameplay tasks, exceeding a playtime quota, or making in-game purchases. We investigated the relationship between RRM implementations and user experience. Video analysis of 35 RRM systems allowed for the creation of a classification system based on contrasting observed dimensions. Interviews with 14 video game players provided insights into how factors such as the affordances of non-optimal rewards and the trade-off between random luck and skill impact player perception and interaction with RRMs. We additionally investigated the relationship between auditory, visual, and gameplay design decisions and player expectations for RRM reward presentations, finding that the resources required to obtain the reward and the relative value of the reward impact its expected presentation. Finally, we applied our findings to propose design methodologies for creating engaging and significant RRM systems.",
    "call-number": "10.1145/3491102.3517642",
    "collection-number": "157",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517642",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "player experience, video games, reward systems",
    "number": "Article 157",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Reward for Luck: Understanding the Effect of Random Reward Mechanisms in Video Games on Player Experience",
    "URL": "https://doi.org/10.1145/3491102.3517642"
  },
  {
    "id": "10.1145/3491102.3517533",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kapania",
        "given": "Shivani"
      },
      {
        "family": "Siy",
        "given": "Oliver"
      },
      {
        "family": "Clapper",
        "given": "Gabe"
      },
      {
        "family": "SP",
        "given": "Azhagu Meena"
      },
      {
        "family": "Sambasivan",
        "given": "Nithya"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Most prior work on human-AI interaction is set in communities that indicate skepticism towards AI, but we know less about contexts where AI is viewed as aspirational. We investigated the perceptions around AI systems by drawing upon 32 interviews and 459 survey respondents in India. Not only do Indian users accept AI decisions (79.2% respondents indicate acceptance), we find a case of AI authority\u2014AI has a legitimized power to influence human actions, without requiring adequate evidence about the capabilities of the system. AI authority manifested into four user attitudes of vulnerability: faith, forgiveness, self-blame, and gratitude, pointing to higher tolerance for system misfires, and introducing potential for irreversible individual and societal harm. We urgently call for calibrating AI authority, reconsidering success metrics and responsible AI approaches and present methodological suggestions for research and deployments in India.",
    "call-number": "10.1145/3491102.3517533",
    "collection-number": "158",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517533",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "algorithmic decision-making, artificial intelligence, perceptions of AI, India",
    "number": "Article 158",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dBecause AI is 100% right and safe\u201d: User Attitudes and Sources of AI Authority in India",
    "URL": "https://doi.org/10.1145/3491102.3517533"
  },
  {
    "id": "10.1145/3491102.3517732",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tolmeijer",
        "given": "Suzanne"
      },
      {
        "family": "Christen",
        "given": "Markus"
      },
      {
        "family": "Kandul",
        "given": "Serhiy"
      },
      {
        "family": "Kneer",
        "given": "Markus"
      },
      {
        "family": "Bernstein",
        "given": "Abraham"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While artificial intelligence (AI) is increasingly applied for decision-making processes, ethical decisions pose challenges for AI applications. Given that humans cannot always agree on the right thing to do, how would ethical decision-making by AI systems be perceived and how would responsibility be ascribed in human-AI collaboration? In this study, we investigate how the expert type (human vs. AI) and level of expert autonomy (adviser vs. decider) influence trust, perceived responsibility, and reliance. We find that participants consider humans to be more morally trustworthy but less capable than their AI equivalent. This shows in participants\u2019 reliance on AI: AI recommendations and decisions are accepted more often than the human expert\u2019s. However, AI team experts are perceived to be less responsible than humans, while programmers and sellers of AI systems are deemed partially responsible instead.",
    "call-number": "10.1145/3491102.3517732",
    "collection-number": "160",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517732",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Trust, Human-AI Collaboration, Ethical AI, Responsibility",
    "number": "Article 160",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Capable but Amoral? Comparing AI and Human Expert Collaboration in Ethical Decision Making",
    "URL": "https://doi.org/10.1145/3491102.3517732"
  },
  {
    "id": "10.1145/3491102.3517443",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Echterhoff",
        "given": "Jessica Maria"
      },
      {
        "family": "Yarmand",
        "given": "Matin"
      },
      {
        "family": "McAuley",
        "given": "Julian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Decision-making involves biases from past experiences, which are difficult to perceive and eliminate. We investigate a specific type of anchoring bias, in which decision-makers are anchored by their own recent decisions, e.g.\u00a0a college admission officer sequentially reviewing students. We propose an algorithm that identifies existing anchored decisions, reduces sequential dependencies to previous decisions, and mitigates decision inaccuracies post-hoc with 2% increased agreement to ground-truth on a large-scale college admission decision data set. A crowd-sourced study validates this algorithm on product preferences (5% increased agreement). To avoid biased decisions ex-ante, we propose a procedure that presents instances in an order that reduces anchoring bias in real-time. Tested in another crowd-sourced study, it reduces bias and increases agreement to ground-truth by 7%. Our work reinforces individuals with similar characteristics to be treated similarly, independent of when they were reviewed in the decision-making process.",
    "call-number": "10.1145/3491102.3517443",
    "collection-number": "161",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517443",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Neural Networks, Bias, Decision-Making, Anchoring, Human-AI Interaction",
    "number": "Article 161",
    "number-of-pages": "9",
    "page": "1\u20139",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AI-Moderated Decision-Making: Capturing and Balancing Anchoring Bias in Sequential Decision Tasks",
    "URL": "https://doi.org/10.1145/3491102.3517443"
  },
  {
    "id": "10.1145/3491102.3501831",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cheng",
        "given": "Hao-Fei"
      },
      {
        "family": "Stapleton",
        "given": "Logan"
      },
      {
        "family": "Kawakami",
        "given": "Anna"
      },
      {
        "family": "Sivaraman",
        "given": "Venkatesh"
      },
      {
        "family": "Cheng",
        "given": "Yanghuidi"
      },
      {
        "family": "Qing",
        "given": "Diana"
      },
      {
        "family": "Perer",
        "given": "Adam"
      },
      {
        "family": "Holstein",
        "given": "Kenneth"
      },
      {
        "family": "Wu",
        "given": "Zhiwei Steven"
      },
      {
        "family": "Zhu",
        "given": "Haiyi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          27
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Machine learning tools have been deployed in various contexts to support human decision-making, in the hope that human-algorithm collaboration can improve decision quality. However, the question of whether such collaborations reduce or exacerbate biases in decision-making remains underexplored. In this work, we conducted a mixed-methods study, analyzing child welfare call screen workers\u2019 decision-making over a span of four years, and interviewing them on how they incorporate algorithmic predictions into their decision-making process. Our data analysis shows that, compared to the algorithm alone, workers reduced the disparity in screen-in rate between Black and white children from 20% to 9%. Our qualitative data show that workers achieved this by making holistic risk assessments and adjusting for the algorithm\u2019s limitations. Our analyses also show more nuanced results about how human-algorithm collaboration affects prediction accuracy, and how to measure these effects. These results shed light on potential mechanisms for improving human-algorithm collaboration in high-risk decision-making contexts.",
    "call-number": "10.1145/3491102.3501831",
    "collection-number": "162",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501831",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "machine learning, algorithmic biases, human-centered AI, algorithm-assisted decision-making, child welfare",
    "number": "Article 162",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How Child Welfare Workers Reduce Racial Disparities in Algorithmic Decisions",
    "URL": "https://doi.org/10.1145/3491102.3501831"
  },
  {
    "id": "10.1145/3491102.3517599",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ceha",
        "given": "Jessy"
      },
      {
        "family": "Law",
        "given": "Edith"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this paper, we explore how expressive auditory gestures added to the speech of a pedagogical agent influence the human-agent relationship and learning outcomes. In a between-subjects experiment, 41 participants assumed the role of a tutor to teach a voice-based agent. The agent used either: expressive interjections (e.g.,\u201cyay\u201d, \u201chmm\u201d, \u201coh\u201d), brief expressive musical executions, or no auditory gestures at all (control condition), throughout the interaction. Overall, the results indicate that both gestures can positively affect the interaction, but in particular, interjections can significantly increase feelings of emotional rapport with the agent and enhance motivation in learners. The implications of our findings are discussed as our work adds to the understanding of conversational agent design and can be useful for education as well as other domains in which dialogue systems are used.",
    "call-number": "10.1145/3491102.3517599",
    "collection-number": "163",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517599",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "rapport, music, agent, voice, interjections, education, motivation",
    "number": "Article 163",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Expressive Auditory Gestures in a Voice-Based Pedagogical Agent",
    "URL": "https://doi.org/10.1145/3491102.3517599"
  },
  {
    "id": "10.1145/3491102.3501974",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Khan",
        "given": "Anam Ahmad"
      },
      {
        "family": "Nawaz",
        "given": "Sadia"
      },
      {
        "family": "Newn",
        "given": "Joshua"
      },
      {
        "family": "Kelly",
        "given": "Ryan M."
      },
      {
        "family": "Lodge",
        "given": "Jason M."
      },
      {
        "family": "Bailey",
        "given": "James"
      },
      {
        "family": "Velloso",
        "given": "Eduardo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Though recent technological advances have enabled note-taking through different modalities (e.g., keyboard, digital ink, voice), there is still a lack of understanding of the effect of the modality choice on learning. In this paper, we compared two note-taking input modalities\u2014keyboard and voice\u2014to study their effects on participants\u2019 understanding of learning content. We conducted a study with 60 participants in which they were asked to take notes using voice or keyboard on two independent digital text passages while also making a judgment about their performance on an upcoming test. We built mixed-effects models to examine the effect of the note-taking modality on learners\u2019 text comprehension, the content of notes and their meta-comprehension judgement. Our findings suggest that taking notes using voice leads to a higher conceptual understanding of the text when compared to typing the notes. We also found that using voice triggers generative processes that result in learners taking more elaborate and comprehensive notes. The findings of the study imply that note-taking tools designed for digital learning environments could incorporate voice as an input modality to promote effective note-taking and higher conceptual understanding of the text.",
    "call-number": "10.1145/3491102.3501974",
    "collection-number": "164",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501974",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Voice notes, Input Modality, Digital learning, Note-taking tools",
    "number": "Article 164",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "To type or to speak? The effect of input modality on text understanding during note-taking",
    "URL": "https://doi.org/10.1145/3491102.3501974"
  },
  {
    "id": "10.1145/3491102.3501848",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kao",
        "given": "Dominic"
      },
      {
        "family": "Ratan",
        "given": "Rabindra"
      },
      {
        "family": "Mousas",
        "given": "Christos"
      },
      {
        "family": "Joshi",
        "given": "Amogh"
      },
      {
        "family": "Melcer",
        "given": "Edward F."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Avatar customization is known to positively affect crucial outcomes in numerous domains. However, it is unknown whether audial customization can confer the same benefits as visual customization. We conducted a preregistered 2 x 2 (visual choice vs. visual assignment x audial choice vs. audial assignment) study in a Java programming game. Participants with visual choice experienced higher avatar identification and autonomy. Participants with audial choice experienced higher avatar identification and autonomy, but only within the group of participants who had visual choice available. Visual choice led to an increase in time spent, and indirectly led to increases in intrinsic motivation, immersion, time spent, future play motivation, and likelihood of game recommendation. Audial choice moderated the majority of these effects. Our results suggest that audial customization plays an important enhancing role vis-\u00e0-vis visual customization. However, audial customization appears to have a weaker effect compared to visual customization. We discuss the implications for avatar customization more generally across digital applications.",
    "call-number": "10.1145/3491102.3501848",
    "collection-number": "165",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501848",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Customization, Games, Player Experience, Identification, Voice, Audio, Avatar",
    "number": "Article 165",
    "number-of-pages": "27",
    "page": "1\u201327",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Audio Matters Too: How Audial Avatar Customization Enhances Visual Avatar Customization",
    "URL": "https://doi.org/10.1145/3491102.3501848"
  },
  {
    "id": "10.1145/3491102.3502050",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Xu",
        "given": "Ying"
      },
      {
        "family": "Vigil",
        "given": "Valery"
      },
      {
        "family": "Bustamante",
        "given": "Andres S."
      },
      {
        "family": "Warschauer",
        "given": "Mark"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Video programs are important, accessible educational resources for young children, especially those from an under-resourced backgrounds. These programs\u2019 potential can be amplified if children are allowed to socially interact with media characters during their video watching. This paper presents the design and empirical investigation of interactive science-focused videos in which the main character, powered by a conversational agent, engaged in contingent conversation with children by asking children questions and providing responsive feedback. We found that children actively interacted with the media character in the conversational videos and their parents spontaneously provided support in the process. We also found that the children who watched the conversational video performed better in the immediate, episode-specific science assessment compared to their peers who watched the broadcast, non-interactive version of the same episode. Several design implications are discussed for using conversational technologies to better support child active learning and parent involvement in video watching.",
    "call-number": "10.1145/3491102.3502050",
    "collection-number": "166",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502050",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "conversational agents, science learning, children, Conversational AI, educational media",
    "number": "Article 166",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cElinor\u2019s Talking to Me!\u201d:Integrating Conversational AI into Children\u2019s Narrative Science Programming",
    "URL": "https://doi.org/10.1145/3491102.3502050"
  },
  {
    "id": "10.1145/3491102.3517680",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Garg",
        "given": "Radhika"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Smart speakers are increasingly being adopted by families in the U.S. In many cases, a smart speaker is shared by family members, which might make the sense of ownership uncertain. Through a diary and interview-based study with 20 Asian Indian parents and teenagers living in the U.S., this study through thematic analysis highlights various aspects of smart speakers that support or hinder the fulfilment of the psychological needs \u2013 self-efficacy, self-identity, territoriality, autonomy, and accountability and responsibility \u2013 that foster a sense of ownership. The paper also discusses the experiences of a cultural group that is not well represented in prior HCI work, and thus, it will add useful nuances and knowledge about inclusivity to the study of smart-speaker technology in HCI. Finally, it contributes six actionable design guidelines, including guidelines that relate to maintaining conversational context across different interactions and fostering a sense of ownership among users who share smart speakers, through the use of territorial markers.",
    "call-number": "10.1145/3491102.3517680",
    "collection-number": "167",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517680",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sense of ownership, autonomy, self-identity, accountability, parents, self-efficacy, Google Home, territoriality, responsibility, Alexa, teenagers, smart speakers",
    "number": "Article 167",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting the Design of Smart Speakers to Foster a Sense of Ownership in Asian Indian Families",
    "URL": "https://doi.org/10.1145/3491102.3517680"
  },
  {
    "id": "10.1145/3491102.3517619",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Miri",
        "given": "Pardis"
      },
      {
        "family": "Arora",
        "given": "Mehul"
      },
      {
        "family": "Malhotra",
        "given": "Aman"
      },
      {
        "family": "Flory",
        "given": "Robert"
      },
      {
        "family": "Hu",
        "given": "Stephanie"
      },
      {
        "family": "Lowber",
        "given": "Ashley"
      },
      {
        "family": "Goyal",
        "given": "Ishan"
      },
      {
        "family": "Nguyen",
        "given": "Jacqueline"
      },
      {
        "family": "Hegarty",
        "given": "John P"
      },
      {
        "family": "Kohn",
        "given": "Marlo D"
      },
      {
        "family": "Schneider",
        "given": "David"
      },
      {
        "family": "Culbertson",
        "given": "Heather"
      },
      {
        "family": "Yamins",
        "given": "Daniel L. K."
      },
      {
        "family": "Fung",
        "given": "Lawrence"
      },
      {
        "family": "Hardan",
        "given": "Antonio"
      },
      {
        "family": "Gross",
        "given": "James J."
      },
      {
        "family": "Marzullo",
        "given": "Keith"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "To address difficulties with affect dysregulation in youth diagnosed with autism spectrum disorder (ASD), we designed and developed an end-to-end vibrotactile breathing pacer system and evaluated its usability. In this paper we describe the system architecture and the features we deployed for this system based on expert advice and reviews. Through piloting this system with one child diagnosed with ASD, we learned that our system was used in ways we did and did not anticipate. For example, the paced-breathing personalization procedure did not meet the attention span of the pilot participant but two instead of one pacer devices encouraged caregiver\u2019s involvement. This paper details our learnings and concludes with a list of system design guidelines at the system architecture level. To the best of our knowledge, this is the first fully functional vibrotactile system designed for ASD children that withstood usability testing in vitro for two weeks.",
    "call-number": "10.1145/3491102.3517619",
    "collection-number": "168",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517619",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Affect Regulation, Vibrotactile, Expert evaluation, Autism Spectrum Disorder, Heuristic evaluation, Haptic, Pacer, Affect, Slow-paced breathing, Anxiety, Wearable, Respiration",
    "number": "Article 168",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FAR: End-to-End Vibrotactile Distributed System Designed to Facilitate Affect Regulation in Children Diagnosed with Autism Spectrum Disorder Through Slow Breathing",
    "URL": "https://doi.org/10.1145/3491102.3517619"
  },
  {
    "id": "10.1145/3491102.3502113",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lin",
        "given": "Hongnan"
      },
      {
        "family": "He",
        "given": "Liang"
      },
      {
        "family": "Song",
        "given": "Fangli"
      },
      {
        "family": "Li",
        "given": "Yifan"
      },
      {
        "family": "Cheng",
        "given": "Tingyu"
      },
      {
        "family": "Zheng",
        "given": "Clement"
      },
      {
        "family": "Wang",
        "given": "Wei"
      },
      {
        "family": "Oh",
        "given": "HyunJoo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper presents FlexHaptics, a design method for creating custom haptic input interfaces. Our approach leverages planar compliant structures whose force-deformation relationship can be altered by adjusting the geometries. Embedded with such structures, a FlexHaptics module exerts a fine-tunable haptic effect (i.e., resistance, detent, or bounce) along a movement path (i.e., linear, rotary, or ortho-planar). These modules can work separately or combine into an interface with complex movement paths and haptic effects. To enable the parametric design of FlexHaptic modules, we provide a design editor that converts user-specified haptic properties into underlying mechanical structures of haptic modules. We validate our approach and demonstrate the potential of FlexHaptic modules through six application examples, including a slider control for a painting application and a piano keyboard interface on touchscreens, a tactile low vision timer, VR game controllers, and a compound input device of a joystick and a two-step button.",
    "call-number": "10.1145/3491102.3502113",
    "collection-number": "169",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502113",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Compliant structure, Digital fabrication, Haptics, Parametric design, Tangible interface.",
    "number": "Article 169",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FlexHaptics: A Design Method for Passive Haptic Inputs Using Planar Compliant Structures",
    "URL": "https://doi.org/10.1145/3491102.3502113"
  },
  {
    "id": "10.1145/3491102.3502065",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yang",
        "given": "Humphrey"
      },
      {
        "family": "Johnson",
        "given": "Tate"
      },
      {
        "family": "Zhong",
        "given": "Ke"
      },
      {
        "family": "Patel",
        "given": "Dinesh"
      },
      {
        "family": "Olson",
        "given": "Gina"
      },
      {
        "family": "Majidi",
        "given": "Carmel"
      },
      {
        "family": "Islam",
        "given": "Mohammad"
      },
      {
        "family": "Yao",
        "given": "Lining"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "From creating input devices to rendering tangible information, the field of HCI is interested in using kinematic mechanisms to create human-computer interfaces. Yet, due to fabrication and design challenges, it is often difficult to create kinematic devices that are compact and have multiple reconfigurable motional degrees of freedom (DOFs) depending on the interaction scenarios. In this work, we combine compliant mechanisms (CMs) with tensioning cables to create dynamically reconfigurable kinematic mechanisms. The devices\u2019 kinematics (DOFs) is enabled and determined by the layout of bendable rods. The additional cables function as on-demand motion constraints that can dynamically lock or unlock the mechanism's DOFs as they are tightened or loosened. We provide algorithms and a design tool prototype to help users design such kinematic devices. We also demonstrate various HCI use cases including a kinematic haptic display, a haptic proxy, and a multimodal input device.",
    "call-number": "10.1145/3491102.3502065",
    "collection-number": "170",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502065",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "kinematic devices, design tool, wearables, compliant mechanism, Haptic proxies",
    "number": "Article 170",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ReCompFig: Designing Dynamically Reconfigurable Kinematic Devices Using Compliant Mechanisms and Tensioning Cables",
    "URL": "https://doi.org/10.1145/3491102.3502065"
  },
  {
    "id": "10.1145/3491102.3501829",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zheng",
        "given": "Clement"
      },
      {
        "family": "Yong",
        "given": "Zhen Zhou"
      },
      {
        "family": "Lin",
        "given": "Hongnan"
      },
      {
        "family": "Oh",
        "given": "HyunJoo"
      },
      {
        "family": "Yen",
        "given": "Ching Chiuan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present Shape-Haptics, an approach for designers to rapidly design and fabricate passive force feedback mechanisms for physical interfaces. Such mechanisms are used in everyday interfaces and tools, and they are challenging to design. Shape-Haptics abstracts and broadens the haptic expression of this class of force feedback systems through 2D laser cut configurations that are simple to fabricate. They leverage the properties of polyoxymethylene plastic and comprise a compliant spring structure that engages with a sliding profile during tangible interaction. By shaping the sliding profile, designers can easily customize the haptic force feedback delivered by the mechanism. We provide a computational design sandbox to facilitate designers to explore and fabricate Shape-Haptics mechanisms. We also propose a series of applications that demonstrate the utility of Shape-Haptics in creating and customizing haptics for different physical interfaces.",
    "call-number": "10.1145/3491102.3501829",
    "collection-number": "171",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501829",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Digital Fabrication, Passive Haptics, Tangible Interactions",
    "number": "Article 171",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Shape-Haptics: Planar & Passive Force Feedback Mechanisms for Physical Interfaces",
    "URL": "https://doi.org/10.1145/3491102.3501829"
  },
  {
    "id": "10.1145/3491102.3517532",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cheng",
        "given": "Tingyu"
      },
      {
        "family": "Park",
        "given": "Jung Wook"
      },
      {
        "family": "Li",
        "given": "Jiachen"
      },
      {
        "family": "Ramey",
        "given": "Charles"
      },
      {
        "family": "Lin",
        "given": "Hongnan"
      },
      {
        "family": "Abowd",
        "given": "Gregory D."
      },
      {
        "family": "Brum Medeiros",
        "given": "Carolina"
      },
      {
        "family": "Oh",
        "given": "HyunJoo"
      },
      {
        "family": "Giordano",
        "given": "Marcello"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This work presents PITAS, a thin-sheet robotic material composed of a reversible phase transition actuating layer and a heating/sensing layer. The synthetic sheet material enables non-expert makers to create shape-changing devices that can locally or remotely convey physical information such as shape, color, texture and temperature changes. PITAS sheets can be manipulated into various 2D shapes or 3D geometries using subtractive fabrication methods such as laser, vinyl, or manual cutting or an optional additive 3D printing method for creating 3D objects. After describing the design of PITAS, this paper also describes a study conducted with thirteen makers to gauge the accessibility, design space, and limitations encountered when PITAS is used as a soft robotic material while designing physical information communication devices. Lastly, this work reports on the results of a mechanical and electrical evaluation of PITAS and presents application examples to demonstrate its utility.",
    "call-number": "10.1145/3491102.3517532",
    "collection-number": "172",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517532",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "shape-changing interface, phase transition actuator, physical telecommunication",
    "number": "Article 172",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PITAS: Sensing and Actuating Embedded Robotic Sheet for Physical Information Communication",
    "URL": "https://doi.org/10.1145/3491102.3517532"
  },
  {
    "id": "10.1145/3491102.3501844",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hanton",
        "given": "Ollie"
      },
      {
        "family": "Shen",
        "given": "Zichao"
      },
      {
        "family": "Fraser",
        "given": "Mike"
      },
      {
        "family": "Roudaut",
        "given": "Anne"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Abstract: FabricatINK explores the personal fabrication of irregularly-shaped low-power displays using electronic ink (E ink). E ink is a programmable bicolour material used in traditional form-factors such as E readers. It has potential for more versatile use within the scope of personal fabrication of custom-shaped displays, and it has the promise to be the pre-eminent material choice for this purpose. We appraise technical literature to identify properties of E ink, suited to fabrication. We identify a key roadblock, universal access to E ink as a material, and we deliver a method to circumvent this by upcycling broken electronics. We subsequently present a novel fabrication method for irregularly-shaped E ink displays. We demonstrate our fabrication process and E ink\u2019s versatility through ten prototypes showing different applications and use cases. By addressing E ink as a material for display fabrication, we uncover the potential for users to create custom-shaped truly bistable displays.",
    "call-number": "10.1145/3491102.3501844",
    "collection-number": "173",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501844",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Electrophoretic, Prototyping, Fabrication, Free-Form Display, Display, E reader, E ink",
    "number": "Article 173",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FabricatINK: Personal Fabrication of Bespoke Displays Using Electronic Ink from Upcycled E Readers",
    "URL": "https://doi.org/10.1145/3491102.3501844"
  },
  {
    "id": "10.1145/3491102.3501842",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mitterberger",
        "given": "Daniela"
      },
      {
        "family": "Ercan Jenny",
        "given": "Selen"
      },
      {
        "family": "Vasey",
        "given": "Lauren"
      },
      {
        "family": "Lloret-Fritschi",
        "given": "Ena"
      },
      {
        "family": "Aejmelaeus-Lindstr\u00f6m",
        "given": "Petrus"
      },
      {
        "family": "Gramazio",
        "given": "Fabio"
      },
      {
        "family": "Kohler",
        "given": "Matthias"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper presents Interactive Robotic Plastering (IRoP), a system enabling designers and skilled workers to engage intuitively with an in-situ robotic plastering process. The research combines three elements: interactive design tools, an augmented reality interface, and a robotic spraying system. Plastering is a complex process relying on tacit knowledge and craftsmanship, making it difficult to simulate and automate. However, our system utilizes a controller-based interaction system to enable diverse users to interactively create articulated plasterwork in-situ. A customizable computational toolset converts human intentions into robotic motions while respecting robotic and material constraints. To accomplish this, we developed both an interactive computational model to translate the data from a motion-tracking system into robotic trajectories using design and editing tools as well as an audio-visual guidance system for in-situ projection. We then conducted two user-studies of designers and skilled workers who used IRoP to design and fabricate a full-scale demonstrator.",
    "call-number": "10.1145/3491102.3501842",
    "collection-number": "174",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501842",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "augmented reality, interactive fabrication, robot, digital fabrication",
    "number": "Article 174",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Interactive Robotic Plastering: Augmented Interactive Design and Fabrication for On-site Robotic Plastering",
    "URL": "https://doi.org/10.1145/3491102.3501842"
  },
  {
    "id": "10.1145/3491102.3517577",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Luo",
        "given": "Yiyue"
      },
      {
        "family": "Wu",
        "given": "Kui"
      },
      {
        "family": "Spielberg",
        "given": "Andrew"
      },
      {
        "family": "Foshey",
        "given": "Michael"
      },
      {
        "family": "Rus",
        "given": "Daniela"
      },
      {
        "family": "Palacios",
        "given": "Tom\u00e1s"
      },
      {
        "family": "Matusik",
        "given": "Wojciech"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Soft actuators with integrated sensing have shown utility in a variety of applications such as assistive wearables, robotics, and interactive input devices. Despite their promise, these actuators can be difficult to both design and fabricate. As a solution, we present a workflow for computationally designing and digitally fabricating soft pneumatic actuators via a machine knitting process. Machine knitting is attractive as a fabrication process because it is fast, digital (programmable), and provides access to a rich material library of functional yarns for specified mechanical behavior and integrated sensing. Our method uses elastic stitches to construct non-homogeneous knitting structures, which program the bending of actuators when inflated. Our method also integrates pressure and swept frequency capacitive sensing structures using conductive yarns. The entire knitted structure is fabricated automatically in a single machine run. We further provide a computational design interface for the user to interactively preview actuators\u2019 quasi-static shape when authoring elastic stitches. Our sensing-integrated actuators are cost-effective, easy to design, robust to large actuation, and require minimal manual post-processing. We demonstrate five use-cases of our actuators in relevant application settings.",
    "call-number": "10.1145/3491102.3517577",
    "collection-number": "175",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517577",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "smart textiles, Pneumatic actuators, machine knitting",
    "number": "Article 175",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Digital Fabrication of Pneumatic Actuators with Integrated Sensing by Machine Knitting",
    "URL": "https://doi.org/10.1145/3491102.3517577"
  },
  {
    "id": "10.1145/3491102.3502018",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "St\u00e5hl",
        "given": "Anna"
      },
      {
        "family": "Balaam",
        "given": "Madeline"
      },
      {
        "family": "Comber",
        "given": "Rob"
      },
      {
        "family": "Sanches",
        "given": "Pedro"
      },
      {
        "family": "H\u00f6\u00f6k",
        "given": "Kristina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Soma design is intended to increase our ability to appreciate through all our senses and lead to more meaningful interactions with the world. We contribute a longer-term study of soma design that shows evidence of this promise. Using storytelling approaches we draw on qualitative data from a three-month study of the soma mat and breathing light in four households. We tell stories of people\u2019s becomings in the world as they learn of new possibilities for their somas; and as their somas transform. We show how people drew on their somaesthetic experiences with the prototypes to find their way through troubled times; and how through continued engagement some felt compelled to make transformations in how they live their lives. We discuss the implications for the overarching soma design program, focusing on what is required to design for ways of leading a better life.",
    "call-number": "10.1145/3491102.3502018",
    "collection-number": "176",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502018",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "somaesthetic experiences, soma mat, soma design, new materialism, longer term study, entanglement theories, breathing light",
    "number": "Article 176",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Making New Worlds \u2013 Transformative Becomings with Soma Design",
    "URL": "https://doi.org/10.1145/3491102.3502018"
  },
  {
    "id": "10.1145/3491102.3501978",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "N\u00fa\u00f1ez-Pacheco",
        "given": "Claudia"
      },
      {
        "family": "Loke",
        "given": "Lian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Attending to the challenges of describing first-person experience, this article illustrates different uses of the Focusing method in interaction design and HCI, offering a systematic way of accessing the subtle qualities of lived experiences for design use. In this approach, the implicit bodily knowledge -or felt sense- becomes the material capture of aesthetic experiences used to inform data collection, ideation and prototyping. We offer a high-level, yet systematic coverage of Focusing applied to two case studies, informing both a set of instructions to use the method and a series of design considerations to adopt this understudied tool of introspection in interaction design research and practice.",
    "call-number": "10.1145/3491102.3501978",
    "collection-number": "177",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501978",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Focusing, Interaction Design, Design Methods, HCI, Soma Design",
    "number": "Article 177",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Focusing for Interaction Design: An Introspective Somatic Method",
    "URL": "https://doi.org/10.1145/3491102.3501978"
  },
  {
    "id": "10.1145/3491102.3501994",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Popova",
        "given": "Kristina"
      },
      {
        "family": "Garrett",
        "given": "Rachael"
      },
      {
        "family": "N\u00fa\u00f1ez-Pacheco",
        "given": "Claudia"
      },
      {
        "family": "Lampinen",
        "given": "Airi"
      },
      {
        "family": "H\u00f6\u00f6k",
        "given": "Kristina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We articulate vulnerability as an ethical stance in soma design processes and discuss the conditions of its emergence. We argue that purposeful vulnerability \u2013 an act of taking risk, exposing oneself, and resigning part of one\u2019s autonomy \u2013 is a necessary although often neglected part of design, and specifically soma design, which builds on felt experience and stimulates designers to engage with the non-habitual by challenging norms, habitual movements, and social interactions. With the help of ethnography, video analysis, and micro-phenomenological interviews, we document an early design exploration around drones, describing how vulnerability is accomplished in collaboration between members of the design team and the design materials. We (1) define vulnerability as an active ethical stance; (2) make vulnerability visible as a necessary but often neglected part of an exploratory design process; and (3) discuss the conditions of its emergence, demonstrating the importance of deliberating ethics within the design process.",
    "call-number": "10.1145/3491102.3501994",
    "collection-number": "178",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501994",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "soma design, drones, vulnerability, ethics",
    "number": "Article 178",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Vulnerability as an ethical stance in soma design processes",
    "URL": "https://doi.org/10.1145/3491102.3501994"
  },
  {
    "id": "10.1145/3491102.3501915",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Papenmeier",
        "given": "Andrea"
      },
      {
        "family": "Kern",
        "given": "Dagmar"
      },
      {
        "family": "Hienert",
        "given": "Daniel"
      },
      {
        "family": "Kammerer",
        "given": "Yvonne"
      },
      {
        "family": "Seifert",
        "given": "Christin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Supervised machine learning utilizes large datasets, often with ground truth labels annotated by humans. While some data points are easy to classify, others are hard to classify, which reduces the inter-annotator agreement. This causes noise for the classifier and might affect the user\u2019s perception of the classifier\u2019s performance. In our research, we investigated whether the classification difficulty of a data point influences how strongly a prediction mistake reduces the \u201cperceived accuracy\u201d. In an experimental online study, 225 participants interacted with three fictive classifiers with equal accuracy (73%). The classifiers made prediction mistakes on three different types of data points (easy, difficult, impossible). After the interaction, participants judged the classifier\u2019s accuracy. We found that not all prediction mistakes reduced the perceived accuracy equally. Furthermore, the perceived accuracy differed significantly from the calculated accuracy. To conclude, accuracy and related measures seem unsuitable to represent how users perceive the performance of classifiers.",
    "call-number": "10.1145/3491102.3501915",
    "collection-number": "180",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501915",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Ground Truth, Perception, Accuracy, Annotations",
    "number": "Article 180",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How Accurate Does It Feel? \u2013 Human Perception of Different Types of Classification Mistakes",
    "URL": "https://doi.org/10.1145/3491102.3501915"
  },
  {
    "id": "10.1145/3491102.3501826",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Wencan"
      },
      {
        "family": "Lim",
        "given": "Brian Y"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Machine learning models need to provide contrastive explanations, since people often seek to understand why a puzzling prediction occurred instead of some expected outcome. Current contrastive explanations are rudimentary comparisons between examples or raw features, which remain difficult to interpret, since they lack semantic meaning. We argue that explanations must be more relatable to other concepts, hypotheticals, and associations. Inspired by the perceptual process from cognitive psychology, we propose the XAI Perceptual Processing Framework and RexNet model for relatable explainable AI with Contrastive Saliency, Counterfactual Synthetic, and Contrastive Cues explanations. We investigated the application of vocal emotion recognition, and implemented a modular multi-task deep neural network to predict and explain emotions from speech. From think-aloud and controlled studies, we found that counterfactual explanations were useful and further enhanced with semantic cues, but not saliency explanations. This work provides insights into providing and evaluating relatable contrastive explainable AI for perception applications.",
    "call-number": "10.1145/3491102.3501826",
    "collection-number": "181",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501826",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "contrastive explanations, Explainable AI, vocal emotion, audio",
    "number": "Article 181",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Relatable Explainable AI with the Perceptual Process",
    "URL": "https://doi.org/10.1145/3491102.3501826"
  },
  {
    "id": "10.1145/3491102.3517522",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Wencan"
      },
      {
        "family": "Dimiccoli",
        "given": "Mariella"
      },
      {
        "family": "Lim",
        "given": "Brian Y"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Model explanations such as saliency maps can improve user trust in AI by highlighting important features for a prediction. However, these become distorted and misleading when explaining predictions of images that are subject to systematic error (bias) by perturbations and corruptions. Furthermore, the distortions persist despite model fine-tuning on images biased by different factors (blur, color temperature, day/night). We present Debiased-CAM to recover explanation faithfulness across various bias types and levels by training a multi-input, multi-task model with auxiliary tasks for explanation and bias level predictions. In simulation studies, the approach not only enhanced prediction accuracy, but also generated highly faithful explanations about these predictions as if the images were unbiased. In user studies, debiased explanations improved user task performance, perceived truthfulness and perceived helpfulness. Debiased training can provide a versatile platform for robust performance and explanation faithfulness for a wide range of applications with data biases.",
    "call-number": "10.1145/3491102.3517522",
    "collection-number": "182",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517522",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Image perturbations, Misleading explanations, Robust machine learning, Class activation map, Explainable AI, User studies",
    "number": "Article 182",
    "number-of-pages": "32",
    "page": "1\u201332",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Debiased-CAM to mitigate image perturbations with faithful visual explanations of machine learning",
    "URL": "https://doi.org/10.1145/3491102.3517522"
  },
  {
    "id": "10.1145/3491102.3517551",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Yunlong"
      },
      {
        "family": "Venkatesh",
        "given": "Priyadarshini"
      },
      {
        "family": "Lim",
        "given": "Brian Y"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Feedback in creativity support tools can help crowdworkers to improve their ideations. However, current feedback methods require human assessment from facilitators or peers. This is not scalable to large crowds. We propose Interpretable Directed Diversity to automatically predict ideation quality and diversity scores, and provide AI explanations \u2014 Attribution, Contrastive Attribution, and Counterfactual Suggestions \u2014 to feedback on why ideations were scored (low), and how to get higher scores. These explanations provide multi-faceted feedback as users iteratively improve their ideations. We conducted formative and controlled user studies to understand the usage and usefulness of explanations to improve ideation diversity and quality. Users appreciated that explanation feedback helped focus their efforts and provided directions for improvement. This resulted in explanations improving diversity compared to no feedback or feedback with scores only. Hence, our approach opens opportunities for explainable AI towards scalable and rich feedback for iterative crowd ideation and creativity support tools.",
    "call-number": "10.1145/3491102.3517551",
    "collection-number": "183",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517551",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Collective Creativity, Explainable AI, Diversity, Crowdsourcing",
    "number": "Article 183",
    "number-of-pages": "28",
    "page": "1\u201328",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Interpretable Directed Diversity: Leveraging Model Explanations for Iterative Crowd Ideation",
    "URL": "https://doi.org/10.1145/3491102.3517551"
  },
  {
    "id": "10.1145/3491102.3517474",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Balayn",
        "given": "Agathe"
      },
      {
        "family": "Rikalo",
        "given": "Natasa"
      },
      {
        "family": "Lofi",
        "given": "Christoph"
      },
      {
        "family": "Yang",
        "given": "Jie"
      },
      {
        "family": "Bozzon",
        "given": "Alessandro"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Deep learning models for image classification suffer from dangerous issues often discovered after deployment. The process of identifying bugs that cause these issues remains limited and understudied. Especially, explainability methods are often presented as obvious tools for bug identification. Yet, the current practice lacks an understanding of what kind of explanations can best support the different steps of the bug identification process, and how practitioners could interact with those explanations. Through a formative study and an iterative co-creation process, we build an interactive design probe providing various potentially relevant explainability functionalities, integrated into interfaces that allow for flexible workflows. Using the probe, we perform 18 user-studies with a diverse set of machine learning practitioners. Two-thirds of the practitioners engage in successful bug identification. They use multiple types of explanations, e.g. visual and textual ones, through non-standardized sequences of interactions including queries and exploration. Our results highlight the need for interactive, guiding, interfaces with diverse explanations, shedding light on future research directions.",
    "call-number": "10.1145/3491102.3517474",
    "collection-number": "184",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517474",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "computer vision, machine learning explainability, machine learning model debugging, user interface",
    "number": "Article 184",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How can Explainability Methods be Used to Support Bug Identification in Computer Vision Models?",
    "URL": "https://doi.org/10.1145/3491102.3517474"
  },
  {
    "id": "10.1145/3491102.3502034",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tsai",
        "given": "Ching-Yi"
      },
      {
        "family": "Tsai",
        "given": "I-Lun"
      },
      {
        "family": "Lai",
        "given": "Chao-Jung"
      },
      {
        "family": "Chow",
        "given": "Derrek"
      },
      {
        "family": "Wei",
        "given": "Lauren"
      },
      {
        "family": "Cheng",
        "given": "Lung-Pan"
      },
      {
        "family": "Chen",
        "given": "Mike Y."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present AirRacket, perceptual modeling and design of ungrounded, directional force feedback for virtual racket sports. Using compressed air propulsion jets to provide directional impact forces, we iteratively designed for three popular sports that span a wide range of force magnitudes: ping-pong, badminton, and tennis. To address the limited force magnitude of ungrounded force feedback technologies, we conducted a perception study which discovered the novel illusion that users perceive larger impact force magnitudes with longer impact duration, by an average factor of 2.57x. Through a series of formative, perceptual, and user experience studies with a combined total of 72 unique participants, we explored several perceptual designs using force magnitude scaling and duration scaling methods to expand the dynamic range of perceived force magnitude. Our user experience evaluation showed that perceptual designs can significantly improve realism and preference vs. physics-based designs for ungrounded force feedback systems.",
    "call-number": "10.1145/3491102.3502034",
    "collection-number": "185",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502034",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "perceptual design, Haptics, force perception, virtual reality., ungrounded force feedback, air propulsion",
    "number": "Article 185",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AirRacket: Perceptual Design of Ungrounded, Directional Force Feedback to Improve Virtual Racket Sports Experiences",
    "URL": "https://doi.org/10.1145/3491102.3502034"
  },
  {
    "id": "10.1145/3491102.3517529",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chen",
        "given": "Kuan-Wen"
      },
      {
        "family": "Chang",
        "given": "Yung-Ju"
      },
      {
        "family": "Chan",
        "given": "Liwei"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Virtual reality (VR) has increasingly been used in many areas, and the need to deliver notifications in VR is also expected to increase accordingly. However, untimely interruptions could largely impact the experience in VR. Identifying opportune times to deliver notifications to users allows for notifications to be scheduled in a way that minimizes disruption. We conducted a study to investigate the use of sensor data available on an off-the-shelf VR device and additional contextual information, including current activity and engagement of users, to predict opportune moments for sending notifications using deep learning models. Our analysis shows that using mainly sensor features could achieve 72% recall, 71% precision and 0.86 area under receiver operating characteristic (AUROC); performance can be further improved to 81% recall, 82% precision, and 0.93 AUROC if information about activity and summarized user engagement is included.",
    "call-number": "10.1145/3491102.3517529",
    "collection-number": "186",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517529",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Notifications, Predictive Models;, Virtual Reality, Interruptibility",
    "number": "Article 186",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Predicting Opportune Moments to Deliver Notifications in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517529"
  },
  {
    "id": "10.1145/3491102.3501959",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Matviienko",
        "given": "Andrii"
      },
      {
        "family": "M\u00fcller",
        "given": "Florian"
      },
      {
        "family": "Zickler",
        "given": "Marcel"
      },
      {
        "family": "Gasche",
        "given": "Lisa Alina"
      },
      {
        "family": "Abels",
        "given": "Julia"
      },
      {
        "family": "Steinert",
        "given": "Till"
      },
      {
        "family": "M\u00fchlh\u00e4user",
        "given": "Max"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Virtual Reality (VR) bicycle simulations aim to recreate the feeling of riding a bicycle and are commonly used in many application areas. However, current solutions still create mismatches between the visuals and physical movement, which causes VR sickness and diminishes the cycling experience. To reduce VR sickness in bicycle simulators, we conducted two controlled lab experiments addressing two main causes of VR sickness: (1) steering methods and (2) cycling trajectory. In the first experiment (N = 18) we compared handlebar, HMD, and upper-body steering methods. In the second experiment (N = 24) we explored three types of movement in VR (1D, 2D, and 3D trajectories) and three countermeasures (airflow, vibration, and dynamic Field-of-View) to reduce VR sickness. We found that handlebar steering leads to the lowest VR sickness without decreasing cycling performance and airflow suggests to be the most promising method to reduce VR sickness for all three types of trajectories.",
    "call-number": "10.1145/3491102.3501959",
    "collection-number": "187",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501959",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "VR sickness, cycling, bicycle simulators, virtual reality",
    "number": "Article 187",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Reducing Virtual Reality Sickness for Cyclists in VR Bicycle Simulators",
    "URL": "https://doi.org/10.1145/3491102.3501959"
  },
  {
    "id": "10.1145/3491102.3501828",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Piitulainen",
        "given": "Roosa"
      },
      {
        "family": "H\u00e4m\u00e4l\u00e4inen",
        "given": "Perttu"
      },
      {
        "family": "Mekler",
        "given": "Elisa D"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Dancing is a universal human activity, and also a domain of enduring significance in Human-Computer Interaction (HCI) research. However, there has been limited investigation into how computing supports the experiences of recreational dancers. Concurrently, a diverse and sizeable dance community has been emerging in VRChat. Little is known about these dancers\u2019 experiences, motivations, and practices. Yet shedding light into these could inform both VR technology development and the design of systems that better support embodied and complex social interactions. To bridge this gap, we interviewed participants active in the VRChat dance scene. Through thematic analysis, we identified six central facets of their experiences related to freedom, community, dance as an individual experience, dance as a shared experience, dance as a performance, and self-expression and -exploration. Based on these findings, we discuss emerging tensions and highlight beneficial impacts of dancing in VR as well as problems that still await resolving.",
    "call-number": "10.1145/3491102.3501828",
    "collection-number": "188",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501828",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "dancing, VRChat, social VR",
    "number": "Article 188",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Vibing Together: Dance Experiences in Social Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3501828"
  },
  {
    "id": "10.1145/3491102.3501847",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Park",
        "given": "Su Han"
      },
      {
        "family": "Han",
        "given": "Bin"
      },
      {
        "family": "Kim",
        "given": "Gerard Jounghyun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Simulator sickness has been one of the major obstacles toward making virtual reality (VR) widely accepted and used. For example, virtual navigation produces vection, which is the illusion of self-motion as one perceives bodily motion despite no movement actually occurs. This, in turn, causes a sensory conflict between visual and actual (or vestibular) motion and sickness. In this study, we explore a method to reduce simulator sickness by visually mixing the optical flow patterns that are in the reverse direction of the virtual visual motion. As visual motion is mainly detected and perceived by the optical flow, artificial mixing in the reverse flow is hypothesized to induce a cancellation effect, thereby reducing the degree of the conflict with the vestibular sense and sickness. To validate our hypothesis, we developed a real-time algorithm to visualize the reverse optical flow and conducted experiments by comparing the before and after sickness levels in seven virtual navigation conditions. The experimental results confirmed the proposed method was effective for reducing the simulator sickness in a statistically significant manner. However, no dependency to the motion type or degrees of freedom were found. Significant distraction and negative influence to the sense of presence and immersion were observed only when the the artificially added reverse optical flow patterns were rather visually marked with high contrast to the background content.",
    "call-number": "10.1145/3491102.3501847",
    "collection-number": "189",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501847",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Optical Flow, Simulator Sickness, Virtual Reality, Vection",
    "number": "Article 189",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mixing in Reverse Optical Flow to Mitigate Vection and Simulation Sickness in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3501847"
  },
  {
    "id": "10.1145/3491102.3501875",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rogers",
        "given": "Katja"
      },
      {
        "family": "Karaosmanoglu",
        "given": "Sukran"
      },
      {
        "family": "Altmeyer",
        "given": "Maximilian"
      },
      {
        "family": "Suarez",
        "given": "Ally"
      },
      {
        "family": "Nacke",
        "given": "Lennart E."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Researchers reference realism in digital games without sufficient specificity. Without clarity about the dimensions of realism, we cannot assess how and when to aim for a higher degree of realism, when lower realism suffices, or when purposeful unrealism is ideal for a game and can benefit player experience (PX). To address this conceptual gap, we conducted a systematic review using thematic synthesis to distinguish between types of realism currently found in the digital games literature. We contribute qualitative themes that showcase contradictory design goals of realism/unrealism. From these themes, we created a framework (i.e., a hierarchical taxonomy and mapping) of realism dimensions in digital games as a conceptual foundation. Our themes and framework enable a workable specificity for designing or analyzing types of realism, equip future work to explore effects of specific realism types on PX, and offer a starting point for similar efforts in non-game applications.",
    "call-number": "10.1145/3491102.3501875",
    "collection-number": "190",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501875",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "thematic synthesis, systematic literature review, fidelity, realism",
    "number": "Article 190",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Much Realistic, Such Wow! A Systematic Literature Review of Realism in Digital Games",
    "URL": "https://doi.org/10.1145/3491102.3501875"
  },
  {
    "id": "10.1145/3491102.3501885",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Misztal",
        "given": "Sebastian"
      },
      {
        "family": "Schild",
        "given": "Jonas"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Visual effects and elements in video games and interactive virtual environments can be applied to transfer (or delegate) non-visual perceptions (e.g., proprioception, presence, pain) to players and users, thus increasing perceptual diversity via the visual modality. Such elements or effects are referred to as visual delegates (VDs). Current findings on the experiences that VDs can elicit relate to specific VDs, not to VDs in general. Deductive and comprehensive VD evaluation frameworks are lacking. We analyzed VDs in video games to generalize VDs in terms of their visual properties. We conducted a systematic paper analysis to explore player and user experiences observed in association with specific VDs in user studies. We conducted semi-structured interviews with expert players to determine their preferences and the impact of VD properties. The resulting VD framework (VD-frame) contributes to a more strategic approach to identifying the impact of VDs on player and user experiences.",
    "call-number": "10.1145/3491102.3501885",
    "collection-number": "191",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501885",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "literature review, graphical user interface, game analysis, visual perception, visual delegates, virtual reality, user experience, semi-structured interview",
    "number": "Article 191",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Visual Delegate Generalization Frame \u2013 Evaluating Impact of Visual Effects and Elements on Player and User Experiences in Video Games and Interactive Virtual Environments",
    "URL": "https://doi.org/10.1145/3491102.3501885"
  },
  {
    "id": "10.1145/3491102.3502110",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Farkas",
        "given": "Timea"
      },
      {
        "family": "Denisova",
        "given": "Alena"
      },
      {
        "family": "Wiseman",
        "given": "Sarah"
      },
      {
        "family": "Fiebrink",
        "given": "Rebecca"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Board gaming is a popular hobby that increasingly features the inclusion of technology, yet little research has sought to understand how board game player experience is impacted by digital augmentation or to inform the design of new technology-enhanced games. We present a mixed-methods study exploring how the presence of music and sound effects impacts the player experience of a board game. We found that the soundtrack increased the enjoyment and tension experienced by players during game play. We also found that a soundtrack provided atmosphere surrounding the gaming experience, though players did not necessarily experience this as enhancing the world-building capabilities of the game. We discuss how our findings can inform the design of new games and soundtracks as well as future research into board game player experience.",
    "call-number": "10.1145/3491102.3502110",
    "collection-number": "192",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502110",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Tension, Enjoyment, Soundtrack, Atmosphere, Thematicness, Music, Player Experience, Board Games",
    "number": "Article 192",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Effects of a Soundtrack on Board Game Player Experience",
    "URL": "https://doi.org/10.1145/3491102.3502110"
  },
  {
    "id": "10.1145/3491102.3517581",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Altmeyer",
        "given": "Maximilian"
      },
      {
        "family": "Hnatovskiy",
        "given": "Vladislav"
      },
      {
        "family": "Rogers",
        "given": "Katja"
      },
      {
        "family": "Lessel",
        "given": "Pascal"
      },
      {
        "family": "Nacke",
        "given": "Lennart E."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sound effects (SFX) complement the visual feedback provided by gamification elements in gamified systems. However, the impact of SFX has not been systematically studied. To bridge this gap, we investigate the effects of SFX\u2014supplementing points (as a gamification element)\u2014on task performance and user experience in a gamified image classification task. We created 18 SFX, studied their impact on perceived valence and arousal (N = 49) and selected four suitable SFX to be used in a between-participants user study (N = 317). Our findings show that neither task performance, affect, immersion, nor enjoyment were significantly affected by the sounds. Only the pressure/tension factor differed significantly, indicating that low valence sounds should be avoided to accompany point rewards. Overall, our results suggest that SFX seem to have less impact than expected in gamified systems. Hence, using SFX in gamification should be a more informed choice and should receive more attention in gamification research.",
    "call-number": "10.1145/3491102.3517581",
    "collection-number": "193",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517581",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sound, gamification, points, SFX, microtasks",
    "number": "Article 193",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Here Comes No Boom! The Lack of Sound Feedback Effects on Performance and User Experience in a Gamified Image Classification Task",
    "URL": "https://doi.org/10.1145/3491102.3517581"
  },
  {
    "id": "10.1145/3491102.3502085",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Bingqing"
      },
      {
        "family": "Barbareschi",
        "given": "Giulia"
      },
      {
        "family": "Ramirez Herrera",
        "given": "Roxana"
      },
      {
        "family": "Carlson",
        "given": "Tom"
      },
      {
        "family": "Holloway",
        "given": "Catherine"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Shared control wheelchairs can help users to navigate through crowds by enabling the person to drive the wheelchair while receiving support in avoiding pedestrians. To date, research into shared control has largely overlooked the perspectives of wheelchair users. In this paper, we present two studies that aim to address this gap. The first study involved a series of semi-structured interviews with wheelchair users which highlighted the presence of two different interaction loops, one between the user and the wheelchair and a second one between the user and the crowd. In the second study we engaged with wheelchair users and designers to co-design appropriate feedback loops for future shared control interaction interfaces. Based on the results of the co-design session, we present design implications for shared control wheelchair around the need for empathy, embodiment and social awareness; situational awareness and adaptability; and selective information management.",
    "call-number": "10.1145/3491102.3502085",
    "collection-number": "194",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502085",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Smart wheelchairs, Wheelchair-user interactions, Wheelchair-pedestrian interactions, Navigation in crowds, Shared control",
    "number": "Article 194",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Interactions for Smart Wheelchair Navigation in Crowds",
    "URL": "https://doi.org/10.1145/3491102.3502085"
  },
  {
    "id": "10.1145/3491102.3501986",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hassan",
        "given": "Saad"
      },
      {
        "family": "Amin",
        "given": "Akhter Al"
      },
      {
        "family": "Gordon",
        "given": "Alexis"
      },
      {
        "family": "Lee",
        "given": "Sooyeon"
      },
      {
        "family": "Huenerfauth",
        "given": "Matt"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Searching for the meaning of an unfamiliar sign-language word in a dictionary is difficult for learners, but emerging sign-recognition technology will soon enable users to search by submitting a video of themselves performing the word they recall. However, sign-recognition technology is imperfect, and users may need to search through a long list of possible results when seeking a desired result. To speed this search, we present a hybrid-search approach, in which users begin with a video-based query and then filter the search results by linguistic properties, e.g., handshape. We interviewed 32 ASL learners about their preferences for the content and appearance of the search-results page and filtering criteria. A between-subjects experiment with 20 ASL learners revealed that our hybrid search system outperformed a video-based search system along multiple satisfaction and performance metrics. Our findings provide guidance for designers of video-based sign-language dictionary search systems, with implications for other search scenarios.",
    "call-number": "10.1145/3491102.3501986",
    "collection-number": "195",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501986",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Sign Languages, IR Effectiveness, American Sign Language (ASL), Search Interfaces, User Satisfaction, Search System Design, Dictionary, Video Search, Search Evaluation",
    "number": "Article 195",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design and Evaluation of Hybrid Search for American Sign Language to English Dictionaries: Making the Most of Imperfect Sign Recognition",
    "URL": "https://doi.org/10.1145/3491102.3501986"
  },
  {
    "id": "10.1145/3491102.3501918",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Das",
        "given": "Maitraye"
      },
      {
        "family": "McHugh",
        "given": "Thomas Barlow"
      },
      {
        "family": "Piper",
        "given": "Anne Marie"
      },
      {
        "family": "Gergle",
        "given": "Darren"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Collaborative writing is an integral part of academic and professional work. Although some prior research has focused on accessibility in collaborative writing, we know little about how visually impaired writers work in real-time with sighted collaborators or how online editing tools could better support their work. Grounded in formative interviews and observations with eight screen reader users, we built Co11ab, a Google Docs extension that provides configurable audio cues to facilitate understanding who is editing (or edited) what and where in a shared document. Results from a design exploration with fifteen screen reader users, including three naturalistic sessions of use with sighted colleagues, reveal how screen reader users understand various auditory representations and use them to coordinate real-time collaborative writing. We revisit what collaboration awareness means for screen reader users and discuss design considerations for future systems.",
    "call-number": "10.1145/3491102.3501918",
    "collection-number": "196",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501918",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "screen readers, vision impairments, Collaborative writing, ability-diverse collaboration, accessibility, collaboration awareness",
    "number": "Article 196",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Co11ab: Augmenting Accessibility in Synchronous Collaborative Writing for People with Vision Impairments",
    "URL": "https://doi.org/10.1145/3491102.3501918"
  },
  {
    "id": "10.1145/3491102.3502092",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Mingrui Ray"
      },
      {
        "family": "Zhong",
        "given": "Mingyuan"
      },
      {
        "family": "Wobbrock",
        "given": "Jacob O."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Animated GIF images have become prevalent in internet culture, often used to express richer and more nuanced meanings than static images. But animated GIFs often lack adequate alternative text descriptions, and it is challenging to generate such descriptions automatically, resulting in inaccessible GIFs for blind or low-vision (BLV) users. To improve the accessibility of animated GIFs for BLV users, we provide a system called Ga11y (pronounced \u201cgalley\u201d), for creating GIF annotations. Ga11y combines the power of machine intelligence and crowdsourcing and has three components: an Android client for submitting annotation requests, a backend server and database, and a web interface where volunteers can respond to annotation requests. We evaluated three human annotation interfaces and employ the one that yielded the best annotation quality. We also conducted a multi-stage evaluation with 12 BLV participants from the United States and China, receiving positive feedback.",
    "call-number": "10.1145/3491102.3502092",
    "collection-number": "197",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502092",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "images, blind, human annotation, crowdsourcing, GIF, low vision, accessibility., text description",
    "number": "Article 197",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Ga11y: An Automated GIF Annotation System for Visually Impaired Users",
    "URL": "https://doi.org/10.1145/3491102.3502092"
  },
  {
    "id": "10.1145/3491102.3501944",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kang",
        "given": "Soowon"
      },
      {
        "family": "Park",
        "given": "Cheul Young"
      },
      {
        "family": "Kim",
        "given": "Auk"
      },
      {
        "family": "Cha",
        "given": "Narae"
      },
      {
        "family": "Lee",
        "given": "Uichin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Mobile experience sampling methods\u00a0(ESMs) are widely used to measure users\u2019 affective states by randomly sending self-report requests. However, this random probing can interrupt users and adversely influence users\u2019 emotional states by inducing disturbance and stress. This work aims to understand how ESMs themselves may compromise the validity of ESM responses and what contextual factors contribute to changes in emotions when users respond to ESMs. Towards this goal, we analyze 2,227 samples of the mobile ESM data collected from 78 participants. Our results show ESM interruptions positively or negatively affected users\u2019 emotional states in at least 38% of ESMs, and the changes in emotions are closely related to the contexts users were in prior to ESMs. Finally, we discuss the implications of using the ESM and possible considerations for mitigating the variability in emotional responses in the context of mobile data collection for affective computing.",
    "call-number": "10.1145/3491102.3501944",
    "collection-number": "198",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501944",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Experience Sampling, Empirical study that tells us about people, Mobile Devices: Phones/Tablets, Emotion / Affective Computing",
    "number": "Article 198",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Emotion Changes in Mobile Experience Sampling",
    "URL": "https://doi.org/10.1145/3491102.3501944"
  },
  {
    "id": "10.1145/3491102.3517661",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Krekhov",
        "given": "Andrey"
      },
      {
        "family": "Emmerich",
        "given": "Katharina"
      },
      {
        "family": "Fuchs",
        "given": "Johannes"
      },
      {
        "family": "Krueger",
        "given": "Jens Harald"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We frequently utilize face emojis to express emotions in digital communication. But how wholly and precisely do such pictographs sample the emotional spectrum, and are there gaps to be closed? Our research establishes emoji intensity scales for seven basic emotions: happiness, anger, disgust, sadness, shock, annoyance, and love. In our survey (N\u00a0=\u00a01195), participants worldwide assigned emotions and intensities to 68 face emojis. According to our results, certain feelings, such as happiness or shock, are visualized by manifold emojis covering a broad spectrum of intensities. Other feelings, such as anger, have limited and only very intense representative visualizations. We further emphasize that the cultural background influences emojis\u2019 perception: for instance, linear-active cultures (e.g., UK, Germany) rate the intensity of such visualizations higher than multi-active (e.g., Brazil, Russia) or reactive cultures (e.g., Indonesia, Singapore). To summarize, our manuscript promotes future research on more expressive, culture-aware emoji design.",
    "call-number": "10.1145/3491102.3517661",
    "collection-number": "200",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517661",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "emoji, emotion visualization, cultures, smiley, intensity",
    "number": "Article 200",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Interpolating Happiness: Understanding the Intensity Gradations of Face Emojis Across Cultures",
    "URL": "https://doi.org/10.1145/3491102.3517661"
  },
  {
    "id": "10.1145/3491102.3517569",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ernala",
        "given": "Sindhu Kiranmai"
      },
      {
        "family": "Burke",
        "given": "Moira"
      },
      {
        "family": "Leavitt",
        "given": "Alex"
      },
      {
        "family": "Ellison",
        "given": "Nicole B."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "\u201cTime spent on platform\u201d is a widely used measure in many studies examining social media use and well-being, yet the current literature presents unresolved findings about the relationship between time on platform and well-being. In this paper, we consider the moderating effect of people\u2019s mindsets about social media \u2014 whether they think a platform is good or bad for themselves and for society more generally. Combining survey responses from 29,284 participants in 15 countries with server-logged data of Facebook use, we found that when people thought that Facebook was good for them and for society, time spent on the platform was not significantly associated with well-being. Conversely, when they thought Facebook was bad, greater time spent was associated with lower well-being. On average, there was a small, negative correlation between time spent and well-being and the causal direction is not known. Beliefs had a stronger moderating relationship when time-spent measures were self-reported rather than coming from server logs. We discuss potential mechanisms for these results and implications for future research on well-being and social media use.",
    "call-number": "10.1145/3491102.3517569",
    "collection-number": "201",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517569",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "well-being, social media, mindsets, Facebook, beliefs",
    "number": "Article 201",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mindsets Matter: How Beliefs About Facebook Moderate the Association Between Time Spent and Well-Being",
    "URL": "https://doi.org/10.1145/3491102.3517569"
  },
  {
    "id": "10.1145/3491102.3517563",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Niu",
        "given": "Shuo"
      },
      {
        "family": "Manon",
        "given": "Hugh S."
      },
      {
        "family": "Bartolome",
        "given": "Ava"
      },
      {
        "family": "Ha",
        "given": "Nguyen Binh"
      },
      {
        "family": "Veazey",
        "given": "Keegan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "ASMR (Autonomous Sensory Meridian Response) has grown to immense popularity on YouTube and drawn HCI designers\u2019 attention to its effects and applications in design. YouTube ASMR creators incorporate visual elements, sounds, motifs of touching and tasting, and other scenarios in multisensory video interactions to deliver enjoyable and relaxing experiences to their viewers. ASMRtists engage viewers by social, physical, and task attractions. Research has identified the benefits of ASMR in mental wellbeing. However, ASMR remains an understudied phenomenon in the HCI community, constraining designers\u2019 ability to incorporate ASMR in video-based designs. This work annotates and analyzes the interaction modalities and parasocial attractions of 2663 videos to identify unique experiences. YouTube comment sections are also analyzed to compare viewers\u2019 responses to different ASMR interactions. We find that ASMR videos are experiences of multimodal social connection, relaxing physical intimacy, and sensory-rich activity observation. Design implications are discussed to foster future ASMR-augmented video interactions.",
    "call-number": "10.1145/3491102.3517563",
    "collection-number": "202",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517563",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "multimodal, video, parasocial, ASMR, YouTube, experience",
    "number": "Article 202",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Close-up and Whispering: An Understanding of Multimodal and Parasocial Interactions in YouTube ASMR videos",
    "URL": "https://doi.org/10.1145/3491102.3517563"
  },
  {
    "id": "10.1145/3491102.3517587",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ma",
        "given": "Zilin"
      },
      {
        "family": "Gajos",
        "given": "Krzysztof Z."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As dating websites are becoming an essential part of how people meet intimate and romantic partners, it is vital to design these systems to be resistant to, or at least do not amplify, bias and discrimination. Instead, the results of our online experiment with a simulated dating website, demonstrate that popular dating website design choices, such as the user of the swipe interface (swiping in one direction to indicate a like and in the other direction to express a dislike) and match scores, resulted in people racially biases choices even when they explicitly claimed not to have considered race in their decision-making. This bias was significantly reduced when the order of information presentation was reversed such that people first saw substantive profile information related to their explicitly-stated preferences before seeing the profile name and photo. These results indicate that currently-popular design choices amplify people\u2019s implicit biases in their choices of potential romantic partners, but the effects of the implicit biases can be reduced by carefully redesigning the dating website interfaces.",
    "call-number": "10.1145/3491102.3517587",
    "collection-number": "203",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517587",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "implicit bias, dating websites",
    "number": "Article 203",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Not Just a Preference: Reducing Biased Decision-making on Dating Websites",
    "URL": "https://doi.org/10.1145/3491102.3517587"
  },
  {
    "id": "10.1145/3491102.3502028",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bhuiyan",
        "given": "Md Momen"
      },
      {
        "family": "Bautista Isaza",
        "given": "Carlos Augusto"
      },
      {
        "family": "Mitra",
        "given": "Tanushree"
      },
      {
        "family": "Lee",
        "given": "Sang Won"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "To promote engagement, recommendation algorithms on platforms like YouTube increasingly personalize users\u2019 feeds, limiting users\u2019 exposure to diverse content and depriving them of opportunities to reflect on their interests compared to others\u2019. In this work, we investigate how exchanging recommendations with strangers can help users discover new content and reflect. We tested this idea by developing OtherTube\u2014a browser extension for YouTube that displays strangers\u2019 personalized YouTube recommendations. OtherTube allows users to (i) create an anonymized profile for social comparison, (ii) share their recommended videos with others, and (iii) browse strangers\u2019 YouTube recommendations. We conducted a 10-day-long user study (n = 41) followed by a post-study interview (n = 11). Our results reveal that users discovered and developed new interests from seeing OtherTube recommendations. We identified user and content characteristics that affect interaction and engagement with exchanged recommendations; for example, younger users interacted more with OtherTube, while the perceived irrelevance of some content discouraged users from watching certain videos. Users reflected on their interests as well as others\u2019, recognizing similarities and differences. Our work shows promise for designs leveraging the exchange of personalized recommendations with strangers.",
    "call-number": "10.1145/3491102.3502028",
    "collection-number": "204",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502028",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Recommender System, Content Discovery, Persona, YouTube, Filter Bubble, Social Comparison, Self-Reflection",
    "number": "Article 204",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "OtherTube: Facilitating Content Discovery and Reflection by Exchanging YouTube Recommendations with Strangers",
    "URL": "https://doi.org/10.1145/3491102.3502028"
  },
  {
    "id": "10.1145/3491102.3517505",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jhaver",
        "given": "Shagun"
      },
      {
        "family": "Chen",
        "given": "Quan Ze"
      },
      {
        "family": "Knauss",
        "given": "Detlef"
      },
      {
        "family": "Zhang",
        "given": "Amy X."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online social platforms centered around content creators often allow comments on content, where creators can then moderate the comments they receive. As creators can face overwhelming numbers of comments, with some of them harassing or hateful, platforms typically provide tools such as word filters for creators to automate aspects of moderation. From needfinding interviews with 19 creators about how they use existing tools, we found that they struggled with writing good filters as well as organizing and revising their filters, due to the difficulty of determining what the filters actually catch. To address these issues, we present FilterBuddy, a system that supports creators in authoring new filters or building from pre-made ones, as well as organizing their filters and visualizing what comments are captured by them over time. We conducted an early-stage evaluation of FilterBuddy with YouTube creators, finding that participants see FilterBuddy not just as a moderation tool, but also a means to organize their comments to better understand their audiences.",
    "call-number": "10.1145/3491102.3517505",
    "collection-number": "205",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517505",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "human-computer integration, FilterBuddy, content moderation, platform governance, content creators, online harassment, YouTube",
    "number": "Article 205",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing Word Filter Tools for Creator-led Comment Moderation",
    "URL": "https://doi.org/10.1145/3491102.3517505"
  },
  {
    "id": "10.1145/3491102.3501822",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Xunhui"
      },
      {
        "family": "Wang",
        "given": "Tao"
      },
      {
        "family": "Yu",
        "given": "Yue"
      },
      {
        "family": "Zeng",
        "given": "Qiubing"
      },
      {
        "family": "Li",
        "given": "Zhixing"
      },
      {
        "family": "Wang",
        "given": "Huaimin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While many forms of financial support are currently available, there are still many complaints about inadequate financing from software maintainers. In May 2019, GitHub, the world\u2019s most active social coding platform, launched the Sponsor mechanism as a step toward more deeply integrating open source development and financial support. This paper collects data on 8,028 maintainers, 13,555 sponsors, and 22,515 sponsorships and conducts a comprehensive analysis. We explore the relationship between the Sponsor mechanism and developers along four dimensions using a combination of qualitative and quantitative analysis, examining why developers participate, how the mechanism affects developer activity, who obtains more sponsorships, and what mechanism flaws developers have encountered in the process of using it. We find a long-tail effect in the act of sponsorship, with most maintainers\u2019 expectations remaining unmet, and sponsorship has only a short-term, slightly positive impact on development activity but is not sustainable. While sponsors participate in this mechanism mainly as a means of thanking the developers of OSS that they use, in practice, the social status of developers is the primary influence on the number of sponsorships. We find that both the Sponsor mechanism and open source donations have certain shortcomings and need further improvements to attract more participants.",
    "call-number": "10.1145/3491102.3501822",
    "collection-number": "206",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501822",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "donation, open source, GitHub, financial support, sponsor",
    "number": "Article 206",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Who, What, Why and How? Towards the Monetary Incentive in Crowd Collaboration: A Case Study of Github\u2019s Sponsor Mechanism",
    "URL": "https://doi.org/10.1145/3491102.3501822"
  },
  {
    "id": "10.1145/3491102.3517707",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Pang",
        "given": "Yuren"
      },
      {
        "family": "Reinecke",
        "given": "Katharina"
      },
      {
        "family": "Just",
        "given": "Ren\u00e9"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The HCI community has been advocating preregistration as a practice to improve the credibility of scientific research. However, it remains unclear how HCI researchers preregister studies and what preregistration users perceive as benefits and challenges. By systematically reviewing the past four CHI proceedings and surveying 11 researchers, we found that only 1.11% of papers presented preregistered studies, though both authors and reviewers of preregistered studies perceive it as beneficial. Our formative studies revealed key challenges ranging from a lack of detail about the study design, hindering comprehensibility, to inconsistencies between preregistrations and published papers. To explore ways for addressing these issues, we developed Ap\u00e9ritif, a research prototype that scaffolds the preregistration process and automatically generates analysis code and a methods description. In an evaluation with 17 HCI researchers, we found that Ap\u00e9ritif reduces the effort of preregistering a study, facilitates researchers\u2019 workflows, and promotes consistency between research artifacts.",
    "call-number": "10.1145/3491102.3517707",
    "collection-number": "207",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517707",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Data analysis, Experiment design, Reproducibility, Preregistration",
    "number": "Article 207",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Ap\u00e9ritif: Scaffolding Preregistrations to Automatically Generate Analysis Code and Methods Descriptions",
    "URL": "https://doi.org/10.1145/3491102.3517707"
  },
  {
    "id": "10.1145/3491102.3517459",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Pan",
        "given": "Lihang"
      },
      {
        "family": "Yu",
        "given": "Chun"
      },
      {
        "family": "Li",
        "given": "JiaHui"
      },
      {
        "family": "Huang",
        "given": "Tian"
      },
      {
        "family": "Bi",
        "given": "Xiaojun"
      },
      {
        "family": "Shi",
        "given": "Yuanchun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Using voice commands to automate smartphone tasks (e.g., making a video call) can effectively augment the interactivity of numerous mobile apps. However, creating voice command interfaces requires a tremendous amount of effort in labeling and compiling the graphical user interface (GUI) and the utterance data. In this paper, we propose AutoVCI, a novel approach to automatically generate voice command interface (VCI) from smartphone operation sequences. The generated voice command interface has two distinct features. First, it automatically maps a voice command to GUI operations and fills in parameters accordingly, leveraging the GUI data instead of corpus or hand-written rules. Second, it launches a complementary Q&A dialogue to confirm the intention in case of ambiguity. In addition, the generated voice command interface can learn and evolve from user interactions. It accumulates the history command understanding results to annotate the user\u2019s input and improve its semantic understanding ability. We implemented this approach on Android devices and conducted a two-phase user study with 16 and 67 participants in each phase. Experimental results of the study demonstrated the practical feasibility of AutoVCI.",
    "call-number": "10.1145/3491102.3517459",
    "collection-number": "208",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517459",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "operation sequence, interaction-centered nature language understanding, voice command interface, generation system",
    "number": "Article 208",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Automatically Generating and Improving Voice Command Interface from Operation Sequences on Smartphones",
    "URL": "https://doi.org/10.1145/3491102.3517459"
  },
  {
    "id": "10.1145/3491102.3501819",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chung",
        "given": "John Joon Young"
      },
      {
        "family": "Kim",
        "given": "Wooseok"
      },
      {
        "family": "Yoo",
        "given": "Kang Min"
      },
      {
        "family": "Lee",
        "given": "Hwaran"
      },
      {
        "family": "Adar",
        "given": "Eytan"
      },
      {
        "family": "Chang",
        "given": "Minsuk"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While advanced text generation algorithms (e.g., GPT-3) have enabled writers to co-create stories with an AI, guiding the narrative remains a challenge. Existing systems often leverage simple turn-taking between the writer and the AI in story development. However, writers remain unsupported in intuitively understanding the AI\u2019s actions or steering the iterative generation. We introduce TaleBrush, a generative story ideation tool that uses line sketching interactions with a GPT-based language model for control and sensemaking of a protagonist\u2019s fortune in co-created stories. Our empirical evaluation found our pipeline reliably controls story generation while maintaining the novelty of generated sentences. In a user study with 14 participants with diverse writing experiences, we found participants successfully leveraged sketching to iteratively explore and write stories according to their intentions about the character\u2019s fortune while taking inspiration from generated stories. We conclude with a reflection on how sketching interactions can facilitate the iterative human-AI co-creation process.",
    "call-number": "10.1145/3491102.3501819",
    "collection-number": "209",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501819",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sketching, creativity support tool, controlled generation, story writing, story generation",
    "number": "Article 209",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TaleBrush: Sketching Stories with Generative Pretrained Language Models",
    "URL": "https://doi.org/10.1145/3491102.3501819"
  },
  {
    "id": "10.1145/3491102.3502102",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "B\u00e4uerle",
        "given": "Alex"
      },
      {
        "family": "Cabrera",
        "given": "\u00c1ngel Alexander"
      },
      {
        "family": "Hohman",
        "given": "Fred"
      },
      {
        "family": "Maher",
        "given": "Megan"
      },
      {
        "family": "Koski",
        "given": "David"
      },
      {
        "family": "Suau",
        "given": "Xavier"
      },
      {
        "family": "Barik",
        "given": "Titus"
      },
      {
        "family": "Moritz",
        "given": "Dominik"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Interfaces for machine learning (ML), information and visualizations about models or data, can help practitioners build robust and responsible ML systems. Despite their benefits, recent studies of ML teams and our interviews with practitioners (n=9) showed that ML interfaces have limited adoption in practice. While existing ML interfaces are effective for specific tasks, they are not designed to be reused, explored, and shared by multiple stakeholders in cross-functional teams. To enable analysis and communication between different ML practitioners, we designed and implemented Symphony, a framework for composing interactive ML interfaces with task-specific, data-driven components that can be used across platforms such as computational notebooks and web dashboards. We developed Symphony through participatory design sessions with 10 teams (n=31), and discuss our findings from deploying Symphony to 3 production ML projects at Apple. Symphony helped ML practitioners discover previously unknown issues like data duplicates and blind spots in models while enabling them to share insights with other stakeholders.",
    "call-number": "10.1145/3491102.3502102",
    "collection-number": "210",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502102",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "visualization, Machine learning, documentation, computational notebooks, interactive programming, AI",
    "number": "Article 210",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Symphony: Composing Interactive Interfaces for Machine Learning",
    "URL": "https://doi.org/10.1145/3491102.3502102"
  },
  {
    "id": "10.1145/3491102.3517466",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yamanaka",
        "given": "Shota"
      },
      {
        "family": "Usuba",
        "given": "Hiroki"
      },
      {
        "family": "Miyashita",
        "given": "Homei"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The effective width method of Fitts\u2019 law can normalize speed-accuracy biases in 1D target pointing tasks. However, in graphical user interfaces, more meaningful target shapes are rectangular. To empirically determine the best way to normalize the subjective biases, we ran remote and crowdsourced user experiments with three speed-accuracy instructions. We propose to normalize the speed-accuracy biases by applying the effective sizes to existing Fitts\u2019 law formulations including width W and height H. We call this target-size adjustment the bivariate effective width method. We found that, overall, Accot and Zhai\u2019s weighted Euclidean model using the effective width and height independently showed the best fit to the data in which the three instruction conditions were mixed (i.e., the time data measured in all instructions were analyzed with a single regression expression). Our approach enables researchers to fairly compare two or more conditions (e.g., devices, input techniques, user groups) with the normalized throughputs.",
    "call-number": "10.1145/3491102.3517466",
    "collection-number": "211",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517466",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "crowdsourcing, Fitts\u2019 law, pointing, human motor performance, graphical user interface",
    "number": "Article 211",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Bivariate Effective Width Method to Improve the Normalization Capability for Subjective Speed-accuracy Biases in Rectangular-target Pointing",
    "URL": "https://doi.org/10.1145/3491102.3517466"
  },
  {
    "id": "10.1145/3491102.3517433",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Foley",
        "given": "Margaret Jean"
      },
      {
        "family": "Roy",
        "given": "Quentin"
      },
      {
        "family": "Huang",
        "given": "Da-Yuan"
      },
      {
        "family": "Li",
        "given": "Wei"
      },
      {
        "family": "Vogel",
        "given": "Daniel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We investigate performance characteristics when switching between four pointing methods: absolute touch, absolute pen, relative mouse, and relative trackpad. The established \u201csubtraction method\u201d protocol used in mode-switching studies is extended to test pairs of methods and accommodate switch direction, multiple baselines, and controlling relative cursor position. A first experiment examines method switching on and around the horizontal surface of a tablet. Results find switching between pen and touch is fastest, and switching between relative and absolute methods incurs additional time penalty. A second experiment expands the investigation to an emerging foldable all-screen laptop form factor where switching also occurs on an angled surface and along a smoothly curved hinge. Results find switching between trackpad and touch is fastest, with all switching times generally higher. Our work contributes missing empirical evidence for switching performance using modern input methods, and our results can inform interaction design for current and emerging device form factors.",
    "call-number": "10.1145/3491102.3517433",
    "collection-number": "212",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517433",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "input devices, foldable displays, mode switching",
    "number": "Article 212",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Switching Between Standard Pointing Methods with Current and Emerging Computer Form Factors",
    "URL": "https://doi.org/10.1145/3491102.3517433"
  },
  {
    "id": "10.1145/3491102.3517691",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zinck",
        "given": "Graeme"
      },
      {
        "family": "Vogel",
        "given": "Daniel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In voice-based interfaces, non-verbal features represent a simple and underutilized design space for hands-free, language-agnostic interactions. We evaluate the performance of three fundamental types of voice-based musical interactions: pitch, interval, and melody. These interactions involve singing or humming a sequence of one or more notes. A 21-person study evaluates the feasibility and enjoyability of these interactions. The top performing participants were able to perform all interactions reasonably quickly (<5s) with average error rates between 1.3% and 8.6% after training. Others improved with training but still had error rates as high as 46% for pitch and melody interactions. The majority of participants found all tasks enjoyable. Using these results, we propose design considerations for using singing interactions as well as potential use cases for both standard computers and augmented reality glasses.",
    "call-number": "10.1145/3491102.3517691",
    "collection-number": "213",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517691",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "music, non-verbal vocal interactions",
    "number": "Article 213",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Evaluating Singing for Computer Input Using Pitch, Interval, and Melody",
    "URL": "https://doi.org/10.1145/3491102.3517691"
  },
  {
    "id": "10.1145/3491102.3517473",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nowak",
        "given": "Oliver"
      },
      {
        "family": "Sch\u00e4fer",
        "given": "Ren\u00e9"
      },
      {
        "family": "Brocker",
        "given": "Anke"
      },
      {
        "family": "Wacker",
        "given": "Philipp"
      },
      {
        "family": "Borchers",
        "given": "Jan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Textile interfaces enable designers to integrate unobtrusive media and smart home controls into furniture such as sofas. While the technical aspects of such controllers have been the subject of numerous research projects, the physical form factor of these controls has received little attention so far. This work investigates how general design properties, such as overall slider shape, raised vs. recessed sliders, and number and layout of tick marks, affect users\u2019 preferences and performance. Our first user study identified a preference for certain design combinations, such as recessed, closed-shaped sliders. Our second user study included performance measurements on variations of the preferred designs from study\u00a01, and took a closer look at tick marks. Tick marks supported orientation better than slider shape. Sliders with at least three tick marks were preferred, and performed well. Non-uniform, equally distributed tick marks reduced the movements users needed to orient themselves on the slider.",
    "call-number": "10.1145/3491102.3517473",
    "collection-number": "214",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517473",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Design recommendations, Continuous input, Sliders, Non-wearables, Textile interfaces, Eyes-free interaction, Embroidery, Smart textiles",
    "number": "Article 214",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Shaping Textile Sliders: An Evaluation of Form Factors and Tick Marks for Textile Sliders",
    "URL": "https://doi.org/10.1145/3491102.3517473"
  },
  {
    "id": "10.1145/3491102.3501863",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Alotaibi",
        "given": "Yosuef"
      },
      {
        "family": "Williamson",
        "given": "John H"
      },
      {
        "family": "Brewster",
        "given": "Stephen Anthony"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Electrotactile stimulation is a novel form of haptic feedback. There is little work investigating its basic design parameters and how they create effective tactile cues. This paper describes two experiments that extend our knowledge of two key parameters. The first investigated the combination of pulse width and amplitude (Intensity) on sensations of urgency, annoyance, valence and arousal. Results showed significant effects: increasing Intensity caused higher ratings of urgency, annoyance and arousal but reduced valence. We established clear levels for differentiating each sensation. A second study then investigated Intensity and Pulse Frequency to find out how many distinguishable levels could be perceived. Results showed that both Intensity and Pulse Frequency significantly affected perception, with four distinguishable levels of Intensity and two of Pulse Frequency. These results add significant new knowledge about the parameter space of electrotactile cue design and help designers select suitable properties to use when creating electrotactile cues.",
    "call-number": "10.1145/3491102.3501863",
    "collection-number": "215",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501863",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "pulse frequency, interaction design, intensity, Electrotactile feedback",
    "number": "Article 215",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "First Steps Towards Designing Electrotactons: Investigating Intensity and Pulse Frequency as Parameters for Electrotactile Cues",
    "URL": "https://doi.org/10.1145/3491102.3501863"
  },
  {
    "id": "10.1145/3491102.3517501",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chin Derix",
        "given": "Eleanor"
      },
      {
        "family": "Wah Leong",
        "given": "Tuck"
      },
      {
        "family": "Prior",
        "given": "Julia"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Research reveals that managing mobile device use during family time can be a source of stress for parents. In particular, it can create conflict in their relationships. As such, there is a need to understand how these problematic experiences might be addressed by new approaches to technology design. This paper presents a study in which 14 parents were prompted to reflect on how their experiences and relationships could be improved by four design proposals. These proposals resulted from ideation workshops involving 12 professional designers, and were presented as scenario-based storyboards during interviews. Our interviews revealed three design approaches that appealed to parents. We describe seven benefits that parents imagined these approaches would have, and discuss ways in which they should be further explored. Thus, we contribute to a more complete understanding of how technology design might better support parents\u2019 aspirations for how devices are used within the family.",
    "call-number": "10.1145/3491102.3517501",
    "collection-number": "216",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517501",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Experiences, Parents, Parental Mediation, Family Technology Use, Mobile Devices",
    "number": "Article 216",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt's A Drag\u201d: Exploring How to Improve Parents\u2019 Experiences of Managing Mobile Device Use During Family Time",
    "URL": "https://doi.org/10.1145/3491102.3517501"
  },
  {
    "id": "10.1145/3491102.3502130",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Theofanopoulou",
        "given": "Nikki"
      },
      {
        "family": "Slovak",
        "given": "Petr"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Emotion-related parent-child interactions during early childhood play a crucial role in the development of emotion regulation, a fundamental life skill central to well-being. However, limited work in HCI has explored how technology could support parents in adopting supportive emotion socialisation practices. In this paper, we explore how an embodied, in-situ intervention in the form of a smart toy can impact emotion-related parent-child interactions in the home. We draw on (1) interviews with 29 parents of young children who had the smart toy for at least 1 month; (2) co-design workshops with 12 parents and 8 parenting course facilitators. We discuss how the smart toy impacted parent-child interactions around emotions for a subset of families, and draw on workshop data to explore how this could be designed for directly. Finally, we propose a set of design directions for technology-enabled systems aiming to elicit and scaffold specific parent-child interactions over time.",
    "call-number": "10.1145/3491102.3502130",
    "collection-number": "217",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502130",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "parent-child interaction, tangible interaction, emotion regulation, emotion socialisation, user-centred design",
    "number": "Article 217",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Technology-Mediated Parental Socialisation of Emotion: Leveraging an Embodied, In-situ Intervention for Child Emotion Regulation",
    "URL": "https://doi.org/10.1145/3491102.3502130"
  },
  {
    "id": "10.1145/3491102.3517479",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Zheng"
      },
      {
        "family": "Xu",
        "given": "Ying"
      },
      {
        "family": "Wang",
        "given": "Yanhao"
      },
      {
        "family": "Yao",
        "given": "Bingsheng"
      },
      {
        "family": "Ritchie",
        "given": "Daniel"
      },
      {
        "family": "Wu",
        "given": "Tongshuang"
      },
      {
        "family": "Yu",
        "given": "Mo"
      },
      {
        "family": "Wang",
        "given": "Dakuo"
      },
      {
        "family": "Li",
        "given": "Toby Jia-Jun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Despite its benefits for children\u2019s skill development and parent-child bonding, many parents do not often engage in interactive storytelling by having story-related dialogues with their child due to limited availability or challenges in coming up with appropriate questions. While recent advances made AI generation of questions from stories possible, the fully-automated approach excludes parent involvement, disregards educational goals, and underoptimizes for child engagement. Informed by need-finding interviews and participatory design (PD) results, we developed StoryBuddy, an AI-enabled system for parents to create interactive storytelling experiences. StoryBuddy\u2019s design highlighted the need for accommodating dynamic user needs between the desire for parent involvement and parent-child bonding and the goal of minimizing parent intervention when busy. The PD revealed varied assessment and educational goals of parents, which StoryBuddy addressed by supporting configuring question types and tracking child progress. A user study validated StoryBuddy\u2019s usability and suggested design insights for future parent-AI collaboration systems.",
    "call-number": "10.1145/3491102.3517479",
    "collection-number": "218",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517479",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "interactive storytelling, dialogic reading, voice user interfaces, child-agent interactions, co-reading, human-AI collaboration",
    "number": "Article 218",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with Flexible Parental Involvement",
    "URL": "https://doi.org/10.1145/3491102.3517479"
  },
  {
    "id": "10.1145/3491102.3501922",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ppali",
        "given": "Sophia"
      },
      {
        "family": "Lalioti",
        "given": "Vali"
      },
      {
        "family": "Branch",
        "given": "Boyd"
      },
      {
        "family": "Ang",
        "given": "Chee Siang"
      },
      {
        "family": "Thomas",
        "given": "Andrew J."
      },
      {
        "family": "Wohl",
        "given": "Bea S."
      },
      {
        "family": "Covaci",
        "given": "Alexandra"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The acoustic and visual experiences of musicians in the spaces they perform in are complex and organic in nature, entailing a continuous interaction with the environment. With this project, we leverage the power of Virtual Reality (VR) to support musicians in their creative practice by transporting them to novel sonic and visual worlds. For this, we developed a musician-centred VR system, featuring various acoustic and visual virtual environments, VR Rehearse & Perform, based on design requirements gathered with musicians and performance experts. To investigate how VR can be designed to support music-makers in their creative musical practice, we performed iterative tests with 19 musicians followed by semi-structured interviews. Our findings suggest that VR has the potential to support different aspects of the creative musical practice, such as rehearsing, performing and improvising. Our research provides insights and inspirations toward designing musician-centred VR experiences for various musical activities.",
    "call-number": "10.1145/3491102.3501922",
    "collection-number": "220",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501922",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Reality, Musical practice, Creativity, Performing, Improvisation, Rehearsing, Music",
    "number": "Article 220",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Keep the VRhythm going: A musician-centred study investigating how Virtual Reality can support creative musical practice",
    "URL": "https://doi.org/10.1145/3491102.3501922"
  },
  {
    "id": "10.1145/3491102.3517626",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mice",
        "given": "Lia"
      },
      {
        "family": "McPherson",
        "given": "Andrew P."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Digital interfaces are shrinking, driven by pressures of mass production and consumer culture, and often accompanied by a discourse of control, precision or convenience. Meanwhile, human bodies remain the same size, and the changing size of interfaces has implications for the formation of user identities. Drawing on embodied cognition, effort and entanglement theories of HCI, we explored the impact of interface size on the co-constitution of humans and technology. We designed an oversized digital musical instrument and invited musicians to use the instrument to create original performances. We found that both the performances and the musicians\u2019 self-perception were influenced by the large size of the instrument, shining new light on the ways in which designing technology is designing humans and in turn culture.",
    "call-number": "10.1145/3491102.3517626",
    "collection-number": "221",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517626",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "interface design, interaction, effort, digital musical instrument, size, entanglement, embodiment",
    "number": "Article 221",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Super Size Me: Interface Size, Identity and Embodiment in Digital Musical Instrument Design",
    "URL": "https://doi.org/10.1145/3491102.3517626"
  },
  {
    "id": "10.1145/3491102.3517695",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Lotus"
      },
      {
        "family": "Shao",
        "given": "Jingyao"
      },
      {
        "family": "Liu",
        "given": "Augustina Ao"
      },
      {
        "family": "Jiang",
        "given": "Lucy"
      },
      {
        "family": "Stangl",
        "given": "Abigale"
      },
      {
        "family": "Fourney",
        "given": "Adam"
      },
      {
        "family": "Morris",
        "given": "Meredith Ringel"
      },
      {
        "family": "Findlater",
        "given": "Leah"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Auditory interfaces increasingly support access to website content, through recent advances in voice interaction. Typically, however, these interfaces provide only limited audio styling, collapsing rich visual design into a static audio output style with a single synthesized voice. To explore the potential for more aesthetic and intuitive sound design for websites, we prompted 14 professional sound designers to create auditory website mockups and interviewed them about their designs and rationale. Our findings reveal their prioritized design considerations (aesthetics and emotion, user engagement, audio clarity, information dynamics, and interactivity), specific sound design ideas to support each consideration (e.g., replacing spoken labels with short, memorable audio expressions), and challenges with applying sound design practices to auditory websites. These findings provide promising direction for how to support designers in creating richer auditory website experiences.",
    "call-number": "10.1145/3491102.3517695",
    "collection-number": "222",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517695",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "voice interaction, interaction design, audio display",
    "number": "Article 222",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Interactive Sound Design for Auditory Websites",
    "URL": "https://doi.org/10.1145/3491102.3517695"
  },
  {
    "id": "10.1145/3491102.3517448",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Walton",
        "given": "Elizabeth"
      },
      {
        "family": "Mackay",
        "given": "Wendy E."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Most current dance support technologies focus on dancers, teachers or choreographers who are engaged in a single activity. We are interested in creating tools that support professional dancers over longer periods of time, as their careers and personal practices evolve. We interviewed 12 professional and pre-professional dancers about a critical moment in their careers: the transition to a new dance style due to shifting interests, ageing or injury. We identify three key challenges\u2014overcoming habits, learning new forms of movement, transitioning over time\u2014and their strategies for addressing them. We argue that successful tools must help dancers change their mentality about new movement styles, rather than focusing solely on movement mechanics. We suggest three possible implications for design: develop \u201cmovement substrates\u201d that handle multiple movement representations; integrate learning and reflection in a single session; and create movement definitions through movement. We conclude with a discussion of directions for future research.",
    "call-number": "10.1145/3491102.3517448",
    "collection-number": "223",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517448",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Movement Support Tools, Transitions, Dance",
    "number": "Article 223",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Dance Transitions: What Forms of Technology Best Support Professional Dancers as They Learn New Movement Styles?",
    "URL": "https://doi.org/10.1145/3491102.3517448"
  },
  {
    "id": "10.1145/3491102.3517556",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Michaelis",
        "given": "Joseph E"
      },
      {
        "family": "Di Canio",
        "given": "Daniela"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this paper, we explore how the physically embodied nature of robots can influence learning through non-verbal communication, such as gesturing. We take an embodied cognition perspective to examine student interactions with a NAO robot that uses gestures while reasoning about geometry conjectures. College aged students (N = 30) were randomly assigned to either a dynamic condition, where the robot uses dynamic gestures that represent and manipulate geometric shapes in the conjectures, or control condition, where the robot uses beat gestures that match the rhythm of speech. Students in the dynamic condition: (1) use more gestures when they reason about geometry conjectures, (2) look more at the robot as it speaks, (3) feel the robot is a better study partner and uses effective gestures, but (4) were not more successful in correctly reasoning about geometry conjectures. We discuss implications for socially supported and embodied learning with a physically present robot.",
    "call-number": "10.1145/3491102.3517556",
    "collection-number": "224",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517556",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "gesture, human-robot interaction, embodied cognition, mathematics learning",
    "number": "Article 224",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Embodied Geometric Reasoning with a Robot: The Impact of Robot Gestures on Student Reasoning about Geometrical Conjectures",
    "URL": "https://doi.org/10.1145/3491102.3517556"
  },
  {
    "id": "10.1145/3491102.3502031",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Druga",
        "given": "Stefania"
      },
      {
        "family": "Christoph",
        "given": "Fee Lia"
      },
      {
        "family": "Ko",
        "given": "Amy J"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Many families engage daily with artificial intelligence (AI) applications, from conversations with a voice assistant to mobile navigation searches. While there are known ways for youth to learn about AI, we do not yet understand how to engage parents in this process. To explore parents\u2019 roles in helping their children develop AI literacies, we designed 11 learning activities organized into four topics: image classification, object recognition, interaction with voice assistants, and unplugged AI co-design. We conducted a 5-week online in-home study with 18 children (5 to 11 years old) and 16 parents. We identify parents\u2019 most common roles in supporting their children and consider the benefits of parent-child partnerships when learning AI literacies. Finally, we discuss how our different activities supported parents\u2019 roles and present design recommendations for future family-centered AI literacies resources.",
    "call-number": "10.1145/3491102.3502031",
    "collection-number": "225",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502031",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 225",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Family as a Third Space for AI Literacies: How do children and parents learn about AI together?",
    "URL": "https://doi.org/10.1145/3491102.3502031"
  },
  {
    "id": "10.1145/3491102.3502091",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Long",
        "given": "Duri"
      },
      {
        "family": "Teachey",
        "given": "Anthony"
      },
      {
        "family": "Magerko",
        "given": "Brian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The unique role that AI plays in making decisions that affect human lives creates a need to foster improved public understanding of AI systems. Informal learning spaces are particularly important contexts for fostering AI literacy, as they have the potential to reach a broader audience and provide spaces for children and parents to learn together. This paper explores 1) what types of dialogue family groups engage in when learning about AI in an at-home learning environment in order to inform our understanding of 2) how to design AI literacy activities for informal learning contexts. We present an analysis of family group dialogue surrounding three different AI education activities and use our findings to reflect on, update, and add to existing principles for designing AI literacy educational interventions.",
    "call-number": "10.1145/3491102.3502091",
    "collection-number": "226",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502091",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "embodied, collaborative, learning talk, informal learning, family learning, AI literacy, AI education",
    "number": "Article 226",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Family Learning Talk in AI Literacy Learning Activities",
    "URL": "https://doi.org/10.1145/3491102.3502091"
  },
  {
    "id": "10.1145/3491102.3517740",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wambsganss",
        "given": "Thiemo"
      },
      {
        "family": "Soellner",
        "given": "Matthias"
      },
      {
        "family": "Koedinger",
        "given": "Kenneth R"
      },
      {
        "family": "Leimeister",
        "given": "Jan Marco"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Advances in Natural Language Processing offer techniques to detect the empathy level in texts. To test if individual feedback on certain students\u2019 empathy level in their peer review writing process will help them to write more empathic reviews, we developed ELEA, an adaptive writing support system that provides students with feedback on the cognitive and emotional empathy structures. We compared ELEA to a proven empathy support tool in a peer review setting with 119 students. We found students using ELEA wrote more empathic peer reviews with a higher level of emotional empathy compared to the control group. The high perceived skill learning, the technology acceptance, and the level of enjoyment provide promising results to use such an approach as a feedback application in traditional learning settings. Our results indicate that learning applications based on NLP are able to foster empathic writing skills of students in peer review scenarios.",
    "call-number": "10.1145/3491102.3517740",
    "collection-number": "227",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517740",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Automated Feedback, Writing Support Systems, Empathy Learning, Educational Applications",
    "number": "Article 227",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Adaptive Empathy Learning Support in Peer Review Scenarios",
    "URL": "https://doi.org/10.1145/3491102.3517740"
  },
  {
    "id": "10.1145/3491102.3502124",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cheng",
        "given": "Ruijia"
      },
      {
        "family": "Dasgupta",
        "given": "Sayamindu"
      },
      {
        "family": "Hill",
        "given": "Benjamin Mako"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Through a mixed-method analysis of data from Scratch, we examine how novices learn to program with simple data structures by using community-produced learning resources. First, we present a qualitative study that describes how community-produced learning resources create archetypes that shape exploration and may disadvantage some with less common interests. In a second quantitative study, we find broad support for this dynamic in several hypothesis tests. Our findings identify a social feedback loop that we argue could limit sources of inspiration, pose barriers to broadening participation, and confine learners\u2019 understanding of general concepts. We conclude by suggesting several approaches that may mitigate these dynamics.",
    "call-number": "10.1145/3491102.3502124",
    "collection-number": "228",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502124",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "connected learning, computational participation, computers and children, learning to code, Scratch, informal learning, creativity support tools, online communities, forums, social computing and social navigation",
    "number": "Article 228",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How Interest-Driven Content Creation Shapes Opportunities for Informal Learning in Scratch: A Case Study on Novices\u2019 Use of Data Structures",
    "URL": "https://doi.org/10.1145/3491102.3502124"
  },
  {
    "id": "10.1145/3491102.3501917",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Choi",
        "given": "Kabdo"
      },
      {
        "family": "Shin",
        "given": "Hyungyu"
      },
      {
        "family": "Xia",
        "given": "Meng"
      },
      {
        "family": "Kim",
        "given": "Juho"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Designing solution plans before writing code is critical for successful algorithmic problem-solving. Novices, however, often plan on-the-fly during implementation, resulting in unsuccessful problem-solving due to lack of mental organization of the solution. Research shows that subgoal learning helps learners develop more complete solution plans by enhancing their understanding of the high-level solution structure. However, expert-created materials such as subgoal labels are necessary to provide learning benefits from subgoal learning, which are a scarce resource in self-learning due to limited availability and high cost. We propose a learnersourcing workflow that collects high-quality subgoal labels from learners by helping them improve their label quality. We implemented the workflow into AlgoSolve, a prototype interface that supports subgoal learning for algorithmic problems. A between-subjects study with 63 problem-solving novices revealed that AlgoSolve helped learners create higher-quality labels and more complete solution plans, compared to a baseline method known to be effective in subgoal learning.",
    "call-number": "10.1145/3491102.3501917",
    "collection-number": "229",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501917",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Subgoal learning, Algorithmic problem-solving, Learnersourcing",
    "number": "Article 229",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AlgoSolve: Supporting Subgoal Learning in Algorithmic Problem-Solving with Learnersourced Microtasks",
    "URL": "https://doi.org/10.1145/3491102.3501917"
  },
  {
    "id": "10.1145/3491102.3502021",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Horn",
        "given": "Mike"
      },
      {
        "family": "Banerjee",
        "given": "Amartya"
      },
      {
        "family": "Brucker",
        "given": "Matthew"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper describes the design of an online learning platform that empowers musical creation and performance with Python code. For this platform we have developed an innovative computational notebook paradigm that we call TunePad playbooks. While playbooks borrow ideas from popular computational notebooks like Jupyter, we have designed them from the ground up to support creative musical expression including live performances. After discussing our design principles and features, we share findings from a series of artifact-centered interviews conducted with experienced TunePad users. Our results show how systems like ours might flexibly support a variety of creative workflows, while suggesting opportunities for future work in this area.",
    "call-number": "10.1145/3491102.3502021",
    "collection-number": "230",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502021",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design, computational notebooks, playbooks, Computational literacy, music",
    "number": "Article 230",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TunePad Playbooks: Designing Computational Notebooks for Creative Music Coding",
    "URL": "https://doi.org/10.1145/3491102.3502021"
  },
  {
    "id": "10.1145/3491102.3501820",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Malysheva",
        "given": "Yana"
      },
      {
        "family": "Kelleher",
        "given": "Caitlin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Undergraduate Teaching Assistants(TAs) in Computer Science courses are often the first and only point of contact when a student gets stuck on a programming problem. But these TAs are often relative beginners themselves, both in programming and in teaching. In this paper, we examine the impact of availability of corrected code on TAs\u2019 ability to find, fix, and address bugs in student code. We found that seeing a corrected version of the student code helps TAs debug code 29% faster, and write more accurate and complete student-facing explanations of the bugs (30% more likely to correctly address a given bug). We also observed that TAs do not generally struggle with the conceptual understanding of the underlying material. Rather, their difficulties seem more related to issues with working memory, attention, and overall high cognitive load.",
    "call-number": "10.1145/3491102.3501820",
    "collection-number": "231",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501820",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 231",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Assisting Teaching Assistants with Automatic Code Corrections",
    "URL": "https://doi.org/10.1145/3491102.3501820"
  },
  {
    "id": "10.1145/3491102.3501997",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Xu",
        "given": "Kefan"
      },
      {
        "family": "Yan",
        "given": "Xinghui"
      },
      {
        "family": "Newman",
        "given": "Mark W"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Making and executing physical activity plans can help people improve their physical activity levels. However, little is known about how people make physical activity plans in everyday settings and how people can be assisted in creating more successful plans. In this paper, we developed and deployed a mobile app as a probe to investigate the in-the-wild physical activity planning experience for 28 days with 17 participants. Additionally, we explored the impact of presenting successful and unsuccessful planning records on participants\u2019 planning behaviors. Based on interviews before, during, and after the deployment, we offer a description of what factors participants considered to fit their exercise plans into their existing routines, as well as factors leading to plan failures and dissatisfaction with planned physical activity. With access to historical records, participants derived insights to improve their plans, including trends in successes and failures. Based on those findings, we discuss the implications for better supporting people to make and execute physical activity plans, including suggestions for incorporating historical records into planning tools.",
    "call-number": "10.1145/3491102.3501997",
    "collection-number": "232",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501997",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Planning, Qualitative Research, Personal Informatics, Physical Activity, Mobile Health, Self-reflection",
    "number": "Article 232",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding People\u2019s Experience for Physical Activity Planning and Exploring the Impact of Historical Records on Plan Creation and Execution",
    "URL": "https://doi.org/10.1145/3491102.3501997"
  },
  {
    "id": "10.1145/3491102.3502039",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nadal",
        "given": "Camille"
      },
      {
        "family": "McCully",
        "given": "Shane"
      },
      {
        "family": "Doherty",
        "given": "Kevin"
      },
      {
        "family": "Sas",
        "given": "Corina"
      },
      {
        "family": "Doherty",
        "given": "Gavin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "User acceptance is key for the successful uptake and use of health technologies, but also impacted by numerous factors not always easily accessible nor operationalised by designers in practice. This work seeks to facilitate the application of acceptance theory in design practice through the Technology Acceptance (TAC) toolkit: a novel theory-based design tool and method comprising 16 cards, 3 personas, 3 scenarios, a virtual think-space, and a website, which we evaluated through workshops conducted with 21 designers of health technologies. Findings showed that the toolkit revised and extended designers\u2019 knowledge of technology acceptance, fostered their appreciation, empathy and ethical values while designing for acceptance, and contributed towards shaping their future design practice. We discuss implications for considering user acceptance a dynamic, multi-stage process in design practice, and better supporting designers in imagining distant acceptance challenges. Finally, we examine the generative value of the TAC toolkit and its possible future evolution.",
    "call-number": "10.1145/3491102.3502039",
    "collection-number": "233",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502039",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "technology acceptance, user-centered design, design cards, technology acceptance lifecycle, macro-temporal perspective",
    "number": "Article 233",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The TAC Toolkit: Supporting Design for User Acceptance of Health Technologies from a Macro-Temporal Perspective",
    "URL": "https://doi.org/10.1145/3491102.3502039"
  },
  {
    "id": "10.1145/3491102.3517535",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shin",
        "given": "Ji Youn"
      },
      {
        "family": "Peng",
        "given": "Wei"
      },
      {
        "family": "Lee",
        "given": "Hee Rin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sleep is a vital health issue. Continued sleep deficiency can increase the chance of stroke, cardiovascular disease, obesity, and diabetes. Previous studies have investigated sleep as an individual activity performed within bedrooms at night. In this study with twenty parents of young children, we identify sleep as a complex experience entangled with social dynamics between family members. For example, children's sleep means not just time for children to rest, but time for self-care for parents. This paper's contributions are twofold. First, we show how the boundaries that define sleep in terms of time (at night), space (in bedrooms), and unit of analysis (individual-focused) limit designers' opportunities to tackle the deeper sleep issues of families. Second, we suggest \"division of labor\" as an important but rarely discussed design concept to enhance family sleep, and as a design theme for home technologies that address issues emerging from social dynamics between householders.",
    "call-number": "10.1145/3491102.3517535",
    "collection-number": "234",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517535",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 234",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "More than Bedtime and the Bedroom: Sleep Management as a Collaborative Work for the Family",
    "URL": "https://doi.org/10.1145/3491102.3517535"
  },
  {
    "id": "10.1145/3491102.3502493",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Barry",
        "given": "Colin"
      },
      {
        "family": "de Souza",
        "given": "Jessica"
      },
      {
        "family": "Xuan",
        "given": "Yinan"
      },
      {
        "family": "Holden",
        "given": "Jason"
      },
      {
        "family": "Granholm",
        "given": "Eric"
      },
      {
        "family": "Wang",
        "given": "Edward Jay"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With recent developments in medical and psychiatric research surrounding pupillary response, cheap and accessible pupillometers could enable medical benefits from early neurological disease detection to measurements of cognitive load. In this paper, we introduce a novel smartphone-based pupillometer to allow for future development in clinical research surrounding at-home pupil measurements. Our solution utilizes a NIR front-facing camera for facial recognition paired with the RGB selfie camera to perform tracking of absolute pupil dilation with sub-millimeter accuracy. In comparison to a gold standard pupillometer during a pupillary light reflex test, the smartphone-based system achieves a median MAE of 0.27mm for absolute pupil dilation tracking and a median error of 3.52% for pupil dilation change tracking. Additionally, we remotely deployed the system to older adults as part of a usability study that demonstrates promise for future smartphone deployments to remotely collect data in older, inexperienced adult users operating the system themselves.",
    "call-number": "10.1145/3491102.3502493",
    "collection-number": "235",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502493",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 235",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "At-Home Pupillometry using Smartphone Facial Identification Cameras",
    "URL": "https://doi.org/10.1145/3491102.3502493"
  },
  {
    "id": "10.1145/3491102.3517600",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Das",
        "given": "Dipto"
      },
      {
        "family": "Semaan",
        "given": "Bryan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While people\u2019s identities can be marginalized through various forces, colonialism is one of the primary ways that continues to influence people\u2019s lives and identities. Colonialism refers to the policies and practices where foreign powers migrate to other lands and alter the social structures, and thus identities, of local populations. What is less understood is how online spaces can support people in the aftermath of colonization in revising, repairing, and strengthening their identities\u2014the process of identity decolonization work. Using trace ethnography beginning on 15 May, 2020 and ending on 15 July, 2020 and drawing on Poka Laenui\u2019s framework of decolonization, we explore how South Asian Bengalis on the platform Bengali Quora (BnQuora) engage in collaborative identity decolonization work to reclaim narrative agency. We discuss how narratives serve to help people bounce back from threat or vulnerability\u2014a concept we dub narrative resilience. We also describe potential implications for future scholarship focused on decolonization that extends multiple ongoing conversations around ICT for development, social justice, decolonial HCI, and identity research within the CHI community.",
    "call-number": "10.1145/3491102.3517600",
    "collection-number": "236",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517600",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Bengali Quora, Identity, Colonial, Bengali, Decolonization",
    "number": "Article 236",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Collaborative Identity Decolonization as Reclaiming Narrative Agency: Identity Work of Bengali Communities on Quora",
    "URL": "https://doi.org/10.1145/3491102.3517600"
  },
  {
    "id": "10.1145/3491102.3517611",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Morrissey",
        "given": "Kellie"
      },
      {
        "family": "Peelo",
        "given": "Doireann"
      },
      {
        "family": "Warren",
        "given": "Steve"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent HCI research has suggested a move from individualistic models of digital care and wellbeing to considering the family unit as a locus of support in this area; however, little work has examined the complex, granular everyday experience of such relationships, and the role of gender, class, and care is underexplored. This study focuses on women's familial relationships through interviews with 6 Irish women about their relationships with their mothers, as well as ways in which they maintain the care of themselves and others within these relationships. Our thematic analysis of this data generated four themes: self-other care, leaky boundaries, changes over the lifecourse, and space and conflict \u2013 from which we ideated a series of design concepts, six of which are presented here with critiques from our participants. From this exploratory work, we delineate four directions for future HCI research into women's close relationships.",
    "call-number": "10.1145/3491102.3517611",
    "collection-number": "237",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517611",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "gender, Digital care, family relationships, wellbeing",
    "number": "Article 237",
    "number-of-pages": "26",
    "page": "1\u201326",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "'She's Just My Life': Digital Design to Support Women's Self-Other Care in Relationships with their Mothers",
    "URL": "https://doi.org/10.1145/3491102.3517611"
  },
  {
    "id": "10.1145/3491102.3502071",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mim",
        "given": "Nusrat Jahan"
      },
      {
        "family": "Nandi",
        "given": "Dipannita"
      },
      {
        "family": "Khan",
        "given": "Sadaf Sumyia"
      },
      {
        "family": "Dey",
        "given": "Arundhuti"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper critically examines the impacts of social media-based business on urban residential architecture in Dhaka, Bangladesh and joins the growing body of work in critical HCI. Based on a seven-month-long qualitative empirical study in Dhaka, this paper reports how Facebook commerce (F-commerce) drives many local women to actively engage in home-based businesses, which in turn, challenges the inherent spatial regulations of modern residential architecture. This paper also documents how F-commerce mediated transformations in residential spaces are promoting heterogeneous functions, re-surfacing traditional values, and altering orders and rationales that define modern housing. Drawing from a rich body of literature in urban housing architecture, critical theories around modernism, South-Asian feminism, and postcolonial computing, we explain how these spatial transformations and alterations are \u201cappropriating\u201d architectural design vocabularies. Our findings further explain how negligence toward such emerging needs often marginalizes the women spatially and economically, who are involved in F-commerce. We conclude with design implications to architecture and HCI to address these issues, and connect our findings to the broader agendas of Postcolonial HCI around diversity, inclusion, and global development.",
    "call-number": "10.1145/3491102.3502071",
    "collection-number": "238",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502071",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Urban Modernity, Global South, Postcolonial HCI, Facebook Commerce, Housing Architecture",
    "number": "Article 238",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "F-commerce and Urban Modernities: The Changing Terrain of Housing Design in Bangladesh",
    "URL": "https://doi.org/10.1145/3491102.3502071"
  },
  {
    "id": "10.1145/3491102.3517608",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Musgrave",
        "given": "Tyler"
      },
      {
        "family": "Cummings",
        "given": "Alia"
      },
      {
        "family": "Schoenebeck",
        "given": "Sarita"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This project illuminates Black women and femme\u2019s experiences with unwanted behavior and harassment on social media, and how they (re)claim and transform their experiences to cope, heal, and experience joy. This work situates Black women and femmes\u2019 experiences within extant social media research, and examines how their unique identity creates multiple forms of interlocking oppression. In our focus groups, participants (N=49) described harms they experienced through racism, misogynoir, ableism, and sexual objectification, and their complex labor of protecting and transforming their experiences online. Despite the harmful effects of unwanted behavior online, participants described a Black feminist transformative politic, in which they cultivated healing and joy through various methods offline and online. Using a transformative justice lens, we discuss their experiences of harassment from white women and men, as well as the complexities of cultural betrayal when experiencing harassment from Black men.",
    "call-number": "10.1145/3491102.3517608",
    "collection-number": "240",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517608",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Online harassment, misogynoir, joy, gender, racism, Black women, justice, healing",
    "number": "Article 240",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Experiences of Harm, Healing, and Joy among Black Women and Femmes on Social Media",
    "URL": "https://doi.org/10.1145/3491102.3517608"
  },
  {
    "id": "10.1145/3491102.3517717",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Heuer",
        "given": "Hendrik"
      },
      {
        "family": "Glassman",
        "given": "Elena Leah"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "During the COVID-19 pandemic, the World Health Organization provided a checklist to help people distinguish between accurate and misinformation. In controlled experiments in the United States and Germany, we investigated the utility of this ordered checklist and designed an interactive version to lower the cost of acting on checklist items. Across interventions, we observe non-trivial differences in participants\u2019 performance in distinguishing accurate and misinformation between the two countries and discuss some possible reasons that may predict the future helpfulness of the checklist in different environments. The checklist item that provides source labels was most frequently followed and was considered most helpful. Based on our empirical findings, we recommend practitioners focus on providing source labels rather than interventions that support readers performing their own fact-checks, even though this recommendation may be influenced by the WHO\u2019s chosen order. We discuss the complexity of providing such source labels and provide design recommendations.",
    "call-number": "10.1145/3491102.3517717",
    "collection-number": "241",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517717",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Disinformation, Propaganda, Misinformation, Fake News, Fact-check, World Health Organization, COVID-19, Social Media",
    "number": "Article 241",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist",
    "URL": "https://doi.org/10.1145/3491102.3517717"
  },
  {
    "id": "10.1145/3491102.3517517",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Goyal",
        "given": "Nitesh"
      },
      {
        "family": "Park",
        "given": "Leslie"
      },
      {
        "family": "Vasserman",
        "given": "Lucy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online harassment is a major societal challenge that impacts multiple communities. Some members of community, like female journalists and activists, bear significantly higher impacts since their profession requires easy accessibility, transparency about their identity, and involves highlighting stories of injustice. Through a multi-phased qualitative research study involving a focus group and interviews with 27 female journalists and activists, we mapped the journey of a target who goes through harassment. We introduce PMCR framework, as a way to focus on needs for Prevention, Monitoring, Crisis and Recovery. We focused on Crisis and Recovery, and designed a tool to satisfy a target\u2019s needs related to documenting evidence of harassment during the crisis and creating reports that could be shared with support networks for recovery. Finally, we discuss users\u2019 feedback to this tool, highlighting needs for targets as they face the burden and offer recommendations to future designers and scholars on how to develop tools that can help targets manage their harassment.",
    "call-number": "10.1145/3491102.3517517",
    "collection-number": "242",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517517",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Harassment, Solidarity, Feminism, PMCR, Sensemaking, Journalist, Activist, Managing Online Harassment, Gendered Harassment, Perspective API, Online Harassment, Social Media",
    "number": "Article 242",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dYou have to prove the threat is real\u201d: Understanding the needs of Female Journalists and Activists to Document and Report Online Harassment",
    "URL": "https://doi.org/10.1145/3491102.3517517"
  },
  {
    "id": "10.1145/3491102.3517570",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dingler",
        "given": "Tilman"
      },
      {
        "family": "Tag",
        "given": "Benjamin"
      },
      {
        "family": "Eccles",
        "given": "David A."
      },
      {
        "family": "van Berkel",
        "given": "Niels"
      },
      {
        "family": "Kostakos",
        "given": "Vassilis"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Implicit tendencies and cognitive biases play an important role in how information is perceived and processed, a fact that can be both utilised and exploited by computing systems. The Implicit Association Test (IAT) has been widely used to assess people\u2019s associations of target concepts with qualitative attributes, such as the likelihood of being hired or convicted depending on race, gender, or age. The condensed version\u2013the Brief IAT\u2013aims to implicit biases by measuring the reaction time to concept classifications. To use this measure in HCI research, however, we need a way to construct and validate target concepts, which tend to quickly evolve and depend on geographical and cultural interpretations. In this paper, we introduce and evaluate a new method to appropriate the BIAT using crowdsourcing to measure people\u2019s leanings on polarising topics. We present a web-based tool to test participants\u2019 bias on custom themes, where self-assessments often fail. We validated our approach with 14 domain experts and assessed the fit of crowdsourced test construction. Our method allows researchers of different domains to create and validate bias tests that can be geographically tailored and updated over time. We discuss how our method can be applied to surface implicit user biases and run studies where cognitive biases may impede reliable results.",
    "call-number": "10.1145/3491102.3517570",
    "collection-number": "243",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517570",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Brief Implicit Association Test, Attitude-Aware Systems, Cognitive Biases",
    "number": "Article 243",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Method for Appropriating the Brief Implicit Association Test to Elicit Biases in Users",
    "URL": "https://doi.org/10.1145/3491102.3517570"
  },
  {
    "id": "10.1145/3491102.3517503",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "McClure Haughey",
        "given": "Melinda"
      },
      {
        "family": "Povolo",
        "given": "Martina"
      },
      {
        "family": "Starbird",
        "given": "Kate"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As misinformation, disinformation, and conspiracy theories increase online, so does journalism coverage of these topics. This reporting is challenging, and journalists fill gaps in their expertise by utilizing external resources, including academic researchers. This paper discusses how journalists work with researchers to report on online misinformation. Through an ethnographic study of thirty collaborations, including participant-observation and interviews with journalists and researchers, we identify five types of collaborations and describe what motivates journalists to reach out to researchers \u2014 from a lack of access to data to support for understanding misinformation context. We highlight challenges within these collaborations, including misalignment in professional work practices, ethical guidelines, and reward structures. We end with a call to action for CHI researchers to attend to this intersection, develop ethical guidelines around supporting journalists with data at speed, and offer practical approaches for researchers filling a \u201cdata mediator\u201d role between social media and journalists.",
    "call-number": "10.1145/3491102.3517503",
    "collection-number": "244",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517503",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 244",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Bridging Contextual and Methodological Gaps on the \u201cMisinformation Beat\u201d: Insights from Journalist-Researcher Collaborations at Speed",
    "URL": "https://doi.org/10.1145/3491102.3517503"
  },
  {
    "id": "10.1145/3491102.3502040",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Allen",
        "given": "Jennifer"
      },
      {
        "family": "Martel",
        "given": "Cameron"
      },
      {
        "family": "Rand",
        "given": "David G"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "There is a great deal of interest in the role that partisanship, and cross-party animosity in particular, plays in interactions on social media. Most prior research, however, must infer users\u2019 judgments of others\u2019 posts from engagement data. Here, we leverage data from Birdwatch, Twitter\u2019s crowdsourced fact-checking pilot program, to directly measure judgments of whether other users\u2019 tweets are misleading, and whether other users\u2019 free-text evaluations of third-party tweets are helpful. For both sets of judgments, we find that contextual features \u2013 in particular, the partisanship of the users \u2013 are far more predictive of judgments than the content of the tweets and evaluations themselves. Specifically, users are more likely to write negative evaluations of tweets from counter-partisans; and are more likely to rate evaluations from counter-partisans as unhelpful. Our findings provide clear evidence that Birdwatch users preferentially challenge content from those with whom they disagree politically. While not necessarily indicating that Birdwatch is ineffective for identifying misleading content, these results demonstrate the important role that partisanship can play in content evaluation. Platform designers must consider the ramifications of partisanship when implementing crowdsourcing programs.",
    "call-number": "10.1145/3491102.3502040",
    "collection-number": "245",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502040",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "misinformation, fact-checking, crowdsourcing",
    "number": "Article 245",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Birds of a feather don\u2019t fact-check each other: Partisanship and the evaluation of news in Twitter\u2019s Birdwatch crowdsourced fact-checking program",
    "URL": "https://doi.org/10.1145/3491102.3502040"
  },
  {
    "id": "10.1145/3491102.3517450",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Disch",
        "given": "Leonie"
      },
      {
        "family": "Fessl",
        "given": "Angela"
      },
      {
        "family": "Pammer-Schindler",
        "given": "Viktoria"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The uptake of open science resources needs knowledge construction on the side of the readers/receivers of scientific content. The design of technologies surrounding open science resources can facilitate such knowledge construction, but this has not been investigated yet. To do so, we first conducted a scoping review of literature, from which we draw design heuristics for knowledge construction in digital environments. Subsequently, we grouped the underlying technological functionalities into three design categories: i) structuring and supporting collaboration, ii) supporting the learning process, and iii) structuring, visualising and navigating (learning) content. Finally, we mapped the design categories and associated design heuristics to core components of popular open science platforms. This mapping constitutes a design space (design implications), which informs researchers and designers in the HCI community about suitable functionalities for supporting knowledge construction in existing or new digital open science platforms.",
    "call-number": "10.1145/3491102.3517450",
    "collection-number": "246",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517450",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "platform design, knowledge construction, design implications, open science",
    "number": "Article 246",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing for Knowledge Construction to Facilitate the Uptake of Open Science: Laying out the Design Space",
    "URL": "https://doi.org/10.1145/3491102.3517450"
  },
  {
    "id": "10.1145/3491102.3501924",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Guo",
        "given": "Siling"
      },
      {
        "family": "Sun",
        "given": "Tianchen"
      },
      {
        "family": "Gong",
        "given": "Jiangtao"
      },
      {
        "family": "Lu",
        "given": "Zhicong"
      },
      {
        "family": "Zhang",
        "given": "Liuxin"
      },
      {
        "family": "Wang",
        "given": "Qianying"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The shortage of high-quality teachers is one of the biggest educational problems faced by underdeveloped areas. With the development of information and communication technologies (ICTs), China has begun a remote co-teaching intervention program using ICTs for rural classes, forming a unique \u201cco-teaching classroom\u201d. We conducted semi-structured interviews with nine remote urban teachers and twelve local rural teachers. We identified the remote co-teaching classes\u2019 standard practices and co-teachers\u2019 collaborative work process. We also found that remote teachers\u2019 high-quality class directly impacted local teachers and students. Furthermore, interestingly, local teachers were also actively involved in making indirect impacts on their students by deeply coordinating with remote teachers and adapting the resources offered by the remote teachers. We conclude by summarizing and discussing the challenges faced by teachers, lessons learned from the current program, and related design implications to achieve a more adaptive and sustainable ICT4D program design.",
    "call-number": "10.1145/3491102.3501924",
    "collection-number": "247",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501924",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "educational inequality, rural education, ICT4D/E, remote collaboration",
    "number": "Article 247",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Remote Co-teaching in Rural Classroom: Current Practices, Impacts, and Challenges",
    "URL": "https://doi.org/10.1145/3491102.3501924"
  },
  {
    "id": "10.1145/3491102.3517576",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Delcourt",
        "given": "Catherine Grevet"
      },
      {
        "family": "Charmaraman",
        "given": "Linda"
      },
      {
        "family": "Durrani",
        "given": "Sidrah"
      },
      {
        "family": "Gu",
        "given": "Quan"
      },
      {
        "family": "Xiao",
        "given": "Le Fan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Leveraging social media as a domain of high relevance in the lives of most young adolescents, we led a synchronous virtual design workshop with 17 ethnically diverse, and geographically-dispersed middle school girls (aged 11-14) to co-create novel ICT experiences. Our participatory workshop centered on social media innovation, collaboration, and computational design. We present the culminating design ideas of novel online social spaces, focused on positive experiences for adolescent girls, produced in small-groups, and a thematic analysis of the idea generation and collaboration processes. We reflect on the strengths of utilizing social media as a domain for computing exploration with diverse adolescent girls, the role of facilitators in a synchronous virtual design workshop, and the technical infrastructure that can enable age-appropriate scaffolding for active participation and use of participatory design principles embedded within educational workshops with this population.",
    "call-number": "10.1145/3491102.3517576",
    "collection-number": "248",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517576",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Participatory design, social media, confidence, adolescent girls, synchronous communication, small-group facilitation, collaboration",
    "number": "Article 248",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Innovating Novel Online Social Spaces with Diverse Middle School Girls: Ideation and Collaboration in a Synchronous Virtual Design Workshop",
    "URL": "https://doi.org/10.1145/3491102.3517576"
  },
  {
    "id": "10.1145/3491102.3501846",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Vermette",
        "given": "Laton"
      },
      {
        "family": "Ramesh",
        "given": "Kavana"
      },
      {
        "family": "McGrenere",
        "given": "Joanna"
      },
      {
        "family": "Chilana",
        "given": "Parmit K"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Instructors regularly learn and customize various feature-rich software applications to meet their unique classroom needs. Although instructors often prefer social help from colleagues to navigate this complex and time-consuming learning process, it can be difficult for them to locate relevant task-specific customizations, a challenge only exacerbated by the transition to online teaching due to COVID-19. To mitigate this, we explored how instructors could use an example-based customization sharing platform to discover, try, and appropriate their colleagues\u2019 customizations within a learning management system (LMS). Our field deployment study revealed diverse ways that ten instructors from different backgrounds used customization sharing features to streamline their workflows, improve their LMS feature awareness, and explore new possibilities for designing their courses to match student expectations. Our findings provide new knowledge about customization sharing practices, highlighting the complex interplay of expertise, software learnability, domain-specific workflows, and social perceptions.",
    "call-number": "10.1145/3491102.3501846",
    "collection-number": "249",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501846",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "personalization, educational technology, learning management systems, customization sharing, software customization, digital classroom tools",
    "number": "Article 249",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Uncovering Instructors\u2019 Diverse Practices and Perceptions: A Field Deployment of a Customization-Sharing Platform that Supports Course Management",
    "URL": "https://doi.org/10.1145/3491102.3501846"
  },
  {
    "id": "10.1145/3491102.3501827",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tener",
        "given": "Felix"
      },
      {
        "family": "Lanir",
        "given": "Joel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Autonomous vehicle (AV) technologies are rapidly evolving with the vision of having self-driving cars moving safely with no human input. However, it is clear that at least in the near and foreseeable future, AVs will not be able to resolve all road incidents and that in some situations remote human assistance will be required. However, remote driving is not trivial and introduces many challenges stemming mostly from the physical disconnect of the remote operator. In order to highlight these challenges and understand how to better design AV teleoperation interfaces, we conducted several observations of AV teleoperation sessions as well as in-depth interviews with 14 experts. Based on these interviews, we provide an investigation and analysis of the major AV teleoperation challenges. We follow this by providing design suggestions for the development of future teleoperation interfaces for assistance and driving of AVs.",
    "call-number": "10.1145/3491102.3501827",
    "collection-number": "250",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501827",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Teleoperation, Remote driving, Autonomous vehicles, Tele-assistance, Teleoperation challenges, User interface design, Tele-driving",
    "number": "Article 250",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Driving from a Distance: Challenges and Guidelines for Autonomous Vehicle Teleoperation Interfaces",
    "URL": "https://doi.org/10.1145/3491102.3501827"
  },
  {
    "id": "10.1145/3491102.3517640",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Boudouraki",
        "given": "Andriana"
      },
      {
        "family": "Reeves",
        "given": "Stuart"
      },
      {
        "family": "Fischer",
        "given": "Joel E"
      },
      {
        "family": "Rintel",
        "given": "Sean"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Mobile Robotic Telepresence (MRP) systems are remotely controlled, mobile videoconferencing devices that allow the remote user to move independently and have a physical presence in the environment. This paper presents a longitudinal study of MRP use in the home, where the first author used an MRP to connect with family, her partner, and friends over a six-month period. Taking an ethnomethodological approach, we present video recorded fragments to explore the phenomenon of \u2018visiting\u2019 where MRP users drop into the home for a period of time. We unpack the more \u2018procedural\u2019 elements\u2014arriving and departing\u2014alongside ways of \u2018dwelling\u2019 together during a visit, and the qualities of mobility, autonomous presence and spontaneity that emerge.",
    "call-number": "10.1145/3491102.3517640",
    "collection-number": "251",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517640",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mediated intimacy, videoconferencing, ethnography, mediated closeness",
    "number": "Article 251",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mediated Visits: Longitudinal Domestic Dwelling with Mobile Robotic Telepresence",
    "URL": "https://doi.org/10.1145/3491102.3517640"
  },
  {
    "id": "10.1145/3491102.3517572",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lyu",
        "given": "Yao"
      },
      {
        "family": "Carroll",
        "given": "John M."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Digital contact tracing is an ICT approach for controlling public health crises. It identifies users\u2019 risk of infection based on their healthcare and travel information. In the COVID-19 pandemic, many countries implemented digital contact tracing to contain the coronavirus outbreak. However, the adoption rates vary significantly across different countries. In this study, we investigate Chinese people\u2019s adoption of digital contact tracing. We aim at finding the influence of Chinese culture on people\u2019s attitudes and behaviors toward the technology. We interviewed 26 Chinese participants and used thematic analysis to interpret the data. Our findings showed that Chinese culture shaped citizens\u2019 interactions with the digital contact tracing at multiple levels; driven by the culture, Chinese citizens accepted digital contact tracing and contributed to making digital contact tracing a socio-technical infrastructure of people\u2019s daily lives. We also discuss such cultural influences with the growing literature of human infrastructure and crisis informatics.",
    "call-number": "10.1145/3491102.3517572",
    "collection-number": "252",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517572",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human Infrastructure, COVID-19 Pandemic, Infrastructure, Contact Tracing, Infrastructuring, Crisis Informatics, Culture Studies",
    "number": "Article 252",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Cultural Influences on Chinese Citizens\u2019 Adoption of Digital Contact Tracing: A Human Infrastructure Perspective",
    "URL": "https://doi.org/10.1145/3491102.3517572"
  },
  {
    "id": "10.1145/3491102.3502058",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "V\u00f6lkel",
        "given": "Sarah Theres"
      },
      {
        "family": "Schoedel",
        "given": "Ramona"
      },
      {
        "family": "Kaya",
        "given": "Lale"
      },
      {
        "family": "Mayer",
        "given": "Sven"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Whilst imbuing robots and voice assistants with personality has been found to positively impact user experience, little is known about user perceptions of personality in purely text-based chatbots. In a within-subjects study, we asked N=34 participants to interact with three chatbots with different levels of Extraversion (extraverted, average, introverted), each over the course of four days. We systematically varied the chatbots\u2019 responses to manipulate Extraversion based on work in the psycholinguistics of human behaviour. Our results show that participants perceived the extraverted and average chatbots as such, whereas verbal cues transferred from human behaviour were insufficient to create an introverted chatbot. Whilst most participants preferred interacting with the extraverted chatbot, participants engaged significantly more with the introverted chatbot as indicated by the users\u2019 average number of written words. We discuss implications for researchers and practitioners on how to design chatbot personalities that can adapt to user preferences.",
    "call-number": "10.1145/3491102.3502058",
    "collection-number": "253",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502058",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "extraversion, conversational agent, chatbot, personalisation, personality",
    "number": "Article 253",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "User Perceptions of Extraversion in Chatbots after Repeated Use",
    "URL": "https://doi.org/10.1145/3491102.3502058"
  },
  {
    "id": "10.1145/3491102.3501961",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Heath",
        "given": "Claude P. R."
      },
      {
        "family": "Coles-Kemp",
        "given": "Lizzie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In a study of everyday digital identity, a set of primary drawings were made by researchers in online focus group settings as a way to capture our participants\u2019 spoken narratives of hyper-[in]security in the usages of digital identity. In a second stage of work, key extracts from the drawings were collaged using the method described in the paper, allowing an exploratory qualitative cartography of hyper-[in]security to be constructed. These secondary collages group the [in]securities thematically without losing essential contextual information. Samples of our data are given, to illustrate the contribution of the method to experience-centred design, with special reference to security from the perspective of marginalised and underserved communities. We discuss our method as a step towards multidimensional cognitive mapping of the salient features of our participants\u2019 narratives about hyper-[in]security, potentially paving the way for further world building explorations of digital identity futures.",
    "call-number": "10.1145/3491102.3501961",
    "collection-number": "254",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501961",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "drawing, security technologies, world building, digital inclusion",
    "number": "Article 254",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Drawing Out the Everyday Hyper-[In]Securities of Digital Identity",
    "URL": "https://doi.org/10.1145/3491102.3501961"
  },
  {
    "id": "10.1145/3491102.3517646",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shahid",
        "given": "Farhana"
      },
      {
        "family": "Kamath",
        "given": "Srujana"
      },
      {
        "family": "Sidotam",
        "given": "Annie"
      },
      {
        "family": "Jiang",
        "given": "Vivian"
      },
      {
        "family": "Batino",
        "given": "Alexa"
      },
      {
        "family": "Vashistha",
        "given": "Aditya"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present a qualitative study with 36 diverse social media users in India to critically examine how low-resource communities engage with fake videos, including cheapfakes and AI-generated deepfakes. We find that most users are unaware of digitally manipulated fake videos and perceive videos to be fake only when they present inaccurate information. Few users who know about doctored videos expect them to be of poor quality and know nothing about sophisticated deepfakes. Moreover, most users lack the skills and willingness to spot fake videos and some were oblivious to the risks and harms of fake videos. Even when users know a video to be fake, they prefer to take no action and sometimes willingly share fake videos that favor their worldview. Drawing on our findings, we discuss design recommendations for social media platforms to curb the spread of fake videos.",
    "call-number": "10.1145/3491102.3517646",
    "collection-number": "255",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517646",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Global South, India, ICTD, Misinformation, Fake videos, HCI4D",
    "number": "Article 255",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dIt Matches My Worldview\u201d: Examining Perceptions and Attitudes Around Fake Videos",
    "URL": "https://doi.org/10.1145/3491102.3517646"
  },
  {
    "id": "10.1145/3491102.3517588",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Varanasi",
        "given": "Rama Adithya"
      },
      {
        "family": "Pal",
        "given": "Joyojeet"
      },
      {
        "family": "Vashistha",
        "given": "Aditya"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Social media has witnessed an unprecedented growth in users based in low-income communities in the Global South. However, much remains unknown about the drivers of misinformation in such communities. To fill this gap, we conducted an interview-based study to examine how rural and urban communities in India engage with misinformation on WhatsApp. We found that misinformation led to bitterness and conflict \u2013 rural users who had higher social status heavily influenced the perceptions and engagement of marginalized members. While urban users relied on the expertise of gatekeepers for verification, rural users engaged in collective deliberations in offline spaces. Both rural and urban users knowingly forwarded misinformation. However, rural users propagated hyperlocal misinformation, whereas urban users forwarded misinformation to reduce their efforts to assess information credibility. Using a public sphere lens, we propose that the reactions to misinformation provide a view of Indian society and its schisms around class, urbanity, and social interactions.",
    "call-number": "10.1145/3491102.3517588",
    "collection-number": "256",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517588",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "public sphere, rural, Misinformation, WhatsApp, disinformation, encrypted platforms",
    "number": "Article 256",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Accost, Accede, or Amplify: Attitudes towards COVID-19 Misinformation on WhatsApp in India",
    "URL": "https://doi.org/10.1145/3491102.3517588"
  },
  {
    "id": "10.1145/3491102.3502094",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kotut",
        "given": "Lindah"
      },
      {
        "family": "McCrickard",
        "given": "D. Scott"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Technology has provided an environment for connecting indigenous community members and provide a means for them to seek and engage with their indigenous knowledge (IK). Emerging research has examined the effects of social media on specific IK, including the possibility of undermining community agency. In this work, we contrast how indigenous community members engage with IK offline, and in their own self-organized communities online. Through interviews with community members and a study of Facebook Pages and Facebook Groups, we seek to better understand these practices and elicit design recommendations. Our findings describe how community roles have shifted in the presence of technology, notably with absence of elders and the inclusion of \u201cborn towns\u201d\u2013community members who live in non-traditional settings. We also find that fluency in the indigenous language served both as a gatekeeper: guarding the community knowledge, while also facilitating discussion surrounding different aspects of IK.",
    "call-number": "10.1145/3491102.3502094",
    "collection-number": "257",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502094",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "HCI4D, Indigenous Knowledge, Online Communities, Intangible Cultural Heritage, Critical Computing, Post-Colonial Computing",
    "number": "Article 257",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Winds of Change: Seeking, Preserving, and Retelling Indigenous Knowledge Through Self-Organized Online Communities",
    "URL": "https://doi.org/10.1145/3491102.3502094"
  },
  {
    "id": "10.1145/3491102.3517528",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Suhaimi",
        "given": "Nurul M"
      },
      {
        "family": "Zhang",
        "given": "Yixuan"
      },
      {
        "family": "Joseph",
        "given": "Mary"
      },
      {
        "family": "Kim",
        "given": "Miso"
      },
      {
        "family": "Parker",
        "given": "Andrea G"
      },
      {
        "family": "Griffin",
        "given": "Jacqueline"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The world population is projected to rapidly age over the next 30 years. Given the increasing digital technology adoption amongst older adults, researchers have investigated how technology can support aging populations. However, little work has examined how technology can support older adults during crises, despite increasingly common natural disasters, public health emergencies, and other crisis scenarios in which older adults are especially vulnerable. Addressing this gap, we conducted focus groups with older adults residing in coastal locations to examine to what extent they felt technology could support them during emergencies. Our findings characterize participants\u2019 desire for tools that enhance community resilience-local knowledge, preparedness, community relationships, and communication, that help communities withstand disasters. Further, older adults\u2019 crisis technology preferences were linked to their sense of control, social relationships, and digital readiness. We discuss how a focus on community resilience can yield crisis technologies that more effectively support older adults.",
    "call-number": "10.1145/3491102.3517528",
    "collection-number": "258",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517528",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "crisis informatics, aging population, critical events, mobile applications, older adults, disasters, emergencies, ageing",
    "number": "Article 258",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Older Adults\u2019 Attitudes towards Crisis Informatics Tools: Opportunities for Enhancing Community Resilience during Disasters",
    "URL": "https://doi.org/10.1145/3491102.3517528"
  },
  {
    "id": "10.1145/3491102.3502099",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gu",
        "given": "Jianzhe"
      },
      {
        "family": "Lin",
        "given": "Yuyu"
      },
      {
        "family": "Cui",
        "given": "Qiang"
      },
      {
        "family": "Li",
        "given": "Xiaoqian"
      },
      {
        "family": "Li",
        "given": "Jiaji"
      },
      {
        "family": "Sun",
        "given": "Lingyun"
      },
      {
        "family": "Yao",
        "given": "Cheng"
      },
      {
        "family": "Ying",
        "given": "Fangtian"
      },
      {
        "family": "Wang",
        "given": "Guanyun"
      },
      {
        "family": "Yao",
        "given": "Lining"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "From transoceanic bridges to large-scale installations, truss structures have been known for their structural stability and shape complexity. In addition to the advantages of static trusses, truss structures have a large degree of freedom to change shape when equipped with rotatable joints and retractable beams. However, it is difficult to design a complex motion and build a control system for large numbers of trusses. In this paper, we present PneuMesh, a novel truss-based shape-changing system that is easy to design and build but still able to achieve a range of tasks. PneuMesh accomplishes this by introducing an air channel connection strategy and reconfigurable constraint design that drastically decreases the number of control units without losing the complexity of shape-changing. We develop a design tool with real-time simulation to assist users in designing the shape and motion of truss-based shape-changing robots and devices. A design session with seven participants demonstrates that PneuMesh empowers users to design and build truss structures with a wide range of shapes and various functional motions.",
    "call-number": "10.1145/3491102.3502099",
    "collection-number": "260",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502099",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Shape-changing Interface, Computational fabrication",
    "number": "Article 260",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PneuMesh: Pneumatic-driven Truss-based Shape Changing System",
    "URL": "https://doi.org/10.1145/3491102.3502099"
  },
  {
    "id": "10.1145/3491102.3501837",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fang",
        "given": "Cathy Mengying"
      },
      {
        "family": "Gu",
        "given": "Jianzhe"
      },
      {
        "family": "Yao",
        "given": "Lining"
      },
      {
        "family": "Harrison",
        "given": "Chris"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We describe how sheets of metalized mylar can be cut and then \u201cinflated\u201d into complex 3D forms with electrostatic charge for use in digitally-controlled, shape-changing displays. This is achieved by placing and nesting various cuts, slits and holes such that mylar elements repel from one another to reach an equilibrium state. Importantly, our technique is compatible with industrial and hobbyist cutting processes, from die and laser cutting to handheld exacto-knives and scissors. Given that mylar film costs <$1 per m2, we can create self-actuating 3D objects for just a few cents, opening new uses in low-cost consumer goods. We describe a design vocabulary, interactive simulation tool, fabrication guide, and proof-of-concept electrostatic actuation hardware. We detail our technique\u2019s performance metrics along with qualitative feedback from a design study. We present numerous examples generated using our pipeline to illustrate the rich creative potential of our method.",
    "call-number": "10.1145/3491102.3501837",
    "collection-number": "261",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501837",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Computational Fabrication, Electrostatic Inflation, Shape-changing Interface",
    "number": "Article 261",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ElectriPop: Low-Cost, Shape-Changing Displays Using Electrostatically Inflated Mylar Sheets",
    "URL": "https://doi.org/10.1145/3491102.3501837"
  },
  {
    "id": "10.1145/3491102.3501910",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tanaka",
        "given": "Yudai"
      },
      {
        "family": "Nishida",
        "given": "Jun"
      },
      {
        "family": "Lopes",
        "given": "Pedro"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We propose a novel interface concept in which interactive systems directly manipulate the user's head orientation. We implement this using electrical-muscle-stimulation (EMS) of the neck muscles, which turns the head around its yaw (left/right) and pitch (up/down) axis. As the first exploration of EMS for head actuation, we characterized which muscles can be robustly actuated. Second, we evaluated the accuracy of our system for actuating participants' head orientation towards static targets and trajectories. Third, we demonstrated how it enables interactions not possible before by building a range of applications, such as (1) synchronizing head orientations of two users, which enables a user to communicate head nods to another user while listening to music, and (2) directly changing the user's head orientation to locate objects in AR. Finally, in our second study, participants felt that our head actuation contributed positively to their experience in four distinct applications.",
    "call-number": "10.1145/3491102.3501910",
    "collection-number": "262",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501910",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Haptics, Virtual Reality, Augmented Reality, Electrical Muscle Stimulation",
    "number": "Article 262",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Electrical Head Actuation: Enabling Interactive Systems to Directly Manipulate Head Orientation",
    "URL": "https://doi.org/10.1145/3491102.3501910"
  },
  {
    "id": "10.1145/3491102.3517462",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Engert",
        "given": "Severin"
      },
      {
        "family": "Klamka",
        "given": "Konstantin"
      },
      {
        "family": "Peetz",
        "given": "Andreas"
      },
      {
        "family": "Dachselt",
        "given": "Raimund"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present STRAIDE, a string-actuated interactive display environment that allows to explore the promising potential of shape-changing interfaces for casual visualizations. At the core, we envision a platform that spatially levitates elements to create dynamic visual shapes in space. We conceptualize this type of tangible mid-air display and discuss its multifaceted design dimensions. Through a design exploration, we realize a physical research platform with adjustable parameters and modular components. For conveniently designing and implementing novel applications, we provide developer tools ranging from graphical emulators to in-situ augmented reality representations. To demonstrate STRAIDE\u2019s reconfigurability, we further introduce three representative physical setups as a basis for situated applications including ambient notifications, personal smart home controls, and entertainment. They serve as a technical validation, lay the foundations for a discussion with developers that provided valuable insights, and encourage ideas for future usage of this type of appealing interactive installation.",
    "call-number": "10.1145/3491102.3517462",
    "collection-number": "263",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517462",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Tangible Interaction, Prototyping Platform, Casual Visualization, Shape-Changing Interface, Data Physicalization, Spatial Display",
    "number": "Article 263",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "STRAIDE: A Research Platform for Shape-Changing Spatial Displays based on Actuated Strings",
    "URL": "https://doi.org/10.1145/3491102.3517462"
  },
  {
    "id": "10.1145/3491102.3517586",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Caldeira",
        "given": "Clara"
      },
      {
        "family": "Nurain",
        "given": "Novia"
      },
      {
        "family": "Connelly",
        "given": "Kay"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Aging in place technologies are designed to extend independence and autonomy in older adults, promoting quality of life and peace of mind. Prior work has described how adoption and continued use of these technologies are low when they are perceived as reinforcing aging stigma or reminding older adults of negative aspects of aging. Building on past research, we investigate older adults\u2019 perceptions of four different kinds of aging in place technologies. Based on in-depth interviews with 18 older adults using a set of scenarios, we describe how different design characteristics contribute to perceived aging stigma. Additionally, we draw on Duner & Nordstr\u00f6m\u2019s classification of coping strategies to discuss how specific kinds of technology can best support older adults during different stages of the aging process.",
    "call-number": "10.1145/3491102.3517586",
    "collection-number": "264",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517586",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "aging in place, older adults, stigma",
    "number": "Article 264",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI hope I never need one\u201d: Unpacking Stigma in Aging in Place Technology",
    "URL": "https://doi.org/10.1145/3491102.3517586"
  },
  {
    "id": "10.1145/3491102.3517621",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Harrington",
        "given": "Christina"
      },
      {
        "family": "Martin-Hammond",
        "given": "Aqueasha"
      },
      {
        "family": "Bray",
        "given": "Kirsten E"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Innovations in HCI research of health-related pervasive and ubiquitous technologies can potentially improve older adults\u2019 access to healthcare resources and support long-term independence in the home. Despite efforts to include their voices in technology research and design, many older adults have yet to actualize these health benefits, with barriers of access and proficiency actually widening the gap of health inequities. We reviewed 174 HCI publications through a systematic review to examine who is engaged in the design of health technologies for older adults, methods used to engage them, and how different types of participation might impact design directions. Findings highlight that thus far, many identity dimensions have not been explored in HCI aging research. We identify research gaps and implications to promote expanding research engagement with these dimensions as a way to support the design of health technologies that see better adoption among marginalized populations.",
    "call-number": "10.1145/3491102.3517621",
    "collection-number": "265",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517621",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "study participants, health, cultural diversity, diversity dimensions, pervasive and ubiquitous technologies, systematic review, older adults",
    "number": "Article 265",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Examining Identity as a Variable of Health Technology Research for Older Adults: A Systematic Review",
    "URL": "https://doi.org/10.1145/3491102.3517621"
  },
  {
    "id": "10.1145/3491102.3517490",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Franklin Mingzhe"
      },
      {
        "family": "Spektor",
        "given": "Franchesca"
      },
      {
        "family": "Xia",
        "given": "Meng"
      },
      {
        "family": "Huh",
        "given": "Mina"
      },
      {
        "family": "Cederberg",
        "given": "Peter"
      },
      {
        "family": "Gong",
        "given": "Yuqi"
      },
      {
        "family": "Shinohara",
        "given": "Kristen"
      },
      {
        "family": "Carrington",
        "given": "Patrick"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Makeup and cosmetics offer the potential for self-expression and the reshaping of social roles for visually impaired people. However, there exist barriers to conducting a beauty regime because of the reliance on visual information and color variances in makeup. We present a content analysis of 145 YouTube videos to demonstrate visually impaired individuals\u2019 unique practices before, during, and after doing makeup. Based on the makeup practices, we then conducted semi-structured interviews with 12 visually impaired people to discuss their perceptions of and challenges with the makeup process in more depth. Overall, through our findings and discussion, we present novel perceptions of makeup from visually impaired individuals (e.g., broader representations of blindness and beauty). The existing challenges provide opportunities for future research to address learning barriers, insufficient feedback, and physical and environmental barriers, making the experience of doing makeup more accessible to people with visual impairments.",
    "call-number": "10.1145/3491102.3517490",
    "collection-number": "266",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517490",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Assistive technology, Accessibility, Qualitative study, People with Visual Impairments, Makeup, Cosmetics",
    "number": "Article 266",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt Feels Like Taking a Gamble\u201d: Exploring Perceptions, Practices, and Challenges of Using Makeup and Cosmetics for People with Visual Impairments",
    "URL": "https://doi.org/10.1145/3491102.3517490"
  },
  {
    "id": "10.1145/3491102.3517566",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Alonzo",
        "given": "Oliver"
      },
      {
        "family": "Trussell",
        "given": "Jessica"
      },
      {
        "family": "Watkins",
        "given": "Matthew"
      },
      {
        "family": "Lee",
        "given": "Sooyeon"
      },
      {
        "family": "Huenerfauth",
        "given": "Matt"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Research has revealed benefits and interest among Deaf and Hard-of-Hearing (DHH) adults in reading-assistance tools powered by Automatic Text Simplification (ATS), a technology whose development benefits from evaluations by specific user groups. While prior work has provided guidance for evaluating text complexity among DHH adults, researchers lack guidance for evaluating the fluency of automatically simplified texts, which may contain errors from the simplification process. Thus, we conduct methodological research on the effectiveness of metrics (including reading speed; comprehension questions; and subjective judgements of understandability, readability, grammaticality, and system performance) for evaluating texts controlled to be at different levels of fluency, when measured among DHH participants at different literacy levels. Reading speed and grammaticality judgements effectively distinguished fluency levels among participants across literacy levels. Readability and understandability judgements, however, only worked among participants with higher literacy. Our findings provide methodological guidance for designing ATS evaluations with DHH participants.",
    "call-number": "10.1145/3491102.3517566",
    "collection-number": "267",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517566",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "accessibility, methodological research, automatic text simplification, deaf and hard-of-hearing",
    "number": "Article 267",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Methods for Evaluating the Fluency of Automatically Simplified Texts with Deaf and Hard-of-Hearing Adults at Various Literacy Levels",
    "URL": "https://doi.org/10.1145/3491102.3517566"
  },
  {
    "id": "10.1145/3491102.3502063",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lei",
        "given": "Wentao"
      },
      {
        "family": "Fan",
        "given": "Mingming"
      },
      {
        "family": "Thang",
        "given": "Juliann"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With about 230 million packages delivered per day in 2020, fetching packages has become a routine for many city dwellers in China. When fetching packages, people usually need to go to collection sites of their apartment complexes or a KuaiDiGui, an increasingly popular type of self-service package pickup machine. However, little is known whether such processes are accessible to blind and low vision (BLV) city dwellers. We interviewed BLV people (N=20) living in a large metropolitan area in China to understand their practices and challenges of fetching packages. Our findings show that participants encountered difficulties in finding the collection site and localizing and recognizing their packages. When fetching packages from KuaiDiGuis, they had difficulty in identifying the correct KuaiDiGui, interacting with its touch screen, navigating the complex on-screen workflow, and opening the target compartment. We discuss design considerations to make the package fetching process more accessible to the BLV community.",
    "call-number": "10.1145/3491102.3502063",
    "collection-number": "268",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502063",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "KuaiDiGui, Package delivery, China, People with vision impairments, Qualitative study, Accessibility, Interview, Blind and low vision",
    "number": "Article 268",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Shake The Package To Check If It\u2019s Mine\u201d: A Study of Package Fetching Practices and Challenges of Blind and Low Vision People in China",
    "URL": "https://doi.org/10.1145/3491102.3502063"
  },
  {
    "id": "10.1145/3491102.3501951",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dogan",
        "given": "Mustafa Doga"
      },
      {
        "family": "Taka",
        "given": "Ahmad"
      },
      {
        "family": "Lu",
        "given": "Michael"
      },
      {
        "family": "Zhu",
        "given": "Yunyi"
      },
      {
        "family": "Kumar",
        "given": "Akshat"
      },
      {
        "family": "Gupta",
        "given": "Aakar"
      },
      {
        "family": "Mueller",
        "given": "Stefanie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Existing approaches for embedding unobtrusive tags inside 3D\u00a0objects require either complex fabrication or high-cost imaging equipment. We present InfraredTags, which are 2D markers and barcodes imperceptible to the naked eye that can be 3D printed as part of objects, and detected rapidly by low-cost near-infrared cameras. We achieve this by printing objects from an infrared-transmitting filament, which infrared cameras can see through, and by having air gaps inside for the tag\u2019s bits, which appear at a different intensity in the infrared image. We built a user interface that facilitates the integration of common tags (QR codes, ArUco markers) with the object geometry to make them 3D printable as InfraredTags. We also developed a low-cost infrared imaging module that augments existing mobile devices and decodes tags using our image processing pipeline. Our evaluation shows that the tags can be detected with little near-infrared illumination (0.2lux) and from distances as far as 250cm. We demonstrate how our method enables various applications, such as object tracking and embedding metadata for augmented reality and tangible interactions.",
    "call-number": "10.1145/3491102.3501951",
    "collection-number": "269",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501951",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "markers, unobtrusive tags, infrared imaging, augmented reality, 3D printing, tracking, personal fabrication, computer vision, identification",
    "number": "Article 269",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "InfraredTags: Embedding Invisible AR Markers and Barcodes Using Low-Cost, Infrared-Based 3D Printing and Imaging Tools",
    "URL": "https://doi.org/10.1145/3491102.3501951"
  },
  {
    "id": "10.1145/3491102.3502074",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Pourjafarian",
        "given": "Narjes"
      },
      {
        "family": "Koelle",
        "given": "Marion"
      },
      {
        "family": "Mjaku",
        "given": "Fjolla"
      },
      {
        "family": "Strohmeier",
        "given": "Paul"
      },
      {
        "family": "Steimle",
        "given": "J\u00fcrgen"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present Print-A-Sketch, an open-source handheld printer prototype for sketching circuits and sensors. Print-A-Sketch combines desirable properties from free-hand sketching and functional electronic printing. Manual human control of large strokes is augmented with computer control of fine detail. Shared control of Print-A-Sketch supports sketching interactive interfaces on everyday objects \u2013 including many objects with materials or sizes which otherwise are difficult to print on. We present an overview of challenges involved in such a system and show how these can be addressed using context-aware, dynamic printing. Continuous sensing ensures quality prints by adjusting inking-rate to hand movement and material properties. Continuous sensing also enables the print to adapt to previously printed traces to support incremental and iterative sketching. Results show good conductivity on many materials and high spatial precision, supporting on-the-fly creation of functional interfaces.",
    "call-number": "10.1145/3491102.3502074",
    "collection-number": "270",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502074",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Fabrication, sketching interfaces, new materials, conductive inkjet printing, prototyping, printed electronics",
    "number": "Article 270",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Print-A-Sketch: A Handheld Printer for Physical Sketching of Circuits and Sensors on Everyday Surfaces",
    "URL": "https://doi.org/10.1145/3491102.3502074"
  },
  {
    "id": "10.1145/3491102.3501919",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Park",
        "given": "Keunwoo"
      },
      {
        "family": "Lempert",
        "given": "Conrad"
      },
      {
        "family": "Abdullah",
        "given": "Muhammad"
      },
      {
        "family": "Katakura",
        "given": "Shohei"
      },
      {
        "family": "Shigeyama",
        "given": "Jotaro"
      },
      {
        "family": "Roumen",
        "given": "Thijs"
      },
      {
        "family": "Baudisch",
        "given": "Patrick"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present FoolProofJoint, a software tool that simplifies the assembly of laser-cut 3D models and reduces the risk of erroneous assembly. FoolProofJoint achieves this by modifying finger joint patterns. Wherever possible, FoolProofJoint makes similar looking pieces fully interchangeable, thereby speeding up the user's visual search for a matching piece. When that is not possible, FoolProofJoint gives finger joints a unique pattern of individual finger placements so as to fit only with the correct piece, thereby preventing erroneous assembly. In our benchmark set of 217 laser-cut 3D models downloaded from kyub.com, FoolProofJoint made groups of similar looking pieces fully interchangeable for 65% of all groups of similar pieces; FoolProofJoint fully prevented assembly mistakes for 97% of all models.",
    "call-number": "10.1145/3491102.3501919",
    "collection-number": "271",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501919",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Personal fabrication, manual assembly, laser cutting, rapid prototyping",
    "number": "Article 271",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FoolProofJoint: Reducing Assembly Errors of Laser Cut 3D Models by Means of Custom Joint Patterns",
    "URL": "https://doi.org/10.1145/3491102.3501919"
  },
  {
    "id": "10.1145/3491102.3501818",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Jiahao"
      },
      {
        "family": "Samoylov",
        "given": "Alexis"
      },
      {
        "family": "Kim",
        "given": "Jeeeun"
      },
      {
        "family": "Chen",
        "given": "Xiang 'Anthony'"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "One important vision of robotics is to provide physical assistance by manipulating different everyday objects, e.g., hand tools, kitchen utensils. However, many objects designed for dexterous hand-control are not easily manipulable by a single robotic arm with a generic parallel gripper. Complementary to existing research on developing grippers and control algorithms, we present Roman, a suite of hardware design and software tool support for robotic engineers to create 3D printable mechanisms attached to everyday handheld objects, making them easier to be manipulated by conventional robotic arms. The Roman hardware comes with a versatile magnetic gripper that can snap on/off handheld objects and drive add-on mechanisms to perform tasks. Roman also provides software support to register and author control programs. To validate our approach, we designed and fabricated Roman mechanisms for 14 everyday objects/tasks presented within a design space and conducted expert interviews with robotic engineers indicating that Roman serves as a practical alternative for enabling robotic manipulation of everyday objects.",
    "call-number": "10.1145/3491102.3501818",
    "collection-number": "272",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501818",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "handheld objects augmentation, mechanism design., Robotic grasping and manipulation",
    "number": "Article 272",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Roman: Making Everyday Objects Robotically Manipulable with 3D-Printable Add-on Mechanisms",
    "URL": "https://doi.org/10.1145/3491102.3501818"
  },
  {
    "id": "10.1145/3491102.3517645",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Arabi",
        "given": "Abul Al"
      },
      {
        "family": "Li",
        "given": "Jiahao"
      },
      {
        "family": "Chen",
        "given": "Xiang 'Anthony"
      },
      {
        "family": "Kim",
        "given": "Jeeeun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent advancements in personal fabrication have brought novices closer to a reality, where they can automate routine tasks with mobilized everyday objects. However, the overall process remains challenging- from capturing design requirements and motion planning to authoring them to creating 3D models of mechanical parts to programming electronics, as it demands expertise. We introduce Mobiot, an end-user toolkit to help non-experts capture the design and motion requirements of legacy objects by demonstration. It then automatically generates 3D printable attachments, programs to operate assembled modules, a list of off-the-shelf electronics, and assembly tutorials. The authoring feature further assists users to fine-tune as well as to reuse existing motion libraries and 3D printed mechanisms to adapt to other real-world objects with different motions. We validate Mobiot through application examples with 8 everyday objects with various motions applied, and through technical evaluation to measure the accuracy of motion reconstruction.",
    "call-number": "10.1145/3491102.3517645",
    "collection-number": "273",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517645",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Motion planning, Home-automation, Personal Fabrication",
    "number": "Article 273",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mobiot: Augmenting Everyday Objects into Moving IoT Devices Using 3D Printed Attachments Generated by Demonstration",
    "URL": "https://doi.org/10.1145/3491102.3517645"
  },
  {
    "id": "10.1145/3491102.3502090",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tatzgern",
        "given": "Markus"
      },
      {
        "family": "Domhardt",
        "given": "Michael"
      },
      {
        "family": "Wolf",
        "given": "Martin"
      },
      {
        "family": "Cenger",
        "given": "Michael"
      },
      {
        "family": "Emsenhuber",
        "given": "Gerlinde"
      },
      {
        "family": "Dinic",
        "given": "Radomir"
      },
      {
        "family": "Gerner",
        "given": "Nathalie"
      },
      {
        "family": "Hartl",
        "given": "Arnulf"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Increased levels of interactivity and multi-sensory stimulation have been shown to enhance the immersion of Virtual Reality experiences. We present the AirRes mask that enables users to utilize their breathing for precise natural interactions with the virtual environment without suffering from limitations of the sensing equipment such as motion artifacts. Furthermore, the AirRes mask provides breathing resistance as novel output modality that can be adjusted in real-time by the application. In a user study, we demonstrate the mask\u2019s precision measurements for interaction as well as its ability to use breathing resistance to communicate contextual information such as adverse environmental conditions that affect the user\u2019s virtual avatar. Our results show that the AirRes mask enhances virtual experiences and has the potential to create more immersive scenarios for applications by enforcing the perception of danger or improving situational awareness in training simulations, or for psychotherapy by providing additional physical stimuli.",
    "call-number": "10.1145/3491102.3502090",
    "collection-number": "274",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502090",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Avatar, Virtual Reality, Environment, Breathing Interface, Resistance, Natural Interaction",
    "number": "Article 274",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AirRes Mask: A Precise and Robust Virtual Reality Breathing Interface Utilizing Breathing Resistance as Output Modality",
    "URL": "https://doi.org/10.1145/3491102.3502090"
  },
  {
    "id": "10.1145/3491102.3501960",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shen",
        "given": "Vivian"
      },
      {
        "family": "Shultz",
        "given": "Craig"
      },
      {
        "family": "Harrison",
        "given": "Chris"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Today\u2019s consumer virtual reality (VR) systems offer limited haptic feedback via vibration motors in handheld controllers. Rendering haptics to other parts of the body is an open challenge, especially in a practical and consumer-friendly manner. The mouth is of particular interest, as it is a close second in tactile sensitivity to the fingertips, offering a unique opportunity to add fine-grained haptic effects. In this research, we developed a thin, compact, beamforming array of ultrasonic transducers, which can render haptic effects onto the mouth. Importantly, all components are integrated into the headset, meaning the user does not need to wear an additional accessory, or place any external infrastructure in their room. We explored several effects, including point impulses, swipes, and persistent vibrations. Our haptic sensations can be felt on the lips, teeth and tongue, which can be incorporated into new and interesting VR experiences.",
    "call-number": "10.1145/3491102.3501960",
    "collection-number": "275",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501960",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 275",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mouth Haptics in VR using a Headset Ultrasound Phased Array",
    "URL": "https://doi.org/10.1145/3491102.3501960"
  },
  {
    "id": "10.1145/3491102.3517432",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wei",
        "given": "Jing"
      },
      {
        "family": "Tag",
        "given": "Benjamin"
      },
      {
        "family": "Trippas",
        "given": "Johanne R"
      },
      {
        "family": "Dingler",
        "given": "Tilman"
      },
      {
        "family": "Kostakos",
        "given": "Vassilis"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Voice user interfaces (VUIs) have made their way into people\u2019s daily lives, from voice assistants to smart speakers. Although VUIs typically just react to direct user commands, increasingly, they incorporate elements of proactive behaviors. In particular, proactive smart speakers have the potential for many applications, ranging from healthcare to entertainment; however, their usability in everyday life is subject to interaction errors. To systematically investigate the nature of errors, we designed a voice-based Experience Sampling Method (ESM) application to run on proactive speakers. We captured 1,213 user interactions in a 3-week field deployment in 13 participants\u2019 homes. Through auxiliary audio recordings and logs, we identify substantial interaction errors and strategies that users apply to overcome those errors. We further analyze the interaction timings and provide insights into the time cost of errors. We find that, even for answering simple ESMs, interaction errors occur frequently and can hamper the usability of proactive speakers and user experience. Our work also identifies multiple facets of VUIs that can be improved in terms of the timing of speech.",
    "call-number": "10.1145/3491102.3517432",
    "collection-number": "276",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517432",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "smart speakers, interaction error, voice assistants, Voice user interface, user experience, Google Home",
    "number": "Article 276",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "Code": "shacklettbp/bps-nav",
    "Data": "Matterport3D"
  },
  {
    "title": "Hopper: Multi-hop Transformer for Spatiotemporal Reasoning",
    "url": "/forum?id=MaZFq7bJif7",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Multi-hop Reasoning, Object Permanence, Spatiotemporal Understanding, Video Recognition, Transformer",
    "Abstract": "This paper considers the problem of spatiotemporal object-centric reasoning in videos. Central to our approach is the notion of object permanence, i.e., the ability to reason about the location of objects as they move through the video while being occluded, contained or carried by other objects. Existing deep learning based approaches often suffer from spatiotemporal biases when applied to video reasoning problems. We propose Hopper, which uses a Multi-hop Transformer for reasoning object permanence in videos. Given a video and a localization query, Hopper reasons over image and object tracks to automatically hop over critical frames in an iterative fashion to predict the final position of the object of interest. We demonstrate the effectiveness of using a contrastive loss to reduce spatiotemporal biases. We evaluate over CATER dataset and find that Hopper achieves 73.2% Top-1 accuracy using just 1 FPS by hopping through just a few critical frames. We also demonstrate Hopper can perform long-term reasoning by building a CATER-h dataset that requires multi-step reasoning to localize objects of interest correctly.",
    "One-sentence Summary": "We propose Hopper, Multi-Hop Transformer, and CATER-h dataset to approach object-centric spatiotemporal reasoning in videos.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "necla-ml/cater-h",
    "Data": "CATER"
  },
  {
    "title": "Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL",
    "url": "/forum?id=fmtSg8591Q",
    "date": "28 Sept 2020 (modified: 09 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "reinforcement learning, factored MDP, constrained RL, learning theory",
    "Abstract": "Reinforcement learning (RL) in episodic, factored Markov decision processes (FMDPs) is studied. We propose an algorithm called FMDP-BF, which leverages the factorization structure of FMDP.  The regret of FMDP-BF is shown to be exponentially smaller than that of optimal algorithms designed for non-factored MDPs, and improves on the best previous result for FMDPs~\\citep{osband2014near} by a factor of nH|Si|, where |Si| is the cardinality of the factored state subspace, H is the planning horizon and n is the number of factored transition. To show the optimality of our bounds, we also provide a lower bound for FMDP, which indicates that our algorithm is near-optimal w.r.t. timestep T, horizon H and factored state-action subspace cardinality. Finally, as an application, we study a new formulation of constrained RL, known as RL with knapsack constraints (RLwK), and provides the first sample-efficient algorithm based on FMDP-BF.",
    "One-sentence Summary": "We propose an efficient algorithm with near-optimal regret guarantee for factored MDP, and apply the algorithm to a new formulation of constrained RL.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Unbiased Teacher for Semi-Supervised Object Detection",
    "url": "/forum?id=MJIve1zgR_",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Object Detection",
    "Abstract": "Semi-supervised learning, i.e., training networks with both labeled and unlabeled data, has made significant progress recently. However, existing works have primarily focused on image classification tasks and neglected object detection which requires more annotation effort. In this work, we revisit the Semi-Supervised Object Detection (SS-OD) and identify the pseudo-labeling bias issue in SS-OD. To address this, we introduce Unbiased Teacher, a simple yet effective approach that jointly trains a student and a gradually progressing teacher in a mutually-beneficial manner. Together with a class-balance loss to downweight overly confident pseudo-labels, Unbiased Teacher consistently improved state-of-the-art methods by significant margins on COCO-standard, COCO-additional, and VOC datasets. Specifically, Unbiased Teacher achieves 6.8 absolute mAP improvements against state-of-the-art method when using 1% of labeled data on MS-COCO, achieves around 10 mAP improvements against the supervised baseline when using only 0.5, 1, 2% of labeled data on MS-COCO.",
    "One-sentence Summary": "We propose Unbiased Teacher to jointly address the pseudo-labeling bias issue and the overfitting issue in semi-supervised object detection, and our model performs favorably against existing works on COCO-standard, COCO-additional, and VOC.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "facebookresearch/unbiased-teacher +  1 community implementation",
    "Data": "COCO"
  },
  {
    "title": "MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning",
    "url": "/forum?id=D3PcGLdMx0",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "few-shot learning, episodic training, cross-episode attention",
    "Abstract": "Most recent few-shot learning (FSL) approaches are based on episodic training whereby each episode samples few training instances (shots) per class to imitate the test condition. However, this strict adhering to test condition has a negative side effect, that is, the trained model is susceptible to the poor sampling of few shots. In this work, for the first time, this problem is addressed by exploiting inter-episode relationships. Specifically, a novel meta-learning via modeling episode-level relationships (MELR) framework is proposed. By sampling two episodes containing the same set of classes for meta-training, MELR is designed to ensure that the meta-learned model is robust against the presence of poorly-sampled shots in the meta-test stage. This is achieved through two key components: (1) a Cross-Episode Attention Module (CEAM) to improve the ability of alleviating the effects of poorly-sampled shots, and (2) a Cross-Episode Consistency Regularization (CECR) to enforce that the two classifiers learned from the two episodes are consistent even when there are unrepresentative instances. Extensive experiments for non-transductive standard FSL on two benchmarks show that our MELR achieves 1.0%-5.0% improvements over the baseline (i.e., ProtoNet) used for FSL in our model and outperforms the latest competitors under the same settings.",
    "One-sentence Summary": "This is the first work on explicitly modeling episode-level relationships for few-shot learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "tieredImageNet"
  },
  {
    "title": "Partitioned Learned Bloom Filters",
    "url": "/forum?id=6BRLOfrMhW",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "optimization, data structures, algorithms, theory, learned algorithms",
    "Abstract": "Bloom filters are space-efficient probabilistic data structures that are used to test whether an element is a member of a set, and may return false positives.  Recently, variations referred to as learned Bloom filters were developed that can provide improved performance in terms of the rate of false positives, by using a learned model for the represented set.  However, previous methods for learned Bloom filters do not take full advantage of the learned model.  Here we show how to frame the problem of optimal model utilization as an optimization problem, and using our framework derive algorithms that can achieve near-optimal performance in many cases.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "EMBER"
  },
  {
    "title": "Wasserstein Embedding for Graph Learning",
    "url": "/forum?id=AAes_3W-2z",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Wasserstein, graph embedding, graph-level prediction",
    "Abstract": "We present Wasserstein Embedding for Graph Learning (WEGL), a novel and fast framework for embedding entire graphs in a vector space, in which various machine learning models are applicable for graph-level prediction tasks. We leverage new insights on defining similarity between graphs as a function of the similarity between their node embedding distributions. Specifically, we use the Wasserstein distance to measure the dissimilarity between node embeddings of different graphs. Unlike prior work, we avoid pairwise calculation of distances between graphs and reduce the computational complexity from quadratic to linear in the number of graphs. WEGL calculates Monge maps from a reference distribution to each node embedding and, based on these maps, creates a fixed-sized vector representation of the graph. We evaluate our new graph embedding approach on various benchmark graph-property prediction tasks, showing state-of-the-art classification performance while having superior computational efficiency. The code is available at https://github.com/navid-naderi/WEGL.",
    "One-sentence Summary": "Wasserstein Embedding for Graph Learning (WEGL) is a novel and fast framework for embedding entire graphs into a vector space in which the Euclidean distance between representations approximates the 2-Wasserstein distance.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "navid-naderi/WEGL",
    "Data": "COLLAB, ENZYMES, IMDB-BINARY, IMDB-MULTI, MUTAG, NCI1, OGB, PROTEINS, PTC, REDDIT-5K, Reddit"
  },
  {
    "title": "High-Capacity Expert Binary Networks",
    "url": "/forum?id=MxaY4FzOTa",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Abstract": "Network binarization is a promising hardware-aware direction for creating efficient deep models. Despite its memory and computational advantages, reducing the accuracy gap between binary models and their real-valued counterparts remains an unsolved challenging research problem. To this end, we make the following 3 contributions: (a) To increase model capacity, we propose Expert Binary Convolution, which, for the first time, tailors conditional computing to binary networks by learning to select one data-specific expert binary filter at a time conditioned on input features. (b) To increase representation capacity, we propose to address the inherent information bottleneck in binary networks by introducing an efficient width expansion mechanism which keeps the binary operations within the same budget. (c) To improve network design, we propose a principled binary network growth mechanism that unveils a set of network topologies of favorable properties. Overall, our method improves upon prior work, with no increase in computational cost, by \u223c6%, reaching a groundbreaking \u223c71% on ImageNet classification. Code will be made available here.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "ImageNet"
  },
  {
    "title": "SAFENet: A Secure, Accurate and Fast Neural Network Inference",
    "url": "/forum?id=Cz3dbFm5u-",
    "date": "28 Sept 2020 (modified: 20 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Cryptographic inference, Channel-Wise Approximated Activation, Hyper-Parameter Optimization, Garbled Circuits",
    "Abstract": "The advances in neural networks have driven many companies to provide prediction services to users in a wide range of applications. However, current prediction systems raise privacy concerns regarding the user's private data. A cryptographic neural network inference service is an efficient way to allow two parties to execute neural network inference without revealing either party\u2019s data or model. Nevertheless, existing cryptographic neural network inference services suffer from huge running latency; in particular, the latency of communication-expensive cryptographic activation function is 3 orders of magnitude higher than plaintext-domain activation function. And activations are the necessary components of the modern neural networks. Therefore, slow cryptographic activation has become the primary obstacle of efficient cryptographic inference. \n        \n        In this paper, we propose a new technique, called SAFENet, to enable a Secure, Accurate and Fast nEural Network inference service. To speedup secure inference and guarantee inference accuracy, SAFENet includes channel-wise activation approximation with multiple-degree options. This is implemented by keeping the most useful activation channels and replacing the remaining, less useful, channels with various-degree polynomials. SAFENet also supports mixed-precision activation approximation by automatically assigning different replacement ratios to various layer; further increasing the approximation ratio and reducing inference latency. Our experimental results show SAFENet obtains the state-of-the-art inference latency and performance, reducing latency by 38%\u223c61% or improving accuracy by 1.8%\u223c4% over prior techniques on various encrypted datasets.",
    "One-sentence Summary": "We propose SAFENet that supports automatic channel-wise activation approximation to enable a Secure, Accurate and Fast nEural Network inference service.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Learning Manifold Patch-Based Representations of Man-Made Shapes",
    "url": "/forum?id=Gu5WqN9J3Fn",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "3D shape representations, CAD modeling, sketch-based modeling, computer graphics, computer vision, deep learning",
    "Abstract": "Choosing the right representation for geometry is crucial for making 3D models compatible with existing applications. Focusing on piecewise-smooth man-made shapes, we propose a new representation that is usable in conventional CAD modeling pipelines and can also be learned by deep neural networks. We demonstrate its benefits by applying it to the task of sketch-based modeling. Given a raster image, our system infers a set of parametric surfaces that realize the input in 3D. To capture piecewise smooth geometry, we learn a special shape representation: a deformable parametric template composed of Coons patches. Naively training such a system, however, is hampered by non-manifold artifacts in the parametric shapes and by a lack of data. To address this, we introduce loss functions that bias the network to output non-self-intersecting shapes and implement them as part of a fully self-supervised system, automatically generating both shape templates and synthetic training data. We develop a testbed for sketch-based modeling, demonstrate shape interpolation, and provide comparison to related work.",
    "One-sentence Summary": "We propose a parametrically defined patch-based 3D shape representation that is compatible both with traditional CAD modeling tools and modern deep learning pipelines.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "dmsm/LearningPatches",
    "Data": "ShapeNet"
  },
  {
    "title": "Universal approximation power of deep residual neural networks via nonlinear control theory",
    "url": "/forum?id=-IXhmY16R3M",
    "date": "28 Sept 2020 (modified: 19 Feb 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Deep residual neural networks, universal approximation, nonlinear control theory",
    "Abstract": "In this paper, we explain the universal approximation capabilities of deep residual neural networks through geometric nonlinear control. Inspired by recent work establishing links between residual networks and control systems, we provide a general sufficient condition for a residual network to have the power of universal approximation by asking the activation function, or one of its derivatives, to satisfy a quadratic differential equation. Many activation functions used in practice satisfy this assumption, exactly or approximately, and we show this property to be sufficient for an adequately deep neural network with n+1 neurons per\n        layer to approximate arbitrarily well, on a compact set and with respect to the supremum norm, any continuous function from Rn to Rn. We further show this result to hold for very simple architectures for which the weights only need to assume two values. The first key technical contribution consists of relating the universal approximation problem to controllability of an ensemble of control systems corresponding to a residual network and to leverage classical Lie algebraic techniques to characterize controllability. The second technical contribution is to identify monotonicity as the bridge between controllability of finite ensembles and uniform approximability on compact sets.",
    "One-sentence Summary": "Using nonlinear control theory, it is shown that deep residual neural networks have the power of universal approximation with respect to the supremum norm.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Learning Neural Event Functions for Ordinary Differential Equations",
    "url": "/forum?id=kW_zpEmMLdP",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "differential equations, implicit differentiation, point processes",
    "Abstract": "The existing Neural ODE formulation relies on an explicit knowledge of the termination time. We extend Neural ODEs to implicitly defined termination criteria modeled by neural event functions, which can be chained together and differentiated through. Neural Event ODEs are capable of modeling discrete and instantaneous changes in a continuous-time system, without prior knowledge of when these changes should occur or how many such changes should exist. We test our approach in modeling hybrid discrete- and continuous- systems such as switching dynamical systems and collision in multi-body systems, and we propose simulation-based training of point processes with applications in discrete control.",
    "One-sentence Summary": "We discuss how event handling in ODE solvers can be differentiated through, allowing us to extend Neural ODEs to cases of implicitly defined termination times and enabling learning of discrete events and discontinuous dynamics.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "rtqichen/torchdiffeq"
  },
  {
    "title": "Neural Spatio-Temporal Point Processes",
    "url": "/forum?id=XQQA6-So14",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "point processes, normalizing flows, differential equations",
    "Abstract": "We propose a new class of parameterizations for spatio-temporal point processes which leverage Neural ODEs as a computational method and enable flexible, high-fidelity models of discrete events that are localized in continuous time and space. Central to our approach is a combination of continuous-time neural networks with two novel neural architectures, \\ie, Jump and Attentive Continuous-time Normalizing Flows. This approach allows us to learn complex distributions for both the spatial and temporal domain and to condition non-trivially on the observed event history. We validate our models on data sets from a wide variety of contexts such as seismology, epidemiology, urban mobility, and neuroscience.",
    "One-sentence Summary": "We motivate the use of Continuous-time Normalizing Flows for building spatio-temporal point processes, and discuss modeling conditional dependencies with recurrent- or attention-based Neural ODEs.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "facebookresearch/neural_stpp"
  },
  {
    "title": "Proximal Gradient Descent-Ascent: Variable Convergence under K\u0141 Geometry",
    "url": "/forum?id=LVotkZmYyDi",
    "date": "28 Sept 2020 (modified: 17 Feb 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Kurdyka-\u0141ojasiewicz geometry, minimax, nonconvex, proximal gradient descent-ascent, variable convergence",
    "Abstract": "The gradient descent-ascent (GDA) algorithm has been widely applied to solve minimax optimization problems. In order to achieve convergent policy parameters for minimax optimization, it is important that GDA generates convergent variable sequences rather than convergent sequences of function value or gradient norm. However, the variable convergence of GDA has been proved only under convexity geometries, and it is lack of understanding in general nonconvex minimax optimization. This paper fills such a gap by studying the convergence of a more general proximal-GDA for regularized nonconvex-strongly-concave minimax optimization. Specifically, we show that proximal-GDA admits a novel Lyapunov function, which monotonically decreases in the minimax optimization process and drives the variable sequences to a critical point. By leveraging this Lyapunov function and the KL geometry that parameterizes the local geometries of general nonconvex functions, we formally establish the variable convergence of proximal-GDA to a certain critical point x\u2217, i.e., xt\u2192x\u2217,yt\u2192y\u2217(x\u2217). Furthermore, over the full spectrum of the KL-parameterized geometry, we show that proximal-GDA achieves different types of convergence rates ranging from sublinear convergence up to finite-step convergence, depending on the geometry associated with the KL parameter. This is the first theoretical result on the variable convergence for nonconvex minimax optimization.",
    "One-sentence Summary": "This is the first work on variable convergence of proximal gradient descent-ascent algorithm for nonconvex minimax optimization under ubiquitous Kurdyka-\u0141ojasiewicz geometry.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Adaptive Universal Generalized PageRank Graph Neural Network",
    "url": "/forum?id=n6jl7fLxrP",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Graph Neural Networks, Generalized PageRank, Heterophily, Homophily, Over-smoothing",
    "Abstract": "In many important graph data processing applications the acquired information includes both node features and observations of the graph topology. Graph neural networks (GNNs) are designed to exploit both sources of evidence but they do not optimally trade-off their utility and integrate them in a manner that is also universal. Here, universality refers to independence on homophily or heterophily graph assumptions. We address these issues by introducing a new Generalized PageRank (GPR) GNN architecture that adaptively learns the GPR weights so as to jointly optimize node feature and topological information extraction, regardless of the extent to which the node labels are homophilic or heterophilic. Learned GPR weights automatically adjust to the node label pattern, irrelevant on the type of initialization, and thereby guarantee excellent learning performance for label patterns that are usually hard to handle. Furthermore, they allow one to avoid feature over-smoothing, a process which renders feature information nondiscriminative, without requiring the network to be shallow. Our accompanying theoretical analysis of the GPR-GNN method is facilitated by novel synthetic benchmark datasets generated by the so-called contextual stochastic block model. We also compare the performance of our GNN architecture with that of several state-of-the-art GNNs on the problem of node-classification, using well-known benchmark homophilic and heterophilic datasets. The results demonstrate that GPR-GNN offers significant performance improvement compared to existing techniques on both synthetic and benchmark data.",
    "One-sentence Summary": "We combine generalized PageRank with GNNs to adapt universal node label patterns and the over-smoothing problem.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "jianhao2016/GPRGNN",
    "Data": "Pubmed, Wiki Squirrel"
  },
  {
    "title": "Open Question Answering over Tables and Text",
    "url": "/forum?id=MmCRswl1UYl",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Question Answering, Tabular Data, Open-domain, Retrieval",
    "Abstract": "In open question answering (QA), the answer to a question is produced by retrieving and then analyzing documents that might contain answers to the question.  Most open QA systems have considered only retrieving information from unstructured text.  Here we consider for the first time open QA over {\\em both} tabular and textual data and present a new large-scale dataset \\emph{Open Table-and-Text Question Answering} (OTT-QA) to evaluate performance on this task. Most questions in OTT-QA require multi-hop inference across tabular data and unstructured text, and the evidence required to answer a question can be distributed in different ways over these two types of input, making evidence retrieval challenging---our baseline model using an iterative retriever and BERT-based reader achieves an exact match score less than 10\\%. We then propose two novel techniques to address the challenge of retrieving and aggregating evidence for OTT-QA. The first technique is to use ``early fusion'' to group multiple highly relevant tabular and textual units into a fused block, which provides more context for the retriever to search for.  The second technique is to use a cross-block reader to model the cross-dependency between multiple retrieved evidence with global-local sparse attention. Combining these two techniques improves the score significantly, to above 27\\%.",
    "One-sentence Summary": "We propose the new task of answering open-domain questions answering over web tables and text and design new techniques: 1) fused retrieval 2) cross-block reader to resolve the challenges posed in the new task.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "wenhuchen/OTT-QA",
    "Data": "OTT-QA, HybridQA, Natural Questions"
  },
  {
    "title": "Text Generation by Learning from Demonstrations",
    "url": "/forum?id=RovX-uQ1Hua",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "text generation, learning from demonstrations, nlp",
    "Abstract": "Current approaches to text generation largely rely on autoregressive models and maximum likelihood estimation. This paradigm leads to (i) diverse but low-quality samples due to mismatched learning objective and evaluation metric (likelihood vs. quality) and (ii) exposure bias due to mismatched history distributions (gold vs. model-generated). To alleviate these problems, we frame text generation as an offline reinforcement learning (RL) problem with expert demonstrations (i.e., the reference), where the goal is to maximize quality given model-generated histories. We propose GOLD (generation by off-policy learning from demonstrations): an easy-to-optimize algorithm that learns from the demonstrations by importance weighting. Intuitively, GOLD upweights confident tokens and downweights unconfident ones in the reference during training, avoiding optimization issues faced by prior RL approaches that rely on online data collection. According to both automatic and human evaluation, models trained by GOLD outperform those trained by MLE and policy gradient on summarization, question generation, and machine translation. Further, our models are less sensitive to decoding algorithms and alleviate exposure bias.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "yzpang/gold-off-policy-text-gen-iclr21"
  },
  {
    "title": "Tilted Empirical Risk Minimization",
    "url": "/forum?id=K5YasWXZT3O",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "exponential tilting, models of learning and generalization, label noise robustness, fairness",
    "Abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.",
    "One-sentence Summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "litian96/TERM",
    "Data": "CIFAR-10, MNIST"
  },
  {
    "title": "Explainable Subgraph Reasoning for Forecasting on Temporal Knowledge Graphs",
    "url": "/forum?id=pGIHq1m7PU",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Temporal knowledge graph, future link prediction, graph neural network, subgraph reasoning.",
    "Abstract": "Modeling time-evolving knowledge graphs (KGs) has recently gained increasing interest. Here, graph representation learning has become the dominant paradigm for link prediction on temporal KGs. However, the embedding-based approaches largely operate in a black-box fashion, lacking the ability to interpret their predictions. This paper provides a link forecasting framework that reasons over query-relevant subgraphs of temporal KGs and jointly models the structural dependencies and the temporal dynamics. Especially, we propose a temporal relational attention mechanism and a novel reverse representation update scheme to guide the extraction of an enclosing subgraph around the query. The subgraph is expanded by an iterative sampling of temporal neighbors and by attention propagation. Our approach provides human-understandable evidence explaining the forecast. We evaluate our model on four benchmark temporal knowledge graphs for the link forecasting task. While being more explainable, our model obtains a relative improvement of up to 20 % on Hits@1 compared to the previous best temporal KG forecasting method. We also conduct a survey with 53 respondents, and the results show that the evidence extracted by the model for link forecasting is aligned with human understanding.",
    "One-sentence Summary": "We propose an explainable attention-based reasoning model for predicting future links on temporal knowledge graphs.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "ICEWS"
  },
  {
    "title": "Bayesian Context Aggregation for Neural Processes",
    "url": "/forum?id=ufZN2-aehFa",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Aggregation Methods, Neural Processes, Latent Variable Models, Meta Learning, Multi-task Learning, Deep Sets",
    "Abstract": "Formulating scalable probabilistic regression models with reliable uncertainty estimates has been a long-standing challenge in machine learning research.  Recently, casting probabilistic regression as a multi-task learning problem in terms of conditional latent variable (CLV) models such as the Neural Process (NP) has shown promising results. In this paper, we focus on context aggregation, a central component of such architectures, which fuses information from multiple context data points. So far, this aggregation operation has been treated separately from the inference of a latent representation of the target function in CLV models. Our key contribution is to combine these steps into one holistic mechanism by phrasing context aggregation as a Bayesian inference problem. The resulting Bayesian Aggregation (BA) mechanism enables principled handling of task ambiguity, which is key for efficiently processing context information. We demonstrate on a range of challenging experiments that BA consistently improves upon the performance of traditional mean aggregation while remaining computationally efficient and fully compatible with existing NP-based models.",
    "One-sentence Summary": "We propose a Bayesian Aggregation mechanism for Neural Process-based models which improves upon traditional mean aggregation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Conformation-Guided Molecular Representation with Hamiltonian Neural Networks",
    "url": "/forum?id=q-cnWaaoUTH",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Molecular Representation, Neural Physics Engines, Molecular Dynamics, Graph Neural Networks",
    "Abstract": "Well-designed molecular representations (fingerprints) are vital to combine medical chemistry and deep learning. Whereas incorporating 3D geometry of molecules (i.e. conformations) in their representations seems beneficial, current 3D algorithms are still in infancy. In this paper, we propose a novel molecular representation algorithm which preserves 3D conformations of molecules with a Molecular Hamiltonian Network (HamNet). In HamNet, implicit positions and momentums of atoms in a molecule interact in the Hamiltonian Engine following the discretized Hamiltonian equations. These implicit coordinations are supervised with real conformations with translation- & rotation-invariant losses, and further used as inputs to the Fingerprint Generator, a message-passing neural network. Experiments show that the Hamiltonian Engine can well preserve molecular conformations, and that the fingerprints generated by HamNet achieve state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark.",
    "One-sentence Summary": "We propose a molecular representation algorithm, which preserves molecular conformations with a neural physics engine and generates fingerprints with an MPNN.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "MoleculeNet"
  },
  {
    "title": "Learning with AMIGo: Adversarially Motivated Intrinsic Goals",
    "url": "/forum?id=ETBc_MIMgoX",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "reinforcement learning, exploration, meta-learning",
    "Abstract": "A key challenge for reinforcement learning (RL) consists of learning in environments with sparse extrinsic rewards. In contrast to current RL methods, humans are able to learn new skills with little or no reward by using various forms of intrinsic motivation. We propose AMIGo, a novel agent incorporating -- as form of meta-learning -- a goal-generating teacher that proposes Adversarially Motivated Intrinsic Goals to train a goal-conditioned \"student\" policy in the absence of (or alongside) environment reward. Specifically, through a simple but effective \"constructively adversarial\" objective, the teacher learns to propose increasingly challenging -- yet achievable -- goals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. We show that our method generates a natural curriculum of self-proposed goals which ultimately allows the agent to solve challenging procedurally-generated tasks where other forms of intrinsic motivation and state-of-the-art RL methods fail.",
    "One-sentence Summary": "A \"constructively adversarial\" teacher-student setup can augment on-policy algorithms to better solve difficult exploration tasks in RL.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "maximecb/gym-minigrid +  5 community implementations"
  },
  {
    "title": "Training with Quantization Noise for Extreme Model Compression",
    "url": "/forum?id=dV19Yyi1fS3",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Compression, Efficiency, Product Quantization",
    "Abstract": "We tackle the problem of producing compact models, maximizing their accuracy for a given model size. A standard solution is to train networks with Quantization Aware Training, where the weights are quantized during training and the gradients approximated with the Straight-Through Estimator. In this paper, we extend this approach to work with extreme compression methods where the approximations introduced by STE are severe. Our proposal is to only quantize a different random subset of weights during each forward, allowing for unbiased gradients to flow through the other weights. Controlling the amount of noise and its form allows for extreme compression rates while maintaining the performance of the original model. As a result we establish new state-of-the-art compromises between accuracy and model size both in natural language processing and image classification. For example, applying our method to state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5% accuracy on MNLI by compressing RoBERTa to 14 MB and 80.0% top-1 accuracy on ImageNet by compressing an EfficientNet-B3 to 3.3 MB.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "pytorch/fairseq +  2 community implementations",
    "Data": "ImageNet, WikiText-103"
  },
  {
    "title": "Interpreting and Boosting Dropout from a Game-Theoretic View",
    "url": "/forum?id=Jacdvfjicf7",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Dropout, Interpretability, Interactions",
    "Abstract": "This paper aims to understand and improve the utility of the dropout operation from the perspective of game-theoretical interactions. We prove that dropout can suppress the strength of interactions between input variables of deep neural networks (DNNs). The theoretical proof is also verified by various experiments. Furthermore, we find that such interactions were strongly related to the over-fitting problem in deep learning. So, the utility of dropout can be regarded as decreasing interactions to alleviating the significance of over-fitting. Based on this understanding, we propose the interaction loss to further improve the utility of dropout. Experimental results on various DNNs and datasets have shown that the interaction loss can effectively improve the utility of dropout and boost the performance of DNNs.",
    "One-sentence Summary": "We prove and improve the utility of the dropout operation from a game-theoretic view.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, CelebA, MNIST, Tiny ImageNet"
  },
  {
    "title": "VTNet: Visual Transformer Network for Object Goal Navigation",
    "url": "/forum?id=DILxQP08O3B",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Abstract": "Object goal navigation aims to steer an agent towards a target object based on observations of the agent. It is of pivotal importance to design effective visual representations of the observed scene in determining navigation actions.  In this paper, we introduce a Visual Transformer Network (VTNet) for learning informative visual representation in navigation.  VTNet is a highly effective structure that embodies two key properties for visual representations: First, the relationships among all the object instances in a scene are exploited; Second, the spatial locations of objects and image regions are emphasized so that directional navigation signals can be learned. Furthermore, we also develop a pre-training scheme to associate the visual representations with navigation signals, and thus facilitate navigation policy learning. In a nutshell, VTNet embeds object and region features with their location cues as spatial-aware descriptors and then incorporates all the encoded descriptors through attention operations to achieve informative representation for navigation. Given such visual representations, agents are able to explore the correlations between visual observations and navigation actions. For example, an agent would prioritize ``turning right'' over ``turning left'' when the visual representation emphasizes on the right side of activation map. Experiments in the artificial environment AI2-Thor demonstrate that VTNet significantly outperforms state-of-the-art methods in unseen testing environments.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "AI2-THOR"
  },
  {
    "title": "Exemplary Natural Images Explain CNN Activations Better than State-of-the-Art Feature Visualization",
    "url": "/forum?id=QO9-y8also-",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "evaluation of interpretability, feature visualization, activation maximization, human psychophysics, understanding CNNs, explanation method",
    "Abstract": "Feature visualizations such as synthetic maximally activating images are a widely used explanation method to better understand the information processing of convolutional neural networks (CNNs). At the same time, there are concerns that these visualizations might not accurately represent CNNs' inner workings. Here, we measure how much extremely activating images help humans to predict CNN activations.\n        Using a well-controlled psychophysical paradigm, we compare the informativeness of synthetic images by Olah et al. (2017) with a simple baseline visualization, namely exemplary natural images that also strongly activate a specific feature map. Given either synthetic or natural reference images, human participants choose which of two query images leads to strong positive activation. The experiment is designed to maximize participants' performance, and is the first to probe intermediate instead of final layer representations. We find that synthetic images indeed provide helpful information about feature map activations (82\u00b14% accuracy; chance would be 50%). However, natural images --- originally intended to be a baseline --- outperform these synthetic images by a wide margin (92\u00b12%). Additionally, participants are faster and more confident for natural images, whereas subjective impressions about the interpretability of the feature visualizations by Olah et al. (2017) are mixed. The higher informativeness of natural images holds across most layers, for both expert and lay participants as well as for hand- and randomly-picked feature visualizations. Even if only a single reference image is given, synthetic images provide less information than natural images (65\u00b15% vs. 73\u00b14%). In summary, synthetic images from a popular feature visualization method are significantly less informative for assessing CNN activations than natural images. We argue that visualization methods should improve over this simple baseline.",
    "One-sentence Summary": "Using human psychophysical experiments, we show that natural images can be significantly more informative for interpreting neural network activations than a state-of-the-art synthetic feature visualization.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "ImageNet"
  },
  {
    "title": "Multi-Class Uncertainty Calibration via Mutual Information Maximization-based Binning",
    "url": "/forum?id=AICNpd8ke-m",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "uncertainty calibration, post-hoc calibration, histogram binning, mutual information, deep neural networks",
    "Abstract": "Post-hoc multi-class calibration is a common approach for providing high-quality confidence estimates of deep neural network predictions. Recent work has shown that widely used scaling methods underestimate their calibration error, while alternative Histogram Binning (HB) methods often fail to preserve classification accuracy. When classes have small prior probabilities, HB also faces the issue of severe sample-inefficiency after the conversion into K one-vs-rest class-wise calibration problems. The goal of this paper is to resolve the identified issues of HB in order to provide calibrated confidence estimates using only a small holdout calibration dataset for bin optimization while preserving multi-class ranking accuracy. From an information-theoretic perspective, we derive the I-Max concept for binning, which maximizes the mutual information between labels and quantized logits. This concept mitigates potential loss in ranking performance due to lossy quantization, and by disentangling the optimization of bin edges and representatives allows simultaneous improvement of ranking and calibration performance. To improve the sample efficiency and estimates from a small calibration set, we propose a shared class-wise (sCW) calibration strategy, sharing one calibrator among similar classes (e.g., with similar class priors) so that the training sets of their class-wise calibration problems can be merged to train the single calibrator. The combination of sCW and I-Max binning outperforms the state of the art calibration methods on various evaluation metrics across different benchmark datasets and models, using a small calibration set (e.g., 1k samples for ImageNet).",
    "One-sentence Summary": "We propose I-Max binning, a novel method for multi-class calibration, improving over previous methods in terms of various ECE measures",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "boschresearch/imax-calibration",
    "Data": "CIFAR-100, ImageNet"
  },
  {
    "title": "A Discriminative Gaussian Mixture Model with Sparsity",
    "url": "/forum?id=-_Zp7r2-cGK",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "classification, sparse Bayesian learning, Gaussian mixture model",
    "Abstract": "In probabilistic classification, a discriminative model based on the softmax function has a potential limitation in that it assumes unimodality for each class in the feature space. The mixture model can address this issue, although it leads to an increase in the number of parameters. We propose a sparse classifier based on a discriminative GMM, referred to as a sparse discriminative Gaussian mixture (SDGM). In the SDGM, a GMM-based discriminative model is trained via sparse Bayesian learning. Using this sparse learning framework, we can simultaneously remove redundant Gaussian components and reduce the number of parameters used in the remaining components during learning; this learning method reduces the model complexity, thereby improving the generalization capability. Furthermore, the SDGM can be embedded into neural networks (NNs), such as convolutional NNs, and can be trained in an end-to-end manner. Experimental results demonstrated that the proposed method outperformed the existing softmax-based discriminative models.",
    "One-sentence Summary": "A sparse classifier based on a discriminative Gaussian mixture model, which can also be embedded into a neural network.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, CIFAR-100, Fashion-MNIST, MNIST"
  },
  {
    "title": "Trusted Multi-View Classification",
    "url": "/forum?id=OOsR8BzCnl5",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Multi-Modal Learning, Multi-View Learning, Uncertainty Machine Learning",
    "Abstract": "Multi-view classification (MVC) generally focuses on improving classification accuracy by using information from different views, typically integrating them into a unified comprehensive representation for downstream tasks. However, it is also crucial to dynamically assess the quality of a view for different samples in order to provide reliable uncertainty estimations, which indicate whether predictions can be trusted. To this end, we propose a novel multi-view classification method, termed trusted multi-view classification, which provides a new paradigm for multi-view learning by dynamically integrating different views at an evidence level. The algorithm jointly utilizes multiple views to promote both classification reliability (uncertainty estimation during testing) and robustness (out-of-distribution-awareness during training) by integrating evidence from each view. To achieve this, the Dirichlet distribution is used to model the distribution of the class probabilities, parameterized with evidence from different views and integrated with the Dempster-Shafer theory. The unified learning framework induces accurate uncertainty and accordingly endows the model with both reliability and robustness for out-of-distribution samples. Extensive experimental results validate the effectiveness of the proposed model in accuracy, reliability and robustness.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "hanmenghan/TMC +  1 community implementation"
  },
  {
    "title": "IEPT: Instance-Level and Episode-Level Pretext Tasks for Few-Shot Learning",
    "url": "/forum?id=xzqLpqRzxLq",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "few-shot learning, self-supervised learning, episode-level pretext task",
    "Abstract": "The need of collecting large quantities of labeled training data for each new task has limited the usefulness of deep neural networks. Given data from a set of source tasks, this limitation can be overcome using two transfer learning approaches: few-shot learning (FSL) and self-supervised learning (SSL). The former aims to learn `how to learn' by designing learning episodes using source tasks to simulate the challenge of solving the target new task with few labeled samples. In contrast, the latter exploits an annotation-free pretext task across all source tasks in order to learn generalizable feature representations. In this work, we propose a novel Instance-level and Episode-level Pretext Task (IEPT) framework that seamlessly integrates SSL into FSL. Specifically, given an FSL episode, we first apply geometric transformations to each instance to generate extended episodes. At the instance-level, transformation recognition is performed as per standard SSL. Importantly, at the episode-level, two SSL-FSL hybrid learning objectives are devised: (1) The consistency across the predictions of an FSL classifier from different extended episodes is maximized as an episode-level pretext task. (2) The features extracted from each instance across different episodes are integrated to construct a single FSL classifier for meta-learning. Extensive experiments show that our proposed model (i.e., FSL with IEPT) achieves the new state-of-the-art.",
    "One-sentence Summary": "This paper proposes a novel Instance-level and Episode-level Pretext Task (IEPT) framework that seamlessly integrates SSL into FSL.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "rucmlcv/IEPT_FSL",
    "Data": "tieredImageNet"
  },
  {
    "title": "Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation",
    "url": "/forum?id=KpfasTaLUpq",
    "date": "28 Sept 2020 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Machine Translation, Sequence Modeling, Natural Language Processing",
    "Abstract": "Much recent effort has been invested in non-autoregressive neural machine translation, which appears to be an efficient alternative to state-of-the-art autoregressive machine translation on modern GPUs.  In contrast to the latter, where generation is sequential, the former allows generation to be parallelized across target token positions. Some of the latest non-autoregressive models have achieved impressive translation quality-speed tradeoffs compared to autoregressive baselines. In this work, we reexamine this tradeoff and argue that autoregressive baselines can be substantially sped up without loss in accuracy. Specifically, we study autoregressive models with encoders and decoders of varied depths. Our extensive experiments show that given a sufficiently deep encoder, a single-layer autoregressive decoder can substantially outperform strong non-autoregressive models with comparable inference speed. We show that the speed disadvantage for autoregressive baselines compared to non-autoregressive methods has been overestimated in three aspects: suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation. Our results establish a new protocol for future research toward fast, accurate machine translation. Our code is available at https://github.com/jungokasai/deep-shallow.",
    "One-sentence Summary": "We show that the speed disadvantage for autoregressive baselines to evaluate non-autoregressive machine translation is overestimated in three aspects: suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "jungokasai/deep-shallow +  1 community implementation",
    "Data": "WMT 2014, WMT 2016"
  },
  {
    "title": "Effective Abstract Reasoning with Dual-Contrast Network",
    "url": "/forum?id=ldxlzGYWDmW",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "abstract reasoning, raven's progressive matrices, deep learning",
    "Abstract": "As a step towards improving the abstract reasoning capability of machines, we aim to solve Raven\u2019s Progressive Matrices (RPM) with neural networks, since solving RPM puzzles is highly correlated with human intelligence. Unlike previous methods that use auxiliary annotations or assume hidden rules to produce appropriate feature representation, we only use the ground truth answer of each question for model learning,  aiming for an intelligent agent to have a strong learning capability with a small amount of supervision.  Based on the RPM problem formulation,  the correct answer filled into the missing entry of the third row/column has  to  best  satisfy  the  same  rules  shared  between  the  first  two  rows/columns.Thus  we  design  a  simple  yet  effective  Dual-Contrast  Network  (DCNet)  to  exploit the inherent structure of RPM puzzles.  Specifically, a rule contrast module is  designed  to  compare  the  latent  rules  between  the  filled  row/column  and  the first two rows/columns; a choice contrast module is designed to increase the relative differences between candidate choices.  Experimental results on the RAVEN and  PGM  datasets  show  that  DCNet  outperforms  the  state-of-the-art  methods by a large margin of 5.77%.   Further experiments on few training samples and model generalization also show the effectiveness of DCNet.  Code is available at https://github.com/visiontao/dcnet.",
    "One-sentence Summary": "We propose a simple yet effective Dual-Contrast Network (DCNet) to solve Raven's progressive matrices without using auxiliary annotations and assumptions.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "AbstractReasoning, PGM, RAVEN, Visual Question Answering"
  },
  {
    "title": "On Position Embeddings in BERT",
    "url": "/forum?id=onxoVA9FxMw",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Position Embedding, BERT, pretrained language model.",
    "Abstract": "Various Position Embeddings (PEs) have been proposed in Transformer based architectures~(e.g. BERT) to model word order. These are empirically-driven and perform well, but no formal framework exists to systematically study them. To address this, we present three properties of PEs that capture word distance in vector space:  translation invariance, monotonicity, and  symmetry. These properties formally capture the behaviour of PEs and allow us to reinterpret sinusoidal PEs in a principled way.\n        Moreover, we propose a new probing test (called `identical word probing') and  mathematical  indicators to quantitatively detect the general  attention patterns with respect to the above properties. An empirical evaluation of seven PEs (and their combinations) for classification (GLUE) and span prediction (SQuAD) shows that: (1) both  classification and span prediction benefit from  translation invariance and local monotonicity, while symmetry slightly decreases performance;\n        (2) The fully-learnable absolute PE performs better in classification, while relative PEs perform better in span prediction.  We contribute the first formal and quantitative analysis of desiderata for PEs, and  a principled discussion about their correlation to the performance of typical downstream tasks.",
    "One-sentence Summary": "This paper amis to understand and evaluate position embeddings, especially in pretrain language models",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "GLUE, SQuAD"
  },
  {
    "title": "Neural Pruning via Growing Regularization",
    "url": "/forum?id=o966_Is_nPA",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "model compression, deep neural network pruning, Hessian matrix, regularization",
    "Abstract": "Regularization has long been utilized to learn sparsity in deep neural network pruning. However, its role is mainly explored in the small penalty strength regime. In this work, we extend its application to a new scenario where the regularization grows large gradually to tackle two central problems of pruning: pruning schedule and weight importance scoring. (1) The former topic is newly brought up in this work, which we find critical to the pruning performance while receives little research attention. Specifically, we propose an L2 regularization variant with rising penalty factors and show it can bring significant accuracy gains compared with its one-shot counterpart, even when the same weights are removed. (2) The growing penalty scheme also brings us an approach to exploit the Hessian information for more accurate pruning without knowing their specific values, thus not bothered by the common Hessian approximation problems. Empirically, the proposed algorithms are easy to implement and scalable to large datasets and networks in both structured and unstructured pruning. Their effectiveness is demonstrated with modern deep neural networks on the CIFAR and ImageNet datasets, achieving competitive results compared to many state-of-the-art algorithms. Our code and trained models are publicly available at https://github.com/mingsun-tse/regularization-pruning.",
    "One-sentence Summary": "We propose two new deep network pruning algorithms based a growing regularization paradigm.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "mingsun-tse/regularization-pruning",
    "Data": "CIFAR-10, CIFAR-100, ImageNet"
  },
  {
    "title": "Mixed-Features Vectors and Subspace Splitting",
    "url": "/forum?id=l-LGlk4Yl6G",
    "date": "28 Sept 2020 (modified: 16 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Abstract": "Motivated by metagenomics, recommender systems, dictionary learning, and related problems, this paper introduces subspace splitting(SS): the task of clustering the entries of what we call amixed-features vector, that is, a vector whose subsets of coordinates agree with a collection of subspaces. We derive precise identifiability conditions under which SS is well-posed, thus providing the first fundamental theory for this problem. We also propose the first three practical SS algorithms, each with advantages and disadvantages: a random sampling method , a projection-based greedy heuristic , and an alternating Lloyd-type algorithm ; all allow noise, outliers, and missing data. Our extensive experiments outline the performance of our algorithms, and in lack of other SS algorithms, for reference we compare against methods for tightly related problems, like robust matched subspace detection and maximum feasible subsystem, which are special simpler cases of SS.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Hierarchical Reinforcement Learning by Discovering Intrinsic Options",
    "url": "/forum?id=r-gPPHEjpmw",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "hierarchical reinforcement learning, reinforcement learning, options, unsupervised skill discovery, exploration",
    "Abstract": "We propose a hierarchical reinforcement learning method, HIDIO, that can learn task-agnostic options in a self-supervised manner while jointly learning to utilize them to solve sparse-reward tasks. Unlike current hierarchical RL approaches that tend to formulate goal-reaching low-level tasks or pre-define ad hoc lower-level policies, HIDIO encourages lower-level option learning that is independent of the task at hand, requiring few assumptions or little knowledge about the task structure. These options are learned through an intrinsic entropy minimization objective conditioned on the option sub-trajectories. The learned options are diverse and task-agnostic. In experiments on sparse-reward robotic manipulation and navigation tasks, HIDIO achieves higher success rates with greater sample efficiency than regular RL baselines and two state-of-the-art hierarchical RL methods. Code at: https://github.com/jesbu1/hidio.",
    "One-sentence Summary": "Hierarchical RL that discovers short-horizon task-agnostic options to perform well on sparse reward manipulation and navigation tasks.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "jesbu1/hidio"
  },
  {
    "title": "Sharper Generalization Bounds for Learning with Gradient-dominated Objective Functions",
    "url": "/forum?id=r28GdiQF7vM",
    "date": "28 Sept 2020 (modified: 25 Oct 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "generalization bounds, non-convex learning",
    "Abstract": "Stochastic optimization has become the workhorse behind many successful machine learning applications, which motivates a lot of theoretical analysis to understand its empirical behavior. As a comparison, there is far less work to study the generalization behavior especially in a non-convex learning setting. In this paper, we study the generalization behavior of stochastic optimization by leveraging the algorithmic stability for learning with \u03b2-gradient-dominated objective functions. We develop generalization bounds of the order O(1/(n\u03b2)) plus the convergence rate of the optimization algorithm, where n is the sample size. Our stability analysis significantly improves the existing non-convex analysis by removing the bounded gradient assumption and implying better generalization bounds. We achieve this improvement by exploiting the smoothness of loss functions instead of the Lipschitz condition in Charles & Papailiopoulos (2018). We apply our general results to various stochastic optimization algorithms, which show clearly how the variance-reduction techniques improve not only training but also generalization. Furthermore, our discussion explains how interpolation helps generalization for highly expressive models.",
    "One-sentence Summary": "We develop sharper generalization bounds for learning with gradient-dominated objective functions.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Representation Learning for Sequence Data with Deep Autoencoding Predictive Components",
    "url": "/forum?id=Naqw7EHIfrv",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Mutual Information, Unsupervised Learning, Sequence Data, Masked Reconstruction",
    "Abstract": "We propose Deep Autoencoding Predictive Components (DAPC) -- a self-supervised representation learning method for sequence data, based on the intuition that useful representations of sequence data should exhibit a simple structure in the latent space. We encourage this latent structure by maximizing an estimate of \\emph{predictive information} of latent feature sequences, which is the mutual information between the past and future windows at each time step. In contrast to the mutual information lower bound commonly used by contrastive learning, the estimate of predictive information we adopt is exact under a Gaussian assumption. Additionally, it can be computed without negative sampling. To reduce the degeneracy of the latent space extracted by powerful encoders and keep useful information from the inputs, we regularize predictive information learning with a challenging masked reconstruction loss. We demonstrate that our method recovers the latent space of noisy dynamical systems, extracts predictive features for forecasting tasks, and improves automatic speech recognition when used to pretrain the encoder on large amounts of unlabeled data.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "JunwenBai/DAPC +  1 community implementation",
    "Data": "LibriSpeech"
  },
  {
    "title": "Average-case Acceleration for Bilinear Games and Normal Matrices",
    "url": "/forum?id=H0syOoy3Ash",
    "date": "28 Sept 2020 (modified: 16 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Smooth games, First-order Methods, Acceleration, Bilinear games, Average-case Analysis, Orthogonal Polynomials",
    "Abstract": "Advances in generative modeling and adversarial learning have given rise to renewed interest in smooth games. However, the absence of symmetry in the matrix of second derivatives poses challenges that are not present in the classical minimization framework. While a rich theory of average-case analysis has been developed for minimization problems, little is known in the context of smooth games. In this work we take a first step towards closing this gap by developing average-case optimal first-order methods for a subset of smooth games. \n        We make the following three main contributions. First, we show that for zero-sum bilinear games the average-case optimal method is the optimal method for the minimization of the Hamiltonian. Second, we provide an explicit expression for the optimal method corresponding to normal matrices, potentially non-symmetric. Finally, we specialize it to matrices with eigenvalues located in a disk and show a provable speed-up compared to worst-case optimal algorithms. We illustrate our findings through benchmarks with a varying degree of mismatch with our assumptions.",
    "One-sentence Summary": "We extend the framework of average-case optimal first-order methods to problems with non-symmetric matrices, which naturally arise in equilibrium finding for games.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Learning Task-General Representations with Generative Neuro-Symbolic Modeling",
    "url": "/forum?id=qzBUIzq5XR2",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "few-shot concept learning, neuro-symbolic models, probabilistic programs, generative models",
    "Abstract": "People can learn rich, general-purpose conceptual representations from only raw perceptual inputs. Current machine learning approaches fall well short of these human standards, although different modeling traditions often have complementary strengths. Symbolic models can capture the compositional and causal knowledge that enables flexible generalization, but they struggle to learn from raw inputs, relying on strong abstractions and simplifying assumptions. Neural network models can learn directly from raw data, but they struggle to capture compositional and causal structure and typically must retrain to tackle new tasks. We bring together these two traditions to learn generative models of concepts that capture rich compositional and causal structure, while learning from raw data. We develop a generative neuro-symbolic (GNS) model of handwritten character concepts that uses the control flow of a probabilistic program, coupled with symbolic stroke primitives and a symbolic image renderer, to represent the causal and compositional processes by which characters are formed. The distributions of parts (strokes), and correlations between parts, are modeled with neural network subroutines, allowing the model to learn directly from raw data and express nonparametric statistical relationships. We apply our model to the Omniglot challenge of human-level concept learning, using a background set of alphabets to learn an expressive prior distribution over character drawings. In a subsequent evaluation, our GNS model uses probabilistic inference to learn rich conceptual representations from a single training image that generalize to 4 unique tasks, succeeding where previous work has fallen short.",
    "One-sentence Summary": "few-shot concept learning with generative neuro-symbolic models",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "rfeinman/GNS-Modeling"
  },
  {
    "title": "Is Label Smoothing Truly Incompatible with Knowledge Distillation: An Empirical Study",
    "url": "/forum?id=PObuuGVrGaZ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "label smoothing, knowledge distillation, image classification, neural machine translation, binary neural networks",
    "Abstract": "This work aims to empirically clarify a recently discovered perspective that label smoothing is incompatible with knowledge distillation. We begin by introducing the motivation behind on how this incompatibility is raised, i.e., label smoothing erases relative information between teacher logits. We provide a novel connection on how label smoothing affects distributions of semantically similar and dissimilar classes. Then we propose a metric to quantitatively measure the degree of erased information in sample's representation. After that, we study its one-sidedness and imperfection of the incompatibility view through massive analyses, visualizations and comprehensive experiments on Image Classification, Binary Networks, and Neural Machine Translation. Finally, we broadly discuss several circumstances wherein label smoothing will indeed lose its effectiveness.",
    "One-sentence Summary": "This work empirically clarifies a recently discovered perspective that label smoothing is incompatible with knowledge distillation. Project page: http://zhiqiangshen.com/projects/LS_and_KD/index.html.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CUB-200-2011, ImageNet, ImageNet-LT, Places, iNaturalist"
  },
  {
    "title": "The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels Methods",
    "url": "/forum?id=aYuZO9DIdnn",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "convolutional kernel methods, image classification",
    "Abstract": "A recent line of work showed that  various forms of convolutional  kernel methods can be competitive with standard supervised deep convolutional networks on datasets like CIFAR-10, obtaining accuracies in the range of 87-90% while being more amenable to theoretical analysis. In this work, we highlight the importance of a data-dependent feature extraction step that is key to the obtain good performance in convolutional kernel methods. This step typically corresponds to a whitened dictionary of patches, and gives rise to a data-driven convolutional kernel methods.We extensively study its effect, demonstrating it is the key ingredient for high performance of these methods. Specifically, we show that one of the simplest instances of such kernel methods, based on a single layer of  image patches followed by a linear classifier is already obtaining classification accuracies on CIFAR-10 in the same range as previous more sophisticated convolutional kernel methods. We scale this method to the challenging ImageNet dataset, showing such a simple approach can exceed all existing non-learned representation methods. This is a new baseline for object recognition without representation learning methods, that  initiates the investigation of  convolutional kernel models  on ImageNet. We conduct experiments to analyze the dictionary that we used, our ablations showing they exhibit low-dimensional properties.",
    "One-sentence Summary": "Patch-based representation is a key ingredient for competitive convolutional kernel methods.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "ImageNet-32"
  },
  {
    "title": "Graph Coarsening with Neural Networks",
    "url": "/forum?id=uxpzitPEooJ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "graph coarsening, graph neural network, Doubly-weighted Laplace operator",
    "Abstract": "As large scale-graphs become increasingly more prevalent, it poses significant computational challenges to process, extract and analyze large graph data. Graph coarsening is one popular technique to reduce the size of a graph while maintaining essential properties. Despite rich graph coarsening literature, there is only limited exploration of data-driven method in the field. In this work, we leverage the recent progress of deep learning on graphs for graph coarsening. We first propose a framework for measuring the quality of coarsening algorithm and show that depending on the goal, we need to carefully choose the Laplace operator on the coarse graph and associated projection/lift operators. Motivated by the observation that the current choice of edge weight for the coarse graph may be sub-optimal, we parametrize the weight assignment map with graph neural networks and train it to improve the coarsening quality in an unsupervised way. Through extensive experiments on both synthetic and real networks, we demonstrate that our method significantly improves common graph coarsening methods under various metrics, reduction ratios, graph sizes, and graph types. It generalizes to graphs of larger size (more than 25\u00d7 of training graphs), adaptive to different losses (both differentiable and non-differentiable), and scales to much larger graphs than previous work.",
    "One-sentence Summary": "We significantly improve the quality of existing graph coarsening algorithms with graph neural network.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "Pubmed"
  },
  {
    "title": "On the Universality of the Double Descent Peak in Ridgeless Regression",
    "url": "/forum?id=0IO5VdnSAaH",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Double Descent, Interpolation Peak, Linear Regression, Random Features, Random Weights Neural Networks",
    "Abstract": "We prove a non-asymptotic distribution-independent lower bound for the expected mean squared generalization error caused by label noise in ridgeless linear regression. Our lower bound generalizes a similar known result to the overparameterized (interpolating) regime. In contrast to most previous works, our analysis applies to a broad class of input distributions with almost surely full-rank feature matrices, which allows us to cover various types of deterministic or random feature maps. Our lower bound is asymptotically sharp and implies that in the presence of label noise, ridgeless linear regression does not perform well around the interpolation threshold for any of these feature maps. We analyze the imposed assumptions in detail and provide a theory for analytic (random) feature maps. Using this theory, we can show that our assumptions are satisfied for input distributions with a (Lebesgue) density and feature maps given by random deep neural networks with analytic activation functions like sigmoid, tanh, softplus or GELU. As further examples, we show that feature maps from random Fourier features and polynomial kernels also satisfy our assumptions. We complement our theory with further experimental and analytic results.",
    "One-sentence Summary": "We prove a distribution-independent lower bound for the generalization error of ridgeless (random) features regression under weak assumptions, showing universal sensitivity to label noise around the interpolation threshold.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "dholzmueller/universal_double_descent"
  },
  {
    "title": "Deep Repulsive Clustering of Ordered Data Based on Order-Identity Decomposition",
    "url": "/forum?id=Yz-XtK5RBxB",
    "date": "28 Sept 2020 (modified: 12 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Clustering, order learning, age estimation, aesthetic assessment, historical color image classification",
    "Abstract": "We propose the deep repulsive clustering (DRC) algorithm of ordered data for effective order learning. First, we develop the order-identity decomposition (ORID) network to divide the information of an object instance into an order-related feature and an identity feature. Then, we group object instances into clusters according to their identity features using a repulsive term. Moreover, we estimate the rank of a test instance, by comparing it with references within the same cluster. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively and also yield excellent rank estimation performance.",
    "One-sentence Summary": "A deep clustering algorithm for ordered data is proposed based on the order-identity decomposition.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Rapid Task-Solving in Novel Environments",
    "url": "/forum?id=F-mvpFpn_0q",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "deep reinforcement learning, meta learning, deep learning, exploration, planning",
    "Abstract": "We propose the challenge of rapid task-solving in novel environments (RTS), wherein an agent must solve a series of tasks as rapidly as possible in an unfamiliar environment. An effective RTS agent must balance between exploring the unfamiliar environment and solving its current task, all while building a model of the new environment over which it can plan when faced with later tasks. While modern deep RL agents exhibit some of these abilities in isolation, none are suitable for the full RTS challenge. To enable progress toward RTS, we introduce two challenge domains: (1) a minimal RTS challenge called the Memory&Planning Game and (2) One-Shot StreetLearn Navigation, which introduces scale and complexity from real-world data. We demonstrate that state-of-the-art deep RL agents fail at RTS in both domains, and that this failure is due to an inability to plan over gathered knowledge. We develop Episodic Planning Networks (EPNs) and show that deep-RL agents with EPNs excel at RTS, outperforming the nearest baseline by factors of 2-3 and learning to navigate held-out StreetLearn maps within a single episode. We show that EPNs learn to execute a value iteration-like planning algorithm and that they generalize to situations beyond their training experience.",
    "One-sentence Summary": "Our agents meta-learn to explore, build models on-the-fly, and plan, enabling them to rapidly solve sequences of tasks in unfamiliar environments.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "StreetLearn"
  },
  {
    "title": "DINO: A Conditional Energy-Based GAN for Domain Translation",
    "url": "/forum?id=WAISmwsqDsb",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Generative Modelling, Domain Translation, Conditional GANs, Energy-Based GANs",
    "Abstract": "Domain translation is the process of transforming data from one domain to another while preserving the common semantics. Some of the most popular domain translation systems are based on conditional generative adversarial networks, which use source domain data to drive the generator and as an input to the discriminator. However, this approach does not enforce the preservation of shared semantics since the conditional input can often be ignored by the discriminator. We propose an alternative method for conditioning and present a new framework, where two networks are simultaneously trained, in a supervised manner, to perform domain translation in opposite directions. Our method is not only better at capturing the shared information between two domains but is more generic and can be applied to a broader range of problems. The proposed framework performs well even in challenging cross-modal translations, such as video-driven speech reconstruction, for which other systems struggle to maintain correspondence.",
    "One-sentence Summary": "A framework  for domain translation which uses a novel mechanism for conditioning energy-based GANs.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "DinoMan/DINO",
    "Data": "CelebAMask-HQ, Cityscapes"
  },
  {
    "title": "Removing Undesirable Feature Contributions Using Out-of-Distribution Data",
    "url": "/forum?id=eIHYL6fpbkA",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "adversarial training, adversarial robustness, generalization, out-of-distribution",
    "Abstract": "Several data augmentation methods deploy unlabeled-in-distribution (UID) data to bridge the gap between the training and inference of neural networks. However, these methods have clear limitations in terms of availability of UID data and dependence of algorithms on pseudo-labels. Herein, we propose a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. We show how to improve generalization theoretically using OOD data in each learning scenario and complement our theoretical analysis with experiments on CIFAR-10, CIFAR-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view. We also present the advantages of the proposed method through comparison with other data augmentation methods, which can be used in the absence of UID data. Furthermore, we demonstrate that the proposed method can further improve the existing state-of-the-art adversarial training.",
    "One-sentence Summary": "We propose a simple method, Out-of-distribution data Augmented Training (OAT), to leverage OOD data for adversarial and standard learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "Saehyung-Lee/OAT",
    "Data": "CIFAR-10, CIFAR-100, ImageNet, Places, SVHN"
  },
  {
    "title": "Accurate Learning of Graph Representations with Graph Multiset Pooling",
    "url": "/forum?id=JHcqXGaqiGn",
    "date": "28 Sept 2020 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Graph representation learning, Graph pooling",
    "Abstract": "Graph neural networks have been widely used on modeling graph data, achieving impressive results on node classification and link prediction tasks. Yet, obtaining an accurate representation for a graph further requires a pooling function that maps a set of node representations into a compact form. A simple sum or average over all node representations considers all node features equally without consideration of their task relevance, and any structural dependencies among them. Recently proposed hierarchical graph pooling methods, on the other hand, may yield the same representation for two different graphs that are distinguished by the Weisfeiler-Lehman test, as they suboptimally preserve information from the node features. To tackle these limitations of existing graph pooling methods, we first formulate the graph pooling problem as a multiset encoding problem with auxiliary information about the graph structure, and propose a Graph Multiset Transformer (GMT) which is a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. We show that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods can be easily extended to the previous node clustering approaches for hierarchical graph pooling. Our experimental results show that GMT significantly outperforms state-of-the-art graph pooling methods on graph classification benchmarks with high memory and time efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks.",
    "One-sentence Summary": "A novel graph pooling method for graph representation learning, that considers multiset with attention-based operations.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "JinheonBaek/GMT",
    "Data": "AIDS Antiviral Screen, CLUSTER, COLLAB, IMDB-BINARY, IMDB-MULTI, MUTAG, OGB, PROTEINS, Tox21, ZINC"
  },
  {
    "title": "Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning",
    "url": "/forum?id=ce6CFXBh30h",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Federated Learning",
    "Abstract": "While existing federated learning approaches mostly require that clients have fully-labeled data to train on, in realistic settings, data obtained at the client-side often comes without any accompanying labels. Such deficiency of labels may result from either high labeling cost, or difficulty of annotation due to the requirement of expert knowledge. Thus the private data at each client may be either partly labeled, or completely unlabeled with labeled data being available only at the server, which leads us to a new practical federated learning problem, namely Federated Semi-Supervised Learning (FSSL). In this work, we study two essential scenarios of FSSL based on the location of the labeled data. The first scenario considers a conventional case where clients have both labeled and unlabeled data (labels-at-client), and the second scenario considers a more challenging case, where the labeled data is only available at the server (labels-at-server). We then propose a novel method to tackle the problems, which we refer to as Federated Matching (FedMatch). FedMatch improves upon naive combinations of federated learning and semi-supervised learning approaches with a new inter-client consistency loss and decomposition of the parameters for disjoint learning on labeled and unlabeled data. Through extensive experimental validation of our method in the two different scenarios, we show that our method outperforms both local semi-supervised learning and baselines which naively combine federated learning with semi-supervised learning.",
    "One-sentence Summary": "We introduce a new practical problem of federated learning with a deficiency of supervision and study two realistic scenarios with a novel method to tackle the problems, including inter-client consistency and disjoint learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "wyjeong/FedMatch"
  },
  {
    "title": "Contrastive  Learning  with Adversarial Perturbations for Conditional Text Generation",
    "url": "/forum?id=Wga_hrCa3P3",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "conditional text generation, contrastive learning",
    "Abstract": "Recently, sequence-to-sequence (seq2seq) models with the Transformer architecture have achieved remarkable performance on various conditional text generation tasks, such as machine translation. However, most of them are trained with teacher forcing with the ground truth label given at each time step, without being exposed to incorrectly generated tokens during training, which hurts its generalization to unseen inputs, that is known as the \"exposure bias\" problem. In this work, we propose to solve the conditional text generation problem by contrasting positive pairs with negative pairs, such that the model is exposed to various valid or incorrect perturbations of the inputs, for improved generalization. However, training the model with na\u00efve contrastive learning framework using random non-target sequences as negative examples is suboptimal, since they are easily distinguishable from the correct output, especially so with models pretrained with large text corpora. Also, generating positive examples requires domain-specific augmentation heuristics which may not generalize over diverse domains. To tackle this problem, we propose a principled method to generate positive and negative samples for contrastive learning of seq2seq models. Specifically, we generate negative examples by adding small perturbations to the input sequence to minimize its conditional likelihood, and positive examples by adding  large perturbations while enforcing it to have a high conditional likelihood. Such `\"hard'' positive and negative pairs generated using our method guides the model to better distinguish correct outputs from incorrect ones. We empirically show that our proposed method significantly improves the generalization of the seq2seq on three text generation tasks --- machine translation, text summarization, and question generation.",
    "One-sentence Summary": "We propose a contrastive learning with adversarial perturbation to tackle the exposure bias problem.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "seanie12/CLAPS",
    "Data": "SQuAD"
  },
  {
    "title": "Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks",
    "url": "/forum?id=FZ1oTwcXchK",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "spiking neural network, weight balance, second-order approximation",
    "Abstract": "Spiking neural networks (SNNs) are biology-inspired artificial neural networks (ANNs) that comprise of spiking neurons to process asynchronous discrete signals. While more efficient in power consumption and inference speed on the neuromorphic hardware, SNNs are usually difficult to train directly from scratch with spikes due to the discreteness. As an alternative, many efforts have been devoted to converting conventional ANNs into SNNs by copying the weights from ANNs and adjusting the spiking threshold potential of neurons in SNNs. Researchers have designed new SNN architectures and conversion algorithms to diminish the conversion error. However, an effective conversion should address the difference between the SNN and ANN architectures with an efficient approximation of the loss function, which is missing in the field. In this work, we analyze the conversion error by recursive reduction to layer-wise summation and propose a novel strategic pipeline that transfers the weights to the target SNN by combining threshold balance and soft-reset mechanisms. This pipeline enables almost no accuracy loss between the converted SNNs and conventional ANNs with only \u223c1/10 of the typical SNN simulation time. Our method is promising to get implanted onto embedded platforms with better support of SNNs with limited energy and memory. Codes are available at https://github.com/Jackn0/snn_optimal_conversion_pipeline.",
    "One-sentence Summary": "We propose and validate an optimal pipeline that efficiently converts conventional artificial neural networks to spiking neural networks with almost no accuracy loss in a fairly short simulation length.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "Jackn0/snn_optimal_conversion_pipeline"
  },
  {
    "title": "Efficient Continual Learning with Modular Networks and Task-Driven Priors",
    "url": "/forum?id=EKV158tSfwv",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Continual learning, Lifelong learning, Benchmark, Modular network, Neural Network",
    "Abstract": "Existing literature in Continual Learning (CL) has focused on overcoming catastrophic forgetting, the inability of the learner to recall how to perform tasks observed in the past. \n        There are however other desirable properties of a CL system, such as the ability to transfer knowledge from previous tasks and to scale memory and compute sub-linearly with the number of tasks. Since most current benchmarks focus only on forgetting using short streams of tasks, we first propose a new suite of benchmarks to probe CL algorithms across these new axes. \n        Finally, we introduce a new modular architecture, whose modules represent atomic skills that can be composed to perform a certain task. Learning a task reduces to figuring out which past modules to re-use, and which new modules to instantiate to solve the current task. Our learning algorithm leverages a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. \n        Our experiments show that this modular architecture and learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks we introduce in this work. The Benchmark is publicly available at https://github.com/facebookresearch/CTrLBenchmark.",
    "One-sentence Summary": "We propose a new benchmark allowing a detailed analysis of the properties of continual learning alogrithms and a new modular neural network leveraging task-based priors to efficiently learn in the CL setting.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "facebookresearch/CTrLBenchmark +  1 community implementation",
    "Data": "CIFAR-100, MNIST, Permuted MNIST"
  },
  {
    "title": "On the Universality of Rotation Equivariant Point Cloud Networks",
    "url": "/forum?id=6NFBvWlRXaG",
    "date": "28 Sept 2020 (modified: 09 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "3D deep learning, Rotation invariance, Invariant and equivariant deep networks, Universal approximation, Point clouds",
    "Abstract": "Learning functions on point clouds has applications in many fields, including computer vision, computer graphics, physics, and chemistry. Recently, there has been a growing interest in neural architectures that are invariant or equivariant to all three shape-preserving transformations of point clouds: translation, rotation, and permutation. In this paper, we present a first study of the approximation power of these architectures. We first derive two sufficient conditions for an equivariant architecture to have the universal approximation property, based on a novel characterization of the space of equivariant polynomials. We then use these conditions to show that two recently suggested models, Tensor field Networks and SE3-Transformers, are universal, and for devising two other novel universal architectures.",
    "One-sentence Summary": "We provide sufficient conditions for universality of rotation equivariant point cloud networks and use these conditions to show that current models are universal as well as for devising new universal architectures.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Neural Learning of One-of-Many Solutions for Combinatorial Problems in Structured Output Spaces",
    "url": "/forum?id=ATp1nW2FuZL",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Neuro symbolic, constraint satisfaction, reasoning",
    "Abstract": "Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any \"one\" of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two-fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks,  demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.",
    "One-sentence Summary": "This work identifies and proposes a solution for handling solution multiplicity while learning neural methods for combinatorial problems in structured output spaces.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy Images",
    "url": "/forum?id=SHvF5xaueVn",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "blind denoising, unsupervised learning, iterative training, generative learning",
    "Abstract": "We tackle a challenging blind image denoising problem, in which only single distinct noisy images are available for training a denoiser, and no information about noise is known, except for it being zero-mean, additive, and independent of the clean image. In such a setting, which often occurs in practice, it is not possible to train a denoiser with the standard discriminative training or with the recently developed Noise2Noise (N2N) training; the former requires the underlying clean image for the given noisy image, and the latter requires two independently realized noisy image pair for a clean image. To that end, we propose GAN2GAN (Generated-Artificial-Noise to Generated-Artificial-Noise) method that first learns a generative model that can 1) simulate the noise in the given noisy images and 2) generate a rough, noisy estimates of the clean images, then 3) iteratively trains a denoiser with subsequently synthesized noisy image pairs (as in N2N), obtained from the generative model. In results, we show the denoiser trained with our GAN2GAN achieves an impressive denoising performance on both synthetic and real-world datasets for the blind denoising setting; it almost approaches the performance of the standard discriminatively-trained or N2N-trained models that have more information than ours, and it significantly outperforms the recent baseline for the same setting, \\textit{e.g.}, Noise2Void, and a more conventional yet strong one, BM3D. The official code of our method is available at https://github.com/csm9493/GAN2GAN.",
    "One-sentence Summary": "We devise GAN2GAN method that trains a blind denoiser solely based on the single noisy images.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "csm9493/GAN2GAN"
  },
  {
    "title": "CPR: Classifier-Projection Regularization for Continual Learning",
    "url": "/forum?id=F2v4aqEL6ze",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "continual learning, regularization, wide local minima",
    "Abstract": "We propose a general, yet simple patch that can be applied to existing regularization-based continual learning methods called classifier-projection regularization (CPR). Inspired by both recent results on neural networks with wide local minima and information theory, CPR adds an additional regularization term that maximizes the entropy of a classifier's output probability. We demonstrate that this additional term can be interpreted as a projection of the conditional probability given by a classifier's output to the uniform distribution. By applying the Pythagorean theorem for KL divergence, we then prove that this projection may (in theory) improve the performance of continual learning methods. In our extensive experimental results, we apply CPR to several state-of-the-art regularization-based continual learning methods and benchmark performance on popular image recognition datasets. Our results demonstrate that CPR indeed promotes a wide local minima and significantly improves both accuracy and plasticity while simultaneously mitigating the catastrophic forgetting of baseline continual learning methods. The codes and scripts for this work are available at https://github.com/csm9493/CPR_CL.",
    "One-sentence Summary": "We devise wide local minima promoting regularization term for continual learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "csm9493/CPR_CL",
    "Data": "SVHN"
  },
  {
    "title": "On the Dynamics of Training Attention Models",
    "url": "/forum?id=1OCTOShAmqB",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Abstract": "The attention mechanism has been widely used in deep neural networks as a model component. By now, it has become a critical building block in many state-of-the-art natural language models. Despite its great success established empirically, the working mechanism of attention has not been investigated at a sufficient theoretical depth to date. In this paper, we set up a simple text classification task and study the dynamics of training a simple attention-based classification model using gradient descent. In this setting, we show that, for the discriminative words that the model should attend to, a persisting identity exists relating its embedding and the inner product of its key and the query. This allows us to prove that training must converge to attending to the discriminative words when the attention output is classified by a linear classifier. Experiments are performed, which validate our theoretical analysis and provide further insights.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "haoyelyu/On_the_Dynamics_of_Training_Attention_Models"
  },
  {
    "title": "Model-Based Offline Planning",
    "url": "/forum?id=OMNB1G5xzd4",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "off-line reinforcement learning, model-based reinforcement learning, model-based control, reinforcement learning, model predictive control, robotics",
    "Abstract": "Offline learning is a key part of making reinforcement learning (RL) useable in real systems. Offline RL looks at scenarios where there is data from a system's operation, but no direct access to the system when learning a policy. Recent work on training RL policies from offline data has shown results both with model-free policies learned directly from the data, or with planning on top of learnt models of the data. Model-free policies tend to be more performant, but are more opaque, harder to command externally, and less easy to integrate into larger systems. We propose an offline learner that generates a model that can be used to control the system directly through planning. This allows us to have easily controllable policies directly from data, without ever interacting with the system. We show the performance of our algorithm, Model-Based Offline Planning (MBOP) on a series of robotics-inspired tasks, and demonstrate its ability leverage planning to respect environmental constraints. We are able to find near-optimal polices for certain simulated systems from as little as 50 seconds of real-time system interaction, and create zero-shot goal-conditioned policies on a series of environments.",
    "One-sentence Summary": "This approach adapts model-based reinforcement learning to offline regimes with little data, and shows state of the art control in offline scenarios.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "D4RL"
  },
  {
    "title": "Modelling Hierarchical Structure between Dialogue Policy and Natural Language Generator with Option Framework for Task-oriented Dialogue System",
    "url": "/forum?id=kLbhLJ8OT12",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Task-oriented Dialogue System, Natural Language Processing, Hierarchical Reinforcement Learning, Policy Optimization",
    "Abstract": "Designing task-oriented dialogue systems is a challenging research topic, since it needs not only to generate utterances fulfilling user requests but also to guarantee the comprehensibility. Many previous works trained end-to-end (E2E) models with supervised learning (SL), however, the bias in annotated system utterances remains as a bottleneck. Reinforcement learning (RL) deals with the problem through using non-differentiable evaluation metrics (e.g., the success rate) as rewards. Nonetheless, existing works with RL showed that the comprehensibility of generated system utterances could be corrupted when improving the performance on fulfilling user requests. In our work, we (1) propose modelling the hierarchical structure between dialogue policy and natural language generator (NLG) with the option framework, called HDNO, where the latent dialogue act is applied to avoid designing specific dialogue act representations; (2) train HDNO via hierarchical reinforcement learning (HRL), as well as suggest the asynchronous updates between dialogue policy and NLG during training to theoretically guarantee their convergence to a local maximizer; and (3) propose using a discriminator modelled with language models as an additional reward to further improve the comprehensibility. We test HDNO on MultiWoz 2.0 and MultiWoz 2.1, the datasets on multi-domain dialogues, in comparison with word-level E2E model trained with RL, LaRL and HDSA, showing improvements on the performance evaluated by automatic evaluation metrics and human evaluation. Finally, we demonstrate the semantic meanings of latent dialogue acts to show the explanability for HDNO.",
    "One-sentence Summary": "We propose a novel algorithm called HDNO for policy optimization for task-oriented dialogue system so that the performance on the comprehensibility of generated responses is improved compared with other RL-based algorithms.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "mikezhang95/HDNO",
    "Data": "MultiWOZ"
  },
  {
    "title": "Distilling Knowledge from Reader to Retriever for Question Answering",
    "url": "/forum?id=NTEz-6wysdb",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "question answering, information retrieval",
    "Abstract": "The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering. While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results. A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents. In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents. Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever. We evaluate our method on question answering, obtaining state-of-the-art results.",
    "One-sentence Summary": "We show that attention scores obtained by training a model to answer questions given a set of support documents can be used to train a model to select relevant passages in a knowledge source.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "2 community implementations",
    "Data": "NarrativeQA, Natural Questions, TriviaQA"
  },
  {
    "title": "Efficient Certified Defenses Against Patch Attacks on Image Classifiers",
    "url": "/forum?id=hr-3PMvDpil",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "robustness, certified defense, adversarial patch, aversarial examples",
    "Abstract": "Adversarial patches pose a realistic threat model for physical world attacks on autonomous systems via their perception component. Autonomous systems in safety-critical domains such as automated driving should thus contain a fail-safe fallback component that combines certifiable robustness against patches with efficient inference while maintaining high performance on clean inputs. We propose BagCert, a novel combination of model architecture and certification procedure that allows efficient certification. We derive a loss that enables end-to-end optimization of certified robustness against patches of different sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in 43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy against 5x5 patches.",
    "One-sentence Summary": "We propose a method for certifying robustness against adversarial patches that combines high certified accuracy with efficient inference while maintaining strong performance on clean data.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10"
  },
  {
    "title": "Taking Notes on the Fly Helps Language Pre-Training",
    "url": "/forum?id=lU5Rs_wCweN",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Natural Language Processing, Pre-training",
    "Abstract": "How to make unsupervised language pre-training more efficient and less resource-intensive is an important research direction in NLP. In this paper, we focus on improving the efficiency of language pre-training methods through providing better data utilization. It is well-known that in language data corpus, words follow a heavy-tail distribution. A large proportion of words appear only very few times and the embeddings of rare words are usually poorly optimized. We argue that such embeddings carry inadequate semantic signals, which could make the data utilization inefficient and slow down the pre-training of the entire model. To mitigate this problem, we propose Taking Notes on the Fly (TNF), which takes notes for rare words on the fly during pre-training to help the model understand them when they occur next time. Specifically, TNF maintains a note dictionary and saves a rare word's contextual information in it as notes when the rare word occurs in a sentence. When the same rare word occurs again during training, the note information saved beforehand can be employed to enhance the semantics of the current sentence. By doing so, TNF provides a better data utilization since cross-sentence information is employed to cover the inadequate semantics caused by rare words in the sentences. We implement TNF on both BERT and ELECTRA to check its efficiency and effectiveness.  Experimental results show that TNF's training time is 60% less than its backbone pre-training models when reaching the same performance.  When trained with same number of iterations, TNF outperforms its backbone methods on most of downstream tasks and the average GLUE score. Code is attached in the supplementary material.",
    "One-sentence Summary": "We improve the efficiency of language pre-training methods through providing better data utilization.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "GLUE, QNLI"
  },
  {
    "title": "Graph Edit Networks",
    "url": "/forum?id=dlEJsyHGeaL",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "graph neural networks, graph edit distance, time series prediction, structured prediction",
    "Abstract": "While graph neural networks have made impressive progress in classification and regression, few approaches to date perform time series prediction on graphs, and those that do are mostly limited to edge changes. We suggest that graph edits are a more natural interface for graph-to-graph learning. In particular,  graph edits are general enough to describe any graph-to-graph change, not only edge changes; they are sparse, making them easier to understand for humans and more efficient computationally; and they are local, avoiding the need for pooling layers in graph neural networks. In this paper, we propose a novel output layer - the graph edit network - which takes node embeddings as input and generates a sequence of graph edits that transform the input graph to the output graph. We prove that a mapping between the node sets of two graphs is sufficient to construct training data for a graph edit network and that an optimal mapping yields edit scripts that are almost as short as the graph edit distance between the graphs. We further provide a proof-of-concept empirical evaluation on several graph dynamical systems, which are difficult to learn for baselines from the literature.",
    "One-sentence Summary": "We show that graph neural networks can predict graph edits and are connected to the graph edit distance via graph mappings",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "bpaassen/graph-edit-networks"
  },
  {
    "title": "FOCAL: Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization",
    "url": "/forum?id=8cpHIfgY4Dj",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "offline/batch reinforcement learning, meta-reinforcement learning, multi-task reinforcement learning, distance metric learning, contrastive learning",
    "Abstract": "We study the offline meta-reinforcement learning (OMRL) problem, a paradigm which enables reinforcement learning (RL) algorithms to quickly adapt to unseen tasks without any interactions with the environments, making RL truly practical in many real-world applications. This problem is still not fully understood, for which two major challenges need to be addressed. First, offline RL usually suffers from bootstrapping errors of out-of-distribution state-actions which leads to divergence of value functions. Second, meta-RL requires efficient and robust task inference learned jointly with control policy. In this work, we enforce behavior regularization on learned policy as a general approach to offline RL, combined with a deterministic context encoder for efficient task inference. We propose a novel negative-power distance metric on bounded context embedding space, whose gradients propagation is detached from the Bellman backup. We provide analysis and insight showing that some simple design choices can yield substantial improvements over recent approaches involving meta-RL and distance metric learning. To the best of our knowledge, our method is the first model-free and end-to-end OMRL algorithm, which is computationally efficient and demonstrated to outperform prior algorithms on several meta-RL benchmarks.",
    "One-sentence Summary": "A novel model-free, end-to-end fully-offline meta-RL algorithm designed to maximize practicality, performance and sample/computational efficiency.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "FOCAL-ICLR/FOCAL-ICLR",
    "Data": "MuJoCo"
  },
  {
    "title": "Effective and Efficient Vote Attack on Capsule Networks",
    "url": "/forum?id=33rtZ4Sjwjn",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Capsule Networks, Adversarial Attacks, Adversarial Example Detection",
    "Abstract": "Standard Convolutional Neural Networks (CNNs) can be easily fooled by images with small quasi-imperceptible artificial perturbations. As alternatives to CNNs, the recently proposed Capsule Networks (CapsNets) are shown to be more robust to white-box attack than CNNs under popular attack protocols. Besides, the class-conditional reconstruction part of CapsNets is also used to detect adversarial examples. In this work, we investigate the adversarial robustness of CapsNets, especially how the inner workings of CapsNets change when the output capsules are attacked. The first observation is that adversarial examples misled CapsNets by manipulating the votes from primary capsules. Another observation is the high computational cost, when we directly apply multi-step attack methods designed for CNNs to attack CapsNets, due to the computationally expensive routing mechanism. Motivated by these two observations, we propose a novel vote attack where we attack votes of CapsNets directly. Our vote attack is not only effective, but also efficient by circumventing the routing process. Furthermore, we integrate our vote attack into the detection-aware attack paradigm, which can successfully bypass the class-conditional reconstruction based detection method. Extensive experiments demonstrate the superior attack performance of our vote attack on CapsNets.",
    "One-sentence Summary": "We propose an effective and efficient vote attack to create adversarial examples and bypass adversarial example detection on Capsule Networks.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "JindongGu/VoteAttack",
    "Data": "CIFAR-10, SVHN"
  },
  {
    "title": "Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets",
    "url": "/forum?id=rkQuFUmUOg3",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Machine Learning, Neural Architecture Search, Meta-learning",
    "Abstract": "Despite the success of recent Neural Architecture Search (NAS) methods on various tasks which have shown to output networks that largely outperform human-designed networks, conventional NAS methods have mostly tackled the optimization of searching for the network architecture for a single task (dataset), which does not generalize well across multiple tasks (datasets). Moreover, since such task-specific methods search for a neural architecture from scratch for every given task, they incur a large computational cost, which is problematic when the time and monetary budget are limited. In this paper, we propose an efficient NAS framework that is trained once on a database consisting of datasets and pretrained networks and can rapidly search for a neural architecture for a novel dataset. The proposed MetaD2A (Meta Dataset-to-Architecture) model can stochastically generate graphs (architectures) from a given set (dataset) via a cross-modal latent space learned with amortized meta-learning. Moreover, we also propose a meta-performance predictor to estimate and select the best architecture without direct training on target datasets. The experimental results demonstrate that our model meta-learned on subsets of ImageNet-1K and architectures from NAS-Bench 201 search space successfully generalizes to multiple unseen datasets including CIFAR-10 and CIFAR-100, with an average search time of 33 GPU seconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than NSGANetV2, a transferable NAS method, with comparable performance. We believe that the MetaD2A proposes a new research direction for rapid NAS as well as ways to utilize the knowledge from rich databases of datasets and architectures accumulated over the past years. Code is available at https://github.com/HayeonLee/MetaD2A.",
    "One-sentence Summary": "We propose an efficient NAS framework that is trained once on a database consisting of datasets and pretrained networks and can rapidly generate a neural architecture for a novel dataset.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "HayeonLee/MetaD2A",
    "Data": "CIFAR-10, CIFAR-100, ImageNet, NAS-Bench-201, Oxford-IIIT Pets, SVHN"
  },
  {
    "title": "Impact of Representation Learning in Linear Bandits",
    "url": "/forum?id=edJ_HipawCa",
    "date": "28 Sept 2020 (modified: 14 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "linear bandits, representation learning, multi-task learning",
    "Abstract": "We study how representation learning can improve the efficiency of bandit problems. We study the setting where we play T linear bandits with dimension d concurrently, and these T bandit tasks share a common k(\u226ad) dimensional linear representation. For the finite-action setting, we present a new algorithm which achieves O~(TkN+dkNT) regret, where N is the number of rounds we play for each bandit. When T is sufficiently large, our algorithm significantly outperforms the naive algorithm (playing T bandits independently) that achieves O~(TdN) regret. We also provide an \u03a9(TkN+dkNT) regret lower bound, showing that our algorithm is minimax-optimal up to poly-logarithmic factors.  Furthermore, we extend our algorithm to the infinite-action setting and obtain a corresponding regret bound which demonstrates the benefit of representation learning in certain regimes. We also present experiments on synthetic and real-world data to illustrate our theoretical findings and demonstrate the effectiveness of our proposed algorithms.",
    "One-sentence Summary": "We show representation learning provably improves multi-task linear bandits.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Creative Sketch Generation",
    "url": "/forum?id=gwnoVHIES05",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "creativity, sketches, part-based, GAN, dataset, generative art",
    "Abstract": "Sketching or doodling is a popular creative activity that people engage in. However, most existing work in automatic sketch understanding or generation has focused on sketches that are quite mundane. In this work, we introduce two datasets of creative sketches -- Creative Birds and Creative Creatures -- containing 10k sketches each along with part annotations. We propose DoodlerGAN -- a part-based Generative Adversarial Network (GAN) -- to generate unseen compositions of novel part appearances. Quantitative evaluations as well as human studies demonstrate that sketches generated by our approach are more creative and of higher quality than existing approaches. In fact, in Creative Birds, subjects prefer sketches generated by DoodlerGAN over those drawn by humans!",
    "One-sentence Summary": "We introduce two creative sketch datasets and DoodlerGAN -- a part-based GAN model that generates creative sketches.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "facebookresearch/DoodlerGAN",
    "Data": "Sketch"
  },
  {
    "title": "Self-supervised Representation Learning with Relative Predictive Coding",
    "url": "/forum?id=068E_JSq9O",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "self-supervised learning, contrastive learning, dependency based method",
    "Abstract": "This paper introduces Relative Predictive Coding (RPC), a new contrastive representation learning objective that maintains a good balance among training stability, minibatch size sensitivity, and downstream task performance. The key to the success of RPC is two-fold. First, RPC introduces the relative parameters to regularize the objective for boundedness and low variance. Second, RPC contains no logarithm and exponential score functions, which are the main cause of training instability in prior contrastive objectives. We empirically verify the effectiveness of RPC on benchmark vision and speech self-supervised learning tasks. Lastly, we relate RPC with mutual information (MI) estimation, showing RPC can be used to estimate MI with low variance.",
    "One-sentence Summary": "We present RPC, the Relative Predictive Coding, that achieves a good balance among the three challenges when modeling a contrastive learning objective: training stability, sensitivity to minibatch size, and downstream task performance.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "martinmamql/relative_predictive_coding",
    "Data": "CIFAR-10, CIFAR-100, LibriSpeech, STL-10"
  },
  {
    "title": "One Network Fits All? Modular versus Monolithic Task Formulations in Neural Networks",
    "url": "/forum?id=uz5uw6gM0m",
    "date": "28 Sept 2020 (modified: 28 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "deep learning theory, multi-task learning",
    "Abstract": "Can deep learning solve multiple, very different tasks simultaneously? We investigate how the representations of the underlying tasks affect the ability of a single neural network to learn them jointly. We present theoretical and empirical findings that a single neural network is capable of simultaneously learning multiple tasks from a combined data set, for a variety of methods for representing tasks---for example, when the distinct tasks are encoded by well-separated clusters or decision trees over some task-code attributes. Indeed, more strongly, we present a novel analysis that shows that families of simple programming-like constructs for the codes encoding the tasks are learnable by two-layer neural networks with standard training. We study more generally how the complexity of learning such combined tasks grows with the complexity of the task codes; we find that learning many tasks can be provably hard, even though the individual tasks are easy to learn. We provide empirical support for the usefulness of the learning bounds by training networks on clusters, decision trees, and SQL-style aggregation.",
    "One-sentence Summary": "Theoretical bounds and experimental results showing that neural networks trained with SGD can provably solve multiple, very different tasks simultaneously.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data",
    "url": "/forum?id=de11dbHzAMF",
    "date": "28 Sept 2020 (modified: 02 Apr 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Multi-Task Learning, Adaptive Learning, Transfer Learning, Natural Language Processing, Hypernetwork",
    "Abstract": "Multi-Task Learning (MTL) networks have emerged as a promising method for transferring learned knowledge across different tasks. However, MTL must deal with challenges such as: overfitting to low resource tasks, catastrophic forgetting, and negative task transfer, or learning interference. Often, in Natural Language Processing (NLP), a separate model per task is needed to obtain the best performance. However, many fine-tuning approaches are both parameter inefficient, i.e., potentially involving one new model per task, and highly susceptible to losing knowledge acquired during pretraining. We propose a novel Transformer based Hypernetwork Adapter consisting of a new conditional attention mechanism as well as a set of task-conditioned modules that facilitate weight sharing. Through this construction, we achieve more efficient parameter sharing and mitigate forgetting by keeping half of the weights of a pretrained model fixed. We also use a new multi-task data sampling strategy to mitigate the negative effects of data imbalance across tasks. Using this approach, we are able to surpass single task fine-tuning methods while being parameter and data efficient (using around 66% of the data). Compared to other BERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by 2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger variant of our single multi-task model approach performs competitively across 26 NLP tasks and yields state-of-the-art results on a number of test and development sets.",
    "One-sentence Summary": "Can multi-task outperform single task fine-tuning? CA-MTL is a new method that shows that it is possible with task conditioned model adaption via a Hypernetwork and uncertainty sampling.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "CAMTL/CA-MTL",
    "Data": "CoLA, GLUE, MRPC, MRQA, QNLI, SNLI, SST, SciTail, SuperGLUE"
  },
  {
    "title": "A Universal Representation Transformer Layer for Few-Shot Image Classification",
    "url": "/forum?id=04cII6MumYV",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Abstract": "Few-shot classification aims to recognize unseen classes when presented with only a small number of samples. We consider the problem of multi-domain few-shot image classification, where unseen classes and examples come from diverse data sources. This problem has seen growing interest and has inspired the development of benchmarks such as Meta-Dataset. A key challenge in this multi-domain setting is to effectively integrate the feature representations from the diverse set of training domains. Here, we propose a Universal Representation Transformer (URT) layer, that meta-learns to leverage universal features for few-shot classification by dynamically re-weighting and composing the most appropriate domain-specific representations. In experiments, we show that URT sets a new state-of-the-art result on Meta-Dataset. Specifically, it achieves top-performance on the highest number of data sources compared to competing methods. We analyze variants of URT and present a visualization of the attention score heatmaps that sheds light on how the model performs cross-domain generalization.",
    "One-sentence Summary": "code at: https://github.com/liulu112601/URT",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "liulu112601/URT",
    "Data": "CIFAR-10, CIFAR-100, MNIST, Meta-Dataset"
  },
  {
    "title": "Isometric Propagation Network for Generalized Zero-shot Learning",
    "url": "/forum?id=-mWcQVLPSPy",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Zero-shot learning, isometric, prototype propagation, alignment of semantic and visual space",
    "Abstract": "Zero-shot learning (ZSL) aims to classify images of an unseen class only based on a few attributes describing that class but no access to any training sample. A popular strategy is to learn a mapping between the semantic space of class attributes and the visual space of images based on the seen classes and their data. Thus, an unseen class image can be ideally mapped to its corresponding class attributes. The key challenge is how to align the representations in the two spaces. For most ZSL settings, the attributes for each seen/unseen class are only represented by a vector while the seen-class data provide much more information. Thus, the imbalanced supervision from the semantic and the visual space can make the learned mapping easily overfitting to the seen classes. To resolve this problem, we propose Isometric Propagation Network (IPN), which learns to strengthen the relation between classes within each space and align the class dependency in the two spaces. Specifically, IPN learns to propagate the class representations on an auto-generated graph within each space. In contrast to only aligning the resulted static representation, we regularize the two dynamic propagation procedures to be isometric in terms of the two graphs' edge weights per step by minimizing a consistency loss between them. IPN achieves state-of-the-art performance on three popular ZSL benchmarks. To evaluate the generalization capability of IPN, we further build two larger benchmarks with more diverse unseen classes and demonstrate the advantages of IPN on them.",
    "One-sentence Summary": "We improve the current zero-shot learning performance by a dynamic alignment between the semantic space and visual space that encourages the isometry of the class-prototype propagation procedures in the two spaces.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "AwA2, aPY, tieredImageNet"
  },
  {
    "title": "Towards Impartial Multi-task Learning",
    "url": "/forum?id=IMPnRXEWpvr",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Multi-task Learning, Impartial Learning, Scene Understanding",
    "Abstract": "Multi-task learning (MTL) has been widely used in representation learning. However, naively training all tasks simultaneously may lead to the partial training issue, where specific tasks are trained more adequately than others. In this paper, we propose to learn multiple tasks impartially. Specifically, for the task-shared parameters, we optimize the scaling factors via a closed-form solution, such that the aggregated gradient (sum of raw gradients weighted by the scaling factors) has equal projections onto individual tasks. For the task-specific parameters, we dynamically weigh the task losses so that all of them are kept at a comparable scale. Further, we find the above gradient balance and loss balance are complementary and thus propose a hybrid balance method to further improve the performance. Our impartial multi-task learning (IMTL) can be end-to-end trained without any heuristic hyper-parameter tuning, and is general to be applied on all kinds of losses without any distribution assumption. Moreover, our IMTL can converge to similar results even when the task losses are designed to have different scales, and thus it is scale-invariant. We extensively evaluate our IMTL on the standard MTL benchmarks including Cityscapes, NYUv2 and CelebA. It outperforms existing loss weighting methods under the same experimental settings.",
    "One-sentence Summary": "We propose an impartial multi-task learning method that treats all tasks equally without bias towards any task.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CelebA, Cityscapes, NYUv2"
  },
  {
    "title": "On Learning Universal Representations Across Languages",
    "url": "/forum?id=Uu1Nw-eeTxJ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "universal representation learning, cross-lingual pretraining, hierarchical contrastive learning",
    "Abstract": "Recent studies have demonstrated the overwhelming advantage of cross-lingual pre-trained models (PTMs), such as multilingual BERT and XLM, on cross-lingual NLP tasks. However, existing approaches essentially capture the co-occurrence among tokens through involving the masked language model (MLM) objective with token-level cross entropy. In this work, we extend these approaches to learn sentence-level representations and show the effectiveness on cross-lingual understanding and generation. Specifically, we propose a Hierarchical Contrastive Learning (HiCTL) method to (1) learn universal representations for parallel sentences distributed in one or multiple languages and (2) distinguish the semantically-related words from a shared cross-lingual vocabulary for each sentence. We conduct evaluations on two challenging cross-lingual tasks, XTREME and machine translation. Experimental results show that the HiCTL outperforms the state-of-the-art XLM-R by an absolute gain of 4.2% accuracy on the XTREME benchmark as well as achieves substantial improvements on both of the high resource and low-resource English\u2192X translation tasks over strong baselines.",
    "One-sentence Summary": "In this work, we extend pre-trained language models to learn universal representations among multiple languages, and show the effectiveness on cross-lingual understanding and generation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "GLUE, MRPC, MultiNLI, QNLI, SST, XNLI"
  },
  {
    "title": "Isotropy in the Contextual Embedding Space: Clusters and Manifolds",
    "url": "/forum?id=xYGNO86OWDH",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Contextual embedding space, Isotropy, Clusters, Manifolds",
    "Abstract": "The geometric properties of contextual embedding spaces for deep language models such as BERT and ERNIE, have attracted considerable attention in recent years. Investigations on the contextual embeddings demonstrate a strong anisotropic space such that most of the vectors fall within a narrow cone, leading to high cosine similarities.  It is surprising that these LMs are as successful as they are, given that most of their embedding vectors are as similar to one another as they are. In this paper, we argue that the isotropy indeed exists in the space, from a different but more constructive perspective. We identify isolated clusters and low dimensional manifolds in the contextual embedding space, and introduce tools to both qualitatively and quantitatively analyze them. We hope the study in this paper could provide insights towards a better understanding of the deep language models.",
    "One-sentence Summary": "This paper reveals isotropy in the clustered contextual embedding space, and found low-dimensional manifolds in there.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "Penn Treebank"
  },
  {
    "title": "MoPro: Webly Supervised Learning with Momentum Prototypes",
    "url": "/forum?id=0-EYBhgw80y",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "webly-supervised learning, weakly-supervised learning, contrastive learning, representation learning",
    "Abstract": "We propose a webly-supervised representation learning method that does not suffer from the annotation unscalability of supervised learning, nor the computation unscalability of self-supervised learning. Most existing works on webly-supervised representation learning adopt a vanilla supervised learning method without accounting for the prevalent noise in the training data, whereas most prior methods in learning with label noise are less effective for real-world large-scale noisy data. We propose momentum prototypes (MoPro), a simple contrastive learning method that achieves online label noise correction, out-of-distribution sample removal, and representation learning. MoPro achieves state-of-the-art performance on WebVision, a weakly-labeled noisy dataset. MoPro also shows superior performance when the pretrained model is transferred to down-stream image classification and detection tasks. It outperforms the ImageNet supervised pretrained model by +10.5 on 1-shot classification on VOC, and outperforms the best self-supervised pretrained model by +17.3 when finetuned on 1% of ImageNet labeled samples. Furthermore, MoPro is more robust to distribution shifts. Code and pretrained models are available at https://github.com/salesforce/MoPro.",
    "One-sentence Summary": "MoPro is a new webly-supervised learning framework which advances representation learning using freely-available Web images.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "salesforce/MoPro",
    "Data": "COCO, ImageNet, ImageNet-A, ImageNet-R, Places205, WebVision"
  },
  {
    "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow",
    "url": "/forum?id=jLoC4ez43PZ",
    "date": "28 Sept 2020 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Pre-training, BERT, Code Representations, Code Structure, Data Flow",
    "Abstract": "Pre-trained models for programming language have achieved dramatic empirical improvements on a variety of code-related tasks such as code search, code completion, code summarization, etc. However, existing pre-trained models regard a code snippet as a sequence of tokens, while ignoring the inherent structure of code, which provides crucial code semantics and would enhance the code understanding process. We present GraphCodeBERT, a pre-trained model for programming language that considers the inherent structure of code. Instead of taking syntactic-level structure of code like abstract syntax tree (AST), we use data flow in the pre-training stage, which is a semantic-level structure of code that encodes the relation of \"where-the-value-comes-from\" between variables. Such a semantic-level structure is neat and does not bring an unnecessarily deep hierarchy of AST, the property of which makes the model more efficient. We develop GraphCodeBERT based on Transformer. In addition to using the task of masked language modeling, we introduce two structure-aware pre-training tasks. One is to predict code structure edges, and the other is to align representations between source code and code structure. We implement the model in an efficient way with a graph-guided masked attention function to incorporate the code structure. We evaluate our model on four tasks, including code search, clone detection, code translation, and code refinement. Results show that code structure and newly introduced pre-training tasks can improve GraphCodeBERT and achieves state-of-the-art performance on the four downstream tasks. We further show that the model prefers structure-level attentions over token-level attentions in the task of code search.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "microsoft/CodeBERT",
    "Data": "CodeSearchNet, ManyTypes4TypeScript"
  },
  {
    "title": "Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation",
    "url": "/forum?id=HOFxeCutxZR",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Image manipulation, GANs, latent space of GANs",
    "Abstract": "Controllable semantic image editing enables a user to change entire image attributes with a few clicks, e.g., gradually making a summer scene look like it was taken in winter. Classic approaches for this task use a Generative Adversarial Net (GAN) to learn a latent space and suitable latent-space transformations. However, current approaches often suffer from attribute edits that are entangled, global image identity changes, and diminished photo-realism. To address these concerns, we learn multiple attribute transformations simultaneously, integrate attribute regression into the training of transformation functions, and apply a content loss and an adversarial loss that encourages the maintenance of image identity and photo-realism. We propose quantitative evaluation strategies for measuring controllable editing performance, unlike prior work, which primarily focuses on qualitative evaluation. Our model permits better control for both single- and multiple-attribute editing while preserving image identity and realism during transformation. We provide empirical results for both natural and synthetic images, highlighting that our model achieves state-of-the-art performance for targeted image manipulation.",
    "One-sentence Summary": "We propose a state-of-the-art approach to semantically edit images by transferring latent vectors towards meaningful latent space directions.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CelebA-HQ, FFHQ, Places"
  },
  {
    "title": "Fourier Neural Operator for Parametric Partial Differential Equations",
    "url": "/forum?id=c8P9NQVtmnO",
    "date": "28 Sept 2020 (modified: 05 Apr 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Partial differential equation, Fourier transform, Neural operators",
    "Abstract": "The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces.  Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.",
    "One-sentence Summary": "A novel neural operator based on Fourier transformation for learning partial differential equations.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "zongyi-li/fourier_neural_operator +  4 community implementations"
  },
  {
    "title": "Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNNs",
    "url": "/forum?id=vYeQQ29Tbvx",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "affine parameters, random features, batchnorm",
    "Abstract": "A wide variety of deep learning techniques from style transfer to multitask learning rely on training affine transformations of features. Most prominent among these is the popular feature normalization technique BatchNorm, which normalizes activations and then subsequently applies a learned affine transform. In this paper, we aim to understand the role and expressive power of affine parameters used to transform features in this way. To isolate the contribution of these parameters from that of the learned features they transform, we investigate the performance achieved when training only these parameters in BatchNorm and freezing all weights at their random initializations. Doing so leads to surprisingly high performance considering the significant limitations that this style of training imposes. For example, sufficiently deep ResNets reach 82% (CIFAR-10) and 32% (ImageNet, top-5) accuracy in this configuration, far higher than when training an equivalent number of randomly chosen parameters elsewhere in the network. BatchNorm achieves this performance in part by naturally learning to disable around a third of the random features. Not only do these results highlight the expressive power of affine parameters in deep learning, but - in a broader sense - they characterize the expressive power of neural networks constructed simply by shifting and rescaling random features.",
    "One-sentence Summary": "We study the role and expressive power of learned affine parameters that transform features by freezing all weights at their random initializations and training only BatchNorm.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "4 community implementations"
  },
  {
    "title": "Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis",
    "url": "/forum?id=1Fqg133qRaI",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "deep learning, generative model, image synthesis, few-shot learning, generative adversarial network, self-supervised learning, unsupervised learning",
    "Abstract": "Training Generative Adversarial Networks (GAN) on high-fidelity images usually requires large-scale GPU-clusters and a vast number of training images. In this paper, we study the few-shot image synthesis task for GAN with minimum computing cost. We propose a light-weight GAN structure that gains superior quality on 1024^2 resolution. Notably, the model converges from scratch with just a few hours of training on a single RTX-2080 GPU, and has a consistent performance, even with less than 100 training samples. Two technique designs constitute our work, a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. With thirteen datasets covering a wide variety of image domains (The datasets and code are available at https://github.com/odegeasslbc/FastGAN-pytorch), we show our model's superior performance compared to the state-of-the-art StyleGAN2, when data and computing budget are limited.",
    "One-sentence Summary": "A computational-efficient GAN for few-shot hi-fi image dataset (converge on single gpu with few hours' training, on 1024 resolution sub-hundred images).",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "odegeasslbc/FastGAN-pytorch +  4 community implementations",
    "Data": "FFHQ, Perceptual Similarity"
  },
  {
    "title": "Targeted Attack against Deep Neural Networks via Flipping Limited Weight Bits",
    "url": "/forum?id=iKQAk8a2kM0",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "targeted attack, bit-flip, weight attack",
    "Abstract": "To explore the vulnerability of deep neural networks (DNNs), many attack paradigms have been well studied, such as the poisoning-based backdoor attack in the training stage and the adversarial attack in the inference stage. In this paper, we study a novel attack paradigm, which modifies model parameters in the deployment stage for malicious purposes. Specifically, our goal is to misclassify a specific sample into a target class without any sample modification, while not significantly reduce the prediction accuracy of other samples to ensure the stealthiness. To this end, we formulate this problem as a binary integer programming (BIP), since the parameters are stored as binary bits (i.e., 0 and 1) in the memory. By utilizing the latest technique in integer programming, we equivalently reformulate this BIP problem as a continuous optimization problem, which can be effectively and efficiently solved using the alternating direction method of multipliers (ADMM) method. Consequently, the flipped critical bits can be easily determined through optimization, rather than using a heuristic strategy. Extensive experiments demonstrate the superiority of our method in attacking DNNs.",
    "One-sentence Summary": "We propose a targeted attack method against the deployed DNN via flipping a few binary weight bits.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "jiawangbai/TA-LBF",
    "Data": "CIFAR-10"
  },
  {
    "title": "FedBN: Federated Learning on Non-IID Features via Local Batch Normalization",
    "url": "/forum?id=6YEQUn0QICG",
    "date": "28 Sept 2020 (modified: 25 Mar 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Federated Learning, Non-IID, Batch Normalization",
    "Abstract": "The emerging paradigm of federated learning (FL) strives to enable collaborative training of deep models on the network edge without centrally aggregating raw data and hence improving data privacy. In most cases, the assumption of independent and identically distributed samples across local clients does not hold for federated learning setups. Under this setting, neural network training performance may vary significantly according to the data distribution and even hurt training convergence. Most of the previous work has focused on a difference in the distribution of labels or client shifts. Unlike those settings, we address an important problem of FL, e.g., different scanners/sensors in medical imaging, different scenery distribution in autonomous driving (highway vs. city), where local clients store examples with different distributions compared to other clients, which we denote as feature shift non-iid. In this work, we propose an effective method that uses local batch normalization to alleviate the feature shift before averaging models. The resulting scheme, called FedBN, outperforms both classical FedAvg, as well as the state-of-the-art for non-iid data (FedProx) on our extensive experiments. These empirical results are supported by a convergence analysis that shows in a simplified setting that FedBN has a faster convergence rate than FedAvg. Code is available at https://github.com/med-air/FedBN.",
    "One-sentence Summary": "We propose a novel and efficient federated learning aggregation method, denoted FedBN, that uses local batch normalization to effectively tackle the underexplored non-iid problem of heterogeneous feature distributions, or feature shift.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "adap/flower +  1 community implementation",
    "Data": "DomainNet, MNIST, SVHN, USPS"
  },
  {
    "title": "AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights",
    "url": "/forum?id=Iz3zU3M316D",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "momentum optimizer, scale-invariant weights, normalize layer, effective learning rate",
    "Abstract": "Normalization techniques, such as batch normalization (BN), are a boon for modern deep learning. They let weights converge more quickly with often better generalization performances. It has been argued that the normalization-induced scale invariance among the weights provides an advantageous ground for gradient descent (GD) optimizers: the effective step sizes are automatically reduced over time, stabilizing the overall training procedure. It is often overlooked, however, that the additional introduction of momentum in GD optimizers results in a far more rapid reduction in effective step sizes for scale-invariant weights, a phenomenon that has not yet been studied and may have caused unwanted side effects in the current practice. This is a crucial issue because arguably the vast majority of modern deep neural networks consist of (1) momentum-based GD (e.g. SGD or Adam) and (2) scale-invariant parameters (e.g. more than 90% of the weights in ResNet are scale-invariant due to BN). In this paper, we verify that the widely-adopted combination of the two ingredients lead to the premature decay of effective step sizes and sub-optimal model performances. We propose a simple and effective remedy, SGDP and AdamP: get rid of the radial component, or the norm-increasing direction, at each optimizer step. Because of the scale invariance, this modification only alters the effective step sizes without changing the effective update directions, thus enjoying the original convergence properties of GD optimizers. Given the ubiquity of momentum GD and scale invariance in machine learning, we have evaluated our methods against the baselines on 13 benchmarks. They range from vision tasks like classification (e.g. ImageNet), retrieval (e.g. CUB and SOP), and detection (e.g. COCO) to language modelling (e.g. WikiText) and audio classification (e.g. DCASE) tasks. We verify that our solution brings about uniform gains in performances in those benchmarks. Source code is available at https://github.com/clovaai/adamp",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "clovaai/AdamP +  4 community implementations",
    "Data": "COCO, CUB-200-2011, MNIST, Speech Commands"
  },
  {
    "title": "Learning Subgoal Representations with Slow Dynamics",
    "url": "/forum?id=wxRwhSdORKG",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Hierarchical Reinforcement Learning, Representation Learning, Exploration",
    "Abstract": "In goal-conditioned Hierarchical Reinforcement Learning (HRL), a high-level policy periodically sets subgoals for a low-level policy, and the low-level policy is trained to reach those subgoals. A proper subgoal representation function, which abstracts a state space to a latent subgoal space, is crucial for effective goal-conditioned HRL, since different low-level behaviors are induced by reaching subgoals in the compressed representation space. Observing that the high-level agent operates at an abstract temporal scale, we propose a slowness objective to effectively learn the subgoal representation (i.e., the high-level action space). We provide a theoretical grounding for the slowness objective. That is, selecting slow features as the subgoal space can achieve efficient hierarchical exploration. As a result of better exploration ability, our approach significantly outperforms state-of-the-art HRL and exploration methods on a number of benchmark continuous-control tasks. Thanks to the generality of the proposed subgoal representation learning method, empirical results also demonstrate that the learned representation and corresponding low-level policies can be transferred between distinct tasks.",
    "One-sentence Summary": "We propose a slowness objective to learn subgoal representations in hierarchical reinforcement learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "MuJoCo"
  },
  {
    "title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability",
    "url": "/forum?id=X76iqnUbBjz",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Adversarial Learning, Interpretability, Adversarial Transferability",
    "Abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.",
    "One-sentence Summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Perceptual Adversarial Robustness: Defense Against Unseen Threat Models",
    "url": "/forum?id=dFwBosAcJkN",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Abstract": "A key challenge in adversarial robustness is the lack of a precise mathematical characterization of human perception, used in the definition of adversarial attacks that are imperceptible to human eyes. Most current attacks and defenses try to get around this issue by considering restrictive adversarial threat models such as those bounded by L2 or L\u221e distance, spatial perturbations, etc. However, models that are robust against any of these restrictive threat models are still fragile against other threat models, i.e. they have poor generalization to unforeseen attacks. Moreover, even if a model is robust against the union of several restrictive threat models, it is still susceptible to other imperceptible adversarial examples that are not contained in any of the constituent threat models. To resolve these issues, we propose adversarial training against the set of all imperceptible adversarial examples. Since this set is intractable to compute without a human in the loop, we approximate it using deep neural networks. We call this threat model the neural perceptual threat model (NPTM); it includes adversarial examples with a bounded neural perceptual distance (a neural network-based approximation of the true perceptual distance) to natural images. Through an extensive perceptual study, we show that the neural perceptual distance correlates well with human judgements of perceptibility of adversarial examples, validating our threat model.\n        \n        Under the NPTM, we develop novel perceptual adversarial attacks and defenses. Because the NPTM is very broad, we find that Perceptual Adversarial Training (PAT) against a perceptual attack gives robustness against many other types of adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five diverse adversarial attacks: L2, L\u221e, spatial, recoloring, and JPEG. We find that PAT achieves state-of-the-art robustness against the union of these five attacks\u2014more than doubling the accuracy over the next best model\u2014without training against any of them. That is, PAT generalizes well to unforeseen perturbation types. This is vital in sensitive applications where a particular threat model cannot be assumed, and to the best of our knowledge, PAT is the first adversarial training defense with this property.\n        \n        Code and data are available at https://github.com/cassidylaidlaw/perceptual-advex",
    "One-sentence Summary": "Adversarial training against a perceptually-aligned attack gives high robustness against many diverse adversarial threat models.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10"
  },
  {
    "title": "Better Fine-Tuning by Reducing Representational Collapse",
    "url": "/forum?id=OQ08SN70M1V",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "finetuning, nlp, representational learning, glue",
    "Abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.",
    "One-sentence Summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "pytorch/fairseq +  1 community implementation",
    "Data": "CNN/Daily Mail, CoLA, GLUE, MRPC, QNLI, Reddit, Reddit TIFU, SST, XNLI"
  },
  {
    "title": "Learning N:M  Fine-grained Structured Sparse Neural Networks From Scratch",
    "url": "/forum?id=K9bw7vqp_s",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "sparsity, efficient training and inference.",
    "Abstract": "Sparsity in Deep Neural Networks (DNNs) has been widely studied to compress and accelerate the models on resource-constrained environments. It can be generally categorized into unstructured fine-grained sparsity that zeroes out multiple individual weights distributed across the neural network, and structured coarse-grained sparsity which prunes blocks of sub-networks of a neural network. Fine-grained sparsity can achieve a high compression ratio but is not hardware friendly and hence receives limited speed gains. On the other hand, coarse-grained sparsity cannot simultaneously achieve both apparent acceleration on modern GPUs and\n        decent performance. In this paper, we are the first to study training from scratch an N:M fine-grained structured sparse network, which can maintain the advantages of both unstructured fine-grained sparsity and structured coarse-grained sparsity simultaneously on specifically designed GPUs. Specifically, a 2 : 4 sparse network could achieve 2\u00d7 speed-up without performance drop on Nvidia A100 GPUs. Furthermore, we propose a novel and effective ingredient, sparse-refined straight-through estimator (SR-STE), to alleviate the negative influence of the approximated gradients computed by vanilla STE during optimization. We also define a metric, Sparse Architecture Divergence (SAD), to measure the sparse network\u2019s topology change during the training process. Finally, We justify SR-STE\u2019s advantages with SAD and demonstrate the effectiveness of SR-STE by performing\n        comprehensive experiments on various tasks. Anonymous code and model will be at available at https://github.com/anonymous-NM-sparsity/NM-sparsity.",
    "One-sentence Summary": "a  simple  yet  universal  recipe  to  learn N:M sparse neural networks from scratch",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "anonymous-NM-sparsity/NM-sparsity +  2 community implementations",
    "Data": "COCO, FlyingChairs, ImageNet"
  },
  {
    "title": "Active Contrastive Learning of Audio-Visual Video Representations",
    "url": "/forum?id=OMizHuea_HB",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "self-supervised learning, contrastive representation learning, active learning, audio-visual representation, video recognition",
    "Abstract": "Contrastive learning has been shown to produce generalizable representations of audio and visual data by maximizing the lower bound on the mutual information (MI) between different views of an instance. However, obtaining a tight lower bound requires a sample size exponential in MI and thus a large set of negative samples. We can incorporate more samples by building a large queue-based dictionary, but there are theoretical limits to performance improvements even with a large number of negative samples. We hypothesize that random negative sampling leads to a highly redundant dictionary that results in suboptimal representations for downstream tasks. In this paper, we propose an active contrastive learning approach that builds an actively sampled dictionary with diverse and informative items, which improves the quality of negative samples and improves performances on tasks where there is high mutual information in the data, e.g., video classification. Our model achieves state-of-the-art performance on challenging audio and visual downstream benchmarks including UCF101, HMDB51 and ESC50.",
    "One-sentence Summary": "We propose an active learning approach to improve negative sampling for contrastive learning and demonstrate it on learning audio-visual representations from videos.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "yunyikristy/CM-ACC",
    "Data": "AudioSet, ESC-50, HMDB51, Kinetics, Kinetics 400, Kinetics-700, UCF101"
  },
  {
    "title": "PseudoSeg: Designing Pseudo Labels for Semantic Segmentation",
    "url": "/forum?id=-TwO99rbVRu",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "pseudo-labeling, semi-supervised, semantic-segmentation",
    "Abstract": "Recent advances in semi-supervised learning (SSL) demonstrate that a combination of consistency regularization and pseudo-labeling can effectively improve image classification accuracy in the low-data regime. Compared to classification, semantic segmentation tasks require much more intensive labeling costs. Thus, these tasks greatly benefit from data-efficient training methods. However, structured outputs in segmentation render particular difficulties (e.g., designing pseudo-labeling and augmentation) to apply existing SSL strategies. To address this problem, we present a simple and novel re-design of pseudo-labeling to generate well-calibrated structured pseudo labels for training with unlabeled or weakly-labeled data. Our proposed pseudo-labeling strategy is network structure agnostic to apply in a one-stage consistency training framework. We demonstrate the effectiveness of the proposed pseudo-labeling strategy in both low-data and high-data regimes. Extensive experiments have validated that pseudo labels generated from wisely fusing diverse sources and strong data augmentation are crucial to consistency training for segmentation. The source code will be released.",
    "One-sentence Summary": "This paper presents a new method that first demonstrates how well-calibrated soft pseudo labels obtained through wise fusion of predictions from diverse sources greatly improve consistency training for semantic segmentation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "googleinterns/wss +  1 community implementation",
    "Data": "COCO, VOC 2012"
  },
  {
    "title": "Counterfactual Generative Networks",
    "url": "/forum?id=BXewfAYMmJw",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Causality, Counterfactuals, Generative Models, Robustness, Image Classification, Data Augmentation",
    "Abstract": "Neural networks are prone to learning shortcuts -- they often model simple correlations, ignoring more complex ones that potentially generalize better. Prior works on image classification show that instead of learning a connection to object shape, deep classifiers tend to exploit spurious correlations with low-level texture or the background for solving the classification task. In this work, we take a step towards more robust and interpretable classifiers that explicitly expose the task's causal structure. Building on current advances in deep generative modeling, we propose to decompose the image generation process into independent causal mechanisms that we train without direct supervision. By exploiting appropriate inductive biases, these mechanisms disentangle object shape, object texture, and background; hence, they allow for generating counterfactual images. We demonstrate the ability of our model to generate such images on MNIST and ImageNet. Further, we show that the counterfactual images can improve out-of-distribution robustness with a marginal drop in performance on the original classification task, despite being synthetic. Lastly, our generative model can be trained efficiently on a single GPU, exploiting common pre-trained models as inductive biases.",
    "One-sentence Summary": "A generative model structured into independent causal mechanisms produces images for training invariant classifiers.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "autonomousvision/counterfactual_generative_networks",
    "Data": "Colored MNIST, ImageNet"
  },
  {
    "title": "Contemplating Real-World Object Classification",
    "url": "/forum?id=Q4EUywJIkqr",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "object recognition, deep learning, ObjectNet, Robustness",
    "Abstract": "Deep object recognition models have been very successful over benchmark\n        datasets such as ImageNet. How accurate and robust are they to distribution\n        shifts arising from natural and synthetic variations in datasets? Prior research on\n        this problem has primarily focused on ImageNet variations (e.g., ImageNetV2,\n        ImageNet-A). To avoid potential inherited biases in these studies, we take a\n        different approach. Specifically, we reanalyze the ObjectNet dataset recently\n        proposed by Barbu et al. containing objects in daily life situations. They showed\n        a dramatic performance drop of the state of the art object recognition models on\n        this dataset. Due to the importance and implications of their results regarding\n        the generalization ability of deep models, we take a second look at their analysis.\n        We find that applying deep models to the isolated objects, rather than the entire\n        scene as is done in the original paper, results in around 20-30% performance\n        improvement. Relative to the numbers reported in Barbu et al., around 10-15%\n        of the performance loss is recovered, without any test time data augmentation.\n        Despite this gain, however, we conclude that deep models still suffer drastically\n        on the ObjectNet dataset. We also investigate the robustness of models against\n        synthetic image perturbations such as geometric transformations (e.g., scale,\n        rotation, translation), natural image distortions (e.g., impulse noise, blur) as well\n        as adversarial attacks (e.g., FGSM and PGD-5). Our results indicate that limiting\n        the object area as much as possible (i.e., from the entire image to the bounding\n        box to the segmentation mask) leads to consistent improvement in accuracy and\n        robustness. Finally, through a qualitative analysis of ObjectNet data, we find that\n        i) a large number of images in this dataset are hard to recognize even for humans,\n        and ii) easy (hard) samples for models match with easy (hard) samples for humans.\n        Overall, our analysis shows that ObjecNet is still a challenging test platform that\n        can be used to measure the generalization ability of models. The code and data\n        are available in [masked due to blind review].",
    "One-sentence Summary": "We address whether current deep learning models are able to solve object recognition in real world and how robust they are to synthetic and natural distribution shifts.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "COCO, MNIST, ObjectNet"
  },
  {
    "title": "Explainable Deep One-Class Classification",
    "url": "/forum?id=A5VV3UyIQz",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "anomaly-detection, deep-learning, explanations, interpretability, xai, one-class-classification, deep-anomaly-detection, novelty-detection, outlier-detection",
    "Abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.",
    "One-sentence Summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "liznerski/fcdd",
    "Data": "CIFAR-10, CIFAR-100, Fashion-MNIST, ImageNet, MNIST, MVTecAD"
  },
  {
    "title": "Batch Reinforcement Learning Through Continuation Method",
    "url": "/forum?id=po-DLlBuAuz",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "batch reinforcement learning, continuation method, relaxed regularization",
    "Abstract": "Many real-world applications of reinforcement learning (RL) require the agent to learn from a fixed set of trajectories, without collecting new interactions.  Policy optimization under this setting is extremely challenging as: 1) the geometry of the objective function is hard to optimize efficiently; 2) the shift of data distributions causes high noise in the value estimation. In this work, we propose a simple yet effective policy iteration approach to batch RL using global optimization techniques known as continuation.  By constraining the difference between the learned policy and the behavior policy that generates the fixed trajectories, and continuously relaxing the constraint, our method 1) helps the agent escape local optima; 2) reduces the error in policy evaluation in the optimization procedure.   We present results on a variety of control tasks, game environments, and a recommendation task to empirically demonstrate the efficacy of our proposed method.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "Arcade Learning Environment"
  },
  {
    "title": "Protecting DNNs from Theft using an Ensemble of Diverse Models",
    "url": "/forum?id=LucJxySuJcE",
    "date": "28 Sept 2020 (modified: 06 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Model stealing, machine learning security",
    "Abstract": "Several recent works have demonstrated highly effective model stealing (MS) attacks on Deep Neural Networks (DNNs) in black-box settings, even when the training data is unavailable. These attacks typically use some form of Out of Distribution (OOD) data to query the target model and use the predictions obtained to train a clone model. Such a clone model learns to approximate the decision boundary of the target model, achieving high accuracy on in-distribution examples. We propose Ensemble of Diverse Models (EDM) to defend against such MS attacks. EDM is made up of models that are trained to produce dissimilar predictions for OOD inputs. By using a different member of the ensemble to service different queries, our defense produces predictions that are highly discontinuous in the input space for the adversary's OOD queries. Such discontinuities cause the clone model trained on these predictions to have poor generalization on in-distribution examples. Our evaluations on several image classification tasks demonstrate that EDM defense can severely degrade the accuracy of clone models (up to 39.7%). Our defense has minimal impact on the target accuracy, negligible computational costs during inference, and is compatible with existing defenses for MS attacks.",
    "One-sentence Summary": "Discontinuous predictions produced by an ensemble of diverse models can be used to create an effective defense against model stealing attacks.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Domain Generalization with MixStyle",
    "url": "/forum?id=6xHJ37MVxxp",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Domain Generalization, Style Mixing",
    "Abstract": "Though convolutional neural networks (CNNs) have demonstrated remarkable ability in learning discriminative features, they often generalize poorly to unseen domains. Domain generalization aims to address this problem by learning from a set of source domains a model that is generalizable to any unseen domain. In this paper, a novel approach is proposed based on probabilistically mixing instance-level feature statistics of training samples across source domains. Our method, termed MixStyle, is motivated by the observation that visual domain is closely related to image style (e.g., photo vs.~sketch images). Such style information is captured by the bottom layers of a CNN where our proposed style-mixing takes place. Mixing styles of training instances results in novel domains being synthesized implicitly, which increase the domain diversity of the source domains, and hence the generalizability of the trained model. MixStyle fits into mini-batch training perfectly and is extremely easy to implement. The effectiveness of MixStyle is demonstrated on a wide range of tasks including category classification, instance retrieval and reinforcement learning.",
    "One-sentence Summary": "MixStyle makes CNNs more domain-generalizable by mixing instance-level feature statistics of training samples across domains.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "KaiyangZhou/Dassl.pytorch +  2 community implementations",
    "Data": "Market-1501, PACS"
  },
  {
    "title": "Efficient Inference of Flexible Interaction in Spiking-neuron Networks",
    "url": "/forum?id=aGfU_xziEX8",
    "date": "28 Sept 2020 (modified: 16 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "neural spike train, nonlinear Hawkes process, auxiliary latent variable, conjugacy",
    "Abstract": "Hawkes process provides an effective statistical framework for analyzing the time-dependent interaction of neuronal spiking activities. Although utilized in many real applications, the classic Hawkes process is incapable of modelling inhibitory interactions among neurons. Instead, the nonlinear Hawkes process allows for a more flexible influence pattern with excitatory or inhibitory interactions. In this paper, three sets of auxiliary latent variables (Polya-Gamma variables, latent marked Poisson processes and sparsity variables) are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. As a result, an efficient expectation-maximization (EM) algorithm is derived to obtain the maximum a posteriori (MAP) estimate. We demonstrate the accuracy and efficiency performance of our algorithm on synthetic and real data. For real neural recordings, we show our algorithm can estimate the temporal dynamics of interaction and reveal the interpretable functional connectivity underlying neural spike trains.",
    "One-sentence Summary": "An efficient conjugate EM algorithm for nonlinear multivariate Hawkes processes based on auxiliary latent variables augmentation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation",
    "url": "/forum?id=R2ZlTVPx0Gk",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Deep Learning, Deep Ensembles, Information Theory, Information Bottleneck, Adversarial Learning",
    "Abstract": "Deep ensembles perform better than a single network thanks to the diversity among their members. Recent approaches regularize predictions to increase diversity; however, they also drastically decrease individual members\u2019 performances. In this paper, we argue that learning strategies for deep ensembles need to tackle the trade-off between ensemble diversity and individual accuracies. Motivated by arguments from information theory and leveraging recent advances in neural estimation of conditional mutual information, we introduce a novel training criterion called DICE: it increases diversity by reducing spurious correlations among features. The main idea is that features extracted from pairs of members should only share information useful for target class prediction without being conditionally redundant. Therefore, besides the classification loss with information bottleneck, we adversarially prevent features from being conditionally predictable from each other. We manage to reduce simultaneous errors while protecting class information. We obtain state-of-the-art accuracy results on CIFAR-10/100: for example, an ensemble of 5 networks trained with DICE matches an ensemble of 7 networks trained independently. We further analyze the consequences on calibration, uncertainty estimation, out-of-distribution detection and online co-distillation.",
    "One-sentence Summary": "Driven by arguments from information theory, we introduce a new learning strategy for deep ensembles that increases diversity among members: we adversarially prevent features from being conditionally redundant, i.e., predictable from each other.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, CIFAR-100"
  },
  {
    "title": "Universal Weakly Supervised Segmentation by Pixel-to-Segment Contrastive Learning",
    "url": "/forum?id=N33d7wjgzde",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "weakly supervised representation learning, representation learning for computer vision, metric learning, semantic segmentation",
    "Abstract": "Weakly supervised segmentation requires assigning a label to every pixel based on training instances with partial annotations such as image-level tags, object bounding boxes, labeled points and scribbles. This task is challenging, as coarse annotations (tags, boxes) lack precise pixel localization whereas sparse annotations (points, scribbles) lack broad region coverage. Existing methods tackle these two types of weak supervision differently: Class activation maps are used to localize coarse labels and iteratively refine the segmentation model, whereas conditional random fields are used to propagate sparse labels to the entire image.\n        \n        We formulate weakly supervised segmentation as a semi-supervised metric learning problem, where pixels of the same (different) semantics need to be mapped to the same (distinctive) features. We propose 4 types of contrastive relationships between pixels and segments in the feature space, capturing low-level image similarity, semantic annotation, co-occurrence, and feature affinity They act as priors; the pixel-wise feature can be learned from training images with any partial annotations in a data-driven fashion. In particular, unlabeled pixels in training images participate not only in data-driven grouping within each image, but also in discriminative feature learning within and across images. We deliver a universal weakly supervised segmenter with significant gains on Pascal VOC and DensePose. Our code is publicly available at https://github.com/twke18/SPML.",
    "One-sentence Summary": "We propose a unified pixel-to-segment contrastive learning loss formulation for weakly supervised semantic segmentation with various types of annotations.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "twke18/SPML",
    "Data": "DensePose, PASCAL VOC, VOC 2012"
  },
  {
    "title": "Shape-Texture Debiased Neural Network Training",
    "url": "/forum?id=Db4yerZTYkz",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "data augmentation, representation learning, debiased training",
    "Abstract": "Shape and texture are two prominent and complementary cues for recognizing objects. Nonetheless, Convolutional Neural Networks are often biased towards either texture or shape, depending on the training dataset. Our ablation shows that such bias degenerates model performance. Motivated by this observation, we develop a simple algorithm for shape-texture debiased learning. To prevent models from exclusively attending on a single cue in representation learning, we augment training data with images with conflicting shape and texture information (eg, an image of chimpanzee shape but with lemon texture) and, most importantly, provide the corresponding supervisions from shape and texture simultaneously. \n        \n        Experiments show that our method successfully improves model performance on several image recognition benchmarks and adversarial robustness. For example, by training on ImageNet, it helps ResNet-152 achieve substantial improvements on ImageNet (+1.2%), ImageNet-A  (+5.2%), ImageNet-C (+8.3%) and Stylized-ImageNet (+11.1%), and on defending against FGSM adversarial attacker on ImageNet (+14.4%). Our method also claims to be compatible with other advanced data augmentation strategies, eg, Mixup, and CutMix. The code is available here: https://github.com/LiYingwei/ShapeTextureDebiasedTraining.",
    "One-sentence Summary": "Training CNNs to acquire a debiased shape-texture representation improves image recognition.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "LiYingwei/ShapeTextureDebiasedTraining",
    "Data": "ImageNet, ImageNet-A, ImageNet-C, ImageNet-Sketch, Stylized ImageNet"
  },
  {
    "title": "Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling",
    "url": "/forum?id=IDFQI9OY6K",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "weak supervision, data programming, data labeling, active learning",
    "Abstract": "Obtaining large annotated datasets is critical for training successful machine learning models and it is often a bottleneck in practice. Weak supervision offers a promising alternative for producing labeled datasets without ground truth annotations by generating probabilistic labels using multiple noisy heuristics. This process can scale to large datasets and has demonstrated state of the art performance in diverse domains such as healthcare and e-commerce. One practical issue with learning from user-generated heuristics is that their creation requires creativity, foresight, and domain expertise from those who hand-craft them, a process which can be tedious and subjective. We develop the first framework for interactive weak supervision in which a method proposes heuristics and learns from user feedback given on each proposed heuristic. Our experiments demonstrate that only a small number of feedback iterations are needed to train models that achieve highly competitive test set performance without access to ground truth training labels. We conduct user studies, which show that users are able to effectively provide feedback on heuristics and that test set results track the performance of simulated oracles.",
    "One-sentence Summary": "We introduce a framework and method for training classifiers on datasets without ground truth annotation by interacting  with domain experts to discover good weak supervision sources.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "benbo/interactive-weak-supervision",
    "Data": "Amazon Product Data, BiasBios, COCO, IMDb Movie Reviews"
  },
  {
    "title": "MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond",
    "url": "/forum?id=8e6BrwU6AjQ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "visual counting, visual question answering, common object counting, visual reasoning, modulated convolution",
    "Abstract": "This paper focuses on visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, we propose a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. Following the design of residual bottleneck, we call our method MoVie, short for Modulated conVolutional bottlenecks. Notably, MoVie reasons implicitly and holistically and only needs a single forward-pass during inference. Nevertheless, MoVie showcases strong performance for counting: 1) advancing the state-of-the-art on counting-specific VQA tasks while being more efficient; 2) outperforming prior-art on difficult benchmarks like COCO for common object counting; 3) helped us secure the first place of 2020 VQA challenge when integrated as a module for \u2018number\u2019 related questions in generic VQA models. Finally, we show evidence that modulated convolutions such as MoVie can serve as a general mechanism for reasoning tasks beyond counting.",
    "One-sentence Summary": "2020 VQA challenge winner; state-of-the-art performance on three counting benchmarks; can work beyond counting towards general visual reasoning",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "facebookresearch/mmf",
    "Data": "CLEVR, COCO, GQA, ImageNet, TallyQA, Visual Question Answering v2.0"
  },
  {
    "title": "Improve Object Detection with Feature-based Knowledge Distillation: Towards Accurate and Efficient Detectors",
    "url": "/forum?id=uKhGRvM8QNH",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Knowledge Distillation, Object Detection, Teacher-Student Learning, Non-Local Modules, Attention Modules",
    "Abstract": "Knowledge distillation, in which a student model is trained to mimic a teacher model, has been proved as an effective technique for model compression and model accuracy boosting. However, most knowledge distillation methods, designed for image classification, have failed on more challenging tasks, such as object detection. In this paper, we suggest that the failure of knowledge distillation on object detection is mainly caused by two reasons: (1) the imbalance between pixels of foreground and background and (2) lack of distillation on the relation between different pixels. Observing the above reasons, we propose attention-guided distillation and non-local distillation to address the two problems, respectively.  Attention-guided distillation is proposed to find the crucial pixels of foreground objects with attention mechanism and then make the students take more effort to learn their features. Non-local distillation is proposed to enable students to learn not only the feature of an individual pixel but also the relation between different pixels captured by non-local modules. Experiments show that our methods achieve excellent AP improvements on both one-stage and two-stage, both anchor-based and anchor-free detectors. For example, Faster RCNN (ResNet101 backbone) with our distillation achieves 43.9 AP on COCO2017, which is 4.1 higher than the baseline. Codes have been released on Github.",
    "One-sentence Summary": "We propose two knowledge distillation methods on object detection - attention-guided distillation and non-local distillation which lead to 4.1 AP improvements on Faster RCNN101 in MS COCO2017.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "COCO"
  },
  {
    "title": "Revisiting Dynamic Convolution via Matrix Decomposition",
    "url": "/forum?id=YwpZmcAehZ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "supervised representation learning, efficient network, dynamic network, matrix decomposition",
    "Abstract": "Recent research in dynamic convolution shows substantial performance boost for efficient CNNs, due to the adaptive aggregation of K static convolution kernels. It has two limitations: (a) it increases the number of convolutional weights by K-times, and (b) the joint optimization of dynamic attention and static convolution kernels is challenging. In this paper, we revisit it from a new perspective of matrix decomposition and reveal the key issue is that dynamic convolution applies dynamic attention over channel groups after projecting into a higher dimensional latent space. To address this issue, we propose dynamic channel fusion to replace dynamic attention over channel groups. Dynamic channel fusion not only enables significant dimension reduction of the latent space, but also mitigates the joint optimization difficulty. As a result, our method is easier to train and requires significantly fewer parameters without sacrificing accuracy. Source code is at https://github.com/liyunsheng13/dcd.",
    "One-sentence Summary": "Efficient network with dynamic matrix decomposition",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "liyunsheng13/dcd",
    "Data": "ImageNet"
  },
  {
    "title": "DynaTune: Dynamic Tensor Program Optimization in Deep Neural Network Compilation",
    "url": "/forum?id=GTGb3M_KcUl",
    "date": "28 Sept 2020 (modified: 15 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Efficient Deep Learning Inference, Scalability, Code Compilation, Bayesian Inference",
    "Abstract": "Recently, the DL compiler, together with Learning to Compile has proven to be a powerful technique for optimizing deep learning models. However, existing methods focus on accelerating the convergence speed of the individual tensor operator rather than the convergence speed of the entire model, which results in long optimization time to obtain a desired latency.\n        \n        In this paper, we present a new method called DynaTune, which provides significantly faster convergence speed to optimize a DNN model. In particular, we consider a Multi-Armed Bandit (MAB) model for the tensor program optimization problem. We use UCB to handle the decision-making of time-slot-based optimization, and we devise a Bayesian belief model that allows predicting the potential performance gain of each operator with uncertainty quantification, which guides the optimization process. We evaluate and compare DynaTune with the state-of-the-art DL compiler. The experiment results show that DynaTune is 1.2--2.4 times faster to achieve the same optimization quality for a range of models across different hardware architectures.",
    "One-sentence Summary": "We accelerate tensor program optimization by considering it as a multi-armed bandits problem and using Bayesian inference to achieve fast convergence.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "MALI: A memory efficient and reverse accurate integrator for Neural ODEs",
    "url": "/forum?id=blfSjHeFM_e",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "neural ode, memory efficient, reverse accuracy, gradient estimation",
    "Abstract": "Neural ordinary differential equations (Neural ODEs) are a new family of deep-learning models with continuous depth. However, the numerical estimation of the gradient in the continuous case is not well solved: existing implementations of the adjoint method suffer from inaccuracy in reverse-time trajectory, while the naive method and the adaptive checkpoint adjoint method (ACA) have a memory cost that grows with integration time. In this project, based on the asynchronous leapfrog (ALF) solver, we propose the Memory-efficient ALF Integrator (MALI), which has a constant memory cost w.r.t integration time similar to the adjoint method, and guarantees accuracy in reverse-time trajectory (hence accuracy in gradient estimation). We validate MALI in various tasks: on image recognition tasks, to our knowledge, MALI is the first to enable feasible training of a Neural ODE on ImageNet and outperform a well-tuned ResNet, while existing methods fail due to either heavy memory burden or inaccuracy; for time series modeling, MALI significantly outperforms the adjoint method; and for continuous generative models, MALI achieves new state-of-the-art performance. We provide a pypi package: https://jzkay12.github.io/TorchDiffEqPack",
    "One-sentence Summary": "A solver for ODE that guarantees accuracy in reverse-time trajectory  at a constant memory cost",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "juntang-zhuang/TorchDiffEqPack",
    "Data": "CIFAR-10, DeepMind Control Suite, ImageNet"
  },
  {
    "title": "Bag of Tricks for Adversarial Training",
    "url": "/forum?id=Xb8xvrtB8Ce",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Adversarial Training, Robustness, Adversarial Examples",
    "Abstract": "Adversarial training (AT) is one of the most effective strategies for promoting model robustness. However, recent benchmarks show that most of the proposed improvements on AT are less effective than simply early stopping the training procedure. This counter-intuitive fact motivates us to investigate the implementation details of tens of AT methods. Surprisingly, we find that the basic settings (e.g., weight decay, training schedule, etc.) used in these methods are highly inconsistent. In this work, we provide comprehensive evaluations on CIFAR-10, focusing on the effects of mostly overlooked training tricks and hyperparameters for adversarially trained models. Our empirical observations suggest that adversarial robustness is much more sensitive to some basic training settings than we thought. For example, a slightly different value of weight decay can reduce the model robust accuracy by more than 7%, which is probable to override the potential promotion induced by the proposed methods. We conclude a baseline training setting and re-implement previous defenses to achieve new state-of-the-art results. These facts also appeal to more concerns on the overlooked confounders when benchmarking defenses.",
    "One-sentence Summary": "Empirical evaluation of basic training tricks used in adversarial training",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "fra31/auto-attack +  1 community implementation",
    "Data": "CIFAR-10, ImageNet"
  },
  {
    "title": "Learning to Generate 3D Shapes with Generative Cellular Automata",
    "url": "/forum?id=rABUmU3ulQh",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "3D generation, generative models",
    "Abstract": "In this work, we present a probabilistic 3D generative model, named Generative Cellular Automata, which is able to produce diverse and high quality shapes. We formulate the shape generation process as sampling from the transition kernel of a Markov chain, where the sampling chain eventually evolves to the full shape of the learned distribution. The transition kernel employs the local update rules of cellular automata, effectively reducing the search space in a high-resolution 3D grid space by exploiting the connectivity and sparsity of 3D shapes. Our progressive generation only focuses on the sparse set of occupied voxels and their neighborhood, thus enables the utilization of an expressive sparse convolutional network. We propose an effective training scheme to obtain the local homogeneous rule of generative cellular automata with sequences that are slightly different from the sampling chain but converge to the full shapes in the training data. Extensive experiments on probabilistic shape completion and shape generation demonstrate that our method achieves competitive performance against recent methods.",
    "One-sentence Summary": "We present a Markov chain based 3D generative model named Generative Cellular Automata (GCA), that progressively evolves to a shape of the learned distribution using the local update rules of cellular automata.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "PartNet, ShapeNet"
  },
  {
    "title": "SEED: Self-supervised Distillation For Visual Representation",
    "url": "/forum?id=AHm3dbp7D1D",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Self Supervised Learning, Knowledge Distillation, Representation Learning",
    "Abstract": "This paper is concerned with self-supervised learning for small models. The problem is motivated by our empirical studies that while the widely used contrastive self-supervised learning method has shown great progress on large model training, it does not work well for small models. To address this problem, we propose a new learning paradigm, named SElf-SupErvised Distillation (SEED), where we leverage a larger network (as Teacher) to transfer its representational knowledge into a smaller architecture (as Student) in a self-supervised fashion. Instead of directly learning from unlabeled data, we train a student encoder to mimic the similarity score distribution inferred by a teacher over a set of instances. We show that SEED dramatically boosts the performance of small networks on downstream tasks. Compared with self-supervised baselines, SEED improves the top-1 accuracy from 42.2% to 67.6% on EfficientNet-B0 and from 36.3% to 68.2% on MobileNet-v3-Large on the ImageNet-1k dataset.",
    "One-sentence Summary": "We propose SEED, a self-supervised distillation technique for visual representation learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "jacobswan1/SEED",
    "Data": "CIFAR-10, CIFAR-100, COCO, ImageNet"
  },
  {
    "title": "PDE-Driven Spatiotemporal Disentanglement",
    "url": "/forum?id=vLaHRtHvfFp",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "disentanglement, spatiotemporal prediction, representation learning, dynamical systems, separation of variables",
    "Abstract": "A recent line of work in the machine learning community addresses the problem of predicting high-dimensional spatiotemporal phenomena by leveraging specific tools from the differential equations theory. Following this direction, we propose in this article a novel and general paradigm for this task based on a resolution method for partial differential equations: the separation of variables. This inspiration allows us to introduce a dynamical interpretation of spatiotemporal disentanglement. It induces a principled model based on learning disentangled spatial and temporal representations of a phenomenon to accurately predict future observations. We experimentally demonstrate the performance and broad applicability of our method against prior state-of-the-art models on physical and synthetic video datasets.",
    "One-sentence Summary": "We introduce a novel interpretation of spatiotemporal disentanglement, inducing a simple and performant disentangled prediction model.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "JeremDona/spatiotemporal_variable_separation",
    "Data": "Chairs, MNIST, Moving MNIST"
  },
  {
    "title": "Rethinking Soft Labels for Knowledge Distillation: A Bias\u2013Variance Tradeoff Perspective",
    "url": "/forum?id=gIHd-5X324",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Knowledge distillation, soft labels, teacher-student model",
    "Abstract": "Knowledge distillation is an effective approach to leverage a well-trained network or an ensemble of them, named as the teacher, to guide the training of a student network.  The outputs from the teacher network are used as soft labels for supervising the training of a new network.  Recent studies (M \u0308uller et al., 2019; Yuan et al., 2020) revealed an intriguing property of the soft labels that making labels soft serves as a good regularization to the student network.   From the perspective of statistical learning,  regularization aims to reduce the variance,  however how bias and variance change is not clear for training with soft labels.   In this paper, we investigate the bias-variance tradeoff brought by distillation with soft labels.   Specifically,  we observe that during training the bias-variance tradeoff varies sample-wisely. Further, under the same distillation temperature setting, we observe that the distillation performance is negatively associated with the number of some specific samples, which are named as regularization samples since these samples lead to bias increasing and variance decreasing.  Nevertheless, we empirically find that completely filtering out regularization samples also deteriorates distillation performance.  Our discoveries inspired us to propose the novel weighted soft labels to help the network adaptively handle the sample-wise bias-variance tradeoff.  Experiments on standard evaluation benchmarks validate the effectiveness of our method. Our code is available in the supplementary.",
    "One-sentence Summary": "For knowledge distillation, we analyze the regularization effect introduced by soft labels from a bias-variance perspective and propose weighted soft labels to handle the tradeoff.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-100, ImageNet"
  },
  {
    "title": "Distributed Momentum for Byzantine-resilient Stochastic Gradient Descent",
    "url": "/forum?id=H8UHdhWG6A3",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Byzantine SGD, Distributed ML, Momentum",
    "Abstract": "Byzantine-resilient Stochastic Gradient Descent (SGD) aims at shielding model training from Byzantine faults, be they ill-labeled training datapoints, exploited software/hardware vulnerabilities, or malicious worker nodes in a distributed setting.\n        Two recent attacks have been challenging state-of-the-art defenses though, often successfully precluding the model from even fitting the training set.\n        The main identified weakness in current defenses is their requirement of a sufficiently low variance-norm ratio for the stochastic gradients.\n        We propose a practical method which, despite increasing the variance, reduces the variance-norm ratio, mitigating the identified weakness.\n        We assess the effectiveness of our method over 736 different training configurations, comprising the 2 state-of-the-art attacks and 6 defenses.\n        For confidence and reproducibility purposes, each configuration is run 5 times with specified seeds (1 to 5), totalling 3680 runs.\n        In our experiments, when the attack is effective enough to decrease the highest observed top-1 cross-accuracy by at least 20% compared to the unattacked run, our technique systematically increases back the highest observed accuracy, and is able to recover at least 20% in more than 60% of the cases.",
    "One-sentence Summary": "An inexpensive method to substantially improve the effectiveness of existing Byzantine-resilient SGD defenses, assessed against state-of-the-art attacks and supported by theoretical insights.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "Fashion-MNIST"
  },
  {
    "title": "Scaling the Convex Barrier with Active Sets",
    "url": "/forum?id=uQfOy7LrlTR",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Neural Network Verification, Neural Network Bounding, Optimisation for Deep Learning",
    "Abstract": "Tight and efficient neural network bounding is of critical importance for the scaling of neural network verification systems. A number of efficient specialised dual solvers for neural network bounds have been presented recently, but they are often too loose to verify more challenging properties. This lack of tightness is linked to the weakness of the employed relaxation, which is usually a linear program of size linear in the number of neurons. While a tighter linear relaxation for piecewise linear activations exists, it comes at the cost of exponentially many constraints and thus currently lacks an efficient customised solver. We alleviate this deficiency via a novel dual algorithm that realises the full potential of the new relaxation by operating on a small active set of dual variables. Our method recovers the strengths of the new relaxation in the dual space: tightness and a linear separation oracle. At the same time, it shares the benefits of previous dual approaches for weaker relaxations: massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time. As a consequence, we obtain better bounds than off-the-shelf solvers in only a fraction of their running time and recover the speed-accuracy trade-offs of looser dual solvers if the computational budget is small. We demonstrate that this results in significant formal verification speed-ups.",
    "One-sentence Summary": "We present a specialised dual solver for a tight ReLU convex relaxation and show that it speeds up formal network verification.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, MNIST"
  },
  {
    "title": "BSQ: Exploring Bit-Level Sparsity for Mixed-Precision Neural Network Quantization",
    "url": "/forum?id=TiXl51SCNw8",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Mixed-precision quantization, bit-level sparsity, DNN compression",
    "Abstract": "Mixed-precision quantization can potentially achieve the optimal tradeoff between performance and compression rate of deep neural networks, and thus, have been widely investigated. However, it lacks a systematic method to determine the exact quantization scheme. Previous methods either examine only a small manually-designed search space or utilize a cumbersome neural architecture search to explore the vast search space. These approaches cannot lead to an optimal quantization scheme efficiently. This work proposes bit-level sparsity quantization (BSQ) to tackle the mixed-precision quantization from a new angle of inducing bit-level sparsity. We consider each bit of quantized weights as an independent trainable variable and introduce a differentiable bit-sparsity regularizer. BSQ can induce all-zero bits across a group of weight elements and realize the dynamic precision reduction, leading to a mixed-precision quantization scheme of the original model. Our method enables the exploration of the full mixed-precision space with a single gradient-based optimization process, with only one hyperparameter to tradeoff the performance and compression. BSQ achieves both higher accuracy and higher bit reduction on various model architectures on the CIFAR-10 and ImageNet datasets comparing to previous methods.",
    "One-sentence Summary": "We propose bit-level sparsity inducing regularizer to induce mixed-percision quantization scheme in DNN with gradient-based training.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "yanghr/BSQ",
    "Data": "CIFAR-10"
  },
  {
    "title": "Dual-mode ASR: Unify and Improve Streaming ASR with Full-context Modeling",
    "url": "/forum?id=Pz_dcqfcKW8",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Speech Recognition, Streaming ASR, Low-latency ASR, Dual-mode ASR",
    "Abstract": "Streaming automatic speech recognition (ASR) aims to emit each hypothesized word as quickly and accurately as possible, while full-context ASR waits for the completion of a full speech utterance before emitting completed hypotheses. In this work, we propose a unified framework, Dual-mode ASR, to train a single end-to-end ASR model with shared weights for both streaming and full-context speech recognition. We show that the latency and accuracy of streaming ASR significantly benefit from weight sharing and joint training of full-context ASR, especially with inplace knowledge distillation during the training. The Dual-mode ASR framework can be applied to recent state-of-the-art convolution-based and transformer-based ASR networks. We present extensive experiments with two state-of-the-art ASR networks, ContextNet and Conformer, on two datasets, a widely used public dataset LibriSpeech and a large-scale dataset MultiDomain. Experiments and ablation studies demonstrate that Dual-mode ASR not only simplifies the workflow of training and deploying streaming and full-context ASR models, but also significantly improves both emission latency and recognition accuracy of streaming ASR. With Dual-mode ASR, we achieve new state-of-the-art streaming ASR results on both LibriSpeech and MultiDomain in terms of accuracy and latency.",
    "One-sentence Summary": "Dual-mode ASR unifies and improves Streaming ASR with full-context modeling, simplifying the development and deployment workflow and improving both latency and accuracy.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "LibriSpeech"
  },
  {
    "title": "Policy-Driven Attack: Learning to Query for Hard-label Black-box Adversarial Examples",
    "url": "/forum?id=pzpytjk3Xb2",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "hard-label attack, black-box attack, adversarial attack, reinforcement learning",
    "Abstract": "To craft black-box adversarial examples, adversaries need to query the victim model and take proper advantage of its feedback. Existing black-box attacks generally suffer from high query complexity, especially when only the top-1 decision (i.e., the hard-label prediction) of the victim model is available.  In this paper, we propose a novel hard-label black-box attack named Policy-Driven Attack, to reduce the query complexity. Our core idea is to learn promising search directions of the adversarial examples using a well-designed policy network in a novel reinforcement learning formulation, in which the queries become more sensible. Experimental results demonstrate that our method can significantly reduce the query complexity in comparison with existing state-of-the-art hard-label black-box attacks on various image classification benchmark datasets. Code and models for reproducing our results are available at https://github.com/ZiangYan/pda.pytorch",
    "One-sentence Summary": "A novel hard-label black-box adversarial attack that introduces a reinforcement learning based formulation with a pre-trained policy network",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10"
  },
  {
    "title": "PSTNet: Point Spatio-Temporal Convolution on Point Cloud Sequences",
    "url": "/forum?id=O3bqkf_Puys",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Point cloud, spatio-temporal modeling, video analysis, action recognition, semantic segmentation, convolutional neural network",
    "Abstract": "Point cloud sequences are irregular and unordered in the spatial dimension while exhibiting regularities and order in the temporal dimension. Therefore, existing grid based convolutions for conventional video processing cannot be directly applied to spatio-temporal modeling of raw point cloud sequences. In this paper, we propose a point spatio-temporal (PST) convolution to achieve informative representations of point cloud sequences. The proposed PST convolution first disentangles space and time in point cloud sequences.  Then, a spatial convolution is employed to capture the local structure of points in the 3D space, and a temporal convolution is used to model the dynamics of the spatial regions along the time dimension.  Furthermore, we incorporate the proposed PST convolution into a deep network, namely PSTNet, to extract features of point cloud sequences in a hierarchical manner.  Extensive experiments on widely-used 3D action recognition and 4D semantic segmentation datasets demonstrate the effectiveness of PSTNet to model point cloud sequences.",
    "One-sentence Summary": "This paper proposes a point spatio-temporal (PST) convolution, which decomposes space and time, to learn representations of raw point cloud sequences in a spatio-temporally hierarchical manner.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "NTU RGB+D, SYNTHIA"
  },
  {
    "title": "Network Pruning That Matters:  A Case Study on Retraining Variants",
    "url": "/forum?id=Cb54AMqHQFP",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Network Pruning",
    "Abstract": "Network pruning is an effective method to reduce the computational expense of over-parameterized neural networks for deployment on low-resource systems. Recent state-of-the-art techniques for retraining pruned networks such as weight rewinding and learning rate rewinding have been shown to outperform the traditional fine-tuning technique in recovering the lost accuracy (Renda et al., 2020), but so far it is unclear what accounts for such performance. In this work, we conduct extensive experiments to verify and analyze the uncanny effectiveness of learning rate rewinding. We find that the reason behind the success of learning rate rewinding is the usage of a large learning rate. Similar phenomenon can be observed in other learning rate schedules that involve large learning rates, e.g., the 1-cycle learning rate schedule (Smith et al., 2019). By leveraging the right learning rate schedule in retraining, we demonstrate a counter-intuitive phenomenon in that randomly pruned networks could even achieve better performance than methodically pruned networks (fine-tuned with the conventional approach). Our results emphasize the cruciality of the learning rate schedule in pruned network retraining - a detail often overlooked by practitioners during the implementation of network pruning.",
    "One-sentence Summary": "We study the effective of different retraining mechanisms while doing pruning",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "lehduong/NPTM",
    "Data": "ImageNet"
  },
  {
    "title": "EEC: Learning to Encode and Regenerate Images for Continual Learning",
    "url": "/forum?id=lWaz5a9lcFU",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Continual Learning, Catastrophic Forgetting, Cognitively-inspired Learning",
    "Abstract": "The two main impediments to continual learning are catastrophic forgetting and memory limitations on the storage of data. To cope with these challenges, we propose a novel, cognitively-inspired approach which trains autoencoders with Neural Style Transfer to encode and store images. Reconstructed images from encoded episodes are replayed when training the classifier model on a new task to avoid catastrophic forgetting. The loss function for the reconstructed images is weighted to reduce its effect during classifier training to cope with image degradation. When the system runs out of memory the encoded episodes are converted into centroids and covariance matrices, which are used to generate pseudo-images during classifier training, keeping classifier performance stable with less memory. Our approach increases classification accuracy by 13-17% over state-of-the-art methods on benchmark datasets, while requiring 78% less storage space.",
    "One-sentence Summary": "We train autoencoders with Neural Style Transfer to replay old tasks data for continual learning. The encoded features are converted into centroids and covariances to keep memory footprint from growing while keeping classifier performance stable.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "aliayub7/EEC"
  },
  {
    "title": "DARTS-: Robustly Stepping out of Performance Collapse Without Indicators",
    "url": "/forum?id=KLH36ELmwIB",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "neural architecture search, DARTS stability",
    "Abstract": "Despite the fast development of differentiable architecture search (DARTS), it suffers from a standing instability issue regarding searching performance, which extremely limits its application. Existing robustifying methods draw clues from the outcome instead of finding out the causing factor. Various indicators such as Hessian eigenvalues are proposed as a signal of performance collapse, and the searching should be stopped once an indicator reaches a preset threshold.\n        However, these methods tend to easily reject good architectures if thresholds are inappropriately set, let alone the searching is intrinsically noisy. In this paper, we undertake a more subtle and direct approach to resolve the collapse. \n        We first demonstrate that skip connections with a learnable architectural coefficient can easily recover from a disadvantageous state and become dominant.  We conjecture that skip connections profit too much from this privilege, hence causing the collapse for the derived model. Therefore, we propose to factor out this benefit with an auxiliary skip connection, ensuring a fairer competition for all operations. Extensive experiments on various datasets verify that our approach can substantially improve the robustness of DARTS. Our code is available at https://github.com/Meituan-AutoML/DARTS-",
    "One-sentence Summary": "Indicator-free approach to stabilize DARTS",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "Meituan-AutoML/DARTS-",
    "Data": "ImageNet, NAS-Bench-201"
  },
  {
    "title": "BiPointNet: Binary Neural Network for Point Clouds",
    "url": "/forum?id=9QLRCVysdlO",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "point clouds, efficient deep learning, binary neural networks",
    "Abstract": "To alleviate the resource constraint for real-time point cloud applications that run on edge devices, in this paper we present BiPointNet, the first model binarization approach for efficient deep learning on point clouds. We discover that the immense performance drop of binarized models for point clouds mainly stems from two challenges: aggregation-induced feature homogenization that leads to a degradation of information entropy, and scale distortion that hinders optimization and invalidates scale-sensitive structures. With theoretical justifications and in-depth analysis, our BiPointNet introduces Entropy-Maximizing Aggregation (EMA) to modulate the distribution before aggregation for the maximum information entropy, and Layer-wise Scale Recovery (LSR) to efficiently restore feature representation capacity. Extensive experiments show that BiPointNet outperforms existing binarization methods by convincing margins, at the level even comparable with the full precision counterpart. We highlight that our techniques are generic, guaranteeing significant improvements on various fundamental tasks and mainstream backbones. Moreover, BiPointNet gives an impressive 14.7\u00d7 speedup and 18.9\u00d7 storage saving on real-world resource-constrained devices.",
    "One-sentence Summary": "We present BiPointNet, the first model binarization approach to efficient deep learning on point clouds, targeting at extreme compression and acceleration.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "htqin/BiPointNet",
    "Data": "ModelNet, S3DIS, ShapeNet"
  },
  {
    "title": "AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition",
    "url": "/forum?id=bM3L3I_853",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Abstract": "Temporal modelling is the key for efficient video action recognition. While understanding temporal information can improve recognition accuracy for dynamic actions, removing temporal redundancy and reusing past features can significantly save computation leading to efficient action recognition. In this paper, we introduce an adaptive temporal fusion network, called AdaFuse, that dynamically fuses channels from current and past feature maps for strong temporal modelling. Specifically, the necessary information from the historical convolution feature maps is fused with current pruned feature maps with the goal of improving both recognition accuracy and efficiency. In addition, we use a skipping operation to further reduce the computation cost of action recognition. Extensive experiments on SomethingV1 & V2, Jester and Mini-Kinetics show that our approach can achieve about 40% computation savings with comparable accuracy to state-of-the-art methods. The project page can be found at https://mengyuest.github.io/AdaFuse/",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "Kinetics, Something-Something V1"
  },
  {
    "title": "Generating Furry Cars: Disentangling Object Shape and Appearance across Multiple Domains",
    "url": "/forum?id=M88oFvqp_9",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "multi-domain disentanglement, generative adversarial networks, appearance transfer",
    "Abstract": "We consider the novel task of learning disentangled representations of object shape and appearance across multiple domains (e.g., dogs and cars).  The goal is to learn a generative model that learns an intermediate distribution, which borrows a subset of properties from each domain, enabling the generation of images that did not exist in any domain exclusively.  This challenging problem requires an accurate disentanglement of object shape, appearance, and background from each domain, so that the appearance and shape factors from the two domains can be interchanged. We augment an existing approach that can disentangle factors within a single domain but struggles to do so across domains.  Our key technical contribution is to represent object appearance with a differentiable histogram of visual features, and to optimize the generator so that two images with the same latent appearance factor but different latent shape factors produce similar histograms. On multiple multi-domain datasets, we demonstrate our method leads to accurate and consistent appearance and shape transfer across domains.",
    "One-sentence Summary": "We present a framework for multi-domain disentanglement, facilitating transfer of appearance from one domain to another.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?",
    "url": "/forum?id=Ig-VyQc-MLK",
    "date": "28 Sept 2020 (modified: 21 Mar 2021)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Pruning, Sparsity, Lottery Ticket, Science",
    "Abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.",
    "One-sentence Summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction",
    "url": "/forum?id=POWv6hDd9XH",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Poster",
    "Keywords": "Post Training Quantization, Mixed Precision, Second-order analysis",
    "Abstract": "We study the challenging task of neural network quantization without end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually requires a small subset of training data but produces less powerful quantized models than Quantization-Aware Training (QAT). In this work, we propose a novel PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to INT2 for the first time. BRECQ leverages the basic building blocks in neural networks and reconstructs them one-by-one. In a comprehensive theoretical study of the second-order error, we show that BRECQ achieves a good balance between cross-layer dependency and generalization error. To further employ the power of quantization, the mixed precision technique is incorporated in our framework by approximating the inter-layer and intra-layer sensitivity. Extensive experiments on various handcrafted and searched neural architectures are conducted for both image classification and object detection tasks. And for the first time we prove that, without bells and whistles, PTQ can attain 4-bit ResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster production of quantized models.  Codes are available at https://github.com/yhhhli/BRECQ.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "yhhhli/BRECQ +  1 community implementation"
  },
  {
    "title": "Practical Real Time Recurrent Learning with a Sparse Approximation",
    "url": "/forum?id=q3KSThy2GwB",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "recurrent neural networks, backpropagation, biologically plausible, forward mode, real time recurrent learning, rtrl, bptt",
    "Abstract": "Recurrent neural networks are usually trained with backpropagation through time, which requires storing a complete history of network states, and prohibits updating the weights \"online\" (after every timestep). Real Time Recurrent Learning (RTRL) eliminates the need for history storage and allows for online weight updates, but does so at the expense of computational costs that are quartic in the state size. This renders RTRL training intractable for all but the smallest networks, even ones that are made highly sparse.\n        We introduce the Sparse n-step Approximation (SnAp) to the RTRL influence matrix. SnAp only tracks the influence of a parameter on hidden units that are reached by the computation graph within n timesteps of the recurrent core. SnAp with n=1 is no more expensive than backpropagation but allows training on arbitrarily long sequences. We find that it substantially outperforms other RTRL approximations with comparable costs such as Unbiased Online Recurrent Optimization. For highly sparse networks, SnAp with n=2 remains tractable and can outperform backpropagation through time in terms of learning speed when updates are done online.",
    "One-sentence Summary": "We show how to make RTRL efficient with sparse RNNs, a sparse approximation, or both.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "WikiText-103"
  },
  {
    "title": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
    "url": "/forum?id=zv-typ1gPxA",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Code Summarization, Graph Neural Network, Retrieval, Generation",
    "Abstract": "Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples).\n        This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds.\n        Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR.",
    "One-sentence Summary": "This paper proposes a novel retrieval-augmented mechanism to augment the code semantics with hybrid graph neural network for source code summarization.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "shangqing-liu/CCSD-benchmark-for-code-summarization"
  },
  {
    "title": "Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods",
    "url": "/forum?id=2m0g1wEafh",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Excess risk, minimax optimal rate, local Rademacher complexity, fast learning rate, kernel method, linear estimator",
    "Abstract": "Establishing a theoretical analysis that explains why deep learning can outperform shallow learning such as kernel methods is one of the biggest issues in the deep learning literature. Towards answering this question, we evaluate excess risk of a deep learning estimator trained by a noisy gradient descent with ridge regularization on a mildly overparameterized neural network, \n        and discuss its superiority to a class of linear estimators that includes neural tangent kernel approach, random feature model, other kernel methods, k-NN estimator and so on. We consider a teacher-student regression model, and eventually show that {\\it any} linear estimator can be outperformed by deep learning in a sense of the minimax optimal rate especially for a high dimension setting. The obtained excess bounds are so-called fast learning rate which is faster than O(1/n) that is obtained by usual Rademacher complexity analysis. This discrepancy is induced by the non-convex geometry of the model and the noisy gradient descent used for neural network training provably reaches a near global optimal solution even though the loss landscape is highly non-convex. Although the noisy gradient descent does not employ any explicit or implicit sparsity inducing regularization, it shows a preferable generalization performance that dominates linear estimators.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Self-supervised Visual Reinforcement Learning with Object-centric Representations",
    "url": "/forum?id=xppLmXCbOw1",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "self-supervision, autonomous learning, object-centric representations, visual reinforcement learning",
    "Abstract": "Autonomous agents need large repertoires of skills to act reasonably on new tasks that they have not seen before. However, acquiring these skills using only a stream of high-dimensional, unstructured, and unlabeled observations is a tricky challenge for any autonomous agent. Previous methods have used variational autoencoders to encode a scene into a low-dimensional vector that can be used as a goal for an agent to discover new skills. Nevertheless, in compositional/multi-object environments it is difficult to disentangle all the factors of variation into such a fixed-length representation of the whole scene. We propose to use object-centric representations as a modular and structured observation space, which is learned with a compositional generative world model.\n        We show that the structure in the representations in combination with goal-conditioned attention policies helps the autonomous agent to discover and learn useful skills. These skills can be further combined to address compositional tasks like the manipulation of several different objects.",
    "One-sentence Summary": "The combination of object-centric representations and goal-conditioned attention policies helps autonomous agents to learn useful multi-task policies in visual multi-object environments",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "martius-lab/SMORL"
  },
  {
    "title": "Discovering a set of policies for the worst case reward",
    "url": "/forum?id=PUkhWz65dy5",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Abstract": "We study the problem of how to construct a set of policies that can be composed together to solve a collection of reinforcement learning tasks. Each task is a different reward function defined as a linear combination of  known features. We consider a specific class of policy compositions which we call set improving policies (SIPs): given a set of policies and a set of tasks, a SIP is any composition of the former whose performance is at least as good as that of its constituents across all the tasks. We focus on the most conservative instantiation of SIPs, set-max policies (SMPs), so our analysis extends to any SIP. This includes known policy-composition operators like generalized policy improvement. Our main contribution is an algorithm that builds a set of policies in order to maximize the worst-case performance of the resulting SMP on the set of tasks. The algorithm works by successively adding new policies to the set. We show that the worst-case performance of the resulting SMP strictly improves at each iteration, and the algorithm only stops when there does not exist a policy that leads to improved performance. We empirically evaluate our algorithm on a grid world and also on a set of domains from the DeepMind control suite. We confirm our theoretical results regarding the monotonically improving performance of our algorithm. Interestingly, we also show empirically that the sets of policies computed by the algorithm are diverse, leading to different trajectories in the grid world and very distinct locomotion skills in the control suite.",
    "One-sentence Summary": "Discovering a set of diverse RL policies by optimising the robustness of the set",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "DeepMind Control Suite"
  },
  {
    "title": "Implicit Normalizing Flows",
    "url": "/forum?id=8PS8m9oYtNy",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Normalizing flows, deep generative models, probabilistic inference, implicit functions",
    "Abstract": "Normalizing flows define a probability distribution by an explicit invertible transformation z=f(x). In this work, we present implicit normalizing flows (ImpFlows), which generalize normalizing flows by allowing the mapping to be implicitly defined by the roots of an equation F(z,x)=0. ImpFlows build on residual flows (ResFlows) with a proper balance between expressiveness and tractability. Through theoretical analysis, we show that the function space of ImpFlow is strictly richer than that of ResFlows. Furthermore, for any ResFlow with a fixed number of blocks, there exists some function that ResFlow has a non-negligible approximation error. However, the function is exactly representable by a single-block ImpFlow. We propose a scalable algorithm to train and draw samples from ImpFlows. Empirically, we evaluate ImpFlow on several classification and density modeling tasks, and ImpFlow outperforms ResFlow with a comparable amount of parameters on all the benchmarks.",
    "One-sentence Summary": "We generalize normalizing flows, allowing the mapping to be implicitly defined by the roots of an equation and enlarging the expressiveness power while retaining the tractability.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "thu-ml/implicit-normalizing-flows",
    "Data": "CIFAR-10, CIFAR-100"
  },
  {
    "title": "Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric graphs",
    "url": "/forum?id=Jnspzp-oIZE",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "symmetry, equivariance, mesh, geometric, convolution",
    "Abstract": "A common approach to define convolutions on meshes is to interpret them as a graph and apply graph convolutional networks (GCNs).  Such GCNs utilize isotropic kernels and are therefore insensitive to the relative orientation of vertices and thus to the geometry of the mesh as a whole. We propose Gauge Equivariant Mesh CNNs which generalize GCNs to apply anisotropic gauge equivariant kernels. Since the resulting features carry orientation information, we introduce a geometric message passing scheme defined by parallel transporting features over mesh edges. Our experiments validate the significantly improved expressivity of the proposed model over conventional GCNs and other methods.",
    "One-sentence Summary": "Expressive anisotropic mesh convolution without having to pick arbitrary kernel orientation by using gauge equivariance",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "qualcomm-ai-research/gauge-equivariant-mesh-cnn"
  },
  {
    "title": "Generalization bounds via distillation",
    "url": "/forum?id=EGdFhBzmAwB",
    "date": "28 Sept 2020 (modified: 12 Apr 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Generalization, statistical learning theory, theory, distillation",
    "Abstract": "This paper theoretically investigates the following empirical phenomenon: given a high-complexity network with poor generalization bounds, one can distill it into a network with nearly identical predictions but low complexity and vastly smaller generalization bounds.  The main contribution is an analysis showing that the original network inherits this good generalization bound from its distillation, assuming the use of well-behaved data augmentation.  This bound is presented both in an abstract and in a concrete form, the latter complemented by a reduction technique to handle modern computation graphs featuring convolutional layers, fully-connected layers, and skip connections, to name a few.  To round out the story, a (looser) classical uniform convergence analysis of compression is also presented, as well as a variety of experiments on cifar and mnist demonstrating similar generalization performance between the original network and its distillation.",
    "One-sentence Summary": "This paper provides a suite of mathematical tools to bound the generalization error of networks which possess low-complexity distillations.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Learning Mesh-Based Simulation with Graph Networks",
    "url": "/forum?id=roNqYL0_XP",
    "date": "28 Sept 2020 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "graph networks, simulation, mesh, physics",
    "Abstract": "Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied.\n        Here we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.",
    "One-sentence Summary": "We introduce a general method for learning the dynamics of complex physics systems accurately and efficiently on meshes",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "deepmind/deepmind-research +  3 community implementations"
  },
  {
    "title": "On Statistical Bias In Active Learning: How and When to Fix It",
    "url": "/forum?id=JiYq3eqTKY",
    "date": "28 Sept 2020 (modified: 31 May 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Active Learning, Monte Carlo, Risk Estimation",
    "Abstract": "Active learning is a powerful tool when labelling data is expensive, but it introduces a bias because the training data no longer follows the population distribution. We formalize this bias and investigate the situations in which it can be harmful and sometimes even helpful. We further introduce novel corrective weights to remove bias when doing so is beneficial. Through this, our work not only provides a useful mechanism that can improve the active learning approach, but also an explanation for the empirical successes of various existing approaches which ignore this bias. In particular, we show that this bias can be actively helpful when training overparameterized models---like neural networks---with relatively modest dataset sizes.",
    "One-sentence Summary": "We formalize the bias introduced by active learning and investigate the situations in which it can be harmful and sometimes even helpful, further introducing novel corrective weights to remove it when doing so is beneficial.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Winning the L2RPN Challenge: Power Grid Management via Semi-Markov Afterstate Actor-Critic",
    "url": "/forum?id=LmUJqB1Cz8",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "power grid management, deep reinforcement learning, graph neural network",
    "Abstract": "Safe and reliable electricity transmission in power grids is crucial for modern society. It is thus quite natural that there has been a growing interest in the automatic management of power grids, exempli\ufb01ed by the Learning to Run a Power Network Challenge (L2RPN), modeling the problem as a reinforcement learning (RL) task. However, it is highly challenging to manage a real-world scale power grid, mostly due to the massive scale of its state and action space. In this paper, we present an off-policy actor-critic approach that effectively tackles the unique challenges in power grid management by RL, adopting the hierarchical policy together with the afterstate representation. Our agent ranked \ufb01rst in the latest challenge (L2RPN WCCI 2020), being able to avoid disastrous situations while maintaining the highest level of operational ef\ufb01ciency in every test scenarios. This paper provides a formal description of the algorithmic aspect of our approach, as well as further experimental studies on diverse power grids.",
    "One-sentence Summary": "We  present  an  off-policy  actor-critic  approach  that  effectively tackles  the  unique  challenges  in  power  grid  management  by  reinforcement learning,  adopting  the hierarchical policy together with the afterstate representation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Expressive Power of Invariant and Equivariant Graph Neural Networks",
    "url": "/forum?id=lxHgXYN4bwl",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Graph Neural Network, Universality, Approximation",
    "Abstract": "Various classes of Graph Neural Networks (GNN) have been proposed and shown to be successful in a wide range of applications with graph structured data. In this paper, we propose a theoretical framework able to compare the expressive power of these GNN architectures. The current universality theorems only apply to intractable classes of GNNs. Here, we prove the first approximation guarantees for practical GNNs, paving the way for a better understanding of their generalization. Our theoretical results are proved for invariant GNNs computing a graph embedding (permutation of the nodes of the input graph does not affect the output) and equivariant GNNs computing an embedding of the nodes (permutation of the input permutes the output). We show that Folklore Graph Neural Networks (FGNN), which are tensor based GNNs augmented with matrix multiplication are the most expressive architectures proposed so far for a given tensor order. We illustrate our results on the Quadratic Assignment Problem (a NP-Hard combinatorial problem) by showing that FGNNs are able to learn how to solve the problem, leading to much better average performances than existing algorithms (based on spectral, SDP or other GNNs architectures). On a practical side, we also implement masked tensors to handle batches of graphs of varying sizes.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "mlelarge/graph_neural_net"
  },
  {
    "title": "MARS: Markov Molecular Sampling for Multi-objective Drug Discovery",
    "url": "/forum?id=kHSu4ebxFXY",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "drug discovery, molecular graph generation, MCMC sampling",
    "Abstract": "Searching for novel molecules with desired chemical properties is crucial in drug discovery. Existing work focuses on developing neural models to generate either molecular sequences or chemical graphs. However, it remains a big challenge to find novel and diverse compounds satisfying several properties. In this paper, we propose MARS, a method for multi-objective drug molecule discovery. MARS is based on the idea of generating the chemical candidates by iteratively editing fragments of molecular graphs. To search for high-quality candidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules with an annealing scheme and an adaptive proposal. To further improve sample efficiency, MARS uses a graph neural network (GNN) to represent and select candidate edits, where the GNN is trained on-the-fly with samples from MCMC. Experiments show that MARS achieves state-of-the-art performance in various multi-objective settings where molecular bio-activity, drug-likeness, and synthesizability are considered. Remarkably, in the most challenging setting where all four objectives are simultaneously optimized, our approach outperforms previous methods significantly in comprehensive evaluations. The code is available at https://github.com/yutxie/mars.",
    "One-sentence Summary": "In this paper, we propose a self-adaptive MCMC sampling method (MARS) to generate molecules targeting multiple objectives for drug discovery for multi-objective drug discovery.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "yutxie/mars"
  },
  {
    "title": "On Self-Supervised Image Representations for GAN Evaluation",
    "url": "/forum?id=NeRdBeTionN",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "GAN, evaluation, embedding",
    "Abstract": "The embeddings from CNNs pretrained on Imagenet classification are de-facto standard image representations for assessing GANs via FID, Precision and Recall measures. Despite broad previous criticism of their usage for non-Imagenet domains, these embeddings are still the top choice in most of the GAN literature.\n        \n        In this paper, we advocate the usage of the state-of-the-art self-supervised representations to evaluate GANs on the established non-Imagenet benchmarks. These representations, typically obtained via contrastive learning, are shown to provide better transfer to new tasks and domains, therefore, can serve as more universal embeddings of natural images. With extensive comparison of the recent GANs on the common datasets, we show that self-supervised representations produce a more reasonable ranking of models in terms of FID/Precision/Recall, while the ranking with classification-pretrained embeddings often can be misleading.",
    "One-sentence Summary": "We show that the state-of-the-art self-supervised representations should be used when comparing GANs on the non-Imagenet datasets",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CelebA-HQ, FFHQ, ImageNet, LSUN"
  },
  {
    "title": "Identifying nonlinear dynamical systems with multiple time scales and long-range dependencies",
    "url": "/forum?id=_XYzwxPIQu6",
    "date": "28 Sept 2020 (modified: 11 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "nonlinear dynamical systems, recurrent neural networks, attractors, computational neuroscience, vanishing gradient problem, LSTM",
    "Abstract": "A main theoretical interest in biology and physics is to identify the nonlinear dynamical system (DS) that generated observed time series. Recurrent Neural Networks (RNN) are, in principle, powerful enough to approximate any underlying DS, but in their vanilla form suffer from the exploding vs. vanishing gradients problem. Previous attempts to alleviate this problem resulted either in more complicated, mathematically less tractable RNN architectures, or strongly limited the dynamical expressiveness of the RNN. \n        Here we address this issue by suggesting a simple regularization scheme for vanilla RNN with ReLU activation which enables them to solve long-range dependency problems and express slow time scales, while retaining a simple mathematical structure which makes their DS properties partly analytically accessible. We prove two theorems that establish a tight connection between the regularized RNN dynamics and their gradients, illustrate on DS benchmarks that our regularization approach strongly eases the reconstruction of DS which harbor widely differing time scales, and show that our method is also en par with other long-range architectures like LSTMs on several tasks.",
    "One-sentence Summary": "We introduce a novel regularization for ReLU-based vanilla RNN that mitigates the exploding vs. vanishing gradient problem while retaining a simple mathematical structure that makes the RNN's dynamical systems properties partly analytically tractable",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Understanding the role of importance weighting for deep learning",
    "url": "/forum?id=_WnwtieRHxM",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Importance Weighting, Deep Learning, Implicit Bias, Gradient Descent, Learning Theory",
    "Abstract": "The recent paper by Byrd & Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justifications on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.",
    "One-sentence Summary": "We study the theoretical properties of importance weighting for deep learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "RMSprop converges with proper hyper-parameter",
    "url": "/forum?id=3UDSdyIcBDA",
    "date": "28 Sept 2020 (modified: 03 Jun 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "RMSprop, convergence, hyperparameter",
    "Abstract": "Despite the existence of divergence examples, RMSprop remains \n        one of the most popular algorithms in machine learning. Towards closing the gap between theory and practice, we prove that RMSprop converges with proper choice of hyper-parameters under certain conditions. More specifically, we prove that when the hyper-parameter \u03b22 is close enough to 1, RMSprop and its random shuffling version converge to a bounded region in general, and to critical points in the interpolation regime. It is worth mentioning that our results do not depend on  ``bounded gradient\"  assumption, which is often the key assumption utilized by existing theoretical work for Adam-type adaptive gradient method. Removing this assumption allows us to establish a phase transition from divergence to non-divergence for RMSprop. \n        \n        Finally, based on our theory, we conjecture that in practice there is a critical threshold \u03b22\u2217, such that RMSprop generates reasonably good results only if 1>\u03b22\u2265\u03b22\u2217. We provide empirical evidence for such a phase transition in our numerical experiments.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "The Intrinsic Dimension of Images and Its Impact on Learning",
    "url": "/forum?id=XJk19XzGq2J",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "generalization, dimension, manifold, ImageNet, CIFAR",
    "Abstract": "It is widely believed that natural image data exhibits low-dimensional structure despite the high dimensionality of conventional pixel representations.  This idea underlies a common intuition for the remarkable success of deep learning in computer vision. In this work, we apply dimension estimation tools to popular datasets and investigate the role of low-dimensional structure in deep learning.  We find that common natural image datasets indeed have very low intrinsic dimension relative to the high number of pixels in the images.  Additionally, we find that low dimensional datasets are easier for neural networks to learn, and models solving these tasks generalize better from training to test data.   Along the way,  we develop a technique for validating our dimension estimation tools on synthetic data generated by GANs allowing us to actively manipulate the intrinsic dimension by controlling the image generation process. Code for our experiments may be found  \\href{https://github.com/ppope/dimensions}{here}.",
    "One-sentence Summary": "We measure the dimensionality of common used datasets, and experimentally investigate whether the links between dimensionality and learning that have been identified in the manifold learning literature describe the behaviors of deep neural networks.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "ppope/dimensions",
    "Data": "CIFAR-10, CIFAR-100, COCO, CelebA, ImageNet, SVHN"
  },
  {
    "title": "Learning with Feature-Dependent Label Noise: A Progressive Approach",
    "url": "/forum?id=ZPa2SyGcbwh",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Noisy Label, Deep Learning, Classification",
    "Abstract": "Label noise is frequently observed in real-world large-scale datasets. The noise is introduced due to a variety of reasons; it is heterogeneous and feature-dependent. Most existing approaches to handling noisy labels fall into two categories: they either assume an ideal feature-independent noise, or remain heuristic without theoretical guarantees. In this paper, we propose to target a new family of feature-dependent label noise, which is much more general than commonly used i.i.d. label noise and encompasses a broad spectrum of noise patterns. Focusing on this general noise family, we propose a progressive label correction algorithm that iteratively corrects labels and refines the model. We provide theoretical guarantees showing that for a wide variety of (unknown) noise patterns, a classifier trained with this strategy converges to be consistent with the Bayes classifier. In experiments, our method outperforms SOTA baselines and is robust to various noise types and levels.",
    "One-sentence Summary": "We propose a progressive label correction approach for noisy label learning task.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "pxiangwu/PLC",
    "Data": "ANIMAL, CIFAR-10, CIFAR-100, Clothing1M, Food-101"
  },
  {
    "title": "Disentangled Recurrent Wasserstein Autoencoder",
    "url": "/forum?id=O7ms4LFdsX",
    "date": "28 Sept 2020 (modified: 16 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Sequential  Representation Learning, Disentanglement, Recurrent Generative Model",
    "Abstract": "Learning disentangled representations leads to interpretable models and facilitates data generation with style transfer, which has been extensively studied on static data such as images in an unsupervised learning framework. However, only a few works have explored unsupervised disentangled sequential representation learning due to challenges of generating sequential data. In this paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new framework for generative modeling of sequential data. R-WAE disentangles the representation of an input sequence into static and dynamic factors (i.e., time-invariant and time-varying parts). Our theoretical analysis shows that, R-WAE minimizes an upper bound of a penalized form of the Wasserstein distance between model distribution and sequential data distribution, and simultaneously maximizes the mutual information between input data and different disentangled latent factors, respectively. This is superior to (recurrent) VAE which does not explicitly enforce mutual information maximization between input data and disentangled latent representations. When the number of actions in sequential data is available as weak supervision information, R-WAE is extended to learn a categorical latent representation of actions to improve its disentanglement. Experiments on a variety of datasets show that our models outperform other baselines with the same settings in terms of disentanglement and unconditional video generation both quantitatively and qualitatively.",
    "One-sentence Summary": "We propose the first recurrent Wasserstein Autoencoder for learning disentangled representations of sequential data with theoretical analysis.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Influence Estimation for Generative Adversarial Networks",
    "url": "/forum?id=opHLcXxYTC_",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "influence, generative adversarial networks, data cleansing",
    "Abstract": "Identifying harmful instances, whose absence in a training dataset improves model performance, is important for building better machine learning models. \n        Although previous studies have succeeded in estimating harmful instances under supervised settings, they cannot be trivially extended to generative adversarial networks (GANs).\n        This is because previous approaches require that (i) the absence of a training instance directly affects the loss value and that (ii) the change in the loss directly measures the harmfulness of the instance for the performance of a model. \n        In GAN training, however, neither of the requirements is satisfied. \n        This is because, (i) the generator\u2019s loss is not directly affected by the training instances as they are not part of the generator's training steps, and (ii) the values of GAN's losses normally do not capture the generative performance of a model.\n        To this end, (i) we propose an influence estimation method that uses the Jacobian of the gradient of the generator's loss with respect to the discriminator\u2019s parameters (and vice versa) to trace how the absence of an instance in the discriminator\u2019s training affects the generator\u2019s parameters, and (ii) we propose a novel evaluation scheme, in which we assess harmfulness of each training instance on the basis of how GAN evaluation metric (e.g., inception score) is expected to change due to the removal of the instance.\n        We experimentally verified that our influence estimation method correctly inferred the changes in GAN evaluation metrics.\n        We also demonstrated that the removal of the identified harmful instances effectively improved the model\u2019s generative performance with respect to various GAN evaluation metrics.",
    "One-sentence Summary": "We propose an influence estimation method which predicts how GAN's output changes if an training instance is abesent, and propose to evaluate harmfulness of the instance by estimating how its absence improves GAN evaluation metric.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "hitachi-rd-cv/influence-estimation-for-gans",
    "Data": "MNIST"
  },
  {
    "title": "Orthogonalizing Convolutional Layers with the Cayley Transform",
    "url": "/forum?id=Pbj8H_jEHYv",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "orthogonal layers, Lipschitz constrained networks, adversarial robustness",
    "Abstract": "Recent work has highlighted several advantages of enforcing orthogonality in the weight layers of deep networks, such as maintaining the stability of activations, preserving gradient norms, and enhancing adversarial robustness by enforcing low Lipschitz constants. Although numerous methods exist for enforcing the orthogonality of fully-connected layers, those for convolutional layers are more heuristic in nature, often focusing on penalty methods or limited classes of convolutions. In this work, we propose and evaluate an alternative approach to directly parameterize convolutional layers that are constrained to be orthogonal. Specifically, we propose to apply the Cayley transform to a skew-symmetric convolution in the Fourier domain, so that the inverse convolution needed by the Cayley transform can be computed efficiently. We compare our method to previous Lipschitz-constrained and orthogonal convolutional layers and show that it indeed preserves orthogonality to a high degree even for large convolutions. Applied to the problem of certified adversarial robustness, we show that networks incorporating the layer outperform existing deterministic methods for certified defense against \u21132-norm-bounded adversaries, while scaling to larger architectures than previously investigated. Code is available at https://github.com/locuslab/orthogonal-convolutions.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "locuslab/orthogonal-convolutions"
  },
  {
    "title": "Predicting Infectiousness for Proactive Contact Tracing",
    "url": "/forum?id=lVgB2FUbzuQ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "covid-19, contact tracing, distributed inference, set transformer, deepset, epidemiology, applications, domain randomization, retraining, simulation",
    "Abstract": "The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual contact tracing in many countries and resulting in widespread lockdowns for emergency containment. Large-scale digital contact tracing (DCT) has emerged as a potential solution to resume economic and social activity while minimizing spread of the virus. Various DCT methods have been proposed, each making trade-offs be-tween privacy, mobility restrictions, and public health. The most common approach, binary contact tracing (BCT), models infection as a binary event, informed only by an individual\u2019s test results, with corresponding binary recommendations that either all or none of the individual\u2019s contacts quarantine. BCT ignores the inherent uncertainty in contacts and the infection process, which could be used to tailor messaging to high-risk individuals, and prompt proactive testing or earlier warnings. It also does not make use of observations such as symptoms or pre-existing medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological simulator to develop and test methods that can be deployed to a smartphone to locally and proactively predict an individual\u2019s infectiousness (risk of infecting others) based on their contact history and other information, while respecting strong privacy constraints. Predictions are used to provide personalized recommendations to the individual via an app, as well as to send anonymized messages to the individual\u2019s contacts, who use this information to better predict their own infectiousness, an approach we call proactive contact tracing (PCT). Similarly to other works, we find that compared to no tracing, all DCT methods tested are able to reduce spread of the disease and thus save lives, even at low adoption rates, strongly supporting a role for DCT methods in managing the pandemic. Further, we find a deep-learning based PCT method which improves over BCT for equivalent average mobility, suggesting PCT could help in safe re-opening and second-wave prevention.",
    "One-sentence Summary": "Proposes a framework called Proactive Contact Tracing which uses distributed inference of expected Covid-19 infectiousness to provide individualized, private recommendations.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "mila-iqia/COVI-ML"
  },
  {
    "title": "Learning a Latent Simplex in Input Sparsity Time",
    "url": "/forum?id=04LZCAxMSco",
    "date": "28 Sept 2020 (modified: 24 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Latent Simplex, numerical linear algebra, low-rank approximation",
    "Abstract": "We consider the problem of learning a latent k-vertex simplex K\u2208Rd, given A\u2208Rd\u00d7n, which can be viewed as n data points that are formed by randomly perturbing some latent points in K, possibly beyond K. A large class of latent variable models, such as adversarial clustering, mixed membership stochastic block models, and topic models can be cast in this view of learning a latent simplex. Bhattacharyya and Kannan (SODA 2020) give an algorithm for learning such a k-vertex latent simplex in time roughly O(k\u22c5nnz(A)), where nnz(A) is the number of non-zeros in A. We show that the dependence on k in the running time is unnecessary given a natural assumption about the mass of the top k singular values of A, which holds in many of these applications. Further, we show this assumption is necessary, as otherwise an algorithm for learning a latent simplex would imply a better low rank approximation algorithm than what is known. \n        \n        We obtain a spectral low-rank approximation to A in input-sparsity time and show that the column space thus obtained has small sin\u2061\u0398 (angular) distance to the right top-k singular space of A. Our algorithm then selects k points in the low-rank  subspace with the largest inner product (in absolute value) with k carefully chosen random vectors. By working in the low-rank subspace, we avoid reading the entire matrix in each iteration and thus circumvent the \u0398(k\u22c5nnz(A)) running time.",
    "One-sentence Summary": "We obtain the first input sparsity runtime algorithm for the problem of learning a latent simplex.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "CPT: Efficient Deep Neural Network Training via Cyclic Precision",
    "url": "/forum?id=87ZwsaQNHPZ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Efficient training, low precision training",
    "Abstract": "Low-precision deep neural network (DNN) training has gained tremendous attention as reducing precision is one of the most effective knobs for boosting DNNs' training time/energy efficiency. In this paper, we attempt to explore low-precision training from a new perspective as inspired by recent findings in understanding DNN training: we conjecture that DNNs' precision might have a similar effect as the learning rate during DNN training, and advocate dynamic precision along the training trajectory for further boosting the time/energy efficiency of DNN training. Specifically, we propose Cyclic Precision Training (CPT) to cyclically vary the precision between two boundary values which can be identified using a simple precision range test within the first few training epochs. Extensive simulations and ablation studies on five datasets and eleven models demonstrate that CPT's effectiveness is consistent across various models/tasks (including classification and language modeling). Furthermore, through experiments and visualization we show that CPT helps to (1) converge to a wider minima with a lower generalization error and (2) reduce training variance which we believe opens up a new design knob for simultaneously improving the optimization and efficiency of DNN training.",
    "One-sentence Summary": "We propose Cyclic Precision Training towards better accuracy-efficiency trade-offs in DNN training.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "RICE-EIC/CPT",
    "Data": "CIFAR-10, CIFAR-100, ImageNet, Penn Treebank, WikiText-103"
  },
  {
    "title": "Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration",
    "url": "/forum?id=w_7JMpGZRh0",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "social perception, human-AI collaboration, theory of mind, multi-agent platform, virtual environment",
    "Abstract": "In this paper, we introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents. In WAH, an AI agent needs to help a human-like agent perform a complex household task efficiently. To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration). For this challenge, we build VirtualHome-Social, a multi-agent household environment, and provide a benchmark including both planning and learning based baselines. We evaluate the performance of AI agents with the human-like agent as well as and with real humans using objective metrics and subjective user ratings. Experimental results demonstrate that our challenge and virtual environment enable a systematic evaluation on the important aspects of machine social intelligence at scale.",
    "One-sentence Summary": "We introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "xavierpuigf/watch_and_help",
    "Data": "HoME"
  },
  {
    "title": "Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models",
    "url": "/forum?id=F1vEjWK-lH_",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Multi-task Learning, Multilingual Modeling",
    "Abstract": "Massively multilingual models subsuming tens or even hundreds of languages pose great challenges to multi-task optimization. While it is a common practice to apply a language-agnostic procedure optimizing a joint multilingual task objective, how to properly characterize and take advantage of its underlying problem structure for improving optimization efficiency remains under-explored. In this paper, we attempt to peek into the black-box of multilingual optimization through the lens of loss function geometry. We find that gradient similarity measured along the optimization trajectory is an important signal, which correlates well with not only language proximity but also the overall model performance. Such observation helps us to identify a critical limitation of existing gradient-based multi-task learning methods, and thus we derive a simple and scalable optimization procedure, named Gradient Vaccine, which encourages more geometrically aligned parameter updates for close tasks. Empirically, our method obtains significant model performance gains on multilingual machine translation and XTREME benchmark tasks for multilingual language models. Our work reveals the importance of properly measuring and utilizing language proximity in multilingual optimization, and has broader implications for multi-task learning beyond multilingual modeling.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "PlasticineLab: A Soft-Body Manipulation Benchmark with Differentiable Physics",
    "url": "/forum?id=xCcdBRQEDW",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Soft Body, Differentiable Physics, Benchmark",
    "Abstract": "Simulated virtual environments serve as one of the main driving forces behind developing and evaluating skill learning algorithms. However, existing environments typically only simulate rigid body physics. Additionally, the simulation process usually does not provide gradients that might be useful for planning and control optimizations. We introduce a new differentiable physics benchmark called PasticineLab, which includes a diverse collection of soft body manipulation tasks. In each task, the agent uses manipulators to deform the plasticine into a desired configuration. The underlying physics engine supports differentiable elastic and plastic deformation using the DiffTaichi system, posing many under-explored challenges to robotic agents. We evaluate several existing reinforcement learning (RL) methods and gradient-based methods on this benchmark. Experimental results suggest that 1) RL-based approaches struggle to solve most of the tasks efficiently;  2) gradient-based approaches, by optimizing open-loop control sequences with the built-in differentiable physics engine, can rapidly find a solution within tens of iterations, but still fall short on multi-stage tasks that require long-term planning. We expect that PlasticineLab will encourage the development of novel algorithms that combine differentiable physics and RL for more complex physics-based skill learning tasks. PlasticineLab will be made publicly available.",
    "One-sentence Summary": "We propose a soft-body manipulation benchmark with differentiable physics support.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "hzaskywalker/PlasticineLab",
    "Data": "PlasticineLab, Arcade Learning Environment, MuJoCo, OpenAI Gym"
  },
  {
    "title": "Distributional Sliced-Wasserstein and Applications to Generative Modeling",
    "url": "/forum?id=QYjO70ACDK",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Deep generative models, Sliced Wasserstein, Optimal Transport",
    "Abstract": "Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein distance (Max-SW), have been used widely in the recent years due to their fast computation and scalability even when the probability measures lie in a very high dimensional space. However, SW requires many unnecessary projection samples to approximate its value while Max-SW only uses the most important projection, which ignores the information of other useful directions. In order to account for these weaknesses, we propose a novel distance, named Distributional Sliced-Wasserstein distance (DSW), that finds an optimal distribution over projections that can balance between exploring distinctive projecting directions and the informativeness of projections themselves. We show that the DSW is a generalization of Max-SW, and it can be computed efficiently by searching for the optimal push-forward measure over a set of probability measures over the unit sphere satisfying certain regularizing constraints that favor distinct directions. Finally, we conduct extensive experiments with large-scale datasets to demonstrate the favorable performances of the proposed distances over the previous sliced-based distances in generative modeling applications.",
    "One-sentence Summary": "A new optimal transport distance based on slicing approach and its applications to generative modeling.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, CelebA, LSUN, MNIST"
  },
  {
    "title": "Systematic generalisation with group invariant predictions",
    "url": "/forum?id=b9PoimzZFJ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Systematic generalisation, invariance penalty, semantic anomaly detection",
    "Abstract": "We consider situations where the presence of dominant simpler correlations with the target variable in a training set can cause an SGD-trained neural network to be less reliant on more persistently correlating complex features. When the non-persistent, simpler correlations correspond to non-semantic background factors, a neural network trained on this data can exhibit dramatic failure upon encountering systematic distributional shift, where the correlating background features are recombined with different objects. We perform an empirical study on three synthetic datasets, showing that group invariance methods across inferred partitionings of the training set can lead to significant improvements at such test-time situations. We also suggest a simple invariance penalty, showing with experiments on our setups that it can perform better than alternatives. We find that even without assuming access to any systematically shifted validation sets, one can still find improvements over an ERM-trained reference model.",
    "One-sentence Summary": "Invariance penalties across splits of a biased dataset can improve systematic generalisation",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "COCO, Places"
  },
  {
    "title": "Memory Optimization for Deep Networks",
    "url": "/forum?id=bnY0jm4l59",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "memory optimized training, memory efficient training, checkpointing, deep network training",
    "Abstract": "Deep learning is slowly, but steadily, hitting a memory bottleneck. While the tensor computation in top-of-the-line GPUs increased by 32\u00d7 over the last five years, the total available memory only grew by 2.5\u00d7. This prevents researchers from exploring larger architectures, as training large networks requires more memory for storing intermediate outputs. In this paper, we present MONeT, an automatic framework that minimizes both the memory footprint and computational overhead of deep networks. MONeT jointly optimizes the checkpointing schedule and the implementation of various operators. MONeT is able to outperform all prior hand-tuned operations as well as automated checkpointing. MONeT reduces the overall memory requirement by 3\u00d7 for various PyTorch models, with a 9-16% overhead in computation. For the same computation cost, MONeT requires 1.2-1.8\u00d7 less memory than current state-of-the-art automated checkpointing frameworks. Our code will be made publicly available upon acceptance.",
    "One-sentence Summary": "MONeT reduces the memory footprint of training while minimizing compute overhead by jointly optimizing checkpointing with operator optimizations.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "utsaslab/MONeT"
  },
  {
    "title": "HW-NAS-Bench: Hardware-Aware Neural Architecture Search Benchmark",
    "url": "/forum?id=_0kaDkv3dVf",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Hardware-Aware Neural Architecture Search, AutoML, Benchmark",
    "Abstract": "HardWare-aware Neural Architecture Search (HW-NAS) has recently gained tremendous attention by automating the design of deep neural networks deployed in more resource-constrained daily life devices. Despite its promising performance, developing optimal HW-NAS solutions can be prohibitively challenging as it requires cross-disciplinary knowledge in the algorithm, micro-architecture, and device-specific compilation. First, to determine the hardware-cost to be incorporated into the NAS process, existing works mostly adopt either pre-collected hardware-cost look-up tables or device-specific hardware-cost models. The former can be time-consuming due to the required knowledge of the device\u2019s compilation method and how to set up the measurement pipeline, while building the latter is often a barrier for non-hardware experts like NAS researchers. Both of them limit the development of HW-NAS innovations and impose a barrier-to-entry to non-hardware experts. Second, similar to generic NAS, it can be notoriously difficult to benchmark HW-NAS algorithms due to their significant required computational resources and the differences in adopted search spaces, hyperparameters, and hardware devices. To this end, we develop HW-NAS-Bench, the first public dataset for HW-NAS research which aims to democratize HW-NAS research to non-hardware experts and make HW-NAS research more reproducible and accessible. To design HW-NAS-Bench, we carefully collected the measured/estimated hardware performance (e.g., energy cost and latency) of all the networks in the search spaces of both NAS-Bench-201 and FBNet, on six hardware devices that fall into three categories (i.e., commercial edge devices, FPGA, and ASIC). Furthermore, we provide a comprehensive analysis of the collected measurements in HW-NAS-Bench to provide insights for HW-NAS research. Finally, we demonstrate exemplary user cases to (1) show that HW-NAS-Bench allows non-hardware experts to perform HW-NAS by simply querying our pre-measured dataset and (2) verify that dedicated device-specific HW-NAS can indeed lead to optimal accuracy-cost trade-offs. The codes and all collected data are available at https://github.com/RICE-EIC/HW-NAS-Bench.",
    "One-sentence Summary": "A Hardware-Aware Neural Architecture Search Benchmark",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, CIFAR-100, NAS-Bench-201"
  },
  {
    "title": "Regularized Inverse Reinforcement Learning",
    "url": "/forum?id=HgLO8yalfwc",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "inverse reinforcement learning, reward learning, regularized markov decision processes, reinforcement learning",
    "Abstract": "Inverse Reinforcement Learning (IRL) aims to facilitate a learner\u2019s ability to imitate expert behavior by acquiring reward functions that explain the expert\u2019s decisions. Regularized IRLapplies strongly convex regularizers to the learner\u2019s policy in order to avoid the expert\u2019s behavior being rationalized by arbitrary constant rewards, also known as degenerate solutions. We propose tractable solutions, and practical methods to obtain them, for regularized IRL. Current methods are restricted to the maximum-entropy IRL framework, limiting them to Shannon-entropy regularizers, as well as proposing solutions that are intractable in practice.  We present theoretical backing for our proposed IRL method\u2019s applicability to both discrete and continuous controls, empirically validating our performance on a variety of tasks.",
    "One-sentence Summary": "We propose tractable solutions of regularized IRL and algorithms to acquire those solutions.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "What are the Statistical Limits of Offline RL with Linear Function Approximation?",
    "url": "/forum?id=30EvkP2aQLD",
    "date": "28 Sept 2020 (modified: 28 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "batch reinforcement learning, function approximation, lower bound, representation",
    "Abstract": "Offline reinforcement learning seeks to utilize offline (observational) data to guide the learning of (causal) sequential decision making strategies. The hope is that offline reinforcement learning coupled with function approximation methods (to deal with the curse of dimensionality) can provide a means to help alleviate the excessive sample complexity burden in modern sequential decision making problems. However, the extent to which this broader approach can be effective is not well understood, where the literature largely consists of sufficient conditions.\n        \n        This work focuses on the basic question of what are necessary representational and distributional conditions that permit provable sample-efficient offline reinforcement learning. Perhaps surprisingly, our main result shows that even if: i) we have realizability in that the true value function of \\emph{every} policy is linear in a given set of features and 2) our off-policy data has good  coverage over all features (under a strong spectral condition), any algorithm still (information-theoretically) requires a number of offline samples that is exponential in the problem horizon to non-trivially estimate the value of \\emph{any} given policy. Our results highlight that sample-efficient offline policy evaluation is not possible unless significantly stronger conditions hold; such conditions include either having low distribution shift (where the offline data distribution is close to the distribution of the policy to be evaluated) or significantly stronger representational conditions (beyond realizability).",
    "One-sentence Summary": "Exponential lower bounds for batch RL with linear function approximation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Behavioral Cloning from Noisy Demonstrations",
    "url": "/forum?id=zrT3HcsWSAt",
    "date": "28 Sept 2020 (modified: 11 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Imitation Learning, Inverse Reinforcement Learning, Noisy Demonstrations",
    "Abstract": "We consider the problem of learning an optimal expert behavior policy given noisy demonstrations that contain observations from both optimal and non-optimal expert behaviors. Popular imitation learning algorithms, such as generative adversarial imitation learning, assume that (clear) demonstrations are given from optimal expert policies but not the non-optimal ones, and thus often fail to imitate the optimal expert behaviors given the noisy demonstrations. Prior works that address the problem require (1) learning policies through environment interactions in the same fashion as reinforcement learning, and (2) annotating each demonstration with confidence scores or rankings. However, such environment interactions and annotations in real-world settings take impractically long training time and a significant human effort. In this paper, we propose an imitation learning algorithm to address the problem without any environment interactions and annotations associated with the non-optimal demonstrations. The proposed algorithm learns ensemble policies with a generalized behavioral cloning (BC) objective function where we exploit another policy already learned by BC. Experimental results show that the proposed algorithm can learn behavior policies that are much closer to the optimal policies than ones learned by BC.",
    "One-sentence Summary": "We propose an imitation learning algorithm to learn from non-optimal (noisy) demonstrations without any environment interactions and annotations associated with the demonstrations.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "How Does Mixup Help With Robustness and Generalization?",
    "url": "/forum?id=8yKEo06dKNo",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Mixup, adversarial robustness, generalization",
    "Abstract": "Mixup is a popular data augmentation technique based on on convex combinations of pairs of examples and their labels. This simple technique has shown to substantially improve both the model's robustness as well as the generalization of the trained model. However,  it is not well-understood why such improvement occurs. In this paper, we provide theoretical analysis to demonstrate how using Mixup in training helps model robustness and generalization. For robustness, we show that minimizing the Mixup loss corresponds to approximately minimizing an upper bound of the adversarial loss. This explains why models obtained by Mixup training exhibits robustness to several kinds of adversarial attacks such as Fast Gradient Sign Method (FGSM). For generalization, we prove that Mixup augmentation corresponds to a specific type of data-adaptive regularization which reduces overfitting. Our analysis provides new insights and a framework to understand Mixup.",
    "One-sentence Summary": "A theoretical point of view for Mixup training",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Emergent Symbols through Binding in External Memory",
    "url": "/forum?id=LSFCEb3GYU7",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "abstract rules, out-of-distribution generalization, external memory, indirection, variable binding",
    "Abstract": "A key aspect of human intelligence is the ability to infer abstract rules directly from high-dimensional sensory data, and to do so given only a limited amount of training experience. Deep neural network algorithms have proven to be a powerful tool for learning directly from high-dimensional data, but currently lack this capacity for data-efficient induction of abstract rules, leading some to argue that symbol-processing mechanisms will be necessary to account for this capacity. In this work, we take a step toward bridging this gap by introducing the Emergent Symbol Binding Network (ESBN), a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. Across a series of tasks, we show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples, and outperforms a number of other competitive neural network architectures.",
    "One-sentence Summary": "We introduce a new architecture,  the Emergent Symbol Binding Network, that enables rapid learning of abstract rules and strong generalization of those rules to novel entities.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "taylorwwebb/emergent_symbols",
    "Data": "RAVEN"
  },
  {
    "title": "Individually Fair Gradient Boosting",
    "url": "/forum?id=JBAa9we1AL",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Algorithmic fairness, boosting, non-smooth models",
    "Abstract": "We consider the task of enforcing individual fairness in gradient boosting. Gradient boosting is a popular method for machine learning from tabular data, which arise often in applications where algorithmic fairness is a concern. At a high level, our approach is a functional gradient descent on a (distributionally) robust loss function that encodes our intuition of algorithmic fairness for the ML task at hand. Unlike prior approaches to individual fairness that only work with smooth ML models, our approach also works with non-smooth models such as decision trees. We show that our algorithm converges globally and generalizes. We also demonstrate the efficacy of our algorithm on three ML problems susceptible to algorithmic bias.",
    "One-sentence Summary": "We propose an algorithm for training individually fair gradient boosted decision trees classifiers.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Structured Prediction as Translation between Augmented Natural Languages",
    "url": "/forum?id=US-TP-xnXI",
    "date": "28 Sept 2020 (modified: 23 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "language models, few-shot learning, transfer learning, structured prediction, generative modeling, sequence to sequence, multi-task learning",
    "Abstract": "We propose a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. Our approach can match or outperform task-specific models on all tasks, and in particular achieves new state-of-the-art results on joint entity and relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic role labeling (CoNLL-2005 and CoNLL-2012). We accomplish this while using the same architecture and hyperparameters for all tasks, and even when training a single model to solve all tasks at the same time (multi-task learning). Finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics.",
    "One-sentence Summary": "We propose a unified text-to-text approach to handle a variety of structured prediction tasks in a single model, allowing seamless multi-task training and providing extra benefits on low-resource scenarios.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "amazon-research/tanl",
    "Data": "FewRel, TACRED"
  },
  {
    "title": "Minimum Width for Universal Approximation",
    "url": "/forum?id=O-XJwyoIF-k",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "universal approximation, neural networks",
    "Abstract": "The universal approximation property of width-bounded networks has been studied as a dual of classical universal approximation results on depth-bounded networks. However, the critical width enabling the universal approximation has not been exactly characterized in terms of the input dimension dx and the output dimension dy. In this work, we provide the first definitive result in this direction for networks using the ReLU activation functions: The minimum width required for the universal approximation of the Lp functions is exactly max{dx+1,dy}. We also prove that the same conclusion does not hold for the uniform approximation with ReLU, but does hold with an additional threshold activation function. Our proof technique can be also used to derive a tighter upper bound on the minimum width required for the universal approximation using networks with general activation functions.",
    "One-sentence Summary": "We establish the tight bound on width for the universal approximability of neural network.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Topology-Aware Segmentation Using Discrete Morse Theory",
    "url": "/forum?id=LGgdb4TS4Z",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Topology, Morse theory, Image segmentation",
    "Abstract": "In the segmentation of fine-scale structures from natural and biomedical images, per-pixel accuracy is not the only metric of concern. Topological correctness, such as vessel connectivity and membrane closure, is crucial for downstream analysis tasks. In this paper, we propose a new approach to train deep image segmentation networks for better topological accuracy. In particular, leveraging the power of discrete Morse theory (DMT), we identify global structures, including 1D skeletons and 2D patches, which are important for topological accuracy. Trained with a novel loss based on these global structures, the network performance is significantly improved especially near topologically challenging locations (such as weak spots of connections and membranes). On diverse datasets, our method achieves superior performance on both the DICE score and topological metrics.",
    "One-sentence Summary": "This paper proposes a loss based on discrete Morse theory to train deep image segmentation networks for better topological accuracy.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "DRIVE"
  },
  {
    "title": "Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking",
    "url": "/forum?id=WznmQa42ZAx",
    "date": "28 Sept 2020 (modified: 15 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Graph neural networks, interpretability, sparse stochastic gates, semantic role labeling, question answering",
    "Abstract": "Graph neural networks (GNNs) have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs (e.g. syntactic trees or co-reference structures) contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected L0 norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.",
    "One-sentence Summary": "We present a novel post-hoc interpretation method for graph neural networks, and apply it to analyse two models from the NLP literature.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control",
    "url": "/forum?id=yr1mzrH3IC",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Policy Optimization, Regularization, Continuous Control, Deep Reinforcement Learning",
    "Abstract": "Deep Reinforcement Learning (Deep RL) has been receiving increasingly more attention  thanks to its encouraging performance on a variety of control tasks. Yet, conventional regularization techniques in training neural networks (e.g., L2 regularization, dropout) have been largely ignored in RL methods, possibly because agents are typically trained and evaluated in the same environment, and because the deep RL community focuses more on high-level algorithm designs. In this work, we present the first comprehensive study of regularization techniques with multiple policy optimization algorithms on continuous control tasks. Interestingly, we find conventional regularization techniques on the policy networks can often bring large improvement, especially on harder tasks. Our findings are shown to be robust against training hyperparameter variations. We also compare these techniques with the more widely used entropy regularization. In addition, we study regularizing different components and find that only regularizing the policy network is typically the best. We further analyze why regularization may help generalization in RL from four perspectives - sample complexity, reward distribution, weight norm, and noise robustness. We hope our study provides guidance for future practices in regularizing policy optimization algorithms. Our code is available at https://github.com/xuanlinli17/iclr2021_rlreg .",
    "One-sentence Summary": "We show that conventional regularization methods (e.g., L2), which have been largely ignored in RL methods, can be very effective in policy optimization on continuous control tasks; we also analyze why they can help from several perspectives.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "anonymouscode114/iclr2021_rlreg",
    "Data": "MuJoCo"
  },
  {
    "title": "Recurrent Independent Mechanisms",
    "url": "/forum?id=mLcmdlEUxy-",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "modular representations, better generalization, learning mechanisms",
    "Abstract": "We explore the hypothesis that learning modular structures which reflect the dynamics of the environment can lead to better generalization and robustness to changes that only affect a few of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a new recurrent architecture in which multiple groups of recurrent cells operate with nearly independent transition dynamics, communicate only sparingly through the bottleneck of attention, and compete with each other so they are updated only at time steps where they are most relevant.  We show that this leads to specialization amongst the RIMs, which in turn allows for remarkably improved generalization on tasks where some factors of variation differ systematically between training and evaluation.",
    "One-sentence Summary": "Learning recurrent mechanisms which operate independently, and sparingly interact  can lead to better generalization to out of distribution samples.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "maximecb/gym-minigrid +  3 community implementations"
  },
  {
    "title": "Dataset Inference: Ownership Resolution in Machine Learning",
    "url": "/forum?id=hvdKKV2yt7T",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "model ownership, model extraction, MLaaS",
    "Abstract": "With increasingly more data and computation involved in their training,  machine learning models constitute valuable intellectual property. This has spurred interest in model stealing, which is made more practical by advances in learning with partial, little, or no supervision. Existing defenses focus on inserting unique watermarks in a model's decision surface, but this is insufficient:  the watermarks are not sampled from the training distribution and thus are not always preserved during model stealing. In this paper, we make the key observation that knowledge contained in the stolen model's training set is what is common to all stolen copies. The adversary's goal, irrespective of the attack employed, is always to extract this knowledge or its by-products. This gives the original model's owner a strong advantage over the adversary: model owners have access to the original training data. We thus introduce dataset inference, the process of identifying whether a suspected model copy has private knowledge from the original model's dataset, as a defense against model stealing. We develop an approach for dataset inference that combines statistical testing with the ability to estimate the distance of multiple data points to the decision boundary. Our experiments on CIFAR10, SVHN, CIFAR100 and ImageNet show that model owners can claim with confidence greater than 99% that their model (or dataset as a matter of fact) was stolen, despite only exposing 50 of the stolen model's training points. Dataset inference defends against state-of-the-art attacks even when the adversary is adaptive. Unlike prior work, it does not require retraining or overfitting the defended model.",
    "One-sentence Summary": "We introduce 'Dataset Inference' as a new method towards resolving model ownership.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "cleverhans-lab/dataset-inference",
    "Data": "CIFAR-10, CIFAR-100, ImageNet, SVHN"
  },
  {
    "title": "Learning from Protein Structure with Geometric Vector Perceptrons",
    "url": "/forum?id=1YLJDvSx6J4",
    "date": "28 Sept 2020 (modified: 04 Apr 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "structural biology, graph neural networks, proteins, geometric deep learning",
    "Abstract": "Learning on 3D structures of large biomolecules is emerging as a distinct area in machine learning, but there has yet to emerge a unifying network architecture that simultaneously leverages the geometric and relational aspects of the problem domain. To address this gap, we introduce geometric vector perceptrons, which extend standard dense layers to operate on collections of Euclidean vectors. Graph neural networks equipped with such layers are able to perform both geometric and relational reasoning on efficient representations of macromolecules. We demonstrate our approach on two important problems in learning from protein structure: model quality assessment and computational protein design. Our approach improves over existing classes of architectures on both problems, including state-of-the-art convolutional neural networks and graph neural networks. We release our code at https://github.com/drorlab/gvp.",
    "One-sentence Summary": "We introduce a novel graph neural network layer to learn from the structure of macromolecules.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "drorlab/gvp-pytorch +  2 community implementations"
  },
  {
    "title": "Unsupervised Object Keypoint Learning using Local Spatial Predictability",
    "url": "/forum?id=GJwMHetHc73",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "unsupervised representation learning, object-keypoint representations, visual saliency",
    "Abstract": "We propose PermaKey, a novel approach to representation learning based on object keypoints. It leverages the predictability of local image regions from spatial neighborhoods to identify salient regions that correspond to object parts, which are then converted to keypoints. Unlike prior approaches, it utilizes predictability to discover object keypoints, an intrinsic property of objects. This ensures that it does not overly bias keypoints to focus on characteristics that are not unique to objects, such as movement, shape, colour etc.  We demonstrate the efficacy of PermaKey on Atari where it learns keypoints corresponding to the most salient object parts and is robust to certain visual distractors. Further, on downstream RL tasks in the Atari domain we demonstrate how agents equipped with our keypoints outperform those using competing alternatives, even on challenging environments with moving backgrounds or distractor objects.",
    "One-sentence Summary": "We propose PermaKey, a novel method for learning object keypoint representations that leverages local predictability as a measure of objectness.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "agopal42/permakey"
  },
  {
    "title": "Fast Geometric Projections for Local Robustness Certification",
    "url": "/forum?id=zWy1uxjDdZJ",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "verification, robustness, safety",
    "Abstract": "Local robustness ensures that a model classifies all inputs within an \u2113p-ball consistently, which precludes various forms of adversarial inputs.\n        In this paper, we present a fast procedure for checking local robustness in feed-forward neural networks with piecewise-linear activation functions.\n        Such networks partition the input space into a set of convex polyhedral regions in which the network\u2019s behavior is linear; \n        hence, a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness.\n        Crucially, we show how the regions around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly-parallel GPU implementation that excels particularly for the \u21132 norm, where previous work has been less effective.\n        Empirically we find this approach to be far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers, and scaling to much deeper networks.",
    "One-sentence Summary": "We present a fast, scalable procedure for checking local robustness in neural networks",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Random Feature Attention",
    "url": "/forum?id=QtTKTdVrFBB",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Attention, transformers, machine translation, language modeling",
    "Abstract": "Transformers are state-of-the-art models for a variety of sequence modeling tasks. At their core is an attention function which models pairwise interactions between the inputs at every timestep. While attention is powerful, it does not scale efficiently to long sequences due to its quadratic time and space complexity in the sequence length. We propose RFA, a linear time and space attention that uses random feature methods to approximate the softmax function, and explore its application in transformers. RFA can be used as a drop-in replacement for conventional softmax attention and offers a straightforward way of learning with recency bias through an optional gating mechanism. Experiments on language modeling and machine translation demonstrate that RFA achieves similar or better performance compared to strong transformer baselines. In the machine translation experiment, RFA decodes twice as fast as a vanilla transformer. Compared to existing efficient transformer variants, RFA is competitive in terms of both accuracy and efficiency on three long text classification datasets. Our analysis shows that RFA\u2019s efficiency gains are especially notable on long sequences, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints.",
    "One-sentence Summary": "We propose a random-feature-based attention that scales linearly in sequence length, and performs on par with strong transformer baselines on language modeling and machine translation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "IMDb Movie Reviews, WMT 2014, WikiText-103"
  },
  {
    "title": "Sharpness-aware Minimization for Efficiently Improving Generalization",
    "url": "/forum?id=6Tm1mposlrM",
    "date": "28 Sept 2020 (modified: 05 Apr 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Sharpness Minimization, Generalization, Regularization, Training Method, Deep Learning",
    "Abstract": "In today's heavily overparameterized models, the value of the training loss provides few guarantees on model generalization ability. Indeed, optimizing only the training loss value, as is commonly done, can easily lead to suboptimal model quality. Motivated by the connection between geometry of the loss landscape and generalization---including a generalization bound that we prove here---we introduce a novel, effective procedure for instead simultaneously minimizing loss value and loss sharpness.  In particular, our procedure, Sharpness-Aware Minimization (SAM), seeks parameters that lie in neighborhoods having uniformly low loss; this formulation results in a min-max optimization problem on which gradient descent can be performed efficiently. We present empirical results showing that SAM improves model generalization across a variety of benchmark datasets (e.g., CIFAR-{10, 100}, ImageNet, finetuning tasks) and models, yielding novel state-of-the-art performance for several.  Additionally, we find that SAM natively provides robustness to label noise on par with that provided by state-of-the-art procedures that specifically target learning with noisy labels.",
    "One-sentence Summary": "Motivated by the connection between geometry of the loss landscape and generalization, we introduce a procedure for simultaneously minimizing loss value and loss sharpness.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "google-research/sam +  11 community implementations",
    "Data": "Birdsnap, CIFAR-10, CIFAR-100, FGVC-Aircraft, Fashion-MNIST, Food-101, ImageNet, Oxford 102 Flower, Oxford-IIIT Pets, SVHN, Stanford Cars"
  },
  {
    "title": "PMI-Masking: Principled masking of correlated spans",
    "url": "/forum?id=3Aoft6NWFej",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Language modeling, BERT, pointwise mutual information",
    "Abstract": "Masking tokens uniformly at random constitutes a common flaw in the pretraining of Masked Language Models (MLMs) such as BERT. We show that such uniform masking allows an MLM to minimize its training objective by latching onto shallow local signals, leading to pretraining inefficiency and suboptimal downstream performance. To address this flaw, we propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information (PMI), which jointly masks a token n-gram if it exhibits high collocation over the corpus. PMI-Masking motivates, unifies, and improves upon prior more heuristic approaches that attempt to address the drawback of random uniform token masking, such as whole-word masking, entity/phrase masking, and random-span masking. Specifically, we show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of pretraining.",
    "One-sentence Summary": "Joint masking of correlated tokens significantly speeds up and improves BERT's pretraining",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "GLUE, SQuAD, WebText"
  },
  {
    "title": "Learning Incompressible Fluid Dynamics from Scratch - Towards Fast, Differentiable Fluid Models that Generalize",
    "url": "/forum?id=KUDUoRsEphu",
    "date": "28 Sept 2020 (modified: 02 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Unsupervised Learning, Fluid Dynamics, U-Net",
    "Abstract": "Fast and stable fluid simulations are an essential prerequisite for applications ranging from computer-generated imagery to computer-aided design in research and development. However, solving the partial differential equations of incompressible fluids is a challenging task and traditional numerical approximation schemes come at high computational costs. Recent deep learning based approaches promise vast speed-ups but do not generalize to new fluid domains, require fluid simulation data for training, or rely on complex pipelines that outsource major parts of the fluid simulation to traditional methods.\n        \n        In this work, we propose a novel physics-constrained training approach that generalizes to new fluid domains, requires no fluid simulation data, and allows convolutional neural networks to map a fluid state from time-point t to a subsequent state at time t+dt in a single forward pass. This simplifies the pipeline to train and evaluate neural fluid models. After training, the framework yields models that are capable of fast fluid simulations and can handle various fluid phenomena including the Magnus effect and K\u00e1rm\u00e1n vortex streets. We present an interactive real-time demo to show the speed and generalization capabilities of our trained models. Moreover, the trained neural networks are efficient differentiable fluid solvers as they offer a differentiable update step to advance the fluid simulation in time. We exploit this fact in a proof-of-concept optimal control experiment. Our models significantly outperform a recent differentiable fluid solver in terms of computational speed and accuracy.",
    "One-sentence Summary": "We present an unsupervised training framework for incompressible fluid dynamics that allows neural networks to perform fast, accurate, differentiable fluid simulations and generalize to new domain geometries.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "A Gradient Flow Framework For Analyzing Network Pruning",
    "url": "/forum?id=rumv7QmLUue",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Network pruning, Gradient flow, Early pruning",
    "Abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.",
    "One-sentence Summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "EkdeepSLubana/flowandprune"
  },
  {
    "title": "Towards Robustness Against Natural Language Word Substitutions",
    "url": "/forum?id=ks5nebunVn_",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Natural Language Processing, Adversarial Defense",
    "Abstract": "Robustness against word substitutions has a well-defined and widely acceptable form, i.e., using semantically similar words as substitutions, and thus it is considered as a fundamental stepping-stone towards broader robustness in natural language processing. Previous defense methods capture word substitutions in vector space by using either l_2-ball or hyper-rectangle, which results in perturbation sets that are not inclusive enough or unnecessarily large, and thus impedes mimicry of worst cases for robust training. In this paper, we introduce a novel Adversarial Sparse Convex Combination (ASCC) method. We model the word substitution attack space as a convex hull and leverages a regularization term to enforce perturbation towards an actual substitution, thus aligning our modeling better with the discrete textual space. Based on  ASCC method, we further propose ASCC-defense, which leverages ASCC to generate worst-case perturbations and incorporates adversarial training towards robustness. Experiments show that ASCC-defense outperforms the current state-of-the-arts in terms of robustness on two prevailing NLP tasks, i.e., sentiment analysis and natural language inference, concerning several attacks across multiple model architectures. Besides, we also envision a new class of defense towards robustness in NLP, where our robustly trained word vectors can be plugged into a normally trained model and enforce its robustness without applying any other defense techniques.",
    "One-sentence Summary": "Capture adversarial word substitutions in the vector space using convex hull towards robustness.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "dongxinshuai/ASCC",
    "Data": "IMDb Movie Reviews, SNLI"
  },
  {
    "title": "Iterative Empirical Game Solving via Single Policy Best Response",
    "url": "/forum?id=R4aWTjmrEKM",
    "date": "28 Sept 2020 (modified: 17 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Empirical Game Theory, Reinforcement Learning, Multiagent Learning",
    "Abstract": "Policy-Space Response Oracles (PSRO) is a general algorithmic framework for learning policies in multiagent systems by interleaving empirical game analysis with deep reinforcement learning (DRL).\n        At each iteration, DRL is invoked to train a best response to a mixture of opponent policies.\n        The repeated application of DRL poses an expensive computational burden as we look to apply this algorithm to more complex domains.\n        We introduce two variations of PSRO designed to reduce the amount of simulation required during DRL training.\n        Both algorithms modify how PSRO adds new policies to the empirical game, based on learned responses to a single opponent policy.\n        The first, Mixed-Oracles, transfers knowledge from previous iterations of DRL, requiring training only against the opponent's newest policy.\n        The second, Mixed-Opponents, constructs a pure-strategy opponent by mixing existing strategy's action-value estimates, instead of their policies.\n        Learning against a single policy mitigates conflicting experiences on behalf of a learner facing an unobserved distribution of opponents.\n        We empirically demonstrate that these algorithms substantially reduce the amount of simulation during training required by PSRO, while producing equivalent or better solutions to the game.",
    "One-sentence Summary": "On each epoch, train against a single opponent policy rather than a distribution; reducing variance and focusing training on salient strategic knowledge.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Self-Supervised Policy Adaptation during Deployment",
    "url": "/forum?id=o_V-MjyyGV_",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "reinforcement learning, robotics, self-supervised learning, generalization, sim2real",
    "Abstract": "In most real world scenarios, a policy trained by reinforcement learning in one environment needs to be deployed in another, potentially quite different environment. However, generalization across different environments is known to be hard. A natural solution would be to keep training after deployment in the new environment, but this cannot be done if the new environment offers no reward signal. Our work explores the use of self-supervision to allow the policy to continue training after deployment without using any rewards. While previous methods explicitly anticipate changes in the new environment, we assume no prior knowledge of those changes yet still obtain significant improvements. Empirical evaluations are performed on diverse simulation environments from DeepMind Control suite and ViZDoom, as well as real robotic manipulation tasks in  continuously changing environments, taking observations from an uncalibrated camera. Our method improves generalization in 31 out of 36 environments across various tasks and outperforms domain randomization on a majority of environments. Webpage and implementation: https://nicklashansen.github.io/PAD/.",
    "One-sentence Summary": "Generalization across enviroments is known to be hard. We propose a self-supervised method for policy adaptation during deployment that assumes no prior knowledge of the test environment, yet still obtains significant improvements.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "4 community implementations",
    "Data": "DeepMind Control Suite"
  },
  {
    "title": "Differentially Private Learning Needs Better Features (or Much More Data)",
    "url": "/forum?id=YTWGvpFOQD-",
    "date": "28 Sept 2020 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Differential Privacy, Privacy, Deep Learning",
    "Abstract": "We demonstrate that differentially private machine learning has not yet reached its ''AlexNet moment'' on many canonical vision tasks: linear models trained on handcrafted features significantly outperform end-to-end deep neural networks for moderate privacy budgets.\n        To exceed the performance of handcrafted features, we show that private learning requires either much more private data, or access to features learned on public data from a similar domain.\n        Our work introduces simple yet strong baselines for differentially private learning that can inform the evaluation of future progress in this area.",
    "One-sentence Summary": "Linear models with handcrafted features outperform end-to-end CNNs for differentially private learning",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "ftramer/Handcrafted-DP +  1 community implementation",
    "Data": "CIFAR-10, CIFAR-100, Fashion-MNIST, ImageNet, Tiny Images"
  },
  {
    "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations",
    "url": "/forum?id=uCQfPZwRaUu",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Reinforcement Learning, Self-Supervised Learning, Representation Learning, Sample Efficiency",
    "Abstract": "While deep reinforcement learning excels at solving tasks where large amounts of data can be collected through virtually unlimited interaction with the environment, learning from limited interaction remains a key challenge. We posit that an agent can learn more efficiently if we augment reward maximization with self-supervised objectives based on structure in its visual input and sequential interaction with the environment.  Our method, Self-Predictive Representations (SPR), trains an agent to predict its own latent state representations multiple steps into the future. We compute target representations for future states using an encoder which is an exponential moving average of the agent\u2019s parameters and we make predictions using a learned transition model.  On its own,  this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. We further improve performance by adding data augmentation to the future prediction loss, which forces the agent\u2019s representations to be consistent across multiple views of an observation.  Our full self-supervised objective, which combines future prediction and data augmentation, achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55% relative improvement over the previous state-of-the-art. Notably, even in this limited data regime, SPR exceeds expert human scores on 7 out of 26 games. We\u2019ve made the code associated with this work available at https://github.com/mila-iqia/spr.",
    "One-sentence Summary": "We propose a temporal, self-supervised objective for RL agents and show that it significantly improves data efficiency in a setting limited to just 2h of gameplay on Atari.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "mila-iqia/spr",
    "Data": "Atari 100k"
  },
  {
    "title": "Meta-GMVAE: Mixture of Gaussian VAE for Unsupervised Meta-Learning",
    "url": "/forum?id=wS0UFjsNYjn",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Unsupervised Learning, Meta-Learning, Unsupervised Meta-learning, Variational Autoencoders",
    "Abstract": "Unsupervised learning aims to learn meaningful representations from unlabeled data which can captures its intrinsic structure, that can be transferred to downstream tasks. Meta-learning, whose objective is to learn to generalize across tasks such that the learned model can rapidly adapt to a novel task, shares the spirit of unsupervised learning in that the both seek to learn more effective and efficient learning procedure than learning from scratch. The fundamental difference of the two is that the most meta-learning approaches are supervised, assuming full access to the labels. However, acquiring labeled dataset for meta-training not only is costly as it requires human efforts in labeling but also limits its applications to pre-defined task distributions. In this paper, we propose a principled unsupervised meta-learning model, namely Meta-GMVAE, based on Variational Autoencoder (VAE) and set-level variational inference. Moreover, we introduce a mixture of Gaussian (GMM) prior, assuming that each modality represents each class-concept in a randomly sampled episode, which we optimize with Expectation-Maximization (EM). Then, the learned model can be used for downstream few-shot classification tasks, where we obtain task-specific parameters by performing semi-supervised EM on the latent representations of the support and query set, and predict labels of the query set by computing aggregated posteriors. We validate our model on Omniglot and Mini-ImageNet datasets by evaluating its performance on downstream few-shot classification tasks. The results show that our model obtain impressive performance gains over existing unsupervised meta-learning baselines, even outperforming supervised MAML on a certain setting.",
    "One-sentence Summary": "we propose a principled unsupervised meta-learning model which meta-learns a set-level variational posterior, by matching it with multi-modal prior distribution obtained by EM.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "db-Lee/Meta-GMVAE"
  },
  {
    "title": "Implicit Convex Regularizers of CNN Architectures: Convex Optimization of Two- and Three-Layer Networks in Polynomial Time",
    "url": "/forum?id=0N8jUH4JMv6",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Convex optimization, non-convex optimization, group sparsity, \u21131 norm, convex duality, polynomial time, deep learning",
    "Abstract": "We study training of Convolutional Neural Networks (CNNs) with ReLU activations and introduce exact convex optimization formulations with a polynomial complexity with respect to the number of data samples, the number of neurons, and data dimension. More specifically, we develop a convex analytic framework utilizing semi-infinite duality to obtain equivalent convex optimization problems for several two- and three-layer CNN architectures. We first prove that two-layer CNNs can be globally optimized via an \u21132 norm regularized convex program. We then show that multi-layer circular CNN training problems with a single ReLU layer are equivalent to an \u21131 regularized convex program that encourages sparsity in the spectral domain. We also extend these results to three-layer CNNs with two ReLU layers. Furthermore, we present extensions of our approach to different pooling methods, which elucidates the implicit architectural bias as convex regularizers.",
    "One-sentence Summary": "We study the training problem for various CNN architectures with ReLU activations and introduce equivalent finite dimensional convex formulations that can be used to globally optimize these architectures.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels",
    "url": "/forum?id=GY6-6sTvGaf",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Abstract": "We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training.  The approach leverages input perturbations commonly used in computer vision tasks to transform input examples, as well as regularizing the value function and policy.  Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC\u2019s performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Hafner et al., 2019; Lee et al., 2019; Hafner et al., 2018) methods and recently proposed contrastive learning (Srinivas et al., 2020).  Our approach, which we dub DrQ: Data-regularized Q, can be combined with any model-free reinforcement learning algorithm. We further demonstrate this by applying it to DQN and significantly improve its data-efficiency on the Atari 100k benchmark.",
    "One-sentence Summary": "The first successful demonstration that image augmentation can be applied to image-based Deep RL to achieve SOTA performance.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "denisyarats/drq",
    "Data": "Atari 100k, DeepMind Control Suite"
  },
  {
    "title": "Dynamic Tensor Rematerialization",
    "url": "/forum?id=Vfs_2RnOD0H",
    "date": "28 Sept 2020 (modified: 21 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Rematerialization, Memory-saving, Runtime Systems, Checkpointing",
    "Abstract": "Checkpointing enables the training of deep learning models under restricted memory budgets by freeing intermediate activations from memory and recomputing them on demand. Current checkpointing techniques statically plan these recomputations offline and assume static computation graphs. We demonstrate that a simple online algorithm can achieve comparable performance by introducing Dynamic Tensor Rematerialization (DTR), a greedy online algorithm for checkpointing that is extensible and general, is parameterized by eviction policy, and supports dynamic models. We prove that DTR can train an N-layer linear feedforward network on an  \u03a9(N) memory budget with only O(N) tensor operations. DTR closely matches the performance of optimal static checkpointing in simulated experiments. We incorporate a DTR prototype into PyTorch merely by interposing on tensor allocations and operator calls and collecting lightweight metadata on tensors.",
    "One-sentence Summary": "We present an online algorithm for rematerialization (recomputing intermediate activations during backpropagation instead of storing them), which enables training under low memory, finding that it is competitive with offline techniques.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "uwsampl/dtr-prototype"
  },
  {
    "title": "Deep Neural Network Fingerprinting by Conferrable Adversarial Examples",
    "url": "/forum?id=VqzVhqxkjH1",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Fingerprinting, Adversarial Examples, Transferability, Conferrability",
    "Abstract": "In Machine Learning as a Service, a provider trains a deep neural network and gives many users access. The hosted (source) model is susceptible to model stealing attacks, where an adversary derives a surrogate model from API access to the source model. For post hoc detection of such attacks, the provider needs a robust method to determine whether a suspect model is a surrogate of their model. We propose a fingerprinting method for deep neural network classifiers that extracts a set of inputs from the source model so that only surrogates agree with the source model on the classification of such inputs. These inputs are a subclass of transferable adversarial examples which we call conferrable adversarial examples that exclusively transfer with a target label from a source model to its surrogates. We propose a new method to generate these conferrable adversarial examples. We present an extensive study on the irremovability of our fingerprint against fine-tuning, weight pruning, retraining, retraining with different architectures, three model extraction attacks from related work, transfer learning, adversarial training, and two new adaptive attacks. Our fingerprint is robust against distillation, related model extraction attacks, and even transfer learning when the attacker has no access to the model provider's dataset. Our fingerprint is the first method that reaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63 by previous fingerprints.",
    "One-sentence Summary": "Proposal of a new property called \"conferrability\" for adversarial examples that we use as a method for DNN fingerprinting robust to model extraction.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "ImageNet, ImageNet-32"
  },
  {
    "title": "Model-Based Visual Planning with Self-Supervised Functional Distances",
    "url": "/forum?id=UcoXdfrORC",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "planning, model learning, distance learning, reinforcement learning, robotics",
    "Abstract": "A generalist robot must be able to complete a variety of tasks in its environment. One appealing way to specify each task is in terms of a goal observation. However, learning goal-reaching policies with reinforcement learning remains a challenging problem, particularly when hand-engineered reward functions are not available. Learned dynamics models are a promising approach for learning about the environment without rewards or task-directed data, but planning to reach goals with such a model requires a notion of functional similarity between observations and goal states. We present a self-supervised method for model-based visual goal reaching, which uses both a visual dynamics model as well as a dynamical distance function learned using model-free reinforcement learning. Our approach learns entirely using offline, unlabeled data, making it practical to scale to large and diverse datasets. In our experiments, we find that our method can successfully learn models that perform a variety of tasks at test-time, moving objects amid distractors with a simulated robotic arm and even learning to open and close a drawer using a real-world robot. In comparisons, we find that this approach substantially outperforms both model-free and model-based prior methods.",
    "One-sentence Summary": "We combine model-based planning with dynamical distance learning to solve visual goal-reaching tasks, using random, unlabeled, experience.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "s-tian/mbold"
  },
  {
    "title": "Mathematical Reasoning via Self-supervised Skip-tree Training",
    "url": "/forum?id=YmqAnY0CMEy",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "self-supervised learning, mathematics, reasoning, theorem proving, language modeling",
    "Abstract": "We demonstrate that self-supervised language modeling applied to mathematical formulas enables logical reasoning. To measure the logical reasoning abilities of language models, we formulate several evaluation (downstream) tasks, such as inferring types, suggesting missing assumptions and completing equalities. For training language models for formal mathematics, we propose a novel skip-tree task. We find that models trained on the skip-tree task show surprisingly strong mathematical reasoning abilities, and outperform models trained on standard skip-sequence tasks. We also analyze the models' ability to formulate new conjectures by measuring how often the predictions are provable and useful in other proofs.",
    "One-sentence Summary": "We demonstrate that self-supervised language modeling applied to mathematical formulas enables logical reasoning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "HOList"
  },
  {
    "title": "DeepAveragers: Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs",
    "url": "/forum?id=eMP1j9efXtX",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Offline Reinforcement Learning, Planning",
    "Abstract": "We study an approach to offline reinforcement learning (RL) based on optimally solving  finitely-represented  MDPs  derived  from  a  static  dataset  of  experience. This approach can be applied on top of any learned representation and has the potential to easily support multiple solution objectives as well as zero-shot adjustment to changing environments and goals.  Our main contribution is to introduce the Deep Averagers with Costs MDP (DAC-MDP) and to investigate its solutions for offline RL.  DAC-MDPs are a non-parametric model that can leverage deep representations and account for limited data by introducing costs for exploiting under-represented parts of the model.  In theory, we show conditions that allow for lower-bounding the performance of DAC-MDP solutions. We also investigate the empirical behavior in a number of environments, including those with image-based observations. Overall, the experiments demonstrate that the framework can work in practice and scale to large complex offline RL problems.",
    "One-sentence Summary": "The paper introduces and investigates an offline RL approach based on optimally solving a finite-state MDP that is derived from the experience dataset using any latent state representation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "maximecb/gym-miniworld +  1 community implementation"
  },
  {
    "title": "On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers",
    "url": "/forum?id=p-NZIuwqhI4",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Implicit Deep Learning, Deep Equilibrium Models, Gradient Descent, Learning Theory, Non-Convex Optimization",
    "Abstract": "A deep equilibrium model uses implicit layers, which are implicitly defined through an equilibrium point of an infinite sequence of computation. It avoids any explicit computation of the infinite sequence by finding an equilibrium point directly via root-finding and by computing gradients via implicit differentiation. In this paper, we analyze the gradient dynamics of deep equilibrium models with nonlinearity only on weight matrices and non-convex objective functions of weights for regression and classification. Despite non-convexity, convergence to global optimum at a linear rate is guaranteed without any assumption on the width of the models, allowing the width to be smaller than the output dimension and the number of data points. Moreover, we prove a relation between the gradient dynamics of the deep implicit layer and the dynamics of trust region Newton method of a shallow explicit layer. This mathematically proven relation along with our numerical observation suggests the importance of understanding implicit bias of implicit layers and an open problem on the topic. Our proofs deal with implicit layers, weight tying and nonlinearity on weights, and differ from those in the related literature.",
    "One-sentence Summary": "We analyze gradient dynamics of a simple deep equilibrium model and mathematically prove its theoretical properties.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, CIFAR-100, Kuzushiji-MNIST, MNIST"
  },
  {
    "title": "BUSTLE: Bottom-Up Program Synthesis Through Learning-Guided Exploration",
    "url": "/forum?id=yHeg4PbFHh",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Program Synthesis",
    "Abstract": "Program synthesis is challenging largely because of the difficulty of search in a large space of programs. Human programmers routinely tackle the task of writing complex programs by writing sub-programs and then analyzing their intermediate results to compose them in appropriate ways. Motivated by this intuition, we present a new synthesis approach that leverages learning to guide a bottom-up search over programs. In particular, we train a model to prioritize compositions of intermediate values during search conditioned on a given set of input-output examples. This is a powerful combination because of several emergent properties. First, in bottom-up search, intermediate programs can be executed, providing semantic information to the neural network. Second, given the concrete values from those executions, we can exploit rich features based on recent work on property signatures. Finally, bottom-up search allows the system substantial flexibility in what order to generate the solution, allowing the synthesizer to build up a program from multiple smaller sub-programs. Overall, our empirical evaluation finds that the combination of learning and bottom-up search is remarkably effective, even with simple supervised learning approaches. We demonstrate the effectiveness of our technique on two datasets, one from the SyGuS competition and one of our own creation.",
    "One-sentence Summary": "We use a learned model to guide a bottom-up program synthesis search to efficiently synthesize spreadsheet programs.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "The Traveling Observer Model: Multi-task Learning Through Spatial Variable Embeddings",
    "url": "/forum?id=qYda4oLEc1",
    "date": "28 Sept 2020 (modified: 22 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Multi-task, Many-task, Multi-domain, Cross-domain, Variable Embeddings, Task Embeddings, Tabular, Analogies",
    "Abstract": "This paper frames a general prediction system as an observer traveling around a continuous space, measuring values at some locations, and predicting them at others. The observer is completely agnostic about any particular task being solved; it cares only about measurement locations and their values. This perspective leads to a machine learning framework in which seemingly unrelated tasks can be solved by a single model, by embedding their input and output variables into a shared space. An implementation of the framework is developed in which these variable embeddings are learned jointly with internal model parameters. In experiments, the approach is shown to (1) recover intuitive locations of variables in space and time, (2) exploit regularities across related datasets with completely disjoint input and output spaces, and (3) exploit regularities across seemingly unrelated tasks, outperforming task-specific single-task models and multi-task learning alternatives. The results suggest that even seemingly unrelated tasks may originate from similar underlying processes, a fact that the traveling observer model can use to make better predictions.",
    "One-sentence Summary": "Learn a single model across \"unrelated\" tasks by embedding their input and output variables in a shared space.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Fidelity-based Deep Adiabatic Scheduling",
    "url": "/forum?id=NECTfffOvn1",
    "date": "28 Sept 2020 (modified: 15 Feb 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Abstract": "Adiabatic quantum computation is a form of computation that acts by slowly interpolating a quantum system between an easy to prepare initial state and a final state that represents a solution to a given computational problem. The choice of the interpolation schedule is critical to the performance: if at a certain time point, the evolution is too rapid, the system has a high probability to transfer to a higher energy state, which does not represent a solution to the problem. On the other hand, an evolution that is too slow leads to a loss of computation time and increases the probability of failure due to decoherence. In this work, we train deep neural models to produce optimal schedules that are conditioned on the problem at hand.  We consider two types of problem representation: the Hamiltonian form, and the Quadratic Unconstrained Binary Optimization (QUBO) form. A novel loss function that scores schedules according to their approximated success probability is introduced. We benchmark our approach on random QUBO problems, Grover search, 3-SAT, and MAX-CUT problems and show that our approach outperforms, by a sizable margin, the linear schedules as well as alternative approaches that were very recently proposed.",
    "One-sentence Summary": "A new loss for applying supervised deep learning to the problem of scheduling adiabatic quantum computations",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Deciphering and Optimizing Multi-Task Learning: a Random Matrix Approach",
    "url": "/forum?id=Cri3xz59ga",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Transfer Learning, Multi Task Learning, Random Matrix Theory",
    "Abstract": "This article provides theoretical insights into the inner workings of multi-task and transfer learning methods, by studying the tractable least-square support vector machine multi-task learning (LS-SVM MTL) method, in the limit of large (p) and numerous (n) data. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL LS-SVM is shown to converge, as n,p\u2192\u221e, to a deterministic limit involving simple (small-dimensional) statistics of the data.\n        \n        We prove (i) that the standard MTL LS-SVM algorithm is in general strongly biased and may dramatically fail (to the point that individual single-task LS-SVMs may outperform the MTL approach, even for quite resembling tasks): our analysis provides a simple method to correct these biases, and that we reveal (ii) the sufficient statistics at play in the method, which can be efficiently estimated, even for quite small datasets. The latter result is exploited to automatically optimize the hyperparameters without resorting to any cross-validation procedure. \n        \n        Experiments on popular datasets demonstrate that our improved MTL LS-SVM method is computationally-efficient and outperforms sometimes much more elaborate state-of-the-art multi-task and transfer learning techniques.",
    "One-sentence Summary": "This paper provides a theoretical analysis of Multi Task Learning schemes for large dimensional data",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "Caltech-256"
  },
  {
    "title": "Learning-based Support Estimation in Sublinear Time",
    "url": "/forum?id=tilovEHA3YS",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "support estimation, sublinear, learning-based, distinct elements, chebyshev polynomial",
    "Abstract": "We consider the  problem of estimating the number of distinct elements in a large data set (or, equivalently, the support size of the distribution induced by the data set) from a random sample of its elements. The problem occurs in many applications, including biology, genomics, computer systems and linguistics. A line of research spanning the last decade resulted in algorithms that estimate the support up to \u00b1\u03b5n from a sample of size O(log2\u2061(1/\u03b5)\u22c5n/log\u2061n), where n is the data set size.  Unfortunately, this bound is known to be tight, limiting further improvements to the complexity of this problem. In this paper we consider estimation algorithms augmented with a machine-learning-based predictor that, given any element, returns an estimation of  its frequency.  We show that if the predictor is correct up to a constant approximation factor, then the sample complexity can be reduced significantly,  to\n        \u00a0log\u2061(1/\u03b5)\u22c5n1\u2212\u0398(1/log\u2061(1/\u03b5)).\n        We evaluate the proposed algorithms on a collection of data sets, using the neural-network based estimators from {Hsu et al, ICLR'19} as predictors. Our experiments  demonstrate substantial (up to 3x) improvements in the estimation accuracy compared to the state of the art algorithm.",
    "One-sentence Summary": "A learning-based algorithm for support size estimation, which given a sufficiently accurate predictor, improves both provably and empirically over state-of-the-art algorithms that do not use a predictor.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Unlearnable Examples: Making Personal Data Unexploitable",
    "url": "/forum?id=iAmZUo0DxC0",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Unlearnable Examples, Data Protection, Adversarial Machine Learning",
    "Abstract": "The volume of \"free\" data on the internet has been key to the current success of deep learning. However, it also raises privacy concerns about the unauthorized exploitation of personal data for training commercial models. It is thus crucial to develop methods to prevent unauthorized data exploitation. This paper raises the question: can data be made unlearnable for deep learning models? We present a type of error-minimizing noise that can indeed make training examples unlearnable. Error-minimizing noise is intentionally generated to reduce the error of one or more of the training example(s) close to zero, which can trick the model into believing there is \"nothing\" to learn from these example(s). The noise is restricted to be imperceptible to human eyes, and thus does not affect normal data utility. We empirically verify the effectiveness of error-minimizing noise in both sample-wise and class-wise forms. We also demonstrate its flexibility under extensive experimental settings and practicability in a case study of face recognition. Our work establishes an important \ufb01rst step towards making personal data unexploitable to deep learning models.",
    "One-sentence Summary": "We present a type of error-minimizing noise that can make training examples unlearnable to deep learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "HanxunH/Unlearnable-Examples",
    "Data": "CASIA-WebFace, CIFAR-10, CIFAR-100, CelebA, SVHN"
  },
  {
    "title": "How Benign is Benign Overfitting ?",
    "url": "/forum?id=g-wu9TMPODo",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "benign overfitting, adversarial robustness, memorization, generalization",
    "Abstract": "We investigate two causes for adversarial vulnerability in deep neural networks: bad data and (poorly) trained models. When trained with SGD, deep neural networks essentially achieve zero training error, even in the presence of label noise, while also exhibiting good generalization on natural test data, something referred to as benign overfitting (Bartlett et al., 2020; Chatterji & Long, 2020).  However, these models are vulnerable to adversarial attacks. We identify label noise as one of the causes for adversarial vulnerability, and provide theoretical and empirical evidence in support of this. Surprisingly, we find several instances of label noise in datasets such as MNIST and CIFAR, and that robustly trained models incur training error on some of these, i.e. they don\u2019t fit the noise. However, removing noisy labels alone does not suffice to achieve adversarial robustness. We conjecture that in part sub-optimal representation learning is also responsible for adversarial vulnerability. By means of simple theoretical setups, we show how the choice of representation can drastically affect adversarial robustness.",
    "One-sentence Summary": "Interpolating label noise hurts adversarial robustness",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, MNIST"
  },
  {
    "title": "Autoregressive Entity Retrieval",
    "url": "/forum?id=5k8F6UU39V",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "entity retrieval, document retrieval, autoregressive language model, entity linking, end-to-end entity linking, entity disambiguation, constrained beam search",
    "Abstract": "Entities are at the center of how we represent and aggregate knowledge. For instance, Encyclopedias such as Wikipedia are structured by entities (e.g., one per Wikipedia article). The ability to retrieve such entities given a query is fundamental for knowledge-intensive tasks such as entity linking and open-domain question answering. One way to understand current approaches is as classifiers among atomic labels, one for each entity. Their weight vectors are dense entity representations produced by encoding entity meta information such as their descriptions. This approach leads to several shortcomings: (i) context and entity affinity is mainly captured through a vector dot product, potentially missing fine-grained interactions between the two; (ii) a large memory footprint is needed to store dense representations when considering large entity sets; (iii) an appropriately hard set of negative data has to be subsampled at training time. In this work, we propose GENRE, the first system that retrieves entities by generating their unique names, left to right, token-by-token in an autoregressive fashion and conditioned on the context. This enables us to mitigate the aforementioned technical issues since: (i) the autoregressive formulation allows us to directly capture relations between context and entity name, effectively cross encoding both; (ii) the memory footprint is greatly reduced because the parameters of our encoder-decoder architecture scale with vocabulary size, not entity count; (iii) the exact softmax loss can be efficiently computed without the need to subsample negative data. We show the efficacy of the approach, experimenting with more than 20 datasets on entity disambiguation, end-to-end entity linking and document retrieval tasks, achieving new state-of-the-art or very competitive results while using a tiny fraction of the memory footprint of competing systems. Finally, we demonstrate that new entities can be added by simply specifying their unambiguous name. Code and pre-trained models at https://github.com/facebookresearch/GENRE.",
    "One-sentence Summary": "We address entity retrieval by generating their unique name identifiers, left to right, in an autoregressive fashion, and conditioned on the context showing SOTA results in more than 20 datasets with a tiny fraction of the memory of recent systems.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "facebookresearch/GENRE",
    "Data": "ACE 2004, AIDA CoNLL-YAGO, AQUAINT, ELI5, HotpotQA, KILT, Natural Questions, T-REx, TriviaQA, Wizard of Wikipedia"
  },
  {
    "title": "Neural Approximate Sufficient Statistics for Implicit Models",
    "url": "/forum?id=SRDuJssQud",
    "date": "28 Sept 2020 (modified: 15 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "likelihood-free inference, bayesian inference, mutual information, representation learning, summary statistics",
    "Abstract": "We consider the fundamental problem of how to automatically construct summary statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The idea is to frame the task of constructing sufficient statistics as learning mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio. We apply our approach to both traditional approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks.",
    "One-sentence Summary": "We learn low-dimensional near-sufficient statistics for implicit models by infomax principle without estimating the density or even the density ratio.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Large Scale Image Completion via Co-Modulated Generative Adversarial Networks",
    "url": "/forum?id=sSjqmfsk95O",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "image completion, generative adversarial networks, co-modulation",
    "Abstract": "Numerous task-specific variants of conditional generative adversarial networks have been developed for image completion. Yet, a serious limitation remains that all existing algorithms tend to fail when handling large-scale missing regions. To overcome this challenge, we propose a generic new approach that bridges the gap between image-conditional and recent modulated unconditional generative architectures via co-modulation of both conditional and stochastic style representations. Also, due to the lack of good quantitative metrics for image completion, we propose the new Paired/Unpaired Inception Discriminative Score (P-IDS/U-IDS), which robustly measures the perceptual fidelity of inpainted images compared to real images via linear separability in a feature space. Experiments demonstrate superior performance in terms of both quality and diversity over state-of-the-art methods in free-form image completion and easy generalization to image-to-image translation. Code is available at https://github.com/zsyzzsoft/co-mod-gan.",
    "One-sentence Summary": "Bridging the gap between between image-conditional and unconditional GAN architectures via co-modulation",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "zsyzzsoft/co-mod-gan",
    "Data": "COCO-Stuff, FFHQ, Places"
  },
  {
    "title": "DDPNOpt: Differential Dynamic Programming Neural Optimizer",
    "url": "/forum?id=6s7ME_X5_Un",
    "date": "28 Sept 2020 (modified: 16 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "deep learning training, optimal control, trajectory optimization, differential dynamica programming",
    "Abstract": "Interpretation of Deep Neural Networks (DNNs) training as an optimal control problem with nonlinear dynamical systems has received considerable attention recently, yet the algorithmic development remains relatively limited. In this work, we make an attempt along this line by reformulating the training procedure from the trajectory optimization perspective. We first show that most widely-used algorithms for training DNNs can be linked to the Differential Dynamic Programming (DDP), a celebrated second-order method rooted in the Approximate Dynamic Programming. In this vein, we propose a new class of optimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and convolution networks. DDPNOpt features layer-wise feedback policies which improve convergence and reduce sensitivity to hyper-parameter over existing methods. It outperforms other optimal-control inspired training methods in both convergence and complexity, and is competitive against state-of-the-art first and second order methods. We also observe DDPNOpt has surprising benefit in preventing gradient vanishing. Our work opens up new avenues for principled algorithmic design built upon the optimal control theory.",
    "One-sentence Summary": "We introduce a new class of optimal-control-theoretic training methods, DDPNOpt, that performs a distinct backward pass inherited with Bellman optimality and generates layer-wise feedback policies to robustify training over existing training methods",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Geometry-Aware Gradient Algorithms for Neural Architecture Search",
    "url": "/forum?id=MuSYkd1hxRP",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "neural architecture search, automated machine learning, weight-sharing, optimization",
    "Abstract": "Recent state-of-the-art methods for neural architecture search (NAS) exploit gradient-based optimization by relaxing the problem into continuous optimization over architectures and shared-weights, a noisy process that remains poorly understood. We argue for the study of single-level empirical risk minimization to understand NAS with weight-sharing, reducing the design of NAS methods to devising optimizers and regularizers that can quickly obtain high-quality solutions to this problem. Invoking the theory of mirror descent, we present a geometry-aware framework that exploits the underlying structure of this optimization to return sparse architectural parameters, leading to simple yet novel algorithms that enjoy fast convergence guarantees and achieve state-of-the-art accuracy on the latest NAS benchmarks in computer vision. Notably, we exceed the best published results for both CIFAR and ImageNet on both the DARTS search space and NAS-Bench-201; on the latter we achieve near-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory and experiments demonstrate a principled way to co-design optimizers and continuous relaxations of discrete NAS search spaces.",
    "One-sentence Summary": "Studying the right single-level optimization geometry yields state-of-the-art methods for NAS.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "liamcli/gaea_release +  1 community implementation",
    "Data": "CIFAR-10, CIFAR-100, NAS-Bench-1Shot1, NAS-Bench-201"
  },
  {
    "title": "Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with 1/n Parameters",
    "url": "/forum?id=rcQdycl0zyk",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "hypercomplex representation learning",
    "Abstract": "Recent works have demonstrated reasonable success of representation learning in hypercomplex space. Specifically, \u201cfully-connected layers with quaternions\u201d (quaternions are 4D hypercomplex numbers), which replace real-valued matrix multiplications in fully-connected layers with Hamilton products of quaternions, both enjoy parameter savings with only 1/4 learnable parameters and achieve comparable performance in various applications. However, one key caveat is that hypercomplex space only exists at very few predefined dimensions (4D, 8D, and 16D). This restricts the flexibility of models that leverage hypercomplex multiplications. To this end, we propose parameterizing hypercomplex multiplications, allowing models to learn multiplication rules from data regardless of whether such rules are predefined. As a result, our method not only subsumes the Hamilton product, but also learns to operate on any arbitrary nD hypercomplex space, providing more architectural flexibility using arbitrarily 1/n learnable parameters compared with the fully-connected layer counterpart. Experiments of applications to the LSTM and transformer models on natural language inference, machine translation, text style transfer, and subject verb agreement demonstrate architectural flexibility and effectiveness of the proposed approach.",
    "One-sentence Summary": "We propose to parameterize hypercomplex multiplications using arbitrarily 1/n learnable parameters compared with the fully-connected layer counterpart.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "MultiNLI, SNLI"
  },
  {
    "title": "Tent: Fully Test-Time Adaptation by Entropy Minimization",
    "url": "/forum?id=uXl3bZLkr3c",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "deep learning, unsupervised learning, domain adaptation, self-supervision, robustness",
    "Abstract": "A model must adapt itself to generalize to new and different data during testing. In this setting of fully test-time adaptation the model has only the test data and its own parameters. We propose to adapt by test entropy minimization (tent): we optimize the model for confidence as measured by the entropy of its predictions. Our method estimates normalization statistics and optimizes channel-wise affine transformations to update online on each batch. Tent reduces generalization error for image classification on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adaptation on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark. These results are achieved in one epoch of test-time optimization without altering training.",
    "One-sentence Summary": "Deep networks can generalize better during testing by adapting to feedback from their own predictions.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "DequanWang/tent",
    "Data": "CIFAR-10, CIFAR-100, ImageNet-C, MNIST, SVHN"
  },
  {
    "title": "Neural Topic Model via Optimal Transport",
    "url": "/forum?id=Oos98K9Lv-k",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "topic modelling, optimal transport, document analysis",
    "Abstract": "Recently, Neural Topic Models (NTMs) inspired by variational autoencoders have obtained increasingly research interest due to their promising results on text analysis. However, it is usually hard for existing NTMs to achieve good document representation and coherent/diverse topics at the same time. Moreover, they often degrade their performance severely on short documents. The requirement of reparameterisation could also comprise their training quality and model flexibility. To address these shortcomings, we present a new neural topic model via the theory of optimal transport (OT). Specifically, we propose to learn the topic distribution of a document by directly minimising its OT distance to the document's word distributions. Importantly, the cost matrix of the OT distance models the weights between topics and words, which is constructed by the distances between topics and words in an embedding space. Our proposed model can be trained efficiently with a differentiable loss. Extensive experiments show that our framework significantly outperforms the state-of-the-art NTMs on discovering more coherent and diverse topics and deriving better document representations for both regular and short texts.",
    "One-sentence Summary": "This paper presents a neural topic model via optimal transport, which can discover more coherent and diverse topics and derive better document representations for both regular and short texts.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit Neural Network Inference",
    "url": "/forum?id=9xC2tWEwBD",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Slowdown attacks, efficient inference, input-adaptive multi-exit neural networks, adversarial examples",
    "Abstract": "Recent increases in the computational demands of deep neural networks (DNNs), combined with the observation that most input samples require only simple models, have sparked interest in input-adaptive multi-exit architectures, such as MSDNets or Shallow-Deep Networks. These architectures enable faster inferences and could bring DNNs to low-power devices, e.g., in the Internet of Things (IoT). However, it is unknown if the computational savings provided by this approach are robust against adversarial pressure. In particular, an adversary may aim to slowdown adaptive DNNs by increasing their average inference time\u2014a threat analogous to the denial-of-service attacks from the Internet. In this paper, we conduct a systematic evaluation of this threat by experimenting with three generic multi-exit DNNs (based on VGG16, MobileNet, and ResNet56) and a custom multi-exit architecture, on two popular image classification benchmarks (CIFAR-10 and Tiny ImageNet). To this end, we show that adversarial example-crafting techniques can be modified to cause slowdown, and we propose a metric for comparing their impact on different architectures. We show that a slowdown attack reduces the efficacy of multi-exit DNNs by 90\u2013100%, and it amplifies the latency by 1.5\u20135\u00d7 in a typical IoT deployment. We also show that it is possible to craft universal, reusable perturbations and that the attack can be effective in realistic black-box scenarios, where the attacker has limited knowledge about the victim. Finally, we show that adversarial training provides limited protection against slowdowns. These results suggest that further research is needed for defending multi-exit architectures against this emerging threat. Our code is available at https://github.com/sanghyun-hong/deepsloth.",
    "One-sentence Summary": "Is the computational savings provided by the input-adaptive 'multi-exit architectures' robust against adversarial perturbations? No.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "sanghyun-hong/deepsloth",
    "Data": "CIFAR-10, CIFAR-100, Tiny ImageNet"
  },
  {
    "title": "Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?",
    "url": "/forum?id=Ut1vF_q_vC",
    "date": "28 Sept 2020 (modified: 22 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Learning to Rank, benchmark, neural network, gradient boosted decision trees",
    "Abstract": "Despite the success of neural models on many major machine learning problems, their effectiveness on traditional Learning-to-Rank (LTR) problems is still not widely acknowledged. We first validate this concern by showing that most recent neural LTR models are, by a large margin, inferior to the best publicly available Gradient Boosted Decision Trees (GBDT) in terms of their reported ranking accuracy on benchmark datasets. This unfortunately was somehow overlooked in recent neural LTR papers. We then investigate why existing neural LTR models under-perform and identify several of their weaknesses. Furthermore, we propose a unified framework comprising of counter strategies to ameliorate the existing weaknesses of neural models. Our models are the first to be able to perform equally well, comparing with the best tree-based baseline, while outperforming recently published neural LTR models by a large margin. Our results can also serve as a benchmark to facilitate future improvement of neural LTR models.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning",
    "url": "/forum?id=qda7-sVg84",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Reinforcement, Generalization, Contrastive learning, Bisimulation, Representation Learning",
    "Abstract": "Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite.",
    "One-sentence Summary": "A contrastive representation learning method which encodes behavioural similarity in RL for improving generalization.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "google-research/google-research"
  },
  {
    "title": "Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images",
    "url": "/forum?id=RLRXCV6DbEJ",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "VAE, generative modeling, deep learning, likelihood-based models",
    "Abstract": "We present a hierarchical VAE that, for the first time, generates samples quickly and outperforms the PixelCNN in log-likelihood on all natural image benchmarks. We begin by observing that, in theory, VAEs can actually represent autoregressive models, as well as faster, better models if they exist, when made sufficiently deep. Despite this, autoregressive models have historically outperformed VAEs in log-likelihood. We test if insufficient depth explains why by scaling a VAE to greater stochastic depth than previously explored and evaluating it CIFAR-10, ImageNet, and FFHQ. In comparison to the PixelCNN, these very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images. Qualitative studies suggest this is because the VAE learns efficient hierarchical visual representations. We release our source code and models at https://github.com/openai/vdvae.",
    "One-sentence Summary": "We argue deeper VAEs should perform better, implement one, and show it outperforms all PixelCNN-based autoregressive models in likelihood, while being substantially more efficient.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "openai/vdvae +  3 community implementations",
    "Data": "CIFAR-10, FFHQ, ImageNet"
  },
  {
    "title": "Async-RED: A Provably Convergent Asynchronous Block Parallel Stochastic Method using Deep Denoising Priors",
    "url": "/forum?id=9EsrXMzlFQY",
    "date": "28 Sept 2020 (modified: 10 Feb 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Regularization by denoising, Computational imaging, asynchronous parallel algorithm, Deep denoising priors",
    "Abstract": "Regularization by denoising (RED) is a recently developed framework for solving inverse problems by integrating advanced denoisers as image priors. Recent work has shown its state-of-the-art performance when combined with pre-trained deep denoisers. However, current RED algorithms are inadequate for parallel processing on multicore systems. We address this issue by proposing a new{asynchronous RED (Async-RED) algorithm that enables asynchronous parallel processing of data, making it significantly faster than its serial counterparts for large-scale inverse problems. The computational complexity of Async-RED is further reduced by using a random subset of measurements at every iteration. We present a complete theoretical analysis of the algorithm by establishing its convergence under explicit assumptions on the data-fidelity and the denoiser. We validate Async-RED on image recovery using pre-trained deep denoisers as priors.",
    "One-sentence Summary": "Our work develops a novel deep-regularized asynchronous parallel method with provable convergence guarantees for solving large-scale inverse problems.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "A Good Image Generator Is What You Need for High-Resolution Video Synthesis",
    "url": "/forum?id=6puCSjH3hwA",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "high-resolution video generation, contrastive learning, cross-domain video generation",
    "Abstract": "Image and video synthesis are closely related areas aiming at generating content from noise. While rapid progress has been demonstrated in improving image-based models to handle large resolutions, high-quality renderings, and wide variations in image content, achieving comparable video generation results remains problematic. We present a framework that leverages contemporary image generators to render high-resolution videos. We frame the video synthesis problem as discovering a trajectory in the latent space of a pre-trained and fixed image generator. Not only does such a framework render high-resolution videos, but it also is an order of magnitude more computationally efficient. We introduce a motion generator that discovers the desired trajectory, in which content and motion are disentangled. With such a representation, our framework allows for a broad range of applications, including content and motion manipulation. Furthermore, we introduce a new task, which we call cross-domain video synthesis, in which the image and motion generators are trained on disjoint datasets belonging to different domains. This allows for generating moving objects for which the desired video data is not available. Extensive experiments on various datasets demonstrate the advantages of our methods over existing video generation techniques. Code will be released at https://github.com/snap-research/MoCoGAN-HD.",
    "One-sentence Summary": "Reuse a pre-trained image generator for high-resolution video synthesis",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "snap-research/MoCoGAN-HD",
    "Data": "FFHQ, FaceForensics, UCF101, VoxCeleb1"
  },
  {
    "title": "Undistillable: Making A Nasty Teacher That CANNOT teach students",
    "url": "/forum?id=0zvfm-nZqQs",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "knowledge distillation, avoid knowledge leaking",
    "Abstract": "Knowledge Distillation (KD) is a widely used technique to transfer knowledge from pre-trained teacher models to  (usually more lightweight) student models. However, in certain situations, this technique is more of a curse than a blessing. For instance, KD poses a potential risk of exposing intellectual properties (IPs): even if a trained machine learning model is released in ``black boxes'' (e.g., as executable software or APIs without open-sourcing code), it can still be replicated by KD through imitating input-output behaviors. To prevent this unwanted effect of KD, this paper introduces and investigates a concept called Nasty Teacher: a specially trained teacher network that yields nearly the same performance as a normal one, but would significantly degrade the performance of student models learned by imitating it. We propose a simple yet effective algorithm to build the nasty teacher, called self-undermining knowledge distillation. Specifically, we aim to maximize the difference between the output of the nasty teacher and a normal pre-trained network. Extensive experiments on several datasets demonstrate that our method is effective on both standard KD and data-free KD, providing the desirable KD-immunity to model owners for the first time. We hope our preliminary study can draw more awareness and interest in this new practical problem of both social and legal importance. Our codes and pre-trained models can be found at: \\urlhttps://github.com/VITA\u2212Group/Nasty\u2212Teacher.",
    "One-sentence Summary": "We propose the Nasty Teacher, a defensive approach to prevent unauthorized cloning from a teacher model through knowledge distillation.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "VITA-Group/Nasty-Teacher"
  },
  {
    "title": "Support-set bottlenecks for video-text representation learning",
    "url": "/forum?id=EqoXe2zmhrh",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "video representation learning, multi-modal learning, video-text learning, contrastive learning",
    "Abstract": "The dominant paradigm for learning video-text representations \u2013 noise contrastive learning \u2013 increases the similarity of the representations of pairs of samples that are known to be related, such as text and video from the same sample, and pushes away the representations of all other pairs. We posit that this last behaviour is too strict, enforcing dissimilar representations even for samples that are semantically-related \u2013 for example, visually similar videos or ones that share the same depicted action. In this paper, we propose a novel method that alleviates this by leveraging a generative model to naturally push these related samples together: each sample\u2019s caption must be reconstructed as a weighted combination of a support set of visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. Our proposed method outperforms others by a large margin on MSR-VTT, VATEX, ActivityNet, and MSVD for video-to-text and text-to-video retrieval.",
    "One-sentence Summary": "We use a generative objective to improve the instance discrimination limitations of contrastive learning to set new state-of-the-art results in text-to-video retrieval",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "HowTo100M, MSR-VTT, VATEX"
  },
  {
    "title": "Grounded Language Learning Fast and Slow",
    "url": "/forum?id=wpSWuz_hyqA",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "language, cognition, fast-mapping, grounding, word-learning, memory, meta-learning",
    "Abstract": "Recent work has shown that large text-based neural language models acquire a surprising propensity for one-shot learning. Here, we show that an agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional RL algorithms. After a single introduction to a novel object via visual perception and language (\"This is a dax\"), the agent can manipulate the object as instructed (\"Put the dax on the bed\"), combining short-term, within-episode knowledge of the nonsense word with long-term lexical and motor knowledge. We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for artificial agents.",
    "One-sentence Summary": "A language-learning agent with dual-coding external memory meta-learns to combine fast-mapped and semantic lexical knowledge to execute instructions in one-shot..",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "deepmind/lab",
    "Data": "ShapeNet"
  },
  {
    "title": "GAN \"Steerability\" without optimization",
    "url": "/forum?id=zDy_nQCXiIj",
    "date": "28 Sept 2020 (modified: 10 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Generative Adversarial Network, semantic directions in latent space, nonlinear walk",
    "Abstract": "Recent research has shown remarkable success in revealing \"steering\" directions in the latent spaces of pre-trained GANs. These directions correspond to semantically meaningful image transformations (e.g., shift, zoom, color manipulations), and have the same interpretable effect across all categories that the GAN can generate. Some methods focus on user-specified transformations, while others discover transformations in an unsupervised manner. However, all existing techniques rely on an optimization procedure to expose those directions, and offer no control over the degree of allowed interaction between different transformations. In this paper, we show that \"steering\" trajectories can be computed in closed form directly from the generator's weights without any form of training or optimization. This applies to user-prescribed geometric transformations, as well as to unsupervised discovery of more complex effects. Our approach allows determining both linear and nonlinear trajectories, and has many advantages over previous methods. In particular, we can control whether one transformation is allowed to come on the expense of another (e.g., zoom-in with or without allowing translation to keep the object centered). Moreover, we can determine the natural end-point of the trajectory, which corresponds to the largest extent to which a transformation can be applied without incurring degradation. Finally, we show how transferring attributes between images can be achieved without optimization, even across different categories.",
    "One-sentence Summary": "Extracting linear & nonlinear semantic directions in GAN latent space without any required optimization",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Noise against noise: stochastic label noise helps combat inherent label noise",
    "url": "/forum?id=80FMcTSZ6J0",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Noisy Labels, Robust Learning, SGD noise, Regularization",
    "Abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect, previously studied in optimization by analyzing the dynamics of parameter updates. In this paper, we are interested in learning with noisy labels, where we have a collection of samples with potential mislabeling. We show that a previously rarely discussed SGD noise, induced by stochastic label noise (SLN), mitigates the effects of inherent label noise. In contrast, the common SGD noise directly applied to model parameters does not. We formalize the differences and connections of SGD noise variants, showing that SLN induces SGD noise dependent on the sharpness of output landscape and the confidence of output probability, which may help escape from sharp minima and prevent overconfidence. SLN not only improves generalization in its simplest form but also boosts popular robust training methods, including sample selection and label correction. Specifically, we present an enhanced algorithm by applying SLN to label correction. Our code is released.",
    "One-sentence Summary": "SGD noise induced by stochastic label noise helps escape sharp minima and prevents overconfidence, hence can mitigate the effects of inherent label noise and improve generalization.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "Clothing1M"
  },
  {
    "title": "VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models",
    "url": "/forum?id=5m3SEczOV8L",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Energy-based Models, Variational Auto-encoder, MCMC",
    "Abstract": "Energy-based models (EBMs) have recently been successful in representing complex distributions of small images. However, sampling from them requires expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate samples quickly and are equipped with a latent space that enables fast traversal of the data manifold. However, VAEs tend to assign high probability density to regions in data space outside the actual data distribution and often fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic composition of a VAE and an EBM that offers the best of both worlds. VAEBM captures the overall mode structure of the data distribution using a state-of-the-art VAE and it relies on its EBM component to explicitly exclude non-data-like regions from the model and refine the image samples. Moreover, the VAE component in VAEBM allows us to speed up MCMC updates by reparameterizing them in the VAE's latent space. Our experimental results show that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on several benchmark image datasets by a large margin. It can generate high-quality images as large as 256\u00d7256 pixels with short MCMC chains. We also demonstrate that VAEBM provides complete mode coverage and performs well in out-of-distribution detection.",
    "One-sentence Summary": "We introduce an energy-based generative model where the data distribution is defined jointly by a VAE and an energy network.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "NVlabs/VAEBM",
    "Data": "CIFAR-10, CelebA, CelebA-HQ, LSUN, Stacked MNIST"
  },
  {
    "title": "Graph-Based Continual Learning",
    "url": "/forum?id=HHSEKOnPvaO",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Abstract": "Despite significant advances, continual learning models still suffer from catastrophic forgetting when exposed to incrementally available data from non-stationary distributions. Rehearsal approaches alleviate the problem by maintaining and replaying a small episodic memory of previous samples, often implemented as an array of independent memory slots. In this work, we propose to augment such an array with a learnable random graph that captures pairwise similarities between its samples, and use it not only to learn new tasks but also to guard against forgetting. Empirical results on several benchmark datasets show that our model consistently outperforms recently proposed baselines for task-free continual learning.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CIFAR-10, MNIST, Permuted MNIST, SVHN"
  },
  {
    "title": "Sparse Quantized Spectral Clustering",
    "url": "/forum?id=pBqLS-7KYAF",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Eigenspectrum, high-dimensional statistic, random matrix theory, spectral clustering",
    "Abstract": "Given a large data matrix, sparsifying, quantizing, and/or performing other entry-wise nonlinear operations can have numerous benefits, ranging from speeding up iterative algorithms for core numerical linear algebra problems to providing nonlinear filters to design state-of-the-art neural network models. Here, we exploit tools from random matrix theory to make precise statements about how the eigenspectrum of a matrix changes under such nonlinear transformations. In particular, we show that very little change occurs in the informative eigenstructure, even under drastic sparsification/quantization, and consequently that very little downstream performance loss occurs when working with very aggressively sparsified or quantized spectral clustering problems.\n        We illustrate how these results depend on the nonlinearity, we characterize a phase transition beyond which spectral clustering becomes possible, and we show when such nonlinear transformations can introduce spurious non-informative eigenvectors.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "MNIST"
  },
  {
    "title": "LambdaNetworks: Modeling long-range Interactions without Attention",
    "url": "/forum?id=xTJEN-ggl1b",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "deep learning, neural networks, attention, transformer, vision, image classification",
    "Abstract": "We present lambda layers -- an alternative framework to self-attention -- for capturing long-range interactions between an input and structured contextual information (e.g. a pixel surrounded by other pixels). Lambda layers capture such interactions by transforming available contexts into linear functions, termed lambdas, and applying these linear functions to each input separately. Similar to linear attention, lambda layers bypass expensive attention maps, but in contrast, they model both content and position-based interactions which enables their application to large structured inputs such as images. The resulting neural network architectures, LambdaNetworks, significantly outperform their convolutional and attentional counterparts on ImageNet classification, COCO object detection and instance segmentation, while being more computationally efficient. Additionally, we design LambdaResNets, a family of hybrid architectures across different scales, that considerably improves the speed-accuracy tradeoff of image classification models. LambdaResNets reach excellent accuracies on ImageNet while being 3.2 - 4.4x faster than the popular EfficientNets on modern machine learning accelerators. In large-scale semi-supervised training with an additional 130M pseudo-labeled images, LambdaResNets achieve up to 86.7% ImageNet accuracy while being 9.5x faster than EfficientNet NoisyStudent and 9x faster than a Vision Transformer with comparable accuracies.",
    "One-sentence Summary": "Scalable framework for capturing long-range interactions between input and structured contextual information, which leads to strong improvements in vision tasks.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "6 community implementations",
    "Data": "COCO, ImageNet"
  },
  {
    "title": "Contrastive Divergence Learning is a Time Reversal Adversarial Game",
    "url": "/forum?id=MLSvqIHRidA",
    "date": "28 Sept 2020 (modified: 15 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Unsupervised learning, energy based model, adversarial learning, contrastive divergence, noise contrastive estimation",
    "Abstract": "Contrastive divergence (CD) learning is a classical method for fitting unnormalized statistical models to data samples. Despite its wide-spread use, the convergence properties of this algorithm are still not well understood. The main source of difficulty is an unjustified approximation which has been used to derive the gradient of the loss. In this paper, we present an alternative derivation of CD that does not require any approximation and sheds new light on the objective that is actually being optimized by the algorithm. Specifically, we show that CD is an adversarial learning procedure, where a discriminator attempts to classify whether a Markov chain generated from the model has been time-reversed. Thus, although predating generative adversarial networks (GANs) by more than a decade, CD is, in fact, closely related to these techniques. Our derivation settles well with previous observations, which have concluded that CD's update steps cannot be expressed as the gradients of any fixed objective function. In addition, as a byproduct, our derivation reveals a simple correction that can be used as an alternative to Metropolis-Hastings rejection, which is required when the underlying Markov chain is inexact (e.g., when using Langevin dynamics with a large step).",
    "One-sentence Summary": "We present an alternative derivation of the classical Contrastive divergence method, which reveals that it is in fact an adversarial learning procedure.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Quantifying Differences in Reward Functions",
    "url": "/forum?id=LwEQnp6CYev",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "rl, irl, reward learning, distance, benchmarks",
    "Abstract": "For many tasks, the reward function is inaccessible to introspection or too complex to be specified procedurally, and must instead be learned from user data. Prior work has evaluated learned reward functions by evaluating policies optimized for the learned reward. However, this method cannot distinguish between the learned reward function failing to reflect user preferences and the policy optimization process failing to optimize the learned reward. Moreover, this method can only tell us about behavior in the evaluation environment, but the reward may incentivize very different behavior in even a slightly different deployment environment. To address these problems, we introduce the Equivalent-Policy Invariant Comparison (EPIC) distance to quantify the difference between two reward functions directly, without a policy optimization step. We prove EPIC is invariant on an equivalence class of reward functions that always induce the same optimal policy. Furthermore, we find EPIC can be efficiently approximated and is more robust than baselines to the choice of coverage distribution. Finally, we show that EPIC distance bounds the regret of optimal policies even under different transition dynamics, and we confirm empirically that it predicts policy training success. Our source code is available at https://github.com/HumanCompatibleAI/evaluating-rewards.",
    "One-sentence Summary": "A theoretically principled distance measure on reward functions that is quick to compute and predicts policy training performance.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "HumanCompatibleAI/evaluating-rewards"
  },
  {
    "title": "Long-tail learning via logit adjustment",
    "url": "/forum?id=37nvvqkCo5",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "long-tail learning, class imbalance",
    "Abstract": "Real-world classification problems typically exhibit an imbalanced or long-tailed label distribution, wherein many labels have only a few associated samples. This poses a challenge for generalisation on such labels, and also  makes naive learning biased towards dominant labels. In this paper,  we present a statistical framework that unifies and generalises several recent proposals to cope with these challenges. Our framework revisits the classic idea of logit adjustment based on the label frequencies, which encourages a large relative margin between logits of rare positive versus dominant negative labels. This yields two techniques  for long-tail learning, where such adjustment is either applied post-hoc to a trained model, or enforced in the loss during training. These techniques are statistically grounded, and practically effective on four real-world datasets with long-tailed label distributions.",
    "One-sentence Summary": "Adjusting classifier logits based on class priors, either post-hoc or during training, can improve performance on rare classes.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "google-research/google-research +  1 community implementation",
    "Data": "ImageNet, ImageNet-LT"
  },
  {
    "title": "Locally Free Weight Sharing for Network Width Search",
    "url": "/forum?id=S0UdquAnr9k",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Abstract": "Searching for network width is an effective way to slim deep neural networks with hardware budgets. With this aim, a one-shot supernet is usually leveraged as a performance evaluator to rank the performance \\wrt~different width. Nevertheless, current methods mainly follow a manually fixed weight sharing pattern, which is limited to distinguish the performance gap of different width. In this paper, to better evaluate each width, we propose a locally free weight sharing strategy (CafeNet) accordingly. In CafeNet, weights are more freely shared, and each width is jointly indicated by its base channels and free channels, where free channels are supposed to locate freely in a local zone to better represent each width. Besides, we propose to further reduce the search space by leveraging our introduced FLOPs-sensitive bins. As a result, our CafeNet can be trained stochastically and get optimized within a min-min strategy. Extensive experiments on ImageNet, CIFAR-10, CelebA and MS COCO dataset have verified our superiority comparing to other state-of-the-art baselines. For example, our method can further boost the benchmark NAS network EfficientNet-B0 by 0.41\\% via searching its width more delicately.",
    "One-sentence Summary": "One-shot locally free weight sharing supernet for searching optimal network width",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "CelebA, ImageNet"
  },
  {
    "title": "Mutual Information State Intrinsic Control",
    "url": "/forum?id=OthEq8I5v1",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Intrinsically Motivated Reinforcement Learning, Intrinsic Reward, Intrinsic Motivation, Deep Reinforcement Learning, Reinforcement Learning",
    "Abstract": "Reinforcement learning has been shown to be highly successful at many challenging tasks. However, success heavily relies on well-shaped rewards. Intrinsically motivated RL attempts to remove this constraint by defining an intrinsic reward function. Motivated by the self-consciousness concept in psychology, we make a natural assumption that the agent knows what constitutes itself, and propose a new intrinsic objective that encourages the agent to have maximum control on the environment. We mathematically formalize this reward as the mutual information between the agent state and the surrounding state under the current agent policy. With this new intrinsic motivation, we are able to outperform previous methods, including being able to complete the pick-and-place task for the first time without using any task reward. A video showing experimental results is available at https://youtu.be/AUCwc9RThpk.",
    "One-sentence Summary": "Motivated by the self-consciousness concept in psychology, we propose a new intrinsic objective that encourages the agent to have maximum control on the environment.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "ruizhaogit/music +  1 community implementation"
  },
  {
    "title": "Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows",
    "url": "/forum?id=WiGQBFuVRv",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "time series, normalizing flows, attention, probabilistic multivariate forecasting",
    "Abstract": "Time series forecasting is often fundamental to scientific and engineering problems and enables decision making. With ever increasing data set sizes, a trivial solution to scale up predictions is to assume independence between interacting time series. However, modeling statistical dependencies can improve accuracy and enable analysis of interaction effects. Deep learning methods are well suited for this problem, but multi-variate models often assume a simple parametric distribution and do not scale to high dimensions. In this work we model the multi-variate temporal dynamics of time series via an autoregressive deep learning model, where the data distribution  is represented by a conditioned normalizing flow. This combination retains the power of autoregressive models, such as good performance in extrapolation into the future, with the flexibility of flows as a general purpose high-dimensional distribution model, while remaining computationally tractable. We show that it improves over the state-of-the-art for standard metrics on many real-world data sets with several thousand interacting time-series.",
    "One-sentence Summary": "SOTA Multivariate probabilistic time series forecasting using RNNs or Attention to model the dynamics and normalizing flows for the emission model.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "zalandoresearch/pytorch-ts"
  },
  {
    "title": "Information Laundering for Model Privacy",
    "url": "/forum?id=dyaIRud1zXg",
    "date": "28 Sept 2020 (modified: 24 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Adversarial Attack, Machine Learning, Model privacy, Privacy-utility tradeoff, Security",
    "Abstract": "In this work, we propose information laundering, a novel framework for enhancing model privacy. Unlike data privacy that concerns the protection of raw data information, model privacy aims to protect an already-learned model that is to be deployed for public use. The private model can be obtained from general learning methods, and its deployment means that it will return a deterministic or random response for a given input query. An information-laundered model consists of probabilistic components that deliberately maneuver the intended input and output for queries of the model, so the model's adversarial acquisition is less likely. Under the proposed framework, we develop an information-theoretic principle to quantify the fundamental tradeoffs between model utility and privacy leakage and derive the optimal design.",
    "One-sentence Summary": "We propose information laundering, a novel framework for enhancing model privacy.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers",
    "url": "/forum?id=v9c7hr9ADKx",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Multi-agent Reinforcement Learning, Transfer Learning",
    "Abstract": "Recent advances in multi-agent reinforcement learning have been largely limited in training one model from scratch for every new task. The limitation is due to the restricted model architecture related to fixed input and output dimensions. This hinders the experience accumulation and transfer of the learned agent over tasks with diverse levels of difficulty (e.g. 3 vs 3 or 5 vs 6 multi-agent games).  In this paper, we make the first attempt to explore a universal multi-agent reinforcement learning pipeline, designing one single architecture to fit tasks with the requirement of different observation and action configurations. Unlike previous RNN-based models, we utilize a transformer-based model to generate a flexible policy by decoupling the policy distribution from the intertwined input observation with an importance weight measured by the merits of the self-attention mechanism. Compared to a standard transformer block, the proposed model, named as Universal Policy Decoupling Transformer (UPDeT), further relaxes the action restriction and makes the multi-agent task's decision process more explainable. UPDeT is general enough to be plugged into any multi-agent reinforcement learning pipeline and equip them with strong generalization abilities that enables the handling of multiple tasks at a time. Extensive experiments on large-scale SMAC multi-agent competitive games demonstrate that the proposed UPDeT-based multi-agent reinforcement learning achieves significant results relative to state-of-the-art approaches, demonstrating advantageous transfer capability in terms of both performance and training speed (10 times faster).",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "SMAC"
  },
  {
    "title": "Correcting experience replay for multi-agent communication",
    "url": "/forum?id=xvxPuCkCNPO",
    "date": "28 Sept 2020 (modified: 28 Feb 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "multi-agent reinforcement learning, experience replay, communication, relabelling",
    "Abstract": "We consider the problem of learning to communicate using multi-agent reinforcement learning (MARL). A common approach is to learn off-policy, using data sampled from a replay buffer. However, messages received in the past may not accurately reflect the current communication policy of each agent, and this complicates learning. We therefore introduce a 'communication correction' which accounts for the non-stationarity of observed communication induced by multi-agent learning. It works by relabelling the received message to make it likely under the communicator's current policy, and thus be a better reflection of the receiver's current environment. To account for cases in which agents are both senders and receivers, we introduce an ordered relabelling scheme. Our correction is computationally efficient and can be integrated with a range of off-policy algorithms. We find in our experiments that it substantially improves the ability of communicating MARL systems to learn across a variety of cooperative and competitive tasks.",
    "One-sentence Summary": "We improve multi-agent learning by relabelling past experience to better reflect current communication policies",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Improving Adversarial Robustness via Channel-wise Activation Suppressing",
    "url": "/forum?id=zQTezqCCtNx",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Adversarial robustness, channel suppressing, activation strategy.",
    "Abstract": "The study of adversarial examples and their activations have attracted significant attention for secure and robust learning with deep neural networks (DNNs).  Different from existing works, in this paper, we highlight two new characteristics of adversarial examples from the channel-wise activation perspective:  1) the activation magnitudes of adversarial examples are higher than that of natural examples; and 2) the channels are activated more uniformly by adversarial examples than natural examples. We find that, while the state-of-the-art defense adversarial training has addressed the first issue of high activation magnitude via training on adversarial examples, the second issue of uniform activation remains.  This motivates us to suppress redundant activations from being activated by adversarial perturbations during the adversarial training process, via a Channel-wise Activation Suppressing (CAS) training strategy.  We show that CAS can train a model that inherently suppresses adversarial activations, and can be easily applied to existing defense methods to further improve their robustness. Our work provides a simplebut generic training strategy for robustifying the intermediate layer activations of DNNs.",
    "One-sentence Summary": "Training with Channel-wise Activation Suppressing (CAS) can help imrove the robustness of adversarial training.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "bymavis/CAS_ICLR2021",
    "Data": "CIFAR-10, SVHN"
  },
  {
    "title": "Long-tailed Recognition by Routing Diverse Distribution-Aware Experts",
    "url": "/forum?id=D9I3drBz4UC",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Long-tailed Recognition, Bias-variance Decomposition",
    "Abstract": "Natural data are often long-tail distributed over semantic classes.  Existing recognition methods tackle this imbalanced classification by placing more emphasis on the tail data, through class re-balancing/re-weighting or ensembling over different data groups, resulting in increased tail accuracies but reduced head accuracies.\n        We take a dynamic view of the training data and provide a principled model bias and variance analysis as the training data fluctuates: Existing long-tail classifiers invariably increase the model variance and the head-tail model bias gap remains large, due to more and larger confusion with hard negatives for the tail.\n        We propose a new long-tailed classifier called RoutIng Diverse Experts (RIDE).  It reduces the model variance with multiple experts, reduces the model bias with a distribution-aware diversity loss, reduces the computational cost with a dynamic expert routing module.  RIDE outperforms the state-of-the-art by 5% to 7% on CIFAR100-LT, ImageNet-LT and iNaturalist 2018 benchmarks.  It is also a universal framework that is applicable to various backbone networks, long-tailed algorithms and training mechanisms for consistent performance gains. Our code is available at: https://github.com/frank-xwang/RIDE-LongTailRecognition.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "frank-xwang/RIDE-LongTailRecognition +  1 community implementation",
    "Data": "CIFAR-100, ImageNet, ImageNet-LT, iNaturalist"
  },
  {
    "title": "Generalization in data-driven models of primary visual cortex",
    "url": "/forum?id=Tp7kI90Htd",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "neuroscience, cognitive science, multitask learning, transfer learning, representation learning, network architecture, computational biology, visual perception",
    "Abstract": "Deep neural networks (DNN) have set new standards at predicting responses of neural populations to visual input.  Most such DNNs consist of a convolutional network (core) shared across all neurons which learns a representation of neural computation in visual cortex and a neuron-specific readout that linearly combines the relevant features in this representation. The goal of this paper is to test whether such a representation is indeed generally characteristic for visual cortex, i.e. generalizes between animals of a species, and what factors contribute to obtaining such a generalizing core. To push all non-linear computations into the core where the generalizing cortical features should be learned, we devise a novel readout that reduces the number of parameters per neuron in the readout by up to two orders of magnitude compared to the previous state-of-the-art. It does so by taking advantage of retinotopy and learns a Gaussian distribution over the neuron\u2019s receptive field position.  With this new readout we train our network on neural responses from mouse primary visual cortex (V1) and obtain a gain in performance of 7% compared to the previous state-of-the-art network.  We then investigate whether the convolutional core indeed captures general cortical features by using the core in transfer learning to a different animal.  When transferring a core trained on thousands of neurons from various animals and scans we exceed the performance of training directly on that animal by 12%, and outperform a commonly used VGG16 core pre-trained on imagenet by 33%. In addition, transfer learning with our data-driven core is more data-efficient than direct training, achieving the same performance with only 40% of the data. Our model with its novel readout thus sets a new state-of-the-art for neural response prediction in mouse visual cortex from natural images, generalizes between animals, and captures better characteristic cortical features than current task-driven pre-training approaches such as VGG16.",
    "One-sentence Summary": "We introduce a novel network architecture which sets a new state of the art at predicting neural responses to visual input and successfully learns generalizing features of mouse visual cortex (V1).",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Data": "ImageNet"
  },
  {
    "title": "Sequential Density Ratio Estimation for Simultaneous Optimization of Speed and Accuracy",
    "url": "/forum?id=Rhsu5qD36cL",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Sequential probability ratio test, Early classification, Density ratio estimation",
    "Abstract": "Classifying sequential data as early and as accurately as possible is a challenging yet critical problem, especially when a sampling cost is high. One algorithm that achieves this goal is the sequential probability ratio test (SPRT), which is known as Bayes-optimal: it can keep the expected number of data samples as small as possible, given the desired error upper-bound. However, the original SPRT makes two critical assumptions that limit its application in real-world scenarios: (i) samples are independently and identically distributed, and (ii) the likelihood of the data being derived from each class can be calculated precisely. Here, we propose the SPRT-TANDEM, a deep neural network-based SPRT algorithm that overcomes the above two obstacles. The SPRT-TANDEM sequentially estimates the log-likelihood ratio of two alternative hypotheses by leveraging a novel Loss function for Log-Likelihood Ratio estimation (LLLR) while allowing correlations up to N(\u2208N)  preceding samples. In tests on one original and two public video databases, Nosaic MNIST, UCF101, and SiW, the SPRT-TANDEM achieves statistically significantly better classification accuracy than other baseline classifiers, with a smaller number of data samples. The code and Nosaic MNIST are publicly available at https://github.com/TaikiMiyagawa/SPRT-TANDEM.",
    "One-sentence Summary": "With a novel sequential density estimation algorithm, we relax critical assumptions of the classical Sequential Probability Ratio Test to be applicable in various real-world scenarios.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "TaikiMiyagawa/SPRT-TANDEM +  1 community implementation",
    "Data": "Moving MNIST, UCF101"
  },
  {
    "title": "Uncertainty Sets for Image Classifiers using Conformal Prediction",
    "url": "/forum?id=eNdiU_DbM9",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "classification, predictive uncertainty, conformal inference, computer vision, imagenet",
    "Abstract": "Convolutional image classifiers can achieve high predictive accuracy, but quanti\u0002fying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network\u2019s probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset. Our method modifies an existing conformal prediction algorithm to give more sta\u0002ble predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller than a stand-alone Platt scaling baseline.",
    "One-sentence Summary": "We quantify uncertainty for image classifiers using prediction sets, with detailed experiments on Imagenet Val and V2.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "aangelopoulos/conformal-classification +  1 community implementation"
  },
  {
    "title": "Graph Convolution with Low-rank Learnable Local Filters",
    "url": "/forum?id=9OHFhefeB86",
    "date": "28 Sept 2020 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Abstract": "Geometric variations like rotation, scaling, and viewpoint changes pose a significant challenge to visual understanding. One common solution is to directly model certain intrinsic structures, e.g., using landmarks. However, it then becomes non-trivial to build effective deep models, especially when the underlying non-Euclidean grid is irregular and coarse. Recent deep models using graph convolutions provide an appropriate framework to handle such non-Euclidean data, but many of them, particularly those based on global graph Laplacians, lack expressiveness to capture local features required for representation of signals lying on the non-Euclidean grid. The current paper introduces a new type of graph convolution with learnable low-rank local filters, which is provably more expressive than previous spectral graph convolution methods. The model also provides a unified framework for both spectral and spatial graph convolutions. To improve model robustness, regularization by local graph Laplacians is introduced. The representation stability against input graph data perturbation is theoretically proved, making use of the graph filter locality and the local graph regularization. Experiments on spherical mesh data, real-world facial expression recognition/skeleton-based action recognition data, and data with simulated graph noise show the empirical advantage of the proposed model.",
    "One-sentence Summary": "Graph convolution model for landmark data with local graph regularization and provable graph signal representation expressiveness and stability.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
    "Code": "ZichenMiao/GNN-with-Low-rank-Learnable-Local-Filters +  1 community implementation",
    "Data": "CK+, Kinetics"
  },
  {
    "title": "Mind the Pad -- CNNs Can Develop Blind Spots",
    "url": "/forum?id=m1CD7tPubNy",
    "date": "28 Sept 2020 (modified: 18 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "CNN, convolution, spatial bias, blind spots, foveation, padding, exposition, debugging, visualization",
    "Abstract": "We show how feature maps in convolutional networks are susceptible to spatial bias. Due to a combination of architectural choices, the activation at certain locations is systematically elevated or weakened. The major source of this bias is the padding mechanism. Depending on several aspects of convolution arithmetic, this mechanism can apply the padding unevenly, leading to asymmetries in the learned weights. We demonstrate how such bias can be detrimental to certain tasks such as small object detection: the activation is suppressed if the stimulus lies in the impacted area, leading to blind spots and misdetection. We explore alternative padding methods and propose solutions for analyzing and mitigating spatial bias.",
    "One-sentence Summary": "The padding mechanism in CNNs can induce harmful spatial bias in the learned weights and in the feature maps, which can be mitigated with careful architectural choices.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Stabilized Medical Image Attacks",
    "url": "/forum?id=QfTXQiGYudJ",
    "date": "28 Sept 2020 (modified: 21 Mar 2021)",
    "acceptance_type": "ICLR 2021 Spotlight",
    "Keywords": "Healthcare, Biometrics",
    "Abstract": "Convolutional Neural Networks (CNNs) have advanced existing medical systems for automatic disease diagnosis. However, a threat to these systems arises that adversarial attacks make CNNs vulnerable. Inaccurate diagnosis results make a negative influence on human healthcare. There is a need to investigate potential adversarial attacks to robustify deep medical diagnosis systems. On the other side, there are several modalities of medical images (e.g., CT, fundus, and endoscopic image) of which each type is significantly different from others. It is more challenging to generate adversarial perturbations for different types of medical images. In this paper, we propose an image-based medical adversarial attack method to consistently produce adversarial perturbations on medical images. The objective function of our method consists of a loss deviation term and a loss stabilization term. The loss deviation term increases the divergence between the CNN prediction of an adversarial example and its ground truth label. Meanwhile, the loss stabilization term ensures similar CNN predictions of this example and its smoothed input. From the perspective of the whole iterations for perturbation generation, the proposed loss stabilization term exhaustively searches the perturbation space to smooth the single spot for local optimum escape. We further analyze the KL-divergence of the proposed loss function and find that the loss stabilization term makes the perturbations updated towards a fixed objective spot while deviating from the ground truth. This stabilization ensures the proposed medical attack effective for different types of medical images while producing perturbations in small variance. Experiments on several medical image analysis benchmarks including the recent COVID-19 dataset show the stability of the proposed method.",
    "One-sentence Summary": "We propose a stabilized adversarial attack method for medical image analysis.",
    "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics"
  },
  {
    "title": "Domino: Discovering Systematic Errors with Cross-Modal Embeddings",
    "url": "/forum?id=FPCMqjI0jXN",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "robustness, subgroup analysis, error analysis, multimodal, slice discovery",
    "Abstract": "Machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices) of data. Identifying underperforming slices is particularly challenging when working with high-dimensional inputs (e.g. images, audio), where important slices are often unlabeled. In order to address this issue, recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices on which a model performs poorly. To be useful to a practitioner, these methods must identify slices that are both underperforming and coherent (i.e. united by a human-understandable concept). However, no quantitative evaluation framework currently exists for rigorously assessing SDMs with respect to these criteria. Additionally, prior qualitative evaluations have shown that SDMs often identify slices that are incoherent. In this work, we address these challenges by first designing a principled evaluation framework that enables a quantitative comparison of SDMs across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data).\n        Then, motivated by the recent development of powerful cross-modal representation learning approaches, we present Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. We find that Domino accurately identifies 36% of the 1,235 slices in our framework -- a 12 percentage point improvement over prior methods. Further, Domino is the first SDM that can provide natural language descriptions of identified slices, correctly generating the exact name of the slice in 35% of settings."
  },
  {
    "title": "Natural Language Descriptions of Deep Visual Features",
    "url": "/forum?id=NudBMY-tzDr",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Abstract": "Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs. In computer vision, techniques exist for identifying neurons that respond to individual concept categories like colors, textures, and object classes. But these techniques are limited in scope, labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron-level computation possible? We introduce a procedure (called MILAN, for mutual information-guided linguistic annotation of neurons) that automatically labels neurons with open-ended, compositional, natural language descriptions. Given a neuron, MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine-grained descriptions that capture categorical, relational, and logical structure in learned features. These descriptions obtain high agreement with human-generated feature descriptions across a diverse set of model architectures and tasks, and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First, we use MILAN for analysis, characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models. Second, we use MILAN for auditing, surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally, we use MILAN for editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels."
  },
  {
    "title": "Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization",
    "url": "/forum?id=tYRrOdSnVUy",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Domain Adaptation, Transfer Learning, Societal Considerations of Representation Learning, Model Watermark",
    "Abstract": "As Artificial Intelligence as a Service gains popularity, protecting well-trained models as intellectual property is becoming increasingly important. There are two common types of protection methods: ownership verification and usage authorization. In this paper, we propose Non-Transferable Learning (NTL), a novel approach that captures the exclusive data representation in the learned model and restricts the model generalization ability to certain domains. This approach provides effective solutions to both model verification and authorization. Specifically: 1) For ownership verification, watermarking techniques are commonly used but are often vulnerable to sophisticated watermark removal methods. By comparison, our NTL-based ownership verification provides robust resistance to state-of-the-art watermark removal methods, as shown in extensive experiments with 6 removal approaches over the digits, CIFAR10 & STL10, and VisDA datasets. 2) For usage authorization, prior solutions focus on authorizing specific users to access the model, but authorized users can still apply the model to any data without restriction. Our NTL-based authorization approach instead provides data-centric protection, which we call applicability authorization, by significantly degrading the performance of the model on unauthorized data. Its effectiveness is also shown through experiments on aforementioned datasets.",
    "One-sentence Summary": "We propose a novel Non-Transferable Learning (NTL) method to restrict the model generalization ability to certain domains for model ownership verification and applicability authorization."
  },
  {
    "title": "Neural Structured Prediction for Inductive Node Classification",
    "url": "/forum?id=YWNAX0caEjI",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Abstract": "This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines."
  },
  {
    "title": "A New Perspective on \"How Graph Neural Networks Go Beyond Weisfeiler-Lehman?\"",
    "url": "/forum?id=uxgg9o7bI_3",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Graph Neural Networks, Graph Isomorphism, Weisfeiler Lehman",
    "Abstract": "We propose a new perspective on designing powerful Graph Neural Networks (GNNs). In a nutshell, this enables a general solution to inject structural properties of graphs into a message-passing aggregation scheme of GNNs. As a theoretical basis, we develop a new hierarchy of local isomorphism on neighborhood subgraphs. Then, we theoretically characterize how message-passing GNNs can be designed to be more expressive than the Weisfeiler Lehman test. To elaborate this characterization, we propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive than the Weisfeiler Lehman test in distinguishing graph structures. We empirically verify the strength of our model on different graph learning tasks. It is shown that our model consistently improves the state-of-the-art methods on the benchmark tasks without sacrificing computational simplicity and efficiency."
  },
  {
    "title": "Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond",
    "url": "/forum?id=LdlwbBP2mlq",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Local SGD, Minibatch SGD, Shuffling, Without-replacement, Convex Optimization, Stochastic Optimization, Federated Learning, Large Scale Learning, Distributed Learning",
    "Abstract": "In distributed learning, local SGD (also known as federated averaging) and its simple baseline minibatch SGD are widely studied optimization methods. Most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. In contrast, we study shuffling-based variants: minibatch and local Random Reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. For smooth functions satisfying the Polyak-\u0141ojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. Moreover, we prove matching lower bounds showing that our convergence analysis is tight. Finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings.",
    "One-sentence Summary": "We provide tight upper and lower bounds on convergence rates of shuffling-based minibatch SGD and local SGD, and propose an algorithmic modification that improves convergence rates beyond our lower bounds."
  },
  {
    "title": "The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions",
    "url": "/forum?id=Z7Lk2cQEG8a",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Neural networks, global optimization, convex optimization, convex analysis",
    "Abstract": "We prove that finding all globally optimal two-layer ReLU neural networks can be performed by solving a convex optimization program with cone constraints. Our analysis is novel, characterizes all optimal solutions, and does not leverage duality-based analysis which was recently used to lift neural network training into convex spaces. Given the set of solutions of our convex optimization program, we show how to construct exactly the entire set of optimal neural networks. We provide a detailed characterization of this optimal set and its invariant transformations. As additional consequences of our convex perspective, (i) we establish that Clarke stationary points found by stochastic gradient descent correspond to the global optimum of a subsampled convex problem (ii) we provide a polynomial-time algorithm for checking if a neural network is a global minimum of the training loss (iii) we provide an explicit construction of a continuous path between any neural network and the global minimum of its sublevel set and (iv) characterize the minimal size of the hidden layer so that the neural network optimization landscape has no spurious valleys.\n        Overall, we provide a rich framework for studying the landscape of neural network training loss through convexity."
  },
  {
    "title": "Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics",
    "url": "/forum?id=RQLLzMCefQu",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Reinforcement Learning Theory, Invariant Representation, Rich Observation Reinforcement Learning, Exogenous Noise, Inverse Dynamics",
    "Abstract": "Many real-world applications of reinforcement learning (RL) require the agent to deal with high-dimensional observations such as those generated from a megapixel camera. Prior work has addressed such problems with representation learning, through which the agent can provably extract endogenous, latent state information from raw observations and subsequently plan efficiently. However, such approaches can fail in the presence of temporally correlated noise in the observations, a phenomenon that is common in practice. We initiate the formal study of latent state discovery in the presence of such exogenous noise sources by proposing a new model, the Exogenous Block MDP (EX-BMDP), for rich observation RL. We start by establishing several negative results, by highlighting failure cases of prior representation learning based approaches. Then, we introduce the Predictive Path Elimination (PPE) algorithm, that learns a generalization of inverse dynamics and is provably sample and computationally efficient in EX-BMDPs when the endogenous state dynamics are near deterministic. The sample complexity of PPE depends polynomially on the size of the latent endogenous state space while not directly depending on the size of the observation space, nor the exogenous state space. We provide experiments on challenging exploration problems which show that our approach works empirically."
  },
  {
    "title": "Bootstrapped Meta-Learning",
    "url": "/forum?id=b-ny3x071E5",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "meta-learning, meta-gradients, meta-reinforcement learning",
    "Abstract": "Meta-learning empowers artificial intelligence to increase its efficiency by learning how to learn. Unlocking this potential involves overcoming a challenging meta-optimisation problem. We propose an algorithm that tackles this problem by letting the meta-learner teach itself. The algorithm first bootstraps a target from the meta-learner, then optimises the meta-learner by minimising the distance to that target under a chosen (pseudo-)metric. Focusing on meta-learning with gradients, we establish conditions that guarantee performance improvements and show that metric can be used to control meta-optimisation. Meanwhile, the bootstrapping mechanism can extend the effective meta-learning horizon without requiring backpropagation through all updates. We achieve a new state-of-the art for model-free agents on the Atari ALE benchmark and demonstrate that it yields both performance and efficiency gains in multi-task meta-learning. Finally, we explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an epsilon-greedy Q-learning agent - without backpropagating through the update rule.",
    "One-sentence Summary": "We propose an algorithm for meta-learning with gradients that bootstraps the meta-learner from itself or another update rule."
  },
  {
    "title": "Coordination Among Neural Modules Through a Shared Global Workspace",
    "url": "/forum?id=XzTtHjgPDsT",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "slot based recurrent architectures, attention, transformers, latent bottleneck.",
    "Abstract": "Deep learning has seen a movement away from representing examples with a monolithic hidden state towards a richly structured state. For example, Transformers segment by position, and object-centric architectures decompose images into entities. In all these architectures, interactions between different elements are modeled via pairwise interactions: Transformers make use of self-attention to incorporate information from other positions and object-centric architectures make use of graph neural networks to model interactions among entities.  We consider how to improve on pairwise interactions in terms of global coordination and a coherent, integrated representation that can be used for downstream tasks. In cognitive science, a global workspace architecture has been proposed in which functionally  specialized  components share information through a common, bandwidth-limited communication channel. We explore the use of such a communication channel in the context of deep learning for modeling the structure of complex environments. The proposed method includes a shared workspace through which communication among different specialist modules takes place but due to limits on the communication bandwidth, specialist modules must compete for access. We show that capacity limitations have  a rational basis in that (1) they encourage specialization and compositionality and (2) they facilitate the synchronization of otherwise  independent specialists.",
    "One-sentence Summary": "communication among different specialist using a shared workspace allowing higher order interactions"
  },
  {
    "title": "Data-Efficient Graph Grammar Learning for Molecular Generation",
    "url": "/forum?id=l4IHywGq6a",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "molecular generation, graph grammar, data efficient generative model",
    "Abstract": "The problem of molecular generation has received significant attention recently. Existing methods are typically based on deep neural networks and require training on large datasets with tens of thousands of samples. In practice, however, the size of class-specific chemical datasets is usually limited (e.g., dozens of samples) due to labor-intensive experimentation and data collection. Another major challenge is to generate only physically synthesizable molecules. This is a non-trivial task for neural network-based generative models since the relevant chemical knowledge can only be extracted and generalized from the limited training data. In this work, we propose a data-efficient generative model that can be learned from datasets with orders of magnitude smaller sizes than common benchmarks. At the heart of this method is a learnable graph grammar that generates molecules from a sequence of production rules. Without any human assistance, these production rules are automatically constructed from training data. Furthermore, additional chemical knowledge can be incorporated into the model by further grammar optimization. Our learned graph grammar yields state-of-the-art results on generating high-quality molecules for three monomer datasets that contain only \u223c20 samples each. Our approach also achieves remarkable performance in a challenging polymer generation task with only 117 training samples and is competitive against existing methods using 81k data points."
  },
  {
    "title": "Poisoning and Backdooring Contrastive Learning",
    "url": "/forum?id=iC4UHbQ01Mp",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Contrastive Learning, Poisoning attack, Backdoor attack, CLIP",
    "Abstract": "Multimodal contrastive learning methods like CLIP train on noisy and uncurated training datasets. This is cheaper than labeling datasets manually, and even improves out-of-distribution robustness. We show that this practice makes backdoor and poisoning attacks a significant threat. By poisoning just 0.01% of a dataset (e.g., just 300 images of the 3 million-example Conceptual Captions dataset), we can cause the model to misclassify test images by overlaying a small patch. Targeted poisoning attacks, whereby the model misclassifies a particular test input  with an adversarially-desired label, are even easier requiring control of 0.0001% of the dataset (e.g., just three out of the 3 million images). Our attacks call into question whether training on noisy and uncurated Internet scrapes is desirable.",
    "One-sentence Summary": "We argue poisoning and backdooring attacks are a serious threat to multimodal contrastive classifiers, because they are explicitly designed to be trained on uncurated datasets from the Internet."
  },
  {
    "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path",
    "url": "/forum?id=w1UbdvWH_R3",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "neural collapse, deep learning theory, deep learning, inductive bias, equiangular tight frame, ETF, nearest class center, mean squared error loss, MSE loss, invariance, renormalization, gradient flow, dynamics, adversarial robustness",
    "Abstract": "The recently discovered Neural Collapse (NC) phenomenon occurs pervasively in today's deep net training paradigm of driving cross-entropy (CE) loss towards zero. During NC, last-layer features collapse to their class-means, both classifiers and class-means collapse to the same Simplex Equiangular Tight Frame, and classifier behavior collapses to the nearest-class-mean decision rule. Recent works demonstrated that deep nets trained with mean squared error (MSE) loss perform comparably to those trained with CE. As a preliminary, we empirically establish that NC emerges in such MSE-trained deep nets as well through experiments on three canonical networks and five benchmark datasets. We provide, in a Google Colab notebook, PyTorch code for reproducing MSE-NC and CE-NC: https://colab.research.google.com/github/neuralcollapse/neuralcollapse/blob/main/neuralcollapse.ipynb. The analytically-tractable MSE loss offers more mathematical opportunities than the hard-to-analyze CE loss, inspiring us to leverage MSE loss towards the theoretical investigation of NC. We develop three main contributions: (I) We show a new decomposition of the MSE loss into (A) terms directly interpretable through the lens of NC and which assume the last-layer classifier is exactly the least-squares classifier; and (B) a term capturing the deviation from this least-squares classifier. (II) We exhibit experiments on canonical datasets and networks demonstrating that term-(B) is negligible during training. This motivates us to introduce a new theoretical construct: the central path, where the linear classifier stays MSE-optimal for feature activations throughout the dynamics. (III) By studying renormalized gradient flow along the central path, we derive exact dynamics that predict NC.",
    "One-sentence Summary": "Neural Collapse occurs empirically on deep nets trained with MSE loss and studying this setting leads to insightful closed-form dynamics."
  },
  {
    "title": "Weighted Training for Cross-Task Learning",
    "url": "/forum?id=ltM1RMZntpu",
    "date": "28 Sept 2021 (modified: 01 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Cross-task learning, Natural language processing, Representation learning",
    "Abstract": "In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks. We show that TAWT is easy to implement, is computationally efficient, requires little hyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees. The effectiveness of TAWT is corroborated through extensive experiments with BERT on four sequence tagging tasks in natural language processing (NLP), including part-of-speech (PoS) tagging, chunking, predicate detection, and named entity recognition (NER). As a byproduct, the proposed representation-based task distance allows one to reason in a theoretically principled way about several critical aspects of cross-task learning, such as the choice of the source data and the impact of fine-tuning.",
    "One-sentence Summary": "We introduce a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks."
  },
  {
    "title": "iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data",
    "url": "/forum?id=wRODLDHaAiW",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "neuroscience, latent variable models, RNN, VAE, motor control, control theory, dynamical systems",
    "Abstract": "Understanding how neural dynamics give rise to behaviour is one of the most fundamental questions in systems neuroscience. To achieve this, a common approach is to record neural populations in behaving animals, and model these data as emanating from a latent dynamical system whose state trajectories can then be related back to behavioural observations via some form of decoding. As recordings are typically performed in localized circuits that form only a part of the wider implicated network, it is important to simultaneously learn the local dynamics and infer any unobserved external input that might drive them. Here, we introduce iLQR-VAE, a novel control-based approach to variational inference in nonlinear dynamical systems, capable of learning both latent dynamics, initial conditions, and ongoing external inputs. As in recent deep learning approaches, our method is based on an input-driven sequential variational autoencoder (VAE). The main novelty lies in the use of the powerful iterative linear quadratic regulator algorithm (iLQR) in the recognition model. Optimization of the standard evidence lower-bound requires differentiating through iLQR solutions, which is made possible by recent advances in differentiable control. Importantly, having the recognition model be implicitly defined by the generative model greatly reduces the number of free parameters and allows for flexible, high-quality inference. This makes it possible for instance to evaluate the model on a single long trial after training on smaller chunks. We demonstrate the effectiveness of iLQR-VAE on a range of synthetic systems, with autonomous as well as input-driven dynamics. We further apply it to neural and behavioural recordings in non-human primates performing two different reaching tasks, and show that iLQR-VAE yields high-quality kinematic reconstructions from the neural data.",
    "One-sentence Summary": "We develop a novel autoencoder that uses iLQR as an inference model and apply it to synthetic data as well as neural recordings from primate motor cortex."
  },
  {
    "title": "Extending the WILDS Benchmark for Unsupervised Adaptation",
    "url": "/forum?id=z7p2V6KROOV",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "distribution shifts, adaptation, unlabeled data",
    "Abstract": "Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data and can often be obtained from distributions beyond the source distribution as well. However, existing distribution shift benchmarks with unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). The update maintains consistency with the original WILDS benchmark by using identical labeled training, validation, and test sets, as well as identical evaluation metrics. We systematically benchmark state-of-the-art methods that use unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS is limited. To facilitate method development, we provide an open-source package that automates data loading and contains the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu.",
    "One-sentence Summary": "We introduce U-WILDS, which augments the WILDS distribution shift benchmark with realistic unlabeled data, and benchmark existing methods for unlabeled data on these in-the-wild distribution shifts."
  },
  {
    "title": "Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks",
    "url": "/forum?id=avgclFZ221l",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "out-of-distribution classification, symmetries, counterfactual invariances, geometric deep learning",
    "Abstract": "Generalizing from observed to new related environments (out-of-distribution) is central to the reliability of classifiers. However, most classifiers fail to predict label Y from input X when the change in environment is due a (stochastic) input transformation Tte\u2218X\u2032 not observed in training, as in training we observe Ttr\u2218X\u2032, where X\u2032 is a hidden variable. This work argues that when the transformations in train Ttr and test Tte are (arbitrary) symmetry transformations induced by a collection of known m equivalence relations, the task of finding a robust OOD classifier can be defined as finding the simplest causal model that defines a causal connection between the target labels and the symmetry transformations that are associated with label changes. We then propose a new learning paradigm, asymmetry learning, that identifies which symmetries the classifier must break in order to correctly predict Y in both train and test. Asymmetry learning performs a causal model search that, under certain identifiability conditions, finds classifiers that perform equally well in-distribution and out-of-distribution. Finally, we show how to learn counterfactually-invariant representations with asymmetry learning in two physics tasks.",
    "One-sentence Summary": "Counterfactual-invariant representations for symmetry transformations"
  },
  {
    "title": "Comparing Distributions by Measuring Differences that Affect Decision Making",
    "url": "/forum?id=KB5onONJIAU",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "probability divergence, two sample test, generative model",
    "Abstract": "Measuring the discrepancy between two probability distributions is a fundamental problem in machine learning and statistics. We propose a new class of discrepancies based on the optimal loss for a decision task -- two distributions are different if the optimal decision loss is higher on their mixture than on each individual distribution. By suitably choosing the decision task, this generalizes the Jensen-Shannon divergence and the maximum mean discrepancy family. We apply our approach to two-sample tests, and on various benchmarks, we achieve superior test power compared to competing methods. In addition, a modeler can directly specify their preferences when comparing distributions through the decision loss. We apply this property to understanding the effects of climate change on different social and economic activities, evaluating sample quality, and selecting features targeting different decision tasks."
  },
  {
    "title": "MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling",
    "url": "/forum?id=UseMOjWENv",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Audio Synthesis, Generative Model, Hierarchical, DDSP, Music, Audio, Structured Models",
    "Abstract": "Musical expression requires control of both what notes that are played, and how they are performed. Conventional audio synthesizers provide detailed expressive controls, but at the cost of realism. Black-box neural audio synthesis and concatenative samplers can produce realistic audio, but have few mechanisms for control. In this work, we introduce MIDI-DDSP a hierarchical model of musical instruments that enables both realistic neural audio synthesis and detailed user control. Starting from interpretable Differentiable Digital Signal Processing (DDSP) synthesis parameters, we infer musical notes and high-level properties of their expressive performance (such as timbre, vibrato, dynamics, and articulation). This creates a 3-level hierarchy (notes, performance, synthesis) that affords individuals the option to intervene at each level, or utilize trained priors (performance given notes, synthesis given performance) for creative assistance. Through quantitative experiments and listening tests, we demonstrate that this hierarchy can reconstruct high-fidelity audio, accurately predict performance attributes for a note sequence, independently manipulate the attributes of a given performance,  and as a complete system, generate realistic audio from a novel note sequence. By utilizing an interpretable hierarchy, with multiple levels of granularity, MIDI-DDSP opens the door to assistive tools to empower individuals across a diverse range of musical experience.",
    "One-sentence Summary": "Controlling musical performance and synthesis with a structured hierarchical generative model"
  },
  {
    "title": "Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling",
    "url": "/forum?id=N0n_QyQ5lBF",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Grammar Induction, Vision-Language Matching, Unsupervised Learning",
    "Abstract": "We introduce a new task, unsupervised vision-language (VL) grammar induction. Given an image-caption pair, the goal is to extract a shared hierarchical structure for both image and language simultaneously.  We argue that such structured output, grounded in both modalities, is a clear step towards the high-level understanding of multimodal information. Besides challenges existing in conventional visually grounded grammar induction tasks, VL grammar induction requires a model to capture contextual semantics and perform a fine-grained alignment. To address these challenges, we propose a novel method, CLIORA, which constructs a shared vision-language constituency tree structure with context-dependent semantics for all possible phrases in different levels of the tree. It computes a matching score between each constituent and image region, trained via contrastive learning.  It integrates two levels of fusion, namely at feature-level and at score-level, so as to allow fine-grained alignment. We introduce a new evaluation metric for VL grammar induction, CCRA, and show a 3.3% improvement over a strong baseline on Flickr30k Entities. We also evaluate our model via two derived tasks, i.e., language grammar induction and phrase grounding, and improve over the state-of-the-art for both.",
    "One-sentence Summary": "We introduce a new unsupervised vision-language grammar induction task to explore the multimodal information and induce a shared hierarchical structure for both image and language simultaneously."
  },
  {
    "title": "PiCO: Contrastive Label Disambiguation for Partial Label Learning",
    "url": "/forum?id=EhYjZy6e1gJ",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Partial Label Learning, Contrastive Learning, Prototype-based Disambiguation",
    "Abstract": "Partial label learning (PLL) is an important problem that allows each training example to be labeled with a coarse candidate set, which well suits many real-world data annotation scenarios with label ambiguity.  Despite the promise, the performance of PLL often lags behind the supervised counterpart. In this work, we bridge the gap by addressing two key research challenges in PLL---representation learning and label disambiguation---in one coherent framework. Specifically, our proposed framework PiCO consists of a contrastive learning module along with a novel class prototype-based label disambiguation algorithm. PiCO produces closely aligned representations for examples from the same classes and facilitates label disambiguation. Theoretically, we show that these two components are mutually beneficial, and can be rigorously justified from an expectation-maximization (EM) algorithm perspective. Extensive experiments demonstrate that PiCO significantly outperforms the current state-of-the-art approaches in PLL and even achieves comparable results to fully supervised learning. Code and data available: https://github.com/hbzju/PiCO.",
    "One-sentence Summary": "A synergistic PLL framework that leverages contrastive learning for enhanced representation and improved label disambiguation."
  },
  {
    "title": "Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting",
    "url": "/forum?id=0EXmFzUn5I",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "sparse attention, pyramidal graph, Transformer, time series forecasting, long-range dependence, multiresolution",
    "Abstract": "Accurate prediction of the future given the past based on time series data is of paramount importance, since it opens the door for decision making and risk management ahead of time. In practice, the challenge is to build a flexible but parsimonious model that can capture a wide range of temporal dependencies. In this paper, we propose Pyraformer by exploring the multiresolution representation of the time series. Specifically, we introduce the pyramidal attention module (PAM) in which the inter-scale tree structure summarizes features at different resolutions and the intra-scale neighboring connections model the temporal dependencies of different ranges. Under mild conditions, the maximum length of the signal traversing path in Pyraformer is a constant (i.e., O(1)) with regard to the sequence length L, while its time and space complexity scale linearly with L. Extensive numerical results show that Pyraformer typically achieves the highest prediction accuracy in both single-step and long-range forecasting tasks with the least amount of time and memory consumption, especially when the sequence is long.",
    "One-sentence Summary": "We propose a multiresolution pyramidal attention mechanism for long-range dependence modeling and time series forecasting, successfully reducing the maximum length of the signal traversing path to O(1) while achieving linear time and space complexity"
  },
  {
    "title": "Expressiveness and Approximation Properties of Graph Neural Networks",
    "url": "/forum?id=wIzUeM3TAU",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Graph Neural Networks, Colour Refinement, Weisfeiler-Leman, Separation Power, Universality",
    "Abstract": "Characterizing the separation power of graph neural networks (GNNs) provides an understanding of their limitations for graph learning tasks. Results regarding separation power are, however, usually geared at specific GNNs architectures, and tools for understanding arbitrary GNN architectures are generally lacking. We provide an elegant way to easily obtain bounds on the separation power of GNNs in terms of the Weisfeiler-Leman (WL) tests, which have become the yardstick to measure the separation power of GNNs. The crux is to view GNNs as expressions in a procedural tensor language describing the computations in the layers of the GNNs. Then, by a simple analysis of the obtained expressions, in terms of the number of indexes used and the nesting depth of summations, bounds on the separation power in terms of the WL-tests readily follow. We use tensor language to define Higher-Order Message-Passing Neural Networks (or k-MPNNs), a natural extension of MPNNs. Furthermore, the tensor language point of view allows for the derivation of universality results for classes of GNNs in a natural way. Our approach provides a toolbox with which GNN architecture designers can analyze the separation power of their GNNs, without needing to know the intricacies of the WL-tests. We also provide insights in what is needed to boost the separation power of GNNs.",
    "One-sentence Summary": "A general methodology for assessing the expressive and approximation power of GNNs is presented."
  },
  {
    "title": "Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space",
    "url": "/forum?id=1L0C5ROtFp",
    "date": "28 Sept 2021 (modified: 01 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Abstract": "Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction."
  },
  {
    "title": "BEiT: BERT Pre-Training of Image Transformers",
    "url": "/forum?id=p-BhZSz59o4",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "self-supervised learning, pre-training, vision Transformer",
    "Abstract": "We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16 x 16 pixels), and visual tokens (i.e., discrete tokens). We first ``tokenize'' the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
    "One-sentence Summary": "We propose a masked image modeling task to pretrain vision Transformers."
  },
  {
    "title": "Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution",
    "url": "/forum?id=UYneFzXSJWh",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "fine-tuning theory, transfer learning theory, fine-tuning, distribution shift, implicit regularization",
    "Abstract": "When transferring a pretrained model to a downstream task, two popular methods are full fine-tuning (updating all the model parameters) and linear probing (updating only the last linear layer---the \"head\"). It is well known that fine-tuning leads to better accuracy in-distribution (ID). However, in this paper, we find that fine-tuning can achieve worse accuracy than linear probing out-of-distribution (OOD) when the pretrained features are good and the distribution shift is large. On 10 distribution shift datasets (BREEDS-Living17, BREEDS-Entity30, DomainNet, CIFAR \u2192 STL, CIFAR-10.1, FMoW, ImageNetV2, ImageNet-R, ImageNet-A, ImageNet-Sketch), fine-tuning obtains on average 2% higher accuracy ID but 7% lower accuracy OOD than linear probing. We show theoretically that this tradeoff between ID and OOD accuracy arises even in a simple setting: fine-tuning overparameterized two-layer linear networks. We prove that the OOD error of fine-tuning is high when we initialize with a fixed or random head---this is because while fine-tuning learns the head, the lower layers of the neural network change simultaneously and distort the pretrained features. Our analysis suggests that the easy two-step strategy of linear probing then full fine-tuning (LP-FT), sometimes used as a fine-tuning heuristic, combines the benefits of both fine-tuning and linear probing. Empirically, LP-FT outperforms both fine-tuning and linear probing on the above datasets (1% better ID, 10% better OOD than full fine-tuning).",
    "One-sentence Summary": "Fine-tuning does better than linear probing (training a linear classifier on pretrained features) in-distribution, but worse out-of-distribution (OOD)---we analyze why this happens and propose a way to get the benefits of both."
  },
  {
    "title": "StyleAlign: Analysis and Applications of Aligned StyleGAN Models",
    "url": "/forum?id=Qg2vi4ZbHM9",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "StyleGAN, transfer learning, fine tuning, model alignment, image-to-image translation, image morphing",
    "Abstract": "In this paper, we perform an in-depth study of the properties and applications of aligned generative models.\n        We refer to two models as aligned if they share the same architecture, and one of them (the child) is obtained from the other (the parent) via fine-tuning to another domain, a common practice in transfer learning. Several works already utilize some basic properties of aligned StyleGAN models to perform image-to-image translation. Here, we perform the first detailed exploration of model alignment, also focusing on StyleGAN. First, we empirically analyze aligned models and provide answers to important questions regarding their nature. In particular, we find that the child model's latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. Second, equipped with this better understanding, we leverage aligned models to solve a diverse set of tasks. In addition to image translation, we demonstrate fully automatic cross-domain image morphing. We further show that zero-shot vision tasks may be performed in the child domain, while relying exclusively on supervision in the parent domain. We demonstrate qualitatively and quantitatively that our approach yields state-of-the-art results, while requiring only simple fine-tuning and inversion.",
    "One-sentence Summary": "Analysis and applications of aligned generative models"
  },
  {
    "title": "Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion",
    "url": "/forum?id=qnQN4yr6FJz",
    "date": "28 Sept 2021 (modified: 22 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Black-box variational inference, missing values, evidence upper bound",
    "Abstract": "We are concerned with the problem of distributional prediction with incomplete features: The goal is to estimate the distribution of target variables given feature vectors with some of the elements missing. A typical approach to this problem is to perform missing-value imputation and regression, simultaneously or sequentially, which we call the generative approach. Another approach is to perform regression after appropriately encoding missing values into the feature, which we call the discriminative approach. In comparison, the generative approach is more robust to the feature corruption while the discriminative approach is more favorable to maximize the performance of prediction. \n        In this study, we propose a hybrid method to take the best of both worlds. Our method utilizes the black-box variational inference framework so that it can be applied to a wide variety of modern machine learning models, including the variational autoencoders. We also confirmed the effectiveness of the proposed method empirically.",
    "One-sentence Summary": "A new variational approximation and algorithm are proposed for discriminative inference with missing features."
  },
  {
    "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
    "url": "/forum?id=uYLFoz1vlAC",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "sequence models, state space, RNN, CNN, Long Range Arena",
    "Abstract": "A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies.  Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of 10000 or more steps.  A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) x\u2032(t)=Ax(t)+Bu(t),y(t)=Cx(t)+Du(t), and showed that for appropriate choices of the state matrix A, this system could handle long-range dependencies mathematically and empirically.  However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution.  We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths.  Our technique involves conditioning A with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel.  S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91\\% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation 60\u00d7 faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.",
    "One-sentence Summary": "We introduce the S3 model based on new algorithms for state spaces that is particularly effective on long-range dependencies."
  },
  {
    "title": "Large Language Models Can Be Strong Differentially Private Learners",
    "url": "/forum?id=bVuP3ltATMz",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "language model, differential privacy, language generation, fine-tuning, NLP",
    "Abstract": "Differentially Private (DP) learning has seen limited success for building large deep learning models of text, and straightforward attempts at applying Differentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have resulted in large performance drops and high computational overhead.\n        We show that this performance drop can be mitigated with (1) the use of large pretrained language models; (2) non-standard hyperparameters that suit DP optimization; and (3) fine-tuning objectives which are aligned with the pretraining procedure.\n        With the above, we obtain NLP models that outperform state-of-the-art DP-trained models under the same privacy budget and strong non-private baselines---by directly fine-tuning pretrained models with DP optimization on moderately-sized corpora. \n        To address the computational challenge of running DP-SGD with large Transformers, we propose a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any linear layer in the model. \n        The technique enables privately training Transformers with almost the same memory cost as non-private training at a modest run-time overhead. \n        Contrary to conventional wisdom that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained language models tends to not suffer from dimension-dependent performance degradation.\n        Code to reproduce results can be found at https://github.com/lxuechen/private-transformers.",
    "One-sentence Summary": "We show how to build highly performant differentially private NLP models by fine-tuning large pretrained models."
  },
  {
    "title": "GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation",
    "url": "/forum?id=PzcvxEMzvQC",
    "date": "28 Sept 2021 (modified: 06 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "molecular conformation generation, deep generative models, diffusion probabilistic models",
    "Abstract": "Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules.",
    "One-sentence Summary": "A novel probabilistic diffusion framework to generate accurate and diverse molecular conformations, achieving state-of-the-art results on conformation generation and property prediction"
  },
  {
    "title": "Frame Averaging for Invariant and Equivariant Network Design",
    "url": "/forum?id=zIUyj55nXR",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Invariant and equivariant neural network, expressive power",
    "Abstract": "Many machine learning tasks involve learning functions that are known to be invariant or equivariant to certain symmetries of the input data. However, it is often challenging to design neural network architectures that respect these symmetries while being expressive and computationally efficient. For example, Euclidean motion invariant/equivariant graph or point cloud neural networks. \n        We introduce Frame Averaging (FA), a highly general purpose and systematic framework for adapting known (backbone) architectures to become invariant or equivariant to new symmetry types. Our framework builds on the well known group averaging operator that guarantees invariance or equivariance but is intractable. In contrast, we observe that for many important classes of symmetries, this operator can be replaced with an averaging operator over a small subset of the group elements, called a frame. We show that averaging over a frame guarantees exact invariance or equivariance while often being much simpler to compute than averaging over the entire group. Furthermore, we prove that FA-based models have maximal expressive power in a broad setting and in general preserve the expressive power of their backbone architectures. Using frame averaging, we propose a new class of universal Graph Neural Networks (GNNs), universal Euclidean motion invariant point cloud networks, and Euclidean motion invariant Message Passing (MP) GNNs. We demonstrate the practical effectiveness of FA on several applications including point cloud normal estimation, beyond 2-WL graph separation, and n-body dynamics prediction, achieving state-of-the-art results in all of these benchmarks.",
    "One-sentence Summary": "Introducing a general methodology for building expressive and efficient invariant and equivariant networks."
  },
  {
    "title": "Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation",
    "url": "/forum?id=oapKSVM2bcj",
    "date": "28 Sept 2021 (modified: 21 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "tensor manipulations, tensor transformation, einops, einstein notation, einsum",
    "Abstract": "Tensor computations underlie modern scientific computing and deep learning.\n        A number of tensor frameworks emerged varying in execution model, hardware support, memory management, model definition, etc.\n        However, tensor operations in all frameworks follow the same paradigm.\n        Recent neural network architectures demonstrate demand for higher expressiveness of tensor operations.\n        The current paradigm is not suited to write readable, reliable, or easy-to-modify code for multidimensional tensor manipulations. \n        Moreover, some commonly used operations do not provide sufficient checks and can break a tensor structure.\n        These mistakes are elusive as no tools or tests can detect them.\n        Independently, API discrepancies complicate code transfer between frameworks.\n        We propose einops notation: a uniform and generic way to manipulate tensor structure, that significantly improves code readability and flexibility by focusing on the structure of input and output tensors.\n        We implement einops notation in a Python package that efficiently supports multiple widely used frameworks and provides framework-independent minimalist API for tensor manipulations.",
    "One-sentence Summary": "We propose a notation for clear and reliable tensor manipulations; we implented notation in Python package to handle multiple frameworks"
  },
  {
    "title": "A Fine-Grained Analysis on Distribution Shift",
    "url": "/forum?id=Dl4LetuLdyK",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "robustness, distribution shifts",
    "Abstract": "Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets.  Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work (Gulrajani & Lopez-Paz, 2021), that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts. We will open source our experimental framework, allowing future work to evaluate new methods over multiple shifts to obtain a more complete picture of a method's effectiveness. \n        Code is available at github.com/deepmind/distribution_shift_framework.",
    "One-sentence Summary": "We investigate and analyse the robustness of a variety of methods under distribution shifts using our flexible experimental framework."
  },
  {
    "title": "Open-Set Recognition: A Good Closed-Set Classifier is All You Need",
    "url": "/forum?id=5hLP5JY9S2d",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "open set recognition, image recognition, computer vision",
    "Abstract": "The ability to identify whether or not a test sample belongs to one of the semantic classes in a classifier's training set is critical to practical deployment of the model. This task is termed open-set recognition (OSR) and has received significant attention in recent years. In this paper, we first demonstrate that the ability of a classifier to make the 'none-of-above' decision is highly correlated with its accuracy on the closed-set classes. We find that this relationship holds across loss objectives and architectures, and further demonstrate the trend both on the standard OSR benchmarks as well as on a large-scale ImageNet evaluation. Second, we use this correlation to boost the performance of the maximum softmax probability OSR 'baseline' by improving its closed-set accuracy, and with this strong baseline achieve state-of-the-art on a number of OSR benchmarks. Similarly, we boost the performance of the existing state-of-the-art method by improving its closed-set accuracy, but the resulting discrepancy with the strong baseline is marginal. Our third contribution is to present the 'Semantic Shift Benchmark' (SSB), which better respects the task of detecting semantic novelty, as opposed to low-level distributional shifts as tackled by neighbouring machine learning fields. On this new evaluation, we again demonstrate that there is negligible difference between the strong baseline and the existing state-of-the-art. Code available at: https://github.com/sgvaze/osr_closed_set_all_you_need.",
    "One-sentence Summary": "We show that the baseline method for open-set recognition can achieve state-of-the-art performance and introduce new benchmark settings"
  },
  {
    "title": "Learning Strides in Convolutional Neural Networks",
    "url": "/forum?id=M752z9FKJP",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Strides, Convolutional neural networks, Downsampling, Spectral representations, Fourier",
    "Abstract": "Convolutional neural networks typically contain several downsampling operators, such as strided convolutions or pooling layers, that progressively reduce the resolution of intermediate representations. This provides some shift-invariance while reducing the computational complexity of the whole architecture. A critical hyperparameter of such layers is their stride: the integer factor of downsampling. As strides are not differentiable, finding the best configuration either requires cross-validation or discrete optimization (e.g. architecture search), which rapidly become prohibitive as the search space grows exponentially with the number of downsampling layers. Hence, exploring this search space by gradient descent would allow finding better configurations at a lower computational cost. This work introduces DiffStride, the first downsampling layer with learnable strides. Our layer learns the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Experiments on audio and image classification show the generality and effectiveness of our solution: we use DiffStride as a drop-in replacement to standard downsampling layers and outperform them. In particular, we show that introducing our layer into a ResNet-18 architecture allows keeping consistent high performance on CIFAR10, CIFAR100 and ImageNet even when training starts from poor random stride configurations. Moreover, formulating strides as learnable variables allows us to introduce a regularization term that controls the computational complexity of the architecture. We show how this regularization allows trading off accuracy for efficiency on ImageNet.",
    "One-sentence Summary": "We introduce DiffStride, the first downsampling layer with learnable strides for convolutional neural networks."
  },
  {
    "title": "Understanding over-squashing and bottlenecks on graphs via curvature",
    "url": "/forum?id=7UmjRGzp-A",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Graph neural networks, Geometric deep learning, Differential geometry, Ricci curvature",
    "Abstract": "Most graph neural networks (GNNs) use the message passing paradigm, in which node features are propagated on the input graph. Recent works pointed to the distortion of information flowing from distant nodes as a factor limiting the efficiency of message passing for tasks relying on long-distance interactions. This phenomenon, referred to as 'over-squashing', has been heuristically attributed to graph bottlenecks where the number of k-hop neighbors grows rapidly with k. We provide a precise description of the over-squashing phenomenon in GNNs and analyze how it arises from bottlenecks in the graph. For this purpose, we introduce a new edge-based combinatorial curvature and prove that negatively curved edges are responsible for the over-squashing issue. We also propose and experimentally test a  curvature-based graph rewiring method to alleviate the over-squashing."
  },
  {
    "title": "Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme",
    "url": "/forum?id=8c50f-DoWAu",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "speech, voice conversion, diffusion models, stochastic differential equations",
    "Abstract": "Voice conversion is a common speech synthesis task which can be solved in different ways depending on a particular real-world scenario. The most challenging one often referred to as one-shot many-to-many voice conversion consists in copying target voice from only one reference utterance in the most general case when both source and target speakers do not belong to the training dataset. We present a scalable high-quality solution based on diffusion probabilistic modeling and demonstrate its superior quality compared to state-of-the-art one-shot voice conversion approaches. Moreover, focusing on real-time applications, we investigate general principles which can make diffusion models faster while keeping synthesis quality at a high level. As a result, we develop a novel Stochastic Differential Equations solver suitable for various diffusion model types and generative tasks as shown through empirical studies and justify it by theoretical analysis."
  },
  {
    "title": "Resolving Training Biases via Influence-based Data Relabeling",
    "url": "/forum?id=EskfH0bwNVn",
    "date": "28 Sept 2021 (modified: 02 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Training bias, influence functions, data relabeling",
    "Abstract": "The performance of supervised learning methods easily suffers from the training bias issue caused by train-test distribution mismatch or label noise. Influence function is a  technique that estimates the impacts of a training sample on the model\u2019s predictions. Recent studies on \\emph{data resampling} have employed influence functions to identify \\emph{harmful} training samples that will degrade model's test performance. They have shown that discarding or downweighting the identified harmful training samples is an effective way to resolve training biases. In this work, we move one step forward and propose an influence-based relabeling framework named RDIA for reusing harmful training samples toward better model performance. To achieve this, we use influence functions to estimate how relabeling a training sample would affect model's test performance and further develop a novel relabeling function R. We theoretically prove that applying R to relabel harmful training samples allows the model to achieve lower test loss than simply discarding them for any classification tasks using cross-entropy loss. Extensive experiments on ten real-world datasets demonstrate RDIA outperforms the state-of-the-art data resampling methods and improves model's robustness against label noise.",
    "One-sentence Summary": "We propose an influence-based relabeling framework for solving training bias with a theoretical guarantee"
  },
  {
    "title": "Representational Continuity for Unsupervised Continual Learning",
    "url": "/forum?id=9Hrka5PA7LW",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Continual Learning, Representational Learning, Deep Learning",
    "Abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting the previously acquired knowledge. However, recent CL advances are restricted to supervised continual learning (SCL) scenarios. Consequently, they are not scalable to real-world applications where the data distribution is often biased and unannotated. In this work, we focus on unsupervised continual learning (UCL), where we learn the feature representations on an unlabelled sequence of tasks and show that reliance on annotated data is not necessary for continual learning. We conduct a systematic study analyzing the learned feature representations and show that unsupervised visual representations are surprisingly more robust to catastrophic forgetting, consistently achieve better performance, and generalize better to out-of-distribution tasks than SCL. Furthermore, we find that UCL achieves a smoother loss landscape through qualitative analysis of the learned representations and learns meaningful feature representations. Additionally, we propose Lifelong Unsupervised Mixup (LUMP), a simple yet effective technique that interpolates between the current task and previous tasks' instances to alleviate catastrophic forgetting for unsupervised representations.",
    "One-sentence Summary": "We attempt to bridge the gap between continual learning & representation learning and show that unsupervised continual learning achieves better performance and learns perceptual features with a smoother loss landscape than SCL."
  },
  {
    "title": "Vision-Based Manipulators Need to Also See from Their Hands",
    "url": "/forum?id=RJkAHKp7kNZ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "reinforcement learning, observation space, out-of-distribution generalization, visuomotor control, robotics, manipulation",
    "Abstract": "We study how the choice of visual perspective affects learning and generalization in the context of physical manipulation from raw sensor observations. Compared with the more commonly used global third-person perspective, a hand-centric (eye-in-hand) perspective affords reduced observability, but we find that it consistently improves training efficiency and out-of-distribution generalization. These benefits hold across a variety of learning algorithms, experimental settings, and distribution shifts, and for both simulated and real robot apparatuses. However, this is only the case when hand-centric observability is sufficient; otherwise, including a third-person perspective is necessary for learning, but also harms out-of-distribution generalization. To mitigate this, we propose to regularize the third-person information stream via a variational information bottleneck. On six representative manipulation tasks with varying hand-centric observability adapted from the Meta-World benchmark, this results in a state-of-the-art reinforcement learning agent operating from both perspectives improving its out-of-distribution generalization on every task. While some practitioners have long put cameras in the hands of robots, our work systematically analyzes the benefits of doing so and provides simple and broadly applicable insights for improving end-to-end learned vision-based robotic manipulation.",
    "One-sentence Summary": "Appropriately designing the observation space of a vision-based manipulator and regularizing its representations leads to clear gains in learning stability and out-of-distribution generalization."
  },
  {
    "title": "Meta-Learning with Fewer Tasks through Task Interpolation",
    "url": "/forum?id=ajXWF7bVR8d",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "meta-learning, task interpolation, meta-regularization",
    "Abstract": "Meta-learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta-learning algorithms is the requirement of a large number of meta-training tasks, which may not be accessible in real-world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, we propose to augment the task set through interpolation. By meta-learning with task interpolation (MLTI), our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Under both gradient-based and metric-based meta-learning settings, our theoretical analysis shows MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, in our experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification, we find that the proposed general MLTI framework is compatible with representative meta-learning algorithms and consistently outperforms other state-of-the-art strategies.",
    "One-sentence Summary": "A new framework to densify the task distribution via task interpolation"
  },
  {
    "title": "DISCOVERING AND EXPLAINING THE REPRESENTATION BOTTLENECK OF DNNS",
    "url": "/forum?id=iRCUlgmdfHJ",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "representation bottleneck, representation ability, interaction, explanation",
    "Abstract": "This paper explores the bottleneck of feature representations of deep neural networks (DNNs), from the perspective of the complexity of interactions between input variables encoded in DNNs. To this end, we focus on the multi-order interaction between input variables, where the order represents the complexity of interactions. We discover that a DNN is more likely to encode both too simple and too complex interactions, but usually fails to learn interactions of intermediate complexity. Such a phenomenon is widely shared by different DNNs for different tasks. This phenomenon indicates a cognition gap between DNNs and humans, and we call it a representation bottleneck. We theoretically prove the underlying reason for the representation bottleneck. Furthermore, we propose losses to encourage/penalize the learning of interactions of specific complexities, and analyze the representation capacities of interactions of different complexities. The code is available at https://github.com/Nebularaid2000/bottleneck."
  },
  {
    "title": "Sparse Communication via Mixed Distributions",
    "url": "/forum?id=WAid50QschI",
    "date": "28 Sept 2021 (modified: 28 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Abstract": "Neural networks and other machine learning models compute continuous representations, while humans communicate mostly through discrete symbols. Reconciling these two forms of communication is desirable for generating human-readable interpretations or learning discrete latent variable models, while maintaining end-to-end differentiability. Some existing approaches (such as the Gumbel-Softmax transformation) build continuous relaxations that are discrete approximations in the zero-temperature limit, while others (such as sparsemax transformations and the Hard Concrete distribution) produce discrete/continuous hybrids. In this paper, we build rigorous theoretical foundations for these hybrids, which we call \"mixed random variables.'' Our starting point is a new \"direct sum'' base measure defined on the face lattice of the probability simplex. From this measure, we introduce new entropy and Kullback-Leibler divergence functions that subsume the discrete and differential cases and have interpretations in terms of code optimality. Our framework suggests two strategies for representing and sampling mixed random variables, an extrinsic (\"sample-and-project'\u2019) and an intrinsic one (based on face stratification). We experiment with both approaches on an  emergent communication benchmark and on modeling MNIST and Fashion-MNIST data with variational auto-encoders with mixed latent variables."
  },
  {
    "title": "Finetuned Language Models are Zero-Shot Learners",
    "url": "/forum?id=gEZrGCozdqR",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "natural language processing, zero-shot learning, language models",
    "Abstract": "This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning\u2014finetuning language models on a collection of datasets described via instructions\u2014substantially improves zero-shot performance on unseen tasks. We take a 137B parameter pretrained language model and instruction tune it on over 60 NLP datasets verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types. FLAN substantially improves the performance of its unmodified counterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 datasets that we evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number of finetuning datasets, model scale, and natural language instructions are key to the success of instruction tuning.",
    "One-sentence Summary": "\"Instruction tuning\", which finetunes language models on a collection of tasks described via instructions, substantially boosts zero-shot performance on unseen tasks."
  },
  {
    "title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization",
    "url": "/forum?id=_CfpJazzXT2",
    "date": "28 Sept 2021 (modified: 24 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Neural Network Quantization, Fixed-Point Arithmetic",
    "Abstract": "Neural network quantization is a promising compression technique to reduce memory footprint and save energy consumption, potentially leading to real-time inference. However, there is a performance gap between quantized and full-precision models. To reduce it, existing quantization approaches require high-precision INT32 or full-precision multiplication during inference for scaling or dequantization. This introduces a noticeable cost in terms of memory, speed, and required energy. To tackle these issues, we present F8Net, a novel quantization framework consisting in only \ufb01xed-point 8-bit multiplication. To derive our method, we \ufb01rst discuss the advantages of \ufb01xed-point multiplication with different formats of \ufb01xed-point numbers and study the statistical behavior of the associated \ufb01xed-point numbers. Second, based on the statistical and algorithmic analysis, we apply different \ufb01xed-point formats for weights and activations of different layers. We introduce a novel algorithm to automatically determine the right format for each layer during training. Third, we analyze a previous quantization algorithm\u2014parameterized clipping activation (PACT)\u2014and reformulate it using \ufb01xed-point arithmetic. Finally, we unify the recently proposed method for quantization \ufb01ne-tuning and our \ufb01xed-point approach to show the potential of our method. We verify F8Net on ImageNet for MobileNet V1/V2 and ResNet18/50. Our approach achieves comparable and better performance, when compared not only to existing quantization techniques with INT32 multiplication or \ufb02oating point arithmetic, but also to the full-precision counterparts, achieving state-of-the-art performance.",
    "One-sentence Summary": "We propose a method for neural network quantization with only 8-bit fixed-point multiplication."
  },
  {
    "title": "Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design",
    "url": "/forum?id=UcDUxjPYWSr",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "Agent Design, Morphology Optimization, Reinforcement Learning",
    "Abstract": "An agent's functionality is largely determined by its design, i.e., skeletal structure and joint attributes (e.g., length, size, strength). However, finding the optimal agent design for a given function is extremely challenging since the problem is inherently combinatorial and the design space is prohibitively large. Additionally, it can be costly to evaluate each candidate design which requires solving for its optimal controller. To tackle these problems, our key idea is to incorporate the design procedure of an agent into its decision-making process. Specifically, we learn a conditional policy that, in an episode, first applies a sequence of transform actions to modify an agent's skeletal structure and joint attributes, and then applies control actions under the new design. To handle a variable number of joints across designs, we use a graph-based policy where each graph node represents a joint and uses message passing with its neighbors to output joint-specific actions. Using policy gradient methods, our approach enables joint optimization of agent design and control as well as experience sharing across different designs, which improves sample efficiency substantially.  Experiments show that our approach, Transform2Act, outperforms prior methods significantly in terms of convergence speed and final performance. Notably, Transform2Act can automatically discover plausible designs similar to giraffes, squids, and spiders. Code and videos are available at https://sites.google.com/view/transform2act.",
    "One-sentence Summary": "We learn a transform-and-control policy to both design and control an agent."
  },
  {
    "title": "ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics",
    "url": "/forum?id=s03AQxehtd_",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "inverse kinematics, deep learning, pose modeling",
    "Abstract": "Our work focuses on the development of a learnable neural representation of human pose for advanced AI assisted animation tooling. Specifically, we tackle the problem of constructing a full static human pose based on sparse and variable user inputs (e.g. locations and/or orientations of a subset of body joints). To solve this problem, we propose a novel neural architecture that combines residual connections with prototype encoding of a partially specified pose to create a new complete pose from the learned latent space. We show that our architecture outperforms a baseline based on Transformer, both in terms of accuracy and computational efficiency. Additionally, we develop a user interface to integrate our neural model in Unity, a real-time 3D development platform. Furthermore, we introduce two new datasets representing the static human pose modeling problem, based on high-quality human motion capture data, which will be released publicly along with model code."
  },
  {
    "title": "Hyperparameter Tuning with Renyi Differential Privacy",
    "url": "/forum?id=-70L8lpp9DF",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "differential privacy, hyperparameter tuning",
    "Abstract": "For many differentially private algorithms, such as the prominent noisy stochastic gradient descent (DP-SGD), the analysis needed to bound the privacy leakage of a single training run is well understood. However, few studies have reasoned about the privacy leakage resulting from the multiple training runs needed to fine tune the value of the training algorithm\u2019s hyperparameters. In this work, we first illustrate how simply setting hyperparameters based on non-private training runs can leak private information. Motivated by this observation, we then provide privacy guarantees for hyperparameter search procedures within the framework of Renyi Differential Privacy. Our results improve and extend the work of Liu and Talwar (STOC 2019). Our analysis supports our previous observation that tuning hyperparameters does indeed leak private information, but we prove that, under certain assumptions, this leakage is modest, as long as each candidate training run needed to select hyperparameters is itself differentially private.",
    "One-sentence Summary": "We provide privacy guarantees for hyperparameter search procedures, showing that tuning hyperparameters leaks private information, but that, under certain assumptions, this leakage is modest."
  },
  {
    "title": "Real-Time Neural Voice Camouflage",
    "url": "/forum?id=qj1IZ-6TInc",
    "date": "28 Sept 2021 (modified: 19 Feb 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "automatic speech recognition, predictive models, privacy",
    "Abstract": "Automatic speech recognition systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping.We propose a method to camouflage a person's voice from these systems without inconveniencing the conversation between people in the room. Standard adversarial attacks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive adversarial attacks, which achieves real-time performance by forecasting the attack vector that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 3.9x more than online projected gradient descent as measured through word error rate, and 6.6x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments with complex scene geometries.",
    "One-sentence Summary": "We introduce predictive attacks, which achieve real-time performance in breaking automatic speech recognition models by forecasting the attack vector that will be the most effective in the future."
  },
  {
    "title": "CycleMLP: A MLP-like Architecture for Dense Prediction",
    "url": "/forum?id=NMEceG4v69Y",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "MLP, Dense Prediction",
    "Abstract": "This paper presents a simple MLP-like architecture, CycleMLP, which is a versatile backbone for visual recognition and dense predictions. As compared to modern MLP architectures, e.g. , MLP-Mixer, ResMLP, and gMLP, whose architectures are correlated to image size and thus are infeasible in object detection and segmentation, CycleMLP has two advantages compared to modern approaches. (1) It can cope\n        with various image sizes. (2) It achieves linear computational complexity to image size by using local windows. In contrast, previous MLPs have $O(N^2)$ computations due to fully spatial connections. We build a family of models which surpass existing MLPs and even state-of-the-art Transformer-based models, e.g. Swin Transformer, while using fewer parameters and FLOPs. We expand the MLP-like models\u2019 applicability, making them a versatile backbone for dense prediction tasks. CycleMLP achieves competitive results on object detection, instance segmentation, and semantic segmentation. In particular, CycleMLP-Tiny outperforms Swin-Tiny by 1.3% mIoU on ADE20K dataset with fewer FLOPs. Moreover, CycleMLP also shows excellent zero-shot robustness on ImageNet-C dataset.",
    "One-sentence Summary": "A versatile MLP-like architecture for both recognition and dense prediction."
  },
  {
    "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models",
    "url": "/forum?id=0xiJLKH-ufZ",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "diffusion probabilistic models, generative models",
    "Abstract": "Diffusion probabilistic models (DPMs) represent a class of powerful generative models. Despite their success, the inference of DPMs is expensive since it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. In this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Building upon it, we propose \\textit{Analytic-DPM}, a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. Further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, our analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a $20\\times$ to $80\\times$ speed up.",
    "One-sentence Summary": "We propose an analytic framework of estimating the optimal reverse variance in DPMs."
  },
  {
    "title": "RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation",
    "url": "/forum?id=uSE03demja",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "differentiable rendering, differentiable simulation, system identification",
    "Abstract": "This work considers identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible. Existing solutions require massive training data or lack generalizability to unknown rendering configurations. We propose a novel approach that marries domain randomization and differentiable rendering gradients to address this problem. Our core idea is to train a rendering-invariant state-prediction (RISP) network that transforms image differences into state differences independent of rendering configurations, e.g., lighting, shadows, or material reflectance. To train this predictor, we formulate a new loss on rendering variances using gradients from differentiable rendering. Moreover, we present an efficient, second-order method to compute the gradients of this loss, allowing it to be integrated seamlessly into modern deep learning frameworks. We evaluate our method in rigid-body and deformable-body simulation environments using four tasks: state estimation, system identification, imitation learning, and visuomotor control. We further demonstrate the efficacy of our approach on a real-world example: inferring the state and action sequences of a quadrotor from a video of its motion sequences. Compared with existing methods, our approach achieves significantly lower reconstruction errors and has better generalizability among unknown rendering configurations.",
    "One-sentence Summary": "We propose a novel approach to address the problem of identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible."
  },
  {
    "title": "The Information Geometry of Unsupervised Reinforcement Learning",
    "url": "/forum?id=3wU2UX0voE",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "unsupervised skill learning, reward-free RL, mutual information, DIAYN",
    "Abstract": "How can a reinforcement learning (RL) agent prepare to solve downstream tasks if those tasks are not known a priori? One approach is unsupervised skill discovery, a class of algorithms that learn a set of policies without access to a reward function. Such algorithms bear a close resemblance to representation learning algorithms (e.g., contrastive learning) in supervised learning, in that both are pretraining algorithms that maximize some approximation to a mutual information objective. While prior work has shown that the set of skills learned by such methods can accelerate downstream RL tasks, prior work offers little analysis into whether these skill learning algorithms are optimal, or even what notion of optimality would be appropriate to apply to them. In this work, we show that unsupervised skill discovery algorithms based on mutual information maximization do not learn skills that are optimal for every possible reward function. However, we show that the distribution over skills provides an optimal initialization minimizing regret against adversarially-chosen reward functions, assuming a certain type of adaptation procedure. Our analysis also provides a geometric perspective on these skill learning methods.",
    "One-sentence Summary": "We show that mutual information skill learning is optimal in one sense but not optimal in another sense."
  },
  {
    "title": "Language modeling via stochastic processes",
    "url": "/forum?id=pMQwKL1yctf",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Oral",
    "Keywords": "contrastive learning, language modelling, stochastic processes",
    "Abstract": "Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. To address these issues, we introduce Time Control (TC), a language model that implicitly plans via a latent stochastic process. TC does this by learning a representation which maps the dynamics of how text changes in a document to the dynamics of a stochastic process of interest. Using this representation, the language model can generate text by first implicitly generating a document plan via a stochastic process, and then generating text that is consistent with this latent plan. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC improves performance on text infilling and discourse coherence. On long text generation settings, TC preserves the text structure both in terms of ordering (up to +40% better) and text length consistency (up to +17% better).  Human evaluators also prefer TC's output 28.6% more than the baselines.",
    "One-sentence Summary": "We introduce a language model that implicitly plans via a latent stochastic process."
  },
  {
    "title": "Learning to Downsample for Segmentation of Ultra-High Resolution Images",
    "url": "/forum?id=HndgQudNb91",
    "date": "29 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "ultra-high resolution image segmentation, non-uniform dowmsampling, efficient segmentation, large volume image segmentation, medical image segmentation",
    "Abstract": "Many computer vision systems require low-cost segmentation algorithms based on deep learning, either because of the enormous size of input images or limited computational budget. Common solutions uniformly downsample the input images to meet memory constraints, assuming all pixels are equally informative. In this work, we demonstrate that this assumption can harm the segmentation performance\n        because the segmentation difficulty varies spatially (see Figure 1 \u201cUniform\u201d). We combat this problem by introducing a learnable downsampling module, which can be optimised together with the given segmentation model in an end-to-end fashion. We formulate the problem of training such downsampling module as optimisation of sampling density distributions over the input images given their low-resolution views. To defend against degenerate solutions (e.g. over-sampling trivial regions like the backgrounds), we propose a regularisation term that encourages the sampling locations to concentrate around the object boundaries. We find the downsampling\n        module learns to sample more densely at difficult locations, thereby improving the segmentation performance (see Figure 1 \"Ours\"). Our experiments on benchmarks of high-resolution street view, aerial and medical images demonstrate substantial improvements in terms of efficiency-and-accuracy trade-off compared to both uniform downsampling and two recent advanced downsampling techniques.",
    "One-sentence Summary": "We propose a method for learning to downsample ultra high-resolution images that reflects the importance of each location."
  },
  {
    "title": "Variational Neural Cellular Automata",
    "url": "/forum?id=7fFO4cMBx_9",
    "date": "29 Sept 2021 (modified: 22 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Cellular Automata, Cellular Automata, Self-Organization, Generative Models",
    "Abstract": "In nature, the process of cellular growth and differentiation has lead to an amazing diversity of organisms --- algae, starfish, giant sequoia, tardigrades, and orcas are all created by the same generative process.\n        Inspired by the incredible diversity of this biological generative process, we propose a generative model, the Variational Neural Cellular Automata (VNCA), which is loosely inspired by the biological processes of cellular growth and differentiation. Unlike previous related works, the VNCA is a proper probabilistic generative model, and we evaluate it according to best practices. We find that the VNCA learns to reconstruct samples well and that despite its relatively few parameters and simple local-only communication, the VNCA can learn to generate a large variety of output from information encoded in a common vector format. While there is a significant gap to the current state-of-the-art in terms of generative modeling performance, we show that the VNCA can learn a purely self-organizing generative process of data. Additionally, the self-organizing nature bestows the VNCA with some inherent robustness against perturbations in the early stages of growth.",
    "One-sentence Summary": "We propose and evaluate the Variational Neural Cellular Automata, a self-organising generative model based on neural cellular automata"
  },
  {
    "title": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous manipulation",
    "url": "/forum?id=FKp8-pIRo3y",
    "date": "29 Sept 2021 (modified: 07 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "goal-conditioned reinforcement learning, learning from demonstrations, long-horizon dexterous manipulation, bi-manual manipulation",
    "Abstract": "Complex sequential tasks in continuous-control settings often require agents to successfully traverse a set of ``narrow passages'' in their state space. Solving such tasks with a sparse reward in a sample-efficient manner poses a challenge to modern reinforcement learning (RL) due to the associated long-horizon nature of the problem and the lack of sufficient positive signal during learning. \n        Various tools have been applied to address this challenge. When available, large sets of demonstrations can guide agent exploration. Hindsight relabelling on the other hand does not require additional sources of information. However, existing strategies explore based on task-agnostic goal distributions, which can render the solution of long-horizon tasks impractical. In this work, we extend hindsight relabelling mechanisms to guide exploration along task-specific distributions implied by a small set of successful demonstrations. We evaluate the approach on four complex, single and dual arm, robotics manipulation tasks against strong suitable baselines. The method requires far fewer demonstrations to solve all tasks and achieves a significantly higher overall performance as task complexity increases. Finally, we investigate the robustness of the proposed solution with respect to the quality of input representations and the number of demonstrations."
  },
  {
    "title": "L0-Sparse Canonical Correlation Analysis",
    "url": "/forum?id=KntaNRo6R48",
    "date": "29 Sept 2021 (modified: 06 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Canonical Correlation Analysis (CCA) models are powerful for studying the associations between two sets of variables. The canonically correlated representations, termed \\textit{canonical variates} are widely used in unsupervised learning to analyze unlabeled multi-modal registered datasets. Despite their success, CCA models may break (or overfit) if the number of variables in either of the modalities exceeds the number of samples. Moreover, often a significant fraction of the variables measures modality-specific information, and thus removing them is beneficial for identifying the \\textit{canonically correlated variates}. Here, we propose \u21130-CCA, a method for learning correlated representations based on sparse subsets of variables from two observed modalities.\n        Sparsity is obtained by multiplying the input variables by stochastic gates, whose parameters are learned together with the CCA weights via an \u21130-regularized correlation loss. \n        We further propose \u21130-Deep CCA for solving the problem of non-linear sparse CCA by modeling the correlated representations using deep nets. We demonstrate the efficacy of the method using several synthetic and real examples. Most notably, by gating nuisance input variables, our approach improves the extracted representations compared to other linear, non-linear and sparse CCA-based models.",
    "One-sentence Summary": "We propose a new \u21130-CCA method for learning correlated representations based on sparse subsets of variables from two observed modalities."
  },
  {
    "title": "Recycling Model Updates in Federated Learning: Are Gradient Subspaces Low-Rank?",
    "url": "/forum?id=B7ZbqNLDn-_",
    "date": "29 Sept 2021 (modified: 01 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Distributed Machine Learning, Federated Learning, Gradient Subspace, SGD",
    "Abstract": "In this paper, we question the rationale behind propagating large numbers of parameters through a distributed system during federated learning. We start by examining the rank characteristics of the subspace spanned by gradients (i.e., the gradient-space) in centralized model training, and observe that the gradient-space often consists of a few leading principal components accounting for an overwhelming majority (95-99%) of the explained variance. Motivated by this, we propose the \"Look-back Gradient Multiplier\" (LBGM) algorithm, which utilizes this low-rank property of the gradient-space in federated learning. Operationally, LBGM recycles the gradients between model update rounds to significantly reduce the number of parameters to be propagated through the system. We analytically characterize the convergence behavior of LBGM, revealing the nature of the trade-off between communication savings and model performance. Our subsequent experimental results demonstrate the improvement LBGM obtains on communication overhead compared to federated learning baselines. Additionally, we show that LBGM is a general plug-and-play algorithm that can be used standalone or stacked on top of existing sparsification techniques for distributed model training.",
    "One-sentence Summary": "We observe that \"gradient-space is low rank\" and propose the LBGM algorithm that utilitizes this low-rank property to recycle gradients between model update rounds in federated learning."
  },
  {
    "title": "Is Homophily a Necessity for Graph Neural Networks?",
    "url": "/forum?id=ucASPPD9GKN",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Graph neural networks (GNNs) have shown great prowess in learning representations suitable for numerous graph-based machine learning tasks. When applied to semi-supervised node classification,  GNNs are widely believed to work well due to the homophily assumption (``like attracts like''), and fail to generalize to heterophilous graphs where dissimilar nodes connect. Recent works design new architectures to overcome such heterophily-related limitations, citing poor baseline performance and new architecture improvements on a few heterophilous graph benchmark datasets as evidence for this notion. In our experiments, we empirically find that standard graph convolutional networks (GCNs) can actually achieve better performance than such carefully designed methods on some commonly used heterophilous graphs. This motivates us to reconsider whether homophily is truly necessary for good GNN performance.  We find that this claim is not quite true, and in fact, GCNs can achieve strong performance on heterophilous graphs under certain conditions. Our work carefully characterizes these conditions and provides supporting theoretical understanding and empirical observations.  Finally, we examine existing heterophilous graphs benchmarks and reconcile how the GCN (under)performs on them based on this understanding."
  },
  {
    "title": "DEGREE: Decomposition Based Explanation for Graph Neural Networks",
    "url": "/forum?id=Ve0Wth3ptT_",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "XAI, GNN",
    "Abstract": "Graph Neural Networks (GNNs) are gaining extensive attention for their application in graph data. However, the black-box nature of GNNs prevents users from understanding and trusting the models, thus hampering their applicability. Whereas explaining GNNs remains a challenge, most existing methods fall into approximation based and perturbation based approaches with suffer from faithfulness problems and unnatural artifacts respectively. To tackle these problems, we propose DEGREE (Decomposition based Explanation for GRaph nEural nEtworks) to provide a faithful explanation for GNN predictions. By decomposing the information generation and aggregation mechanism of GNNs, DEGREE allows tracking the contributions of specific components of the input graph to the final prediction. Based on this, we further design a subgraph level interpretation algorithm to reveal complex interactions between graph nodes that are overlooked by previous methods. The efficiency of our algorithm can be further improved by utilizing GNN characteristics. Finally, we conduct quantitative and qualitative experiments on synthetic and real-world datasets to demonstrate the effectiveness of DEGREE on node classification and graph classification tasks.",
    "One-sentence Summary": "We propose a new decomposition based explanation for Graph Neural Networks."
  },
  {
    "title": "Improving Mutual Information Estimation with Annealed and Energy-Based Bounds",
    "url": "/forum?id=T0B9AoM_bFg",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "mutual information estimation, annealed importance sampling, energy-based models",
    "Abstract": "Mutual information (MI) is a fundamental quantity in information theory and machine learning. However, direct estimation of MI is intractable, even if the true joint probability density for the variables of interest is known, as it involves estimating a potentially high-dimensional log partition function. In this work, we present a unifying view of existing MI bounds from the perspective of importance sampling, and propose three novel bounds based on this approach. Since a tight MI bound without density information requires a sample size exponential in the true MI, we assume either a single marginal or the full joint density information is known. In settings where the full joint density is available, we propose Multi-Sample Annealed Importance Sampling (AIS) bounds on MI, which we demonstrate can tightly estimate large values of MI in our experiments. In settings where only a single marginal distribution is known, we propose Generalized IWAE (GIWAE) and MINE-AIS bounds. Our GIWAE bound unifies variational and contrastive bounds in a single framework that generalizes InfoNCE, IWAE, and Barber-Agakov bounds. Our MINE-AIS method improves upon existing energy-based methods such as MINE-DV and MINE-F by directly optimizing a tighter lower bound on MI. MINE-AIS uses MCMC sampling to estimate gradients for training and Multi-Sample AIS for evaluating the bound. Our methods are particularly suitable for evaluating MI in deep generative models, since explicit forms of the marginal or joint densities are often available. We evaluate our bounds on estimating the MI of VAEs and GANs trained on the MNIST and CIFAR datasets, and showcase significant gains over existing bounds in these challenging settings with high ground truth MI.",
    "One-sentence Summary": "We derive new annealed importance sampling and energy-based bounds, resulting in vastly more accurate estimates of mutual information."
  },
  {
    "title": "Sequence Approximation using Feedforward Spiking Neural Network for Spatiotemporal Learning: Theory and Optimization Methods",
    "url": "/forum?id=bp-LJ4y_XC",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "spiking neural network, spatiotemporal processing, feedforward network",
    "Abstract": "A dynamical system of spiking neurons with only feedforward connections can classify spatiotemporal patterns without recurrent connections. However, the theoretical construct of a feedforward spiking neural network (SNN) for approximating a temporal sequence remains unclear, making it challenging to optimize SNN architectures for learning complex spatiotemporal patterns. In this work, we establish a theoretical framework to understand and improve sequence approximation using a feedforward SNN. Our framework shows that a feedforward SNN with one neuron per layer and skip-layer connections can approximate the mapping function between any arbitrary pairs of input and output spike train on a compact domain. Moreover, we prove that heterogeneous neurons with varying dynamics and skip-layer connections improve sequence approximation using feedforward SNN. Consequently, we propose SNN architectures incorporating the preceding constructs that are trained using supervised backpropagation-through-time (BPTT) and unsupervised spiking-timing-dependent plasticity (STDP) algorithms for classification of spatiotemporal data. A dual-search-space Bayesian optimization method is developed to optimize architecture and parameters of the proposed SNN with heterogeneous neuron dynamics and skip-layer connections.",
    "One-sentence Summary": "A theoretical approache to study the approximation capability of feedforward spiking neural network and optimization methods for such network."
  },
  {
    "title": "Diverse Client Selection for Federated Learning via Submodular Maximization",
    "url": "/forum?id=nwKXyFvaUm",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "federated learning, submodularity, diversity",
    "Abstract": "In every communication round of federated learning, a random subset of clients communicate  their  model  updates  back  to  the  server  which  then  aggregates them all.  The optimal size of this subset is not known and several studies have shown that typically random selection does not perform very well in terms of convergence, learning efficiency and fairness. We, in this paper, propose to select a small diverse subset of clients, namely those carrying representative gradient information, and we transmit only these updates to the server.  Our aim is for updating via only a subset to approximate updating via aggregating all client information. We achieve this by choosing a subset that maximizes a submodular facility location function defined over gradient space. We introduce \u201cfederated averaging with diverse client selection (DivFL)\u201d. We provide a thorough analysis of its convergence in the heterogeneous setting and apply it both to synthetic and to real datasets. Empirical results show several benefits to our approach including improved learning efficiency, faster convergence and also more uniform (i.e., fair) performance across clients. We further show a communication-efficient version of DivFL that can still outperform baselines on the above metrics.",
    "One-sentence Summary": "The paper addresses a key challenge of selecting the most representative clients iteratively for federated learning through formulating it as a submodular optimization problem and developing efficient algorithms."
  },
  {
    "title": "From Intervention to Domain Transportation: A Novel Perspective to Optimize Recommendation",
    "url": "/forum?id=jT1EwXu-4hj",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Information retrieval, Learning theory, Causal inference, Missing data, Overlapping, Reweighting, Optimal transport",
    "Abstract": "The interventional nature of recommendation has attracted increasing attention in recent years. It particularly motivates researchers to formulate learning and evaluating recommendation as causal inference and data missing-not-at-random problems. However, few take seriously the consequence of violating the critical assumption of overlapping, which we prove can significantly threaten the validity and interpretation of the outcome. We find a critical piece missing in the current understanding of information retrieval (IR) systems: as interventions, recommendation not only affects the already observed data, but it also interferes with the target domain (distribution) of interest. We then rephrase optimizing recommendation as finding an intervention that best transports the patterns it learns from the observed domain to its intervention domain. Towards this end, we use domain transportation to characterize the learning-intervention mechanism of recommendation. We design a principled transportation-constraint risk minimization objective and convert it to a two-player minimax game.\n        We prove the consistency, generalization, and excessive risk bounds for the proposed objective, and elaborate how they compare to the current results. Finally, we carry out extensive real-data and semi-synthetic experiments to demonstrate the advantage of our approach, and launch online testing with a real-world IR system.",
    "One-sentence Summary": "We propose and study a novel domain-transportation view for optimizing recommendation for information retrieval systems."
  },
  {
    "title": "Variational Predictive Routing with Nested Subjective Timescales",
    "url": "/forum?id=JxFgJbZ-wft",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Hierarchical temporal abstraction, event discovery, hierarchical generative models, variational inference",
    "Abstract": "Discovery and learning of an underlying spatiotemporal hierarchy in sequential data is an important topic for machine learning. Despite this, little work has been done to explore hierarchical generative models that can flexibly adapt their layerwise representations in response to datasets with different temporal dynamics. Here, we present Variational Predictive Routing (VPR) \u2013 a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy, based on their rates of change, thus modeling continuous data as a hierarchical renewal process. By employing an event detection mechanism that relies solely on the system\u2019s latent representations (without the need of a separate model), VPR is able to dynamically adjust its internal state following changes in the observed features, promoting an optimal organisation of representations across the levels of the model\u2019s latent hierarchy.  Using several video datasets, we show that VPR is able to detect event boundaries, disentangle spatiotemporal features across its hierarchy, adapt to the dynamics of the data, and produce accurate time-agnostic rollouts of the future. Our approach integrates insights from neuroscience and introduces a framework with high potential for applications in model-based reinforcement learning, where flexible and informative state-space rollouts are of particular interest.",
    "One-sentence Summary": "Variational inference hierarchical model that relies on a change detection mechanism to impose a nested temporal hierarchy on its latent structure."
  },
  {
    "title": "Sample and Computation Redistribution for Efficient Face Detection",
    "url": "/forum?id=RhB1AdoFfGE",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "efficient face detection, computation redistribution, sample redistribution",
    "Abstract": "Although tremendous strides have been made in uncontrolled face detection, accurate face detection with a low computation cost remains an open challenge. In this paper, we point out that computation distribution and scale augmentation are the keys to detecting small faces from low-resolution images. Motivated by these observations, we introduce two simple but effective methods: (1) Computation Redistribution (CR), which reallocates the computation between the backbone, neck and head of the model; and (2) Sample Redistribution (SR), which augments training samples for the most needed stages. The proposed Sample and Computation Redistribution for Face Detection (SCRFD) is implemented by a random search in a meticulously designed search space. Extensive experiments conducted on WIDER FACE demonstrate the state-of-the-art accuracy-efficiency trade-off for the proposed SCRFD family across a wide range of compute regimes. In particular, SCRFD-34GF outperforms the best competitor, TinaFace, by 4.78% (AP at hard set) while being more than 3\u00d7 faster on GPUs with VGA-resolution images. Code is available at: https://github.com/deepinsight/insightface/tree/master/detection/scrfd.",
    "One-sentence Summary": "We search for optimised computation distribution and training sample distribution for the task of face detection."
  },
  {
    "title": "Sound Adversarial Audio-Visual Navigation",
    "url": "/forum?id=NkZq4OEYN-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Audio-visual navigation task requires an agent to find a sound source in a realistic, unmapped 3D environment by utilizing egocentric audio-visual observations. Existing audio-visual navigation works assume a clean environment that solely contains the target sound, which, however, would not be suitable in most real-world applications due to the unexpected sound noise or intentional interference. In this work, we design an acoustically complex environment in which, besides the target sound, there exists a sound attacker playing a zero-sum game with the agent. More specifically, the attacker can move and change the volume and category of the sound to make the agent suffer from finding the sounding object while the agent tries to dodge the attack and navigate to the goal under the intervention. Under certain constraints to the attacker, we can improve the robustness of the agent towards unexpected sound attacks in audio-visual navigation. For better convergence, we develop a joint training mechanism by employing the property of a centralized critic with decentralized actors. Experiments on two real-world 3D scan datasets, Replica, and Matterport3D, verify the effectiveness and the robustness of the agent trained under our designed environment when transferred to the clean environment or the one containing sound attackers with random policy. Project: https://yyf17.github.io/SAAVN .",
    "One-sentence Summary": "This work aims to do an adversarial sound intervention for robust audio-visual navigation."
  },
  {
    "title": "Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations",
    "url": "/forum?id=12RoR2o32T",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "spurious correlations, out of distribution generalization, ml for health, representation learning",
    "Abstract": "In many prediction problems, spurious correlations are induced by a changing relationship between the label and a nuisance variable that is also correlated with the covariates. For example, in classifying animals in natural images, the background, which is a nuisance, can predict the type of animal. This nuisance-label relationship does not always hold, and the performance of a model trained under one such relationship may be poor on data with a different nuisance-label relationship. To build predictive models that perform well regardless of the nuisance-label relationship, we develop Nuisance-Randomized Distillation (NURD). We introduce the nuisance-randomized distribution, a distribution where the nuisance and the label are independent. Under this distribution, we define the set of representations such that conditioning on any member, the nuisance and the label remain independent. We prove that the representations in this set always perform better than chance, while representations outside of this set may not. NURD finds a representation from this set that is most informative of the label under the nuisance-randomized distribution, and we prove that this representation achieves the highest performance regardless of the nuisance-label relationship. We evaluate NURD on several tasks including chest X-ray classification where, using non-lung patches as the nuisance, NURD produces models that predict pneumonia under strong spurious correlations.",
    "One-sentence Summary": "This paper build models robust to nuisance-induced spurious correlations by constructing a representation that distills out the influence of the nuisance variables, while also maximizing its information with the label."
  },
  {
    "title": "AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis",
    "url": "/forum?id=OM_lYiHXiCL",
    "date": "28 Sept 2021 (modified: 24 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Deep neural networks (DNNs) are proved to be vulnerable against backdoor attacks. A backdoor could be embedded in the target DNNs through injecting a backdoor trigger into the training examples,  which can cause the target DNNs misclassify an input attached with the backdoor trigger. Recent backdoor detection methods often require the access to the original poisoned training data, the parameters of the target DNNs, or the predictive confidence for each given input, which are impractical in many real-world applications, e.g., on-device de-ployed DNNs. We address the black-box hard-label backdoor detection problem where the DNN is a fully black-box and only its final output label is accessible. We approach this problem from the optimization perspective and show that the objective of backdoor detection is bounded by an adversarial objective. Further theoretical and empirical studies reveal that this adversarial objective leads to a solution with highly skewed distribution;  a singularity is often observed in the adversarial map of a backdoor-infected example, which we call the adversarial singularity phenomenon. Based on this observation, we propose the adversarial extreme value analysis(AEVA) algorithm to detect backdoors in black-box neural networks. The AEVA algorithm is based on an extreme value analysis on the adversarial map, computed from the monte-carlo gradient estimation due to the black-box hard-label constraint. Evidenced by extensive experiments across three popular tasks and backdoor attacks, our approach is shown effective in detecting backdoor attacks under the black-box hard-label scenarios"
  },
  {
    "title": "Resonance in Weight Space: Covariate Shift Can Drive Divergence of SGD with Momentum",
    "url": "/forum?id=5ECQL05ub0J",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "optimization, momentum, stochastic gradient descent, non-iid sampling",
    "Abstract": "Most convergence guarantees for stochastic gradient descent with momentum (SGDm) rely on iid  sampling. Yet, SGDm is often used outside this regime, in settings with temporally correlated input samples such as continual learning and reinforcement learning. Existing work has shown that SGDm with a decaying step-size can converge under Markovian temporal correlation. In this work, we show that SGDm under covariate shift with a fixed step-size can be unstable and diverge. In particular, we show SGDm under covariate shift is a parametric oscillator, and so can suffer from a phenomenon known as resonance. We approximate the learning system as a time varying system of ordinary differential equations, and leverage existing theory to characterize the system's divergence/convergence as resonant/nonresonant modes. The theoretical result is limited to the linear setting with periodic covariate shift, so we empirically supplement this result to show that resonance phenomena persist even under non-periodic covariate shift, nonlinear dynamics with neural networks, and optimizers other than SGDm.",
    "One-sentence Summary": "We show that SGDm under covariate shift with fixed step-size can be unstable and diverge due to a phenomenon known as parametric resonance."
  },
  {
    "title": "Top-label calibration and multiclass-to-binary reductions",
    "url": "/forum?id=WqoBaaPHS-",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "calibration, multiclass, uncertainty quantification, distribution-free, histogram binning",
    "Abstract": "We propose a new notion of multiclass calibration called top-label calibration. A classifier is said to be top-label calibrated if the reported probability for the predicted class label---the top-label---is calibrated, conditioned on the top-label. This conditioning is essential for practical utility of the calibration property, since the top-label is always reported and we must condition on what is reported. However, the popular notion of confidence calibration erroneously skips this conditioning. Furthermore, we outline a multiclass-to-binary (M2B) reduction framework that unifies confidence, top-label, and class-wise calibration, among others. As its name suggests, M2B works by reducing multiclass calibration to different binary calibration problems; various types of multiclass calibration can then be achieved using simple binary calibration routines. We instantiate the M2B framework with the well-studied histogram binning (HB) binary calibrator, and prove that the overall procedure is multiclass calibrated without making any assumptions on the underlying data distribution. In an empirical evaluation with four deep net architectures on CIFAR-10 and CIFAR-100, we find that the M2B + HB procedure achieves lower top-label and class-wise calibration error than other approaches such as temperature scaling. Code for this work is available at https://github.com/aigen/df-posthoc-calibration.",
    "One-sentence Summary": "We propose top-label calibration, a new and arguably natural notion for multiclass calibration, along with 'wrapper' calibration algorithms that reduce multiclass calibration to binary calibration."
  },
  {
    "title": "Anisotropic Random Feature Regression in High Dimensions",
    "url": "/forum?id=JfaWawZ8BmX",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "random feature models, high dimensional asymptotics, generalization, learning curves, double descent, multiple descent, alignment",
    "Abstract": "In contrast to standard statistical wisdom, modern learning algorithms typically find their best performance in the overparameterized regime in which the model has many more parameters than needed to fit the training data. A growing number of recent works have shown that random feature models can offer a detailed theoretical explanation for this unexpected behavior, but typically these analyses have utilized isotropic distributional assumptions on the underlying data generation process, thereby failing to provide a realistic characterization of real-world models that are designed to identify and harness the structure in natural data. In this work, we examine the high-dimensional asymptotics of random feature regression in the presence of structured data, allowing for arbitrary input correlations and arbitrary alignment between the data and the weights of the target function. We define a partial order on the space of weight-data alignments and prove that generalization performance improves in response to stronger alignment. We also clarify several previous observations in the literature by distinguishing the behavior of the sample-wise and parameter-wise learning curves, finding that sample-wise multiple descent can occur at scales dictated by the eigenstructure of the data covariance, but that parameter-wise multiple descent is limited to double descent, although strong anisotropy can induce additional signatures such as wide plateaus and steep cliffs. Finally, these signatures are related to phase transitions in the spectrum of the feature kernel matrix, and unlike the double descent peak, persist even under optimal regularization.",
    "One-sentence Summary": "We derive exact asymptotic formulas for the total error, bias, and variance of random feature regression with anisotropic inputs and target weights, and identify a new type of singularity in sample-wise learning curves."
  },
  {
    "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future",
    "url": "/forum?id=L01Nn_VJ9i",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Epidemic Forecasting, Data revisions, Graph Representation learning, Time Series Forecasting",
    "Abstract": "For real-time forecasting in domains like public health and macroeconomics, data collection is a non-trivial and demanding task. Often after being initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches a stable value. This so-called \u2018backfill\u2019 phenomenon and its effect on model performance have been barely addressed in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. \n        We construct a detailed dataset composed of relevant signals over the past year of the pandemic. \n        We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework, Back2Future, that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of the diverse set of top models for COVID-19 forecasting and GDP growth forecasting. Specifically, we show that Back2Future refined top COVID-19 models by 6.65% to 11.24% and yield an 18% improvement over non-trivial baselines. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.",
    "One-sentence Summary": "We study the problem of multi-variate backfill for both features and targets and show how to leverage our insights for more general neural framework to improve both model predictions and evaluation"
  },
  {
    "title": "Approximation and Learning with Deep Convolutional Models: a Kernel Perspective",
    "url": "/forum?id=lrocYB-0ST2",
    "date": "28 Sept 2021 (modified: 18 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "kernel methods, deep learning theory, convolution, approximation, generalization",
    "Abstract": "The empirical success of deep convolutional networks on tasks involving high-dimensional data such as images or audio suggests that they can efficiently approximate certain functions that are well-suited for such tasks. In this paper, we study this through the lens of kernel methods, by considering simple hierarchical kernels with two or three convolution and pooling layers, inspired by convolutional kernel networks. These achieve good empirical performance on standard vision datasets, while providing a precise description of their functional space that yields new insights on their inductive bias. We show that the RKHS consists of additive models of interaction terms between patches, and that its norm encourages spatial similarities between these terms through pooling layers. We then provide generalization bounds which illustrate how pooling and patches yield improved sample complexity guarantees when the target function presents such regularities.",
    "One-sentence Summary": "We study the inductive bias of multi-layer convolutional models through a kernel lens, showing generalization benefits of various architectural choices such as locality, depth, and pooling layers."
  },
  {
    "title": "Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning",
    "url": "/forum?id=vgqS1vkkCbE",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "hierarchical reinforcement learning, planning, representation learning, robotics",
    "Abstract": "Reinforcement learning can train policies that effectively perform complex tasks. However for long-horizon tasks, the performance of these methods degrades with horizon, often necessitating reasoning over and chaining lower-level skills. Hierarchical reinforcement learning aims to enable this by providing a bank of low-level skills as action abstractions. Hierarchies can further improve on this by abstracting the space states as well. We posit that a suitable state abstraction should depend on the capabilities of the available lower-level policies. We propose Value Function Spaces: a simple approach that produces such a representation by using the value functions corresponding to each lower-level skill. These value functions capture the affordances of the scene, thus forming a  representation that compactly abstracts task relevant information and robustly ignores distractors. Empirical evaluations for maze-solving and robotic manipulation tasks demonstrate that our approach improves long-horizon performance and enables better zero-shot generalization than alternative model-free and model-based methods.",
    "One-sentence Summary": "We introduce value function spaces, a learned representation of state through the values of low-level skills, which capture affordances and ignores distractors to enable long-horizon reasoning and zero-shot generalization."
  },
  {
    "title": "Fast Regression for Structured Inputs",
    "url": "/forum?id=gNp54NxHUPJ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "regression, sublinear time algorithm, structured input",
    "Abstract": "We study the \u2113p regression problem, which requires finding x\u2208Rd that minimizes \u2225Ax\u2212b\u2225p for a matrix A\u2208Rn\u00d7d and response vector b\u2208Rn. There has been recent interest in developing subsampling methods for this problem that can outperform standard techniques when n is very large. However, all known subsampling approaches have run time that depends exponentially on p, typically, dO(p), which can be prohibitively expensive. \n        \n        We improve on this work by showing that for a large class of common \\emph{structured matrices}, such as combinations of low-rank matrices, sparse matrices, and Vandermonde matrices, there are subsampling based methods for \u2113p regression that depend polynomially on p. For example, we give an algorithm for \u2113p regression on Vandermonde matrices that runs in time O(nlog3\u2061n+(dp2)0.5+\u03c9\u22c5polylogn), where \u03c9 is the exponent of matrix multiplication. The polynomial dependence on p crucially allows our algorithms to extend naturally to efficient algorithms for \u2113\u221e regression, via approximation of \u2113\u221e by \u2113O(log\u2061n). Of practical interest, we also develop a new subsampling algorithm for \u2113p regression for arbitrary matrices, which is simpler than previous approaches for p\u22654."
  },
  {
    "title": "CrossBeam: Learning to Search in Bottom-Up Program Synthesis",
    "url": "/forum?id=qhC8mr2LEKq",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Program Synthesis, Bottom-Up Search",
    "Abstract": "Many approaches to program synthesis perform a search within an enormous space of programs to find one that satisfies a given specification. Prior works have used neural models to guide combinatorial search algorithms, but such approaches still explore a huge portion of the search space and quickly become intractable as the size of the desired program increases. To tame the search space blowup, we propose training a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm. Our approach, called CrossBeam, uses the neural model to choose how to combine previously-explored programs into new programs, taking into account the search history and partial program executions. Motivated by work in structured prediction on learning to search, CrossBeam is trained on-policy using data extracted from its own bottom-up searches on training tasks. We evaluate CrossBeam in two very different domains, string manipulation and logic programming. We observe that CrossBeam learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.",
    "One-sentence Summary": "We propose training a neural model to learn a hands-on search policy for bottom-up program synthesis, in an effort to tame the search space blowup."
  },
  {
    "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning",
    "url": "/forum?id=M6M8BEmd6dq",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Differential Privacy, Generative Model",
    "Abstract": "We propose a new framework of synthesizing data using deep generative models in a differentially private manner.\n        Within our framework, sensitive data are sanitized with rigorous privacy guarantees in a one-shot fashion, such that training deep generative models is possible without re-using the original data.\n        Hence, no extra privacy costs or model constraints are incurred, in contrast to popular gradient sanitization approaches, which, among other issues, cause degradation in privacy guarantees as the training iteration increases.\n        We demonstrate a realization of our framework by making use of the characteristic function and an adversarial re-weighting objective, which are of independent interest as well.\n        Our proposal has theoretical guarantees of performance, and empirical evaluations on multiple datasets show that our approach outperforms other methods at reasonable levels of privacy."
  },
  {
    "title": "Divisive Feature Normalization Improves Image Recognition Performance in AlexNet",
    "url": "/forum?id=aOX3a9q3RVV",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "divisive normalization, AlexNet, ImageNet, CIFAR-100, manifold capacity, sparsity, receptive fields, Batch Normalization, Group Normalization, Layer Normalization",
    "Abstract": "Local divisive normalization provides a phenomenological description of many nonlinear response properties of neurons across visual cortical areas. To gain insight into the utility of this operation, we studied the effects on AlexNet of a local divisive normalization between features, with learned parameters. Developing features were arranged in a line topology, with the influence between features determined by an exponential function of the distance between them. We compared an AlexNet model with no normalization or with canonical normalizations (Batch, Group, Layer) to the same models with divisive normalization added. Divisive normalization always improved performance for models with batch or group or no normalization, generally by 1-2 percentage points, on both the CIFAR-100 and ImageNet databases. To gain insight into mechanisms underlying the improved performance, we examined several aspects of network representations. In the early layers both canonical and divisive normalizations reduced manifold capacities and increased average dimension of the individual categorical manifolds. In later layers the capacity was higher and manifold dimension lower for models roughly in order of their performance improvement. Examining the sparsity of activations across a given layer, divisive normalization layers increased sparsity, while the canonical normalization layers decreased it. Nonetheless, in the final layer, the sparseness of activity increased in the order of no normalization, divisive, com- bined, and canonical. We also investigated how the receptive fields (RFs) in the first convolutional layer (where RFs are most interpretable) change with normalization. Divisive normalization enhanced RF Fourier power at low wavelengths, while divisive+canonical enhanced power at mid (batch, group) or low (layer) wavelengths, compared to canonical alone or no normalization. In conclusion, divisive normalization enhances image recognition performance, most strongly when combined with canonical normalization, and in doing so it reduces manifold capacity and sparsity in early layers while increasing them in final layers, and increases low- or mid-wavelength power in the first-layer receptive fields.",
    "One-sentence Summary": "DIVISIVE FEATURE NORMALIZATION IMPROVES IMAGE RECOGNITION PERFORMANCE AND IN- CREASES MANIFOLD CAPACITY, SPARSITY, AND LOW-FREQUENCY REPRESENTATION IN DEEP NETS"
  },
  {
    "title": "Evaluating Distributional Distortion in Neural Language Modeling",
    "url": "/forum?id=bTteFbU99ye",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "A fundamental characteristic of natural language is the high rate at which speakers produce novel expressions. Because of this novelty, a heavy-tail of rare events accounts for a significant amount of the total probability mass of distributions in language (Baayen, 2001). Standard language modeling metrics such as perplexity quantify the performance of language models (LM) in aggregate.  As a result, we have relatively little understanding of whether neural LMs accurately estimate the probability of sequences in this heavy-tail of rare events. To address this gap, we develop a controlled evaluation scheme which uses generative models trained on natural data as artificial languages from which we can exactly compute sequence probabilities. Training LMs on generations from these artificial languages, we compare the sequence-level probability estimates given by LMs to the true probabilities in the target language. Our experiments reveal that LSTM and Transformer language models (i) systematically underestimate the probability of sequences drawn from the target language, and (ii) do so more severely for less-probable sequences. Investigating where this probability mass went, (iii) we find that LMs tend to overestimate the probability of ill formed (perturbed) sequences. In addition, we find that this underestimation behaviour (iv) is weakened, but not eliminated by greater amounts of training data, and (v) is exacerbated for target distributions with lower entropy."
  },
  {
    "title": "MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining",
    "url": "/forum?id=r5qumLiYwf9",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep Generative Networks, Uniform Sampling, Fairness, Data Augmentation",
    "Abstract": "Deep Generative Networks (DGNs) are extensively employed in Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and their variants to approximate the data manifold, and data distribution on that manifold. However, training samples are often obtained based on preferences, costs, or convenience producing artifacts in the empirical data distribution e.g. the large fraction of smiling faces in the CelebA dataset or the large fraction of dark-haired individuals in FFHQ). {\\em These inconsistencies will be reproduced when sampling from the trained DGN, which has far-reaching potential implications for fairness, data augmentation, anomaly detection, domain adaptation, and beyond.} In response, we develop a differential geometry based sampler -coined MaGNET- that, given any trained DGN, produces samples that are uniformly distributed on the learned manifold. We prove theoretically and empirically that our technique produces a uniform distribution on the manifold regardless of the training set distribution. We perform a range of experiments on various datasets and DGNs. One of them considers the state-of-the-art StyleGAN2 trained on FFHQ dataset, where uniform sampling via MaGNET increases distribution precision \\& recall by 4.12\\% \\& 3.01\\% and decreases gender bias by 41.2\\%, without requiring labels or retraining.",
    "One-sentence Summary": "We propose a differential-geometry-based technique to provably sample uniformly from the data manifold of a trained Deep Generative Network without the need for retraining."
  },
  {
    "title": "Neural Contextual Bandits with Deep Representation and Shallow Exploration",
    "url": "/forum?id=xnYACQquaGV",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural network, deep representation learning",
    "Abstract": "We study neural contextual bandits, a general class of contextual bandits, where each context-action pair is associated with a raw feature vector, but the specific reward generating function is unknown. We propose a novel learning algorithm that transforms the raw feature vector using the last hidden layer of a deep ReLU neural network (deep representation learning), and uses an upper confidence bound (UCB) approach to explore in the last linear layer (shallow exploration). We prove that under standard assumptions, our proposed algorithm achieves O~(T) finite-time regret, where T is the learning time horizon. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network.",
    "One-sentence Summary": "A new neural network based algorithm for contextual bandit problems with theoretical guarantees and empirical advantages."
  },
  {
    "title": "PI3NN: Out-of-distribution-aware Prediction Intervals from Three Neural Networks",
    "url": "/forum?id=NoB8YgRuoFU",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We propose a novel prediction interval (PI) method for uncertainty quantification, which addresses three major issues with the state-of-the-art PI methods. First, existing PI methods require retraining of neural networks (NNs) for every given confidence level and suffer from the crossing issue in calculating multiple PIs. Second, they usually rely on customized loss functions with extra sensitive hyperparameters for which fine tuning is required to achieve a well-calibrated PI. Third, they usually underestimate uncertainties of out-of-distribution (OOD) samples leading to over-confident PIs. Our PI3NN method calculates PIs from linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root-finding algorithms to ensure tight PIs for a given confidence level. We theoretically prove that PI3NN can calculate PIs for a series of confidence levels without retraining NNs and it completely avoids the crossing issue. Additionally, PI3NN does not introduce any unusual hyperparameters resulting in a stable performance. Furthermore, we address OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in-distribution samples. Benchmark and real-world experiments show that our method outperforms several state-of-the-art approaches with respect to predictive uncertainty quality, robustness, and OOD samples identification."
  },
  {
    "title": "Discriminative Similarity for Data Clustering",
    "url": "/forum?id=kj0_45Y4r9i",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Discriminative Similarity, Rademacher Complexity, Generalization Bound, Data Clustering",
    "Abstract": "Similarity-based clustering methods separate data into clusters according to the pairwise similarity between the data, and the pairwise similarity is crucial for their performance. In this paper, we propose {\\em Clustering by  Discriminative Similarity (CDS)}, a novel method which learns discriminative similarity for data clustering. CDS learns an unsupervised similarity-based classifier from each data partition, and searches for the optimal partition of the data by minimizing the generalization error of the learnt classifiers associated with the data partitions. By generalization analysis via Rademacher complexity, the generalization error bound for the unsupervised similarity-based classifier is expressed as the sum of discriminative similarity between the data from different classes. It is proved that the derived discriminative similarity can also be induced by the integrated squared error bound for kernel density classification. In order to evaluate the performance of the proposed discriminative similarity, we propose a new clustering method using a kernel as the similarity function, CDS via unsupervised kernel classification (CDSK), with its effectiveness demonstrated by experimental results.",
    "One-sentence Summary": "We present a novel discriminative similarity for data clustering, and the discriminative similarity is induced by generalization error bound for unsupervised classifier"
  },
  {
    "title": "It Takes Four to Tango: Multiagent Self Play for Automatic Curriculum Generation",
    "url": "/forum?id=q4tZR1Y-UIs",
    "date": "28 Sept 2021 (modified: 21 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "curriculum generation, unsupervised reinforcement learning, goal conditioned reinforcement learning, multi agent",
    "Abstract": "We are interested in training general-purpose reinforcement learning agents that can solve a wide variety of goals. Training such agents efficiently requires automatic generation of a goal curriculum. This is challenging as it requires (a) exploring goals of increasing difficulty, while ensuring that the agent (b) is exposed to a diverse set of goals in a sample efficient manner and (c) does not catastrophically forget previously solved goals. We propose Curriculum Self Play (CuSP), an automated goal generation framework that seeks to satisfy these desiderata by virtue of a multi-player game with 4 agents. We extend the asymmetric curricula learning in PAIRED (Dennis et al., 2020) to a symmetrized game that carefully balances cooperation and competition between two off-policy student learners and two regret-maximizing teachers. CuSP additionally introduces entropic goal coverage and accounts for the non-stationary nature of the students, allowing us to automatically induce a curriculum that balances progressive exploration with anti-catastrophic exploitation. We demonstrate that our method succeeds at generating an effective curricula of goals for a range of control tasks, outperforming other methods at zero-shot test-time generalization to novel out-of-distribution goals."
  },
  {
    "title": "CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing",
    "url": "/forum?id=HOjLHrlZhmx",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "As reinforcement learning (RL) has achieved great success and been even adopted in safety-critical domains such as autonomous vehicles, a range of empirical studies have been conducted to improve its robustness against adversarial attacks. However, how to certify its robustness with theoretical guarantees still remains challenging. In this paper, we present the \ufb01rst uni\ufb01ed framework CROP (Certifying Robust Policies for RL) to provide robustness certi\ufb01cation on both action and reward levels. In particular, we propose two robustness certi\ufb01cation criteria: robustness of per-state actions and lower bound of cumulative rewards. We then develop a local smoothing algorithm for policies derived from Q-functions to guarantee the robustness of actions taken along the trajectory; we also develop a global smoothing algorithm for certifying the lower bound of a \ufb01nite-horizon cumulative reward, as well as a novel local smoothing algorithm to perform adaptive search in order to obtain tighter reward certi\ufb01cation. Empirically, we apply CROP to evaluate several existing empirically robust RL algorithms, including adversarial training and different robust regularization, in four environments (two representative Atari games, Highway, and CartPole). Furthermore, by evaluating these algorithms against adversarial attacks, we demonstrate that our certi\ufb01cations are often tight. All experiment results are available at website https://crop-leaderboard.github.io."
  },
  {
    "title": "Neural Link Prediction with Walk Pooling",
    "url": "/forum?id=CCu6RcUMwK0",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph neural network, Link prediction, Random walk, Graph topology.",
    "Abstract": "Graph neural networks achieve high accuracy in link prediction by jointly leveraging graph topology and node attributes. Topology, however, is represented indirectly; state-of-the-art methods based on subgraph classification label nodes with distance to the target link, so that, although topological information is present, it is tempered by pooling. This makes it challenging to leverage features like loops and motifs associated with network formation mechanisms. We propose a link prediction algorithm based on a new pooling scheme called WalkPool. WalkPool combines the expressivity of topological heuristics with the feature-learning ability of neural networks. It summarizes a putative link by random walk probabilities of adjacent paths. Instead of extracting transition probabilities from the original graph, it computes the transition matrix of a ``predictive'' latent graph by applying attention to learned features; this may be interpreted as feature-sensitive topology fingerprinting. WalkPool can leverage unsupervised node features or be combined with GNNs and trained end-to-end. It outperforms state-of-the-art methods on all common link prediction benchmarks, both homophilic and heterophilic, with and without node attributes. Applying WalkPool to a set of unsupervised GNNs significantly improves prediction accuracy, suggesting that it may be used as a general-purpose graph pooling scheme."
  },
  {
    "title": "On the Convergence of Certified Robust Training with Interval Bound Propagation",
    "url": "/forum?id=YeShU5mLfLt",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Certified robustness, Adversarial robustness, Convergence",
    "Abstract": "Interval Bound Propagation (IBP) is so far the base of state-of-the-art methods for training neural networks with certifiable robustness guarantees when potential adversarial perturbations present, while the convergence of IBP training remains unknown in existing literature. In this paper, we present a theoretical analysis on the convergence of IBP training. With an overparameterized assumption, we analyze the convergence of IBP robust training. We show that when using  IBP training to train a randomly initialized two-layer ReLU neural network with logistic loss, gradient descent can linearly converge to zero robust training error with a high probability if  we have sufficiently small perturbation radius and large network width.",
    "One-sentence Summary": "We present the first theoretical analysis on the convergence of certified robust training with interval bound propagation."
  },
  {
    "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators",
    "url": "/forum?id=sX3XaHwotOg",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Language Model Pretraining",
    "Abstract": "We present a new framework AMOS that pretrains text encoders with an Adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators. Following ELECTRA-style pretraining, the main encoder is trained as a discriminator to detect replaced tokens generated by auxiliary masked language models (MLMs). Different from ELECTRA which trains one MLM as the generator, we jointly train multiple MLMs of different sizes to provide training signals at various levels of difficulty. To push the discriminator to learn better with challenging replaced tokens, we learn mixture weights over the auxiliary MLMs' outputs to maximize the discriminator loss by backpropagating the gradient from the discriminator via Gumbel-Softmax. For better pretraining efficiency, we propose a way to assemble multiple MLMs into one unified auxiliary model. AMOS outperforms ELECTRA and recent state-of-the-art pretrained models by about 1 point on the GLUE benchmark for BERT base-sized models.",
    "One-sentence Summary": "We present AMOS, a new method that pretrains text encoders with an Adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators."
  },
  {
    "title": "Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations",
    "url": "/forum?id=0jP2n0YFmKG",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Atomic Simulations, Computational Chemistry",
    "Abstract": "Recent progress in Graph Neural Networks (GNNs) for modeling atomic simulations has the potential to revolutionize catalyst discovery, which is a key step in making progress towards the energy breakthroughs needed to combat climate change. However, the GNNs that have proven most effective for this task are memory intensive as they model higher-order interactions in the graphs such as those between triplets or quadruplets of atoms, making it challenging to scale these models. In this paper, we introduce Graph Parallelism, a method to distribute input graphs across multiple GPUs, enabling us to train very large GNNs with hundreds of millions or billions of parameters. We empirically evaluate our method by scaling up the recently proposed DimeNet++ and GemNet models by over an order of magnitude in the number of parameters. On the large-scale Open Catalyst 2020 (OC20) dataset, these graph-parallelized models lead to relative improvements of 1) 15% on the force MAE metric on the S2EF task and 2) 21% on the AFbT metric on the IS2RS task, establishing new state-of-the-art results.",
    "One-sentence Summary": "We scale GNNs used for modeling atomic simulations by an order of magnitude and obtain large performance improvements on the Open Catalyst 2020 dataset."
  },
  {
    "title": "Understanding and Leveraging Overparameterization in Recursive Value Estimation",
    "url": "/forum?id=shbAgEsk3qM",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Temporal Difference Learning, Residual Minimization, Value Estimation, Overparameterization",
    "Abstract": "The theory of function approximation in reinforcement learning (RL) typically considers low capacity representations that incur a tradeoff between approximation error, stability and generalization.  Current deep architectures, however, operate in an overparameterized regime where approximation error is not necessarily a bottleneck.  To better understand the utility of deep models in RL we present an analysis of recursive value estimation using \\emph{overparameterized} linear representations that provides useful, transferable findings.  First, we show that classical updates such as temporal difference (TD) learning or fitted-value-iteration (FVI) converge to \\emph{different} fixed points than residual minimization (RM) in the overparameterized linear case.  We then develop a unified interpretation of overparameterized linear value estimation as minimizing the Euclidean norm of the weights subject to alternative constraints.  A practical consequence is that RM can be modified by a simple alteration of the backup targets to obtain the same fixed points as FVI and TD (when they converge), while universally ensuring stability.  Further, we provide an analysis of the generalization error of these methods, demonstrating per iterate bounds on the value prediction error of FVI, and fixed point bounds for TD and RM.  \n        Given this understanding, we then develop new algorithmic tools for improving recursive value estimation with deep models. \n        In particular, we extract two regularizers that penalize out-of-span top-layer weights and co-linearity in top-layer features respectively.  Empirically we find that these regularizers dramatically improve the stability of TD and FVI, while allowing RM to match and even sometimes surpass their generalization performance with assured stability.",
    "One-sentence Summary": "We present an analysis of value estimation under overparameterized linear representations, and develop new algorithmic tools for improving recursive value estimation with deep models based on the new findings."
  },
  {
    "title": "Optimization and Adaptive Generalization of Three layer Neural Networks",
    "url": "/forum?id=dPyRNUlttBv",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep learning theory, adaptive kernel, robust deep learning, neural tangent kernel, adaptive generalization, non-convex optimization",
    "Abstract": "While there has been substantial recent work studying  generalization of neural networks, \n        the ability of deep nets in automating the process of feature extraction still evades a thorough mathematical understanding.  \n        As a step toward this goal, we analyze learning and generalization of a three-layer neural network with ReLU activations in a regime that goes beyond the linear approximation of the network, and is hence not captured by the common Neural Tangent Kernel. We show that despite nonconvexity of the empirical loss, a variant of SGD converges in polynomially many iterations to a good solution that generalizes. In particular, our generalization bounds are adaptive: they automatically optimize over a family of kernels that includes the Neural Tangent Kernel, to provide the tightest bound.",
    "One-sentence Summary": "Algorithmically obtaining noise-robust and adaptive generalization bounds for a three layer network model by going beyond the linear approximation of the network"
  },
  {
    "title": "Non-Parallel Text Style Transfer with Self-Parallel Supervision",
    "url": "/forum?id=-TSe5o7STVR",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "style transfer, non-parallel corpus, imitation learning, language models, political stance transfer",
    "Abstract": "The performance of existing text style transfer models is severely limited by the non-parallel datasets on which the models are trained. In non-parallel datasets, no direct mapping exists between sentences of the source and target style; the style transfer models thus only receive weak supervision of the target sentences during training, which often leads the model to discard too much style-independent information, or utterly fail to transfer the style.\n        \n        In this work, we propose LaMer, a novel text style transfer framework based on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer) and a newly proposed challenging task (political stance transfer), our model achieves qualitative advances in transfer accuracy, content preservation, and fluency. Further empirical and human evaluations demonstrate that our model not only makes training more efficient, but also generates more readable and diverse expressions than previous models.",
    "One-sentence Summary": "We propose a new text style transfer model for non-parallel corpus with supervision from intrinsic parallelism."
  },
  {
    "title": "Can an Image Classifier Suffice For Action Recognition?",
    "url": "/forum?id=qhkFX-HLuHV",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "action recognition, image classifier, super image, vision transformer",
    "Abstract": "We explore a new perspective on video understanding by casting the video recognition problem as an image recognition task. Our approach rearranges input video frames into super images, which allow for training an image classifier directly to fulfill the task of action recognition, in exactly the same way as image classification. With such a simple idea, we show that transformer-based image classifiers alone can suffice for action recognition. In particular, our approach demonstrates strong and promising performance against SOTA methods on several public datasets including Kinetics400, Moments In Time, Something-Something V2 (SSV2), Jester and Diving48. We also experiment with the prevalent ResNet image classifiers in computer vision to further validate our idea. The results on both Kinetics400 and SSV2 are comparable to some of the best-performed CNN approaches based on spatio-temporal modeling. Our source codes and models are available at \\url{https://github.com/IBM/sifar-pytorch}.",
    "One-sentence Summary": "We propose the idea of super images to re-purpose an image classifer for action recognition."
  },
  {
    "title": "Interacting Contour Stochastic Gradient Langevin Dynamics",
    "url": "/forum?id=IK9ap6nxXr2",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "stochastic gradient Langevin dynamics, MCMC, importance sampling, Wang-Landau algorithm, Parallel MCMC Methods, stochastic approximation",
    "Abstract": "We propose an interacting contour stochastic gradient Langevin dynamics (ICSGLD) sampler, an embarrassingly parallel multiple-chain contour stochastic gradient Langevin dynamics (CSGLD) sampler with efficient interactions. We show that ICSGLD can be theoretically more efficient than a single-chain CSGLD with an equivalent computational budget. We also present a novel random-field function, which facilitates the estimation of self-adapting parameters in big data and obtains free mode explorations. Empirically, we compare the proposed algorithm with popular benchmark methods for posterior sampling. The numerical results show a great potential of ICSGLD for large-scale uncertainty estimation tasks.",
    "One-sentence Summary": "We propose an interacting contour stochastic gradient Langevin dynamics sampler and prove it can be theoretically more efficient than a single-chain process with an equivalent computational budget."
  },
  {
    "title": "NeuPL: Neural Population Learning",
    "url": "/forum?id=MIX3fJkl_1",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multi-Agent Learning, Game Theory, Population Learning",
    "Abstract": "Learning in strategy games (e.g. StarCraft, poker) requires the discovery of diverse policies. This is often achieved by iteratively training new policies against existing ones, growing a policy population that is robust to exploit. This iterative approach suffers from two issues in real-world games: a) under finite budget, approximate best-response operators at each iteration needs truncating, resulting in under-trained good-responses populating the population; b) repeated learning of basic skills at each iteration is wasteful and becomes intractable in the presence of increasingly strong opponents. In this work, we propose Neural Population Learning (NeuPL) as a solution to both issues. NeuPL offers convergence guarantees to a population of best-responses under mild assumptions. By representing a population of policies within a single conditional model, NeuPL enables transfer learning across policies. Empirically, we show the generality, improved performance and efficiency of NeuPL across several test domains. Most interestingly, we show that novel strategies become more accessible, not less, as the neural population expands.",
    "One-sentence Summary": "We propose NeuPL, a general and efficient population learning framework that learns and represents diverse policies in symmetric zero-sum games within a single conditional network via self-play."
  },
  {
    "title": "DeSKO: Stability-Assured Robust Control with a Deep Stochastic Koopman Operator",
    "url": "/forum?id=hniLRD_XCA",
    "date": "28 Sept 2021 (modified: 21 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Koopman Operator, Robust Control, Robotics, Model Predictive Control, Soft Robotics",
    "Abstract": "The Koopman operator theory linearly describes nonlinear dynamical systems in a high-dimensional functional space and it allows to apply linear control methods to highly nonlinear systems. However, the Koopman operator does not account for any uncertainty in dynamical systems, causing it to perform poorly in real-world applications.\n        Therefore, we propose a deep stochastic Koopman operator (DeSKO) model in a robust learning control framework to guarantee stability of nonlinear stochastic systems. The DeSKO model captures a dynamical system's uncertainty by inferring a distribution of observables. We use the inferred distribution to design a robust, stabilizing closed-loop controller for a dynamical system. Modeling and control experiments on several advanced control benchmarks show that our framework is more robust and scalable than state-of-the-art deep Koopman operators and reinforcement learning methods. Tested control benchmarks include a soft robotic arm, a legged robot, and a biological gene regulatory network. We also demonstrate that this robust control method resists previously unseen uncertainties, such as external disturbances, with a magnitude of up to five times the maximum control input. Our approach opens up new possibilities in learning control for high-dimensional nonlinear systems while robustly managing internal or external uncertainty.",
    "One-sentence Summary": "A robust learning control framework with guarantee stability based on deep stochastic Koopman operator models"
  },
  {
    "title": "Neural Network Approximation based on Hausdorff distance of Tropical Zonotopes",
    "url": "/forum?id=oiZJwC_fyS",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Tropical Geometry, Zonotopes, Hausdorff Approximation, Neural Network Compression",
    "Abstract": "In this work we theoretically contribute to neural network approximation by providing a novel tropical geometrical viewpoint to structured neural network compression. In particular, we show that the approximation error between two neural networks with ReLU activations and one hidden layer depends on the Hausdorff distance of the tropical zonotopes of the networks. This theorem comes as a first step towards a purely geometrical interpretation of neural network approximation. Based on this theoretical contribution, we propose geometrical methods that employ the K-means algorithm to compress the fully connected parts of ReLU activated deep neural networks. We analyze the error bounds of our algorithms theoretically based on our approximation theorem and evaluate them empirically on neural network compression. Our experiments follow a proof-of-concept strategy and indicate that our geometrical tools achieve improved performance over relevant tropical geometry techniques and can be competitive against non-tropical methods."
  },
  {
    "title": "Learning Towards The Largest Margins",
    "url": "/forum?id=hqkhcFHOeKD",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "loss function design, margin-based loss, classification",
    "Abstract": "One of the main challenges for feature representation in deep learning-based classification is the design of appropriate loss functions that exhibit strong discriminative power. The classical softmax loss does not explicitly encourage discriminative learning of features. A popular direction of research is to incorporate margins in well-established losses in order to enforce extra intra-class compactness and inter-class separability, which, however, were developed through heuristic means, as opposed to rigorous mathematical principles. In this work, we attempt to address this limitation by formulating the principled optimization objective as learning towards the largest margins. Specifically, we firstly propose to employ the class margin as the measure of inter-class separability, and the sample margin as the measure of intra-class compactness. Accordingly, to encourage discriminative representation of features, the loss function should promote the largest possible margins for both classes and samples. Furthermore, we derive a generalized margin softmax loss to draw general conclusions for the existing margin-based losses. Not only does this principled framework offer new perspectives to understand and interpret existing margin-based losses, but it also provides new insights that can guide the design of new tools, including \\textit{sample margin regularization} and \\textit{largest margin softmax loss} for class balanced cases, and \\textit{zero centroid regularization} for class imbalanced cases. Experimental results demonstrate the effectiveness of our strategy for multiple tasks including visual classification, imbalanced classification, person re-identification, and face verification."
  },
  {
    "title": "Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?",
    "url": "/forum?id=28ib9tf6zhr",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Vision transformer, adversarial examples, robustness",
    "Abstract": "Vision transformers (ViTs) have recently set off a new wave in neural architecture design thanks to their record-breaking performance in various vision tasks. In parallel, to fulfill the goal of deploying ViTs into real-world vision applications, their robustness against potential malicious attacks has gained increasing attention. In particular, recent works show that ViTs are more robust against adversarial attacks as compared with convolutional neural networks (CNNs), and conjecture that this is because ViTs focus more on capturing global interactions among different input/feature patches, leading to their improved robustness to local perturbations imposed by adversarial attacks. In this work, we ask an intriguing question: \"Under what kinds of perturbations do ViTs become more vulnerable learners compared to CNNs?\" Driven by this question, we first conduct a comprehensive experiment regarding the robustness of both ViTs and CNNs under various existing adversarial attacks to understand the underlying reason favoring their robustness. Based on the drawn insights, we then propose a dedicated attack framework, dubbed Patch-Fool, that fools the self-attention mechanism by attacking its basic component (i.e., a single patch) with a series of attention-aware optimization techniques. Interestingly, our Patch-Fool framework shows for the first time that ViTs are not necessarily more robust than CNNs against adversarial perturbations. In particular, we find that ViTs are more vulnerable learners compared with CNNs against our Patch-Fool attack which is consistent across extensive experiments, and the observations from Sparse/Mild Patch-Fool, two variants of Patch-Fool, indicate an intriguing insight that the perturbation density and strength on each patch seem to be the key factors that influence the robustness ranking between ViTs and CNNs. It can be expected that our Patch-Fool framework will shed light on both future architecture designs and training schemes for robustifying ViTs towards their real-world deployment. Our codes are available at https://github.com/RICE-EIC/Patch-Fool.",
    "One-sentence Summary": "We propose the Patch-Fool attack to unveil a vulnerability perspective of ViTs."
  },
  {
    "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation",
    "url": "/forum?id=Q5uh1Nvv5dm",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "unsupervised domain adaptation, semi-supervised learning, semi-supervised domain adaptation",
    "Abstract": "We extend semi-supervised learning to the problem of domain adaptation to learn significantly higher-accuracy models that train on one data distribution and test on a different one. With the goal of generality, we introduce AdaMatch, a unified solution for unsupervised domain adaptation (UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation (SSDA). In an extensive experimental study, we compare its behavior with respective state-of-the-art techniques from SSL, SSDA, and UDA and find that AdaMatch either matches or significantly exceeds the state-of-the-art in each case using the same hyper-parameters regardless of the dataset or task. For example, AdaMatch nearly doubles the accuracy compared to that of the prior state-of-the-art on the UDA task for DomainNet and even exceeds the accuracy of the prior state-of-the-art obtained with pre-training by 6.4% when AdaMatch is trained completely from scratch. Furthermore, by providing AdaMatch with just one labeled example per class from the target domain (i.e., the SSDA setting), we increase the target accuracy by an additional 6.1%, and with 5 labeled examples, by 13.6%.",
    "One-sentence Summary": "We introduce AdaMatch, a unified solution that achieves state-of-the-art results for unsupervised domain adaptation (UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation (SSDA)."
  },
  {
    "title": "Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound",
    "url": "/forum?id=l_amHf1oaK",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Certified Robustness, Branch-and-Bound, Convex Relaxation",
    "Abstract": "State-of-the-art neural network verifiers are fundamentally based on one of two paradigms: either encoding the whole verification problem via tight multi-neuron convex relaxations or applying a Branch-and-Bound (BaB) procedure leveraging imprecise but fast bounding methods on a large number of easier subproblems. The former can capture complex multi-neuron dependencies but sacrifices completeness due to the inherent limitations of convex relaxations. The latter enables complete verification but becomes increasingly ineffective on larger and more challenging networks. In this work, we present a novel complete verifier which combines the strengths of both paradigms: it leverages multi-neuron relaxations to drastically reduce the number of subproblems generated during the BaB process and an efficient GPU-based dual optimizer to solve the remaining ones. An extensive evaluation demonstrates that our verifier achieves a new state-of-the-art on both established benchmarks as well as networks with significantly higher accuracy than previously considered. The latter result (up to 28% certification gains) indicates meaningful progress towards creating verifiers that can handle practically relevant networks.",
    "One-sentence Summary": "We obtain a state-of-the-art GPU-based neural network verifier by leveraging tight multi-neuron constraints in a Branch-and-Bound setting."
  },
  {
    "title": "Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality",
    "url": "/forum?id=VFBjuF8HEp",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Diffusion models have emerged as an expressive family of generative models rivaling GANs in sample quality and autoregressive models in likelihood scores. Standard diffusion models typically require hundreds of forward passes through the model to generate a single high-fidelity sample. We introduce Differentiable Diffusion Sampler Search (DDSS): a method that optimizes fast samplers for any pre-trained diffusion model by differentiating through sample quality scores. We also present Generalized Gaussian Diffusion Models (GGDM), a family of flexible non-Markovian samplers for diffusion models. We show that optimizing the degrees of freedom of GGDM samplers by maximizing sample quality scores via gradient descent leads to improved sample quality. Our optimization procedure backpropagates through the sampling process using the reparametrization trick and gradient rematerialization. DDSS achieves strong results on unconditional image generation across various datasets (e.g., FID scores on LSUN church 128x128 of 11.6 with only 10 inference steps, and 4.82 with 20 steps, compared to 51.1 and 14.9 with strongest DDPM/DDIM baselines). Our method is compatible with any pre-trained diffusion model without fine-tuning or re-training required.",
    "One-sentence Summary": "We propose a method to discover fast, high-fidelity samplers for diffusion probabilistic models."
  },
  {
    "title": "Distribution Compression in Near-Linear Time",
    "url": "/forum?id=lzupY5zjaU9",
    "date": "28 Sept 2021 (modified: 25 Jun 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Distribution compression, linear time, thinning, i.i.d. sampling, Markov chain Monte Carlo, maximum mean discrepancy, reproducing kernel Hilbert space",
    "Abstract": "In distribution compression, one aims to accurately summarize a probability distribution $\\mathbb{P}$ using a small number of representative points. Near-optimal thinning procedures achieve this goal by sampling $n$ points from a Markov chain and identifying $\\sqrt{n}$ points with $\\widetilde{\\mathcal{O}}(1/\\sqrt{n})$ discrepancy to $\\mathbb{P}$. Unfortunately, these algorithms suffer from quadratic or super-quadratic runtime in the sample size $n$. To address this deficiency, we introduce Compress++, a simple meta-procedure for speeding up any thinning algorithm while suffering at most a factor of $4$ in error. When combined with the quadratic-time kernel halving and kernel thinning algorithms of Dwivedi and Mackey (2021), Compress++ delivers $\\sqrt{n}$ points with $\\mathcal{O}(\\sqrt{\\log n/n})$ integration error and better-than-Monte-Carlo maximum mean discrepancy in $\\mathcal{O}(n \\log^3 n)$ time and  $\\mathcal{O}( \\sqrt{n} \\log^2 n )$ space. Moreover, Compress++ enjoys the same near-linear runtime given any quadratic-time input and reduces the runtime of super-quadratic algorithms by a square-root factor. In our benchmarks with high-dimensional Monte Carlo samples and Markov chains targeting challenging differential equation posteriors, Compress++ matches or nearly matches the accuracy of its input algorithm in orders of magnitude less time.",
    "One-sentence Summary": "We introduce a simple algorithm for compressing an $n$-point summary of a probability distribution into a $\\sqrt{n}$-point summary of comparable quality in $O(n \\log^2 n)$ time."
  },
  {
    "title": "Capturing Structural Locality in Non-parametric Language Models",
    "url": "/forum?id=nnU3IUMJmN",
    "date": "28 Sept 2021 (modified: 01 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Structural locality is a ubiquitous feature of real-world datasets, wherein data points are organized into local hierarchies. Some examples include topical clusters in text or project hierarchies in source code repositories. In this paper, we explore utilizing this structural locality within non-parametric language models, which generate sequences that reference retrieved examples from an external source. We propose a simple yet effective approach for adding locality information into such models by adding learned parameters that improve the likelihood of retrieving examples from local neighborhoods. Experiments on two different domains, Java source code and Wikipedia text, demonstrate that locality features improve model efficacy over models without access to these features, with interesting differences. We also perform an analysis of how and where locality features contribute to improving performance and why the traditionally used contextual similarity metrics alone are not enough to grasp the locality structure.",
    "One-sentence Summary": "We propose, study the effect of, and incorporate structural locality in non-parametric language models."
  },
  {
    "title": "Audio Lottery: Speech Recognition Made Ultra-Lightweight, Noise-Robust, and Transferable",
    "url": "/forum?id=9Nk6AJkVYB",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Speech Recognition, Lottery Ticket Hypothesis",
    "Abstract": "Lightweight speech recognition models have seen explosive demands owing to a growing amount of speech-interactive features on mobile devices. Since designing such systems from scratch is non-trivial, practitioners typically choose to compress large (pre-trained) speech models. Recently, lottery ticket hypothesis reveals the existence of highly sparse subnetworks that can be trained in isolation without sacrificing the performance of the full models. In this paper, we investigate the tantalizing possibility of using lottery ticket hypothesis to discover lightweight speech recognition models, that are (1) robust to various noise existing in speech; (2) transferable to fit the open-world personalization; and 3) compatible with structured sparsity. We conducted extensive experiments on  CNN-LSTM, RNN-Transducer, and Transformer models, and verified the existence of highly sparse winning tickets that can match the full model performance across those backbones. We obtained winning tickets that have less than 20% of full model weights on all backbones, while the most lightweight one only keeps 4.4% weights. Those winning tickets generalize to structured sparsity with no performance loss, and transfer exceptionally from large source datasets to various target datasets. Perhaps most surprisingly, when the training utterances have high background noises, the winning tickets even substantially outperform the full models, showing the extra bonus of noise robustness by inducing sparsity. Codes are available at https://github.com/VITA-Group/Audio-Lottery.",
    "One-sentence Summary": "We for the first time investigate three unique properties that were rarely studied in previous LTH research but are key to user-interactive ASR devices, bringing new insights to both LTH theory and lightweight ASR research."
  },
  {
    "title": "Learning to Map for Active Semantic Goal Navigation",
    "url": "/forum?id=swrMQttr6wN",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "visual navigation, semantic map, uncertainty estimation",
    "Abstract": "We consider the problem of object goal navigation in unseen environments. Solving this problem requires learning of contextual semantic priors, a challenging endeavour given the spatial and semantic variability of indoor environments. Current methods learn to implicitly encode these priors through goal-oriented navigation policy functions operating on spatial representations that are limited to the agent's observable areas. In this work, we propose a novel framework that actively learns to generate semantic maps outside the field of view of the agent and leverages the uncertainty over the semantic classes in the unobserved areas to decide on long term goals. We demonstrate that through this spatial prediction strategy, we are able to learn semantic priors in scenes that can be leveraged in unknown environments. Additionally, we show how different objectives can be defined by balancing exploration with exploitation during searching for semantic targets. Our method is validated in the visually realistic environments of the Matterport3D dataset and show improved results on object goal navigation over competitive baselines.",
    "One-sentence Summary": "A framework for object goal navigation that actively learns to predict semantic maps and choose long-term goals based on uncertainty measures."
  },
  {
    "title": "Benchmarking the Spectrum of Agent Capabilities",
    "url": "/forum?id=1W0z96MFEoH",
    "date": "28 Sept 2021 (modified: 12 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Evaluation, Reinforcement Learning, Environment, Benchmark, Unsupervised Reinforcement Learning, Exploration",
    "Abstract": "Evaluating the general abilities of intelligent agents requires complex simulation environments. Existing benchmarks typically evaluate only one narrow task per environment, requiring researchers to perform expensive training runs on many different environments. We introduce Crafter, an open world survival game with visual inputs that evaluates a wide range of general abilities within a single environment. Agents either learn from the provided reward signal or through intrinsic objectives and are evaluated by semantically meaningful achievements that can be unlocked during each episode, such as discovering resources and crafting tools. Consistently unlocking all achievements requires strong generalization, deep exploration, and long-term reasoning. We experimentally verify that Crafter is of appropriate difficulty to drive future research and provide baselines scores of reward agents and unsupervised agents. Furthermore, we observe sophisticated behaviors emerging from maximizing the reward signal, such as building tunnel systems, bridges, houses, and plantations. We hope that Crafter will accelerate research progress by quickly evaluating a wide spectrum of abilities."
  },
  {
    "title": "Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks",
    "url": "/forum?id=vqGi8Kp0wM",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "GAN, StyleGAN, Clip, Domain Adaptation, Style Transfer, Single Shot",
    "Abstract": "We present a new method for one shot domain adaptation. The input to our method is trained GAN that can produce images in domain A and a single reference image I_B from domain B. The proposed algorithm can translate any output of the trained GAN from domain A to domain B. There are two main advantages of our method compared to the current state of the art: First, our solution achieves higher visual quality, e.g. by noticeably reducing overfitting. Second, our solution allows for more degrees of freedom to control the domain gap, i.e. what aspects of image I_B are used to define the domain B. Technically, we realize the new method by building on a pre-trained StyleGAN generator as GAN and a pre-trained CLIP model for representing the domain gap. We propose several new regularizers for controlling the domain gap to optimize the weights of the pre-trained StyleGAN generator to output images in domain B instead of domain A. The regularizers prevent the optimization from taking on too many attributes of the single reference image. Our results show significant visual improvements over the state of the art as well as multiple applications that highlight improved control.",
    "One-sentence Summary": "We propose several regularizers to control the domain transfer for single shot domain adaptation in the context of generative adversarial networks."
  },
  {
    "title": "On Evaluation Metrics for Graph Generative Models",
    "url": "/forum?id=EnwCZixjSh",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "In image generation, generative models can be evaluated naturally by visually inspecting model outputs. However, this is not always the case for graph generative models (GGMs), making their evaluation challenging. Currently, the standard process for evaluating GGMs suffers from three critical limitations: i) it does not produce a single score which makes model selection challenging, ii) in many cases it fails to consider underlying edge and node features, and iii) it is prohibitively slow to perform. In this work, we mitigate these issues by searching for \\emph{scalar, domain-agnostic, and scalable metrics} for evaluating and ranking GGMs. To this end, we study existing GGM metrics and neural-network-based metrics emerging from generative models of images that use embeddings extracted from a task-specific network. Motivated by the power of Graph Neural Networks (GNNs) to extract meaningful graph representations \\emph{without any training}, we introduce several metrics based on the features extracted by an untrained random GNN. We design experiments to thoroughly test and objectively score metrics on their ability to measure the diversity and fidelity of generated graphs, as well as their sample and computational efficiency. Depending on the quantity of samples, we recommend one of two metrics from our collection of random-GNN-based metrics. We show these two metrics to be more expressive than pre-existing and alternative random-GNN-based metrics using our objective scoring. While we focus on applying these metrics to GGM evaluation, in practice this enables the ability to easily compute the dissimilarity between any two sets of graphs \\emph{regardless of domain}. Our code is released at: https://github.com/uoguelph-mlrg/GGM-metrics."
  },
  {
    "title": "Selective Ensembles for Consistent Predictions",
    "url": "/forum?id=HfUyCRBeQc",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "consistency, prediction consistency, model duplicity, inconsistent predictions, deep models, deep networks, explanations, saliency maps, gradient-based explanations, fairness, interpretability",
    "Abstract": "Recent work has shown that models trained to the same objective, and which achieve similar measures of accuracy on consistent test data, may nonetheless behave very differently on individual predictions. This inconsistency is undesirable in high-stakes contexts, such as medical diagnosis and finance. We show that this duplicitous behavior extends beyond predictions to feature attributions, which may likewise have negative implications for the intelligibility of a model, and one's ability to find recourse for subjects. We then introduce selective ensembles to mitigate such inconsistencies by applying hypothesis testing to the predictions of a set of models trained using randomly-selected starting conditions; importantly, selective ensembles can abstain in cases where a consistent outcome cannot be achieved up to a specified confidence level. We prove that that prediction disagreement between selective ensembles is bounded, and empirically demonstrate that selective ensembles achieve consistent predictions and feature attributions while maintaining low abstention rates. On several benchmark datasets, selective ensembles reach zero inconsistently predicted points, with abstention rates as low as 1.5%.",
    "One-sentence Summary": "Deep models give inconsistent predictions and explanations over small changes (e.g. random initialization). We can mitigate this by using selective ensemble models, which abstain from prediction if their constituent models do not agree sufficiently."
  },
  {
    "title": "Graph Condensation for Graph Neural Networks",
    "url": "/forum?id=WLEx3Jo4QaB",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "data-efficient learning, graph generation, graph neural networks",
    "Abstract": "Given the prevalence of large-scale graphs in real-world applications, the storage and time for training neural models have raised increasing concerns. To alleviate the concerns, we propose and study the problem of graph condensation for graph neural networks (GNNs).  Specifically, we aim to condense the large, original graph into a small, synthetic and highly-informative graph, such that GNNs trained on the small graph and large graph have comparable performance. We approach the condensation problem by imitating the GNN training trajectory  on the original graph through the optimization of a gradient matching loss and design a strategy to condense node futures and structural information simultaneously. Extensive experiments have demonstrated the effectiveness of the proposed framework in condensing different graph datasets into informative smaller graphs. In particular, we are able to approximate the original test accuracy by 95.3\\% on Reddit, 99.8\\% on Flickr and 99.0\\% on Citeseer,  while reducing their graph size by more than 99.9\\%, and the condensed graphs can be used to train various GNN architectures.",
    "One-sentence Summary": "We study the problem of graph condensation which targets at condensing a large-real graph into a small-synthetic one while maintaining the performances of GNNs."
  },
  {
    "title": "DIVA: Dataset Derivative of a Learning Task",
    "url": "/forum?id=bVvMOtLMiw",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Leave one out cross validation, AutoML, dataset optimization",
    "Abstract": "We present a method to compute the derivative of a learning task with respect to a dataset. A learning task is a function from a training set to the validation error, which can be represented by a trained deep neural network (DNN). The ``dataset derivative'' is a linear operator, computed around the trained model, that informs how perturbations of the weight of each training sample affect the validation error, usually computed on a separate validation dataset.  Our method, DIVA (Differentiable Validation) hinges on a closed-form differentiable expression of the leave-one-out cross-validation error around a pre-trained DNN. Such expression constitutes the dataset derivative. DIVA could be used for dataset auto-curation, for example removing samples with faulty annotations, augmenting a dataset with additional relevant samples, or rebalancing. More generally, DIVA can be used to optimize the dataset, along with the parameters of the model, as part of the training process without the need for a separate validation dataset, unlike bi-level optimization methods customary in AutoML. To illustrate the flexibility of DIVA, we report experiments on sample auto-curation tasks such as outlier rejection, dataset extension, and automatic aggregation of multi-modal data.",
    "One-sentence Summary": "Presents a method to optimize a dataset based on a notion of a dataset derivative that is computed in closed form using linearization"
  },
  {
    "title": "Towards General Function Approximation in Zero-Sum Markov Games",
    "url": "/forum?id=sA4qIu3zv6v",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "This paper considers two-player zero-sum finite-horizon Markov games with simultaneous moves. The study focuses on the challenging settings where the value\n        function or the model is parameterized by general function classes. Provably efficient\n        algorithms for both decoupled and coordinated settings are developed. In the decoupled setting where the agent controls a single player and plays against an arbitrary opponent, we propose a new model-free algorithm. The sample complexity is governed by the Minimax Eluder dimension\u2014a new dimension of the function class in Markov games. As a special case, this method improves the state-of-the-art algorithm\n        by a $\\sqrt{d}$ factor in the regret when the reward function and transition kernel are parameterized with d-dimensional linear features. In the coordinated setting where both\n        players are controlled by the agent, we propose a model-based algorithm and a model-free algorithm. In the model-based algorithm, we prove that sample complexity can\n        be bounded by a generalization of Witness rank to Markov games. The model-free\n        algorithm enjoys a  $\\sqrt{K}$-regret upper bound where $K$ is the number of episodes. Our\n        algorithms are based on new techniques of alternate optimism"
  },
  {
    "title": "Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings",
    "url": "/forum?id=6PvWo1kEvlT",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Masked Language Models, Energy-based models, Metropolis Hastings Monte Carlo, Bidirectional Sequence models",
    "Abstract": "While recent work has shown that scores from models trained by the ubiquitous masked language modeling (MLM) objective effectively discriminate probable from improbable sequences, it is still an open question if these MLMs specify a principled probability distribution over the space of possible sequences. In this paper, we interpret MLMs as energy-based sequence models and propose two energy parametrizations derivable from the trained MLMs. In order to draw samples correctly from these models, we develop a tractable sampling scheme based on the Metropolis--Hastings Monte Carlo algorithm. In our approach, samples are proposed from the same masked conditionals used for training the masked language models, and they are accepted or rejected based on their energy values according to the target distribution. We validate the effectiveness of the proposed parametrizations by exploring the quality of samples drawn from these energy-based models for both open-ended unconditional generation and a conditional generation task of machine translation. We theoretically and empirically justify our sampling algorithm by showing that the masked conditionals on their own do not yield a Markov chain whose stationary distribution is that of our target distribution, and our approach generates higher quality samples than other recently proposed undirected generation approaches (Wang et al., 2019, Ghazvininejad et al., 2019).",
    "One-sentence Summary": "We interpret masked language models for sequences as energy based models and propose a tractable scheme inspired by Metropolis--Hasting Monte Carlo to draw samples from these models."
  },
  {
    "title": "ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods",
    "url": "/forum?id=EZNOb_uNpJk",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "GAN, Climate Change, Domain Adaptation, Representation Learning, Computer Vision, Application",
    "Abstract": "Climate change is a major threat to humanity and the actions required to prevent its catastrophic consequences include changes in both policy-making and individual behaviour. However, taking action requires understanding its seemingly abstract and distant consequences. Projecting the potential impacts of extreme climate events such as flooding in familiar places can help make the impacts of climate change more concrete and encourage action. As part of a larger initiative to build a website (https://thisclimatedoesnotexist.com) that projects extreme climate events onto user-chosen photos, we present our solution to simulate photo-realistic floods on authentic images. To address this complex task in the absence of suitable data, we propose ClimateGAN, a model that leverages both simulated and real data through unsupervised domain adaptation and conditional image generation. In this paper, we describe the details of our framework, thoroughly evaluate the main components of our architecture and demonstrate that our model is capable of robustly generating photo-realistic flooding on street images.",
    "One-sentence Summary": "This paper presents a model to robustly produce photo-realistic images of floods for raising climate change awareness, leveraging unsupervised domain adaptation and conditional image generation."
  },
  {
    "title": "A Comparison of Hamming Errors of Representative Variable Selection Methods",
    "url": "/forum?id=nhN-fqxmNGx",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Lasso, Hamming error, phase diagram, rare and weak signals, elastic net, SCAD, thresholded Lasso, forward selection, forward backward selection",
    "Abstract": "Lasso is a celebrated method for variable selection in linear models, but it faces challenges when the covariates are moderately or strongly correlated. This motivates alternative approaches such as using a non-convex penalty, adding a ridge regularization, or conducting a post-Lasso thresholding. In this paper, we compare Lasso with 5 other methods: Elastic net, SCAD, forward selection, thresholded Lasso, and forward backward selection. We measure their performances theoretically by the expected Hamming error, assuming that the regression coefficients are ${\\it iid}$ drawn from a two-point mixture and that the Gram matrix is block-wise diagonal. By deriving the rates of convergence of Hamming errors and the phase diagrams, we obtain useful conclusions about the pros and cons of different methods.",
    "One-sentence Summary": "A theoretical comparison of the Hamming errors for 6 different variable selection methods"
  },
  {
    "title": "A Program to Build E(N)-Equivariant Steerable CNNs",
    "url": "/forum?id=WE4qe9xlnQw",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "equivariance, 3D, geometric deep learning, isometries, steerable CNN",
    "Abstract": "Equivariance is becoming an increasingly popular design choice to build data efficient neural networks by exploiting prior knowledge about the symmetries of the problem at hand. Euclidean steerable CNNs are one of the most common classes of equivariant networks. While the constraints these architectures need to satisfy are understood, existing approaches are tailored to specific (classes of) groups. No generally applicable method that is practical for implementation has been described so far. In this work, we generalize the Wigner-Eckart theorem proposed in Lang & Weiler (2020), which characterizes general $G$-steerable kernel spaces for compact groups $G$ over their homogeneous spaces, to arbitrary $G$-spaces. This enables us to directly parameterize filters in terms of a band-limited basis on the whole space rather than on $G$'s orbits, but also to easily implement steerable CNNs equivariant to a large number of groups. To demonstrate its generality, we instantiate our method on a variety of isometry groups acting on the Euclidean space $\\mathbb{R}^3$. Our framework allows us to build $E(3)$ and $SE(3)$-steerable CNNs like previous works, but also CNNs with arbitrary $G\\leq O(3)$-steerable kernels. For example, we build 3D CNNs equivariant to the symmetries of platonic solids or choose $G=SO(2)$ when working with 3D data having only azimuthal symmetries. We compare these models on 3D shapes and molecular datasets, observing improved performance by matching the model's symmetries to the ones of the data.",
    "One-sentence Summary": "We derive a general method to build G-steerable kernel spaces for equivariant steerable CNNs"
  },
  {
    "title": "Minimax Optimization with Smooth Algorithmic Adversaries",
    "url": "/forum?id=UdxJ2fJx7N0",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Minimax optimization, two player zero sum games, generative adversarial networks, adversarial training",
    "Abstract": "This paper considers minimax optimization $\\min_x \\max_y f(x, y)$ in the challenging setting where $f$ can be both nonconvex in $x$ and nonconcave in $y$. Though such optimization problems arise in many machine learning paradigms including training generative adversarial networks (GANs) and adversarially robust models, from a theoretical point of view, two fundamental issues remain: (i) the absence of simple and efficiently computable optimality notions, and (ii) cyclic or diverging behavior of existing algorithms. This paper proposes a new theoretical framework for nonconvex-nonconcave minimax optimization that addresses both of the above issues. The starting point of this paper is the observation that, under a computational budget, the max-player can not fully maximize $f(x,\\cdot)$ since nonconcave maximization is NP-hard in general. So, we propose a new framework, and a corresponding algorithm, for the min-player to play against \\emph{smooth algorithms} deployed by the adversary (i.e., the max-player) instead of against full maximization. Our algorithm is guaranteed to make monotonic progress (thus having no limit cycles or diverging behavior), and to find an appropriate ``stationary point'' in a polynomial number of iterations. Our framework covers practically relevant settings where the smooth algorithms deployed by the adversary are multi-step stochastic gradient ascent, and its accelerated version. We further present experimental results that confirm our theoretical findings and demonstrate the effectiveness of the proposed approach in practice on simple, conceptual settings.",
    "One-sentence Summary": "We propose a tractable formulation of minimax optimization by modeling the adversary's algorithm, and present new algorithms which are guaranteed to converge and find appropriate stationary points."
  },
  {
    "title": "On Distributed Adaptive Optimization with Gradient Compression",
    "url": "/forum?id=CI-xXX9dg9l",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We study COMP-AMS, a distributed optimization framework based on gradient averaging and adaptive AMSGrad algorithm. Gradient compression with error feedback is applied to reduce the communication cost in the gradient transmission process. Our convergence analysis of COMP-AMS shows that such compressed gradient averaging strategy yields same convergence rate as standard AMSGrad, and also exhibits the linear speedup effect w.r.t. the number of local workers. Compared with recently proposed protocols on distributed adaptive methods, COMP-AMS is simple and convenient. Numerical experiments are conducted to justify the theoretical findings, and demonstrate that the proposed method can achieve same test accuracy as the full-gradient AMSGrad with substantial communication savings. With its simplicity and efficiency, COMP-AMS can serve as a useful distributed training framework for adaptive methods."
  },
  {
    "title": "Leveraging unlabeled data to predict out-of-distribution performance",
    "url": "/forum?id=o_HsiMPYh_x",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Distribution Shift, OOD error prediction, Deep Learning",
    "Abstract": "Real-world machine learning deployments are characterized by mismatches between the source (training) and target (test) distributions\n        that may cause performance drops. In this work, we investigate methods for predicting the target domain accuracy using only labeled source data and unlabeled target data. We propose Average Thresholded Confidence (ATC), a practical method that learns a \\emph{threshold} on the model's confidence, predicting accuracy as the fraction of unlabeled examples for which model confidence exceeds that threshold. ATC outperforms previous methods across several model architectures, types of distribution shifts (e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (\\textsc{Wilds}-FMoW, ImageNet, \\breeds, CIFAR, and MNIST).  In our experiments, ATC estimates target performance $2\\text{--}4\\times$ more accurately than prior methods. We also explore the theoretical foundations of the problem, proving that, in general, identifying the accuracy is just as hard as identifying the optimal predictor and thus, the efficacy of any method rests upon (perhaps unstated) assumptions on the nature of the shift. Finally, analyzing our method on some toy distributions, we provide insights concerning when it works."
  },
  {
    "title": "VC dimension of partially quantized neural networks in the overparametrized regime",
    "url": "/forum?id=7udZAsEzd60",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "VC dimension, quantized neural networks, classification, minimax theory, overparametrization",
    "Abstract": "Vapnik-Chervonenkis (VC) theory has so far been unable to explain the small generalization error of overparametrized neural networks. Indeed, existing applications of VC theory to large networks obtain upper bounds on VC dimension that are proportional to the number of weights, and for a large class of networks, these upper bound are known to be tight. In this work, we focus on a class of partially quantized networks that we refer to as hyperplane arrangement neural networks (HANNs). Using a sample compression analysis, we show that HANNs can have VC dimension significantly smaller than the number of weights, while being highly expressive. In particular, empirical risk minimization over HANNs in the overparametrized regime achieves the minimax rate for classification with Lipschitz posterior class probability. We further demonstrate the expressivity of HANNs empirically. On a panel of 121 UCI datasets, overparametrized HANNs are able to match the performance of state-of-the-art full-precision models.",
    "One-sentence Summary": "We apply VC theory to analyze the performance of a neural network in the overparametrized regime and obtain a minimax-optimality result."
  },
  {
    "title": "Optimal Representations for Covariate Shift",
    "url": "/forum?id=Rf58LPCwJj0",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "distribution shift, domain generalization, representation learning, self-supervised learning, invariance, robustness",
    "Abstract": "Machine learning systems often experience a distribution shift between training and testing. In this paper, we introduce a simple variational objective whose optima are exactly the set of all representations on which risk minimizers are guaranteed to be robust to any distribution shift that preserves the Bayes predictor, e.g., covariate shifts. Our objective has two components. First, a representation must remain discriminative for the task, i.e., some predictor must be able to simultaneously minimize the source and target risk. Second, the representation's marginal support needs to be the same across source and target. We make this practical by designing self-supervised objectives that only use unlabelled data and augmentations to train robust representations. \n        Our objectives give insights into the robustness of CLIP, and further improve CLIP's representations to achieve SOTA results on DomainBed.",
    "One-sentence Summary": "We give a simple variational objective whose optima are exactly the set of representations that are robust under covariate shift"
  },
  {
    "title": "Fortuitous Forgetting in Connectionist Networks",
    "url": "/forum?id=ei3SY1_zYsE",
    "date": "28 Sept 2021 (modified: 01 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Networks, Generalization, Iterative Training, Compositionality, Iterated Learning",
    "Abstract": "Forgetting is often seen as an unwanted characteristic in both human and machine learning. However, we propose that forgetting can in fact be favorable to learning. We introduce forget-and-relearn as a powerful paradigm for shaping the learning trajectories of artificial neural networks. In this process, the forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The forget-and-relearn framework unifies many existing iterative training algorithms in the image classification and language emergence literature, and allows us to understand the success of these algorithms in terms of the disproportionate forgetting of undesirable information. We leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations. Insights from our analysis provide a coherent view on the dynamics of iterative training in neural networks and offer a clear path towards performance improvements.",
    "One-sentence Summary": "We introduce \"forget-and-relearn\" as a training paradigm where forgetting removes undesirable information and relearning bolsters useful features towards better generalization and compositionality."
  },
  {
    "title": "EigenGame Unloaded: When playing games is better than optimizing",
    "url": "/forum?id=So6YAqnqgMj",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "pca, principal components analysis, nash, games, eigendecomposition, svd, singular value decomposition",
    "Abstract": "We build on the recently proposed EigenGame that views eigendecomposition as a competitive game. EigenGame's updates are biased if computed using minibatches of data, which hinders convergence and more sophisticated parallelism in the stochastic setting. In this work, we propose an unbiased stochastic update that is asymptotically equivalent to EigenGame, enjoys greater parallelism allowing computation on datasets of larger sample sizes, and outperforms EigenGame in experiments. We present applications to finding the principal components of massive datasets and performing spectral clustering of graphs. We analyze and discuss our proposed update in the context of EigenGame and the shift in perspective from optimization to games.",
    "One-sentence Summary": "We improve the EigenGame algorithm by removing update bias, enabling further parallelism and better performance."
  },
  {
    "title": "Contextualized Scene Imagination for Generative Commonsense Reasoning",
    "url": "/forum?id=Oh1r2wApbPv",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Commonsense reasoning, constrained text generation, knowledge representation",
    "Abstract": "Humans use natural language to compose common concepts from their environment into plausible, day-to-day scene descriptions. However, such generative commonsense reasoning (GCSR) skills are lacking in state-of-the-art text generation methods. Descriptive sentences about arbitrary concepts generated by neural text generation models (e.g., pre-trained text-to-text Transformers) are often grammatically fluent but may not correspond to human common sense, largely due to their lack of mechanisms to capture concept relations, to identify implicit concepts, and to perform generalizable reasoning about unseen concept compositions. In this paper, we propose an Imagine-and-Verbalize (I\\&V) method, which learns to imagine a relational scene knowledge graph (SKG) with relations between the input concepts, and leverage the SKG as a constraint when generating a plausible scene description. We collect and harmonize a set of knowledge resources from different domains and modalities, providing a rich auxiliary supervision signal for I\\&V. The experiments demonstrate the effectiveness of I\\&V in improving language models on both concept-to-sentence and concept-to-story generation tasks, while enabling the model to learn well from fewer task examples and generate SKGs that make common sense to human annotators.",
    "One-sentence Summary": "This work aims at tackling generative commonsense reasoning by allowing machines to imagine a reasonable scene before generating text."
  },
  {
    "title": "Scene Transformer: A unified architecture for predicting future trajectories of multiple agents",
    "url": "/forum?id=Wm3EA5OlHsG",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "trajectory prediction, motion forecasting, multi-task learning, attention, autonomous vehicles",
    "Abstract": "Predicting the motion of multiple agents is necessary for planning in dynamic environments. This task is challenging for autonomous driving since agents (e.g., vehicles and pedestrians) and their associated behaviors may be diverse and influence one another. Most prior work have focused on predicting independent futures for each agent based on all past motion, and planning against these independent predictions. However, planning against independent predictions can make it challenging to represent the future interaction possibilities between different agents, leading to sub-optimal planning. In this work, we formulate a model for predicting the behavior of all agents jointly, producing consistent futures that account for interactions between agents. Inspired by recent language modeling approaches, we use a masking strategy as the query to our model, enabling one to invoke a single model to predict agent behavior in many ways, such as potentially conditioned on the goal or full future trajectory of the autonomous vehicle or the behavior of other agents in the environment. Our model architecture employs attention to combine features across road elements, agent interactions, and time steps. We evaluate our approach on autonomous driving datasets for both marginal and joint motion prediction, and achieve state of the art performance across two popular datasets. Through combining a scene-centric approach, agent permutation equivariant model, and a sequence masking strategy, we show that our model can unify a variety of motion prediction tasks from joint motion predictions to conditioned prediction.",
    "One-sentence Summary": "We introduce a scene-centric masked sequence based motion prediction model that unifies a variety of motion prediction tasks from joint motion predictions to conditioned prediction."
  },
  {
    "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals",
    "url": "/forum?id=qY79G8jGsep",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Explainability, Interpretability, Counterfactual generation, Generative Adversarial Network, Variational Autoencoder",
    "Abstract": "Explaining deep learning model inferences is a promising venue for scientific understanding, improving safety, uncovering hidden biases, evaluating fairness, and beyond, as argued by many scholars. One of the principal benefits of counterfactual explanations is allowing users to explore \"what-if\" scenarios through what does not and cannot exist in the data, a quality that many other forms of explanation such as heatmaps and influence functions are inherently incapable of doing. However, most previous work on generative explainability cannot disentangle important concepts effectively, produces unrealistic examples, or fails to retain relevant information. We propose a novel approach, DISSECT, that jointly trains a generator, a discriminator, and a concept disentangler to overcome such challenges using little supervision. DISSECT generates Concept Traversals (CTs), defined as a sequence of generated examples with increasing degrees of concepts that influence a classifier's decision. By training a generative model from a classifier's signal, DISSECT offers a way to discover a classifier's inherent \"notion\" of distinct concepts automatically rather than rely on user-predefined concepts. We show that DISSECT produces CTs that (1) disentangle several concepts, (2) are influential to a classifier's decision and are coupled to its reasoning due to joint training (3), are realistic, (4) preserve relevant information, and (5) are stable across similar inputs. We validate DISSECT on several challenging synthetic and realistic datasets where previous methods fall short of satisfying desirable criteria for interpretability and show that it performs consistently well. Finally, we present experiments showing applications of DISSECT for detecting potential biases of a classifier and identifying spurious artifacts that impact predictions.",
    "One-sentence Summary": "We propose a novel counterfactual explainability method that simultaneously satisfies several desirable qualities where other methods fail by training a generator, a discriminator, and a concept disentangler using the classifier\u2019s signal."
  },
  {
    "title": "Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series",
    "url": "/forum?id=Az7opqbQE-3",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "irregular sampling, uncertainty, imputation, interpolation, multivariate time series, missing data, variational autoencoder",
    "Abstract": "Irregularly sampled time series commonly occur in several domains where they present a significant challenge to standard deep learning models. In this paper, we propose a new deep learning framework for probabilistic interpolation of irregularly sampled time series that we call the Heteroscedastic Temporal Variational Autoencoder (HeTVAE). HeTVAE includes a novel input layer to encode information about input observation sparsity, a temporal VAE architecture to propagate uncertainty due to input sparsity, and a heteroscedastic output layer to enable variable uncertainty in the output interpolations.  Our results show that the proposed architecture is better able to reflect variable uncertainty through time due to sparse and irregular sampling than a range of baseline and traditional models, as well as recently proposed deep latent variable models that use homoscedastic output layers.",
    "One-sentence Summary": "We present a new deep learning architecture for probabilistic interpolation of irregularly sampled time series."
  },
  {
    "title": "A Neural Tangent Kernel Perspective of Infinite Tree Ensembles",
    "url": "/forum?id=vUH85MOXO7h",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Tangent Kernel, Tree Ensemble, Soft Tree",
    "Abstract": "In practical situations, the tree ensemble is one of the most popular models along with neural networks. A soft tree is a variant of a decision tree. Instead of using a greedy method for searching splitting rules, the soft tree is trained using a gradient method in which the entire splitting operation is formulated in a differentiable form. Although ensembles of such soft trees have been used increasingly in recent years, little theoretical work has been done to understand their behavior. By considering an ensemble of infinite soft trees, this paper introduces and studies the Tree Neural Tangent Kernel (TNTK), which provides new insights into the behavior of the infinite ensemble of soft trees. Using the TNTK, we theoretically identify several non-trivial properties, such as global convergence of the training, the equivalence of the oblivious tree structure, and the degeneracy of the TNTK induced by the deepening of the trees.",
    "One-sentence Summary": "By considering an ensemble of infinite trees, we introduce and study the Tree Neural Tangent Kernel (TNTK), which provides new insights into the behavior of the infinite ensemble of soft trees."
  },
  {
    "title": "AlphaZero-based Proof Cost Network to Aid Game Solving",
    "url": "/forum?id=nKWjE4QF1hB",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Monte-Carlo Tree Search, Solving Games, AlphaZero, Deep Reinforcement Learning",
    "Abstract": "The AlphaZero algorithm learns and plays games without hand-crafted expert knowledge. However, since its objective is to play well, we hypothesize that a better objective can be defined for the related but separate task of solving games. This paper proposes a novel approach to solving problems by modifying the training target of the AlphaZero algorithm, such that it prioritizes solving the game quickly, rather than winning. We train a Proof Cost Network (PCN), where proof cost is a heuristic that estimates the amount of work required to solve problems. This matches the general concept of the so-called proof number from proof number search, which has been shown to be well-suited for game solving. We propose two specific training targets. The first finds the shortest path to a solution, while the second estimates the proof cost. We conduct experiments on solving 15x15 Gomoku and 9x9 Killall-Go problems with both MCTS-based and FDFPN solvers. Comparisons between using AlphaZero networks and PCN as heuristics show that PCN can solve more problems.",
    "One-sentence Summary": "This paper proposes a novel approach to solving problems by modifying the training target of the AlphaZero algorithm, such that it prioritizes solving the game quickly, rather than winning."
  },
  {
    "title": "Bayesian Framework for Gradient Leakage",
    "url": "/forum?id=f2lrIbGx3x7",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "federated learning, privacy, gradient leakage",
    "Abstract": "Federated learning is an established method for training machine learning models without sharing training data. However, recent work has shown that it cannot guarantee data privacy as shared gradients can still leak sensitive information. To formalize the problem of gradient leakage, we propose a theoretical framework that enables, for the first time, analysis of the Bayes optimal adversary phrased as an optimization problem. We demonstrate that existing leakage attacks can be seen as approximations of this optimal adversary with different assumptions on the probability distributions of the input data and gradients. Our experiments confirm the effectiveness of the Bayes optimal adversary when it has knowledge of the underlying distribution. Further, our experimental evaluation shows that several existing heuristic defenses are not effective against stronger attacks, especially early in the training process. Thus, our findings indicate that the construction of more effective defenses and their evaluation remains an open problem.",
    "One-sentence Summary": "We propose a theoretical framework for analysis of the Bayes optimal adversary for gradient leakage, and perform evaluation of existing defenses."
  },
  {
    "title": "Universalizing Weak Supervision",
    "url": "/forum?id=YpPiNigTzMT",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Weak supervision",
    "Abstract": "Weak supervision (WS) frameworks are a popular way to bypass hand-labeling large datasets for training data-hungry models.\n        These approaches synthesize multiple noisy but cheaply-acquired estimates of labels into a set of high-quality pseudo-labels for downstream training. However, the synthesis technique is specific to a particular kind of label, such as binary labels or sequences, and each new label type requires manually designing a new synthesis algorithm. Instead, we propose a universal technique that enables weak supervision over any label type while still offering desirable properties, including practical flexibility, computational efficiency, and theoretical guarantees. We apply this technique to important problems previously not tackled by WS frameworks including learning to rank, regression, and learning in hyperbolic space. Theoretically, our synthesis approach produces a consistent estimators for learning some challenging but important generalizations of the exponential family model. Experimentally, we validate our framework and show improvement over baselines in diverse settings including real-world learning-to-rank and regression problems along with learning on hyperbolic manifolds.",
    "One-sentence Summary": "We extend weak supervision frameworks to new settings \u2014 rankings, regression, Riemannian spaces, and more \u2014 with a universal algorithm with theoretical guarantees."
  },
  {
    "title": "Maximum n-times Coverage for Vaccine Design",
    "url": "/forum?id=ULfq0qR25dY",
    "date": "28 Sept 2021 (modified: 21 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "computational biology, vaccine design, COVID-19, maximum n-times coverage, combinatorial optimization, integer linear programming",
    "Abstract": "We introduce the maximum $n$-times coverage problem that selects $k$ overlays to maximize the summed coverage of weighted elements, where each element must be covered at least $n$ times. We also define the min-cost $n$-times coverage problem where the objective is to select the minimum set of overlays such that the sum of the weights of elements that are covered at least $n$ times is at least $\\tau$. Maximum $n$-times coverage is a generalization of the multi-set multi-cover problem, is NP-complete, and is not submodular. We introduce two new practical solutions for $n$-times coverage based on integer linear programming and sequential greedy optimization. We show that maximum $n$-times coverage is a natural way to frame peptide vaccine design, and find that it produces a pan-strain COVID-19 vaccine design that is superior to 29 other published designs in predicted population coverage and the expected number of peptides displayed by each individual's HLA molecules.",
    "One-sentence Summary": "We introduce the maximum $n$-times coverage problem that selects $k$ overlays to maximize the summed coverage of weighted elements, where each element must be covered at least $n$ times, and show its importance for vaccine design."
  },
  {
    "title": "KL Guided Domain Adaptation",
    "url": "/forum?id=0JzqUlIVVDd",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "domain adaptation, invariant representation",
    "Abstract": "Domain adaptation is an important problem and often needed for real-world applications. In this problem, instead of i.i.d. training and testing datapoints, we assume that the source (training) data and the target (testing) data have different distributions. With that setting, the empirical risk minimization training procedure often does not perform well, since it does not account for the change in the distribution. A common approach in the domain adaptation literature is to learn a representation of the input that has the same (marginal) distribution over the source and the target domain. However, these approaches often require additional networks and/or optimizing an adversarial (minimax) objective, which can be very expensive or unstable in practice. To improve upon these marginal alignment techniques, in this paper, we first derive a generalization bound for the target loss based on the training loss and the reverse Kullback-Leibler (KL) divergence between the source and the target representation distributions. Based on this bound, we derive an algorithm that minimizes the KL term to obtain a better generalization to the target domain. We show that with a probabilistic representation network, the KL term can be estimated efficiently via minibatch samples without any additional network or a minimax objective. This leads to a theoretically sound alignment method which is also very efficient and stable in practice. Experimental results also suggest that our method outperforms other representation-alignment approaches.",
    "One-sentence Summary": "We derive a generalization bound for the domain adaptation problem based on the reversed KL divergence, and propose to regularize the KL term to lower the generalization bound."
  },
  {
    "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness",
    "url": "/forum?id=Mspk_WYKoEH",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Expressiveness, Message Passing Neural Network, Graph Classification",
    "Abstract": "Message Passing Neural Networks (MPNNs) are a common type of Graph Neural Network (GNN), in which each node\u2019s representation is computed recursively by aggregating representations (\u201cmessages\u201d) from its immediate neighbors akin to a star-shaped pattern. MPNNs are appealing for being efficient and scalable, however their expressiveness is upper-bounded by the 1st-order Weisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose highly expressive models at the cost of scalability and sometimes generalization performance. Our work stands between these two regimes: we introduce a general framework to uplift any MPNN to be more expressive, with limited scalability overhead and greatly improved practical performance. We achieve this by extending local aggregation in MPNNs from star patterns to general subgraph patterns (e.g., k-egonets): in our framework, each node representation is computed as the encoding of a surrounding induced subgraph rather than encoding of immediate neighbors only (i.e. a star). We choose the subgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design a general framework that serves as a wrapper to uplift any GNN. We call our proposed method GNN-AK (GNN As Kernel), as the framework resembles a convolutional neural network by replacing the kernel with\n        GNNs. Theoretically, we show that our framework is strictly more powerful than 1&2-WL, and is not less powerful than 3-WL. We also design subgraph sampling strategies which greatly reduce memory footprint and improve speed while maintaining performance. Our method sets new state-of-the-art performance by large margins for several well-known graph ML tasks; specifically, 0.08 MAE on ZINC,\n        74.79% and 86.887% accuracy on CIFAR10 and PATTERN respectively."
  },
  {
    "title": "NETWORK INSENSITIVITY TO PARAMETER NOISE VIA PARAMETER ATTACK DURING TRAINING",
    "url": "/forum?id=-8sBpe7rDiV",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "parameter attack, adversarial attack, neural network, deep learning, optimisation, neuromorphic processor",
    "Abstract": "Neuromorphic neural network processors, in the form of compute-in-memory crossbar arrays of memristors, or in the form of subthreshold analog and mixed-signal ASICs, promise enormous advantages in compute density and energy efficiency for NN-based ML tasks. However, these technologies are prone to computational non-idealities, due to process variation and intrinsic device physics. This degrades the task performance of networks deployed to the processor, by introducing parameter noise into the deployed model. While it is possible to calibrate each device, or train networks individually for each processor, these approaches are expensive and impractical for commercial deployment. Alternative methods are therefore needed to train networks that are inherently robust against parameter variation, as a consequence of network architecture and parameters. We present a new network training algorithm that attacks network parameters during training, and promotes robust performance during inference in the face of random parameter variation. Our approach introduces a loss regularization term that penalizes the susceptibility of a network to weight perturbation. We compare against previous approaches for producing parameter insensitivity such as dropout, weight smoothing and introducing parameter noise during training. We show that our approach produces models that are more robust to random mismatch-induced parameter variation as well as to targeted parameter variation. Our approach finds minima in flatter locations in the weight-loss landscape compared with other approaches, highlighting that the networks found by our technique are less sensitive to parameter perturbation. Our work provides an approach to deploy neural network architectures to inference devices that suffer from computational non-idealities, with minimal loss of performance. This method will enable deployment at scale to novel energy-efficient computational substrates, promoting cheaper and more prevalent edge inference.",
    "One-sentence Summary": "We flatten the weight loss-landscape by introducing a parameter attack term in the loss function and demonstrate improved network insensitivity to noise common in analog neuromorphic hardware."
  },
  {
    "title": "Gradient Importance Learning for Incomplete Observations",
    "url": "/forum?id=fXHl76nO2AZ",
    "date": "28 Sept 2021 (modified: 25 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Missing Data, Reinforcement Learning, Representation Learning",
    "Abstract": "Though recent works have developed methods that can generate estimates (or imputations) of the missing entries in a dataset to facilitate downstream analysis, most depend on assumptions that may not align with real-world applications and could suffer from poor performance in subsequent tasks such as classification. This is particularly true if the data have large missingness rates or a small sample size. More importantly, the imputation error could be propagated into the prediction step that follows, which may constrain the capabilities of the prediction model. In this work, we introduce the gradient importance learning (GIL) method to train multilayer perceptrons (MLPs) and long short-term memories (LSTMs) to directly perform inference from inputs containing missing values without imputation. Specifically, we employ reinforcement learning (RL) to adjust the gradients used to train these models via back-propagation. This allows the model to exploit the underlying information behind missingness patterns. We test the approach on real-world time-series (i.e., MIMIC-III), tabular data obtained from an eye clinic, and a standard dataset (i.e., MNIST), where our imputation-free predictions outperform the traditional two-step imputation-based predictions using state-of-the-art imputation methods."
  },
  {
    "title": "Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset",
    "url": "/forum?id=v6s3HVjPerv",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Interpretable ML, User Study, Human Subject Evaluation, Invertible Neural Networks, Convolutional Networks",
    "Abstract": "A variety of methods exist to explain image classification models. However, whether they provide any benefit to users over simply comparing various inputs and the model\u2019s respective predictions remains unclear. We conducted a user study (N=240) to test how such a baseline explanation technique performs against concept-based and counterfactual explanations. To this end, we contribute a synthetic dataset generator capable of biasing individual attributes and quantifying their relevance to the model. In a study, we assess if participants can identify the relevant set of attributes compared to the ground-truth. Our results show that the baseline outperformed concept-based explanations. Counterfactual explanations from an invertible neural network performed similarly as the baseline. Still, they allowed users to identify some attributes more accurately. Our results highlight the importance of measuring how well users can reason about biases of a model, rather than solely relying on technical evaluations or proxy tasks. We open-source our study and dataset so it can serve as a blue-print for future studies.",
    "One-sentence Summary": "Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset"
  },
  {
    "title": "Understanding the Variance Collapse of SVGD in High Dimensions",
    "url": "/forum?id=Qycd9j5Qp9J",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Stein Variational Gradient Descent, Approximate Inference, Particle-based Variational Inference",
    "Abstract": "Stein variational gradient descent (SVGD) is a deterministic inference algorithm that evolves a set of particles to fit a target distribution. Despite its computational efficiency, SVGD often underestimates the variance of the target distribution in high dimensions. In this work we attempt to explain the variance collapse in SVGD. On the qualitative side, we compare the SVGD update with gradient descent on the maximum mean discrepancy (MMD) objective; we observe that the variance collapse phenomenon relates to the bias from deterministic updates present in the \"driving force\" of SVGD, and empirically verify that removal of such bias leads to more accurate variance estimation. On the quantitative side, we demonstrate that the variance collapse of SVGD can be accurately predicted in the proportional asymptotic limit, i.e., when the number of particles $n$ and dimensions $d$ diverge at the same rate. In particular, for learning high-dimensional isotropic Gaussians, we derive the exact equilibrium variance for both SVGD and MMD-descent under certain near-orthogonality assumption on the converged particles, and confirm that SVGD suffers from the \"curse of dimensionality\".",
    "One-sentence Summary": "Qualitative and quantitative analysis of the variance collapse phenomenon of SVGD in high dimensions."
  },
  {
    "title": "Generalisation in Lifelong Reinforcement Learning through Logical Composition",
    "url": "/forum?id=ZOcX-eybqoL",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Lifelong learning, Multi task learning, Transfer learning, Logical composition, Deep Reinforcement Learning",
    "Abstract": "We leverage logical composition in reinforcement learning to create a framework that enables an agent to autonomously determine whether a new task can be immediately solved using its existing abilities, or whether a task-specific skill should be learned. In the latter case, the proposed algorithm also enables the agent to learn the new task faster by generating an estimate of the optimal policy. Importantly, we provide two main theoretical results: we bound the performance of the transferred policy on a new task, and we give bounds on the necessary and sufficient number of tasks that need to be learned throughout an agent's lifetime to generalise over a distribution. We verify our approach in a series of experiments, where we perform transfer learning both after learning a set of base tasks, and after learning an arbitrary set of tasks. We also demonstrate that, as a side effect of our transfer learning approach, an agent can produce an interpretable Boolean expression of its understanding of the current task. Finally, we demonstrate our approach in the full lifelong setting where an agent receives tasks from an unknown distribution. Starting from scratch, an agent is able to quickly generalise over the task distribution after learning only a few tasks, which are sub-logarithmic in the size of the task space.",
    "One-sentence Summary": "A framework with theoretical guarantees for an agent to quickly generalize over a task space by autonomously determining whether a new task can be solved zero-shot using existing skills, or whether a task-specific skill should be learned few-shot."
  },
  {
    "title": "PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions",
    "url": "/forum?id=gSdSJoenupI",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "classification, computer vision, loss",
    "Abstract": "Cross-entropy loss and focal loss are the most common choices when training deep neural networks for classification problems. Generally speaking, however, a good loss function can take on much more flexible forms, and should be tailored for different tasks and datasets. Motivated by how functions can be approximated via Taylor expansion, we propose a simple framework, named PolyLoss, to view and design loss functions as a linear combination of polynomial functions. Our PolyLoss allows the importance of different polynomial bases to be easily adjusted depending on the targeting tasks and datasets, while naturally subsuming the aforementioned cross-entropy loss and focal loss as special cases. Extensive experimental results show that the optimal choice within the PolyLoss is indeed dependent on the task and dataset. Simply by introducing one extra hyperparameter and adding one line of code, our Poly-1 formulation outperforms the cross-entropy loss and focal loss on 2D image classification, instance segmentation, object detection, and 3D object detection tasks, sometimes by a large margin.",
    "One-sentence Summary": "In the PolyLoss framework, we propose a simple and effective Poly-1 formulation which outperforms the cross-entropy loss and focal loss on various of tasks."
  },
  {
    "title": "Improving Non-Autoregressive Translation Models Without Distillation",
    "url": "/forum?id=I2Hw58KHp8O",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Natural Language Processing, Deep Learning, Non-autoregressive Machine Translation, Transformer, Distillation",
    "Abstract": "Transformer-based autoregressive (AR) machine translation models have achieved significant performance improvements, nearing human-level accuracy on some languages. The AR framework translates one token at a time which can be time consuming, especially for long sequences. To accelerate inference, recent work has been exploring non-autoregressive (NAR) approaches that translate blocks of tokens in parallel. Despite significant progress, leading NAR models still lag behind their AR counterparts, and only become competitive when trained with distillation. In this paper we investigate possible reasons behind this performance gap, namely, the indistinguishability of tokens, and mismatch between training and inference. We then propose the Conditional Masked Language Model with Correction (CMLMC) that addresses these problems. Empirically, we show that CMLMC achieves state-of-the-art NAR performance when trained on raw data without distillation and approaches AR performance on multiple datasets. Full code for this work will be released at the time of publication.",
    "One-sentence Summary": "Improving the CMLM non-autoregressive machine translation model so it trains without knowledge distillation and achieves SOTA BLEU score on both raw and distilled dataset"
  },
  {
    "title": "A Theory of Tournament Representations",
    "url": "/forum?id=zzk231Ms1Ih",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "tournament, skew-symmetric, pairwise ranking",
    "Abstract": "Real-world tournaments are almost always intransitive. Recent works have noted that parametric models which assume  $d$ dimensional node representations can effectively model intransitive tournaments. However, nothing is known about the structure of the class of tournaments that arise out of any fixed $d$ dimensional representations. In this work, we develop a novel theory for understanding parametric tournament representations. Our first contribution is to structurally characterize the class of tournaments that arise out of $d$ dimensional representations. We do this by showing that these tournament classes have forbidden configurations that must necessarily be a union of flip classes, a novel way to partition the set of all tournaments. We further characterize rank $2$ tournaments completely by showing that the associated forbidden flip class contains just $2$ tournaments. Specifically, we show that the rank $2$ tournaments are equivalent to locally transitive tournaments. This insight allows us to show that the minimum feedback arc set problem on this tournament class can be solved using the standard Quicksort procedure. We also exhibit specific forbidden configurations for rank $4$ tournaments. For a general rank $d$ tournament class, we show that the flip class associated with a coned-doubly regular tournament of size $\\mathcal{O}(\\sqrt{d})$ must be a forbidden configuration. To answer a dual question, using a celebrated result of Froster, we show a lower bound of $\\Theta(\\sqrt{n})$ on the minimum dimension needed to represent all tournaments on $n$ nodes. For any given tournament, we show a novel upper bound on the smallest representation dimension that depends on the least size of the number of unique nodes in any feedback arc set of the flip class associated with a tournament. We show how our results also shed light on the upper bound of sign-rank of matrices.",
    "One-sentence Summary": "We develop a theory to understand tournament representations i.e. structurally characterise when a tournament graph can be represented in lower dimensions using a skew symmetric matrix."
  },
  {
    "title": "Convergent and Efficient Deep Q Learning Algorithm",
    "url": "/forum?id=OJm3HZuj4r7",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "DQN, reinforcement learning, convergence",
    "Abstract": "Despite the empirical success of the deep Q network (DQN) reinforcement learning algorithm and its variants, DQN is still not well understood and it does not guarantee convergence. In this work, we show that DQN can indeed diverge and cease to operate in realistic settings. Although there exist gradient-based convergent methods, we show that they actually have inherent problems in learning dynamics which cause them to fail even for simple tasks. To overcome these problems, we propose a convergent DQN algorithm (C-DQN) that is guaranteed to converge and can work with large discount factors (0.9998). It learns robustly in difficult settings and can learn several difficult games in the Atari 2600 benchmark that DQN fails to solve."
  },
  {
    "title": "Trigger Hunting with a Topological Prior for Trojan Detection",
    "url": "/forum?id=TXsjU8BaibT",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Trojan detection, diversity loss, topological prior",
    "Abstract": "Despite their success and popularity, deep neural networks (DNNs) are vulnerable when facing backdoor attacks. This impedes their wider adoption, especially in mission critical applications. This paper tackles the problem of Trojan detection, namely, identifying Trojaned models \u2013 models trained with poisoned data. One popular approach is reverse engineering, i.e., recovering the triggers on a clean image by manipulating the model\u2019s prediction. One major challenge of reverse engineering approach is the enormous search space of triggers. To this end, we propose innovative priors such as diversity and topological simplicity to not only increase the chances of finding the appropriate triggers but also improve the quality of the found triggers. Moreover, by encouraging a diverse set of trigger candidates, our method can perform effectively in cases with unknown target labels. We demonstrate that these priors can significantly improve the quality of the recovered triggers, resulting in substantially improved Trojan detection accuracy as validated on both synthetic and publicly available TrojAI benchmarks."
  },
  {
    "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL",
    "url": "/forum?id=JM2kFbJvvI",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "adversarial RL, robustness of RL, evasion attack, optimal attack, observation perturbation",
    "Abstract": "Evaluating the worst-case performance of a reinforcement learning (RL) agent under the strongest/optimal adversarial perturbations on state observations (within some constraints) is crucial for understanding the robustness of RL agents. However, finding the optimal adversary is challenging, in terms of both whether we can find the optimal attack and how efficiently we can find it. Existing works on adversarial RL either use heuristics-based methods that may not find the strongest adversary, or directly train an RL-based adversary by treating the agent as a part of the environment, which can find the optimal adversary but may become intractable in a large state space. \n        This paper introduces a novel attacking method to find the optimal attacks through collaboration between a designed function named \"actor\" and an RL-based learner named \"director'\". The actor crafts state perturbations for a given policy perturbation direction, and the director learns to propose the best policy perturbation directions. Our proposed algorithm, PA-AD, is theoretically optimal and significantly more efficient than prior RL-based works in environments with large state spaces. Empirical results show that our proposed PA-AD universally outperforms state-of-the-art attacking methods in various Atari and MuJoCo environments. By applying PA-AD to adversarial training, we achieve state-of-the-art empirical robustness in multiple tasks under strong adversaries.",
    "One-sentence Summary": "We theoretically characterize the essence of evasion attacks in RL, and propose a novel attack algorithm for RL agents, which achieves state-of-the-art performance on both attacking and robustifying RL agents in many Atari and MuJoCo tasks."
  },
  {
    "title": "Chunked Autoregressive GAN for Conditional Waveform Synthesis",
    "url": "/forum?id=v3aeIsY_vVX",
    "date": "28 Sept 2021 (modified: 03 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "audio generation, speech synthesis, deep learning, generative models, autoregression, generative adversarial networks",
    "Abstract": "Conditional waveform synthesis models learn a distribution of audio waveforms given conditioning such as text, mel-spectrograms, or MIDI. These systems employ deep generative models that model the waveform via either sequential (autoregressive) or parallel (non-autoregressive) sampling. Generative adversarial networks (GANs) have become a common choice for non-autoregressive waveform synthesis. However, state-of-the-art GAN-based models produce artifacts when performing mel-spectrogram inversion. In this paper, we demonstrate that these artifacts correspond with an inability for the generator to learn accurate pitch and periodicity. We show that simple pitch and periodicity conditioning is insufficient for reducing this error relative to using autoregression. We discuss the inductive bias that autoregression provides for learning the relationship between instantaneous frequency and phase, and show that this inductive bias holds even when autoregressively sampling large chunks of the waveform during each forward pass. Relative to prior state-of-the-art GAN-based models, our proposed model, Chunked Autoregressive GAN (CARGAN) reduces pitch error by 40-60%, reduces training time by 58%, maintains a fast inference speed suitable for real-time or interactive applications, and maintains or improves subjective quality.",
    "One-sentence Summary": "We improve the state-of-the-art of conditional waveform synthesis by combining the strengths of GANs and autoregression"
  },
  {
    "title": "COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks",
    "url": "/forum?id=psh0oeMSBiF",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "certified robustness, poisoning attacks, reinforcement learning",
    "Abstract": "As reinforcement learning (RL) has achieved near human-level performance in a variety of tasks, its robustness has raised great attention. While a vast body of research has explored test-time (evasion) attacks in RL and corresponding defenses, its robustness against training-time (poisoning) attacks remains largely unanswered. In this work, we focus on certifying the robustness of of\ufb02ine RL in the presence of poisoning attacks, where a subset of training trajectories could be arbitrarily manipulated. We propose the \ufb01rst certi\ufb01cation framework, COPA, to certify the number of poisoning trajectories that can be tolerated regarding different certi\ufb01cation criteria. Given the complex structure of RL, we propose two certi\ufb01cation criteria: per-state action stability and cumulative reward bound. To further improve the certi\ufb01cation, we propose new partition and aggregation protocols to train robust policies. We further prove that some of the proposed certi\ufb01cation methods are theoretically tight and some are NP-Complete problems. We leverage COPA to certify three RL environments trained with different algorithms and conclude: (1) The proposed robust aggregation protocols such as temporal aggregation can signi\ufb01cantly improve the certi\ufb01cations; (2) Our certi\ufb01cations for both per-state action stability and cumulative reward bound are ef\ufb01cient and tight; (3) The certi\ufb01cation for different training algorithms and environments are different, implying their intrinsic robustness properties. All experimental results are available at https://copa-leaderboard.github.io.",
    "One-sentence Summary": "We propose the first framework for certifiying robustness of offline reinforcement learning against poisoning attacks."
  },
  {
    "title": "ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning",
    "url": "/forum?id=Vzh1BFUCiIX",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Natural Language Processing, Transfer Learning, Multi-task Learning",
    "Abstract": "Despite the recent success of multi-task learning and transfer learning for natural language processing (NLP), few works have systematically studied the effect of scaling up the number of tasks during pre-training. Towards this goal, this paper introduces ExMix (Extreme Mixture): a massive collection of 107 supervised NLP tasks across diverse domains and task-families. Using ExMix, we study the effect of multi-task pre-training at the largest scale to date, and analyze co-training transfer amongst common families of tasks. Through this analysis, we show that manually curating an ideal set of tasks for multi-task pre-training is not straightforward, and that multi-task scaling can vastly improve models on its own. Finally, we propose ExT5: a model pre-trained using a multi-task objective of self-supervised span denoising and supervised ExMix. Via extensive experiments, we show that ExT5 outperforms strong T5 baselines on SuperGLUE, GEM, Rainbow, Closed-Book QA tasks, and several tasks outside of ExMix. ExT5 also significantly improves sample efficiency while pre-training.",
    "One-sentence Summary": "Using a suite of 107 NLP tasks, we show that massively multi-task pre-training can improve downstream performance on NLP tasks, overcoming trends of negative transfer between tasks while fine-tuning."
  },
  {
    "title": "Provable Adaptation across Multiway Domains via Representation Learning",
    "url": "/forum?id=gRCCdgpVZf",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Representation learning, tensor, statistical learning theory",
    "Abstract": "This paper studies zero-shot domain adaptation where each domain is indexed on a multi-dimensional array, and we only have data from a small subset of domains. Our goal is to produce predictors that perform well on \\emph{unseen} domains. We propose a model which consists of a domain-invariant latent representation layer and a domain-specific linear prediction layer with a low-rank tensor structure. Theoretically, we present explicit sample complexity bounds to characterize the prediction error on unseen domains in terms of the number of domains with training data and the number of data per domain. To our knowledge, this is the first finite-sample guarantee for zero-shot domain adaptation. In addition, we provide experiments on two-way MNIST and four-way fiber sensing datasets to demonstrate the effectiveness of our proposed model."
  },
  {
    "title": "Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators",
    "url": "/forum?id=EXHG-A3jlM",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self attention, linear complexity, high-resolution inputs, operator learning, Fourier transform",
    "Abstract": "Vision transformers have delivered tremendous success in representation learning. This is primarily due to effective token mixing through self attention. However, this scales quadratically with the number of pixels, which becomes infeasible for high-resolution inputs. To cope with this challenge, we propose Adaptive Fourier Neural Operator (AFNO) as an efficient token mixer that learns to mix in the Fourier domain. AFNO is based on a principled foundation of operator learning which allows us to frame token mixing as a continuous global convolution without any dependence on the input resolution. This principle was previously used to design FNO, which solves global convolution efficiently in the Fourier domain and has shown promise in learning challenging PDEs. To handle challenges in visual representation learning such as discontinuities in images and high resolution inputs, we propose principled architectural modifications to FNO which results in memory and computational efficiency. This includes imposing a block-diagonal structure on the channel mixing weights, adaptively sharing weights across tokens, and sparsifying the frequency modes via soft-thresholding and shrinkage. The resulting model is highly parallel with a quasi-linear complexity and has linear memory in the sequence size. AFNO outperforms self-attention mechanisms for few-shot segmentation in terms of both efficiency and accuracy. For Cityscapes segmentation with the Segformer-B3 backbone, AFNO can handle a sequence size of 65k and outperforms other efficient self-attention mechanisms.",
    "One-sentence Summary": "We propose Adaptive Fourier Neural Operators (AFNO) for scaling self-attention to high resolution images in vision transformers by establishing a link between operator learning and token mixing."
  },
  {
    "title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
    "url": "/forum?id=xENf4QUL4LW",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Learning with noisy labels, Sample selection, Uncertainty",
    "Abstract": "In learning with noisy labels, the sample selection approach is very popular, which regards small-loss data as correctly labeled data during training. However, losses are generated on-the-\ufb02y based on the model being trained with noisy labels, and thus large-loss data are likely but not certain to be incorrect. There are actually two possibilities of a large-loss data point: (a) it is mislabeled, and then its loss decreases slower than other data, since deep neural networks learn patterns \ufb01rst; (b) it belongs to an underrepresented group of data and has not been selected yet. In this paper, we incorporate the uncertainty of losses by adopting interval estimation instead of point estimation of losses, where lower bounds of the con\ufb01dence intervals of losses derived from distribution-free concentration inequalities, but not losses themselves, are used for sample selection. In this way, we also give large-loss but less selected data a try; then, we can better distinguish between the cases (a) and (b) by seeing if the losses effectively decrease with the uncertainty after the try. As a result, we can better explore underrepresented data that are correctly labeled but seem to be mislabeled at \ufb01rst glance. Experiments demonstrate that the proposed method is superior to baselines and robust to a broad range of label noise types."
  },
  {
    "title": "Data-Driven Offline Optimization for Architecting Hardware Accelerators",
    "url": "/forum?id=GsH-K1VIyy",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "computer architecture and systems, machine learning, data-driven optimization",
    "Abstract": "To attain higher efficiency, the industry has gradually reformed towards application-specific hardware accelerators. While such a paradigm shift is already starting to show promising results, designers need to spend considerable manual effort and perform large number of time-consuming simulations to find accelerators that can accelerate multiple target applications while obeying design constraints. Moreover, such a simulation-driven approach must be re-run from scratch every time the set of target applications or design constraints change. An alternative paradigm is to use a data-driven, offline approach that utilizes logged simulation data, to architect hardware accelerators, without needing any form of simulations. Such an approach not only alleviates the need to run time-consuming simulation, but also enables data reuse and applies even when set of target applications changes. In this paper, we develop such a data-driven offline optimization method for designing hardware accelerators, dubbed PRIME, that enjoys all of these properties. Our approach learns a conservative, robust estimate of the desired cost function, utilizes infeasible points and optimizes the design against this estimate without any additional simulator queries during optimization. PRIME architects accelerators---tailored towards both single- and multi-applications---improving performance upon stat-of-the-art simulation-driven methods by about 1.54x and 1.20x, while considerably reducing the required total simulation time by 93% and 99%, respectively. In addition, PRIME also architects effective accelerators for unseen applications in a zero-shot setting, outperforming simulation-based methods by 1.26x."
  },
  {
    "title": "Multi-Agent MDP Homomorphic Networks",
    "url": "/forum?id=H7HDG--DJF0",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multiagent systems, reinforcement learning, equivariance, symmetry",
    "Abstract": "This paper introduces Multi-Agent MDP Homomorphic Networks, a class of networks that allows distributed execution using only local information, yet is able to share experience between global symmetries in the joint state-action space of cooperative multi-agent systems. In cooperative multi-agent systems, complex symmetries arise between different configurations of the agents and their local observations. For example, consider a group of agents navigating: rotating the state globally results in a permutation of the optimal joint policy. Existing work on symmetries in single agent reinforcement learning can only be generalized to the fully centralized setting, because such approaches rely on the global symmetry in the full state-action spaces, and these can result in correspondences across agents. To encode such symmetries while still allowing distributed execution we propose a factorization that decomposes global symmetries into local transformations. Our proposed factorization allows for distributing the computation that enforces global symmetries over local agents and local interactions. We introduce a multi-agent equivariant policy network based on this factorization. We show empirically on symmetric multi-agent problems that globally symmetric distributable policies improve data efficiency compared to non-equivariant baselines.",
    "One-sentence Summary": "We introduce globally equivariant multi-agent policy networks with distributed execution."
  },
  {
    "title": "Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields",
    "url": "/forum?id=yhCp5RcZD7",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "implicit functions, shape reconstruction, shape representation, object reconstruction",
    "Abstract": "We present implicit displacement fields, a novel representation for detailed 3D geometry. Inspired by a classic surface deformation technique, displacement mapping, our method represents a complex surface as a smooth base surface plus a displacement along the base's normal directions, resulting in a frequency-based shape decomposition, where the high-frequency signal is constrained geometrically by the low-frequency signal. Importantly, this disentanglement is unsupervised thanks to a tailored architectural design that has an innate frequency hierarchy by construction. We explore implicit displacement field surface reconstruction and detail transfer\n        and demonstrate superior representational power, training stability, and generalizability.",
    "One-sentence Summary": "We extend classic displacement mapping to the neural implicit framework. The resulting novel implicit representation demonstrates superior reconstruction accuracy, parameter efficiency and enable implicit shape editing such as detail transfer."
  },
  {
    "title": "Modeling Label Space Interactions in Multi-label Classification using Box Embeddings",
    "url": "/forum?id=tyTH9kOxcvh",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multi-label classification, Box Embeddings, Representation Learning, Embeddings",
    "Abstract": "Multi-label classification is a challenging structured prediction task in which a set of output class labels are predicted for each input. Real-world datasets often have natural or latent taxonomic relationships between labels, making it desirable for models to employ label representations capable of capturing such taxonomies. Most existing multi-label classification methods do not do so, resulting in label predictions that are inconsistent with the taxonomic constraints, thus failing to accurately represent the fundamentals of problem setting. In this work, we introduce the multi-label box model (MBM), a multi-label classification method that combines the encoding power of neural networks with the inductive bias and probabilistic semantics of box embeddings (Vilnis, et al 2018).  Box embeddings can be understood as trainable Venn-diagrams based on hyper-rectangles.  Representing labels by boxes rather than vectors, MBM is able to capture taxonomic relations among labels.  Furthermore, since box embeddings allow these relations to be learned by stochastic gradient descent from data, and to be read as calibrated conditional probabilities, our model is endowed with a high degree of interpretability. This interpretability also facilitates the injection of partial information about label-label relationships into model training, to further improve its consistency. We provide theoretical grounding for our method and show experimentally the model's ability to learn the true latent taxonomic structure from data. Through extensive empirical evaluations on both small and large-scale multi-label classification datasets, we show that BBM can significantly improve taxonomic consistency while preserving or surpassing the state-of-the-art predictive performance.",
    "One-sentence Summary": "Improving the consistency for multi-label classification by modeling label space interactions using Box Embeddings."
  },
  {
    "title": "It Takes Two to Tango: Mixup for Deep Metric Learning",
    "url": "/forum?id=ZKy2X3dgPA",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Metric learning involves learning a discriminative representation such that embeddings of similar classes are encouraged to be close, while embeddings of dissimilar classes are pushed far apart. State-of-the-art methods focus mostly on sophisticated loss functions or mining strategies. On the one hand, metric learning losses consider two or more examples at a time. On the other hand, modern data augmentation methods for classification consider two or more examples at a time. The combination of the two ideas is under-studied.\n        \n        In this work, we aim to bridge this gap and improve representations using mixup, which is a powerful data augmentation approach interpolating two or more examples and corresponding target labels at a time. This task is challenging because, unlike classification, the loss functions used in metric learning are not additive over examples, so the idea of interpolating target labels is not straightforward. To the best of our knowledge, we are the first to investigate mixing both examples and target labels for deep metric learning. We develop a generalized formulation that encompasses existing metric learning loss functions and modify it to accommodate for mixup, introducing Metric Mix, or Metrix. We also introduce a new metric---utilization---to demonstrate that by mixing examples during training, we are exploring areas of the embedding space beyond the training classes, thereby improving representations. To validate the effect of improved representations, we show that mixing inputs, intermediate representations or embeddings along with target labels significantly outperforms state-of-the-art metric learning methods on four benchmark deep metric learning datasets.",
    "One-sentence Summary": "We systematically study different mixup strategies in the context of deep metric learning, and study how to, and the effect of, mixing inputs, features, and output embeddings."
  },
  {
    "title": "Data Efficient Language-Supervised Zero-Shot Recognition with Optimal Transport Distillation",
    "url": "/forum?id=G89-1yZLFHk",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Zero shot learning, contrastive learning, optimal transport, vision and language",
    "Abstract": "Traditional computer vision models are trained to predict a fixed set of predefined categories. Recently, natural language has been shown to be a broader and richer source of supervision that provides finer descriptions to visual concepts than supervised \"gold\" labels. Previous works, such as CLIP, use InfoNCE loss to train a model to predict the pairing between images and text captions. CLIP, however, is data hungry and requires more than 400M image-text pairs for training. The inefficiency can be \\textit{partially} attributed to the fact that the image-text pairs are noisy. To address this, we propose OTTER (Optimal TransporT distillation for Efficient zero-shot Recognition), which uses online entropic optimal transport to find a soft image-text match as labels for contrastive learning. Based on pretrained image and text encoders, models trained with OTTER achieve strong performance with only 3M image text pairs. Compared with InfoNCE loss, label smoothing, and knowledge distillation, OTTER consistently outperforms these baselines in zero-shot evaluation on Google Open Images (19,958 classes) and multi-labeled ImageNet 10K (10032 classes) from Tencent ML-Images. Over 42 evaluations on 7 different dataset/architecture settings x 6 metrics, OTTER outperforms (32) or ties (2) all baselines in 34 of them. Our source code is open sourced at https://github.com/facebookresearch/OTTER.",
    "One-sentence Summary": "We improve the image-text contrastive learning by augmenting InfoNCE with Optimal Transport"
  },
  {
    "title": "A Statistical Framework for Efficient Out of Distribution Detection in Deep Neural Networks",
    "url": "/forum?id=Oy9WeuZD51",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "out of distribution, DNNs, p-value, hypothesis testing, inductive conformal predictor",
    "Abstract": "Background.\n        Commonly, Deep Neural Networks (DNNs) generalize well on samples drawn from a distribution similar to that of the training set. However, DNNs' predictions are brittle and unreliable when the test samples are drawn from a dissimilar distribution.\n        This is a major concern for deployment in real-world applications, where such behavior may come at a considerable cost, such as industrial production lines, autonomous vehicles, or healthcare applications.\n        \n        Contributions.\n        We frame Out Of Distribution (OOD) detection in DNNs as a statistical hypothesis testing problem. Tests generated within our proposed framework combine evidence from the entire network.\n        Unlike previous OOD detection heuristics, this framework returns a $p$-value for each test sample. It is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD for an actual in-distribution sample) for test data. Moreover, this allows to combine several detectors while maintaining the T1E.\n        \n        Building on this framework, we suggest a novel OOD procedure based on low-order statistics. Our method achieves comparable or better results than state-of-the-art methods on well-accepted OOD benchmarks, without retraining the network parameters or assuming prior knowledge on the test distribution --- and at a fraction of the computational cost."
  },
  {
    "title": "FedBABU: Toward Enhanced Representation for Federated Image Classification",
    "url": "/forum?id=HuaYQfggn5u",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, Representation Learning",
    "Abstract": "Federated learning has evolved to improve a single global model under data heterogeneity (as a curse) or to develop multiple personalized models using data heterogeneity (as a blessing). However, little research has considered both directions simultaneously. In this paper, we first investigate the relationship between them by analyzing Federated Averaging at the client level and determine that a better federated global model performance does not constantly improve personalization. To elucidate the cause of this personalization performance degradation problem, we decompose the entire network into the body (extractor), which is related to universality, and the head (classifier), which is related to personalization. We then point out that this problem stems from training the head. Based on this observation, we propose a novel federated learning algorithm, coined FedBABU, which only updates the body of the model during federated training (i.e., the head is randomly initialized and never updated), and the head is fine-tuned for personalization during the evaluation process. Extensive experiments show consistent performance improvements and an efficient personalization of FedBABU. The code is available at https://github.com/jhoon-oh/FedBABU.",
    "One-sentence Summary": "We propose a novel algorithm, FedBABU, which updates and aggregates only the body during federated training for enhanced representation."
  },
  {
    "title": "Should I Run Offline Reinforcement Learning or Behavioral Cloning?",
    "url": "/forum?id=AP1MKT37rJ",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "offline RL",
    "Abstract": "Offline reinforcement learning (RL) algorithms can acquire effective policies by utilizing only previously collected experience, without any online interaction.  While it is widely understood that offline RL is able to extract good policies even from highly suboptimal data, in practice offline RL is often used with data that resembles demonstrations. In this case, one can also use behavioral cloning (BC) algorithms, which mimic a subset of the dataset via supervised learning. It seems natural to ask: When should we prefer offline RL over BC? In this paper, our goal is to characterize environments and dataset compositions where offline RL leads to better performance than BC.  In particular, we characterize the properties of environments that allow offline RL methods to perform better than BC methods even when only provided with expert data. Additionally, we show that policies trained on suboptimal data that is sufficiently noisy can attain better performance than even BC algorithms with expert data, especially on long-horizon problems. We validate our theoretical results via extensive experiments on both diagnostic and high-dimensional domains including robot manipulation, maze navigation and Atari games, when learning from a variety of data sources. We observe that modern offline RL methods trained on suboptimal, noisy data in sparse reward domains outperform cloning the expert data in several practical problems.",
    "One-sentence Summary": "Characterization of scenarios where offline reinforcement learning outperforms behavioral cloning"
  },
  {
    "title": "Learning State Representations via Retracing in Reinforcement Learning",
    "url": "/forum?id=CLpxpXqqBV",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Representation learning, model-based reinforcement learning",
    "Abstract": "We propose learning via retracing, a novel self-supervised approach for learning the state representation (and the associated dynamics model) for reinforcement learning tasks. In addition to the predictive (reconstruction) supervision in the forward direction, we propose to include \"retraced\" transitions for representation/model learning, by enforcing the cycle-consistency constraint between the original and retraced states, hence improve upon the sample efficiency of learning. Moreover, learning via retracing explicitly propagates information about future transitions backward for inferring previous states, thus facilitates stronger representation learning for the downstream reinforcement learning tasks. We introduce Cycle-Consistency World Model (CCWM), a concrete model-based instantiation of learning via retracing. Additionally we propose a novel adaptive \"truncation\" mechanism for counteracting the negative impacts brought by \"irreversible\" transitions such that learning via retracing can be maximally effective. Through extensive empirical studies on visual-based continuous control benchmarks, we demonstrate that CCWM achieves state-of-the-art performance in terms of sample efficiency and asymptotic performance, whilst exhibiting behaviours that are indicative of stronger representation learning.",
    "One-sentence Summary": "We introduce Learning via Retracing, a novel self-supervised framework based on temporal cycle-consistency assumption of the transition dynamics, for improved learning of the representation (and the dynamics model) in RL tasks."
  },
  {
    "title": "Open-World Semi-Supervised Learning",
    "url": "/forum?id=O-r8LOR-CCA",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep learning, semi-supervised learning, novel class discovery, clustering",
    "Abstract": "A fundamental limitation of applying semi-supervised learning in real-world settings is the assumption that unlabeled test data contains only classes previously encountered in the labeled training data. However, this assumption rarely holds for data in-the-wild, where instances belonging to novel classes may appear at testing time. Here, we introduce a novel open-world semi-supervised learning setting that formalizes the notion that novel classes may appear in the unlabeled test data. In this novel setting, the goal is to solve the class distribution mismatch problem between labeled and unlabeled data, where at the test time every input instance either needs to be classified into one of the existing classes or a new unseen class needs to be initialized and the instance assigned to it. To tackle this challenging problem, we propose ORCA, an end-to-end approach that assigns instances to previously seen classes or  forms novel classes by grouping similar instances without assuming any prior knowledge. The key idea in ORCA is to utilize uncertainty adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. In this way, ORCA gradually increases the discriminability of the model during the training and reduces the gap between intra-class variance of seen with respect to novel classes. Extensive experiments on image classification datasets and a single-cell dataset demonstrate that ORCA consistently outperforms alternative baselines, achieving 25% improvement on seen and 96% improvement on novel classes of the ImageNet dataset.",
    "One-sentence Summary": "We propose a pipeline that recognizes previously seen classes and discovers novel, never-before-seen classes at the same time."
  },
  {
    "title": "Evading Adversarial Example Detection Defenses with Orthogonal Projected Gradient Descent",
    "url": "/forum?id=af1eUDdUVz",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial examples, adversarial attacks",
    "Abstract": "Evading adversarial example detection defenses requires finding adversarial examples that must simultaneously (a) be misclassified by the model and (b) be detected as non-adversarial. We find that existing attacks that attempt to satisfy multiple simultaneous constraints often over-optimize against one constraint at the cost of satisfying another. We introduce Selective Projected Gradient Descent and Orthogonal Projected Gradient Descent, improved attack techniques to generate adversarial examples that avoid this problem by orthogonalizing the gradients when running standard gradient-based attacks. We use our technique to evade four state-of-the-art detection defenses, reducing their accuracy to 0% while maintaining a 0% detection rate.",
    "One-sentence Summary": "We break four defenses that detect adversarial examples by introducing an improved attack technique that modifies the gradient before applying PGD."
  },
  {
    "title": "Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off",
    "url": "/forum?id=Azh9QBQ4tR7",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "adversarial training, robustness",
    "Abstract": "While adversarial training has become the de facto approach for training robust classifiers, it leads to a drop in accuracy. This has led to prior works postulating that accuracy is inherently at odds with robustness. Yet, the phenomenon remains inexplicable. In this paper, we closely examine the changes induced in the decision boundary of a deep network during adversarial training. We find that adversarial training leads to unwarranted increase in the margin along certain adversarial directions, thereby hurting accuracy. Motivated by this observation, we present a novel algorithm, called Helper-based Adversarial Training (HAT), to reduce this effect by incorporating additional wrongly labelled examples during training. Our proposed method provides a notable improvement in accuracy without compromising robustness. It achieves a better trade-off between accuracy and robustness in comparison to existing defenses. Code is available at https://github.com/imrahulr/hat."
  },
  {
    "title": "Expressivity of Emergent Languages is a Trade-off between Contextual Complexity and Unpredictability",
    "url": "/forum?id=WxuE_JWxjkW",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Emergent Language, Expressivity",
    "Abstract": "Researchers are using deep learning models to explore the emergence of language in various language games, where agents interact and develop an emergent language to solve tasks. We focus on the factors that determine the expressivity of emergent languages, which reflects the amount of information about input spaces those languages are capable of encoding. We measure the expressivity of emergent languages based on the generalisation performance across different games, and demonstrate that the expressivity of emergent languages is a trade-off between the complexity and unpredictability of the context those languages emerged from. Another contribution of this work is the discovery of message type collapse, i.e. the number of unique messages is lower than that of inputs. We also show that using the contrastive loss proposed by Chen et al. (2020) can alleviate this problem.",
    "One-sentence Summary": "We demonstrate that the expressivity of emergent languages is a trade-off between the complexity and unpredictability of the context those languages are used in."
  },
  {
    "title": "Fast AdvProp",
    "url": "/forum?id=hcoswsDHNAW",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial examples, efficient training, generalization",
    "Abstract": "Adversarial Propagation (AdvProp) is an effective way to improve recognition models, leveraging adversarial examples. Nonetheless, AdvProp suffers from the extremely slow training speed, mainly because: a) extra forward and backward passes are required for generating adversarial examples; b) both original samples and their adversarial counterparts are used for training (i.e., 2X data).  In this paper, we introduce Fast AdvProp, which aggressively revamps AdvProp's costly training components, rendering the method nearly as cheap as the vanilla training. Specifically, our modifications in Fast AdvProp are guided by the hypothesis that disentangled learning with adversarial examples is the key for performance improvements, while other training recipes (e.g., paired clean and adversarial training samples, multi-step adversarial attackers) could be largely simplified.   \n        \n        Our empirical results show that, compared to the vanilla training baseline, Fast AdvProp is able to further model performance on a spectrum of visual benchmarks, without incurring extra training cost. Additionally, our ablations find Fast AdvProp scales better if larger models are used, is compatible with existing data augmentation methods (i.e., Mixup and CutMix), and can be easily adapted to other recognition tasks like object detection.  The code is available here: https://github.com/meijieru/fast_advprop."
  },
  {
    "title": "Triangle and Four Cycle Counting with Predictions in Graph Streams",
    "url": "/forum?id=8in_5gN9I0",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "learning augmented, streaming, graph streaming, data driven, cycle counting, triangle counting",
    "Abstract": "We propose data-driven one-pass streaming algorithms for estimating the number of triangles and four cycles, two fundamental problems in graph analytics that are widely studied in the graph data stream literature. Recently, Hsu et al. (2019) and Jiang et al. (2020) applied machine learning techniques in other data stream problems, using a trained oracle that can predict certain properties of the stream elements to improve on prior \u201cclassical\u201d algorithms that did not use oracles. In this paper, we explore the power of a \u201cheavy edge\u201d oracle in multiple graph edge streaming models. In the adjacency list model, we present a one-pass triangle counting algorithm improving upon the previous space upper bounds without such an oracle. In the arbitrary order model, we present algorithms for both triangle and four cycle estimation with fewer passes and the same space complexity as in previous algorithms, and we show several of these bounds are optimal. We analyze our algorithms under several noise models, showing that the algorithms perform well even when the oracle errs. Our methodology expands upon prior work on \u201cclassical\u201d streaming algorithms, as previous multi-pass and random order streaming algorithms can be seen as special cases of our algorithms, where the first pass or random order was used to implement the heavy edge oracle. Lastly, our experiments demonstrate advantages of the proposed method compared to state-of-the-art streaming algorithms.",
    "One-sentence Summary": "We propose algorithms for counting triangles and four cycles in graph streams with the aid of ML predictors."
  },
  {
    "title": "Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning",
    "url": "/forum?id=js62_xuLDDv",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep metric learning, fairness, representation learning",
    "Abstract": "Deep metric learning (DML) enables learning with less supervision through its emphasis on the similarity structure of representations. There has been much work on improving  generalization of DML in settings like zero-shot retrieval, but little is known about its implications for fairness. In this paper, we are the first to evaluate state-of-the-art DML methods trained on imbalanced data, and to show the negative impact these representations have on minority subgroup performance when used for downstream tasks. In this work, we first define fairness in DML through an analysis of three properties of the representation space -- inter-class alignment, intra-class alignment, and uniformity -- and propose \\textit{\\textbf{finDML}}, the \\textit{\\textbf{f}}airness \\textit{\\textbf{i}}n \\textit{\\textbf{n}}on-balanced \\textit{\\textbf{DML}} benchmark to characterize representation fairness. Utilizing \\textit{finDML}, we find bias in DML representations to propagate to common downstream classification tasks. Surprisingly, this bias is propagated even when training data in the downstream task is re-balanced. To address this problem, we present Partial Attribute De-correlation (\\textit{\\textbf{\\pad}}) to disentangle feature representations from sensitive attributes and reduce performance gaps between subgroups in both embedding space and downstream metrics.",
    "One-sentence Summary": "We provide a benchmark for fairness in the scope of deep metric learning; investigate fairness impacts of learned representations on downstream classification; and provide a novel method for reducing subgroup gaps in deep metric learning methods."
  },
  {
    "title": "NodePiece: Compositional and Parameter-Efficient Representations of Large Knowledge Graphs",
    "url": "/forum?id=xMJWUKJnFSw",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "knowledge graphs, graph representation learning, tokenization, link prediction, node classification",
    "Abstract": "Conventional representation learning algorithms for knowledge graphs (KG) map each entity to a unique embedding vector. \n        Such a shallow lookup results in a linear growth of memory consumption for storing the embedding matrix and incurs high computational costs of working with real-world KGs.\n        Drawing parallels with subword tokenization commonly used in NLP, we explore the landscape of more parameter-efficient node embedding strategies with possibly sublinear memory requirements. \n        To this end, we propose NodePiece, an anchor-based approach to learn a fixed-size entity vocabulary. \n        In NodePiece, a vocabulary of subword/sub-entity units is constructed from anchor nodes in a graph with known relation types. Given such a fixed-size vocabulary, it is possible to bootstrap an encoding and embedding for any entity, including those unseen during training.\n        Experiments show that NodePiece performs competitively in node classification, link prediction, and relation prediction tasks retaining less than 10% of explicit nodes in a graph as anchors and often having 10x fewer parameters. To this end, we show that a NodePiece-enabled model outperforms existing shallow models on a large OGB WikiKG 2 graph having 70x fewer parameters.",
    "One-sentence Summary": "Node hashing in graphs for 10-100x embedding size reduction without significant performance losses on many tasks and inductive out of the box."
  },
  {
    "title": "Pix2seq: A Language Modeling Framework for Object Detection",
    "url": "/forum?id=e42KbIw6Wb",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "language modeling, object detection",
    "Abstract": "We present Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, we cast object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural network to perceive the image and generate the desired sequence. Our approach is based mainly on the intuition that if a neural network knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task-specific data augmentations, our approach makes minimal assumptions about the task, yet it achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms.",
    "One-sentence Summary": "We demonstrated that object detection can be tackled by simply training a language model conditioned on pixel inputs."
  },
  {
    "title": "Particle Stochastic Dual Coordinate Ascent: Exponential convergent algorithm for mean field neural network optimization",
    "url": "/forum?id=PQQp7AJwz3",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Network Optimization, Mean field Regime, Overparameterization",
    "Abstract": "We introduce Particle-SDCA, a gradient-based optimization algorithm for two-layer neural networks in the mean field regime that achieves exponential convergence rate in regularized empirical risk minimization. The proposed algorithm can be regarded as an infinite dimensional extension of Stochastic Dual Coordinate Ascent (SDCA) in the probability space: we exploit the convexity of the dual problem, for which the coordinate-wise proximal gradient method can be applied. Our proposed method inherits advantages of the original SDCA, including (i) exponential convergence (with respect to the outer iteration steps), and (ii) better dependency on the sample size and condition number than the full-batch gradient method. One technical challenge in implementing the SDCA update is the intractable integral over the entire parameter space at every step. To overcome this limitation, we propose a tractable \\textit{particle method} that approximately solves the dual problem, and an importance re-weighted technique to reduce the computational cost. The convergence rate of our method is verified by numerical experiments.",
    "One-sentence Summary": "Proposed a new algorithm for optimizing two-layer neural network in the mean field regime that achieves exponential convergence in regularized empirical risk minimization (w.r.t. outer loop iterations)."
  },
  {
    "title": "The Effects of Invertibility on the Representational Complexity of Encoders in Variational Autoencoders",
    "url": "/forum?id=7_JR7WpwKV1",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "variational autoencoders, encoder, representational complexity, Langevin, invertibility, deep learning theory",
    "Abstract": "Training and using modern neural-network based latent-variable generative models (like Variational Autoencoders) often require simultaneously training a generative direction along with an inferential (encoding) direction, which approximates the posterior distribution over the latent variables. Thus, the question arises: how complex does the inferential model need to be, in order to be able to accurately model the posterior distribution of a given generative model?  In this paper, we identify an important property of the generative map impacting the required size of the encoder. We show that if the generative map is ``strongly invertible\" (in a sense we suitably formalize), the inferential model need not be much more complex. Conversely, we prove that there exist non-invertible generative maps, for which the encoding direction needs to be exponentially larger (under standard assumptions in computational complexity). Importantly, we do not require the generative model to be layerwise invertible, which a lot of the related literature assumes and isn't satisfied by many architectures used in practice (e.g. convolution and pooling based networks). Thus, we provide theoretical support for the empirical wisdom that learning deep generative models is harder when data lies on a low-dimensional manifold.",
    "One-sentence Summary": "VAEs with invertible mean map have small approximate encoders; non-invertible maps can result in large encoders."
  },
  {
    "title": "Tracking the risk of a deployed model and detecting harmful distribution shifts",
    "url": "/forum?id=Ro_zAjZppv",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Distribution shift, sequential testing",
    "Abstract": "When deployed in the real world, machine learning models inevitably encounter changes in the data distribution, and certain---but not all---distribution shifts could result in significant performance degradation. In practice, it may make sense to ignore benign shifts, under which the performance of a deployed model does not degrade substantially, making interventions by a human expert (or model retraining) unnecessary.  While several works have developed tests for distribution shifts, these typically either use non-sequential methods, or detect arbitrary shifts (benign or harmful), or both. We argue that a sensible method for firing off a warning has to both (a) detect harmful shifts while ignoring benign ones, and (b) allow continuous monitoring of model performance without increasing the false alarm rate. In this work, we design simple sequential tools for testing if the difference between source (training) and target (test) distributions leads to a significant increase in a risk function of interest, like accuracy or calibration. Recent advances in constructing time-uniform confidence sequences allow efficient aggregation of statistical evidence accumulated during the tracking process. The designed framework is applicable in settings where (some) true labels are revealed after the prediction is performed, or when batches of labels become available in a delayed fashion. We demonstrate the efficacy of the proposed framework through an extensive empirical study on a collection of simulated and real datasets."
  },
  {
    "title": "Towards Understanding the Robustness Against Evasion Attack on Categorical Data",
    "url": "/forum?id=BmJV7kyAmg",
    "date": "28 Sept 2021 (modified: 03 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "robustness certification, adversarial learning, categorical data",
    "Abstract": "Characterizing and assessing the adversarial vulnerability of classification models with categorical input has been a practically important, while rarely explored research problem. Our work echoes the challenge by first unveiling the impact factors of adversarial vulnerability of classification models with categorical data based on an information-theoretic adversarial risk analysis about the targeted classifier. Though certifying the robustness of such classification models is intrinsically an NP-hard combinatorial problem, our study shows that the robustness certification can be solved via an efficient greedy exploration of the discrete attack space for any measurable classifiers with a mild smoothness constraint. Our proposed robustness certification framework is instantiated with deep neural network models applied on real-world safety-critic data sources. Our empirical observations confirm the impact of the key adversarial risk factors with categorical input.",
    "One-sentence Summary": "This paper explores the characterization and certification of the robustness against evasion attack with categorical input."
  },
  {
    "title": "Learning Curves for SGD on Structured Features",
    "url": "/forum?id=WPI2vbkAl3Q",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Stochastic Gradient Descent, Generalization",
    "Abstract": "The generalization performance of a machine learning algorithm such as a neural network depends in a non-trivial way on the structure of the data distribution. To analyze the influence of data structure on test loss dynamics, we study an exactly solveable model of stochastic gradient descent (SGD) on the square loss which predicts test error when training on features with arbitrary covariance structure. We solve the theory exactly for both Gaussian features and arbitrary features and we show that the simpler Gaussian model accurately predicts test loss of nonlinear random-feature models and neural networks in the kernel regime trained with SGD on real datasets such as MNIST and CIFAR-10. We show that the optimal batch size at a fixed compute budget is typically small and depends on the feature correlation structure, demonstrating the computational benefits of SGD with small batch sizes. Lastly, we extend our theory to the more usual setting of stochastic gradient descent on a fixed subsampled training set, showing that both training and test error can be accurately predicted in our framework on real data.",
    "One-sentence Summary": "The average case test risk for stochastic gradient descent on mean square error is computed in terms of feature covariance structure."
  },
  {
    "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training",
    "url": "/forum?id=Qaw16njk6L",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "vision transformer, gradient conflict, neural architecture search",
    "Abstract": "Designing accurate and efficient vision transformers (ViTs) is a highly important but challenging task. Supernet-based one-shot neural architecture search (NAS) enables fast architecture optimization and has achieved state-of-the-art (SOTA) results on convolutional neural networks (CNNs). However, directly applying the supernet-based NAS to optimize ViTs leads to poor performance - even worse compared to training single ViTs. In this work, we observe that the poor performance is due to a gradient conflict issue: the gradients of different sub-networks conflict with that of the supernet more severely in ViTs than CNNs, which leads to early saturation in training and inferior convergence. To alleviate this issue, we propose a series of techniques, including a gradient projection algorithm, a switchable layer scaling design, and a simplified data augmentation and regularization training recipe. The proposed techniques significantly improve the convergence and the performance of all sub-networks. Our discovered hybrid ViT model family, dubbed NASViT, achieves top-1 accuracy from 78.2% to 81.8% on ImageNet from 200M to 800M FLOPs, and outperforms all the prior art CNNs and ViTs, including AlphaNet and LeViT, etc. When transferred to semantic segmentation tasks, NASViTs also outperform previous backbones on both Cityscape and ADE20K datasets, achieving 73.2% and 37.9% mIoU with only 5G FLOPs, respectively. Code is available at\n        https://github.com/facebookresearch/NASViT.",
    "One-sentence Summary": "we identify one key issue of ViT supernet training that the supernet gradients and the sub-network gradients are likely to disagree with each other, and propose gradient conflict aware training."
  },
  {
    "title": "Graphon based Clustering and Testing of Networks: Algorithms and Theory",
    "url": "/forum?id=sTNHCrIKDQc",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Clustering, Networks, Graphs, Two-sample testing, Graphon",
    "Abstract": "Network-valued data are encountered in a wide range of applications, and pose challenges in learning due to their complex structure and absence of vertex correspondence. Typical examples of such problems include classification or grouping of protein structures and social networks. Various methods, ranging from graph kernels to graph neural networks, have been proposed that achieve some success in graph classification problems. However, most methods have limited theoretical justification, and their applicability beyond classification remains unexplored. In this work, we propose methods for clustering multiple graphs, without vertex correspondence, that are inspired by the recent literature on estimating graphons---symmetric functions corresponding to infinite vertex limit of graphs. We propose a novel graph distance based on sorting-and-smoothing graphon estimators. Using the proposed graph distance, we present two clustering algorithms and show that they achieve state-of-the-art results. We prove the statistical consistency of both algorithms under Lipschitz assumptions on the graph degrees. We further study the applicability of the proposed distance for graph two-sample testing problems."
  },
  {
    "title": "Network Augmentation for Tiny Deep Learning",
    "url": "/forum?id=TYw3-OlrRm-",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Tiny Deep Learning",
    "Abstract": "We introduce Network Augmentation (NetAug), a new training method for improving the performance of tiny neural networks. Existing regularization techniques (e.g., data augmentation, dropout) have shown much success on large neural networks by adding noise to overcome over-fitting. However, we found these techniques hurt the performance of tiny neural networks. We argue that training tiny models are different from large models: rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity. To alleviate this issue, NetAug augments the network (reverse dropout) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub-model of larger models to get extra supervision, in addition to functioning as an independent model. At test time, only the tiny model is used for inference, incurring zero inference overhead. We demonstrate the effectiveness of NetAug on image classification and object detection. NetAug consistently improves the performance of tiny models, achieving up to 2.2% accuracy improvement on ImageNet. On object detection, achieving the same level of performance, NetAug requires 41% fewer MACs on Pascal VOC and 38% fewer MACs on COCO than the baseline.",
    "One-sentence Summary": "a training method for tiny neural networks"
  },
  {
    "title": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations",
    "url": "/forum?id=o-1v9hdSult",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Explanations, XAI, Post-hoc explanations",
    "Abstract": "As increasingly complex AI systems are introduced into our daily lives, it becomes important for such systems to be capable of explaining the rationale for their decisions and allowing users to contest these decisions. A significant hurdle to allowing for such explanatory dialogue could be the {\\em vocabulary mismatch} between the user and the AI system. This paper introduces methods for providing contrastive explanations in terms of user-specified concepts for sequential decision-making settings where the system's model of the task may be best represented as an inscrutable model. We do this by building partial symbolic models of a local approximation of the task that can be leveraged to answer the user queries. We test these methods on a popular Atari game (Montezuma's Revenge) and variants of Sokoban (a well-known planning benchmark) and report the results of user studies to evaluate whether people find explanations generated in this form useful."
  },
  {
    "title": "Distributional Reinforcement Learning with Monotonic Splines",
    "url": "/forum?id=C8Ltz08PtBp",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Distributional RL",
    "Abstract": "Distributional Reinforcement Learning (RL) differs from traditional RL by estimating the distribution over returns to capture the intrinsic uncertainty of MDPs. One key challenge in distributional RL lies in how to parameterize the quantile function when minimizing the Wasserstein metric of temporal differences. Existing algorithms use step functions or piecewise linear functions. In this paper, we propose to learn smooth continuous quantile functions represented by monotonic rational-quadratic splines, which also naturally solve the quantile crossing problem. Experiments in stochastic environments show that a dense estimation for quantile functions enhances distributional RL in terms of faster empirical convergence and higher rewards in most cases."
  },
  {
    "title": "Toward Faithful Case-based Reasoning through Learning Prototypes in a Nearest Neighbor-friendly Space.",
    "url": "/forum?id=R79ZGjHhv6p",
    "date": "28 Sept 2021 (modified: 28 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "case-based reasoning, interpretable machine learning, explainable artificial intelligence, xai, prototype learning",
    "Abstract": "Recent advances in machine learning have brought opportunities for the ever-increasing use of AI in the real world. This has created concerns about the black-box nature of many of the most recent machine learning approaches. In this work, we propose an interpretable neural network that leverages metric and prototype learning for classification tasks. It encodes its own explanations and provides an improved case-based reasoning through learning prototypes in an embedding space learned by a probabilistic nearest neighbor rule. Through experiments, we demonstrated the effectiveness of the proposed method in both performance and the accuracy of the explanations provided.",
    "One-sentence Summary": "Offering better prototype explanations using a nearest-neighbor friendly embedding space."
  },
  {
    "title": "Augmented Sliced Wasserstein Distances",
    "url": "/forum?id=iMqTLyfwnOO",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "While theoretically appealing, the application of the Wasserstein distance to large-scale machine learning problems has been hampered by its prohibitive computational cost. The sliced Wasserstein distance and its variants improve the computational efficiency through the random projection, yet they suffer from low accuracy if the number of projections is not sufficiently large, because the majority of projections result in trivially small values. In this work, we propose a new family of distance metrics, called augmented sliced Wasserstein distances (ASWDs), constructed by first mapping samples to higher-dimensional hypersurfaces parameterized by neural networks. It is derived from a key observation that (random) linear projections of samples residing on these hypersurfaces would translate to much more flexible nonlinear projections in the original sample space, so they can capture complex structures of the data distribution. We show that the hypersurfaces can be optimized by gradient ascent efficiently. We provide the condition under which the ASWD is a valid metric and show that this can be obtained by an injective neural network architecture. Numerical results demonstrate that the ASWD significantly outperforms other Wasserstein variants for both synthetic and real-world problems."
  },
  {
    "title": "Relational Learning with Variational Bayes",
    "url": "/forum?id=Az-7gJc6lpr",
    "date": "28 Sept 2021 (modified: 02 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Relational learning, psychology, unsupervised learning, variational inference, probabilistic graphical model.",
    "Abstract": "In psychology, relational learning refers to the ability to recognize and respond to relationship among objects irrespective of the nature of those objects. Relational learning has long been recognized as a hallmark of human cognition and a key question in artificial intelligence research. In this work, we propose an unsupervised learning method for addressing the relational learning problem where we learn the underlying relationship between a pair of data irrespective of the nature of those data. The central idea of the proposed method is to encapsulate the relational learning problem with a probabilistic graphical model in which we perform inference to learn about data relationship and other relational processing tasks.",
    "One-sentence Summary": "Propose an unsupervised learning method for addressing the relational learning problem where we learn the underlying relationship between a pair of data irrespective of the nature of those data."
  },
  {
    "title": "Provably Robust Adversarial Examples",
    "url": "/forum?id=UMfhoMtIaP5",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial attacks, Robustness Certification, Abstract Interpretation, Deep Learning",
    "Abstract": "We introduce the concept of provably robust adversarial examples for deep neural networks \u2013 connected input regions constructed from standard adversarial examples which are guaranteed to be robust to a set of real-world perturbations (such as changes in pixel intensity and geometric transformations). We present a novel method called PARADE for generating these regions in a scalable manner which works by iteratively refining the region initially obtained via sampling until a refined region is certified to be adversarial with existing state-of-the-art verifiers. At each step, a novel optimization procedure is applied to maximize the region's volume under the constraint that the convex relaxation of the network behavior with respect to the region implies a chosen bound on the certification objective. Our experimental evaluation shows the effectiveness of PARADE: it successfully finds large provably robust regions including ones containing $\\approx 10^{573}$ adversarial examples for pixel intensity and $\\approx 10^{599}$ for geometric perturbations. The provability enables our robust examples to be significantly more effective against state-of-the-art defenses based on randomized smoothing than the individual attacks used to construct the regions.",
    "One-sentence Summary": "We introduce the concept of provably robust adversarial examples $-$ connected input regions constructed from standard adversarial examples and guaranteed to be provably robust to a set of perturbations."
  },
  {
    "title": "Joint Shapley values: a measure of joint feature importance",
    "url": "/forum?id=vcUmUvQCloe",
    "date": "28 Sept 2021 (modified: 08 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "explainable AI, Shapley value, interaction index, cooperative game theory",
    "Abstract": "The Shapley value is one of the most widely used measures of feature importance partly as it measures a feature's average effect on a model's prediction.  We introduce joint Shapley values, which directly extend Shapley's axioms and intuitions: joint Shapley values measure a set of features' average effect on a model's prediction.  We prove the uniqueness of joint Shapley values, for any order of explanation.  Results for games show that joint Shapley values present different insights from existing interaction indices, which assess the effect of a feature within a set of features.  The joint Shapley values seem to provide sensible results in ML attribution problems.  With binary features, we present a presence-adjusted global value that is more consistent with local intuitions than the usual approach.",
    "One-sentence Summary": "We present a direct extension of Shapley's value to sets of features, thus extending the Shapley value's intuition: a set of feature's average effect on a model's prediction"
  },
  {
    "title": "Low-Budget Active Learning via Wasserstein Distance: An Integer Programming Approach",
    "url": "/forum?id=v8OlxjGn23S",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "active learning, integer optimization",
    "Abstract": "Active learning is the process of training a model with limited labeled data by selecting a core subset of an unlabeled data pool to label. The large scale of data sets used in deep learning forces most sample selection strategies to employ efficient heuristics. This paper introduces an integer optimization problem for selecting a core set that minimizes the discrete Wasserstein distance from the unlabeled pool. We demonstrate that this problem can be tractably solved with a Generalized Benders Decomposition algorithm. Our strategy uses high-quality latent features that can be obtained by unsupervised learning on the unlabeled pool. Numerical results on several data sets show that our optimization approach is competitive with baselines and particularly outperforms them in the low budget regime where less than one percent of the data set is labeled.",
    "One-sentence Summary": "We propose an integer optimization problem for active learning and demonstrate how optimally selecting which points to label can significantly improve classifiers under low labeling budgets."
  },
  {
    "title": "Efficient Self-supervised Vision Transformers for Representation Learning",
    "url": "/forum?id=fVu3o-YUGQK",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self-supervised learning, vision transformers, non-contrastive region-matching task",
    "Abstract": "This paper investigates two techniques for developing efficient self-supervised vision transformers (EsViT) for visual representation learning. First, we show through a comprehensive empirical study that multi-stage architectures with sparse self-attentions can significantly reduce modeling complexity but with a cost of losing the ability to capture fine-grained correspondences between image regions. Second, we propose a new pre-training task, non-contrastive region-matching, which allows the model to capture fine-grained region dependencies and as a result significantly improves the quality of the learned vision representations. Our results show that combining the two techniques, EsViT achieves 81.3% top-1 on the ImageNet linear probe evaluation, outperforming prior arts with around an order magnitude of higher throughput. When transferring to downstream linear classification tasks, EsViT outperforms its supervised counterpart on 17 out of 18 datasets. The code and pre-trained models are released at: https://github.com/microsoft/esvit",
    "One-sentence Summary": "Achieving SoTA ImageNet linear probe task with 10 times higher throughput, using the synergy of a multi-stage Transformer architecture and a non-contrastive region-matching pre-training task."
  },
  {
    "title": "Visual Representation Learning Does Not Generalize Strongly Within the Same Domain",
    "url": "/forum?id=9RUHPlladgh",
    "date": "28 Sept 2021 (modified: 12 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generalization, Composition, Out of distribution, Disentanglement",
    "Abstract": "An important component for generalization in machine learning is to uncover underlying latent factors of variation as well as the mechanism through which each factor acts in the world.\n        In this paper, we test whether 17 unsupervised, weakly supervised, and fully supervised representation learning approaches correctly infer the generative factors of variation in simple datasets (dSprites, Shapes3D, MPI3D) from controlled environments, and on our contributed CelebGlow dataset. \n        In contrast to prior robustness work that introduces novel factors of variation during test time, such as blur or other (un)structured noise, we here recompose, interpolate, or extrapolate only existing factors of variation from the training data set (e.g., small and medium-sized objects during training and large objects during testing). Models that learn the correct mechanism should be able to generalize to this benchmark.\n        In total, we train and test 2000+ models and observe that all of them struggle to learn the underlying mechanism regardless of supervision signal and architectural bias. Moreover, the generalization capabilities of all tested models drop significantly as we move from artificial datasets towards more realistic real-world datasets.\n        Despite their inability to identify the correct mechanism, the models are quite modular as their ability to infer other in-distribution factors remains fairly stable, providing only a single factor is out-of-distribution. These results point to an important yet understudied problem of learning mechanistic models of observations that can facilitate generalization.",
    "One-sentence Summary": "We study and benchmark the inductive biases for generalization in visual representation learning on systematic out-of-distribution settings."
  },
  {
    "title": "Hidden Convexity of Wasserstein GANs: Interpretable Generative Models with Closed-Form Solutions",
    "url": "/forum?id=e2Lle5cij9D",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Wasserstein GAN, convex-concave game, saddle points, generative models, quadratic, polynomial activation, convex duality",
    "Abstract": "Generative Adversarial Networks (GANs) are commonly used for modeling complex distributions of data. Both the generators and discriminators of GANs are often modeled by neural networks, posing a non-transparent optimization problem which is non-convex and non-concave over the generator and discriminator, respectively. Such networks are often heuristically optimized with gradient descent-ascent (GDA), but it is unclear whether the optimization problem contains any saddle points, or whether heuristic methods can find them in practice. In this work, we analyze the training of Wasserstein GANs with two-layer neural network discriminators through the lens of convex duality, and for a variety of generators expose the conditions under which Wasserstein GANs can be solved exactly with convex optimization approaches, or can be represented as convex-concave games. Using this convex duality interpretation, we further demonstrate the impact of different activation functions of the discriminator. Our observations are verified with numerical results demonstrating the power of the convex interpretation, with an application in progressive training of convex architectures corresponding to linear generators and quadratic-activation discriminators for CelebA image generation. The code for our experiments is available at https://github.com/ardasahiner/ProCoGAN.",
    "One-sentence Summary": "We demonstrate that Wasserstein GANs with two-layer discriminators and a variety of generators are equivalent to convex optimization problems or convex-concave games, allowing for global optimization in polynomial time and improved interpretability."
  },
  {
    "title": "Memory Augmented Optimizers for Deep Learning",
    "url": "/forum?id=NRX9QZ6yqt",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Optimization for Deep learning, Memory augmented Optimizers",
    "Abstract": "Popular approaches for minimizing loss in data-driven learning often involve an abstraction or an explicit retention of the history of gradients for efficient parameter updates. \n        The aggregated history of gradients nudges the parameter updates in the right direction even when the gradients at any given step are not informative. \n        Although the history of gradients summarized in meta-parameters or explicitly stored in memory has been shown effective in theory and practice, the question of whether $all$ or only a subset of the gradients in the history are sufficient in deciding the parameter updates remains unanswered. \n        In this paper, we propose a framework of memory-augmented gradient descent optimizers that retain a limited view of their gradient history in their internal memory. \n        Such optimizers scale well to large real-life datasets, and our experiments show that the memory augmented extensions of standard optimizers enjoy accelerated convergence and improved performance on a majority of computer vision and language tasks that we considered.\n        Additionally, we prove that the proposed class of optimizers with fixed-size memory converge under assumptions of strong convexity, regardless of which gradients are selected or how they are linearly combined to form the update step.",
    "One-sentence Summary": "We propose a framework of memory augmented optimizers and empirically show that the class of optimizers provide accelerated convergence and even better test performance. We show the proposed optimizers converge in smooth strongly convex setting."
  },
  {
    "title": "Orchestrated Value Mapping for Reinforcement Learning",
    "url": "/forum?id=c87d0TS4yX",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Value Mapping, Reward Decomposition",
    "Abstract": "We present a general convergent class of reinforcement learning algorithms that is founded on two distinct principles: (1) mapping value estimates to a different space using arbitrary functions from a broad class, and (2) linearly decomposing the reward signal into multiple channels. The first principle enables incorporating specific properties into the value estimator that can enhance learning. The second principle, on the other hand, allows for the value function to be represented as a composition of multiple utility functions. This can be leveraged for various purposes, e.g. dealing with highly varying reward scales, incorporating a priori knowledge about the sources of reward, and ensemble learning. Combining the two principles yields a general blueprint for instantiating convergent algorithms by orchestrating diverse mapping functions over multiple reward channels. This blueprint generalizes and subsumes algorithms such as Q-Learning, Log Q-Learning, and Q-Decomposition. In addition, our convergence proof for this general class relaxes certain required assumptions in some of these algorithms. Based on our theory, we discuss several interesting configurations as special cases. Finally, to illustrate the potential of the design space that our theory opens up, we instantiate a particular algorithm and evaluate its performance on the Atari suite.",
    "One-sentence Summary": "We present a general convergent class of RL algorithms based on combining arbitrary value mappings and reward decomposition."
  },
  {
    "title": "Learning to Generalize across Domains on Single Test Samples",
    "url": "/forum?id=CIaQKbTBwtU",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "domain generalization, single test sample generalization, meta learning, variational inference",
    "Abstract": "We strive to learn a model from a set of source domains that generalizes well to unseen target domains. The main challenge in such a domain generalization scenario is the unavailability of any target domain data during training, resulting in the learned model not being explicitly adapted to the unseen target domains. We propose learning to generalize across domains on single test samples. We leverage a meta-learning paradigm to learn our model to acquire the ability of adaptation with single samples at training time so as to further adapt itself to each single test sample at test time. We formulate the adaptation to the single test sample as a variational Bayesian inference problem, which incorporates the test sample as a conditional into the generation of model parameters. The adaptation to each test sample requires only one feed-forward computation at test time without any fine-tuning or self-supervised training on additional data from the unseen domains.  Extensive ablation studies demonstrate that our model learns the ability to adapt models to each single sample by mimicking domain shifts during training. Further, our model achieves at least comparable -- and often better -- performance than state-of-the-art methods on multiple benchmarks for domain generalization.",
    "One-sentence Summary": "We leverage a meta-learning paradigm to learn our model to acquire the ability of adaptation with single samples at training time so as to further adapt itself to each single test sample at test time."
  },
  {
    "title": "Prototype memory and attention mechanisms for few shot image generation",
    "url": "/forum?id=lY0-7bj0Vfz",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neuroscience, deep learning",
    "Abstract": "Recent discoveries indicate that the neural codes in the primary visual cortex (V1) of macaque monkeys are complex, diverse and sparse. This leads us to ponder the computational advantages and functional role of these \u201cgrandmother cells.\" Here, we propose that such cells can serve as prototype memory priors that bias and shape the distributed feature processing within the image generation process in the brain. These memory prototypes are learned by momentum online clustering and are utilized via a memory-based attention operation, which we define as Memory Concept Attention (MoCA). To test our proposal, we show in a few-shot image generation task, that having a prototype memory during attention can improve image synthesis quality, learn interpretable visual concept clusters, as well as improve the robustness of the model. Interestingly, we also find that our attentional memory mechanism can implicitly modify the horizontal connections by updating the transformation into the prototype embedding space for self-attention. Insofar as GANs can be seen as plausible models for reasoning about the top-down synthesis in the analysis-by-synthesis loop of the hierarchical visual cortex, our findings demonstrate a plausible computational role for these \u201cprototype concept\" neurons in visual processing in the brain.",
    "One-sentence Summary": "computational role for \u201cprototype concept neurons\u201d in top-down synthesis path"
  },
  {
    "title": "TPU-GAN: Learning temporal coherence from dynamic point cloud sequences",
    "url": "/forum?id=FEBFJ98FKx",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Point cloud super resolution, Temporal learning, Generative Adversarial Networks",
    "Abstract": "Point cloud sequence is an important data representation that provides flexible shape and motion information. Prior work demonstrates that incorporating scene flow information into loss can make model learn temporally coherent feature spaces. However, it is prohibitively expensive to acquire point correspondence information across frames in real-world environments. In this work, we propose a super-resolution generative adversarial network (GAN) for upsampling dynamic point cloud sequences, which does not require point correspondence annotation.  Our model, Temporal Point cloud Upsampling GAN (TPU-GAN), can implicitly learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, we propose a learnable masking module to adapt upsampling ratio according to the point distribution. We conduct extensive experiments on point cloud sequences from two different domains: particles in the fluid dynamical system and human action scanned data. The quantitative and qualitative evaluation demonstrates the effectiveness of our method on upsampling tasks as well as learning temporal coherence from irregular point cloud sequences.",
    "One-sentence Summary": "We propose a GAN framework for super-resolution task on dynamic point cloud sequences."
  },
  {
    "title": "A First-Occupancy Representation for Reinforcement Learning",
    "url": "/forum?id=JBAZe2yN6Ub",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "successor representation, successor features, generalized policy improvement, GPI",
    "Abstract": "Both animals and artificial agents benefit from state representations that support rapid transfer of learning across tasks and which enable them to efficiently traverse their environments to reach rewarding states.  The successor representation (SR), which measures the expected cumulative, discounted state occupancy under a fixed policy, enables efficient transfer to different reward structures in an otherwise constant Markovian environment and has been hypothesized to underlie aspects of biological behavior and neural activity.  However, in the real world, rewards may only be available for consumption once, may shift location, or agents may simply aim to reach goal states as rapidly as possible without the constraint of artificially imposed task horizons. In such cases, the most behaviorally-relevant representation would carry information about when the agent was likely to first reach states of interest, rather than how often it should expect to visit them over a potentially infinite time span.  To reflect such demands, we introduce the first-occupancy representation (FR), which measures the expected temporal discount to the first time a state is accessed.  We demonstrate that the FR facilitates exploration, the selection of efficient paths to desired states, allows the agent, under certain conditions, to plan provably optimal trajectories defined by a sequence of subgoals, and induces similar behavior to animals avoiding threatening stimuli.",
    "One-sentence Summary": "We introduce the first-occupancy representation, a modification of the successor representation which enables agents to perform rapid policy evaluation and planning for a class of ethologically important non-Markovian reward functions."
  },
  {
    "title": "Deep ReLU Networks Preserve Expected Length",
    "url": "/forum?id=ci7LBzDn2Q",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep learning theory, random ReLU networks, length distortion, initialization, expressivity",
    "Abstract": "Assessing the complexity of functions computed by a neural network helps us understand how the network will learn and generalize. One natural measure of complexity is how the network distorts length - if the network takes a unit-length curve as input, what is the length of the resulting curve of outputs? It has been widely believed that this length grows exponentially in network depth. We prove that in fact this is not the case: the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU networks with standard random initialization. We also generalize this result by proving upper bounds both for higher moments of the length distortion and for the distortion of higher-dimensional volumes. These theoretical results are corroborated by our experiments.",
    "One-sentence Summary": "This article proves that, both on average and with high probability, randomly initialized ReLU networks with width larger than depth do not distort lengths and volumes."
  },
  {
    "title": "Phenomenology of Double Descent in Finite-Width Neural Networks",
    "url": "/forum?id=lTqGXfn9Tv",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "double descent, generalization, neural networks, hessian, flatness",
    "Abstract": "`Double descent' delineates the generalization behaviour of models depending on the regime they belong to: under- or over-parameterized. The current theoretical understanding behind the occurrence of this phenomenon is primarily based on linear and kernel regression models --- with informal parallels to neural networks via the Neural Tangent Kernel. Therefore such analyses do not adequately capture the mechanisms behind double descent in finite-width neural networks, as well as, disregard crucial components --- such as the choice of the loss function. We address these shortcomings by leveraging influence functions in order to derive suitable expressions of the population loss and its lower bound, while imposing minimal assumptions on the form of the parametric model. Our derived bounds bear an intimate connection with the spectrum of the Hessian at the optimum, and importantly, exhibit a double descent behaviour at the interpolation threshold. Building on our analysis, we further investigate how the loss function affects double descent --- and thus uncover interesting properties of neural networks and their Hessian spectra near the interpolation threshold.",
    "One-sentence Summary": "We provide a theoretical analysis of double descent that applies for finite-width neural networks and delivers insights into the properties of neural networks (and its Hessian spectrum) near the interpolation threshold."
  },
  {
    "title": "How Attentive are Graph Attention Networks?",
    "url": "/forum?id=F72ximsx7C1",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "graph attention networks, dynamic attention, GAT, GNN",
    "Abstract": "Graph Attention Networks (GATs) are one of the most popular GNN architectures and are considered as the state-of-the-art architecture for representation learning with graphs. In GAT, every node attends to its neighbors given its own representation as the query.\n        However, in this paper we show that GAT computes a very limited kind of attention: the ranking of the attention scores is unconditioned on the query node. We formally define this restricted kind of attention as static attention and distinguish it from a strictly more expressive dynamic attention.\n        Because GATs use a static attention mechanism, there are simple graph problems that GAT cannot express: in a controlled problem, we show that static attention hinders GAT from even fitting the training data. \n        To remove this limitation, we introduce a simple fix by modifying the order of operations and propose GATv2: a dynamic graph attention variant that is strictly more expressive than GAT. We perform an extensive evaluation and show that GATv2 outperforms GAT across 12 OGB and other benchmarks while we match their parametric costs. \n        Our code is available at https://github.com/tech-srl/how_attentive_are_gats . GATv2 is available as part of the PyTorch Geometric library, the Deep Graph Library, and the TensorFlow GNN library.",
    "One-sentence Summary": "We identify that Graph Attention Networks (GAT) compute a very weak form of attention. We show its empirical implications and propose a fix."
  },
  {
    "title": "Learning Transferable Reward for Query Object Localization with Policy Adaptation",
    "url": "/forum?id=92tYQiil17",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We propose a reinforcement learning based approach to query object localization, for which an agent is trained to localize objects of interest specified by a small exemplary set. We learn a transferable reward signal formulated using the exemplary set by ordinal metric learning. Our proposed method enables test-time policy adaptation to new environments where the reward signals are not readily available, and outperforms fine-tuning approaches that are limited to annotated images. In addition, the transferable reward allows repurposing the trained agent from one specific class to another class. Experiments on corrupted MNIST, CU-Birds, and COCO datasets demonstrate the effectiveness of our approach."
  },
  {
    "title": "CKConv: Continuous Kernel Convolution For Sequential Data",
    "url": "/forum?id=8FhxBtXSl0",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Convolutional Networks, Continuous kernel Convolutions, Continuous Convolutional Kernels, Implicit Neural Representations, Sequential Data.",
    "Abstract": "Conventional neural architectures for sequential data present important limitations. Recurrent neural networks suffer from exploding and vanishing gradients, small effective memory horizons, and must be trained sequentially. Convolutional neural networks cannot handle sequences of unknown size and their memory horizon must be defined a priori. In this work, we show that these problems can be solved by formulating the convolutional kernels of CNNs as continuous functions. The resulting Continuous Kernel Convolution (CKConv) handles arbitrarily long sequences in a parallel manner, within a single operation, and without relying on any form of recurrence. We show that Continuous Kernel Convolutional Networks (CKCNNs) obtain state-of-the-art results in multiple datasets, e.g., permuted MNIST, and, thanks to their continuous nature, are able to handle non-uniformly sampled datasets and irregularly-sampled data natively. CKCNNs match or perform better than neural ODEs designed for these purposes in a faster and simpler manner.",
    "One-sentence Summary": "We provide  a continuous parameterization to convolutional kernels, with which several advantages upon conventional (discrete) parameterizations are obtained."
  },
  {
    "title": "Towards Empirical Sandwich Bounds on the Rate-Distortion Function",
    "url": "/forum?id=H4PmOqSZDY",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "information theory, deep generative modeling, lossy data compression",
    "Abstract": "Rate-distortion (R-D) function, a key quantity in information theory, characterizes the fundamental limit of how much a data source can be compressed subject to a fidelity criterion, by any compression algorithm. As researchers push for ever-improving compression performance, establishing the R-D function of a given data source is not only of scientific interest, but also reveals the possible room for improvement in existing compression algorithms. Previous work on this problem relied on distributional assumptions on the data source (Gibson, 2017) or only applied to discrete data (Blahut, 1972; Arimoto, 1972). By contrast, this paper makes the first attempt at an algorithm for sandwiching the R-D function of a general (not necessarily discrete) source requiring only i.i.d. data samples. We estimate R-D sandwich bounds for a variety of artificial and real-world data sources, in settings far beyond the feasibility of any known method, and shed light on the optimality of neural data compression (Ball\u00e9 et al., 2021; Yang et al., 2022). Our R-D upper bound on natural images indicates theoretical room for improving state-of-the-art image compression methods by at least one dB in PSNR at various bitrates. Our data and code can be found at https://github.com/mandt-lab/RD-sandwich.",
    "One-sentence Summary": "We make a first attempt at an algorithm for sandwiching the rate-distortion function of a general data sources requiring only i.i.d. samples."
  },
  {
    "title": "Pareto Policy Adaptation",
    "url": "/forum?id=wfZGut6e09",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multi-objective reinforcement learning, policy gradient, pareto optimality, policy adaptation",
    "Abstract": "We present a policy gradient method for Multi-Objective Reinforcement Learning under unknown, linear preferences. By enforcing Pareto stationarity, a first-order condition for Pareto optimality, we are able to design a simple policy gradient algorithm that approximates the Pareto front and infers the unknown preferences. Our method relies on a projected gradient descent solver that identifies common ascent directions for all objectives. Leveraging the solution of that solver, we introduce Pareto Policy Adaptation (PPA), a loss function that adapts the policy to be optimal with respect to any distribution over preferences. PPA uses implicit differentiation to back-propagate the loss gradient bypassing the operations of the projected gradient descent solver. Our approach is straightforward, easy to implement and can be used with all existing policy gradient and actor-critic methods. We evaluate our method in a series of reinforcement learning tasks",
    "One-sentence Summary": "We propose a policy gradient method for multi-objective reinforcement learning under unknown, linear preferences."
  },
  {
    "title": "Fair Normalizing Flows",
    "url": "/forum?id=BrFIKuxrZE",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "fairness, fair representation learning, adversarial fairness, trustworthy machine learning",
    "Abstract": "Fair representation learning is an attractive approach that promises fairness of downstream predictors by encoding sensitive data. Unfortunately, recent work has shown that strong adversarial predictors can still exhibit unfairness by recovering sensitive attributes from these representations. In this work, we present Fair Normalizing Flows (FNF), a new approach offering more rigorous fairness guarantees for learned representations. Specifically, we consider a practical setting where we can estimate the probability density for sensitive groups. The key idea is to model the encoder as a normalizing flow trained to minimize the statistical distance between the latent representations of different groups. The main advantage of FNF is that its exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. We experimentally demonstrate the effectiveness of FNF in enforcing various group fairness notions, as well as other attractive properties such as interpretability and transfer learning, on a variety of challenging real-world datasets.",
    "One-sentence Summary": "We propose a new fair representation learning method based on normalizing flows which can bound the accuracy of any adversary trying to predict sensitive attributes."
  },
  {
    "title": "The Convex Geometry of Backpropagation: Neural Network Gradient Flows Converge to Extreme Points of the Dual Convex Program",
    "url": "/forum?id=5QhUE1qiVC6",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Two-layer ReLU networks, convex optimization, convex duality, gradient flow",
    "Abstract": "We study non-convex subgradient flows for training two-layer ReLU neural networks from a convex geometry and duality perspective. We characterize the implicit bias of unregularized non-convex gradient flow as convex regularization of an equivalent convex model. We then show that the limit points of non-convex subgradient flows can be identified via primal-dual correspondence in this convex optimization problem.  Moreover, we derive a sufficient condition on the dual variables which ensures that the stationary points of the non-convex objective are the KKT points of the convex objective, thus proving convergence of non-convex gradient flows to the global optimum. For a class of regular training data distributions such as orthogonal separable data, we show that this sufficient condition holds. Therefore, non-convex gradient flows in fact converge to optimal solutions of a convex optimization problem. We present numerical results verifying the predictions of our theory for non-convex subgradient descent."
  },
  {
    "title": "Adaptive Wavelet Transformer Network for 3D Shape Representation Learning",
    "url": "/forum?id=5MLb3cLCJY",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We present a novel method for 3D shape representation learning using multi-scale wavelet decomposition. Previous works often decompose 3D shapes into complementary components in spatial domain at a single scale. In this work, we study to decompose 3D shapes into sub-bands components in frequency domain at multiple scales, resulting in a hierarchical decomposition tree in a principled manner rooted in multi-resolution wavelet analysis. Specifically, we propose Adaptive Wavelet Transformer Network (AWT-Net) that firstly generates approximation or detail wavelet coefficients per point, classifying each point into high or low sub-bands components, using lifting scheme at multiple scales recursively and hierarchically. Then, AWT-Net exploits Transformer to enhance the original shape features by querying and fusing features from different but integrated sub-bands. The wavelet coefficients can be learned without direct supervision on coefficients, and AWT-Net is fully differentiable and can be learned in an end-to-end fashion. Extensive experiments demonstrate that AWT-Net achieves competitive performance on 3D shape classification and segmentation benchmarks."
  },
  {
    "title": "On the Convergence of mSGD and AdaGrad for Stochastic Optimization",
    "url": "/forum?id=g5tANwND04i",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "stochastic gradient descent, adaptive gradient algorithm, asymptotic convergence",
    "Abstract": "As one of the most fundamental stochastic optimization algorithms, stochastic gradient descent (SGD) has been intensively developed and extensively applied in machine learning in the past decade. There have been some modified SGD-type algorithms, which outperform the SGD in many competitions and applications in terms of convergence rate and accuracy, such as momentum-based SGD (mSGD) and adaptive gradient algorithm (AdaGrad). Despite these empirical successes, the theoretical properties of these algorithms have not been well established due to technical difficulties. With this motivation, we focus on convergence analysis of mSGD and AdaGrad for any smooth (possibly non-convex) loss functions in stochastic optimization. First, we prove that the iterates of mSGD are asymptotically convergent to a connected set of stationary points with probability one, which is more general than existing works on subsequence convergence or convergence of time averages. Moreover, we prove that the loss function of mSGD decays at a certain rate faster than that of SGD. In addition, we prove the iterates of AdaGrad are asymptotically convergent to a connected set of stationary points with probability one. Also, this result extends the results from the literature on subsequence convergence and the convergence of time averages. Despite the generality of the above convergence results, we have relaxed some assumptions of gradient noises, convexity of loss functions, as well as boundedness of iterates.",
    "One-sentence Summary": "A theoretical paper focusing on the investigation for the convergence of mSGD and AdaGrad optimization algorithms."
  },
  {
    "title": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs Theory",
    "url": "/forum?id=nioAdKCEdXB",
    "date": "28 Sept 2021 (modified: 05 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Schr\u00f6dinger Bridge, score-based generative model, optimal transport, forward-backward stochastic differential equations, stochastic optimal control",
    "Abstract": "Schr\u00f6dinger Bridge (SB) is an entropy-regularized optimal transport problem that has received increasing attention in deep generative modeling for its mathematical flexibility compared to the Scored-based Generative Model (SGM). However, it remains unclear whether the optimization principle of SB relates to the modern training of deep generative models, which often rely on constructing log-likelihood objectives.This raises questions on the suitability of SB models as a principled alternative for generative applications. In this work, we present a novel computational framework for likelihood training of SB models grounded on Forward-Backward Stochastic Differential Equations Theory \u2013 a mathematical methodology appeared in stochastic optimal control that transforms the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be used to construct the likelihood objectives for SB that, surprisingly, generalizes the ones for SGM as special cases. This leads to a new optimization principle that inherits the same SB optimality yet without losing applications of modern generative training techniques, and we show that the resulting training algorithm achieves comparable results on generating realistic images on MNIST, CelebA, and CIFAR10. Our code is available at https://github.com/ghliu/SB-FBSDE.",
    "One-sentence Summary": "We present a new computational framework, grounded on Forward-Backward SDEs theory, for the log-likelihood training of Schr\u00f6dinger Bridge and provide theoretical connections to score-baesd generative models."
  },
  {
    "title": "Imitation Learning from Observations under Transition Model Disparity",
    "url": "/forum?id=twv2QlJhXzo",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Imitation Learning, Deep Reinforcement Learning",
    "Abstract": "Learning to perform tasks by leveraging a dataset of expert observations, also known as imitation learning from observations (ILO), is an important paradigm for learning skills without access to the expert reward function or the expert actions. We consider ILO in the setting where the expert and the learner agents operate in different environments, with the source of the discrepancy being the transition dynamics model. Recent methods for scalable ILO utilize adversarial learning to match the state-transition distributions of the expert and the learner, an approach that becomes challenging when the dynamics are dissimilar. In this work, we propose an algorithm that trains an intermediary policy in the learner environment and uses it as a surrogate expert for the learner. The intermediary policy is learned such that the state transitions generated by it are close to the state transitions in the expert dataset. To derive a practical and scalable algorithm, we employ concepts from prior work on estimating the support of a probability distribution. Experiments using MuJoCo locomotion tasks highlight that our method compares favorably to the baselines for ILO with transition dynamics mismatch.",
    "One-sentence Summary": "Imitation learning from observations when the expert and the learner agents operate in environments with dissimilar transition dynamics models."
  },
  {
    "title": "MCMC Should Mix: Learning Energy-Based Model with Neural Transport Latent Space MCMC",
    "url": "/forum?id=4C93Qvn-tz",
    "date": "28 Sept 2021 (modified: 19 Apr 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generative models, energy-based models, MCMC",
    "Abstract": "Learning energy-based model (EBM) requires MCMC sampling of the learned model as an inner loop of the learning algorithm. However, MCMC sampling of EBMs in high-dimensional data space is generally not mixing, because the energy function, which is usually parametrized by deep network, is highly multi-modal in the data space. This is a serious handicap for both theory and practice of EBMs. In this paper, we propose to learn EBM with a flow-based model (or in general latent variable model) serving as a backbone, so that the EBM is a correction or an exponential tilting of the flow-based model. We show that the model has a particularly simple form in the space of the latent variables of the generative model, and MCMC sampling of the EBM in the latent space mixes well and traverses modes in the data space. This enables proper sampling and learning of EBMs.",
    "One-sentence Summary": "Learning energy-based models with mixing Markov chains."
  },
  {
    "title": "Autonomous Learning of Object-Centric Abstractions for High-Level Planning",
    "url": "/forum?id=rrWeE9ZDw_",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, planning, multitask, transfer, objects",
    "Abstract": "We propose a method for autonomously learning an object-centric representation of a continuous and high-dimensional environment that is suitable for planning. Such representations can immediately be transferred between tasks that share the same types of objects, resulting in agents that require fewer samples to learn a model of a new task. We first demonstrate our approach on a 2D crafting domain consisting of numerous objects where the agent learns a compact, lifted representation that generalises across objects. We then apply it to a series of Minecraft tasks to learn object-centric representations and object types - directly from pixel data - that can be leveraged to solve new tasks quickly. The resulting learned representations enable the use of a task-level planner, resulting in an agent capable of transferring learned representations to form complex, long-term plans.",
    "One-sentence Summary": "We learn object-centric PDDL representations directly from raw observation data"
  },
  {
    "title": "A fast and accurate splitting method for optimal transport: analysis and implementation",
    "url": "/forum?id=fCSq8yrDkc",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Optimal transport, Operator splitting, Douglas-Rachford, ADMM, GPUs",
    "Abstract": "We develop a fast and reliable method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. Built on the celebrated Douglas-Rachford splitting technique, our method tackles the original OT problem directly instead of solving an approximate regularized problem, as many state-of-the-art techniques do. This allows us to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. The proposed method enjoys an iteration complexity $O(1/\\epsilon)$ compared to the best-known $O(1/\\epsilon^2)$ of the Sinkhorn method. In addition, we establish a linear convergence rate for our formulation of the OT problem. We detail an efficient GPU implementation of the proposed method that maintains a primal-dual stopping criterion at no extra cost. Substantial experiments demonstrate the effectiveness of our method, both in terms of computation times and robustness.",
    "One-sentence Summary": "We develop a fast and reliable method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy."
  },
  {
    "title": "Implicit Bias of MSE Gradient Optimization in Underparameterized Neural Networks",
    "url": "/forum?id=VLgmhQDVBV",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "underparameterized regime, spectral bias, neural tangent kernel, implicit bias, implicit regularization, gradient flow",
    "Abstract": "We study the dynamics of a neural network in function space when optimizing the mean squared error via gradient flow.  We show that in the underparameterized regime the network learns eigenfunctions of an integral operator $T_K$ determined by the Neural Tangent Kernel at rates corresponding to their eigenvalues.  For example, for uniformly distributed data on the sphere $S^{d - 1}$ and rotation invariant weight distributions, the eigenfunctions of $T_K$ are the spherical harmonics.  Our results can be understood as describing a spectral bias in the underparameterized regime. The proofs use the concept of ``Damped Deviations'' where deviations of the NTK matter less for eigendirections with large eigenvalues.  Aside from the underparameterized regime, the damped deviations point-of-view allows us to extend certain results in the literature in the overparameterized setting.",
    "One-sentence Summary": "Underparameterized networks optimizing MSE learn eigenfunctions of an NTK integral operator at rates corresponding to their eigenvalues."
  },
  {
    "title": "Discovering Latent Concepts Learned in BERT",
    "url": "/forum?id=POTMtpYI1xH",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "interpretation, BERT, NLP",
    "Abstract": "A large number of studies that analyze deep neural network models and their ability to encode various linguistic and non-linguistic concepts provide an interpretation of the inner mechanics of these models. The scope of the analyses is limited to pre-defined concepts that reinforce the traditional linguistic knowledge and do not reflect on how novel concepts are learned by the model. We address this limitation by discovering and analyzing latent concepts learned in neural network models in an unsupervised fashion and provide interpretations from the model's perspective. In this work, we study: i) what latent concepts exist in the pre-trained BERT model, ii) how the discovered latent concepts align or diverge from classical linguistic hierarchy and iii) how the latent concepts evolve across layers. \n        Our findings show: i) a model learns novel concepts (e.g. animal categories and demographic groups), which do not strictly adhere to any pre-defined categorization (e.g. POS, semantic tags), ii) several latent concepts are based on multiple properties which may include semantics, syntax, and  morphology, iii) the lower layers in the model dominate in learning shallow lexical concepts while the higher layers learn semantic relations and iv) the discovered  latent concepts highlight potential biases learned in the model. We also release a novel BERT ConceptNet dataset consisting of 174 concept labels and 1M annotated instances.",
    "One-sentence Summary": "We approach interpretability from a model\u2019s perspective by discovering and analyzing latent concepts learned in pre-trained models in an unsupervised fashion."
  },
  {
    "title": "The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks",
    "url": "/forum?id=dNigytemkL",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Permutation, Invariance, Mode Connectivity, Energy Barrier, Loss landscape, Deep Learning",
    "Abstract": "In this paper, we conjecture that if the permutation invariance of neural networks is taken into account, SGD solutions will likely have no barrier in the linear interpolation between them. Although it is a bold conjecture, we show how extensive empirical attempts fall short of refuting it. We further provide a preliminary theoretical result to support our conjecture. Our conjecture has implications for the lottery ticket hypothesis, distributed training, and ensemble methods. The source code is available at \\url{https://github.com/rahimentezari/PermutationInvariance}.",
    "One-sentence Summary": "We conjecture that if the permutation invariance of neural networks is taken into account, SGD solutions will likely have no barrier in the linear interpolation between them."
  },
  {
    "title": "Data Poisoning Won\u2019t Save You From Facial Recognition",
    "url": "/forum?id=B5XahNLmna",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Poisoning attacks, adversarial examples, facial recognition, arms race, defenses",
    "Abstract": "Data poisoning has been proposed as a compelling defense against facial recognition models trained on Web-scraped pictures. Users can perturb images they post online, so that models will misclassify future (unperturbed) pictures.\n          \n         We demonstrate that this strategy provides a false sense of security, as it ignores an inherent asymmetry between the parties: users' pictures are perturbed once and for all before being published (at which point they are scraped) and must thereafter fool all future models---including models trained adaptively against the users' past attacks, or models that use new technologies discovered after the attack.\n          \n        We evaluate two systems for poisoning attacks against large-scale facial recognition, Fawkes (500,000+ downloads) and LowKey. We demonstrate how an \"oblivious\" model trainer can simply wait for future developments in computer vision to nullify the protection of pictures collected in the past. We further show that an adversary with black-box access to the attack can (i) train a robust model that resists the perturbations of collected pictures and (ii) detect poisoned pictures uploaded online.\n          \n        We caution that facial recognition poisoning will not admit an \"arms race\" between attackers and defenders. Once perturbed pictures are scraped, the attack cannot be changed so any future successful defense irrevocably undermines users' privacy.",
    "One-sentence Summary": "Data poisoning and adversarial examples won't protect users from facial recognition"
  },
  {
    "title": "MetaMorph: Learning Universal Controllers with Transformers",
    "url": "/forum?id=Opmqtk_GvYL",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "RL, Modular Robots, Transformers",
    "Abstract": "Multiple domains like vision, natural language, and audio are witnessing tremendous progress by leveraging Transformers for large scale pre-training followed by task specific fine tuning. In contrast, in robotics we primarily train a single robot for a single task. However, modular robot systems now allow for the flexible combination of general-purpose building blocks into task optimized morphologies. However, given the exponentially large number of possible robot morphologies, training a controller for each new design is impractical. In this work, we propose MetaMorph, a Transformer based approach to learn a universal controller over a modular robot design space. MetaMorph is based on the insight that robot morphology is just another modality on which we can condition the output of a Transformer. Through extensive experiments we demonstrate that large scale pre-training on a variety of robot morphologies results in policies with combinatorial generalization capabilities, including zero shot generalization to unseen robot morphologies. We further demonstrate that our pre-trained policy can be used for sample-efficient transfer to completely new robot morphologies and tasks.",
    "One-sentence Summary": "We learn a transformer based general purpose controller for a modular robot design space which can zero-shot generalize to unseen variations in dynamics, kinematics, new morphologies and tasks."
  },
  {
    "title": "HTLM: Hyper-Text Pre-Training and Prompting of Language Models",
    "url": "/forum?id=P-pPW1nxf1r",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "prompting, nlp, representational learning, priming",
    "Abstract": "We introduce HTLM, a hyper-text language model trained on a large-scale web crawl. Modeling hyper-text has a number of advantages: (1) it is easily gathered at scale, (2) it provides rich document-level and end-task-adjacent supervision (e.g. 'class' and 'id' attributes often encode document category information), and (3) it allows for new structured prompting that follows the established semantics of HTML (e.g. to do zero-shot summarization by infilling '<title>' tags for a webpage that contains the input text).  We show that pretraining with a BART-style denoising loss directly on simplified HTML provides highly effective transfer for a wide range of end tasks and supervision levels. HTLM matches or exceeds the performance of comparably sized text-only LMs for zero-shot prompting and fine-tuning for classification benchmarks, while also setting new state-of-the-art performance levels for zero-shot summarization. We also find that hyper-text prompts provide more value to HTLM, in terms of data efficiency, than plain text prompts do for existing LMs, and that HTLM is highly effective at auto-prompting itself, by simply generating the most likely hyper-text formatting for any available training data. We will release all code and models to support future HTLM research.",
    "One-sentence Summary": "We unlock new state-of-the-art ways of priming and automatically generating prompts by pre-training on simplified HTML."
  },
  {
    "title": "Illiterate DALL-E Learns to Compose",
    "url": "/forum?id=h0OYV0We3oh",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Zero-Shot Image Generation, Compositional Representation, Object-Centric Representation, Out-of-Distribution Generalization, Image Transformers",
    "Abstract": "Although DALL-E has shown an impressive ability of composition-based systematic generalization in image generation, it requires the dataset of text-image pairs and the compositionality is provided by the text. In contrast, object-centric representation models like the Slot Attention model learn composable representations without the text prompt. However, unlike DALL-E, its ability to systematically generalize for zero-shot generation is significantly limited. In this paper, we propose a simple but novel slot-based autoencoding architecture, called SLATE, for combining the best of both worlds: learning object-centric representations that allow systematic generalization in zero-shot image generation without text. As such, this model can also be seen as an illiterate DALL-E model. Unlike the pixel-mixture decoders of existing object-centric representation models, we propose to use the Image GPT decoder conditioned on the slots for capturing complex interactions among the slots and pixels. In experiments, we show that this simple and easy-to-implement architecture not requiring a text prompt achieves significant improvement in in-distribution and out-of-distribution (zero-shot) image generation and qualitatively comparable or better slot-attention structure than the models based on mixture decoders.",
    "One-sentence Summary": "To learn compositional slot-based representation of an image and perform slot composition for zero-shot novel image generation."
  },
  {
    "title": "The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models",
    "url": "/forum?id=JYtwGwIL7ye",
    "date": "28 Sept 2021 (modified: 13 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reward misspecification, reinforcement learning, reward hacking, alignment, ml safety",
    "Abstract": "Reward hacking---where RL agents exploit gaps in misspecified proxy rewards---has been widely observed, but not yet systematically studied. To understand reward hacking, we construct four RL environments with different misspecified rewards. We investigate reward hacking as a function of agent capabilities: model capacity, action space resolution, and observation space noise. Typically, more capable agents are able to better exploit reward misspecifications, causing them to attain higher proxy reward and lower true reward. Moreover, we find instances of \\emph{phase transitions}: capability thresholds at which the agent's behavior qualitatively shifts, leading to a sharp decrease in the true reward. Such phase transitions pose challenges to monitoring the safety of ML systems. To encourage further research on reward misspecification, address this, we propose an anomaly detection task for aberrant policies and offer several baseline detectors.",
    "One-sentence Summary": "We map out trends in reward misspecification and how to mitigate their impact."
  },
  {
    "title": "Optimizing Neural Networks with Gradient Lexicase Selection",
    "url": "/forum?id=J_2xNmVcY4",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep learning, lexicase selection, optimization, evolutionary algorithms",
    "Abstract": "One potential drawback of using aggregated performance measurement in machine learning is that models may learn to accept higher errors on some training cases as compromises for lower errors on others, with the lower errors actually being instances of overfitting. This can lead both to stagnation at local optima and to poor generalization. Lexicase selection is an uncompromising method developed in evolutionary computation, which selects models on the basis of sequences of individual training case errors instead of using aggregated metrics such as loss and accuracy. In this paper, we investigate how the general idea of lexicase selection can fit into the context of deep learning to improve generalization. We propose Gradient Lexicase Selection, an optimization framework that combines gradient descent and lexicase selection in an evolutionary fashion. Experimental results show that the proposed method improves the generalization performance of various popular deep neural network architectures on three image classification benchmarks. Qualitative analysis also indicates that our method helps the networks learn more diverse representations.",
    "One-sentence Summary": "We propose Gradient Lexicase Selection, an evolutionary optimization method that improves the generalization of deep neural networks."
  },
  {
    "title": "Offline Reinforcement Learning with Implicit Q-Learning",
    "url": "/forum?id=68n2s9ZJWF8",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep Reinforcement Learning, Offline Reinforcement Learning, Batch Reinforcement Learning, Continuous Control",
    "Abstract": "Offline reinforcement learning requires reconciling two conflicting aims: learning a policy that improves over the behavior policy that collected the dataset, while at the same time minimizing the deviation from the behavior policy so as to avoid errors due to distributional shift. This tradeoff is critical, because most current offline reinforcement learning methods need to query the value of unseen actions during training to improve the policy, and therefore need to either constrain these actions to be in-distribution, or else regularize their values. We propose a new offline RL method that never needs to evaluate actions outside of the dataset, but still enables the learned policy to improve substantially over the best behavior in the data through generalization. The main insight in our work is that, instead of evaluating unseen actions from the latest policy, we can approximate the policy improvement step implicitly by treating the state value function as a random variable, with randomness determined by the action (while still integrating over the dynamics to avoid excessive optimism), and then taking a state conditional upper expectile of this random variable to estimate the value of the best actions in that state. This leverages the generalization capacity of the function approximator to estimate the value of the best available action at a given state without ever directly querying a Q-function with this unseen action. Our algorithm alternates between fitting this upper expectile value function and backing it up into a Q-function, without any explicit policy. Then, we extract the policy via advantage-weighted behavioral cloning, which also avoids querying out-of-sample actions. We dub our method Implicit Q-learning (IQL).  IQL is easy to implement, computationally efficient, and only requires fitting an additional critic with an asymmetric L2 loss. IQL demonstrates the state-of-the-art performance on D4RL, a standard benchmark for offline reinforcement learning. We also demonstrate that IQL achieves strong performance fine-tuning using online interaction after offline initialization.",
    "One-sentence Summary": "Offline RL method with only dataset actions."
  },
  {
    "title": "Learning Distributionally Robust Models at Scale via Composite Optimization",
    "url": "/forum?id=To-R742x7se",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Composite Optimization, Distributionally Robust Optimization",
    "Abstract": "To train machine learning models that are robust to distribution shifts in the data, distributionally robust optimization (DRO) has been proven very effective. However, the existing approaches to learning a distributionally robust model either require solving complex optimization problems such as semidefinite programming or a first-order method whose convergence scales linearly with the number of data samples-- which hinders their scalability to large datasets.  In this paper, we show how different variants of DRO are simply instances of a finite-sum composite optimization for which we provide scalable methods.  We also provide empirical results that demonstrate the effectiveness of our proposed algorithm with respect to the prior art in order to learn robust models from very large datasets."
  },
  {
    "title": "Counterfactual Plans under Distributional Ambiguity",
    "url": "/forum?id=noaG7SrPVK0",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Counterfactual explanations, Robust optimization",
    "Abstract": "Counterfactual explanations are attracting significant attention due to the flourishing applications of machine learning models in consequential domains. A counterfactual plan consists of multiple possibilities to modify a given instance so that the model's prediction will be altered. As the predictive model can be updated subject to the future arrival of new data, a counterfactual plan may become ineffective or infeasible, with respect to the future values of the model parameters. In this work, we study the counterfactual plans under model uncertainty, in which the distribution of the model parameters is partially prescribed using only the first- and second-moment information. First, we propose an uncertainty quantification tool to compute the lower and upper bounds of the probability of feasibility for any given counterfactual plan. We then provide corrective methods to adjust the counterfactual plan to improve the feasibility measure. The numerical experiments validate our bounds and demonstrate that our correction increases the robustness of the counterfactual plans in different real-world datasets.",
    "One-sentence Summary": "This study the counterfactual plans under model uncertainty, in which the distribution of the model parameters is partially prescribed using only the first- and second-moment information."
  },
  {
    "title": "Neural Parameter Allocation Search",
    "url": "/forum?id=srtIXtySfT4",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "efficient training methods, cross-layer parameter sharing",
    "Abstract": "Training neural networks requires increasing amounts of memory. Parameter sharing can reduce memory and communication costs, but existing methods assume networks have many identical layers and utilize hand-crafted sharing strategies that fail to generalize. We introduce Neural Parameter Allocation Search (NPAS), a novel task where the goal is to train a neural network given an arbitrary, fixed parameter budget. NPAS covers both low-budget regimes, which produce compact networks, as well as a novel high-budget regime, where additional capacity can be added to boost performance without increasing inference FLOPs.  To address NPAS, we introduce Shapeshifter Networks (SSNs), which automatically learn where and how to share parameters in a network to support any parameter budget without requiring any changes to the architecture or loss function. NPAS and SSNs provide a complete framework for addressing generalized parameter sharing, and can also be combined with prior work for additional performance gains. We demonstrate the effectiveness of our approach using nine network architectures across four diverse tasks, including ImageNet classification and transformers.",
    "One-sentence Summary": "An efficient approach for searching for the optimal allocation of parameters to layers across any neural network"
  },
  {
    "title": "Non-Linear Operator Approximations for Initial Value Problems",
    "url": "/forum?id=d2TT6gK9qZn",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "exponential operators, initial value problem, pade approximation, multiwavelets, partial differential equations",
    "Abstract": "Time-evolution of partial differential equations is the key to model several dynamical processes, events forecasting but the operators associated with such problems are non-linear. We propose a Pad\u00e9 approximation based exponential neural operator scheme for efficiently learning the map between a given initial condition and activities at a later time. The multiwavelets bases are used for space discretization. By explicitly embedding the exponential operators in the model, we reduce the training parameters and make it more data-efficient which is essential in dealing with scarce real-world datasets. The Pad\u00e9 exponential operator uses a $\\textit{recurrent structure with shared parameters}$ to model the non-linearity compared to recent neural operators that rely on using multiple linear operator layers in succession. We show theoretically that the gradients associated with the recurrent Pad\u00e9 network are bounded across the recurrent horizon. We perform experiments on non-linear systems such as Korteweg-de Vries (KdV) and Kuramoto\u2013Sivashinsky (KS) equations to show that the proposed approach achieves the best performance and at the same time is data-efficient. We also show that urgent real-world problems like Epidemic forecasting (for example, COVID-19) can be formulated as a 2D time-varying operator problem. The proposed Pad\u00e9 exponential operators yield better prediction results ($\\textbf{53\\%} (\\textbf{52\\%})$ better MAE than best neural operator (non-neural operator deep learning model)) compared to state-of-the-art forecasting models.",
    "One-sentence Summary": "A Pad\u00e9 approximation based exponential operator module is proposed for working with the Initial Value Problems. The compactness of model yields data-efficiency and better performance which is demonstrated on scarce real-world dataset."
  },
  {
    "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates",
    "url": "/forum?id=7IWGzQ6gZ1D",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, lifelong learning, transfer learning, successor features",
    "Abstract": "We study the problem of learning a good set of policies, so that when combined together, they can solve a wide variety of unseen reinforcement learning tasks with no or very little new data. Specifically, we consider the framework of generalized policy evaluation and improvement, in which the rewards for all tasks of interest are assumed to be expressible as a linear combination of a fixed set of features. We show theoretically that, under certain assumptions, having access to a specific set of diverse policies, which we call a set of independent policies, can allow for instantaneously achieving high-level performance on all possible downstream tasks which are typically more complex than the ones on which the agent was trained. Based on this theoretical analysis, we propose a simple algorithm that iteratively constructs this set of policies. In addition to empirically validating our theoretical results, we compare our approach with recently proposed diverse policy set construction methods and show that, while others fail, our approach is able to build a behavior basis that enables instantaneous transfer to all possible downstream tasks. We also show empirically that having access to a set of independent policies can better bootstrap the learning process on downstream tasks where the new reward function cannot be described as a linear combination of the features. Finally, we demonstrate how this policy set can be useful in a lifelong reinforcement learning setting."
  },
  {
    "title": "Collapse by Conditioning: Training Class-conditional GANs with Limited Data",
    "url": "/forum?id=7TZeCsNOUB_",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generative Adversarial Network, GAN, Conditional GAN, limited data",
    "Abstract": "Class-conditioning offers a direct means to control a Generative Adversarial Network (GAN) based on a discrete input variable. While necessary in many applications, the additional information provided by the class labels could even be expected to benefit the training of the GAN itself. On the contrary, we observe that class-conditioning causes mode collapse in limited data settings, where unconditional learning leads to satisfactory generative ability. Motivated by this observation, we propose a training strategy for class-conditional GANs (cGANs) that effectively prevents the observed mode-collapse by leveraging unconditional learning. Our training strategy starts with an unconditional GAN and gradually injects the class conditioning into the generator and the objective function. The proposed method for training cGANs with limited data results not only in stable training but also in generating high-quality images, thanks to the early-stage exploitation of the shared information across classes. We analyze the observed mode collapse problem in comprehensive experiments on four datasets. Our approach demonstrates outstanding results compared with state-of-the-art methods and established baselines. The code is available at https://github.com/mshahbazi72/transitional-cGAN"
  },
  {
    "title": "High Probability Bounds for a Class of Nonconvex Algorithms with AdaGrad Stepsize",
    "url": "/forum?id=dSw0QtRMJkO",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "adaptive methods, nonconvex optimization, stochastic optimization, high probability bounds",
    "Abstract": "In this paper, we propose a new, simplified high probability analysis of AdaGrad for smooth, non-convex problems. \n        More specifically, we focus on a particular accelerated gradient (AGD) template (Lan, 2020), through which we recover the original AdaGrad and its variant with averaging, and prove a convergence rate of $\\mathcal O (1/ \\sqrt{T})$ with high probability without the knowledge of smoothness and variance. \n        We use a particular version of Freedman's concentration bound for martingale difference sequences (Kakade & Tewari, 2008) which enables us to achieve the best-known dependence of $\\log (1 / \\delta )$ on the probability margin $\\delta$. \n        We present our analysis in a modular way and obtain a complementary $\\mathcal O (1 / T)$ convergence rate in the deterministic setting. \n        To the best of our knowledge, this is the first high probability result for AdaGrad with a truly adaptive scheme, i.e., completely oblivious to the knowledge of smoothness and uniform variance bound, which simultaneously has best-known dependence of $\\log( 1/ \\delta)$. \n        We further prove noise adaptation property of AdaGrad under additional noise assumptions."
  },
  {
    "title": "Map Induction: Compositional spatial submap learning for efficient exploration in novel environments",
    "url": "/forum?id=1NUsBU-7HAL",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Cognitive Science, Bayesian Framework, Program Induction, Spatial Navigation, Planning, Map Learning",
    "Abstract": "Humans are expert explorers and foragers. Understanding the computational cognitive mechanisms that support this capability can advance the study of the human mind and enable more efficient exploration algorithms. We hypothesize that humans explore new environments by inferring the structure of unobserved spaces through re-use of spatial information collected from previously explored spaces. Taking inspiration from the neuroscience of repeating map fragments and ideas about program induction, we present a novel ``Map Induction'' framework, which involves the generation of novel map proposals for unseen environments based on compositions of already-seen spaces in a Hierarchical Bayesian framework. The model thus explicitly reasons about unseen spaces through a distribution of strong spatial priors. We introduce a new behavioral Map Induction Task (MIT) that involves foraging for rewards to compare human performance with state-of-the-art existing models and Map Induction. We show that Map Induction better predicts human behavior than the non-inductive baselines. We also show that Map Induction, when used to augment state-of-the-art approximate planning algorithms, improves their performance.",
    "One-sentence Summary": "Modelling Map Induction for efficient exploration in novel environments."
  },
  {
    "title": "How Did the Model Change? Efficiently Assessing Machine Learning API Shifts",
    "url": "/forum?id=gFDFKC4gHL4",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "ML API performance shifts, ML as a service, ML monitoring, ML performance evaluation",
    "Abstract": "ML prediction APIs from providers like Amazon and Google have made it simple to use ML in applications. A challenge for users is that such APIs continuously change over time as the providers update models, and changes can happen silently without users knowing. It is thus important to monitor when and how much the MLAPIs\u2019 performance shifts. To provide detailed change assessment, we model MLAPI shifts as confusion matrix differences, and propose a principled algorithmic framework, MASA, to provably assess these shifts efficiently given a sample budget constraint.MASAemploys an upper-confidence bound based approach to adaptively determine on which data point to query the ML API to estimate shifts. Empirically, we observe significant ML API shifts from 2020 to 2021 among 12 out of 36 applications using commercial APIs from Google, Microsoft, Amazon, and other providers. These real-world shifts include both improvements and reductions in accuracy. Extensive experiments show that MASA can estimate such API shifts more accurately than standard approaches given the same budget",
    "One-sentence Summary": "We systematically study real world ML APIs' performance shifts due to API updates/retraining and propose a framework to efficiently estimate those shifts."
  },
  {
    "title": "A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model",
    "url": "/forum?id=31d5RLCUuXC",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Langevin dynamics, energy-based model, normalizing flow, cooperative learning, short-run MCMC",
    "Abstract": "This paper studies the cooperative learning of two generative flow models, in which the two models are iteratively updated based on the jointly synthesized examples. The first flow model is a normalizing flow that transforms an initial simple density to a target density by applying a sequence of invertible transformations. The second flow model is a Langevin flow that runs finite steps of gradient-based MCMC toward an energy-based model. We start from proposing a generative framework that trains an energy-based model with a normalizing flow as an amortized sampler to initialize the MCMC chains of the energy-based model. In each learning iteration, we generate synthesized examples by using a normalizing flow initialization followed by a short-run Langevin flow revision toward the current energy-based model. Then we treat the synthesized examples as fair samples from the energy-based model and update the model parameters with the maximum likelihood learning gradient, while the normalizing flow directly learns from the synthesized examples by maximizing the tractable likelihood. Under the short-run non-mixing MCMC scenario, the estimation of the energy-based model  is shown to follow the perturbation of maximum likelihood, and the short-run Langevin flow and the normalizing flow form a two-flow generator that we call CoopFlow. We provide an  understating of the CoopFlow algorithm by information geometry and show that it is a valid generator as it converges to a moment matching estimator. We demonstrate that the trained CoopFlow is capable of synthesizing realistic images, reconstructing images, and interpolating between images.",
    "One-sentence Summary": "Joint learning of a short-run MCMC generator and a normalizing flow in the context of energy-based model for image representation and generation."
  },
  {
    "title": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?",
    "url": "/forum?id=WVX0NNVBBkV",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "adversarial robustness, certified adversarial robustness, adversarial attacks, generative models, proxy distribution",
    "Abstract": "While additional training data improves the robustness of deep neural networks against adversarial examples, it presents the challenge of curating a large number of specific real-world samples. We circumvent this challenge by using additional data from proxy distributions learned by advanced  generative models. We first seek to formally understand the transfer of robustness from classifiers trained on proxy distributions to the real data distribution. We prove that the difference between the robustness of a classifier on the two distributions is upper bounded by the conditional Wasserstein distance between them. Next we use proxy distributions to significantly improve the performance of adversarial training on five different datasets. For example, we improve robust accuracy by up to $7.5$% and $6.7$% in $\\ell_{\\infty}$ and $\\ell_2$ threat model over baselines that are not using proxy distributions on the CIFAR-10 dataset. We also improve certified robust accuracy by $7.6$% on the CIFAR-10 dataset. We further demonstrate that different generative models brings a disparate improvement in the performance in robust training. We propose a robust discrimination approach to characterize the impact and further provide a deeper understanding of why diffusion-based generative models are a better choice for proxy distribution than generative adversarial networks.",
    "One-sentence Summary": "We leverage proxy distributions to significantly improve the robustness of deep neural network."
  },
  {
    "title": "Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap",
    "url": "/forum?id=ECvgmYVyeUz",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Contrastive Learning, Representation Learning, Self-supervised Learning",
    "Abstract": "Recently, contrastive learning has risen to be a promising approach for large-scale self-supervised learning. However, theoretical understanding of how it works is still unclear. In this paper, we propose a new guarantee on the downstream performance without resorting to the conditional independence assumption that is widely adopted in previous work but hardly holds in practice. Our new theory hinges on the insight that the support of different intra-class samples will become more overlapped under aggressive data augmentations, thus simply aligning the positive samples (augmented views of the same sample) could make contrastive learning cluster intra-class samples together. Based on this augmentation overlap perspective, theoretically, we obtain asymptotically closed bounds for downstream performance under weaker assumptions, and empirically, we propose an unsupervised model selection metric ARC that aligns well with downstream accuracy. Our theory suggests an alternative understanding of contrastive learning: the role of aligning positive samples is more like a surrogate task than an ultimate goal, and the overlapped augmented views (i.e., the chaos) create a ladder for contrastive learning to gradually learn class-separated representations. The code for computing ARC is available at https://github.com/zhangq327/ARC."
  },
  {
    "title": "Language-biased image classification: evaluation based on semantic representations",
    "url": "/forum?id=xNO7OEIcJc6",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "interpretation of learned representations, language and visual processing, language-biased image classification, cognitive science",
    "Abstract": "Humans show language-biased image recognition for a word-embedded image, known as picture-word interference. Such interference depends on hierarchical semantic categories and reflects that human language processing highly interacts with visual processing. Similar to humans, recent artificial models jointly trained on texts and images, e.g., OpenAI CLIP, show language-biased image classification. Exploring whether the bias leads to interference similar to those observed in humans can contribute to understanding how much the model acquires hierarchical semantic representations from joint learning of language and vision. The present study introduces methodological tools from the cognitive science literature to assess the biases of artificial models. Specifically, we introduce a benchmark task to test whether words superimposed on images can distort the image classification across different category levels and, if it can, whether the perturbation is due to the shared semantic representation between language and vision. Our dataset is a set of word-embedded images and consists of a mixture of natural image datasets and hierarchical word labels with superordinate/basic category levels. Using this benchmark test, we evaluate the CLIP model. We show that presenting words distorts the image classification by the model across different category levels, but the effect does not depend on the semantic relationship between images and embedded words. This suggests that the semantic word representation in the CLIP visual processing is not shared with the image representation, although the word representation strongly dominates for word-embedded images.",
    "One-sentence Summary": "We developed a benchmark test based on hierarchical semantic compositionality to evaluate the language-biased image classification of artificial models  and evaluated the CLIP model using it."
  },
  {
    "title": "Robbing the Fed:  Directly Obtaining Private Data in Federated Learning with Modified Models",
    "url": "/forum?id=fwzUgo0FM9v",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Privacy, Federated Learning, Gradient Inversion",
    "Abstract": "Federated learning has quickly gained popularity with its promises of increased user privacy and efficiency.  Previous works have shown that federated gradient updates contain information that can be used to approximately recover user data in some situations.  These previous attacks on user privacy have been limited in scope and do not scale to gradient updates aggregated over even a handful of  data  points,  leaving  some  to  conclude  that  data  privacy  is  still  intact  for realistic training regimes.  In this work, we introduce a new threat model based on minimal but malicious modifications of the shared model architecture which enable the server to directly obtain a verbatim copy of user data from gradient updates without solving difficult inverse problems.  Even user data aggregated over large batches \u2013 where previous methods fail to extract meaningful content \u2013 can be reconstructed by these minimally modified models."
  },
  {
    "title": "Practical Conditional Neural Process Via Tractable Dependent Predictions",
    "url": "/forum?id=3pugbNqOh5m",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "conditional neural processes, neural processes, meta-learning, convolutional conditional neural processes, Gaussian neural processes",
    "Abstract": "Conditional Neural Processes (CNPs; Garnelo et al., 2018a) are meta-learning models which leverage the flexibility of deep learning to produce well-calibrated predictions and naturally handle off-the-grid and missing data. CNPs scale to large datasets and train with ease. Due to these features, CNPs appear well-suited to tasks from environmental sciences or healthcare. Unfortunately, CNPs do not produce correlated predictions, making them fundamentally inappropriate for many estimation and decision making tasks. Predicting heat waves or floods, for example, requires modelling dependencies in temperature or precipitation over time and space. Existing approaches which model output dependencies, such as Neural Processes (NPs; Garnelo et al., 2018b) or the FullConvGNP (Bruinsma et al., 2021), are either complicated to train or prohibitively expensive. What is needed is an approach which provides dependent predictions, but is simple to train and computationally tractable. In this work, we present a new class of Neural Process models that make correlated predictions and support exact maximum likelihood training that is simple and scalable. We extend the proposed models by using invertible output transformations, to capture non-Gaussian output distributions. Our models can be used in downstream estimation tasks which require dependent function samples. By accounting for output dependencies, our models show improved predictive performance on a range of experiments with synthetic and real data."
  },
  {
    "title": "Reward Uncertainty for Exploration in Preference-based Reinforcement Learning",
    "url": "/forum?id=OWZVD-l-ZrC",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Conveying complex objectives to reinforcement learning (RL) agents often requires meticulous reward engineering. Preference-based RL methods are able to learn a more flexible reward model based on human preferences by actively incorporating human feedback, i.e. teacher's preferences between two clips of behaviors. However, poor feedback-efficiency still remains as a problem in current preference-based RL algorithms, as tailored human feedback is very expensive. To handle this issue, previous methods have mainly focused on improving query selection and policy initialization. At the same time, recent exploration methods have proven to be a recipe for improving sample-efficiency in RL. We present an exploration method specifically for preference-based RL algorithms. Our main idea is to design an intrinsic reward by measuring the novelty based on learned reward. Specifically, we utilize disagreement across ensemble of learned reward models. Our intuition is that disagreement in learned reward model reflects uncertainty in tailored human feedback and could be useful for exploration. Our experiments show that reward uncertainty exploration improves both feedback- and sample-efficiency of preference-based RL algorithms on complex robot manipulation tasks from Meta-World benchmarks, compared with other existing exploration methods that measure the novelty of state visitation."
  },
  {
    "title": "Decentralized Learning for Overparameterized Problems: A Multi-Agent Kernel Approximation Approach",
    "url": "/forum?id=oj2yn1Q4Ett",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "distributed optimization, over-parameterized optimization, kernel learning",
    "Abstract": "This work develops a novel framework for communication-efficient distributed learning where the models to be learned are overparameterized. We focus on a class of kernel learning problems (which includes the popular neural tangent kernel (NTK) learning as a special case) and propose a novel {\\it multi-agent kernel approximation} technique that allows the agents to distributedly estimate the full kernel function, and subsequently perform decentralized optimization, without directly exchanging any local data or parameters. The proposed framework is a significant departure from the classical consensus-based approaches, because the agents do not exchange problem parameters, and no consensus is required. We analyze the optimization and the generalization performance of the proposed framework for the $\\ell_2$ loss. We show that with $M$ agents and $N$ total samples when certain generalized inner-product kernels (resp. the random features kernel) are used, each agent needs to communicate $\\mathcal{O}\\big({N^2}/{M}\\big)$ bits (resp. $\\mathcal{O}\\big(N \\sqrt{N}/M \\big)$ real values) to achieve minimax optimal generalization performance. We validate the theoretical results on 90 UCI benchmarking datasets (with average data size $N \\approx 1000$) and show that each agent needs to share a total of $200N/M$ bits (resp. $3N/M$ real values) to closely match the performance of the centralized algorithms, and these numbers are independent of parameter and feature dimensions.",
    "One-sentence Summary": "Decentralized optimization for overparameterized kernel learning"
  },
  {
    "title": "Permutation-Based SGD: Is Random Optimal?",
    "url": "/forum?id=YiBa9HKTyXE",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Convex Optimization, Stochastic Optimization, Large Scale Learning",
    "Abstract": "A recent line of ground-breaking results for permutation-based SGD  has corroborated a widely observed phenomenon: random permutations offer faster convergence than with-replacement sampling. However, is random optimal? We show that this depends heavily on what functions we are optimizing, and the convergence gap between optimal and random permutations can vary from exponential to nonexistent. We first show that for 1-dimensional strongly convex functions, with smooth second derivatives, there exist optimal permutations that offer exponentially faster convergence compared to random. However, for general strongly convex functions, random permutations are optimal. Finally, we show that for quadratic, strongly-convex functions, there are easy-to-construct permutations that lead to accelerated convergence compared to random. Our results suggest that a general convergence characterization of optimal permutations cannot capture the nuances of individual function classes, and can  mistakenly indicate that one cannot do much better than random.",
    "One-sentence Summary": "We show that the question of whether random permutations are optimal for permutation-based SGD is nuanced, and depends on the family of functions one is trying to optimize."
  },
  {
    "title": "Graph-less Neural Networks: Teaching Old MLPs New Tricks Via Distillation",
    "url": "/forum?id=4p6_5HBWPCw",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Distillation, Node Classification, Model Inference Acceleration",
    "Abstract": "Graph Neural Networks (GNNs) are popular for graph machine learning and have shown great results on wide node classification tasks. Yet, they are less popular for practical deployments in the industry owing to their scalability challenges incurred by data dependency. Namely, GNN inference depends on neighbor nodes multiple hops away from the target, and fetching them burdens latency-constrained applications. Existing inference acceleration methods like pruning and quantization can speed up GNNs by reducing Multiplication-and-ACcumulation (MAC) operations, but the improvements are limited given the data dependency is not resolved. Conversely, multi-layer perceptrons (MLPs) have no graph dependency and infer much faster than GNNs, even though they are less accurate than GNNs for node classification in general. Motivated by these complementary strengths and weaknesses, we bring GNNs and MLPs together via knowledge distillation (KD). Our work shows that the performance of MLPs can be improved by large margins with GNN KD. We call the distilled MLPs Graph-less Neural Networks (GLNNs) as they have no inference graph dependency. We show that GLNNs with competitive accuracy infer faster than GNNs by 146X-273X and faster than other acceleration methods by 14X-27X. Under a production setting involving both transductive and inductive predictions across 7 datasets, GLNN accuracies improve over stand-alone MLPs by 12.36% on average and match GNNs on 6/7 datasets. Comprehensive analysis shows when and why GLNNs can achieve competitive accuracies to GNNs and suggests GLNN as a handy choice for latency-constrained applications.",
    "One-sentence Summary": "Distill knowledge from GNNs to MLPs to accelerate model inference and facilitate deployment for large-scale applications"
  },
  {
    "title": "Relating transformers to models and neural representations of the hippocampal formation",
    "url": "/forum?id=B8DVo9B1YE0",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neuroscience, representation learning, hippocampus, cortex, transformers",
    "Abstract": "Many deep neural network architectures loosely based on brain networks have recently been shown to replicate neural firing patterns observed in the brain. One of the most exciting and promising novel architectures, the Transformer neural network, was developed without the brain in mind. In this work, we show that transformers, when equipped with recurrent position encodings, replicate the precisely tuned spatial representations of the hippocampal formation; most notably place and grid cells. Furthermore, we show that this result is no surprise since it is closely related to current hippocampal models from neuroscience. We additionally show the transformer version offers dramatic performance gains over the neuroscience version. This work continues to bind computations of artificial and brain networks, offers a novel understanding of the hippocampal-cortical interaction, and suggests how wider cortical areas may perform complex tasks beyond current neuroscience models such as language comprehension.",
    "One-sentence Summary": "Transformers learn brain representatations and they are algorithmically related to models of the hippocampal formation."
  },
  {
    "title": "How many degrees of freedom do we need to train deep networks: a loss landscape perspective",
    "url": "/forum?id=ChMLTGRjFcU",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "loss landscape, high-dimensional geometry, random hyperplanes, optimization",
    "Abstract": "A variety of recent works, spanning pruning, lottery tickets, and training within random subspaces, have shown that deep neural networks can be trained using far fewer degrees of freedom than the total number of parameters. We analyze this phenomenon for random subspaces by first examining the success probability of hitting a training loss sublevel set when training within a random subspace of a given training dimensionality.  We find a sharp phase transition in the success probability from $0$ to $1$ as the training dimension surpasses a threshold. This threshold training dimension increases as the desired final loss decreases, but decreases as the initial loss decreases. We then theoretically explain the origin of this phase transition, and its dependence on initialization and final desired loss, in terms of properties of the high-dimensional geometry of the loss landscape.  In particular, we show via Gordon's escape theorem, that the training dimension plus the Gaussian width of the desired loss sublevel set, projected onto a unit sphere surrounding the initialization, must exceed the total number of parameters for the success probability to be large.  In several architectures and datasets, we measure the threshold training dimension as a function of initialization and demonstrate that it is a small fraction of the total parameters, implying by our theory that successful training with so few dimensions is possible precisely because the Gaussian width of low loss sublevel sets is very large. Moreover, we compare this threshold training dimension to more sophisticated ways of reducing training degrees of freedom, including lottery tickets as well as a new, analogous method: lottery subspaces."
  },
  {
    "title": "Is Importance Weighting Incompatible with Interpolating Classifiers?",
    "url": "/forum?id=uqBOne3LUKy",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "overparameterization, distribution shifts, importance weighting, implicit bias, generalization analysis, interpolation",
    "Abstract": "Importance weighting is a classic technique to handle distribution shifts. However, prior work has presented strong empirical and theoretical evidence demonstrating that importance weights can have little to no effect on overparameterized neural networks. \\emph{Is importance weighting truly incompatible with the training of overparameterized neural networks?} Our paper answers this in the negative. We show that importance weighting fails not because of the overparameterization, but instead, as a result of using exponentially-tailed losses like the logistic or cross-entropy loss. As a remedy, we show that polynomially-tailed losses restore the effects of importance reweighting in correcting distribution shift in overparameterized models. We characterize the behavior of gradient descent on importance weighted polynomially-tailed losses with overparameterized linear models, and theoretically demonstrate the advantage of using polynomially-tailed losses in a label shift setting. Surprisingly, our theory shows that using weights that are obtained by exponentiating the classical unbiased importance weights can improve performance. Finally, we demonstrate the practical value of our analysis with neural network experiments on a subpopulation shift and a label shift dataset. When reweighted, our loss function can outperform reweighted cross-entropy by as much as 9\\% in test accuracy. Our loss function also gives test accuracies comparable to, or even exceeding, well-tuned state-of-the-art methods for correcting distribution shifts.",
    "One-sentence Summary": "We theoretically and empirically demonstrate that importance weighting can be effective in handling distribution shifts in overparameterized classifiers."
  },
  {
    "title": "Neural Models for Output-Space Invariance in Combinatorial Problems",
    "url": "/forum?id=ibrUkC-pbis",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural reasoning, output space invariance",
    "Abstract": "Recently many neural models have been proposed to solve combinatorial puzzles by implicitly learning underlying constraints using their solved instances, such as sudoku or graph coloring (GCP). One drawback of the proposed architectures, which are often based on Graph Neural Networks (GNN) (Zhou et al., 2020), is that they cannot generalize across the size of the output space from which variables are assigned a value, for example, set of colors in a GCP, or board-size in sudoku. We call the output space for the variables as \u2018value-set\u2019. While many works have demonstrated generalization of GNNs across graph size, there has been no study on how to design a GNN for achieving value-set invariance for problems that come from the same domain. For example, learning to solve 16 x 16 sudoku after being trained on only 9 x 9 sudokus, or coloring a 7 colorable graph after training on 4 colorable graphs.  In this work, we propose novel methods to extend GNN based architectures to achieve value-set invariance. Specifically, our model builds on recently proposed Recurrent Relational Networks (RRN) (Palm et al., 2018). Our first approach exploits the graph-size invariance of GNNs by converting a multi-class node classification problem into a binary node classification problem. Our second approach works directly with multiple classes by adding multiple nodes corresponding to the values in the value-set, and then connecting variable nodes to value nodes depending on the problem initialization. Our experimental evaluation on three different combinatorial problems demonstrates that both our models perform well on our novel problem, compared to a generic neural reasoner. Between two of our models, we observe an inherent trade-off: while the binarized model gives better performance when trained on smaller value-sets, multi-valued model is much more memory efficient, resulting in improved performance when trained on larger value-sets, where binarized model fails to train.",
    "One-sentence Summary": "We design GNN based neural models to achieve output space invariance in combinatorial problems, e.g. solving 16 x 16 sudoku after training on 9 x 9 sudoku"
  },
  {
    "title": "StyleNeRF: A Style-based 3D Aware Generator for High-resolution Image Synthesis",
    "url": "/forum?id=iUuzzTMUw9K",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Radiance Field, StyleGAN, high resolution image generation",
    "Abstract": "We propose StyleNeRF, a 3D-aware generative model for photo-realistic high-resolution image synthesis with high multi-view  consistency, which can be trained on unstructured 2D images. Existing approaches either cannot synthesize high-resolution images with fine details or yield clearly noticeable 3D-inconsistent artifacts. In addition, many of them lack control on style attributes and explicit 3D camera poses. To address these issues, StyleNeRF integrates the neural radiance field (NeRF) into a style-based generator to tackle the aforementioned challenges, i.e., improving rendering efficiency and 3D consistency for high-resolution image generation. To address the first issue, we perform volume rendering only to produce a low-resolution feature map, and progressively apply upsampling in 2D. To mitigate the inconsistencies caused by 2D upsampling, we propose multiple designs including a better upsampler choice and a new regularization loss to enforce 3D consistency. With these designs, StyleNeRF is able to synthesize high-resolution images at interactive rates while preserving 3D consistency at high quality. StyleNeRF also enables control of camera poses and different levels of styles, which can generalize to unseen views. It also supports challenging tasks such as style mixing, inversion and simple semantic edits.",
    "One-sentence Summary": "We present StyleNeRF, a 3D-aware generative model that can synthesize high-resolution images with high multi-view consistency."
  },
  {
    "title": "The Role of Pretrained Representations for the OOD Generalization of RL Agents",
    "url": "/forum?id=8eb12UQYxrG",
    "date": "28 Sept 2021 (modified: 03 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "representations, out-of-distribution, generalization, deep learning, reinforcement learning",
    "Abstract": "Building sample-efficient agents that generalize out-of-distribution (OOD) in real-world settings remains a fundamental unsolved problem on the path towards achieving higher-level cognition. One particularly promising approach is to begin with low-dimensional, pretrained representations of our world, which should facilitate efficient downstream learning and generalization. By training 240 representations and over 10,000 reinforcement learning (RL) policies on a simulated robotic setup, we evaluate to what extent different properties of pretrained VAE-based representations affect the OOD generalization of downstream agents. We observe that many agents are surprisingly robust to realistic distribution shifts, including the challenging sim-to-real case. In addition, we find that the generalization performance of a simple downstream proxy task reliably predicts the generalization performance of our RL agents under a wide range of OOD settings. Such proxy tasks can thus be used to select pretrained representations that will lead to agents that generalize.",
    "One-sentence Summary": "We study the role of pretrained representations for the out-of-distribution generalization of RL agents."
  },
  {
    "title": "Enabling Arbitrary Translation Objectives with Adaptive Tree Search",
    "url": "/forum?id=rhOiUS8KQM9",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Machine Translation, Decoding, MCTS, Beam Search",
    "Abstract": "We introduce an adaptive tree search algorithm, which is a deterministic variant of Monte Carlo tree search, that can find high-scoring outputs under translation models that make no assumptions about the form or structure of the search objective. This algorithm enables the exploration of new kinds of models that are unencumbered by constraints imposed to make decoding tractable, such as autoregressivity or conditional independence assumptions. When applied to autoregressive models, our algorithm has different biases than beam search has, which enables a new analysis of the role of decoding bias in autoregressive models. Empirically, we show that our adaptive tree search algorithm finds outputs with substantially better model scores compared to beam search in autoregressive models, and compared to reranking techniques in models whose scores do not decompose additively with respect to the words in the output. We also characterise the correlation of several translation model objectives with respect to BLEU. We find that while some standard models are poorly calibrated and benefit from the beam search bias, other often more robust models (autoregressive models tuned to maximize expected automatic metric scores, the noisy channel model and a newly proposed objective) benefit from increasing amounts of search using our proposed decoder, whereas the beam search bias limits the improvements obtained from such objectives. Thus, we argue that as models improve, the improvements may be masked by over-reliance on beam search or reranking based methods.",
    "One-sentence Summary": "MCTS is used as a decoder for autoregressive and non-autoregressive machine translation models."
  },
  {
    "title": "Proof Artifact Co-Training for Theorem Proving with Language Models",
    "url": "/forum?id=rpxJc9j04U",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self-supervised learning, mathematics, reasoning, theorem proving, language modeling",
    "Abstract": "Labeled data for imitation learning of theorem proving in large libraries of formalized mathematics is scarce as such libraries require years of concentrated effort by human specialists to be built. This is particularly challenging when applying large Transformer language models to tactic prediction, because the scaling of performance with respect to model size is quickly disrupted in the data-scarce, easily-overfitted regime.  We propose PACT (Proof Artifact Co-Training), a general methodology for extracting abundant self-supervised data from kernel-level proof terms for joint training alongside the usual tactic prediction objective.  We apply this methodology to Lean,an interactive proof assistant which hosts some of the most sophisticated formalized mathematics to date. We instrument Lean with a neural theorem prover driven by a Transformer language model and show that PACT improves theorem proving success rate on a held-out suite of test theorems from 32% to 48%.",
    "One-sentence Summary": "Co-training on low-level proof tasks in a Transformer theorem prover improves success from 32% to 48% on Lean theorems."
  },
  {
    "title": "Mirror Descent Policy Optimization",
    "url": "/forum?id=aBO5SvgSt1",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Policy Optimization",
    "Abstract": "Mirror descent (MD), a well-known first-order method in constrained convex optimization, has recently been shown as an important tool to analyze trust-region algorithms in reinforcement learning (RL). However, there remains a considerable gap between such theoretically analyzed algorithms and the ones used in practice. Inspired by this, we propose an efficient RL algorithm, called {\\em mirror descent policy optimization} (MDPO). MDPO iteratively updates the policy by {\\em approximately} solving a trust-region problem, whose objective function consists of two terms: a linearization of the standard RL objective and a proximity term that restricts two consecutive policies to be close to each other. Each update performs this approximation by taking multiple gradient steps on this objective function. We derive {\\em on-policy} and {\\em off-policy} variants of MDPO, while emphasizing important design choices motivated by the existing theory of MD in RL. We highlight the connections between on-policy MDPO and two popular trust-region RL algorithms: TRPO and PPO, and show that explicitly enforcing the trust-region constraint is in fact {\\em not} a necessity for high performance gains in TRPO. We then show how the popular soft actor-critic (SAC) algorithm can be derived by slight modifications of off-policy MDPO. Overall, MDPO is derived from the MD principles, offers a unified approach to viewing a number of popular RL algorithms, and performs better than or on-par with TRPO, PPO, and SAC in a number of continuous and discrete control tasks.",
    "One-sentence Summary": "A theory-grounded practical algorithm for policy optimization in RL, which is conceptually simpler and performs better or on par to SOTA."
  },
  {
    "title": "A Loss Curvature Perspective on Training Instabilities of Deep Learning Models",
    "url": "/forum?id=OcKMT-36vUs",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Optimization, Deep Learning, Training Instability, Curvature, Loss Landscape, Hessian",
    "Abstract": "In this work, we study the evolution of the loss Hessian across many classification tasks in order to understand the effect the curvature of the loss has on the training dynamics. Whereas prior work has focused on how different learning rates affect the loss Hessian observed during training, we also analyze the effects of model initialization, architectural choices, and common training heuristics such as gradient clipping and learning rate warmup. Our results demonstrate that successful model and hyperparameter choices allow the early optimization trajectory to either avoid---or navigate out of---regions of high curvature and into flatter regions that tolerate a higher learning rate. Our results suggest a unifying perspective on how disparate mitigation strategies for training instability ultimately address the same underlying failure mode of neural network optimization, namely poor conditioning. Inspired by the conditioning perspective, we show that learning rate warmup can improve training stability just as much as batch normalization, layer normalization, MetaInit, GradInit, and Fixup initialization.",
    "One-sentence Summary": "Our results suggest a unifying perspective on how disparate mitigation strategies for training instability ultimately address poor conditioning."
  },
  {
    "title": "Cross-Domain Imitation Learning via Optimal Transport",
    "url": "/forum?id=xP3cPq2hQC",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "optimal transportation, imitation learning, cross-domain imitation learning, gromov-Wasserstein",
    "Abstract": "Cross-domain imitation learning studies how to leverage expert demonstrations of one agent to train an imitation agent with a different embodiment or morphology. Comparing trajectories and stationary distributions between the expert and imitation agents is challenging because they live on different systems that may not even have the same dimensionality. We propose Gromov-Wasserstein Imitation Learning (GWIL), a method for cross-domain imitation that uses the Gromov-Wasserstein distance to align and compare states between the different spaces of the agents. Our theory formally characterizes the scenarios where GWIL preserves optimality, revealing its possibilities and limitations. We demonstrate the effectiveness of GWIL in non-trivial continuous control domains ranging from simple rigid transformation of the expert domain to arbitrary transformation of the state-action space.",
    "One-sentence Summary": "We study the use of Gromov-Wasserstein for cross-domain imitation learning"
  },
  {
    "title": "Large-Scale Representation Learning on Graphs via Bootstrapping",
    "url": "/forum?id=0UXT6PpRpW",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Self-supervised learning provides a promising path towards eliminating the need for costly label information in representation learning on graphs.  However, to achieve state-of-the-art performance, methods often need large numbers of negative examples and rely on complex augmentations.  This can be prohibitively expensive, especially for large graphs. To address these challenges, we introduce Bootstrapped Graph Latents (BGRL) - a graph representation learning method that learns by predicting alternative augmentations of the input. BGRL uses only simple augmentations and alleviates the need for contrasting with negative examples, and thus is scalable by design. BGRL outperforms or matches prior methods on several established benchmarks, while achieving a 2-10x reduction in memory costs. Furthermore, we show that BGRL can be scaled up to extremely large graphs with hundreds of millions of nodes in the semi-supervised regime, achieving state-of-the-art performance and improving over supervised baselines where representations are shaped only through label information.  In particular, our solution centered on BGRL constituted one of the winning entries to the Open Graph Benchmark -Large Scale Challenge at KDD Cup 2021, on a graph orders of magnitudes larger than all previously available benchmarks, thus demonstrating the scalability and effectiveness of our approach."
  },
  {
    "title": "Robust and Scalable SDE Learning: A Functional Perspective",
    "url": "/forum?id=xZ6H7wydGl",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "SDE Learning, Parallelization, Importance Sampling",
    "Abstract": "Stochastic differential equations provide a rich class of flexible generative\n        models, capable of describing a wide range of spatio-temporal processes. A host\n        of recent work looks to learn data-representing SDEs, using neural networks and\n        other flexible function approximators. Despite these advances, learning remains\n        computationally expensive due to the sequential nature of SDE integrators. In\n        this work, we propose an importance-sampling estimator for probabilities of\n        observations of SDEs for the purposes of learning. Crucially, the approach we\n        suggest does not rely on such integrators. The proposed method produces\n        lower-variance gradient estimates compared to algorithms based on SDE\n        integrators and has the added advantage of being embarrassingly parallelizable.\n        This facilitates the effective use of large-scale parallel hardware for massive\n        decreases in computation time.",
    "One-sentence Summary": "We provide an algorithm for estimating the probability of observations of a stochastic process which is significantly faster and more stable than those based on standard integration schemes"
  },
  {
    "title": "Neural Processes with Stochastic Attention: Paying more attention to the context dataset",
    "url": "/forum?id=JPkQwEdYn8",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural processes, stochastic attention, variational inference, information theory",
    "Abstract": "Neural processes (NPs) aim to stochastically complete unseen data points based on a given context dataset. NPs essentially leverage a given dataset as a context representation to derive a suitable identifier for a novel task. To improve the prediction accuracy, many variants of NPs have investigated context embedding approaches that generally design novel network architectures and aggregation functions satisfying permutation invariant. In this work, we propose a stochastic attention mechanism for NPs to capture appropriate context information. From the perspective of information theory, we demonstrate that the proposed method encourages context embedding to be differentiated from a target dataset, allowing NPs to consider features in a target dataset and context embedding independently. We observe that the proposed method can appropriately capture context embedding even under noisy data sets and restricted task distributions, where typical NPs suffer from a lack of context embeddings. We empirically show that our approach substantially outperforms conventional NPs in various domains through 1D regression, predator-prey model, and image completion. Moreover, the proposed method is also validated by MovieLens-10k dataset, a real-world problem.",
    "One-sentence Summary": "This paper extends the attentive neural process (ANP), replacing the deterministic weights in the cross-attention module of ANP with latent weights."
  },
  {
    "title": "Evaluating Disentanglement of Structured Representations",
    "url": "/forum?id=SLz5sZjacp",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We introduce the first metric for evaluating disentanglement at individual hierarchy levels of a structured latent representation. Applied to object-centric generative models, this offers a systematic, unified approach to evaluating (i) object separation between latent slots (ii) disentanglement of object properties inside individual slots (iii) disentanglement of intrinsic and extrinsic object properties. We theoretically show that our framework gives stronger guarantees of selecting a good model than previous disentanglement metrics. Experimentally, we demonstrate that viewing object compositionality as a disentanglement problem addresses several issues with prior visual metrics of object separation. As a core technical component, we present the first representation probing algorithm handling slot permutation invariance.",
    "One-sentence Summary": "We introduce the first metric for evaluating disentanglement at individual hierarchy levels of a structured latent representation, and apply it to object-centric generative models."
  },
  {
    "title": "Geometric Transformers for Protein Interface Contact Prediction",
    "url": "/forum?id=CS4463zx6Hi",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Geometric Deep Learning, Graph Transformers, Protein Bioinformatics, Invariance",
    "Abstract": "Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.",
    "One-sentence Summary": "We introduce a geometry-evolving graph transformer for 3D protein structures and employ it to achieve state-of-the-art precision for predicting inter-protein residue-residue contacts in challenging protein complex targets."
  },
  {
    "title": "Diurnal or Nocturnal? Federated Learning of Multi-branch Networks from Periodically Shifting Distributions",
    "url": "/forum?id=E4EE_ohFGz",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, Peroredical Distribution Shift",
    "Abstract": "Federated learning has been deployed to train machine learning models from decentralized client data on mobile devices in practice. The clients available for training are observed to have periodically shifting distributions changing with the time of day, which can cause instability in training and degrade the model performance. In this paper, instead of modeling the distribution shift with a block-cyclic pattern as previous works, we model it with a mixture of distributions that gradually shifts between daytime and nighttime modes, and find this intuitive model to better match the observations in practical federated learning systems. \n        Furthermore, we propose to jointly train a clustering model and a multi-branch network to allocate lightweight specialized branches to clients from different modes. A temporal prior is used to significantly boost the training performance.\n        Experiments for image classification on EMNIST and CIFAR datasets, and next word prediction on the Stack Overflow dataset show that the proposed algorithm can counter the effects of the distribution shift and significantly improve the final model performance.",
    "One-sentence Summary": "We study a better modeling assumption for the periodical distribution shift in FL, and propose algorithms that learn better from the shifting distribution."
  },
  {
    "title": "IGLU: Efficient GCN Training via Lazy Updates",
    "url": "/forum?id=5kq11Tl1z4",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph convolutional networks, Graph neural networks, Optimization, Lazy updates",
    "Abstract": "Training multi-layer Graph Convolution Networks (GCN) using standard SGD techniques scales poorly as each descent step ends up updating node embeddings for a large portion of the graph. Recent attempts to remedy this sub-sample the graph that reduces compute but introduce additional variance and may offer suboptimal performance. This paper develops the IGLU method that caches intermediate computations at various GCN layers thus enabling lazy updates that significantly reduce the compute cost of descent. IGLU introduces bounded bias into the gradients but nevertheless converges to a first-order saddle point under standard assumptions such as objective smoothness. Benchmark experiments show that IGLU offers up to 1.2% better accuracy despite requiring up to 88% less compute.",
    "One-sentence Summary": "IGLU is a novel lazy update-based optimization technique for accelerated GCN training with provable convergence guarantees"
  },
  {
    "title": "Procedural generalization by planning with self-supervised world models",
    "url": "/forum?id=FmBegXJToY",
    "date": "28 Sept 2021 (modified: 02 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-Supervised Learning, Model-Based RL, Generalization in RL",
    "Abstract": "One of the key promises of model-based reinforcement learning is the ability to generalize using an internal model of the world to make predictions in novel environments and tasks. However, the generalization ability of model-based agents is not well understood because existing work has focused on model-free agents when benchmarking generalization. Here, we explicitly measure the generalization ability of model-based agents in comparison to their model-free counterparts. We focus our analysis on MuZero (Schrittwieser et al., 2020), a powerful model-based agent, and evaluate its performance on both procedural and task generalization. We identify three factors of procedural generalization---planning, self-supervised representation learning, and procedural data diversity---and show that by combining these techniques, we achieve state-of-the art generalization performance and data efficiency on Procgen (Cobbe et al., 2019). However, we find that these factors do not always provide the same benefits for the task generalization benchmarks in Meta-World (Yu et al., 2019), indicating that transfer remains a challenge and may require different approaches than procedural generalization. Overall, we suggest that building generalizable agents requires moving beyond the single-task, model-free paradigm and towards self-supervised model-based agents that are trained in rich, procedural, multi-task environments.",
    "One-sentence Summary": "We study generalization in model-based agents and find that they excel at procedural generalization, with planning, self-supervision and data-diversity combining to yield SoTA results on Procgen; however, task generalization is more challenging."
  },
  {
    "title": "Top-N: Equivariant Set and Graph Generation without Exchangeability",
    "url": "/forum?id=-Gk_IPJWvk",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "set generation, graph generation, permutation equivariance, generative models, Top-N",
    "Abstract": "This work addresses one-shot set and graph generation, and, more specifically, the parametrization of probabilistic decoders that map a vector-shaped prior to a distribution over sets or graphs. Sets and graphs are most commonly generated by first sampling points i.i.d. from a normal distribution, and then processing these points along with the prior vector using Transformer layers or Graph Neural Networks. \n        This architecture is designed to generate exchangeable distributions, i.e., all permutations of the generated outputs are equally likely. We however show that it only optimizes a proxy to the evidence lower bound, which makes it hard to train. We then study equivariance in generative settings and show that non-exchangeable methods can still achieve permutation equivariance. Using this result, we introduce Top-n creation, a differentiable generation mechanism that uses the latent vector to select the most relevant points from a trainable reference set. Top-n can replace i.i.d. generation in any Variational Autoencoder or Generative Adversarial Network. Experimentally, our method outperforms i.i.d. generation by 15% at SetMNIST reconstruction, by 33% at object detection on CLEVR, generates sets that are 74% closer to the true distribution on a synthetic molecule-like dataset, and generates more valid molecules on QM9.",
    "One-sentence Summary": "We propose the Top-N method for one-shot set and graph probabilistic decoders as a replacement for i.i.d. generation in the first layer."
  },
  {
    "title": "The Spectral Bias of Polynomial Neural Networks",
    "url": "/forum?id=P7FLfMLTSEX",
    "date": "28 Sept 2021 (modified: 11 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep Neural Networks, Polynomials, Spectral Bias, Neural Tangent Kernel, Deep Image Prior, Infinite Width, Mercer Decomposition",
    "Abstract": "Polynomial neural networks (PNNs) have been recently shown to be particularly effective at image generation and face recognition, where high-frequency information is critical. Previous studies have revealed that neural networks demonstrate a $\\text{\\it{spectral bias}}$ towards low-frequency functions, which yields faster learning of low-frequency components during training. Inspired by such studies, we conduct a spectral analysis of the Neural Tangent Kernel (NTK) of PNNs. We find that the $\\Pi$-Net family, i.e., a recently proposed parametrization of PNNs, speeds up the learning of the higher frequencies. \n        We verify the theoretical bias through extensive experiments. We expect our analysis to provide novel insights into designing architectures and learning frameworks by incorporating multiplicative interactions via polynomials.",
    "One-sentence Summary": "We study the spectral bias of polynomial networks and compare it with the spectral bias of standard neural nets using kernel approximations"
  },
  {
    "title": "Invariant Causal Representation Learning for Out-of-Distribution Generalization",
    "url": "/forum?id=-e4EXDWXnSn",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Due to spurious correlations, machine learning systems often fail to generalize to environments whose distributions differ from the ones used at training time. Prior work addressing this, either explicitly or implicitly, attempted to find a data representation that has an invariant relationship with the target. This is done by leveraging a diverse set of training environments to reduce the effect of spurious features and build an invariant predictor. However, these methods have generalization guarantees only when both data representation and classifiers come from a linear model class. We propose invariant Causal Representation Learning (iCaRL), an approach that enables out-of-distribution (OOD) generalization in the nonlinear setting (i.e., nonlinear representations and nonlinear classifiers). It builds upon a practical and general assumption: the prior over the data representation (i.e., a set of latent variables encoding the data) given the target and the environment belongs to general exponential family distributions, i.e., a more flexible conditionally non-factorized prior that can actually capture complicated dependences between the latent variables. Based on this, we show that it is possible to identify the data representation up to simple transformations. We also show that all direct causes of the target can be fully discovered, which further enables us to obtain generalization guarantees in the nonlinear setting. Experiments on both synthetic and real-world datasets demonstrate that our approach outperforms a variety of baseline methods."
  },
  {
    "title": "LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5",
    "url": "/forum?id=HCRVf71PMF",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "lifelong few-shot language Learning, prompt tuning, pseudo samples, knowledge distillation",
    "Abstract": "Existing approaches to lifelong language learning rely on plenty of labeled data for learning a new task, which is hard to obtain in most real scenarios. Considering that humans can continually learn new tasks from a handful of examples, we expect the models also to be able to generalize well on new few-shot tasks without forgetting the previous ones. In this work, we define this more challenging yet practical problem as Lifelong Few-shot Language Learning (LFLL) and propose a unified framework for it based on prompt tuning of T5. Our framework called LFPT5 takes full advantage of PT's strong few-shot learning ability, and simultaneously trains the model as a task solver and a data generator. Before learning a new domain of the same task type, LFPT5 generates pseudo (labeled) samples of previously learned domains, and later gets trained on those samples to alleviate forgetting of previous knowledge as it learns the new domain. In addition, a KL divergence loss is minimized to achieve label consistency between the previous and the current model. While adapting to a new task type, LFPT5 includes and tunes additional prompt embeddings for the new task. With extensive experiments, we demonstrate that LFPT5 can be applied to various different types of tasks and significantly outperform previous methods in different LFLL settings.",
    "One-sentence Summary": "We define a challenging yet practical problem as Lifelong Few-shot Language Learning and propose a unified framework for it based on prompt tuning of T5."
  },
  {
    "title": "On Non-Random Missing Labels in Semi-Supervised Learning",
    "url": "/forum?id=6yVvwR9H9Oj",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Semi-Supervised Learning, Missing Not At Random, Image Classification",
    "Abstract": "Semi-Supervised Learning (SSL) is fundamentally a missing label problem, in which the label Missing Not At Random (MNAR) problem is more realistic and challenging, compared to the widely-adopted yet naive Missing Completely At Random assumption where both labeled and unlabeled data share the same class distribution. Different from existing SSL solutions that overlook the role of  ''class'' in causing the non-randomness, e.g., users are more likely to label popular classes, we explicitly incorporate ''class'' into SSL. Our method is three-fold: 1) We propose Class-Aware Propensity (CAP) that exploits the unlabeled data to train an improved classifier using the biased labeled data. 2) To encourage rare class training, whose model is low-recall but high-precision that discards too many pseudo-labeled data, we propose Class-Aware Imputation (CAI) that dynamically decreases (or increases) the pseudo-label assignment threshold for rare (or frequent) classes. 3) Overall, we integrate CAP and CAI into a Class-Aware Doubly Robust (CADR) estimator for training an unbiased SSL model. Under various MNAR settings and ablations, our method not only significantly outperforms existing baselines, but also surpasses other label bias removal SSL methods.",
    "One-sentence Summary": "We presented a principled class-aware doubly robust solution to handle the non-random missing labels in semi-supervised learning."
  },
  {
    "title": "Mapping conditional distributions for domain adaptation under generalized target shift",
    "url": "/forum?id=sPfB2PI87BZ",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Unsupervised domain adaptation, generalized target shift",
    "Abstract": "We consider the problem of unsupervised domain adaptation (UDA) between a source and a target domain under conditional and label shift a.k.a Generalized Target Shift (GeTarS). Unlike simpler UDA settings, few works have addressed this challenging problem. Recent approaches learn domain-invariant representations, yet they have practical limitations and rely on strong assumptions that may not hold in practice. In this paper, we explore a novel and general approach to align pretrained representations, which circumvents existing drawbacks. Instead of constraining representation invariance, it learns an optimal transport map, implemented as a NN, which maps source representations onto target ones. Our approach is flexible and scalable, it preserves the problem's structure and it has strong theoretical guarantees under mild assumptions. In particular, our solution is unique, matches conditional distributions across domains, recovers target proportions and explicitly controls the target generalization risk. Through an exhaustive comparison on several datasets, we challenge the state-of-the-art in GeTarS.",
    "One-sentence Summary": "We propose a novel theoretically grounded approach for domain adaptation under Generalized Target Shift; it learns a map between pretrained source and target representations that matches conditional distributions and recovers target proportions."
  },
  {
    "title": "On the Generalization of Models Trained with SGD: Information-Theoretic Bounds and Implications",
    "url": "/forum?id=oWZsQ8o5EA",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep learning, generalization, information theory, learning bound, regularization",
    "Abstract": "This paper follows up on a recent work of Neu et al. (2021) and presents some new information-theoretic upper bounds for the generalization error of machine learning models, such as neural networks, trained with SGD. We apply these bounds to analyzing the generalization behaviour of linear and two-layer ReLU networks. Experimental study of these bounds provide some insights on the SGD training of neural networks. They also point to a new and simple regularization scheme which we show performs comparably to the current state of the art.",
    "One-sentence Summary": "We derived new information-theoretic generalization bounds for SGD and we also proposed a new regularization scheme."
  },
  {
    "title": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
    "url": "/forum?id=3PN4iyXBeF",
    "date": "28 Sept 2021 (modified: 18 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "bilevel optimization, stochastic optimization",
    "Abstract": "We study a class of algorithms for solving bilevel optimization problems in both stochastic and deterministic settings when the inner-level objective is strongly convex. Specifically, we consider  algorithms based on inexact implicit differentiation and we exploit a warm-start strategy to amortize the estimation of the exact gradient. We then introduce a unified theoretical framework inspired by the study of singularly perturbed systems to analyze such amortized algorithms. By using this framework, our analysis shows these algorithms to match the computational complexity of oracle methods that have access to an unbiased estimate of the gradient, thus outperforming many existing results for bilevel optimization.\n        We illustrate these findings on synthetic experiments and demonstrate the efficiency of these algorithms on hyper-parameter optimization experiments involving several thousands of variables.",
    "One-sentence Summary": "We provide a unified framework for analyzing bilevel optimization algorithm based on approximate implicit differentiation with a warm-start strategy"
  },
  {
    "title": "Multi-objective Optimization by Learning Space Partition",
    "url": "/forum?id=FlwzVjfMryn",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Optimization, Machine Learning",
    "Abstract": "In contrast to single-objective optimization (SOO), multi-objective optimization (MOO) requires an optimizer to find the Pareto frontier, a subset of feasible solutions that are not dominated by other feasible solutions. In this paper, we propose LaMOO, a novel multi-objective optimizer that learns a model from observed samples to partition the search space and then focus on promising regions that are likely to contain a subset of the Pareto frontier. The partitioning is based on the dominance number, which measures \"how close'' a data point is to the Pareto frontier among existing samples. To account for possible partition errors due to limited samples and model mismatch, we leverage Monte Carlo Tree Search (MCTS) to exploit promising regions while exploring suboptimal regions that may turn out to contain good solutions later. Theoretically, we prove the efficacy of learning space partitioning via LaMOO under certain assumptions. Empirically, on the HyperVolume (HV) benchmark, a popular MOO metric, LaMOO substantially outperforms strong baselines on multiple real-world MOO tasks, by up to 225% in sample efficiency for neural architecture search on Nasbench201, and up to 10% for molecular design.",
    "One-sentence Summary": "Multi-objective Optimization by Learning Space Partition"
  },
  {
    "title": "Mapping Language Models to Grounded Conceptual Spaces",
    "url": "/forum?id=gJcEM8sxHK",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "A fundamental criticism of text-only language models (LMs) is their lack of grounding---that is, the ability to tie a word for which they have learned a representation, to its actual use in the world. However, despite this limitation, large pre-trained LMs have been shown to have a remarkable grasp of the conceptual structure of language, as demonstrated by their ability to answer questions, generate fluent text, or make inferences about entities, objects, and properties that they have never physically observed. In this work we investigate the extent to which the rich conceptual structure that LMs learn indeed reflects the conceptual structure of the non-linguistic world---which is something that LMs have never observed. We do this by testing whether the LMs can learn to map an entire conceptual domain (e.g., direction or colour) onto a grounded world representation given only a small number of examples. For example, we show a model what the word ``left\" means using a textual depiction of a grid world, and assess how well it can generalise to related concepts, for example, the word ``right\", in a similar grid world. We investigate a range of generative language models of varying sizes (including GPT-2 and GPT-3), and see that although the smaller models struggle to perform this mapping, the largest model can not only learn to ground the concepts that it is explicitly taught, but appears to generalise to several instances of unseen concepts as well. Our results suggest an alternative means of building grounded language models: rather than learning grounded representations ``from scratch'', it is possible that large text-only models learn a sufficiently rich conceptual structure that could allow them to be grounded in a data-efficient way.",
    "One-sentence Summary": "Mapping text-only pre-trained language models to grounded conceptual worlds."
  },
  {
    "title": "The Efficiency Misnomer",
    "url": "/forum?id=iulEMLYh1uR",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Efficiency in Machine Learning, FLOPs, Number of Parameters, Throughput",
    "Abstract": "Model efficiency is a critical aspect of developing and deploying machine learning models. \n        Inference time and latency directly affect the user experience, and some applications have hard requirements. In addition to inference costs, model training also have direct financial and environmental impacts.\n        Although there are numerous well-established metrics (cost indicators) for measuring model efficiency, researchers and practitioners often assume that these metrics are correlated with each other and report only a few of them.\n        In this paper, we thoroughly discuss common cost indicators, their advantages and disadvantages, and how they can contradict each other.\n        We demonstrate how incomplete reporting of cost indicators can lead to partial conclusions and a blurred or incomplete picture of the practical considerations of different models. We further present suggestions to improve reporting of efficiency metrics."
  },
  {
    "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface",
    "url": "/forum?id=auOPcdAcoy",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "wake-sleep, variational inference, neuro-symbolic generative models",
    "Abstract": "Modeling complex phenomena typically involves the use of both discrete and continuous variables. Such a setting applies across a wide range of problems, from identifying trends in time-series data to performing effective compositional scene understanding in images. Here, we propose Hybrid Memoised Wake-Sleep (HMWS), an algorithm for effective inference in such hybrid discrete-continuous models. Prior approaches to learning suffer as they need to perform repeated expensive inner-loop discrete inference. We build on a recent approach, Memoised Wake-Sleep (MWS), which alleviates part of the problem by memoising discrete variables, and extend it to allow for a principled and effective way to handle continuous variables by learning a separate recognition model used for importance-sampling based approximate inference and marginalization. We evaluate HMWS in the GP-kernel learning and 3D scene understanding domains, and show that it outperforms current state-of-the-art inference methods."
  },
  {
    "title": "Adversarial Retriever-Ranker for Dense Text Retrieval",
    "url": "/forum?id=MR7XubKUFB",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Current dense text retrieval models face two typical challenges. First, it adopts a siamese dual-encoder architecture to encode query and document independently for fast indexing and searching, whereas neglecting the finer-grained term-wise interactions. This results in a sub-optimal recall performance. Second, it highly relies on a negative sampling technique to build up the negative documents in its contrastive loss. To address these challenges, we present Adversarial Retriever-Ranker (AR2), which consists of a dual-encoder retriever plus a cross-encoder ranker. The two models are jointly optimized according to a minimax adversarial objective: the retriever learns to retrieve negative documents to cheat the ranker, while the ranker learns to rank a collection of candidates including both the ground-truth and the retrieved ones, as well as providing progressive direct feedback to the dual-encoder retriever. Through this adversarial game, the retriever gradually produces harder negative documents to train a better ranker, whereas the cross-encoder ranker provides progressive feedback to improve retriever. We evaluate AR2 on three benchmarks. Experimental results show that AR2 consistently and significantly outperforms existing dense retriever methods and achieves new state-of-the-art results on all of them. This includes the improvements on Natural Questions R@5 to 77.9%(+2.1%), TriviaQA R@5 to 78.2%(+1.4), and MS-MARCO MRR@10 to 39.5%(+1.3%). We will make our code, models, and data publicly available."
  },
  {
    "title": "Conditioning Sequence-to-sequence Networks with Learned Activations",
    "url": "/forum?id=t5s-hd1bqLk",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Conditional Neural Networks, Sound Enhancement, Personalized ASR",
    "Abstract": "Conditional neural networks play an important role in a number of sequence-to-sequence modeling tasks, including personalized sound enhancement (PSE), speaker dependent automatic speech recognition (ASR), and generative modeling such as text-to-speech synthesis. In conditional neural networks, the output of a model is often influenced by a conditioning vector, in addition to the input. Common approaches of conditioning include input concatenation or modulation with the conditioning vector, which comes at a cost of increased model size. In this work, we introduce a novel approach of neural network conditioning by learning intermediate layer activations based on the conditioning vector. We systematically explore and show that learned activation functions can produce conditional models with comparable or better quality, while decreasing model sizes, thus making them ideal candidates for resource-efficient on-device deployment. As exemplary target use-cases we consider (i) the task of PSE as a pre-processing technique for improving telephony or pre-trained ASR performance under noise, and (ii) personalized ASR in single speaker scenarios. We find that conditioning via activation function learning is an effective modeling strategy, suggesting a broad applicability of the proposed technique across a number of application domains.",
    "One-sentence Summary": "Conditioning neural networks by learning the layer activations based on the conditioning vector"
  },
  {
    "title": "LOSSY COMPRESSION WITH DISTRIBUTION SHIFT AS ENTROPY CONSTRAINED OPTIMAL TRANSPORT",
    "url": "/forum?id=BRFWxcZfAdC",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Image Compression, Image Restoration, Optimal Transport, Deep Learning",
    "Abstract": "We study an extension of lossy compression where the reconstruction distribution is different from the source distribution in order to account for distributional shift due to processing. We formulate this as a generalization of optimal transport with an entropy bottleneck to account for the rate constraint due to compression. We provide expressions for the tradeoff between  compression rate and the achievable distortion with and without shared common randomness between the encoder and decoder.  We study the examples of binary, uniform and Gaussian sources (in an asymptotic setting) in detail and  demonstrate that shared randomness can strictly improve the tradeoff. For the case without common randomness and squared-Euclidean distortion, we show that the optimal solution partially decouples into the problem of optimal compression and transport and also characterize the penalty associated with fully decoupling them. We provide experimental results by training deep learning end-to-end compression systems for performing denoising on SVHN and super-resolution on MNIST suggesting consistency with our theoretical results.",
    "One-sentence Summary": "We consider the novel task of cross-distribution lossy compression and characterize it as an optimal transport problem under an entropy constraint, then provide experimental results to demonstrate the principles suggested by our theory."
  },
  {
    "title": "Equivariant Self-Supervised Learning: Encouraging Equivariance in Representations",
    "url": "/forum?id=gKLAAfiytI",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self-supervised learning, contrastive learning, photonics science",
    "Abstract": "In state-of-the-art self-supervised learning (SSL) pre-training produces semantically good representations by encouraging them to be invariant under meaningful transformations prescribed from human knowledge. In fact, the property of invariance is a trivial instance of a broader class called equivariance, which can be intuitively understood as the property that representations transform according to the way the inputs transform. Here, we show that rather than using only invariance, pre-training that encourages non-trivial equivariance to some transformations, while maintaining invariance to other transformations, can be used to improve the semantic quality of representations. Specifically, we extend popular SSL methods to a more general framework which we name Equivariant Self-Supervised Learning (E-SSL). In E-SSL, a simple additional pre-training objective encourages equivariance by predicting the transformations applied to the input. We demonstrate E-SSL\u2019s effectiveness empirically on several popular computer vision benchmarks, e.g. improving SimCLR to 72.5% linear probe accuracy on ImageNet. Furthermore, we demonstrate usefulness of E-SSL for applications beyond computer vision; in particular, we show its utility on regression problems in photonics science. Our code, datasets and pre-trained models are available at https://github.com/rdangovs/essl to aid further research in E-SSL.",
    "One-sentence Summary": "Imposing invariance to certain transformations (e.g. random resized cropping) and sensitivity to other transformations (e.g. four-fold rotations) learns better features."
  },
  {
    "title": "Direct then Diffuse: Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching",
    "url": "/forum?id=25kzAhUB1lz",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "unsupervised reinforcement learning, skill discovery, mutual information",
    "Abstract": "Learning meaningful behaviors in the absence of reward is a difficult problem in reinforcement learning. A desirable and challenging unsupervised objective is to learn a set of diverse skills that provide a thorough coverage of the state space while being directed, i.e., reliably reaching distinct regions of the environment. In this paper, we build on the mutual information framework for skill discovery and introduce UPSIDE, which addresses the coverage-directedness trade-off in the following ways: 1) We design policies with a decoupled structure of a directed skill, trained to reach a specific region, followed by a diffusing part that induces a local coverage. 2) We optimize policies by  maximizing their number under the constraint that each of them reaches distinct regions of the environment (i.e., they are sufficiently discriminable) and prove that this serves as a lower bound to the original mutual information objective. 3) Finally, we compose the learned directed skills into a growing tree that adaptively covers the environment. We illustrate in several navigation and control environments how the skills learned by UPSIDE solve sparse-reward downstream tasks better than existing baselines."
  },
  {
    "title": "Normalization of Language Embeddings for Cross-Lingual Alignment",
    "url": "/forum?id=Nh7CtbyoqV5",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "cross-lingual word embeddings, natural language processing",
    "Abstract": "Learning a good transfer function to map the word vectors from two languages into a shared cross-lingual word vector space plays a crucial role in cross-lingual NLP. It is useful in translation tasks and important in allowing complex models built on a high-resource language like English to be directly applied on an aligned low resource language.  While Procrustes and other techniques can align language models with some success, it has recently been identified that structural differences (for instance, due to differing word frequency) create different profiles for various monolingual embedding. When these profiles differ across languages, it correlates with how well languages can align and their performance on cross-lingual downstream tasks.  In this work, we develop a very general language embedding normalization procedure, building and subsuming various previous approaches, which removes these structural profiles across languages without destroying their intrinsic meaning.  We demonstrate that meaning is retained and alignment is improved on similarity, translation, and cross-language classification tasks.  Our proposed normalization clearly outperforms all prior approaches like centering and vector normalization on each task and with each alignment approach.",
    "One-sentence Summary": "Our embedding normalization subsumes existing approaches and consistently improves cross-lingual alignment."
  },
  {
    "title": "Boosting the Certified Robustness of L-infinity Distance Nets",
    "url": "/forum?id=Q76Y7wkiji",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial Robustness, Certified Defense, Lipschitz Network",
    "Abstract": "Recently, Zhang et al. (2021) developed a new neural network architecture based on $\\ell_\\infty$-distance functions, which naturally possesses certified $\\ell_\\infty$ robustness by its construction. Despite the novel design and theoretical foundation, so far the model only achieved comparable performance to conventional networks. In this paper, we make the following two contributions: $\\mathrm{(i)}$ We demonstrate that $\\ell_\\infty$-distance nets enjoy a fundamental advantage in certified robustness over conventional networks (under typical certification approaches); $\\mathrm{(ii)}$ With an improved training process we are able to significantly boost the certified accuracy of $\\ell_\\infty$-distance nets. Our training approach largely alleviates the optimization problem that arose in the previous training scheme, in particular, the unexpected large Lipschitz constant due to the use of a crucial trick called \\textit{$\\ell_p$-relaxation}. The core of our training approach is a novel objective function that combines scaled cross-entropy loss and clipped hinge loss with a decaying mixing coefficient. Experiments show that using the proposed training strategy, the certified accuracy of $\\ell_\\infty$-distance net can be dramatically improved from 33.30% to 40.06% on CIFAR-10 ($\\epsilon=8/255$), meanwhile outperforming other approaches in this area by a large margin. Our results clearly demonstrate the effectiveness and potential of $\\ell_\\infty$-distance net for certified robustness. Codes are available at https://github.com/zbh2047/L_inf-dist-net-v2.",
    "One-sentence Summary": "We design a new training strategy that significantly boosts the performance of $\\ell_\\infty$-distance nets and establishes new state-of-the-art certified robustness."
  },
  {
    "title": "Stochastic Training is Not Necessary for Generalization",
    "url": "/forum?id=ZBESeIUB5k",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Optimization, Generalization, Stochasticity, SGD, full-batch, implicit regularization, implicit bias",
    "Abstract": "It is widely believed that the implicit regularization of SGD is fundamental to the impressive generalization behavior we observe in neural networks.  In this work, we demonstrate that non-stochastic full-batch training can achieve comparably strong performance to SGD on CIFAR-10 using modern architectures. To this end, we show that the implicit regularization of SGD can be completely replaced with explicit regularization. Our observations indicate that the perceived difficulty of full-batch training may be the result of its optimization properties and the disproportionate time and effort spent by the ML community tuning optimizers and hyperparameters for small-batch training.",
    "One-sentence Summary": "Models trained with full-batch gradient descent and explicit regularization can match the generalization performance of models trained with stochastic minibatching."
  },
  {
    "title": "Transfer RL across Observation Feature Spaces via Model-Based Regularization",
    "url": "/forum?id=7KdAoOsI81C",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "transfer reinforcement learning, representation learning, observation space change, latent dynamics model",
    "Abstract": "In many reinforcement learning (RL) applications, the observation space is specified by human developers and restricted by physical realizations, and may thus be subject to dramatic changes over time (e.g. increased number of observable features). However, when the observation space changes, the previous policy will likely fail due to the mismatch of input features, and another policy must be trained from scratch, which is inefficient in terms of computation and sample complexity. Following theoretical insights, we propose a novel algorithm which extracts the latent-space dynamics in the source task, and transfers the dynamics model to the target task to use as a model-based regularizer. Our algorithm works for drastic changes of observation space (e.g. from vector-based observation to image-based observation), without any inter-task mapping or any prior knowledge of the target task. Empirical results show that our algorithm significantly improves the efficiency and stability of learning in the target task.",
    "One-sentence Summary": "We propose a model-based transfer learning algorithm that transfers knowledge across tasks with drastically different observation spaces, without any prior knowledge of the inter-task mapping."
  },
  {
    "title": "GATSBI: Generative Adversarial Training for Simulation-Based Inference",
    "url": "/forum?id=kR1hC6j48Tp",
    "date": "28 Sept 2021 (modified: 15 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Machine Learning, simulation-based inference, generative adversarial networks, approximate bayesian computation, data-driven modelling, GANs, SBI, likelihood-free inference, implicit models",
    "Abstract": "Simulation-based inference (SBI) refers to statistical inference on stochastic models for which we can generate samples, but not compute likelihoods.\n        Like SBI algorithms, generative adversarial networks (GANs) do not require explicit likelihoods. We study the relationship between SBI and GANs, and introduce GATSBI, an adversarial approach to SBI. GATSBI reformulates the variational objective in an adversarial setting to learn implicit posterior distributions. Inference with GATSBI is amortised across observations, works in high-dimensional posterior spaces and supports implicit priors. We evaluate GATSBI on two common SBI benchmark problems and on two high-dimensional simulators. On a model for wave propagation on the surface of a shallow water body, we show that GATSBI can return well-calibrated posterior estimates even in high dimensions. \n        On a model of camera optics, it infers a high-dimensional posterior given an implicit prior, and performs better than a\n        state-of-the-art SBI approach. We also show how GATSBI can be extended to perform sequential posterior estimation to focus on individual observations.\n        Overall, GATSBI opens up opportunities for leveraging advances in GANs to perform Bayesian inference on high-dimensional simulation-based models.",
    "One-sentence Summary": "Using generative adversarial networks for simulation-based inference"
  },
  {
    "title": "Domain Adversarial Training: A Game Perspective",
    "url": "/forum?id=AwgtcUAhBq",
    "date": "28 Sept 2021 (modified: 09 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Domain Adversarial Training, Domain Adaptation, Neural Networks Optimization, Game Theory",
    "Abstract": "The dominant line of work in domain adaptation has focused on learning invariant representations using domain-adversarial training. In this paper, we interpret this approach from a game theoretical perspective. Defining optimal solutions in domain-adversarial training as a local Nash equilibrium, we show that gradient descent in domain-adversarial training can violate the asymptotic convergence guarantees of the optimizer, oftentimes hindering the transfer performance. Our analysis leads us to replace gradient descent with high-order ODE solvers (i.e., Runge\u2013Kutta), for which we derive asymptotic convergence guarantees. This family of optimizers is significantly more stable and allows more aggressive learning rates, leading to high performance gains when used as a drop-in replacement over standard optimizers. Our experiments show that in conjunction with state-of-the-art domain-adversarial methods, we achieve up to 3.5% improvement with less than of half training iterations. Our optimizers are easy to implement, free of additional parameters, and can be plugged into any domain-adversarial framework.",
    "One-sentence Summary": "A novel perspective on domain-adversarial training that leads to more stable and performant optimizers."
  },
  {
    "title": "Differentiable Expectation-Maximization for Set Representation Learning",
    "url": "/forum?id=MXdFBmHT4C",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Representation learning, Bayesian models, Mixture estimation, Optimal transport, Attention",
    "Abstract": "We tackle the set2vec problem, the task of extracting a vector representation from an input set comprised of a variable number of feature vectors. Although recent approaches based on self attention such as (Set)Transformers were very successful due to the capability of capturing complex interaction between set elements, the  computational overhead is the well-known downside. The inducing-point attention and the latest optimal transport kernel embedding (OTKE) are promising remedies that attain comparable or better performance with reduced computational cost, by incorporating a fixed number of learnable queries in attention. In this paper we approach the set2vec problem from a completely different perspective. The elements of an input set are considered as i.i.d.~samples from a mixture distribution, and we define our set embedding feed-forward network as the  maximum-a-posterior (MAP) estimate of the mixture which is approximately attained by a few Expectation-Maximization (EM) steps. The whole MAP-EM steps are differentiable operations with a fixed number of mixture parameters, allowing efficient auto-diff back-propagation for any given downstream task. Furthermore, the proposed mixture set data fitting framework allows unsupervised set representation learning naturally via marginal likelihood maximization aka the empirical Bayes. Interestingly, we also find that OTKE can be seen as a special case of our framework, specifically a single-step EM with extra balanced assignment constraints on the E-step. Compared to OTKE, our approach provides more flexible set embedding as well as prior-induced model regularization. We evaluate our approach on various tasks demonstrating improved performance over the state-of-the-arts.",
    "One-sentence Summary": "We propose a novel set embedding function, a feed-forward network defined as the (differentiable) maximum-a-posterior estimate of the mixture, approximately attained by a few Expectation-Maximization steps."
  },
  {
    "title": "Overcoming The Spectral Bias of Neural Value Approximation",
    "url": "/forum?id=vIC-xLFuM6",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "spectral bias, neural value approximation, Q learning, reinforcement learning, neural tangent kernels, kernel regression",
    "Abstract": "Value approximation using deep neural networks is at the heart of off-policy deep reinforcement learning, and is often the primary module that provides learning signals to the rest of the algorithm.  While multi-layer perceptron networks are universal function approximators, recent works in neural kernel regression suggest the presence of a \\textit{spectral bias}, where fitting high-frequency components of the value function requires exponentially more gradient update steps than the low-frequency ones. In this work, we re-examine off-policy reinforcement learning through the lens of kernel regression and propose to overcome such bias via a composite neural tangent kernel. With just a single line-change, our approach, the Fourier feature networks (FFN) produce state-of-the-art performance on challenging continuous control domains with only a fraction of the compute. Faster convergence and better off-policy stability also make it possible to remove the target network without suffering catastrophic divergences, which further reduces TD(0)'s estimation bias on a few tasks. Code and analysis available at https://geyang.github.io/ffn.",
    "One-sentence Summary": "Overcoming the spectral bias of neural value approximation via fourier features"
  },
  {
    "title": "Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients",
    "url": "/forum?id=AIgn9uwfcD1",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "pruning, lottery ticket hypothesis, pruning at initialization",
    "Abstract": "Pruning neural networks at initialization would enable us to find sparse models that retain the accuracy of the original network while consuming fewer computational resources for training and inference. However, current methods are insufficient to enable this optimization and lead to a large degradation in model performance. In this paper, we identify a fundamental limitation in the formulation of current methods, namely that their saliency criteria look at a single step at the start of training without taking into account the trainability of the network. While pruning iteratively and gradually has been shown to improve pruning performance, explicit consideration of the training stage that will immediately follow pruning has so far been absent from the computation of the saliency criterion. To overcome the short-sightedness of existing methods, we propose Prospect Pruning (ProsPr), which uses meta-gradients through the first few steps of optimization to determine which weights to prune. ProsPr combines an estimate of the higher-order effects of pruning on the loss and the optimization trajectory to identify the trainable sub-network. Our method achieves state-of-the-art pruning performance on a variety of vision classification tasks, with less data and in a single shot compared to existing pruning-at-initialization methods.",
    "One-sentence Summary": "We use meta-gradients to prune neural networks at initialization based on \"trainability\" of weights instead of their impact on the loss at a single step."
  },
  {
    "title": "CoMPS: Continual Meta Policy Search",
    "url": "/forum?id=PVJ6j87gOHz",
    "date": "28 Sept 2021 (modified: 22 Nov 2021)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning",
    "Abstract": "We develop a new continual meta-learning method to address challenges in sequential multi-task learning. In this setting, the agent's goal is to achieve high reward over any sequence of tasks quickly. Prior meta-reinforcement learning algorithms have demonstrated promising results in accelerating the acquisition of new tasks. However, they require access to all tasks during training. Beyond simply transferring past experience to new tasks, our goal is to devise continual reinforcement learning algorithms that learn to learn, using their experience on previous tasks to learn new tasks more quickly. We introduce a new method, continual meta-policy search (CoMPS), that removes this limitation by meta-training in an incremental fashion, over each task in a sequence, without revisiting prior tasks. CoMPS continuously repeats two subroutines: learning a new task using RL and using the experience from RL to perform completely offline meta-learning to prepare for subsequent task learning. We find that CoMPS outperforms prior continual learning and off-policy meta-reinforcement methods on several sequences of challenging continuous control tasks.",
    "One-sentence Summary": "Cotinual meta-reinforcement learning accelerates task learning, via repeated meta off-policy search."
  },
  {
    "title": "Generalized rectifier wavelet covariance models for texture synthesis",
    "url": "/forum?id=ziRLU3Y2PN_",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "texture synthesis, generative models, wavelets",
    "Abstract": "State-of-the-art maximum entropy models for texture synthesis are built from statistics relying on image representations defined by convolutional neural networks (CNN). Such representations capture rich structures in texture images, outperforming wavelet-based representations in this regard. However, conversely to neural networks, wavelets offer meaningful representations, as they are known to detect structures at multiple scales (e.g. edges) in images. In this work, we propose a family of statistics built upon non-linear wavelet based representations, that can be viewed as a particular instance of a one-layer CNN, using a generalized rectifier non-linearity. These statistics significantly improve the visual quality of previous classical wavelet-based models, and allow one to produce syntheses of similar quality to state-of-the-art models, on both gray-scale and color textures. We further provide insights on memorization effects in these models.",
    "One-sentence Summary": "This paper presents a model for texture synthesis, built on a wavelet-based representation of images."
  },
  {
    "title": "Towards Evaluating the Robustness of Neural Networks Learned by Transduction",
    "url": "/forum?id=_5js_8uTrx1",
    "date": "28 Sept 2021 (modified: 27 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "adversarial robustness, transductive learning, test-time defense, dynamic defense, attacking model spaces",
    "Abstract": "There has been emerging interest in using transductive learning for adversarial robustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020; Wang et al., ArXiv 2021). Compared to traditional defenses, these defense mechanisms \"dynamically learn\" the model based on test-time input; and theoretically, attacking these defenses reduces to solving a bilevel optimization problem, which poses difficulty in crafting adaptive attacks. In this paper, we examine these defense mechanisms from a principled threat analysis perspective. We formulate and analyze threat models for transductive-learning based defenses, and point out important subtleties. We propose the principle of attacking model space for solving bilevel attack objectives, and present Greedy Model Space Attack (GMSA), an attack framework that can serve as a new baseline for evaluating transductive-learning based defenses. Through systematic evaluation, we show that GMSA, even with weak instantiations, can break previous transductive-learning based defenses, which were resilient to previous attacks, such as AutoAttack (Croce and Hein, ICML 2020). On the positive side, we report a somewhat surprising empirical result of \"transductive adversarial training\": Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks we consider.",
    "One-sentence Summary": "Exploring evaluating the adversarial robustness of transductive-learning based defenses."
  },
  {
    "title": "OBJECT DYNAMICS DISTILLATION FOR SCENE DECOMPOSITION AND REPRESENTATION",
    "url": "/forum?id=oJGDYQFKL3i",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "The ability to perceive scenes in terms of abstract entities is crucial for us to\n        achieve higher-level intelligence. Recently, several methods have been proposed\n        to learn object-centric representations of scenes with multiple objects, yet most\n        of which focus on static scenes. In this paper, we work on object dynamics and\n        propose Object Dynamics Distillation Network (ODDN), a framework that distillates explicit object dynamics (e.g., velocity) from sequential static representations. ODDN also builds a relation module to model object interactions. We verify\n        our approach on tasks of video reasoning and video prediction, which are two important evaluations for video understanding. The results show that the reasoning\n        model with visual representations of ODDN performs better in answering reasoning questions around physical events in a video compared to the previous state-of-the-art methods. The distilled object dynamics also could be used to predict\n        future video frames given two input frames, involving occlusion and objects collision. In addition, our architecture brings better segmentation quality and higher\n        reconstruction accuracy."
  },
  {
    "title": "Practical Integration via Separable Bijective Networks",
    "url": "/forum?id=NlObxR0rosG",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "integration, flow, likelihood, classification, regression, out of distribution, regularization",
    "Abstract": "Neural networks have enabled learning over examples that contain thousands of dimensions.\n        However, most of these models are limited to training and evaluating on a finite collection of \\textit{points} and do not consider the hypervolume in which the data resides.\n        Any analysis of the model's local or global behavior is therefore limited to very expensive or imprecise estimators.\n        We propose to formulate neural networks as a composition of a bijective (flow) network followed by a learnable, separable network.\n        This construction allows for learning (or assessing) over full hypervolumes with precise estimators at tractable computational cost via integration over the \\textit{input space}.\n        We develop the necessary machinery, propose several practical integrals to use during training, and demonstrate their utility.",
    "One-sentence Summary": "We explore a method that enables learning over hypervolumes within the data space."
  },
  {
    "title": "Self-Joint Supervised Learning",
    "url": "/forum?id=zuqcmNVK4c2",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Supervised learning is a fundamental framework used to train machine learning systems. A supervised learning problem is often formulated using an i.i.d. assumption that restricts model attention to a single relevant signal at a time when predicting. This contrasts with the human ability to actively use related samples as reference when making decisions. We hypothesize that the restriction to a single signal for each prediction in the standard i.i.d. framework contributes to well-known drawbacks of supervised learning: making overconfident predictions and vulnerability to overfitting, adversarial attacks, and out-of-distribution data. To address these limitations, we propose a new supervised learning paradigm called self-joint learning that generalizes the standard approach by modeling the joint conditional distribution of two observed samples, where each sample is an image and its label. Rather than assuming samples are independent, our models explicitly learn the sample-to-sample relation of conditional independence. Our framework can naturally incorporate auxiliary unlabeled data to further improve the performance. Experiments on benchmark image datasets show our method offers significant improvement over standard supervised learning in terms of accuracy, robustness against adversarial attacks, out-of-distribution detection, and overconfidence mitigation."
  },
  {
    "title": "Rethinking Supervised Pre-Training for Better Downstream Transferring",
    "url": "/forum?id=Jjcv9MTqhcq",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Pre-Training, Contrastive Learning, Representation Learning, Downstream Transferring",
    "Abstract": "The pretrain-finetune paradigm has shown outstanding performance on many applications of deep learning, where a model is pre-trained on an upstream large dataset (e.g. ImageNet), and is then fine-tuned to different downstream tasks. Though for most cases, the pre-training stage is conducted based on supervised methods, recent works on self-supervised pre-training have shown powerful transferability and even outperform supervised pre-training on multiple downstream tasks. It thus remains an open question how to better generalize supervised pre- training model to downstream tasks. In this paper, we argue that the worse transferability of existing supervised pre-training methods arise from the negligence of valuable intra-class semantic difference. This is because these methods tend to push images from the same class close to each other despite of the large diversity in their visual contents, a problem to which referred as \u201coverfit of upstream tasks\u201d. To alleviate this problem, we propose a new supervised pre-training method based on Leave-One-Out K-Nearest-Neighbor, or LOOK for short. It relieves the problem of overfitting upstream tasks by only requiring each image to share its class label with most of its k nearest neighbors, thus allowing each class to exhibit a multi-mode distribution and consequentially preserving part of intra-class difference for better transferring to downstream tasks. We developed efficient implementation of the proposed method that scales well to large datasets. Experimental studies on multiple downstream tasks show that LOOK outperforms other state-of-the-art methods for supervised and self-supervised pre-training.",
    "One-sentence Summary": "We propose a new supervised pre-training method based on Leave-One-Out K-Nearest-Neighbor, which relieves the problem of overfitting upstream tasks  and preserving part of intra-class difference for better transferring to downstream tasks."
  },
  {
    "title": "A Zest of LIME: Towards Architecture-Independent Model Distances",
    "url": "/forum?id=OUz_9TiTv9j",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "model distance, model stealing, machine unlearning, fairwashing",
    "Abstract": "Definitions of the distance between two machine learning models either characterize the similarity of the models' predictions or of their weights. While similarity of weights is attractive because it implies similarity of predictions in the limit, it suffers from being inapplicable to comparing models with different architectures. On the other hand, the similarity of predictions is broadly applicable but depends heavily on the choice of model inputs during comparison. In this paper, we instead propose to compute distance between black-box models by comparing their Local Interpretable Model-Agnostic Explanations (LIME). To compare two models, we take a reference dataset, and locally approximate the models on each reference point with linear models trained by LIME. We then compute the cosine distance between the concatenated weights of the linear models. This yields an approach that is both architecture-independent and possesses the benefits of comparing models in weight space. We empirically show that our method, which we call Zest, can be applied to two problems that require measurements of model similarity: detecting model stealing and machine unlearning.",
    "One-sentence Summary": "We propose an architecture-independent distance metric that measures the similarity between ML models by comparing their global behaviors, approximated using LIME."
  },
  {
    "title": "Meta-Imitation Learning by Watching Video Demonstrations",
    "url": "/forum?id=KTPuIsx4pmo",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Meta-imitation Learning, One-shot Learning, Learning by Watching, Generative Adversarial Networks",
    "Abstract": "Meta-Imitation Learning is a promising technique for the robot to learn a new task from observing one or a few human demonstrations. However, it usually requires a significant number of demonstrations both from humans and robots during the meta-training phase, which is a laborious and hard work for data collection, especially in recording the actions and specifying the correspondence between human and robot. In this work, we present an approach of meta-imitation learning by watching video demonstrations from humans. In comparison to prior works, our approach is able to translate human videos into practical robot demonstrations and train the meta-policy with adaptive loss based on the quality of the translated data. Our approach relies only on human videos and does not require robot demonstration, which facilitates data collection and is more in line with human imitation behavior. Experiments reveal that our method achieves the comparable performance to the baseline on fast learning a set of vision-based tasks through watching a single video demonstration.",
    "One-sentence Summary": "We present an approach of meta-imitation learning by watching video demonstrations from humans."
  },
  {
    "title": "Understanding Intrinsic Robustness Using Label Uncertainty",
    "url": "/forum?id=6ET9SzlgNX",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Concentration of Measure, Intrinsic Adversarial Robustness, Label Uncertainty",
    "Abstract": "A fundamental question in adversarial machine learning is whether a robust classifier exists for a given task. A line of research has made some progress towards this goal by studying the concentration of measure, but we argue standard concentration fails to fully characterize the intrinsic robustness of a classification problem since it ignores data labels which are essential to any classification task. Building on a novel definition of label uncertainty, we empirically demonstrate that error regions induced by state-of-the-art models tend to have much higher label uncertainty than randomly-selected subsets. This observation motivates us to adapt a concentration estimation algorithm to account for label uncertainty, resulting in more accurate intrinsic robustness measures for benchmark image classification problems."
  },
  {
    "title": "Efficient Split-Mix Federated Learning for On-Demand and In-Situ Customization",
    "url": "/forum?id=_QLmakITKg",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "federated learning",
    "Abstract": "Federated learning (FL) provides a distributed learning framework for multiple participants to collaborate learning without sharing raw data. In many practical FL scenarios, participants have heterogeneous resources due to disparities in hardware and inference dynamics that require quickly loading models of different sizes and levels of robustness. The heterogeneity and dynamics together impose significant challenges to existing FL approaches and thus greatly limit FL's applicability. In this paper, we propose a novel Split-Mix FL strategy for heterogeneous participants that, once training is done, provides in-situ customization of model sizes and robustness. Specifically, we achieve customization by learning a set of base sub-networks of different sizes and robustness levels, which are later aggregated on-demand according to inference requirements. This split-mix strategy achieves customization with high efficiency in communication, storage, and inference. Extensive experiments demonstrate that our method provides better in-situ customization than the existing heterogeneous-architecture FL methods. Codes and pre-trained models are available: https://github.com/illidanlab/SplitMix."
  },
  {
    "title": "Anti-Concentrated Confidence Bonuses For Scalable Exploration",
    "url": "/forum?id=RXQ-FPbQYVn",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep reinforcement learning, reinforcement learning, bandits, exploration",
    "Abstract": "Intrinsic rewards play a central role in handling the exploration-exploitation tradeoff when designing sequential decision-making algorithms, in both foundational theory and state-of-the-art deep reinforcement learning. The LinUCB algorithm, a centerpiece of the stochastic linear bandits literature, prescribes an elliptical bonus which addresses the challenge of leveraging shared information in large action spaces. This bonus scheme cannot be directly transferred to high-dimensional exploration problems, however, due to the computational cost of maintaining the inverse covariance matrix of action features. We introduce anti-concentrated confidence bounds for efficiently approximating the elliptical bonus, using an ensemble of regressors trained to predict random noise from policy network-derived features. Using this approximation, we obtain stochastic linear bandit algorithms which obtain $\\tilde O(d \\sqrt{T})$ regret bounds for $\\mathsf{poly}(d)$ fixed actions. We develop a practical variant that is competitive with contemporary intrinsic reward heuristics on Atari benchmarks."
  },
  {
    "title": "Sqrt(d) Dimension Dependence of Langevin Monte Carlo",
    "url": "/forum?id=5-2mX9_U5i",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "unadjusted Langevin algorithm / Langevin Monte Carlo, non-asymptotic sampling error in Wasserstein-2 distance, optimal dimension dependence, mean square analysis",
    "Abstract": "This article considers the popular MCMC method of unadjusted Langevin Monte Carlo (LMC) and provides a non-asymptotic analysis of its sampling error in 2-Wasserstein distance. The proof is based on a refinement of mean-square analysis in Li et al. (2019), and this refined framework automates the analysis of a large class of sampling algorithms based on discretizations of contractive SDEs. Using this framework, we establish an $\\tilde{O}(\\sqrt{d}/\\epsilon)$ mixing time bound for LMC, without warm start, under the common log-smooth and log-strongly-convex conditions, plus a growth condition on the 3rd-order derivative of the potential of target measures. This bound improves the best previously known $\\tilde{O}(d/\\epsilon)$ result and is optimal (in terms of order) in both dimension $d$ and accuracy tolerance $\\epsilon$ for target measures satisfying the aforementioned assumptions. Our theoretical analysis is further validated by numerical experiments.",
    "One-sentence Summary": "The known dimension dependence of LMC is improved, under regularity assumptions, from d to sqrt(d), based on a refined mean square analysis framework."
  },
  {
    "title": "Relational Surrogate Loss Learning",
    "url": "/forum?id=dZPgfwaTaXv",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Evaluation metrics in machine learning are often hardly taken as loss functions, as they could be non-differentiable and non-decomposable, e.g., average precision and F1 score. This paper aims to address this problem by revisiting the surrogate loss learning, where a deep neural network is employed to approximate the evaluation metrics. Instead of pursuing an exact recovery of the evaluation metric through a deep neural network, we are reminded of the purpose of the existence of these evaluation metrics, which is to distinguish whether one model is better or worse than another. In this paper, we show that directly maintaining the relation of models between surrogate losses and metrics suffices, and propose a rank correlation-based optimization method to maximize this relation and learn surrogate losses. Compared to previous works, our method is much easier to optimize and enjoys significant efficiency and performance gains. Extensive experiments show that our method achieves improvements on various tasks including image classification and neural machine translation, and even outperforms state-of-the-art methods on human pose estimation and machine reading comprehension tasks. Code is available at: https://github.com/hunto/ReLoss."
  },
  {
    "title": "Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning",
    "url": "/forum?id=fy_XRVHqly",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multitask Reinforcement Learning, Modular Reinforcement Learning, Transfer Learning, Transformer, Structural Embedding",
    "Abstract": "Modular Reinforcement Learning, where the agent is assumed to be morphologically structured as a graph, for example composed of limbs and joints, aims to learn a policy that is transferable to a structurally similar but different agent. Compared to traditional Multi-Task Reinforcement Learning, this promising approach allows us to cope with inhomogeneous tasks where the state and action space dimensions differ across tasks. Graph Neural Networks are a natural model for representing the pertinent policies, but a recent work has shown that their multi-hop message passing mechanism is not ideal for conveying important information to other modules and thus a transformer model without morphological information was proposed. In this work, we argue that the morphological information is still very useful and propose a transformer policy model that effectively encodes such information. Specifically, we encode the morphological information in terms of the traversal-based positional embedding and the graph-based relational embedding. We empirically show that the morphological information is crucial for modular reinforcement learning, substantially outperforming prior state-of-the-art methods on multi-task learning as well as transfer learning settings with different state and action space dimensions.",
    "One-sentence Summary": "We present a modular Multi-task Reinforcement Learning method for inhomogeneous control tasks incorporating structural embedding of morphology."
  },
  {
    "title": "Toward Efficient Low-Precision Training: Data Format Optimization and Hysteresis Quantization",
    "url": "/forum?id=3HJOA-1hb0e",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "low-precision training, quantized training, logarithmic weight, data format optimization, hysteresis quantization",
    "Abstract": "As the complexity and size of deep neural networks continue to increase, low-precision training has been extensively studied in the last few years to reduce hardware overhead. Training performance is largely affected by the numeric formats representing different values in low-precision training, but finding an optimal format typically requires numerous training runs, which is a very time-consuming process. In this paper, we propose a method to efficiently find an optimal format for activations and errors without actual training. We employ this method to determine an 8-bit format suitable for training various models. In addition, we propose hysteresis quantization to suppress undesired fluctuation in quantized weights during training. This scheme enables deeply quantized training using 4-bit weights, exhibiting only 0.2% degradation for ResNet-18 trained on ImageNet.",
    "One-sentence Summary": "We propose a systematic data format optimization method and hysteresis quantization scheme to enable efficient low-precision training."
  },
  {
    "title": "Knowledge Infused Decoding",
    "url": "/forum?id=upnDJ7itech",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "natural language, decoding, reinforcement learning, knowledge integration, generation",
    "Abstract": "Pre-trained language models (LMs) have been shown to memorize a substantial amount of knowledge from the pre-training corpora; however, they are still limited in recalling factually correct knowledge given a certain context. Hence. they tend to suffer from counterfactual or hallucinatory generation when used in knowledge-intensive natural language generation (NLG) tasks. Recent remedies to this problem focus on modifying either the pre-training or task fine-tuning objectives to incorporate knowledge, which normally require additional costly training or architecture modification of LMs for practical applications.\n        \n        We present Knowledge Infused Decoding (KID)---a novel decoding algorithm for generative LMs, which dynamically infuses external knowledge into each step of the LM decoding. Specifically, we maintain a local knowledge memory based on the current context, interacting with a dynamically created external knowledge trie, and continuously update the local memory as a knowledge-aware constraint to guide decoding via reinforcement learning. On six diverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART) armed with KID outperform many task-optimized state-of-the-art models, and show particularly strong performance in few-shot scenarios over seven related knowledge-infusion techniques. Human evaluation confirms KID's ability to generate more relevant and factual language for the input context when compared with multiple baselines. Finally, KID also alleviates exposure bias and provides stable generation quality when generating longer sequences.",
    "One-sentence Summary": "We propose a new decoding algorithm for language model generation, to obtain better performance in knowledge-intensive tasks."
  },
  {
    "title": "Parallel Training of GRU Networks with a Multi-Grid Solver for Long Sequences",
    "url": "/forum?id=N1WI0vJLER",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "GRU, MGRIT, parallel-in-time, distributed machine learning",
    "Abstract": "Parallelizing Gated Recurrent Unit (GRU) is a challenging task, as the training procedure of GRU is inherently sequential. Prior efforts to parallelize GRU have largely focused on conventional parallelization strategies such as data-parallel and model-parallel training algorithms. However, when the given sequences are very long, existing approaches are still inevitably performance limited in terms of both training time and model accuracy. In this paper, we present a novel parallel training scheme (called  parallel-in-time) for GRU based on a multigrid reduction in time (MGRIT) solver. MGRIT partitions a sequence into multiple shorter sub-sequences and trains the sub-sequences on different processors in parallel. The key to achieving speedup is a hierarchical correction of the hidden state to accelerate end-to-end communication in both the forward and backward propagation phases of gradient descent. Experimental results on the HMDB51 dataset, where each video is an image sequence, demonstrate that a new parallel training scheme of GRU achieves up to $6.5 \\times$ speedup over a serial approach. As efficiency of our new parallelization strategy is associated with the sequence length, our parallel GRU algorithm achieves significant performance improvement as the length of sequence increases. Further, the proposed approach can be applied simultaneously with batch and other forms of model parallelism.",
    "One-sentence Summary": "This paper presents a novel parallel-in-time training scheme for GRU networks based on a MGRIT solver."
  },
  {
    "title": "QUERY EFFICIENT DECISION BASED SPARSE ATTACKS AGAINST BLACK-BOX DEEP LEARNING MODELS",
    "url": "/forum?id=73MEhZ0anV",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "decision-based attacks, sparse attacks, evolution algorithms, vision transformer, convolutional neural network",
    "Abstract": "Despite our best efforts, deep learning models remain highly vulnerable to even tiny adversarial perturbations applied to the inputs. The ability to extract information from solely the output of a machine learning model to craft adversarial perturbations to black-box models is a practical threat against real-world systems, such as Machine Learning as a Service (MLaaS), particularly $sparse~attacks$. The realization of sparse attacks in black-box settings demonstrates that machine learning models are more vulnerable than we believe. Because, these attacks aim to $minimize~the~number~of~perturbed~pixels$\u2014measured by $l_0$ norm\u2014required to mislead a model by $solely$ observing the decision ($the~predicted~label$) returned to a model query; the so-called $decision-based~setting$. But, such an attack leads to an NP-hard optimization problem. We develop an evolution-based algorithm\u2014$SparseEvo$\u2014for the problem and evaluate it against both convolutional deep neural networks and $vision~transformers$. Notably, vision transformers are yet to be investigated under a decision-based attack setting. SparseEvo requires significantly fewer queries than the state-of-the-art sparse attack $Pointwise$ for both untargeted and targeted attacks. The attack algorithm, although conceptually simple, is competitive with only a limited query budget against the state-of-the-art gradient-based $white-box$ attacks in standard computer vision tasks such as $ImageNet$. Importantly, the query efficient SparseEvo, along with decision-based attacks, in general, raises new questions regarding the safety of deployed systems and poses new directions to study and understand the robustness of machine learning models."
  },
  {
    "title": "Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations",
    "url": "/forum?id=gJLEXy3ySpu",
    "date": "28 Sept 2021 (modified: 21 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Top-$k$ predictions are used in many real-world applications such as machine learning as a service, recommender systems, and web searches. $\\ell_0$-norm adversarial perturbation characterizes an attack that arbitrarily modifies some features of an input such that a classifier makes an incorrect prediction for the perturbed input. $\\ell_0$-norm adversarial perturbation is easy to interpret and can be implemented in the physical world. Therefore, certifying  robustness of top-$k$ predictions against $\\ell_0$-norm adversarial perturbation is important. However, existing studies either focused on certifying $\\ell_0$-norm robustness of top-$1$ predictions or  $\\ell_2$-norm robustness of top-$k$ predictions. In this work, we aim to bridge the gap. Our approach is based on randomized smoothing, which builds a provably robust classifier from an arbitrary classifier via randomizing an input. Our major theoretical contribution is an almost tight $\\ell_0$-norm certified robustness guarantee for top-$k$ predictions. We empirically evaluate our method on CIFAR10 and ImageNet. For instance, our method can build a classifier that achieves a certified top-3 accuracy of 69.2\\% on ImageNet when an attacker can arbitrarily perturb 5 pixels of a testing image.",
    "One-sentence Summary": "In this work, we derive the certified robustness against $\\ell_0$-norm adversarial perturbation for top-$k$ prediction."
  },
  {
    "title": "Proving the Lottery Ticket Hypothesis for Convolutional Neural Networks",
    "url": "/forum?id=Vjki79-619-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "lottery ticket hypothesis, convolutional neural network, network pruning, random subset sum, random neural network",
    "Abstract": "The lottery ticket hypothesis states that a randomly-initialized neural network contains a small subnetwork which, when trained in isolation, can compete with the performance of the original network. Recent theoretical works proved an even stronger version: every sufficiently overparameterized (dense) neural network contains a subnetwork that, even without training, achieves accuracy comparable to that of the trained large network. These works left as an open problem to extend the result to convolutional neural networks (CNNs).\n        In this work we provide such generalization by showing that, with high probability, it is possible to approximate any CNN by pruning a random CNN whose size is larger by a logarithmic factor.",
    "One-sentence Summary": "We prove the lottery ticket hypothesis for convolutional neural networks"
  },
  {
    "title": "Discovering Nonlinear PDEs from Scarce Data with Physics-encoded Learning",
    "url": "/forum?id=Vog_3GXsgmb",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Data-driven equation discovery, dynamical system modeling, physics-encoded learning",
    "Abstract": "There have been growing interests in leveraging experimental measurements to discover the underlying partial differential equations (PDEs) that govern complex physical phenomena. Although past research attempts have achieved great success in data-driven PDE discovery, the robustness of the existing methods cannot be guaranteed when dealing with low-quality measurement data. To overcome this challenge, we propose a novel physics-encoded discrete learning framework for discovering spatiotemporal PDEs from scarce and noisy data. The general idea is to (1) firstly introduce a novel deep convolutional-recurrent networks, which can encode prior physics knowledge (e.g., known terms, assumed PDE structure, initial/boundary conditions, etc.) while remaining flexible on representation capability, to accurately reconstruct high-fidelity data, and (2) then perform sparse regression with the reconstructed data to identify the analytical form of the governing PDEs. We validate our proposed framework on three high-dimensional PDE systems. The effectiveness and superiority of the proposed method over baselines are demonstrated.",
    "One-sentence Summary": "This work seeks to solve the data-driven governing equation discovery problem with a novel physics-encoded learning framework."
  },
  {
    "title": "Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL",
    "url": "/forum?id=KJztlfGPdwW",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Goal-conditioned reinforcement learning, offline reinforcement learning, goal-conditioned supervised learning",
    "Abstract": "Solving goal-conditioned tasks with sparse rewards using self-supervised learning is promising because of its simplicity and stability over current reinforcement learning (RL) algorithms. A recent work, called Goal-Conditioned Supervised Learning (GCSL), provides a new learning framework by iteratively relabeling and imitating self-generated experiences. In this paper, we revisit the theoretical property of GCSL --- optimizing a lower bound of the goal reaching objective, and extend GCSL as a novel offline goal-conditioned RL algorithm. The proposed method is named Weighted GCSL (WGCSL), in which we introduce an advanced compound weight consisting of three parts (1) discounted weight for goal relabeling, (2) goal-conditioned exponential advantage weight, and (3) best-advantage weight. Theoretically, WGCSL is proved to optimize an equivalent lower bound of the goal-conditioned RL objective and generates monotonically improved policies via an iterated scheme. The monotonic property holds for any behavior policies, and therefore WGCSL can be applied to both online and offline settings. To evaluate algorithms in the offline goal-conditioned RL setting, we provide a benchmark including a range of point and simulated robot domains. Experiments in the introduced benchmark demonstrate that WGCSL can consistently outperform GCSL and existing state-of-the-art offline methods in the fully offline goal-conditioned setting.",
    "One-sentence Summary": "We revisit GCSL's theoretical foundation and present a simple but effective algorithm for offline goal-conditioned RL via weighted supervised learning"
  },
  {
    "title": "Topologically Regularized Data Embeddings",
    "url": "/forum?id=P1QUVhOtEFP",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Embedding, Dimensionality Reduction, Topological Data Analysis, Persistent Homology, Optimization, Regularization",
    "Abstract": "Unsupervised feature learning often finds low-dimensional embeddings that capture the structure of complex data.  For tasks for which prior expert topological knowledge is available, incorporating this into the learned representation may lead to higher quality embeddings. For example, this may help one to embed the data into a given number of clusters, or to accommodate for noise that prevents one from deriving the distribution of the data over the model directly, which can then be learned more effectively. However, a general tool for integrating different prior topological knowledge into embeddings is lacking. Although differentiable topology layers have been recently developed that can (re)shape embeddings into prespecified topological models, they have two important limitations for representation learning, which we address in this paper. First, the currently suggested topological losses fail to represent simple models such as clusters and flares in a natural manner. Second, these losses neglect all original structural (such as neighborhood) information in the data that is useful for learning. We overcome these limitations by introducing a new set of topological losses, and proposing their usage as a way for topologically regularizing data embeddings to naturally represent a prespecified model. We include thorough experiments on synthetic and real data that highlight the usefulness and versatility of this approach, with applications ranging from modeling high-dimensional single-cell data, to graph embedding.",
    "One-sentence Summary": "A method for incorporating expert prior topological knowledge into data embeddings."
  },
  {
    "title": "PF-GNN: Differentiable particle filtering based approximation of universal graph representations",
    "url": "/forum?id=oh4TirnfSem",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Graph representation learning, Expressive GNN",
    "Abstract": "Message passing Graph Neural Networks (GNNs) are known to be limited in expressive power by the 1-WL color-refinement test for graph isomorphism. Other more expressive models either are computationally expensive or need preprocessing to extract structural features from the graph. In this work, we propose to make GNNs universal by guiding the learning process with exact isomorphism solver techniques which operate on the paradigm of $\\textit{Individualization and refinement}$ (IR), a method to artificially introduce asymmetry and further refine the coloring when 1-WL stops. Isomorphism solvers generate a search-tree of colorings whose leaves uniquely identify the graph. However, the tree grows exponentially large and needs hand-crafted pruning techniques which are not desirable from a learning perspective. We take a probabilistic view and approximate the search tree of colorings ( i.e. embeddings) by sampling multiple paths from root to leaves of the search-tree. To learn more discriminative representations, we guide the sampling process with $\\textit{particle filter}$ updates, a principled approach for sequential state estimation. Our algorithm is end-to-end differentiable, can be applied with any GNN as backbone and learns richer graph representations with only linear increase in runtime. Experimental evaluation shows that our approach consistently outperforms leading GNN models on both synthetic benchmarks for isomorphism detection as well as real-world datasets.",
    "One-sentence Summary": "Increasing the expressive power of Graph Neural Networks by using techniques from exact isomorphism solvers with a particle filtering approach."
  },
  {
    "title": "Nonlinear ICA Using Volume-Preserving Transformations",
    "url": "/forum?id=AMpki9kp8Cn",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Independent Component Analysis, Nonlinear ICA, Identifiability",
    "Abstract": "Nonlinear ICA is a fundamental problem in machine learning, aiming to identify the underlying independent components (sources) from data which is assumed to be a nonlinear function (mixing function) of these sources. Recent works prove that if the sources have some particular structures (e.g. temporal structure), they are theoretically identifiable even if the mixing function is arbitrary. However, in many cases such restrictions on the sources are difficult to satisfy or even verify, hence it inhibits the applicability of the proposed methods. Different from these works, we propose a general framework for nonlinear ICA, in which the mixing function is assumed to be a volume-preserving transformation, and meanwhile the conditions on the sources can be much looser. We provide an insightful proof of the identifiability of the proposed framework. We implement the framework by volume-preserving Flow-based models, and verify our theory by experiments on artificial data and synthesized images. Moreover, results on real-world images indicate that our framework can disentangle interpretable features.",
    "One-sentence Summary": "We propose a general framework for nonlinear ICA, in which the mixing function is restricted to a volume-preserving transformation, and establish two novel identifiability theorems and provide insightful proofs."
  },
  {
    "title": "Online Ad Hoc Teamwork under Partial Observability",
    "url": "/forum?id=18Ys0-PzyPI",
    "date": "28 Sept 2021 (modified: 18 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "coordination, reinforcement learning",
    "Abstract": "Autonomous agents often need to work together as a team to accomplish complex cooperative tasks. Due to privacy and other realistic constraints, agents might need to collaborate with previously unknown teammates on the fly. This problem is known as ad hoc teamwork, which remains a core research challenge. Prior works usually rely heavily on strong assumptions like full observability, fixed and predefined teammates' types. This paper relaxes these assumptions with a novel reinforcement learning framework called ODITS, which allows the autonomous agent to adapt to arbitrary teammates in an online fashion. Instead of limiting teammates into a finite set of predefined types, ODITS automatically learns latent variables of teammates' behaviors to infer how to cooperate with new teammates effectively. To overcome partial observability, we introduce an information-based regularizer to derive proxy representations of the learned variables from local observations. Extensive experimental results show that ODITS significantly outperforms various baselines in widely used ad hoc teamwork tasks."
  },
  {
    "title": "Continual Normalization: Rethinking Batch Normalization for Online Continual Learning",
    "url": "/forum?id=vwLLQ-HwqhZ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Continual Learning, Batch Normalization",
    "Abstract": "Existing continual learning methods use Batch Normalization (BN) to facilitate training and improve generalization across tasks. However, the non-i.i.d and non-stationary nature of continual learning data, especially in the online setting, amplify the discrepancy between training and testing in BN and hinder the performance of older tasks. In this work, we study the cross-task normalization effect of BN in online continual learning where BN normalizes the testing data using moments biased towards the current task, resulting in higher catastrophic forgetting. This limitation motivates us to propose a simple yet effective method that we call Continual Normalization (CN) to facilitate training similar to BN while mitigating its negative effect. Extensive experiments on different continual learning algorithms and online scenarios show that CN is a direct replacement for BN and can provide substantial performance improvements. Our implementation will be made publicly available upon acceptance.",
    "One-sentence Summary": "A negative effect of BN in online continual learning and a simple strategy to alleviate it."
  },
  {
    "title": "Equivariant Graph Mechanics Networks with Constraints",
    "url": "/forum?id=SHbhHHfePhP",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Learning to reason about relations and dynamics over multiple interacting objects is a challenging topic in machine learning. The challenges mainly stem from that the interacting systems are exponentially-compositional, symmetrical, and commonly geometrically-constrained.\n        Current methods, particularly the ones based on equivariant Graph Neural Networks (GNNs), have targeted on the first two challenges but remain immature for constrained systems. \n        In this paper, we propose Graph Mechanics Network (GMN) which is combinatorially efficient, equivariant and constraint-aware. The core of GMN is that it represents, by generalized coordinates, the forward kinematics information (positions and velocities) of a structural object. In this manner, the geometrical constraints are implicitly and naturally encoded in the forward kinematics. Moreover, to allow equivariant message passing in GMN, we have developed a general form of orthogonality-equivariant functions, given that the dynamics of constrained systems are more complicated than the unconstrained counterparts. Theoretically, the proposed equivariant formulation is proved to be universally expressive under certain conditions. Extensive experiments  support the advantages of GMN compared to the state-of-the-art GNNs in terms of prediction accuracy, constraint satisfaction and data efficiency on the simulated systems consisting of particles, sticks and hinges, as well as two real-world datasets for molecular dynamics prediction and human motion capture."
  },
  {
    "title": "Towards Continual Knowledge Learning of Language Models",
    "url": "/forum?id=vfsRB5MImo9",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "continual learning, knowledge acquisition, catastrophic forgetting, large language models, pretraining, natural language processing",
    "Abstract": "Large Language Models (LMs) are known to encode world knowledge in their parameters as they pretrain on a vast amount of web corpus, which is often utilized for performing knowledge-dependent downstream tasks such as question answering, fact-checking, and open dialogue. In real-world scenarios, the world knowledge stored in the LMs can quickly become outdated as the world changes, but it is non-trivial to avoid catastrophic forgetting and reliably acquire new knowledge while preserving invariant knowledge. To push the community towards better maintenance of ever-changing LMs, we formulate a new continual learning (CL) problem called Continual Knowledge Learning (CKL). We construct a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. We adopt applicable recent methods from literature to create several strong baselines. Through extensive experiments, we find that CKL exhibits unique challenges that are not addressed in previous CL setups, where parameter expansion is necessary to reliably retain and learn knowledge simultaneously. By highlighting the critical causes of knowledge forgetting, we show that CKL is a challenging and important problem that helps us better understand and train ever-changing LMs.",
    "One-sentence Summary": "We propose a novel continual learning formulation named Continual Knowledge Learning which allows large language models to constantly obtain new and updated knowledge while mitigating forgetting of previous learned time-invariant knowledge."
  },
  {
    "title": "Surreal-GAN:Semi-Supervised Representation Learning via GAN for uncovering heterogeneous disease-related imaging patterns",
    "url": "/forum?id=nf3A0WZsXS5",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Representation Learning, Disease-related imaging patterns, Alzheimer's disease, MRI, GAN",
    "Abstract": "A plethora of machine learning methods have been applied to imaging data, enabling the construction of clinically relevant imaging signatures of neurological and neuropsychiatric diseases. Oftentimes, such methods don't explicitly model the heterogeneity of disease effects, or approach it via nonlinear models that are not interpretable. Moreover, unsupervised methods may parse heterogeneity that is driven by nuisance confounding factors that affect brain structure or function, rather than heterogeneity relevant to a pathology of interest. On the other hand, semi-supervised clustering methods seek to derive a dichotomous subtype membership, ignoring the truth that disease heterogeneity spatially and temporally extends along a continuum.  To address the aforementioned limitations, herein, we propose a novel method, termed Surreal-GAN (Semi-SUpeRvised ReprEsentAtion Learning via GAN). Using cross-sectional imaging data, Surreal-GAN dissects underlying disease-related heterogeneity under the principle of semi-supervised clustering (cluster mappings from normal control to patient), proposes a continuously dimensional representation, and infers the disease severity of patients at individual level along each dimension. The model first learns a transformation function from normal control (CN) domain to the patient (PT) domain with latent variables controlling transformation directions. An inverse mapping function together with regularization on function continuity, pattern orthogonality and monotonicity was also imposed to make sure that the transformation function captures necessarily meaningful imaging patterns with clinical significance. We first validated the model through extensive semi-synthetic experiments, and then demonstrate its potential in capturing biologically plausible imaging patterns in Alzheimer's disease (AD).",
    "One-sentence Summary": "We proposed a novel method, Surreal-GAN, to derive low dimensional representation of disease-related patterns from neuroimaging data."
  },
  {
    "title": "SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning",
    "url": "/forum?id=TfhfZLQ2EJO",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "preference-based reinforcement learning, human-in-the-loop reinforcement learning, deep reinforcement learning, semi-supervised learning",
    "Abstract": "Preference-based reinforcement learning (RL) has shown potential for teaching agents to perform the target tasks without a costly, pre-defined reward function by learning the reward with a supervisor\u2019s preference between the two agent behaviors. However, preference-based learning often requires a large amount of human feedback, making it difficult to apply this approach to various applications. This data-efficiency problem, on the other hand, has been typically addressed by using unlabeled samples or data augmentation techniques in the context of supervised learning. Motivated by the recent success of these approaches, we present SURF, a semi-supervised reward learning framework that utilizes a large amount of unlabeled samples with data augmentation. In order to leverage unlabeled samples for reward learning, we infer pseudo-labels of the unlabeled samples based on the confidence of the preference predictor. To further improve the label-efficiency of reward learning, we introduce a new data augmentation that temporally crops consecutive subsequences from the original behaviors. Our experiments demonstrate that our approach significantly improves the feedback-efficiency of the state-of-the-art preference-based method on a variety of locomotion and robotic manipulation tasks.",
    "One-sentence Summary": "We present SURF, a semi-supervised reward learning algorithm with data augmentation for feedback-efficient preference-based RL."
  },
  {
    "title": "Convergent Graph Solvers",
    "url": "/forum?id=ItkxLQU01lD",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph, Graph Neural Network, Fixed point, Implicit model, Implicit function theorem, Convergent",
    "Abstract": "We propose the convergent graph solver (CGS), a deep learning method that learns iterative mappings to predict the properties of a graph system at its stationary state (fixed point) with guaranteed convergence. The forward propagation of CGS proceeds in three steps: (1) constructing the input-dependent linear contracting iterative maps, (2) computing the fixed points of the iterative maps, and (3) decoding the fixed points to estimate the properties. The contractivity of the constructed linear maps guarantees the existence and uniqueness of the fixed points following the Banach fixed point theorem. To train CGS efficiently, we also derive a tractable analytical expression for its gradient by leveraging the implicit function theorem. We evaluate the performance of CGS by applying it to various network-analytic and graph benchmark problems. The results indicate that CGS has competitive capabilities for predicting the stationary properties of graph systems,  irrespective of whether the target systems are linear or non-linear. CGS also shows high performance for graph classification problems where the existence or the meaning of a fixed point is hard to be clearly defined, which highlights the potential of CGS as a general graph neural network architecture."
  },
  {
    "title": "Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation",
    "url": "/forum?id=_F9xpOrqyX9",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "worst-group loss minimization, spurious correlation",
    "Abstract": "The paradigm of worst-group loss minimization has shown its promise in avoiding to learn spurious correlations, but requires costly additional supervision on spurious attributes. To resolve this, recent works focus on developing weaker forms of supervision---e.g., hyperparameters discovered with a small number of validation samples with spurious attribute annotation---but none of the methods retain comparable performance to methods using full supervision on the spurious attribute. In this paper, instead of searching for weaker supervisions, we ask: Given access to a fixed number of samples with spurious attribute annotations, what is the best achievable worst-group loss if we ''fully exploit'' them? To this end, we propose a pseudo-attribute-based algorithm, coined Spread Spurious Attribute (SSA), for improving the worst-group accuracy. In particular, we leverage samples both with and without spurious attribute annotations to train a model to predict the spurious attribute, then use the pseudo-attribute predicted by the trained model as supervision on the spurious attribute to train a new robust model having minimal worst-group loss. Our experiments on various benchmark datasets show that our algorithm consistently outperforms the baseline methods using the same number of validation samples with spurious attribute annotations. We also demonstrate that the proposed SSA can achieve comparable performances to methods using full (100%) spurious attribute supervision, by using a much smaller number of annotated samples---from 0.6% and up to 1.5%, depending on the dataset.",
    "One-sentence Summary": "Using a small amount of attribute annotated samples for training can boost worst-group performance in the presence of spurious correlation."
  },
  {
    "title": "Learning Scenario Representation for Solving Two-stage Stochastic Integer Programs",
    "url": "/forum?id=06Wy2BtxXrz",
    "date": "28 Sept 2021 (modified: 25 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Conditional Variational Autoencoder, Stochastic Integer Programming, Scenario Reduction",
    "Abstract": "Many practical combinatorial optimization problems under uncertainty can be modeled as stochastic integer programs (SIPs), which are extremely challenging to solve due to the high complexity. To solve two-stage SIPs efficiently, we propose a conditional variational autoencoder (CVAE) based method to learn scenario representation for a class of SIP instances. Specifically, we design a graph convolutional network based encoder to embed each scenario with the deterministic part of its instance (i.e. context) into a low-dimensional latent space, from which a decoder reconstructs the scenario from its latent representation conditioned on the context. Such a design effectively captures the dependencies of the scenarios on their corresponding instances. We apply the trained encoder to two tasks in typical SIP solving, i.e. scenario reduction and objective prediction. Experiments on two SIP problems show that the learned latent representation significantly boosts the solving performance to attain high-quality solutions in short computational time, and generalizes fairly well to problems of larger sizes or with more scenarios.",
    "One-sentence Summary": "This paper provides a CVAE based method to learn scenario representations for solving stochastic integer programs."
  },
  {
    "title": "Generalization Through the Lens of Leave-One-Out Error",
    "url": "/forum?id=7grkzyj89A_",
    "date": "28 Sept 2021 (modified: 01 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Despite the tremendous empirical success of deep learning models to solve various learning tasks, our theoretical understanding of their generalization ability is very limited. Classical generalization bounds based on tools such as the VC dimension or Rademacher complexity, are so far unsuitable for deep models and it is doubtful that these techniques can yield tight bounds even in the most idealistic settings~\\citep{nagarajan2019uniform}. In this work, we instead revisit the concept of leave-one-out (LOO) error to measure the generalization ability of deep models in the so-called kernel regime. While popular in statistics, the LOO error has been largely overlooked in the context of deep learning. By building upon the recently established connection between neural networks and kernel learning, we leverage the closed-form expression for the leave-one-out error, giving us access to an efficient proxy for the test error. We show both theoretically and empirically that the leave-one-out error is capable of capturing various phenomena in generalization theory, such as double descent, random labels or transfer learning.\n        Our work therefore demonstrates that the leave-one-out error provides a tractable way to estimate the generalization ability of deep neural networks in the kernel regime, opening the door to potential, new research directions in the field of generalization."
  },
  {
    "title": "Self-Supervised Inference in State-Space Models",
    "url": "/forum?id=VPjw9KPWRSK",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self-supervision, inference, state-space model, Kalman filter, recurrent neural network",
    "Abstract": "We perform approximate inference in state-space models with nonlinear state transitions. Without parameterizing a generative model, we apply Bayesian update formulas using a local linearity approximation parameterized by neural networks. It comes accompanied by a maximum likelihood objective that requires no supervision via uncorrupt observations or ground truth latent states. The optimization backpropagates through a recursion similar to the classical Kalman filter and smoother. Additionally, using an approximate conditional independence, we can perform smoothing without having to parameterize a separate model. In scientific applications, domain knowledge can give a linear approximation of the latent transition maps, which we can easily incorporate into our model. Usage of such domain knowledge is reflected in excellent results (despite our model's simplicity) on the chaotic Lorenz system compared to fully supervised and variational inference methods. Finally, we show competitive results on an audio denoising experiment."
  },
  {
    "title": "On the Role of Neural Collapse in Transfer Learning",
    "url": "/forum?id=SwIp410B6aQ",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We study the ability of foundation models to learn representations for classification that are transferable to new, unseen classes. Recent results in the literature show that representations learned by a single classifier over many classes are competitive on few-shot learning problems with representations learned by special-purpose algorithms designed for such problems. In this paper, we provide an explanation for this behavior based on the recently observed phenomenon that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. We demonstrate both theoretically and empirically that neural collapse generalizes to new samples from the training classes, and -- more importantly -- to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few-shot setting."
  },
  {
    "title": "Information-theoretic Online Memory Selection for Continual Learning",
    "url": "/forum?id=IpctgL7khPp",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Task-free continual learning, replay memory, information theoretic, reservoir sampling",
    "Abstract": "A challenging problem in task-free continual learning is the online selection of a representative replay memory from data streams. In this work, we investigate the online memory selection problem from an information-theoretic perspective. To gather the most information, we propose the \\textit{surprise} and the \\textit{learnability} criteria to pick informative points and to avoid outliers. We present a Bayesian model to compute the criteria efficiently by exploiting rank-one matrix structures. We demonstrate that these criteria encourage selecting informative points in a greedy algorithm for online memory selection. Furthermore, by identifying the importance of \\textit{the timing to update the memory}, we introduce a stochastic information-theoretic reservoir sampler (InfoRS), which conducts sampling among selective points with high information. Compared to reservoir sampling, InfoRS demonstrates improved robustness against data imbalance. Finally, empirical performances over continual learning benchmarks manifest its efficiency and efficacy.",
    "One-sentence Summary": "We present information-theoretic algorithms to tackle the online memory selection problem in task-free and data imbalanced continual learning."
  },
  {
    "title": "Dealing with Non-Stationarity in MARL via Trust-Region Decomposition",
    "url": "/forum?id=XHUxf5aRB3s",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Nonstationarity, Trust-Region Methods, Multi-Agent Reinforcement Learning",
    "Abstract": "Non-stationarity is one thorny issue in cooperative multi-agent reinforcement learning (MARL). One of the reasons is the policy changes of agents during the learning process. Some existing works have discussed various consequences caused by non-stationarity with several kinds of measurement indicators. This makes the objectives or goals of existing algorithms are inevitably inconsistent and disparate. In this paper, we introduce a novel notion, the $\\delta$-$stationarity$ measurement, to explicitly measure the non-stationarity of a policy sequence, which can be further proved to be bounded by the KL-divergence of consecutive joint policies. A straightforward but highly non-trivial way is to control the joint policies' divergence, which is difficult to estimate accurately by imposing the trust-region constraint on the joint policy. Although it has lower computational complexity to decompose the joint policy and impose trust-region constraints on the factorized policies, simple policy factorization like mean-field approximation will lead to more considerable policy divergence, which can be considered as the trust-region decomposition dilemma. We model the joint policy as a pairwise Markov random field and propose a trust-region decomposition network (TRD-Net) based on message passing to estimate the joint policy divergence more accurately. The Multi-Agent Mirror descent policy algorithm with Trust region decomposition, called MAMT, is established by adjusting the trust-region of the local policies adaptively in an end-to-end manner. MAMT can approximately constrain the consecutive joint policies' divergence to satisfy $\\delta$-stationarity and alleviate the non-stationarity problem. Our method can bring noticeable and stable performance improvement compared with baselines in cooperative tasks of different complexity."
  },
  {
    "title": "Information Bottleneck: Exact Analysis of (Quantized) Neural Networks",
    "url": "/forum?id=kF9DZQQrU0w",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "information bottleneck, quantization, neural network",
    "Abstract": "The information bottleneck (IB) principle has been suggested as a way to analyze deep neural networks. The learning dynamics are studied by inspecting the mutual information (MI) between the hidden layers and the input and output. Notably, separate fitting and compression phases  during training have been reported. This led to some controversy including claims that the observations are not reproducible and strongly dependent on the type of activation function used as well as on the way the MI is estimated. Our study confirms that  different ways of binning  when computing the MI lead to qualitatively different results, either supporting or refusing IB conjectures.\n        To resolve the controversy, we study the IB principle in settings where MI is non-trivial and can be computed exactly. We monitor the dynamics of quantized neural networks, that is, we discretize the whole deep learning system so that no approximation is required when computing the MI. This allows us to quantify the information flow without measurement errors. \n        In this setting, we observed a fitting phase for all layers and a compression phase for the output layer in all experiments; the compression in the hidden layers was dependent on the type of activation function. Our study shows that the initial IB results were not artifacts of binning when computing the MI. However, the critical claim that the compression phase may not be observed for some networks also holds true.",
    "One-sentence Summary": "We investigate the information bottleneck in quantized neural networks, allowing us to compute the exact mutual information and provide an analysis free from estimation artifacts."
  },
  {
    "title": "GLASS: GNN with Labeling Tricks for Subgraph Representation Learning",
    "url": "/forum?id=XLxhEjKNbXj",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Despite the remarkable achievements of Graph Neural Networks (GNNs) on graph representation learning, few works have tried to use them to predict properties of subgraphs in the whole graph. The existing state-of-the-art method SubGNN introduces an overly complicated subgraph-level GNN model which synthesizes three artificial channels each of which has two carefully designed subgraph-level message passing modules, yet only slightly outperforms a plain GNN which performs node-level message passing and then pools node embeddings within the subgraph. By analyzing SubGNN and plain GNNs, we find that the key for subgraph representation learning might be to distinguish nodes inside and outside the subgraph. With this insight, we propose an expressive and scalable labeling trick, namely max-zero-one, to enhance plain GNNs for subgraph tasks. The resulting model is called GLASS (GNN with LAbeling trickS for Subgraph). We theoretically characterize GLASS's expressive power. Compared with SubGNN, GLASS is more expressive, more scalable, and easier to implement. Experiments on eight benchmark datasets show that GLASS outperforms the strongest baseline by $14.8\\%$ on average. And ablation analysis shows that our max-zero-one labeling trick can boost the performance of a plain GNN by up to $105\\%$ in maximum, which illustrates the effectiveness of labeling trick on subgraph tasks. Furthermore, training a GLASS model only takes $37\\%$ time needed for a SubGNN on average."
  },
  {
    "title": "MoReL: Multi-omics Relational Learning",
    "url": "/forum?id=DnG75_KyHjX",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "relational learning, data integration, multi-view learning, Bayesian generative model",
    "Abstract": "Multi-omics data analysis has the potential to discover hidden molecular interactions, revealing potential regulatory and/or signal transduction pathways for cellular processes of interest when studying life and disease systems. One of critical challenges when dealing with real-world multi-omics data is that they may manifest heterogeneous structures and data quality as often existing data may be collected from different subjects under different conditions for each type of omics data. We propose a novel deep Bayesian generative model to efficiently infer a multi-partite graph encoding molecular interactions across such heterogeneous views, using a fused Gromov-Wasserstein (FGW) regularization between latent representations of corresponding views for integrative analysis. With such an optimal transport regularization in the deep Bayesian generative model, it not only allows incorporating view-specific side information, either with graph-structured or unstructured data in different views, but also increases the model flexibility with the distribution-based regularization. This allows efficient alignment of heterogeneous latent variable distributions to derive reliable interaction predictions compared to the existing point-based graph embedding methods. Our experiments on several real-world datasets demonstrate enhanced performance of MoReL in inferring meaningful interactions compared to existing baselines."
  },
  {
    "title": "Provable Learning-based Algorithm For Sparse Recovery",
    "url": "/forum?id=BwPaPxwgyQb",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "learning to learn, sparse parameter estimation, learning to optimize, algorithm unrolling, generalization bound",
    "Abstract": "Recovering sparse parameters from observational data is a fundamental problem in machine learning with wide applications. Many classic algorithms can solve this problem with theoretical guarantees, but their performances rely on choosing the correct hyperparameters. Besides, hand-designed algorithms do not fully exploit the particular problem distribution of interest. In this work, we propose a deep learning method for algorithm learning called PLISA (Provable Learning-based Iterative Sparse recovery Algorithm). PLISA is designed by unrolling a classic path-following algorithm for sparse recovery, with some components being more flexible and learnable. We theoretically show the improved recovery accuracy achievable by PLISA. Furthermore, we analyze the empirical Rademacher complexity of PLISA to characterize its generalization ability to solve new problems outside the training set. This paper contains novel theoretical contributions to the area of learning-based algorithms in the sense that (i) PLISA is generically applicable to a broad class of sparse estimation problems, (ii) generalization analysis has received less attention so far, and (iii) our analysis makes novel connections between the generalization ability and algorithmic properties such as stability and convergence of the unrolled algorithm, which leads to a tighter bound that can explain the empirical observations. The techniques could potentially be applied to analyze other learning-based algorithms in the literature."
  },
  {
    "title": "Defending Against Image Corruptions Through Adversarial Augmentations",
    "url": "/forum?id=jJOjjiZHy3h",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "robustness, adversarial training, image corruptions",
    "Abstract": "Modern neural networks excel at image classification, yet they remain vulnerable to common image corruptions such as blur, speckle noise or fog. Recent methods that focus on this problem, such as AugMix and DeepAugment, introduce defenses that operate in expectation over a distribution of image corruptions. In contrast, the literature on Lp-norm bounded perturbations focuses on defenses against worst-case corruptions. In this work, we reconcile both approaches by proposing AdversarialAugment, a technique which optimizes the parameters of image-to-image models to generate adversarially corrupted augmented images. We theoretically motivate our method and give sufficient conditions for the consistency of its idealized version as well as that of DeepAugment. Our classifiers improve upon the state-of-the-art on common image corruption benchmarks conducted in expectation on CIFAR-10-C and improve worst-case performance against Lp-norm bounded perturbations on both CIFAR-10 and ImageNet.",
    "One-sentence Summary": "Our theoretically-supported method finds adversarial examples by optimizing over the weights of pre-trained autoencoders, and yields classifiers with improved robustness to image corruptions."
  },
  {
    "title": "Attacking deep networks with surrogate-based adversarial black-box methods is easy",
    "url": "/forum?id=Zf4ZdI4OQPV",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "adversarial attacks, black-box attacks, network robustness, network analysis",
    "Abstract": "A recent line of work on black-box adversarial attacks has revived the use of transfer from surrogate models by integrating it into query-based search. However, we find that existing approaches of this type underperform their potential, and can be overly complicated besides. Here, we provide a short and simple algorithm which achieves state-of-the-art results through a search which uses the surrogate network's class-score gradients, with no need for other priors or heuristics. The guiding assumption of the algorithm is that the studied networks are in a fundamental sense learning similar functions, and that a transfer attack from one to the other should thus be fairly \"easy\". This assumption is validated by the extremely low query counts and failure rates achieved: e.g. an untargeted attack on a VGG-16 ImageNet network using a ResNet-152 as the surrogate yields a median query count of 6 at a success rate of 99.9%. Code is available at https://github.com/fiveai/GFCS.",
    "One-sentence Summary": "We present a simple and extremely effective score- and surrogate-based black-box adversarial attack which uses a specific gradient/Jacobian transfer strategy."
  },
  {
    "title": "Autoregressive Diffusion Models",
    "url": "/forum?id=Lm8T39vLDTE",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "diffusion, autoregressive models, lossless compression",
    "Abstract": "We introduce Autoregressive Diffusion Models (ARDMs), a model class encompassing and generalizing order-agnostic autoregressive models (Uria et al., 2014) and absorbing discrete diffusion (Austin et al., 2021), which we show are special cases of ARDMs under mild assumptions. ARDMs are simple to implement and easy to train. Unlike standard ARMs, they do not require causal masking of model representations, and can be trained using an efficient objective similar to modern probabilistic diffusion models that scales favourably to highly-dimensional data. At test time, ARDMs support parallel generation which can be adapted to fit any given generation budget. We find that ARDMs require significantly fewer steps than discrete diffusion models to attain the same performance. Finally, we apply ARDMs to lossless compression, and show that they are uniquely suited to this task. Contrary to existing approaches based on bits-back coding, ARDMs obtain compelling results not only on complete datasets, but also on compressing single data points. Moreover, this can be done using a modest number of network calls for (de)compression due to the model's adaptable parallel generation.",
    "One-sentence Summary": "A new model class for discrete variables encompassing order agnostic autoregressive models and absorbing discrete diffusion."
  },
  {
    "title": "Auto-scaling Vision Transformers without Training",
    "url": "/forum?id=H94a1_Pyr-6",
    "date": "28 Sept 2021 (modified: 27 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "vision transformer, neural architecture search, training-free search, efficient training",
    "Abstract": "This work targets automated designing and scaling of Vision Transformers (ViTs). The motivation comes from two pain spots: 1) the lack of efficient and principled methods for designing and scaling ViTs; 2) the tremendous computational cost of training ViT that is much heavier than its convolution counterpart. To tackle these issues, we propose As-ViT, an auto-scaling framework for ViTs without training, which automatically discovers and scales up ViTs in an efficient and principled manner. Specifically, we first design a \"seed\" ViT topology by leveraging a training-free search process. This extremely fast search is fulfilled by a comprehensive study of ViT's network complexity, yielding a strong Kendall-tau correlation with ground-truth accuracies. Second, starting from the \"seed\" topology, we automate the scaling rule for ViTs by growing widths/depths to different ViT layers. This results in a series of architectures with different numbers of parameters in a single run. Finally, based on the observation that ViTs can tolerate coarse tokenization in early training stages, we propose a progressive tokenization strategy to train ViTs faster and cheaper. As a unified framework, As-ViT achieves strong performance on classification (83.5% top1 on ImageNet-1k) and detection (52.7% mAP on COCO) without any manual crafting nor scaling of ViT architectures: the end-to-end model design and scaling process costs only 12 hours on one V100 GPU. Our code is available at https://github.com/VITA-Group/AsViT.",
    "One-sentence Summary": "We automate the design and scaling of vision transformers without any training, achieving state-of-the-art performance on ImageNet classification and COCO object detection."
  },
  {
    "title": "Fine-grained Differentiable Physics: A Yarn-level Model for Fabrics",
    "url": "/forum?id=KPEFXR1HdIo",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Differentiable physics modeling combines physics models with gradient-based learning to provide model explicability and data efficiency. It has been used to learn dynamics, solve inverse problems and facilitate design, and is at its inception of impact. Current successes have concentrated on general physics models such as rigid bodies, deformable sheets, etc, assuming relatively simple structures and forces. Their granularity is intrinsically coarse and therefore incapable of modelling complex physical phenomena. Fine-grained models are still to be developed to incorporate sophisticated material structures and force interactions with gradient-based learning. Following this motivation, we propose a new differentiable fabrics model for composite materials such as cloths, where we dive into the granularity of yarns and model individual yarn physics and yarn-to-yarn interactions. To this end, we propose several differentiable forces, whose counterparts in empirical physics are indifferentiable, to facilitate gradient-based learning. These forces, albeit applied to cloths, are ubiquitous in various physical systems. Through comprehensive evaluation and comparison, we demonstrate our model's $\\textit{explicability}$ in learning meaningful physical parameters, $\\textit{versatility}$ in incorporating complex physical structures and heterogeneous materials, $\\textit{data-efficiency}$ in learning, and $\\textit{high-fidelity}$ in capturing subtle dynamics."
  },
  {
    "title": "Revisiting flow generative models for Out-of-distribution detection",
    "url": "/forum?id=6y2KBh-0Fd9",
    "date": "28 Sept 2021 (modified: 05 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "flow models, out-of-distribution detection, random projection, distribution comparison",
    "Abstract": "Deep generative models have been widely used in practical applications such as the detection of out-of-distribution (OOD) data. In this work,  we aim to re-examine the potential of generative flow models in OOD detection. We first propose a simple combination of univariate one-sample statistical test (e.g., Kolmogorov-Smirnov) and random projections in the latent space of flow models to perform OOD detection.  Then, we propose a two-sample version of our test to account for imperfect flow models. Quite distinctly, our method does not pose parametric assumptions on OOD data and is capable of exploiting any flow model. Experimentally, firstly we confirm the efficacy of our method against state-of-the-art baselines through extensive experiments on several image datasets; secondly we investigate the relationship between model accuracy (e.g., the generation quality) and the OOD detection performance, and found surprisingly that they are not always positively correlated; and thirdly we show that detection in the latent space of flow models generally outperforms detection in the sample space across various OOD datasets, hence highlighting the benefits of training a flow model."
  },
  {
    "title": "Missingness Bias in Model Debugging",
    "url": "/forum?id=Te5ytkqsnl",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "model debugging, vision transformers, missingness",
    "Abstract": "Missingness, or the absence of features from an input, is a concept fundamental to many model debugging tools. However, in computer vision, pixels cannot simply be removed from an image. One thus tends to resort to heuristics such as blacking out pixels, which may in turn introduce bias into the debugging process. We study such biases and, in particular, show how transformer-based architectures can enable a more natural implementation of missingness, which side-steps these issues and improves the reliability of model debugging in practice.",
    "One-sentence Summary": "We investigate how current missingness approximations for model debugging can impose undesirable biases on the model predictions and hinder our ability to debug models, and we show how transformer-based architectures can side-step these issues."
  },
  {
    "title": "Meta Learning Low Rank Covariance Factors for Energy Based Deterministic Uncertainty",
    "url": "/forum?id=GQd7mXSPua",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "calibration, meta-learning",
    "Abstract": "Numerous recent works utilize bi-Lipschitz regularization of neural network layers to preserve relative distances between data instances in the feature spaces of each layer. This distance sensitivity with respect to the data aids in tasks such as uncertainty calibration and out-of-distribution (OOD) detection. In previous works, features extracted with a distance sensitive model are used to construct feature covariance matrices which are used in deterministic uncertainty estimation or OOD detection. However, in cases where there is a distribution over tasks, these methods result in covariances which are sub-optimal, as they may not leverage all of the meta information which can be shared among tasks. With the use of an attentive set encoder, we propose to meta learn either diagonal or diagonal plus low-rank factors to efficiently construct task specific covariance matrices. Additionally, we propose an inference procedure which utilizes scaled energy to achieve a final predictive distribution which is well calibrated under a distributional dataset shift.",
    "One-sentence Summary": "We propose a novel meta learning algorithm which learns low rank covariance factors, and utilizes an energy-based inference to achieve a calibrated prediction."
  },
  {
    "title": "Conditional Object-Centric Learning from Video",
    "url": "/forum?id=aD7uesX1GF_",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Object-centric representations are a promising path toward more systematic generalization by providing flexible abstractions upon which compositional world models can be built. Recent work on simple 2D and 3D datasets has shown that models with object-centric inductive biases can learn to segment and represent meaningful objects from the statistical structure of the data alone without the need for any supervision. However, such fully-unsupervised methods still fail to scale to diverse realistic data, despite the use of increasingly complex inductive biases such as priors for the size of objects or the 3D geometry of the scene. In this paper, we instead take a weakly-supervised approach and focus on how 1) using the temporal dynamics of video data in the form of optical flow and 2) conditioning the model on simple object location cues can be used to enable segmenting and tracking objects in significantly more realistic synthetic data. We introduce a sequential extension to Slot Attention which we train to predict optical flow for realistic looking synthetic scenes and show that conditioning the initial state of this model on a small set of hints, such as center of mass of objects in the first frame, is sufficient to significantly improve instance segmentation. These benefits generalize beyond the training distribution to novel objects, novel backgrounds, and to longer video sequences. We also find that such initial-state-conditioning can be used during inference as a flexible interface to query the model for specific objects or parts of objects, which could pave the way for a range of weakly-supervised approaches and allow more effective interaction with trained models."
  },
  {
    "title": "Scale Efficiently: Insights from Pretraining and Finetuning Transformers",
    "url": "/forum?id=f2OYVDyfIB",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "transformers, attention, deep learning",
    "Abstract": "There remain many open questions pertaining to the scaling behaviour of Transformer architectures. These scaling decisions and findings can be critical, as training runs often come with an associated computational cost which have both financial and/or environmental impact. The goal of this paper is to present scaling insights from pretraining and finetuning Transformers. While Kaplan et al. presents a comprehensive study of the scaling behaviour of Transformer language models, the scope is only on the upstream (pretraining) loss. Therefore, it is still unclear if these set of findings transfer to downstream task within the context of the pretrain-finetune paradigm. The key findings of this paper are as follows: (1) we show that aside from only the model size, model shape matters for downstream fine-tuning, (2) scaling protocols operate differently at different compute regions, (3) widely adopted T5-base and T5-large sizes are Pareto-inefficient. To this end, we present improved scaling protocols whereby our redesigned models achieve similar downstream fine-tuning quality while having 50\\% fewer parameters and training 40\\% faster compared to the widely adopted T5-base model. We publicly release over 100 pretrained checkpoints of different T5 configurations to facilitate future research and analysis.",
    "One-sentence Summary": "Scaling laws for upstream and downstream tasks"
  },
  {
    "title": "Vitruvion: A Generative Model of Parametric CAD Sketches",
    "url": "/forum?id=Ow1C7s3UcY",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "generative modeling, CAD, transformers, design, geometric constraints",
    "Abstract": "Parametric computer-aided design (CAD) tools are the predominant way that engineers specify physical structures, from bicycle pedals to airplanes to printed circuit boards. The key characteristic of parametric CAD is that design intent is encoded not only via geometric primitives, but also by parameterized constraints between the elements. This relational specification can be viewed as the construction of a constraint program, allowing edits to coherently propagate to other parts of the design. Machine learning offers the intriguing possibility of accelerating the design process via generative modeling of these structures, enabling new tools such as autocompletion, constraint inference, and conditional synthesis. In this work, we present such an approach to generative modeling of parametric CAD sketches, which constitute the basic computational building blocks of modern mechanical design. Our model, trained on real-world designs from the SketchGraphs dataset, autoregressively synthesizes sketches as sequences of primitives, with initial coordinates, and constraints that reference back to the sampled primitives. As samples from the model match the constraint graph representation used in standard CAD software, they may be directly imported, solved, and edited according to downstream design tasks. In addition, we condition the model on various contexts, including partial sketches (primers) and images of hand-drawn sketches. Evaluation of the proposed approach demonstrates its ability to synthesize realistic CAD sketches and its potential to aid the mechanical design workflow.",
    "One-sentence Summary": "We build a generative model for parametric CAD sketches and use it to perform autocompletion and hand drawing conversion tasks relevant to design."
  },
  {
    "title": "Space-Time Graph Neural Networks",
    "url": "/forum?id=XJiajt89Omg",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "ST-GNNs, GNNs, stability, graph-time perturbations",
    "Abstract": "We introduce space-time graph neural network (ST-GNN), a novel GNN architecture, tailored to jointly process the underlying space-time topology of time-varying network data. The cornerstone of our proposed architecture is the composition of time and graph convolutional filters followed by pointwise nonlinear activation functions. We introduce a generic definition of convolution operators that mimic the diffusion process of signals over its underlying support. On top of this definition, we propose space-time graph convolutions that are built upon a composition of time and graph shift operators.  We prove that ST-GNNs with multivariate integral Lipschitz filters are stable to small perturbations in the underlying graphs as well as small perturbations in the time domain caused by time warping. Our analysis shows that small variations in the network topology and time evolution of a system does not significantly affect the performance of ST-GNNs. Numerical experiments with decentralized control systems showcase the effectiveness and stability of the proposed ST-GNNs.",
    "One-sentence Summary": "We introduce space-time graph neural network (ST-GNN) tailored to jointly process the underlying space-time topology of time-varying network data, and we show its stability to perturbations."
  },
  {
    "title": "Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs",
    "url": "/forum?id=bjy5Zb2fo2",
    "date": "28 Sept 2021 (modified: 03 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Convolutional neural networks (CNNs) constructed natively on the sphere have been developed recently and shown to be highly effective for the analysis of spherical data.  While an efficient framework has been formulated, spherical CNNs are nevertheless highly computationally demanding; typically they cannot scale beyond spherical signals of thousands of pixels.  We develop scattering networks constructed natively on the sphere that provide a powerful representational space for spherical data.  Spherical scattering networks are computationally scalable and exhibit rotational equivariance, while their representational space is invariant to isometries and provides efficient and stable signal representations.  By integrating scattering networks as an additional type of layer in the generalized spherical CNN framework, we show how they can be leveraged to scale spherical CNNs to the high-resolution data typical of many practical applications, with spherical signals of many tens of megapixels and beyond.",
    "One-sentence Summary": "Scaling rotationally equivariant spherical CNNs to high-resolution data through spherical scattering networks"
  },
  {
    "title": "Bayesian Neural Network Priors Revisited",
    "url": "/forum?id=xkjqJYqRJy",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Bayesian deep learning, Bayesian neural networks, Priors",
    "Abstract": "Isotropic Gaussian priors are the de facto standard for modern Bayesian neural network inference. However, it is unclear whether these priors accurately reflect our true beliefs about the weight distributions or give optimal performance. To find better priors, we study summary statistics of neural network weights in networks trained using stochastic gradient descent (SGD). We find that convolutional neural network (CNN) and ResNet weights display strong spatial correlations, while fully connected networks (FCNNs) display heavy-tailed weight distributions. We show that building these observations into priors can lead to improved performance on a variety of image classification datasets. Surprisingly, these priors mitigate the cold posterior effect in FCNNs, but slightly increase the cold posterior effect in ResNets.",
    "One-sentence Summary": "Using BNN priors that are not isotropic Gaussians can improve performance and reduce the cold posterior effect."
  },
  {
    "title": "Goal-Directed Planning via Hindsight Experience Replay",
    "url": "/forum?id=6NePxZwfae",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Goal-Directed Planning, Monte Carlo Tree Search",
    "Abstract": "We consider the problem of goal-directed planning under a deterministic transition model. Monte Carlo Tree Search has shown remarkable performance in solving deterministic control problems. It has been extended from complex continuous domains through function approximators to bias the search of the planning tree in AlphaZero. Nonetheless, these algorithms still struggle with control problems with sparse rewards, such as goal-directed domains, where a positive reward is awarded only when reaching a goal state. In this work, we recast AlphaZero with Hindsight Experience Replay to tackle complex goal-directed planning tasks. We perform a thorough empirical evaluation in several simulated domains, including a novel application to a quantum compiling domain.",
    "One-sentence Summary": "This paper presents an extension of AlphaZero to tackle sparse reward goal-based tasks"
  },
  {
    "title": "Hybrid Random Features",
    "url": "/forum?id=EMigfE6ZeS",
    "date": "28 Sept 2021 (modified: 20 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "random features, softmax kernel, attention mechanism, compositional kernels",
    "Abstract": "We propose a new class of random feature methods for linearizing softmax and Gaussian kernels called hybrid random features (HRFs) that automatically adapt the quality of kernel estimation to provide most accurate approximation in the defined regions of interest. Special instantiations of HRFs lead to well-known methods such as trigonometric (Rahimi & Recht, 2007) or (recently introduced in the context of linear-attention Transformers) positive random features (Choromanski et al., 2021). By generalizing Bochner\u2019s Theorem for softmax/Gaussian kernels and leveraging random features for compositional kernels, the HRF-mechanism provides strong theoretical guarantees - unbiased approximation and strictly smaller worst-case relative errors than its counterparts.  We conduct exhaustive empirical evaluation of HRF ranging from pointwise kernel estimation experiments, through tests on data admitting clustering structure to benchmarking implicit-attention Transformers (also for downstream Robotics applications), demonstrating its quality in a wide spectrum of machine learning problems.",
    "One-sentence Summary": "We propose a new class of random feature methods for softmax and Gaussian kernel estimation that are adaptable to provide particularly accurate approximation in the desired regions of interest."
  },
  {
    "title": "Pretrained Language Model in Continual Learning: A Comparative Study",
    "url": "/forum?id=figzpGMrdD",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Continual Learning, Pre-trained Language Model",
    "Abstract": "Continual learning (CL) is a  setting in which a model learns from a stream of incoming data while avoiding to forget previously learned knowledge. Pre-trained language models (PLMs) have been successfully employed in continual learning of different natural language problems. With the rapid development of many continual learning methods and PLMs, understanding and disentangling their interactions become essential for continued improvement of continual learning performance. In this paper, we thoroughly compare the continual learning performance over the combination of 5 PLMs and 4 CL approaches on 3 benchmarks in 2 typical incremental settings. Our extensive experimental analyses reveal interesting performance differences across PLMs and across CL methods. Furthermore, our representativeness probing analyses dissect PLMs\u2019 performance characteristics in a layer-wise and task-wise manner, uncovering the extent to which their inner layers suffer from forgetting, and the effect of different CL approaches on each layer. Finally, our observations and analyses open up a number of important research questions that will inform and guide the design of effective continual learning techniques.",
    "One-sentence Summary": "In this paper, we thoroughly compare the continual learning performance over the combination of 5 PLMs and 4 veins of CL methods on 3 benchmarks in 2 typical incremental settings."
  },
  {
    "title": "Salient ImageNet: How to discover spurious features in Deep Learning?",
    "url": "/forum?id=XVPqLyNxSyh",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "interpretability, failure explanation, debugging, robustness",
    "Abstract": "Deep neural networks can be unreliable in the real world especially when they heavily use {\\it spurious} features for their predictions. Focusing on image classifications, we define {\\it core features} as the set of visual features that are always a part of the object definition while {\\it spurious features} are the ones that are likely to {\\it co-occur} with the object but not a part of it (e.g., attribute ``fingers\" for class ``band aid\"). Traditional methods for discovering spurious features either require extensive human annotations (thus, not scalable), or are useful on specific models. In this work, we introduce a {\\it general} framework to discover a subset of spurious and core visual features used in inferences of a general model and localize them on a large number of images with minimal human supervision. Our methodology is based on this key idea: to identify spurious or core \\textit{visual features} used in model predictions, we identify spurious or core \\textit{neural features} (penultimate layer neurons of a robust model) via limited human supervision (e.g., using top 5 activating images per feature). We then show that these neural feature annotations {\\it generalize} extremely well to many more images {\\it without} any human supervision. We use the activation maps for these neural features as the soft masks to highlight spurious or core visual features. Using this methodology, we introduce the {\\it Salient Imagenet} dataset containing core and spurious masks for a large set of samples from Imagenet. Using this dataset, we show that several popular Imagenet models rely heavily on various spurious features in their predictions, indicating the standard accuracy alone is not sufficient to fully assess model' performance specially in safety-critical applications. Code is available at \\url{https://github.com/singlasahil14/salient_imagenet}.",
    "One-sentence Summary": "A scalable framework for discovering spurious features of deep neural networks"
  },
  {
    "title": "Differentiable DAG Sampling",
    "url": "/forum?id=9wOQOgNe-w",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "DAG, Differentiable, Sampling, Probabilistic model",
    "Abstract": "We propose a new differentiable probabilistic model over DAGs (DP-DAG). DP-DAG allows fast and differentiable DAG sampling suited to continuous optimization. To this end, DP-DAG samples a DAG by successively (1) sampling a linear ordering of the node and (2) sampling edges consistent with the sampled linear ordering. We further propose VI-DP-DAG, a new method for DAG learning from observational data which combines DP-DAG with variational inference. Hence,VI-DP-DAG approximates the posterior probability over DAG edges given the observed data. VI-DP-DAG is guaranteed to output a valid DAG at any time during training and does not require any complex augmented Lagrangian optimization scheme in contrast to existing differentiable DAG learning approaches. In our extensive experiments, we compare VI-DP-DAG to other differentiable DAG learning baselines on synthetic and real datasets. VI-DP-DAG significantly improves DAG structure and causal mechanism learning while training faster than competitors."
  },
  {
    "title": "Evaluating Model-Based Planning and Planner Amortization for Continuous Control",
    "url": "/forum?id=SS8F6tFX3-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Model-based Reinforcement Learning, Planning, Robotics, Model Predictive Control, Learning",
    "Abstract": "There is a widespread intuition that model-based control methods should be able to surpass the data efficiency of model-free approaches. In this paper we attempt to evaluate this intuition on various challenging locomotion tasks. We take a hybrid approach, combining model predictive control (MPC) with a learned model and model-free policy learning; the learned policy serves as a proposal for MPC. We show that MPC with learned proposals and models (trained on the fly or transferred from related tasks) can significantly improve performance and data efficiency with respect to model-free methods. However, we find that well-tuned model-free agents are strong baselines even for high DoF control problems. Finally, we show that it is possible to distil a model-based planner into a policy that amortizes the planning computation without any loss of performance.",
    "One-sentence Summary": "We combine MPC with model-free RL and evaluate on continuous control tasks from scratch and in transfer settings; our results show that model-free RL is a strong baseline in single task settings and model-based methods shine in multi-goal tasks."
  },
  {
    "title": "Hierarchical Few-Shot Imitation with Skill Transition Models",
    "url": "/forum?id=xKZ4K0lTj_",
    "date": "28 Sept 2021 (modified: 22 Nov 2021)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "behavioral priors, skill extraction, imitation learning, few-shot learning",
    "Abstract": "A desirable property of autonomous agents is the ability to both solve long-horizon problems and generalize to unseen tasks. Recent advances in data-driven skill learning have shown that extracting behavioral priors from offline data can enable agents to solve challenging long-horizon tasks with reinforcement learning. However, generalization to tasks unseen during behavioral prior training remains an outstanding challenge. To this end, we present Few-shot Imitation with Skill Transition Models (FIST), an algorithm that extracts skills from offline data and utilizes them to generalize to unseen tasks given a few downstream demonstrations. FIST learns an inverse skill dynamics model, a distance function, and utilizes a semi-parametric approach for imitation. We show that FIST is capable of generalizing to new tasks and substantially outperforms prior baselines in navigation experiments requiring traversing unseen parts of a large maze and 7-DoF robotic arm experiments requiring manipulating previously unseen objects in a kitchen.",
    "One-sentence Summary": "We introduce a new algorithm (FIST) which extracts skills from offline data and adapts them in few-shot to solve unseen complex long-horizon tasks by utilizing an inverse skill dynamics model and semi-parametric imitation."
  },
  {
    "title": "End-to-End Learning of Probabilistic Hierarchies on Graphs",
    "url": "/forum?id=g2LCQwG7Of",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "hierarchical clustering, graphs, networks, graph mining, network mining, graph custering",
    "Abstract": "We propose a novel probabilistic model over hierarchies on graphs obtained by continuous relaxation of tree-based hierarchies. We draw connections to Markov chain theory, enabling us to perform hierarchical clustering by efficient end-to-end optimization of relaxed versions of quality metrics such as Dasgupta cost or Tree-Sampling Divergence (TSD). \n        We show that our model learns rich, high-quality hierarchies present in 11 real world graphs, including a large  graph with 2.3M nodes. Our model consistently outperforms recent as well as strong traditional baselines such as average linkage. \n        Our model also obtains strong results on link prediction despite not being trained on this task, highlighting the quality of the hierarchies discovered by our model.",
    "One-sentence Summary": "End-to-end gradient-based hierarchical clustering on graphs by exploiting Markov chain theory leads to state-of-the-art results."
  },
  {
    "title": "GeneDisco: A Benchmark for Experimental Design in Drug Discovery",
    "url": "/forum?id=-w2oomO6qgc",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "batch active learning, drug discovery, benchmark",
    "Abstract": "In vitro cellular experimentation with genetic interventions, using for example CRISPR technologies, is an essential step in early-stage drug discovery and target validation that serves to assess initial hypotheses about causal associations between biological mechanisms and disease pathologies. With billions of potential hypotheses to test, the experimental design space for in vitro genetic experiments is extremely vast, and the available experimental capacity - even at the largest research institutions in the world - pales in relation to the size of this biological hypothesis space. Machine learning methods, such as active and reinforcement learning, could aid in optimally exploring the vast biological space by integrating prior knowledge from various information sources as well as extrapolating to yet unexplored areas of the experimental design space based on available data. However, there exist no standardised benchmarks and data sets for this challenging task and little research has been conducted in this area to date. Here, we introduce GeneDisco, a benchmark suite for evaluating active learning algorithms for experimental design in drug discovery. GeneDisco contains a curated set of multiple publicly available experimental data sets as well as open-source implementations of state-of-the-art active learning policies for experimental design and exploration.",
    "One-sentence Summary": "A comprehensive benchmark for batch active learning in drug discovery."
  },
  {
    "title": "GraphENS: Neighbor-Aware Ego Network Synthesis for Class-Imbalanced Node Classification",
    "url": "/forum?id=MXEl7i-iru",
    "date": "28 Sept 2021 (modified: 18 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep learning, Node classification, Class imbalance, Data Augmentation",
    "Abstract": "In many real-world node classification scenarios, nodes are highly class-imbalanced, where graph neural networks (GNNs) can be readily biased to major class instances. Albeit existing class imbalance approaches in other domains can alleviate this issue to some extent, they do not consider the impact of message passing between nodes. In this paper, we hypothesize that overfitting to the neighbor sets of minor class due to message passing is a major challenge for class-imbalanced node classification. To tackle this issue, we propose GraphENS, a novel augmentation method that synthesizes the whole ego network for minor class (minor node and its one-hop neighbors) by combining two different ego networks based on their similarity. Additionally, we introduce a saliency-based node mixing method to exploit the abundant class-generic attributes of other nodes while blocking the injection of class-specific features. Our approach consistently outperforms the baselines over multiple node classification benchmark datasets and architectures."
  },
  {
    "title": "Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization",
    "url": "/forum?id=hcQHRHKfN_",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "diverse behavior, deep reinforcement learning, multi-agent reinforcement learning",
    "Abstract": "We present Reward-Switching Policy Optimization (RSPO), a paradigm to discover diverse strategies in complex RL environments by iteratively finding novel policies that are both locally optimal and sufficiently different from existing ones. To encourage the learning policy to consistently converge towards a previously undiscovered local optimum, RSPO switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. When a sampled trajectory is sufficiently distinct, RSPO performs standard policy optimization with extrinsic rewards. For trajectories with high likelihood under existing policies, RSPO utilizes an intrinsic diversity reward to promote exploration. Experiments show that RSPO is able to discover a wide spectrum of strategies in a variety of domains, ranging from single-agent navigation tasks and MuJoCo control to multi-agent stag-hunt games and the StarCraft II Multi-Agent Challenge.",
    "One-sentence Summary": "We propose Reward-Switching Policy Optimization (RSPO), a paradigm to discover diverse strategies in complex RL environments by iteratively finding novel policies that are both locally optimal and sufficiently different from existing ones."
  },
  {
    "title": "Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting",
    "url": "/forum?id=wwDg3bbYBIq",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Traffic Forecasting, Deep Learning",
    "Abstract": "Traffic forecasting is a challenging problem due to complex road networks and sudden speed changes caused by various events on roads. Several models have been proposed to solve this challenging problem, with a focus on learning the spatio-temporal dependencies of roads. In this work, we propose a new perspective for converting the forecasting problem into a pattern-matching task, assuming that large traffic data can be represented by a set of patterns. To evaluate the validity of this new perspective, we design a novel traffic forecasting model called Pattern-Matching Memory Networks (PM-MemNet), which learns to match input data to representative patterns with a key-value memory structure. We first extract and cluster representative traffic patterns that serve as keys in the memory. Then, by matching the extracted keys and inputs, PM-MemNet acquires the necessary information on existing traffic patterns from the memory and uses it for forecasting. To model the spatio-temporal correlation of traffic, we proposed a novel memory architecture, GCMem, which integrates attention and graph convolution. The experimental results indicate that PM-MemNet is more accurate than state-of-the-art models, such as Graph WaveNet, with higher responsiveness. We also present a qualitative analysis describing how PM-MemNet works and achieves higher accuracy when road speed changes rapidly.",
    "One-sentence Summary": "We presents a novel graph convolutional memory network, PM-MemNet, for the traffic forecasting."
  },
  {
    "title": "Why Propagate Alone? Parallel Use of Labels and Features on Graphs",
    "url": "/forum?id=VTNjxbFRKly",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "One of the challenges of graph-based semi-supervised learning over ordinary supervised learning for classification tasks lies in label utilization.  The direct use of ground-truth labels in graphs for training purposes can result in a parametric model learning trivial degenerate solutions (e.g., an identity mapping from input to output).  In addressing this issue, a label trick has recently been proposed in the literature and applied to a wide range of graph neural network (GNN) architectures, achieving state-of-the-art results on various datasets.  The essential idea is to randomly split the observed labels on the graph and use a fraction of them as input to the model (along with original node features), and predict the remaining fraction.  Despite its success in enabling GNNs to propagate features and labels simultaneously, this approach has never been analyzed from a theoretical perspective, nor fully explored across certain natural use cases.  In this paper, we demonstrate that under suitable settings, this stochastic trick can be reduced to a more interpretable deterministic form, allowing us to better explain its behavior, including an emergent regularization effect, and motivate broader application scenarios.  Our experimental results corroborate these analyses while also demonstrating improved node classification performance applying the label trick in new domains.",
    "One-sentence Summary": "We analyze a powerful label trick from a theoretical perspective and reduce it to an interpretable form that inspires broader application scenarios."
  },
  {
    "title": "Learning by Directional Gradient Descent",
    "url": "/forum?id=5i7lJLuhTm",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "credit assignment, directional derivative, recurrent networks",
    "Abstract": "How should state be constructed from a sequence of observations, so as to best achieve some objective? Most deep learning methods update the parameters of the state representation by gradient descent. However, no prior method for computing the gradient is fully satisfactory, for example consuming too much memory, introducing too much variance, or adding too much bias. In this work, we propose a new learning algorithm that addresses these limitations. The basic idea is to update the parameters of the representation by using the directional derivative along a candidate direction, a quantity that may be computed online with the same computational cost as the representation itself. We consider several different choices of candidate direction, including random selection and approximations to the true gradient, and investigate their performance on several synthetic tasks.",
    "One-sentence Summary": "Computing directional derivative of a recurrent function along a candidate direction, and using it to create a valid descent direction."
  },
  {
    "title": "Maximum Entropy RL (Provably) Solves Some Robust RL Problems",
    "url": "/forum?id=PtSAD3caaA2",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, robustness, maximum entropy",
    "Abstract": "Many potential applications of reinforcement learning (RL) require guarantees that the agent will perform well in the face of disturbances to the dynamics or reward function. In this paper, we prove theoretically that maximum entropy (MaxEnt) RL maximizes a lower bound on a robust RL objective, and thus can be used to learn policies that are robust to some disturbances in the dynamics and the reward function. While this capability of MaxEnt RL has been observed empirically in prior work, to the best of our knowledge our work provides the first rigorous proof and theoretical characterization of the MaxEnt RL robust set. While a number of prior robust RL algorithms have been designed to handle similar disturbances to the reward function or dynamics, these methods typically require additional moving parts and hyperparameters on top of a base RL algorithm. In contrast, our results suggest that MaxEnt RL by itself is robust to certain disturbances, without requiring any additional modifications. While this does not imply that MaxEnt RL is the best available robust RL method, MaxEnt RL is a simple robust RL method with appealing formal guarantees.",
    "One-sentence Summary": "Maximum Entropy RL (provably) solves some robust RL problems."
  },
  {
    "title": "A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training",
    "url": "/forum?id=XhF2VOMRHS",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generative Models, Energy-based Models, Sampling, Adversarial Training",
    "Abstract": "Adversarial Training (AT) is known as an effective approach to enhance the robustness of deep neural networks. Recently researchers notice that robust models with AT have good generative ability and can synthesize realistic images, while the reason behind it is yet under-explored. In this paper, we demystify this phenomenon by developing a unified probabilistic framework, called Contrastive Energy-based Models (CEM). On the one hand, we provide the first probabilistic characterization of AT through a unified understanding of robustness and generative ability. On the other hand, our unified framework can be extended to the unsupervised scenario, which interprets unsupervised contrastive learning as an important sampling of CEM. Based on these, we propose a principled method to develop adversarial learning and sampling methods. Experiments show that the sampling methods derived from our framework improve the sample quality in both supervised and unsupervised learning. Notably, our unsupervised adversarial sampling method achieves an Inception score of 9.61 on CIFAR-10, which is superior to previous energy-based models and comparable to state-of-the-art generative models."
  },
  {
    "title": "Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks",
    "url": "/forum?id=e95i1IHcWj",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Network, Spectral Graph Theory, System Stability",
    "Abstract": "Graph neural networks (GNN) have shown great advantages in many graph-based learning tasks but often fail to predict accurately for a task-based on sets of nodes such as link/motif prediction and so on.  Many works have recently proposed to address this problem by using random node features or node distance features. However, they suffer from either slow convergence, inaccurate prediction, or high complexity. In this work, we revisit GNNs that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable.  Here, we study these issues in a principled way and propose a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original node features and rotation equivariance w.r.t. the positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability. Code is available at https://github.com/Graph-COM/PEG."
  },
  {
    "title": "BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models",
    "url": "/forum?id=Mng8CQ9eBW",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Pre-trained Natural Language Processing (NLP) models, which can be adapted to a variety of downstream language tasks via fine-tuning, highly accelerate the learning progress of NLP models. However, NLP models have been shown to be vulnerable to backdoor attacks. Previous NLP backdoor attacks mainly focus on one specific task. This limitation makes existing solutions less applicable to different NLP models which have been widely used in various tasks.\n        In this work, we propose BadPre, the first backdoor attack against various downstream models built based on pre-trained NLP models. BadPre can launch trojan attacks against different language tasks with the same trigger.\n        The key insight of our approach is that downstream models can inherit the security characteristics from the pre-trained models. Specifically, we leverage data posing to the pre-trained NLP models and then inference the downstream models with sentences embedded triggers. Furthermore, to fool backdoor detectors, we design a novel adversarial attack method to generate a more robust trigger.\n        Experimental results indicate that our approach can effectively attack a wide range of downstream NLP tasks and exhibit significant robustness against backdoor detectors."
  },
  {
    "title": "Shallow and Deep Networks are Near-Optimal Approximators of Korobov Functions",
    "url": "/forum?id=AV8FPoMTTa",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "In this paper, we analyze the number of neurons and training parameters that a neural network needs to approximate multivariate functions of bounded second mixed derivatives --- Korobov functions. We prove upper bounds on these quantities for shallow and deep neural networks, drastically lessening the curse of dimensionality. Our bounds hold for general activation functions, including ReLU. We further prove that these bounds nearly match the minimal number of parameters any continuous function approximator needs to approximate Korobov functions, showing that neural networks are near-optimal function approximators.",
    "One-sentence Summary": "We analyze the number of neurons and training parameters that a neural network needs to approximate multivariate functions of bounded second mixed derivatives"
  },
  {
    "title": "What Makes Better Augmentation Strategies? Augment Difficult but Not too Different",
    "url": "/forum?id=Ucx3DQbC9GH",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "NLP, data augmentation, learning augmentation policy, text classification",
    "Abstract": "The practice of data augmentation has been extensively used to boost the performance of deep neural networks for various NLP tasks. It is more effective when only a limited number of labeled samples is available, e.g., low-data or class-imbalanced regimes. Most current augmentation techniques rely on parameter tuning or inherent randomness; hence, their effectiveness largely varies on the tasks. To efficiently find the best augmentation strategy for each task, learning data augmentation policy is a promising solution, but the question of what makes a good augmentation in NLP tasks and how to design the reward function for learning a good policy remains under-explored. To answer this, we hypothesize that good data augmentation should construct more diverse and challenging samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples. Therefore, we design a novel reward function for updating the augmentation policy to construct difficult but not too different samples (DND). Particularly, we jointly optimize a data augmentation policy while training the model, to construct the augmented samples with low confidence but a high semantic similarity with original ones. In addition, we introduce a sample re-weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. Our learning-based augmentation outperforms the recent state-of-the-art augmentation schemes on various text classification tasks and GLUE benchmark by successfully discovering the effective augmentations for each task. Remarkably, our method is more effective on the challenging low-data and class-imbalanced regimes, and the learned augmentation policy is well-transferable to the different tasks and models.",
    "One-sentence Summary": "Effective learning-based augmentation in NLP tasks by constructing difficult but not too different samples"
  },
  {
    "title": "Generative Pseudo-Inverse Memory",
    "url": "/forum?id=Harn4_EZBw",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We propose Generative Pseudo-Inverse Memory (GPM), a class of deep generative memory models that are fast to write in and read out. Memory operations are recast as seeking robust solutions of linear systems, which naturally lead to the use of matrix pseudo-inverses. The pseudo-inverses are iteratively approximated, with practical computation complexity of almost $O(1)$. We prove theoretically and verify empirically that our model can retrieve exactly what have been written to the memory under mild conditions. A key capability of GPM is iterative reading, during which the attractor dynamics towards fixed points are enabled, allowing the model to iteratively improve sample quality in denoising and generating. More impressively, GPM can store a large amount of data while maintaining key abilities of accurate retrieving of stored patterns, denoising of corrupted data and generating novel samples. Empirically we demonstrate the efficiency and versatility of GPM on a comprehensive suite of experiments involving binarized MNIST, binarized Omniglot, FashionMNIST, CIFAR10 & CIFAR100 and CelebA."
  },
  {
    "title": "A Deep Variational Approach to Clustering Survival Data",
    "url": "/forum?id=RQ428ZptQfU",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "survival analysis, clustering, healthcare, variational autoencoders, deep generative models",
    "Abstract": "In this work, we study the problem of clustering survival data \u2014 a challenging and so far under-explored task. We introduce a novel semi-supervised probabilistic approach to cluster survival data by leveraging recent advances in stochastic gradient variational inference. In contrast to previous work, our proposed method employs a deep generative model to uncover the underlying distribution of both the explanatory variables and censored survival times. We compare our model to the related work on clustering and mixture models for survival data in comprehensive experiments on a wide range of synthetic, semi-synthetic, and real-world datasets, including medical imaging data. Our method performs better at identifying clusters and is competitive at predicting survival times. Relying on novel generative assumptions, the proposed model offers a holistic perspective on clustering survival data and holds a promise of discovering subpopulations whose survival is regulated by different generative mechanisms.",
    "One-sentence Summary": "We introduce a novel semi-supervised probabilistic approach to cluster survival data"
  },
  {
    "title": "GPT-Critic: Offline Reinforcement Learning for End-to-End Task-Oriented Dialogue Systems",
    "url": "/forum?id=qaxhBG1UUaS",
    "date": "28 Sept 2021 (modified: 19 Apr 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "task-oriented dialogue, pre-trained language model, offline reinforcement learning",
    "Abstract": "Training a task-oriented dialogue agent can be naturally formulated as offline reinforcement learning (RL) problem, where the agent aims to learn a conversational strategy to achieve user goals, only from a dialogue corpus. It is very challenging in terms of RL since the natural language action space is astronomical, while feasible (syntactically and semantically correct) actions are very sparse. Thus, standard RL methods easily fail and generate responses diverging from human language, even when fine-tuning a powerful pre-trained language model. In this paper, we introduce GPT-Critic, an offline RL method for task-oriented dialogue. GPT-Critic is built upon GPT-2, fine-tuning the language model through behavior cloning of the critic-guided self-generated sentences. GPT-Critic is essentially free from the issue of diverging from human language since it learns from the sentences sampled from the pre-trained language model. In the experiments, we demonstrate that our algorithm outperforms the state-of-the-art in the task-oriented dialogue benchmarks including MultiWOZ 2.0 and ConvLab."
  },
  {
    "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization",
    "url": "/forum?id=JtBRnrlOEFN",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "transformers, NLP, language",
    "Abstract": "State-of-the-art models in natural language processing rely on separate rigid subword tokenization algorithms, which limit their generalization ability and adaptation to new settings. In this paper, we propose a new model inductive bias that learns a subword tokenization end-to-end as part of the model. To this end, we introduce a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. Concretely, GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. We additionally introduce Charformer, a deep Transformer model that integrates GBST and operates on the character level. Via extensive experiments on English GLUE, multilingual, and noisy text datasets, we show that Charformer outperforms a series of competitive character-level baselines while generally performing on par and sometimes outperforming subword-based models. Additionally, Charformer is fast, improving the speed of vanilla character-level Transformers by up to  while maintaining quality. We believe this work paves the way for highly performant token-free models that are trained completely end-to-end.",
    "One-sentence Summary": "Fast Token-Free Models"
  },
  {
    "title": "Regularized Autoencoders for Isometric Representation Learning",
    "url": "/forum?id=mQxt8l7JL04",
    "date": "28 Sept 2021 (modified: 01 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Autoencoders, Manifold Learning, Regularization, Geometry, Distortion",
    "Abstract": "The recent success of autoencoders for representation learning can be traced in large part to the addition of a regularization term.\n        Such regularized autoencoders ``constrain\" the representation so as to prevent overfitting to the data while producing a parsimonious generative model. A regularized autoencoder should in principle learn not only the data manifold, but also a set of geometry-preserving coordinates for the latent representation space; by geometry-preserving we mean that the latent space representation should attempt to preserve actual distances and angles on the data manifold. In this paper we first formulate a hierarchy for geometry-preserving mappings (isometry, conformal mapping of degree $k$, area-preserving mappings). We then show that a conformal regularization term of degree zero -- i.e., one that attempts to preserve angles and relative distances, instead of angles and exact distances -- produces data representations that are superior to other existing methods. Applying our algorithm to an unsupervised information retrieval task for CelebA data with 40 annotations, we achieve 79\\% precision at five retrieved images, an improvement of more than 10\\% compared to recent related work. Code is available at https://github.com/Gabe-YHLee/IRVAE-public.",
    "One-sentence Summary": "Regularized Autoencoders that simultaneously learn data manifold and a set of latent space coordinates that preserves the geometry of the learned manifold."
  },
  {
    "title": "Knowledge Removal in Sampling-based Bayesian Inference",
    "url": "/forum?id=dTqOcTUOQO",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Bayesian inference, Markov chain Monte Carlo, machine unlearning",
    "Abstract": "The right to be forgotten has been legislated in many countries, but its enforcement in the AI industry would cause unbearable costs. When single data deletion requests come, companies may need to delete the whole models learned with massive resources. Existing works propose methods to remove knowledge learned from data for explicitly parameterized models, which however are not appliable to the sampling-based Bayesian inference, {\\it i.e.}, Markov chain Monte Carlo (MCMC), as MCMC can only infer implicit distributions. In this paper, we propose the first machine unlearning algorithm for MCMC. We first convert the MCMC unlearning problem into an explicit optimization problem. Based on this problem conversion, an {\\it MCMC influence function} is designed to provably characterize the learned knowledge from data, which then delivers the MCMC unlearning algorithm. Theoretical analysis shows that MCMC unlearning would not compromise the generalizability of the MCMC models. Experiments on Gaussian mixture models and Bayesian neural networks confirm the effectiveness of the proposed algorithm. The code is available at \\url{https://github.com/fshp971/mcmc-unlearning}.",
    "One-sentence Summary": "This paper proposes the first machine unlearning algorithm for MCMC."
  },
  {
    "title": "Actor-critic is implicitly biased towards high entropy optimal policies",
    "url": "/forum?id=vEZyTBRPP6o",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "implicit bias, reinforcement learning, actor-critic, policy gradient, mixing time, convergence rate, mirror ascent.",
    "Abstract": "We show that the simplest actor-critic method \u2014 a linear softmax policy updated with TD through interaction with a linear MDP, but featuring no explicit regularization or exploration \u2014 does not merely find an optimal policy, but moreover prefers high entropy optimal policies. To demonstrate the strength of this bias, the algorithm not only has no regularization, no projections, and no exploration like $\\epsilon$-greedy, but is moreover trained on a single trajectory with no resets. The key consequence of the high entropy bias is that uniform mixing assumptions on the MDP, which exist in some form in all prior work, can be dropped: the implicit regularization of the high entropy bias is enough to ensure that all chains mix and an optimal policy is reached with high probability. As auxiliary contributions, this work decouples concerns between the actor and critic by writing the actor update as an explicit mirror descent, provides tools to uniformly bound mixing times within KL balls of policy space, and provides a projection-free TD analysis with its own implicit bias which can be run from an unmixed starting distribution.",
    "One-sentence Summary": "We show that actor-critic, without any explicit exploration or regularization, can obtain an $\\epsilon$-optimal high entropy policy in $\\text{poly}(1/\\epsilon)$ samples via a single trajectory without the usual uniform mixing assumptions."
  },
  {
    "title": "Igeood: An Information Geometry Approach to Out-of-Distribution Detection",
    "url": "/forum?id=mfwdY3U_9ea",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "out-of-distribution detection, anomaly detection, deep learning",
    "Abstract": "Reliable out-of-distribution (OOD) detection is fundamental to implementing safer modern machine learning (ML)  systems. In this paper, we introduce Igeood, an effective method for detecting OOD samples. Igeood applies to any pre-trained neural network, works under various degrees of access to the ML model, does not require OOD samples or assumptions on the OOD data but can also benefit (if available) from OOD samples. By building on the geodesic (Fisher-Rao) distance between the underlying data distributions, our discriminator can combine confidence scores from the logits outputs and the learned features of a deep neural network. Empirically, we show that Igeood outperforms competing state-of-the-art methods on a variety of network architectures and datasets.",
    "One-sentence Summary": "We propose a flexible and effective out-of-distribution detection method by building on the Fisher-Rao distance between probability distributions."
  },
  {
    "title": "Bag of Instances Aggregation Boosts Self-supervised Distillation",
    "url": "/forum?id=N0uJGWDw21d",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-supervised learning, knowledge distillation, instance bagging",
    "Abstract": "Recent advances in self-supervised learning have experienced remarkable progress, especially for contrastive learning based methods, which regard each image as well as its augmentations as an individual class and try to distinguish them from all other images. However, due to the large quantity of exemplars, this kind of pretext task intrinsically suffers from slow convergence and is hard for optimization. This is especially true for small-scale models, in which we find the performance drops dramatically comparing with its supervised counterpart. In this paper, we propose a simple but effective distillation strategy for unsupervised learning. The highlight is that the relationship among similar samples counts and can be seamlessly transferred to the student to boost the performance. Our method, termed as BINGO, which is short for Bag of InstaNces aGgregatiOn, targets at transferring the relationship learned by the teacher to the student. Here bag of instances indicates a set of similar samples constructed by the teacher and are grouped within a bag, and the goal of distillation is to aggregate compact representations over the student with respect to instances in a bag. Notably, BINGO achieves new state-of-the-art performance on small-scale models, i.e., 65.5% and 68.9% top-1 accuracies with linear evaluation on ImageNet, using ResNet-18 and ResNet-34 as the backbones respectively, surpassing baselines (52.5% and 57.4% top-1 accuracies) by a significant margin. The code is available at https://github.com/haohang96/bingo.",
    "One-sentence Summary": "This paper proposes a new self-supervised distillation method which aggregates related instances bagged by the teacher and shows stronger performance than previous relation-agnostic methods."
  },
  {
    "title": "Stability Regularization for Discrete Representation Learning",
    "url": "/forum?id=6tmjoym9LR6",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We present a method for training neural network models with discrete stochastic variables.\n        The core of the method is \\emph{stability regularization}, which is a regularization procedure based on the idea of noise stability developed in Gaussian isoperimetric theory in the analysis of Gaussian functions.\n        Stability regularization is method to make the output of continuous functions of Gaussian random variables close to discrete, that is binary or categorical, without the need for significant manual tuning.\n        The method allows control over the extent to which a Gaussian function's output is close to discrete, thus allowing for continued flow of gradient.\n        The method can be used standalone or in combination with existing continuous relaxation methods.\n        We validate the method in a broad range of experiments using discrete variables including neural relational inference, generative modeling, clustering and conditional computing."
  },
  {
    "title": "Unrolling PALM for Sparse Semi-Blind Source Separation",
    "url": "/forum?id=aBVxf5NaaRt",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Algorithm Unrolling/Unfolding, Blind Source Separation, Sparse Representations, Multi-Convex Optimization, Hyper-parameter Choice",
    "Abstract": "Sparse  Blind  Source  Separation  (BSS)  has  become  a  well  established  tool  for a  wide  range  of  applications  \u2013  for  instance,  in  astrophysics  and  remote  sensing.  Classical sparse BSS methods, such as the Proximal Alternating Linearized Minimization (PALM) algorithm, nevertheless often suffer from a difficult hyper-parameter choice, which undermines their results.  To bypass this pitfall, we propose in this work to build on the thriving field of algorithm unfolding/unrolling. Unrolling PALM enables to leverage the data-driven knowledge stemming from realistic simulations or ground-truth data by learning both PALM hyper-parameters and variables.  In contrast to most existing unrolled algorithms, which assume a fixed known dictionary during the training and testing phases, this article further emphasizes on the ability to deal with variable mixing matrices (a.k.a.  dictionaries).  The proposed Learned PALM (LPALM) algorithm thus enables to perform semi-blind source separation, which is key to increase the generalization of the learnt model in real-world applications. We illustrate the relevance of LPALM in astrophysical multispectral imaging: the algorithm not only needs up to $10^4\u221210^5$ times less iterations than PALM, but also improves the separation quality, while avoiding the cumbersome hyper-parameter and initialization choice of PALM. We further show that LPALM outperforms other unrolled source separation methods in the semi-blind setting."
  },
  {
    "title": "Fast Generic Interaction Detection for Model Interpretability and Compression",
    "url": "/forum?id=fQTlgI2qZqE",
    "date": "28 Sept 2021 (modified: 29 Jan 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "The ability of discovering feature interactions in a black-box model is vital to explainable deep learning. We propose a principled, global interaction detection method by casting our target as a multi-arm bandits problem and solving it swiftly with the UCB algorithm. This adaptive method is free of ad-hoc assumptions and among the cutting-edge methods with outstanding detection accuracy and stability. Based on the detection outcome, a lightweight and interpretable deep learning model (called ParaACE) is further built using the alternating conditional expectation (ACE) method. Our proposed ParaACE improves the prediction performance by 26 % and reduces the model size by 100+ times as compared to its Teacher model over various datasets. Furthermore, we show the great potential of our method for scientific discovery through interpreting various real datasets in the economics and smart medicine sectors. The code is available at https://github.com/zhangtj1996/ParaACE."
  },
  {
    "title": "Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift",
    "url": "/forum?id=cGDAkQo1C0p",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Time-series forecasting, Normalization, Distribution shift",
    "Abstract": "Statistical properties such as mean and variance often change over time in time series, i.e., time-series data suffer from a distribution shift problem. This change in temporal distribution is one of the main challenges that prevent accurate time-series forecasting. To address this issue, we propose a simple yet effective normalization method called reversible instance normalization (RevIN), a generally-applicable normalization-and-denormalization method with learnable affine transformation. The proposed method is symmetrically structured to remove and restore the statistical information of a time-series instance, leading to significant performance improvements in time-series forecasting, as shown in Fig. 1. We demonstrate the effectiveness of RevIN via extensive quantitative and qualitative analyses on various real-world datasets, addressing the distribution shift problem.",
    "One-sentence Summary": "We propose a simple yet effective normalization method, reversible instance normalization (RevIN), which solves the time-series forecasting task against the distribution shift problem."
  },
  {
    "title": "On the Pitfalls of Analyzing Individual Neurons in Language Models",
    "url": "/forum?id=8uz0EWPQIMu",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "NLP, interpretability, multilingual, individual neurons",
    "Abstract": "While many studies have shown that linguistic information is encoded in hidden word representations, few have studied individual neurons, to show how and in which neurons it is encoded.\n        Among these, the common approach is to use an external probe to rank neurons according to their relevance to some linguistic attribute, and to evaluate the obtained ranking using the same probe that produced it.\n        We show two pitfalls in this methodology:\n            1. It confounds distinct factors: probe quality and ranking quality.\n            We separate them and draw conclusions on each.\n            2. It focuses on encoded information, rather than information that is used by the model.\n            We show that these are not the same.\n        We compare two recent ranking methods and a simple one we introduce, and evaluate them with regard to both of these aspects.",
    "One-sentence Summary": "We analyze and compare methods to rank neurons in hidden representations according to their relevance to morphologic attributes, and show some of their weaknesses."
  },
  {
    "title": "Query Embedding on Hyper-Relational Knowledge Graphs",
    "url": "/forum?id=4rLw09TgRw9",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Query embedding, Approximate Query Answering, Graph Neural Network, Hyper-relational Graph, Knowledge Graph",
    "Abstract": "Multi-hop logical reasoning is an established problem in the field of representation learning on knowledge graphs (KGs). It subsumes both one-hop link prediction as well as other more complex types of logical queries. Existing algorithms operate only on classical, triple-based graphs, whereas modern KGs often employ a hyper-relational modeling paradigm. In this paradigm, typed edges may have several key-value pairs known as qualifiers that provide fine-grained context for facts. In queries, this context modifies the meaning of relations, and usually reduces the answer set. Hyper-relational queries are often observed in real-world KG applications, and existing approaches for approximate query answering cannot make use of qualifier pairs. In this work, we bridge this gap and extend the multi-hop reasoning problem to hyper-relational KGs allowing to tackle this new type of complex queries. Building upon recent advancements in Graph Neural Networks and query embedding techniques, we study how to embed and answer hyper-relational conjunctive queries. Besides that, we propose a method to answer such queries and demonstrate in our experiments that qualifiers improve query answering on a diverse set of query patterns.",
    "One-sentence Summary": "We investigate how to extend the multi-hop reasoning problem to hyper-relational queries on knowledge graphs and consider methods for solving it."
  },
  {
    "title": "Neural Solvers for Fast and Accurate Numerical Optimal Control",
    "url": "/forum?id=m8bypnj7Yl5",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep Learning, Numerical Methods, Optimal Control",
    "Abstract": "Synthesizing optimal controllers for dynamical systems often involves solving optimization problems with hard real-time constraints. These constraints determine the class of numerical methods that can be applied: computationally expensive but accurate numerical routines are replaced by fast and inaccurate methods, trading inference time for solution accuracy. This paper provides techniques to improve the quality of optimized control policies given a fixed computational budget. We achieve the above via a hypersolvers approach, which hybridizes a differential equation solver and a neural network. The performance is evaluated in direct and receding-horizon optimal control tasks in both low and high dimensions, where the proposed approach shows consistent Pareto improvements in solution accuracy and control performance.",
    "One-sentence Summary": "We propose a hypersolvers approach for numerical optimal control which shows consistent Pareto improvements in solution accuracy and control performance."
  },
  {
    "title": "PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series",
    "url": "/forum?id=Ix_mh42xq5w",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Synthetic Time Series, GAN, Generative Modeling, Time Series, Forecasting",
    "Abstract": "Realistic synthetic time series data of sufficient length enables practical applications in time series modeling tasks, such as forecasting, but remains a challenge. In this paper we present PSA-GAN, a generative adversarial network (GAN) that generates long time series samples of high quality using progressive growing of GANs and self-attention. We show that PSA-GAN can be used to reduce the error in several downstream forecasting tasks over baselines that only use real data. We also introduce a Frechet-Inception Distance-like score for time series, Context-FID, assessing the quality of synthetic time series samples. We find that Context-FID is indicative for downstream performance. Therefore, Context-FID could be a useful tool to develop time series GAN models."
  },
  {
    "title": "ToM2C: Target-oriented Multi-agent Communication and Cooperation with Theory of Mind",
    "url": "/forum?id=2t7CkQXNpuq",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Theory of Mind, Target-oriented Multi-Agent Cooperation, Multi-agent Communication",
    "Abstract": "Being able to predict the mental states of others is a key factor to effective social interaction. It is also crucial for distributed multi-agent systems, where agents are required to communicate and cooperate. In this paper, we introduce such an important social-cognitive skill, i.e. Theory of Mind (ToM), to build socially intelligent agents who are able to communicate and cooperate effectively to accomplish challenging tasks. With ToM, each agent is capable of inferring the mental states and intentions of others according to its (local) observation. Based on the inferred states, the agents decide \"when'' and with \"whom'' to share their intentions. With the information observed, inferred, and received, the agents decide their sub-goals and reach a consensus among the team. In the end, the low-level executors independently take primitive actions to accomplish the sub-goals. We demonstrate the idea in two typical target-oriented multi-agent tasks: cooperative navigation and multi-sensor target coverage. The experiments show that the proposed model not only outperforms the state-of-the-art methods on reward and communication efficiency, but also shows good generalization across different scales of the environment."
  },
  {
    "title": "Better Supervisory Signals by Observing Learning Paths",
    "url": "/forum?id=Iog0djAdbHj",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Classification, Supervision, Knowledge Distillation",
    "Abstract": "Better-supervised models might have better performance. In this paper, we first clarify what makes for good supervision for a classification problem, and then explain two existing label refining methods, label smoothing and knowledge distillation, in terms of our proposed criterion. To further answer why and how better supervision emerges, we observe the learning path, i.e., the trajectory of the model's predictions during training, for each training sample. We find that the model can spontaneously refine \"bad\" labels through a \"zig-zag\" learning path, which occurs on both toy and real datasets. Observing the learning path not only provides a new perspective for understanding knowledge distillation, overfitting, and learning dynamics, but also reveals that the supervisory signal of a teacher network can be very unstable near the best points in training on real tasks. Inspired by this, we propose a new knowledge distillation scheme, Filter-KD, which improves downstream classification performance in various settings.",
    "One-sentence Summary": "A study of how and why teachers in knowledge distillation end up with better supervisory signals than the original labels."
  },
  {
    "title": "TAda! Temporally-Adaptive Convolutions for Video Understanding",
    "url": "/forum?id=izj68lUcBpt",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Video understanding, Action classification, Dynamic networks",
    "Abstract": "Spatial convolutions are widely used in numerous deep video models. It fundamentally assumes spatio-temporal invariance, i.e., using shared weights for every location in different frames. This work presents Temporally-Adaptive Convolutions (TAdaConv) for video understanding, which shows that adaptive weight calibration along the temporal dimension is an efficient way to facilitate modelling complex temporal dynamics in videos. Specifically, TAdaConv empowers the spatial convolutions with temporal modelling abilities by calibrating the convolution weights for each frame according to its local and global temporal context. Compared to previous temporal modelling operations, TAdaConv is more efficient as it operates over the convolution kernels instead of the features, whose dimension is an order of magnitude smaller than the spatial resolutions. Further, the kernel calibration brings an increased model capacity. We construct TAda2D and TAdaConvNeXt networks by replacing the 2D convolutions in ResNet and ConvNeXt with TAdaConv, which leads to at least on par or better performance compared to state-of-the-art approaches on multiple video action recognition and localization benchmarks. We also demonstrate that as a readily plug-in operation with negligible computation overhead, TAdaConv can effectively improve many existing video models with a convincing margin.",
    "One-sentence Summary": "A stand-alone temporal modelling module or a plug-in enhancement of the 1D/2D/3D convolutions used in video models for better and more efficient temporal modelling."
  },
  {
    "title": "Learning a subspace of policies for online adaptation in Reinforcement Learning",
    "url": "/forum?id=4Muj-t_4o4",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep Reinforcement Learning, Online adaptation",
    "Abstract": "Deep Reinforcement Learning (RL) is mainly studied in a setting where the training and the testing environments are similar. But in many practical applications, these environments may differ. For instance, in control systems, the robot(s) on which a policy is learned might differ from the robot(s) on which a policy will run. It can be caused by different internal factors (e.g., calibration issues, system attrition, defective modules) or also by external changes (e.g., weather conditions). There is  a need to develop RL methods that generalize well to variations of the training conditions. In this article, we consider the simplest yet hard to tackle generalization setting where the test environment is unknown at train time, forcing the agent to adapt to the system's new dynamics. This online adaptation process can be computationally expensive (e.g., fine-tuning) and cannot rely on meta-RL techniques since there is just a single train environment. To do so, we propose an approach where we learn a subspace of policies within the parameter space. This subspace contains an infinite number of policies that are trained to solve the training environment while having different parameter values. As a consequence, two policies in that subspace process information differently and exhibit different behaviors when facing variations of the train environment. Our experiments carried out over a large variety of benchmarks compare our approach with baselines, including diversity-based methods. In comparison, our approach is simple to tune, does not need any extra component  (e.g., discriminator) and learns policies able to gather a high reward on unseen environments.",
    "One-sentence Summary": "We propose an approach to learn a subspace of policies that are robust to different variations of the train environment."
  },
  {
    "title": "ZeroFL: Efficient On-Device Training for  Federated Learning with Local Sparsity",
    "url": "/forum?id=2sDQwC_hmnM",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, sparse training",
    "Abstract": "When the available hardware cannot meet the memory and compute requirements to efficiently train high performing machine learning models, a compromise in either the training quality or the model complexity is needed. In Federated Learning (FL), nodes are orders of magnitude more constrained than traditional server-grade hardware and are often battery powered, severely limiting the sophistication of models that can be trained under this paradigm. While most research has focused on designing better aggregation strategies to improve convergence rates and in alleviating the communication costs of FL, fewer efforts have been devoted to accelerating on-device training. Such stage, which repeats hundreds of times (i.e. every round) and can involve thousands of devices, accounts for the majority of the time required to train federated models and, the totality of the energy consumption at the client side. In this work, we present the first study on the unique aspects that arise when introducing sparsity at training time in FL workloads. We then propose ZeroFL, a framework that relies on highly sparse operations to accelerate on-device training. Models trained with ZeroFL and 95% sparsity achieve up to 2.3% higher accuracy compared to competitive baselines obtained from adapting a state-of-the-art sparse training framework to the FL setting.",
    "One-sentence Summary": "This work studies the challenges of accelerating on-device training in Federated Learning workloads by using highly sparse operations, with our framework we achieve lower accuracy degradation in addition to reducing the uplink communication costs."
  },
  {
    "title": "Gaussian Mixture Convolution Networks",
    "url": "/forum?id=Oxeka7Z7Hor",
    "date": "28 Sept 2021 (modified: 18 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep learning architecture, gaussian convolution, gaussian mixture, 3d",
    "Abstract": "This paper proposes a novel method for deep learning based on the analytical convolution of multidimensional Gaussian mixtures.\n        In contrast to tensors, these do not suffer from the curse of dimensionality and allow for a compact representation, as data is only stored where details exist.\n        Convolution kernels and data are Gaussian mixtures with unconstrained weights, positions, and covariance matrices.\n        Similar to discrete convolutional networks, each convolution step produces several feature channels, represented by independent Gaussian mixtures.\n        Since traditional transfer functions like ReLUs do not produce Gaussian mixtures, we propose using a fitting of these functions instead.\n        This fitting step also acts as a pooling layer if the number of Gaussian components is reduced appropriately.\n        We demonstrate that networks based on this architecture reach competitive accuracy on Gaussian mixtures fitted to the MNIST and ModelNet data sets.",
    "One-sentence Summary": "Deep learning based on the analytical convolution of multi-dimensional Gaussian mixtures"
  },
  {
    "title": "How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning",
    "url": "/forum?id=bwq6O4Cwdl",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "SimSiam, Negative samples, SSL, Collapse, Covariance",
    "Abstract": "To avoid collapse in self-supervised learning (SSL), a contrastive loss is widely used but often requires a large number of negative samples. Without negative samples yet achieving competitive performance, a recent work~\\citep{chen2021exploring} has attracted significant attention for providing a minimalist simple Siamese (SimSiam) method to avoid collapse. However, the reason for how it avoids collapse without negative samples remains not fully clear and our investigation starts by revisiting the explanatory claims in the original SimSiam. After refuting their claims, we introduce vector decomposition for analyzing the collapse based on the gradient analysis of the $l_2$-normalized representation vector. This yields a unified perspective on how negative samples and SimSiam alleviate collapse. Such a unified perspective comes timely for understanding the recent progress in SSL."
  },
  {
    "title": "Attention-based Interpretability with Concept Transformers",
    "url": "/forum?id=kAa9eDS0RdO",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "attention, transformer, concepts, interpretability",
    "Abstract": "Attention is a mechanism that has been instrumental in driving remarkable performance gains of deep neural network models in a host of visual, NLP and multimodal tasks.\n        One additional notable aspect of attention is that it conveniently exposes the ``reasoning'' behind each particular output generated by the model.\n        Specifically, attention scores over input regions or intermediate features have been interpreted as a measure of the contribution of the attended element to the model inference.\n        While the debate in regard to the interpretability of attention is still not settled, researchers have pointed out the existence of architectures and scenarios that afford a meaningful interpretation of the attention mechanism.\n        \n        Here we propose the generalization of attention from low-level input features to high-level concepts as a mechanism to ensure the interpretability of attention scores within a given application domain.\n        In particular, we design the ConceptTransformer, a deep learning module that exposes explanations of the output of a model in which it is embedded in terms of attention over user-defined high-level concepts.\n        Such explanations are \\emph{plausible} (i.e.\\ convincing to the human user) and \\emph{faithful} (i.e.\\ truly reflective of the reasoning process of the model).\n        Plausibility of such explanations is obtained by construction by training the attention heads to conform with known relations between inputs, concepts and outputs dictated by domain knowledge.\n        Faithfulness is achieved by design by enforcing a linear relation between the transformer value vectors that represent the concepts and their contribution to the classification log-probabilities.\n        \n        We validate our ConceptTransformer module on established explainability benchmarks and show how it can be used to infuse domain knowledge into classifiers to improve accuracy, and conversely to extract concept-based explanations of classification outputs. Code to reproduce our results is available at: \\url{https://github.com/ibm/concept_transformer}.",
    "One-sentence Summary": "We the Concept Transformer an architecture that generalization attention from low-level input features to high-level concepts as a mechanism to ensure the interpretability of attention scores within a given application domain."
  },
  {
    "title": "Inductive Relation Prediction Using Analogy Subgraph Embeddings",
    "url": "/forum?id=PTRo58zPt3P",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Link Prediction, Relation Modelling, Heterogeneous Graphs, Knowledge Graphs",
    "Abstract": "Prevailing methods for relation prediction in heterogeneous graphs aim at learning latent representations (i.e., embeddings) of observed nodes and relations, and thus are limited to the transductive setting where the relation types must be known during training.  Here,  we propose ANalogy  SubGraphEmbeddingLearning (GraphANGEL), a novel relation prediction framework that predicts relations5between each node pair based on the subgraphs containing the pair, as well as other  (analogy)  subgraphs with the same graph patterns.   Each graph pattern explicitly represents a specific logical rule, which contributes to an inductive bias that facilitates generalization to unseen relations and leads to more explainable predictive models. Moreover, our method also removes the limited neighborhood constraint of graph neural networks. Our model consistently outperforms existing models on heterogeneous graph based recommendation as well as knowledge graph completion.  We also empirically demonstrate our model\u2019s capability in generalizing to new relations while producing explainable heat maps of attention scores across the discovered logic.",
    "One-sentence Summary": "In this paper, we propose GraphANGEL, a novel relation prediction framework that predicts (new) relations between each node pair by checking whether the subgraphs containing the pair are similar to other subgraphs containing the considered relation."
  },
  {
    "title": "Reinforcement Learning in Presence of Discrete Markovian Context Evolution",
    "url": "/forum?id=CmsfC7u054S",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "context-dependent Reinforcement Learning, model-based reinforcement learning, hierarchical Dirichlet process",
    "Abstract": "We consider a context-dependent Reinforcement Learning (RL) setting, which is characterized by: a) an unknown finite number of not directly observable contexts; b) abrupt (discontinuous) context changes occurring during an episode; and c) Markovian context evolution. We argue that this challenging case is often met in applications and we tackle it using a Bayesian model-based approach and variational inference. We adapt a sticky Hierarchical Dirichlet Process (HDP) prior for model learning, which is arguably best-suited for infinite Markov chain modeling. We then derive a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. We argue that the combination of these two components allows inferring the number of contexts from data thus dealing with the context cardinality assumption. We then find the representation of the optimal policy enabling efficient policy learning using off-the-shelf RL algorithms. Finally, we demonstrate empirically (using gym environments cart-pole swing-up, drone, intersection) that our approach succeeds where state-of-the-art methods of other frameworks fail and elaborate on the reasons for such failures."
  },
  {
    "title": "Optimal Transport for Long-Tailed Recognition with Learnable Cost Matrix",
    "url": "/forum?id=t98k9ePQQpn",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Long-tailed recognition, imbalanced classification, optimal transport",
    "Abstract": "It is attracting attention to the long-tailed recognition problem, a burning issue that has become very popular recently. Distinctive from conventional recognition is that it posits that the allocation of the training set is supremely distorted. Predictably, it will pose challenges to the generalisation behaviour of the model. Approaches to these challenges revolve into two groups: firstly, training-aware methods, with the aim of enhancing the generalisability of the model by exploiting its potential in the training period; and secondly, post-hoc correction, liberally coupled with training-aware methods, which is intended to refine the predictions to the extent possible in the post-processing stage, offering the advantages of simplicity and effectiveness. This paper introduces an alternative direction to do the post-hoc correction, which goes beyond the statistical methods. Mathematically, we approach this issue from the perspective of optimal transport (OT), yet, choosing the exact cost matrix when applying OT is challenging and requires expert knowledge of various tasks. To overcome this limitation, we propose to employ linear mapping to learn the cost matrix without necessary configurations adaptively. Testing our methods in practice, along with high efficiency and excellent performance, our method surpasses all previous methods and has the best performance to date.",
    "One-sentence Summary": "A new paradigm for post-hoc correction based on optimal transport to cope with long-tailed recognition."
  },
  {
    "title": "PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior",
    "url": "/forum?id=_BNiN4IjC5",
    "date": "28 Sept 2021 (modified: 20 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "diffusion-based model, generative model, speech synthesis",
    "Abstract": "Denoising diffusion probabilistic models have been recently proposed to generate high-quality samples by estimating the gradient of the data density. The framework assumes the prior noise as a standard Gaussian distribution, whereas the corresponding data distribution may be more complicated than the standard Gaussian distribution, which potentially introduces inefficiency in denoising the prior noise into the data sample because of the discrepancy between the data and the prior. In this paper, we propose PriorGrad to improve the efficiency of the conditional diffusion model (for example, a vocoder using a mel-spectrogram as the condition) by applying an adaptive prior derived from the data statistics based on the conditional information. We formulate the training and sampling procedures of PriorGrad and demonstrate the advantages of an adaptive prior through a theoretical analysis. Focusing on the audio domain, we consider the recently proposed diffusion-based audio generative models based on both the spectral and time domains and show that PriorGrad achieves faster convergence and superior performance, leading to an improved perceptual quality and tolerance to a smaller network capacity, and thereby demonstrating the efficiency of a data-dependent adaptive prior.",
    "One-sentence Summary": "We improve the efficiency of diffusion-based conditional generative models for audio by using data-dependent non-standard Gaussian as a prior."
  },
  {
    "title": "Target-Side Input Augmentation for Sequence to Sequence Generation",
    "url": "/forum?id=pz1euXohm4H",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
