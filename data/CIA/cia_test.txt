While the performance of NLP methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world’s ≈6,500 languages .
We introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in NLP .
Our analyses involve the field at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as foundational NLP tasks (dependency parsing, morphological inflection) .
In the process, we (1) quantify disparities in the current state of NLP research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidence-based policy making aimed at promoting more global and equitable language technologies .
Data and code to reproduce the findings discussed in this paper areavailable on GitHub (https://github.com/neubig/globalutility) .
We introduce CaMEL (Case Marker Extraction without Labels), a novel and challenging task in computational morphology that is especially relevant for low-resource languages .
We propose a first model for CaMEL that uses a massively multilingual corpus to extract case markers in 83 languages based only on a noun phrase chunker and an alignment system .
To evaluate CaMEL, we automatically construct a silver standard from UniMorph .
The case markers extracted by our model can be used to detect and visualise similarities and differences between the case systems of different languages as well as to annotate fine-grained deep cases in languages in which they are not overtly marked .
Robustness of machine learning models on ever-changing real-world data is critical, especially for applications affecting human well-being such as content moderation .
New kinds of abusive language continually emerge in online discussions in response to current events (e.g., COVID-19), and the deployed abuse detection systems should be updated regularly to remain accurate .
In this paper, we show that general abusive language classifiers tend to be fairly reliable in detecting out-of-domain explicitly abusive utterances but fail to detect new types of more subtle, implicit abuse .
Next, we propose an interpretability technique, based on the Testing Concept Activation Vector (TCAV) method from computer vision, to quantify the sensitivity of a trained model to the human-defined concepts of explicit and implicit abusive language, and use that to explain the generalizability of the model on new data, in this case, COVID-related anti-Asian hate speech .
Extending this technique, we introduce a novel metric, Degree of Explicitness, for a single instance and show that the new metric is beneficial in suggesting out-of-domain unlabeled examples to effectively enrich the training data with informative, implicitly abusive texts .
Reports of personal experiences or stories can play a crucial role in argumentation, as they represent an immediate and (often) relatable way to back up one’s position with respect to a given topic .
They are easy to understand and increase empathy: this makes them powerful in argumentation .
The impact of personal reports and stories in argumentation has been studied in the Social Sciences, but it is still largely underexplored in NLP .
Our work is the first step towards filling this gap: our goal is to develop robust classifiers to identify documents containing personal experiences and reports .
The main challenge is the scarcity of annotated data: our solution is to leverage existing annotations to be able to scale-up the analysis .
Our contribution is two-fold .
First, we conduct a set of in-domain and cross-domain experiments involving three datasets (two from Argument Mining, one from the Social Sciences), modeling architectures, training setups and fine-tuning options tailored to the involved domains .
We show that despite the differences among datasets and annotations, robust cross-domain classification is possible .
Second, we employ linear regression for performance mining, identifying performance trends both for overall classification performance and individual classifier predictions .
In recent years, neural models have often outperformed rule-based and classic Machine Learning approaches in NLG .
These classic approaches are now often disregarded, for example when new neural models are evaluated .
We argue that they should not be overlooked, since, for some tasks, well-designed non-neural approaches achieve better performance than neural ones .
In this paper, the task of generating referring expressions in linguistic context is used as an example .
We examined two very different English datasets (WEBNLG and WSJ), and evaluated each algorithm using both automatic and human evaluations.Overall, the results of these evaluations suggest that rule-based systems with simple rule sets achieve on-par or better performance on both datasets compared to state-of-the-art neural REG systems .
In the case of the more realistic dataset, WSJ, a machine learning-based system with well-designed linguistic features performed best .
We hope that our work can encourage researchers to consider non-neural models in future .
Text-to-SQL parsers map natural language questions to programs that are executable over tables to generate answers, and are typically evaluated on large-scale datasets like Spider (Yu et al., 2018) .
We argue that existing benchmarks fail to capture a certain out-of-domain generalization problem that is of significant practical importance: matching domain specific phrases to composite operation over columns .
To study this problem, we first propose a synthetic dataset along with a re-purposed train/test split of the Squall dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations, and find existing state-of-the-art parsers struggle in these benchmarks .
We propose to address this problem by incorporating prior domain knowledge by preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning .
This method can be easily applied to multiple existing base parsers, and we show that it significantly outperforms baseline parsers on this domain generalization problem, boosting the underlying parsers’ overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new Squall data split .
Paraphrase identification involves identifying whether a pair of sentences express the same or similar meanings .
While cross-encoders have achieved high performances across several benchmarks, bi-encoders such as SBERT have been widely applied to sentence pair tasks .
They exhibit substantially lower computation complexity and are better suited to symmetric tasks .
In this work, we adopt a bi-encoder approach to the paraphrase identification task, and investigate the impact of explicitly incorporating predicate-argument information into SBERT through weighted aggregation .
Experiments on six paraphrase identification datasets demonstrate that, with a minimal increase in parameters, the proposed model is able to outperform SBERT/SRoBERTa significantly .
Further, ablation studies reveal that the predicate-argument based component plays a significant role in the performance gain .
NER model has achieved promising performance on standard NER benchmarks .
However, recent studies show that previous approaches may over-rely on entity mention information, resulting in poor performance on out-of-vocabulary(OOV) entity recognition .
In this work, we propose MINER, a novel NER learning framework, to remedy this issue from an information-theoretic perspective .
The proposed approach contains two mutual information based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rotate memorizing entity names or exploiting biased cues in data .
Experiments on various settings and datasets demonstrate that it achieves better performance in predicting OOV entities .
Detecting biased language is useful for a variety of applications, such as identifying hyperpartisan news sources or flagging one-sided rhetoric .
In this work we introduce WikiEvolve, a dataset for document-level promotional tone detection .
Unlike previously proposed datasets, WikiEvolve contains seven versions of the same article from Wikipedia, from different points in its revision history; one with promotional tone, and six without it .
This allows for obtaining more precise training signal for learning models from promotional tone detection .
We adapt the previously proposed gradient reversal layer framework to encode two article versions simultaneously and thus leverage this additional training signal .
In our experiments, our proposed adaptation of gradient reversal improves the accuracy of four different architectures on both in-domain and out-of-domain evaluation .
Informal social interaction is the primordial home of human language .
Linguistically diverse conversational corpora are an important and largely untapped resource for computational linguistics and language technology .
Through the efforts of a worldwide language documentation movement, such corpora are increasingly becoming available .
We show how interactional data from 63 languages (26 families) harbours insights about turn-taking, timing, sequential structure and social action, with implications for language technology, natural language understanding, and the design of conversational interfaces .
Harnessing linguistically diverse conversational corpora will provide the empirical foundations for flexible, localizable, humane language technologies of the future .
Adversarial robustness has attracted much attention recently, and the mainstream solution is adversarial training .
However, the tradition of generating adversarial perturbations for each input embedding (in the settings of NLP) scales up the training computational complexity by the number of gradient steps it takes to obtain the adversarial samples .
To address this problem, we leverage Flooding method which primarily aims at better generalization and we find promising in defending adversarial attacks .
We further propose an effective criterion to bring hyper-parameter-dependent flooding into effect with a narrowed-down search space by measuring how the gradient steps taken within one epoch affect the loss of each batch .
Our approach requires zero adversarial sample for training, and its time consumption is equivalent to fine-tuning, which can be 2-15 times faster than standard adversarial training .
We experimentally show that our method improves BERT’s resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks .
Evaluating Natural Language Generation (NLG) systems is a challenging task .
Firstly, the metric should ensure that the generated hypothesis reflects the reference’s semantics .
Secondly, it should consider the grammatical quality of the generated sentence .
Thirdly, it should be robust enough to handle various surface forms of the generated sentence .
Thus, an effective evaluation metric has to be multifaceted .
In this paper, we propose an automatic evaluation metric incorporating several core aspects of natural language understanding (language competence, syntactic and semantic variation) .
Our proposed metric, RoMe, is trained on language features such as semantic similarity combined with tree edit distance and grammatical acceptability, using a self-supervised neural network to assess the overall quality of the generated sentence .
Moreover, we perform an extensive robustness analysis of the state-of-the-art methods and RoMe .
Empirical results suggest that RoMe has a stronger correlation to human judgment over state-of-the-art metrics in evaluating system-generated sentences across several NLG tasks .
In this work, we investigate the knowledge learned in the embeddings of multimodal-BERT models .
More specifically, we probe their capabilities of storing the grammatical structure of linguistic data and the structure learned over objects in visual data .
To reach that goal, we first make the inherent structure of language and visuals explicit by a dependency parse of the sentences that describe the image and by the dependencies between the object regions in the image, respectively .
We call this explicit visual structure the scene tree, that is based on the dependency tree of the language description .
Extensive probing experiments show that the multimodal-BERT models do not encode these scene trees .
Hyperbolic neural networks have shown great potential for modeling complex data .
However, existing hyperbolic networks are not completely hyperbolic, as they encode features in the hyperbolic space yet formalize most of their operations in the tangent space (a Euclidean subspace) at the origin of the hyperbolic model .
This hybrid method greatly limits the modeling ability of networks .
In this paper, we propose a fully hyperbolic framework to build hyperbolic networks based on the Lorentz model by adapting the Lorentz transformations (including boost and rotation) to formalize essential operations of neural networks .
Moreover, we also prove that linear transformation in tangent spaces used by existing hyperbolic networks is a relaxation of the Lorentz rotation and does not include the boost, implicitly limiting the capabilities of existing hyperbolic networks .
The experimental results on four NLP tasks show that our method has better performance for building both shallow and deep networks .
Our code will be released to facilitate follow-up research .
Multimodal machine translation (MMT) aims to improve neural machine translation (NMT) with additional visual information, but most existing MMT methods require paired input of source sentence and image, which makes them suffer from shortage of sentence-image pairs .
In this paper, we propose a phrase-level retrieval-based method for MMT to get visual information for the source input from existing sentence-image data sets so that MMT can break the limitation of paired sentence-image input .
Our method performs retrieval at the phrase level and hence learns visual information from pairs of source phrase and grounded region, which can mitigate data sparsity .
Furthermore, our method employs the conditional variational auto-encoder to learn visual representations which can filter redundant visual information and only retain visual information related to the phrase .
Experiments show that the proposed method significantly outperforms strong baselines on multiple MMT datasets, especially when the textual context is limited .
The emotional state of a speaker can be influenced by many different factors in dialogues, such as dialogue scene, dialogue topic, and interlocutor stimulus .
The currently available data resources to support such multimodal affective analysis in dialogues are however limited in scale and diversity .
In this work, we propose a Multi-modal Multi-scene Multi-label Emotional Dialogue dataset, M3ED, which contains 990 dyadic emotional dialogues from 56 different TV series, a total of 9,082 turns and 24,449 utterances .
M3ED is annotated with 7 emotion categories (happy, surprise, sad, disgust, anger, fear, and neutral) at utterance level, and encompasses acoustic, visual, and textual modalities .
To the best of our knowledge, M3ED is the first multimodal emotional dialogue dataset in Chinese.It is valuable for cross-culture emotion analysis and recognition .
We apply several state-of-the-art methods on the M3ED dataset to verify the validity and quality of the dataset .
We also propose a general Multimodal Dialogue-aware Interaction framework, MDI, to model the dialogue context for emotion recognition, which achieves comparable performance to the state-of-the-art methods on the M3ED .
The full dataset and codes are available .
Few-shot NER needs to effectively capture information from limited instances and transfer useful knowledge from external resources .
In this paper, we propose a self-describing mechanism for few-shot NER, which can effectively leverage illustrative instances and precisely transfer knowledge from external resources by describing both entity types and mentions using a universal concept set .
Specifically, we design Self-describing Networks (SDNet), a Seq2Seq generation model which can universally describe mentions using concepts, automatically map novel entity types to concepts, and adaptively recognize entities on-demand .
We pre-train SDNet with large-scale corpus, and conduct experiments on 8 benchmarks from different domains .
Experiments show that SDNet achieves competitive performances on all benchmarks and achieves the new state-of-the-art on 6 benchmarks, which demonstrates its effectiveness and robustness .
Motivated by the success of T5 (Text-To-Text Transfer Transformer) in pre-trained natural language processing models, we propose a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning .
The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets .
After preprocessing the input speech/text through the pre-nets, the shared encoder-decoder network models the sequence-to-sequence transformation, and then the post-nets generate the output in the speech/text modality based on the output of the decoder .
Leveraging large-scale unlabeled speech and text data, we pre-train SpeechT5 to learn a unified-modal representation, hoping to improve the modeling capability for both speech and text .
To align the textual and speech information into this unified semantic space, we propose a cross-modal vector quantization approach that randomly mixes up speech/text states with latent units as the interface between encoder and decoder .
Extensive evaluations show the superiority of the proposed SpeechT5 framework on a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification .
In recent years, machine learning models have rapidly become better at generating clinical consultation notes; yet, there is little work on how to properly evaluate the generated consultation notes to understand the impact they may have on both the clinician using them and the patient’s clinical safety.To address this we present an extensive human evaluation study of consultation notes where 5 clinicians (i) listen to 57 mock consultations, (ii) write their own notes, (iii) post-edit a number of automatically generated notes, and (iv) extract all the errors, both quantitative and qualitative .
We then carry out a correlation study with 18 automatic quality metrics and the human judgements .
We find that a simple, character-based Levenshtein distance metric performs on par if not better than common model-based metrics like BertScore .
All our findings and annotations are open-sourced .
Information extraction suffers from its varying targets, heterogeneous structures, and demand-specific schemas .
In this paper, we propose a unified text-to-structure generation framework, namely UIE, which can universally model different IE tasks, adaptively generate targeted structures, and collaboratively learn general IE abilities from different knowledge sources .
Specifically, UIE uniformly encodes different extraction structures via a structured extraction language, adaptively generates target extractions via a schema-based prompt mechanism – structural schema instructor, and captures the common IE abilities via a large-scale pretrained text-to-structure model .
Experiments show that UIE achieved the state-of-the-art performance on 4 IE tasks, 13 datasets, and on all supervised, low-resource, and few-shot settings for a wide range of entity, relation, event and sentiment extraction tasks and their unification .
These results verified the effectiveness, universality, and transferability of UIE .
Recent works on knowledge base question answering (KBQA) retrieve subgraphs for easier reasoning .
The desired subgraph is crucial as a small one may exclude the answer but a large one might introduce more noises .
However, the existing retrieval is either heuristic or interwoven with the reasoning, causing reasoning on the partial subgraphs, which increases the reasoning bias when the intermediate supervision is missing .
This paper proposes a trainable subgraph retriever (SR) decoupled from the subsequent reasoning process, which enables a plug-and-play framework to enhance any subgraph-oriented KBQA model .
Extensive experiments demonstrate SR achieves significantly better retrieval and QA performance than existing retrieval methods .
Via weakly supervised pre-training as well as the end-to-end fine-tuning, SR achieves new state-of-the-art performance when combined with NSM (He et al., 2021), a subgraph-oriented reasoner, for embedding-based KBQA methods .
Codes and datasets are available online (https://github.com/RUCKBReasoning/SubgraphRetrievalKBQA) .
Low-shot relation extraction (RE) aims to recognize novel relations with very few or even no samples, which is critical in real scenario application .
Few-shot and zero-shot RE are two representative low-shot RE tasks, which seem to be with similar target but require totally different underlying abilities .
In this paper, we propose Multi-Choice Matching Networks to unify low-shot relation extraction .
To fill in the gap between zero-shot and few-shot RE, we propose the triplet-paraphrase meta-training, which leverages triplet paraphrase to pre-train zero-shot label matching ability and uses meta-learning paradigm to learn few-shot instance summarizing ability .
Experimental results on three different low-shot RE tasks show that the proposed method outperforms strong baselines by a large margin, and achieve the best performance on few-shot RE leaderboard .
Prompt-based probing has been widely used in evaluating the abilities of pretrained language models (PLMs) .
Unfortunately, recent studies have discovered such an evaluation may be inaccurate, inconsistent and unreliable .
Furthermore, the lack of understanding its inner workings, combined with its wide applicability, has the potential to lead to unforeseen risks for evaluating and applying PLMs in real-world applications .
To discover, understand and quantify the risks, this paper investigates the prompt-based probing from a causal view, highlights three critical biases which could induce biased results and conclusions, and proposes to conduct debiasing via causal intervention .
This paper provides valuable insights for the design of unbiased datasets, better probing frameworks and more reliable evaluations of pretrained language models .
Furthermore, our conclusions also echo that we need to rethink the criteria for identifying better pretrained language models .
Several natural language processing (NLP) tasks are defined as a classification problem in its most complex form: Multi-label Hierarchical Extreme classification, in which items may be associated with multiple classes from a set of thousands of possible classes organized in a hierarchy and with a highly unbalanced distribution both in terms of class frequency and the number of labels per item .
We analyze the state of the art of evaluation metrics based on a set of formal properties and we define an information theoretic based metric inspired by the Information Contrast Model (ICM) .
Experiments on synthetic data and a case study on real data show the suitability of the ICM for such scenarios .
We present a complete pipeline to extract characters in a novel and link them to their direct-speech utterances .
Our model is divided into three independent components: extracting direct-speech, compiling a list of characters, and attributing those characters to their utterances .
Although we find that existing systems can perform the first two tasks accurately, attributing characters to direct speech is a challenging problem due to the narrator’s lack of explicit character mentions, and the frequent use of nominal and pronominal coreference when such explicit mentions are made .
We adapt the progress made on Dialogue State Tracking to tackle a new problem: attributing speakers to dialogues .
This is the first application of deep learning to speaker attribution, and it shows that is possible to overcome the need for the hand-crafted features and rules used in the past .
Our full pipeline improves the performance of state-of-the-art models by a relative 50% in F1-score .
With the rapid growth in language processing applications, fairness has emerged as an important consideration in data-driven solutions .
Although various fairness definitions have been explored in the recent literature, there is lack of consensus on which metrics most accurately reflect the fairness of a system .
In this work, we propose a new formulation – accumulated prediction sensitivity, which measures fairness in machine learning models based on the model’s prediction sensitivity to perturbations in input features .
The metric attempts to quantify the extent to which a single prediction depends on a protected attribute, where the protected attribute encodes the membership status of an individual in a protected group .
We show that the metric can be theoretically linked with a specific notion of group fairness (statistical parity) and individual fairness .
It also correlates well with humans’ perception of fairness .
We conduct experiments on two text classification datasets – Jigsaw Toxicity, and Bias in Bios, and evaluate the correlations between metrics and manual annotations on whether the model produced a fair outcome .
We observe that the proposed fairness metric based on prediction sensitivity is statistically significantly more correlated with human annotation than the existing counterfactual fairness metric .
Temporal factors are tied to the growth of facts in realistic applications, such as the progress of diseases and the development of political situation, therefore, research on Temporal Knowledge Graph (TKG) attracks much attention .
In TKG, relation patterns inherent with temporality are required to be studied for representation learning and reasoning across temporal facts .
However, existing methods can hardly model temporal relation patterns, nor can capture the intrinsic connections between relations when evolving over time, lacking of interpretability .
In this paper, we propose a novel temporal modeling method which represents temporal entities as Rotations in Quaternion Vector Space (RotateQVS) and relations as complex vectors in Hamilton’s quaternion space .
We demonstrate our method can model key patterns of relations in TKG, such as symmetry, asymmetry, inverse, and can capture time-evolved relations by theory .
And empirically, we show that our method can boost the performance of link prediction tasks over four temporal knowledge graph benchmarks .
Machine Reading Comprehension (MRC) reveals the ability to understand a given text passage and answer questions based on it .
Existing research works in MRC rely heavily on large-size models and corpus to improve the performance evaluated by metrics such as Exact Match (EM) and F1 .
However, such a paradigm lacks sufficient interpretation to model capability and can not efficiently train a model with a large corpus .
In this paper, we argue that a deep understanding of model capabilities and data properties can help us feed a model with appropriate training data based on its learning status .
Specifically, we design an MRC capability assessment framework that assesses model capabilities in an explainable and multi-dimensional manner .
Based on it, we further uncover and disentangle the connections between various data properties and model performance .
Finally, to verify the effectiveness of the proposed MRC capability assessment framework, we incorporate it into a curriculum learning pipeline and devise a Capability Boundary Breakthrough Curriculum (CBBC) strategy, which performs a model capability-based training to maximize the data value and improve training efficiency .
Extensive experiments demonstrate that our approach significantly improves performance, achieving up to an 11.22% / 8.71% improvement of EM / F1 on MRC tasks .
Simile interpretation (SI) and simile generation (SG) are challenging tasks for NLP because models require adequate world knowledge to produce predictions .
Previous works have employed many hand-crafted resources to bring knowledge-related into models, which is time-consuming and labor-intensive .
In recent years, pre-trained language models (PLMs) based approaches have become the de-facto standard in NLP since they learn generic knowledge from a large corpus .
The knowledge embedded in PLMs may be useful for SI and SG tasks .
Nevertheless, there are few works to explore it .
In this paper, we probe simile knowledge from PLMs to solve the SI and SG tasks in the unified framework of simile triple completion for the first time .
The backbone of our framework is to construct masked sentences with manual patterns and then predict the candidate words in the masked position .
In this framework, we adopt a secondary training process (Adjective-Noun mask Training) with the masked language model (MLM) loss to enhance the prediction diversity of candidate words in the masked position .
Moreover, pattern ensemble (PE) and pattern search (PS) are applied to improve the quality of predicted words .
Finally, automatic and human evaluations demonstrate the effectiveness of our framework in both SI and SG tasks .
Entity alignment (EA) aims to discover the equivalent entity pairs between KGs, which is a crucial step for integrating multi-source KGs.For a long time, most researchers have regarded EA as a pure graph representation learning task and focused on improving graph encoders while paying little attention to the decoding process.In this paper, we propose an effective and efficient EA Decoding Algorithm via Third-order Tensor Isomorphism (DATTI).Specifically, we derive two sets of isomorphism equations: (1) Adjacency tensor isomorphism equations and (2) Gramian tensor isomorphism equations.By combining these equations, DATTI could effectively utilize the adjacency and inner correlation isomorphisms of KGs to enhance the decoding process of EA.Extensive experiments on public datasets indicate that our decoding algorithm can deliver significant performance improvements even on the most advanced EA methods, while the extra required time is less than 3 seconds .
Typed entailment graphs try to learn the entailment relations between predicates from text and model them as edges between predicate nodes .
The construction of entailment graphs usually suffers from severe sparsity and unreliability of distributional similarity .
We propose a two-stage method, Entailment Graph with Textual Entailment and Transitivity (EGT2) .
EGT2 learns the local entailment relations by recognizing the textual entailment between template sentences formed by typed CCG-parsed predicates .
Based on the generated local graph, EGT2 then uses three novel soft transitivity constraints to consider the logical transitivity in entailment structures .
Experiments on benchmark datasets show that EGT2 can well model the transitivity in entailment graph to alleviate the sparsity, and leads to signifcant improvement over current state-of-the-art methods .
Modern deep learning models are notoriously opaque, which has motivated the development of methods for interpreting how deep models predict.This goal is usually approached with attribution method, which assesses the influence of features on model predictions .
As an explanation method, the evaluation criteria of attribution methods is how accurately it reflects the actual reasoning process of the model (faithfulness) .
Meanwhile, since the reasoning process of deep models is inaccessible, researchers design various evaluation methods to demonstrate their arguments.However, some crucial logic traps in these evaluation methods are ignored in most works, causing inaccurate evaluation and unfair comparison.This paper systematically reviews existing methods for evaluating attribution scores and summarizes the logic traps in these methods.We further conduct experiments to demonstrate the existence of each logic trap.Through both theoretical and experimental analysis, we hope to increase attention on the inaccurate evaluation of attribution scores .
Moreover, with this paper, we suggest stopping focusing on improving performance under unreliable evaluation systems and starting efforts on reducing the impact of proposed logic traps .
In this paper, we study how to continually pre-train language models for improving the understanding of math problems .
Specifically, we focus on solving a fundamental challenge in modeling math problems, how to fuse the semantics of textual description and formulas, which are highly different in essence .
To address this issue, we propose a new approach called COMUS to continually pre-train language models for math problem understanding with syntax-aware memory network .
In this approach, we first construct the math syntax graph to model the structural semantic information, by combining the parsing trees of the text and formulas, and then design the syntax-aware memory networks to deeply fuse the features from the graph and text .
With the help of syntax relations, we can model the interaction between the token from the text and its semantic-related nodes within the formulas, which is helpful to capture fine-grained semantic correlations between texts and formulas .
Besides, we devise three continual pre-training tasks to further align and fuse the representations of the text and math syntax graph .
Experimental results on four tasks in the math domain demonstrate the effectiveness of our approach .
Our code and data are publicly available at the link: bluehttps://github.com/RUCAIBox/COMUS .
The definition generation task can help language learners by providing explanations for unfamiliar words .
This task has attracted much attention in recent years .
We propose a novel task of Simple Definition Generation (SDG) to help language learners and low literacy readers .
A significant challenge of this task is the lack of learner’s dictionaries in many languages, and therefore the lack of data for supervised training .
We explore this task and propose a multitasking framework SimpDefiner that only requires a standard dictionary with complex definitions and a corpus containing arbitrary simple texts .
We disentangle the complexity factors from the text by carefully designing a parameter sharing scheme between two decoders .
By jointly training these components, the framework can generate both complex and simple definitions simultaneously .
We demonstrate that the framework can generate relevant, simple definitions for the target words through automatic and manual evaluations on English and Chinese datasets .
Our method outperforms the baseline model by a 1.77 SARI score on the English dataset, and raises the proportion of the low level (HSK level 1-3) words in Chinese definitions by 3.87% .
Solving math word problems requires deductive reasoning over the quantities in the text .
Various recent research efforts mostly relied on sequence-to-sequence or sequence-to-tree models to generate mathematical expressions without explicitly performing relational reasoning between quantities in the given context .
While empirically effective, such approaches typically do not provide explanations for the generated expressions .
In this work, we view the task as a complex relation extraction problem, proposing a novel approach that presents explainable deductive reasoning steps to iteratively construct target expressions, where each step involves a primitive operation over two quantities defining their relation .
Through extensive experiments on four benchmark datasets, we show that the proposed model significantly outperforms existing strong baselines .
We further demonstrate that the deductive procedure not only presents more explainable steps but also enables us to make more accurate predictions on questions that require more complex reasoning .
Indirect speech such as sarcasm achieves a constellation of discourse goals in human communication .
While the indirectness of figurative language warrants speakers to achieve certain pragmatic goals, it is challenging for AI agents to comprehend such idiosyncrasies of human communication .
Though sarcasm identification has been a well-explored topic in dialogue analysis, for conversational systems to truly grasp a conversation’s innate meaning and generate appropriate responses, simply detecting sarcasm is not enough; it is vital to explain its underlying sarcastic connotation to capture its true essence .
In this work, we study the discourse structure of sarcastic conversations and propose a novel task – Sarcasm Explanation in Dialogue (SED) .
Set in a multimodal and code-mixed setting, the task aims to generate natural language explanations of satirical conversations .
To this end, we curate WITS, a new dataset to support our task .
We propose MAF (Modality Aware Fusion), a multimodal context-aware attention and global information fusion module to capture multimodality and use it to benchmark WITS .
The proposed attention module surpasses the traditional multimodal fusion baselines and reports the best performance on almost all metrics .
Lastly, we carry out detailed analysis both quantitatively and qualitatively .
Recently, finetuning a pretrained language model to capture the similarity between sentence embeddings has shown the state-of-the-art performance on the semantic textual similarity (STS) task .
However, the absence of an interpretation method for the sentence similarity makes it difficult to explain the model output .
In this work, we explicitly describe the sentence distance as the weighted sum of contextualized token distances on the basis of a transportation problem, and then present the optimal transport-based distance measure, named RCMD; it identifies and leverages semantically-aligned token pairs .
In the end, we propose CLRCMD, a contrastive learning framework that optimizes RCMD of sentence pairs, which enhances the quality of sentence similarity and their interpretation .
Extensive experiments demonstrate that our learning framework outperforms other baselines on both STS and interpretable-STS benchmarks, indicating that it computes effective sentence similarity and also provides interpretation consistent with human judgement .
Recent years have witnessed growing interests in incorporating external knowledge such as pre-trained word embeddings (PWEs) or pre-trained language models (PLMs) into neural topic modeling .
However, we found that employing PWEs and PLMs for topic modeling only achieved limited performance improvements but with huge computational overhead .
In this paper, we propose a novel strategy to incorporate external knowledge into neural topic modeling where the neural topic model is pre-trained on a large corpus and then fine-tuned on the target dataset .
Experiments have been conducted on three datasets and results show that the proposed approach significantly outperforms both current state-of-the-art neural topic models and some topic modeling approaches enhanced with PWEs or PLMs .
Moreover, further study shows that the proposed approach greatly reduces the need for the huge size of training data .
Dense retrieval has achieved impressive advances in first-stage retrieval from a large-scale document collection, which is built on bi-encoder architecture to produce single vector representation of query and document .
However, a document can usually answer multiple potential queries from different views .
So the single vector representation of a document is hard to match with multi-view queries, and faces a semantic mismatch problem .
This paper proposes a multi-view document representation learning framework, aiming to produce multi-view embeddings to represent documents and enforce them to align with different queries .
First, we propose a simple yet effective method of generating multiple embeddings through viewers .
Second, to prevent multi-view embeddings from collapsing to the same one, we further propose a global-local loss with annealed temperature to encourage the multiple viewers to better align with different potential queries .
Experiments show our method outperforms recent works and achieves state-of-the-art results .
Abstract meaning representation (AMR) highlights the core semantic information of text in a graph structure.Recently, pre-trained language models (PLMs) have advanced tasks of AMR parsing and AMR-to-text generation, respectively.However, PLMs are typically pre-trained on textual data, thus are sub-optimal for modeling structural knowledge.To this end, we investigate graph self-supervised training to improve the structure awareness of PLMs over AMR graphs.In particular, we introduce two graph auto-encoding strategies for graph-to-graph pre-training and four tasks to integrate text and graph information during pre-training.We further design a unified framework to bridge the gap between pre-training and fine-tuning tasks.Experiments on both AMR parsing and AMR-to-text generation show the superiority of our model.To our knowledge, we are the first to consider pre-training on semantic graphs .
Models pre-trained with a language modeling objective possess ample world knowledge and language skills, but are known to struggle in tasks that require reasoning .
In this work, we propose to leverage semi-structured tables, and automatically generate at scale question-paragraph pairs, where answering the question requires reasoning over multiple facts in the paragraph .
We add a pre-training step over this synthetic data, which includes examples that require 16 different reasoning skills such as number comparison, conjunction, and fact composition .
To improve data efficiency, we sample examples from reasoning skills where the model currently errs .
We evaluate our approach on three reasoning-focused reading comprehension datasets, and show that our model, PReasM, substantially outperforms T5, a popular pre-trained encoder-decoder model .
Moreover, sampling examples based on model errors leads to faster training and higher performance .
Existing KBQA approaches, despite achieving strong performance on i.i.d .
test data, often struggle in generalizing to questions involving unseen KB schema items .
Prior ranking-based approaches have shown some success in generalization, but suffer from the coverage issue .
We present RnG-KBQA, a Rank-and-Generate approach for KBQA, which remedies the coverage issue with a generation model while preserving a strong generalization capability .
Our approach first uses a contrastive ranker to rank a set of candidate logical forms obtained by searching over the knowledge graph .
It then introduces a tailored generation model conditioned on the question and the top-ranked candidates to compose the final logical form .
We achieve new state-of-the-art results on GrailQA and WebQSP datasets .
In particular, our method surpasses the prior state-of-the-art by a large margin on the GrailQA leaderboard .
In addition, RnG-KBQA outperforms all prior approaches on the popular WebQSP benchmark, even including the ones that use the oracle entity linking .
The experimental results demonstrate the effectiveness of the interplay between ranking and generation, which leads to the superior performance of our proposed approach across all settings with especially strong improvements in zero-shot generalization .
Given the claims of improved text generation quality across various pre-trained neural models, we consider the coherence evaluation of machine generated text to be one of the principal applications of coherence models that needs to be investigated .
Prior work in neural coherence modeling has primarily focused on devising new architectures for solving the permuted document task .
We instead use a basic model architecture and show significant improvements over state of the art within the same training regime .
We then design a harder self-supervision objective by increasing the ratio of negative samples within a contrastive learning setup, and enhance the model further through automatic hard negative mining coupled with a large global negative queue encoded by a momentum encoder .
We show empirically that increasing the density of negative samples improves the basic model, and using a global negative queue further improves and stabilizes the model while training with hard negative samples .
We evaluate the coherence model on task-independent test sets that resemble real-world applications and show significant improvements in coherence evaluations of downstream tasks .
Word and sentence embeddings are useful feature representations in natural language processing .
However, intrinsic evaluation for embeddings lags far behind, and there has been no significant update since the past decade .
Word and sentence similarity tasks have become the de facto evaluation method .
It leads models to overfit to such evaluations, negatively impacting embedding models’ development .
This paper first points out the problems using semantic similarity as the gold standard for word and sentence embedding evaluations .
Further, we propose a new intrinsic evaluation method called EvalRank, which shows a much stronger correlation with downstream tasks .
Extensive experiments are conducted based on 60+ models and popular datasets to certify our judgments .
Finally, the practical evaluation toolkit is released for future benchmarking purposes .
Multimodal pre-training with text, layout, and image has made significant progress for Visually Rich Document Understanding (VRDU), especially the fixed-layout documents such as scanned document images .
While, there are still a large number of digital documents where the layout information is not fixed and needs to be interactively and dynamically rendered for visualization, making existing layout-based pre-training approaches not easy to apply .
In this paper, we propose MarkupLM for document understanding tasks with markup languages as the backbone, such as HTML/XML-based documents, where text and markup information is jointly pre-trained .
Experiment results show that the pre-trained MarkupLM significantly outperforms the existing strong baseline models on several document understanding tasks .
The pre-trained model and code will be publicly available at https://aka.ms/markuplm .
CLIP has shown a remarkable zero-shot capability on a wide range of vision tasks .
Previously, CLIP is only regarded as a powerful visual encoder .
However, after being pre-trained by language supervision from a large amount of image-caption pairs, CLIP itself should also have acquired some few-shot abilities for vision-language tasks .
In this work, we empirically show that CLIP can be a strong vision-language few-shot learner by leveraging the power of language .
We first evaluate CLIP’s zero-shot performance on a typical visual question answering task and demonstrate a zero-shot cross-modality transfer capability of CLIP on the visual entailment task .
Then we propose a parameter-efficient fine-tuning strategy to boost the few-shot performance on the vqa task .
We achieve competitive zero/few-shot results on the visual question answering and visual entailment tasks without introducing any additional pre-training procedure .
Complex question answering over knowledge base (Complex KBQA) is challenging because it requires various compositional reasoning capabilities, such as multi-hop inference, attribute comparison, set operation, etc .
Existing benchmarks have some shortcomings that limit the development of Complex KBQA: 1) they only provide QA pairs without explicit reasoning processes; 2) questions are poor in diversity or scale .
To this end, we introduce KQA Pro, a dataset for Complex KBQA including around 120K diverse natural language questions .
We introduce a compositional and interpretable programming language KoPL to represent the reasoning process of complex questions .
For each question, we provide the corresponding KoPL program and SPARQL query, so that KQA Pro can serve for both KBQA and semantic parsing tasks .
Experimental results show that state-of-the-art KBQA methods cannot achieve promising results on KQA Pro as on current datasets, which suggests that KQA Pro is challenging and Complex KBQA requires further research efforts .
We also treat KQA Pro as a diagnostic dataset for testing multiple reasoning skills, conduct a thorough evaluation of existing models and discuss further directions for Complex KBQA .
Our codes and datasets can be obtained from https://github.com/shijx12/KQAPro_Baselines .
Recently, contrastive learning has been shown to be effective in improving pre-trained language models (PLM) to derive high-quality sentence representations .
It aims to pull close positive examples to enhance the alignment while push apart irrelevant negatives for the uniformity of the whole representation space.However, previous works mostly adopt in-batch negatives or sample from training data at random .
Such a way may cause the sampling bias that improper negatives (false negatives and anisotropy representations) are used to learn sentence representations, which will hurt the uniformity of the representation space.To address it, we present a new framework DCLR (Debiased Contrastive Learning of unsupervised sentence Representations) to alleviate the influence of these improper negatives.In DCLR, we design an instance weighting method to punish false negatives and generate noise-based negatives to guarantee the uniformity of the representation space.Experiments on seven semantic textual similarity tasks show that our approach is more effective than competitive baselines .
Our code and data are publicly available at the link: bluehttps://github.com/RUCAIBox/DCLR .
Prompting has recently been shown as a promising approach for applying pre-trained language models to perform downstream tasks .
We present Multi-Stage Prompting, a simple and automatic approach for leveraging pre-trained language models to translation tasks .
To better mitigate the discrepancy between pre-training and translation, MSP divides the translation process via pre-trained language models into three separate stages: the encoding stage, the re-encoding stage, and the decoding stage .
During each stage, we independently apply different continuous prompts for allowing pre-trained language models better shift to translation tasks .
We conduct extensive experiments on three translation tasks .
Experiments show that our method can significantly improve the translation performance of pre-trained language models .
Dialogue systems are usually categorized into two types, open-domain and task-oriented .
The first one focuses on chatting with users and making them engage in the conversations, where selecting a proper topic to fit the dialogue context is essential for a successful dialogue .
The other one focuses on a specific task instead of casual talks, e.g., finding a movie on Friday night, playing a song .
These two directions have been studied separately due to their different purposes .
However, how to smoothly transition from social chatting to task-oriented dialogues is important for triggering the business opportunities, and there is no any public data focusing on such scenarios .
Hence, this paper focuses on investigating the conversations starting from open-domain social chatting and then gradually transitioning to task-oriented purposes, and releases a large-scale dataset with detailed annotations for encouraging this research direction .
To achieve this goal, this paper proposes a framework to automatically generate many dialogues without human involvement, in which any powerful open-domain dialogue generation model can be easily leveraged .
The human evaluation shows that our generated dialogue data has a natural flow at a reasonable quality, showing that our released data has a great potential of guiding future research directions and commercial activities .
Furthermore, the released models allow researchers to automatically generate unlimited dialogues in the target scenarios, which can greatly benefit semi-supervised and unsupervised approaches .
High-quality phrase representations are essential to finding topics and related terms in documents (a.k.a .
topic mining) .
Existing phrase representation learning methods either simply combine unigram representations in a context-free manner or rely on extensive annotations to learn context-aware knowledge .
In this paper, we propose UCTopic, a novel unsupervised contrastive learning framework for context-aware phrase representations and topic mining .
UCTopic is pretrained in a large scale to distinguish if the contexts of two phrase mentions have the same semantics .
The key to the pretraining is positive pair construction from our phrase-oriented assumptions .
However, we find traditional in-batch negatives cause performance decay when finetuning on a dataset with small topic numbers .
Hence, we propose cluster-assisted contrastive learning (CCL) which largely reduces noisy negatives by selecting negatives from clusters and further improves phrase representations for topics accordingly .
UCTopic outperforms the state-of-the-art phrase representation model by 38.2% NMI in average on four entity clustering tasks .
Comprehensive evaluation on topic mining shows that UCTopic can extract coherent and diverse topical phrases .
In this paper, we introduce ELECTRA-style tasks to cross-lingual language model pre-training .
Specifically, we present two pre-training tasks, namely multilingual replaced token detection, and translation replaced token detection .
Besides, we pretrain the model, named as XLM-E, on both multilingual and parallel corpora .
Our model outperforms the baseline models on various cross-lingual understanding tasks with much less computation cost .
Moreover, analysis shows that XLM-E tends to obtain better cross-lingual transferability .
Nested named entity recognition (NER) has been receiving increasing attention .
Recently, Fu et al .
(2020) adapt a span-based constituency parser to tackle nested NER .
They treat nested entities as partially-observed constituency trees and propose the masked inside algorithm for partial marginalization .
However, their method cannot leverage entity heads, which have been shown useful in entity mention detection and entity typing .
In this work, we resort to more expressive structures, lexicalized constituency trees in which constituents are annotated by headwords, to model nested entities .
We leverage the Eisner-Satta algorithm to perform partial marginalization and inference efficiently.In addition, we propose to use (1) a two-stage strategy (2) a head regularization loss and (3) a head-aware labeling loss in order to enhance the performance .
We make a thorough ablation study to investigate the functionality of each component .
Experimentally, our method achieves the state-of-the-art performance on ACE2004, ACE2005 and NNE, and competitive performance on GENIA, and meanwhile has a fast inference speed .
NLP practitioners often want to take existing trained models and apply them to data from new domains .
While fine-tuning or few-shot learning can be used to adapt a base model, there is no single recipe for making these techniques work; moreover, one may not have access to the original model weights if it is deployed as a black box .
We study how to improve a black box model’s performance on a new domain by leveraging explanations of the model’s behavior .
Our approach first extracts a set of features combining human intuition about the task with model attributions generated by black box interpretation techniques, then uses a simple calibrator, in the form of a classifier, to predict whether the base model was correct or not .
We experiment with our method on two tasks, extractive question answering and natural language inference, covering adaptation from several pairs of domains with limited target-domain data .
The experimental results across all the domain pairs show that explanations are useful for calibrating these models, boosting accuracy when predictions do not have to be returned on every example .
We further show that the calibration model transfers to some extent between tasks .
Different Open Information Extraction (OIE) tasks require different types of information, so the OIE field requires strong adaptability of OIE algorithms to meet different task requirements .
This paper discusses the adaptability problem in existing OIE systems and designs a new adaptable and efficient OIE system - OIE@OIA as a solution .
OIE@OIA follows the methodology of Open Information eXpression (OIX): parsing a sentence to an Open Information Annotation (OIA) Graph and then adapting the OIA graph to different OIE tasks with simple rules .
As the core of our OIE@OIA system, we implement an end-to-end OIA generator by annotating a dataset (we make it open available) and designing an efficient learning algorithm for the complex OIA graph .
We easily adapt the OIE@OIA system to accomplish three popular OIE tasks .
The experimental show that our OIE@OIA achieves new SOTA performances on these tasks, showing the great adaptability of our OIE@OIA system .
Furthermore, compared to other end-to-end OIE baselines that need millions of samples for training, our OIE@OIA needs much fewer training samples (12K), showing a significant advantage in terms of efficiency .
Code completion, which aims to predict the following code token(s) according to the code context, can improve the productivity of software development .
Recent work has proved that statistical language modeling with transformers can greatly improve the performance in the code completion task via learning from large-scale source code datasets .
However, current approaches focus only on code context within the file or project, i.e .
internal context .
Our distinction is utilizing ”external” context, inspired by human behaviors of copying from the related code snippets when writing code .
Specifically, we propose a retrieval-augmented code completion framework, leveraging both lexical copying and referring to code with similar semantics by retrieval .
We adopt a stage-wise training approach that combines a source code retriever and an auto-regressive language model for programming language .
We evaluate our approach in the code completion task in Python and Java programming languages, achieving a state-of-the-art performance on CodeXGLUE benchmark .
DocRED is a widely used dataset for document-level relation extraction .
In the large-scale annotation, a recommend-revise scheme is adopted to reduce the workload .
Within this scheme, annotators are provided with candidate relation instances from distant supervision, and they then manually supplement and remove relational facts based on the recommendations .
However, when comparing DocRED with a subset relabeled from scratch, we find that this scheme results in a considerable amount of false negative samples and an obvious bias towards popular entities and relations .
Furthermore, we observe that the models trained on DocRED have low recall on our relabeled dataset and inherit the same bias in the training data .
Through the analysis of annotators’ behaviors, we figure out the underlying reason for the problems above: the scheme actually discourages annotators from supplementing adequate instances in the revision phase .
We appeal to future research to take into consideration the issues with the recommend-revise scheme when designing new models and annotation schemes .
The relabeled dataset is released at https://github.com/AndrewZhe/Revisit-DocRED, to serve as a more reliable test set of document RE models .
Recent parameter-efficient language model tuning (PELT) methods manage to match the performance of fine-tuning with much fewer trainable parameters and perform especially well when training data is limited .
However, different PELT methods may perform rather differently on the same task, making it nontrivial to select the most appropriate method for a specific task, especially considering the fast-growing number of new PELT methods and tasks .
In light of model diversity and the difficulty of model selection, we propose a unified framework, UniPELT, which incorporates different PELT methods as submodules and learns to activate the ones that best suit the current data or task setup via gating mechanism .
On the GLUE benchmark, UniPELT consistently achieves 1 4% gains compared to the best individual PELT method that it incorporates and even outperforms fine-tuning under different setups .
Moreover, UniPELT generally surpasses the upper bound that takes the best performance of all its submodules used individually on each task, indicating that a mixture of multiple PELT methods may be inherently more effective than single methods .
A recent study by Feldman (2020) proposed a long-tail theory to explain the memorization behavior of deep learning models .
However, memorization has not been empirically verified in the context of NLP, a gap addressed by this work .
In this paper, we use three different NLP tasks to check if the long-tail theory holds .
Our experiments demonstrate that top-ranked memorized training instances are likely atypical, and removing the top-memorized training instances leads to a more serious drop in test accuracy compared with removing training instances randomly .
Furthermore, we develop an attribution method to better understand why a training instance is memorized .
We empirically show that our memorization attribution method is faithful, and share our interesting finding that the top-memorized parts of a training instance tend to be features negatively correlated with the class label .
Pretrained multilingual models are able to perform cross-lingual transfer in a zero-shot setting, even for languages unseen during pretraining .
However, prior work evaluating performance on unseen languages has largely been limited to low-level, syntactic tasks, and it remains unclear if zero-shot learning of high-level, semantic tasks is possible for unseen languages .
To explore this question, we present AmericasNLI, an extension of XNLI (Conneau et al., 2018) to 10 Indigenous languages of the Americas .
We conduct experiments with XLM-R, testing multiple zero-shot and translation-based approaches .
Additionally, we explore model adaptation via continued pretraining and provide an analysis of the dataset by considering hypothesis-only models .
We find that XLM-R’s zero-shot performance is poor for all 10 languages, with an average performance of 38.48% .
Continued pretraining offers improvements, with an average accuracy of 43.85% .
Surprisingly, training on poorly translated data by far outperforms all other methods with an accuracy of 49.12% .
Understanding the functional (dis)-similarity of source code is significant for code modeling tasks such as software vulnerability and code clone detection .
We present DISCO (DIS-similarity of COde), a novel self-supervised model focusing on identifying (dis)similar functionalities of source code .
Different from existing works, our approach does not require a huge amount of randomly collected datasets .
Rather, we design structure-guided code transformation algorithms to generate synthetic code clones and inject real-world security bugs, augmenting the collected datasets in a targeted way .
We propose to pre-train the Transformer model with such automatically generated program contrasts to better identify similar code in the wild and differentiate vulnerable programs from benign ones .
To better capture the structural features of source code, we propose a new cloze objective to encode the local tree-based context (e.g., parents or sibling nodes) .
We pre-train our model with a much smaller dataset, the size of which is only 5% of the state-of-the-art models’ training datasets, to illustrate the effectiveness of our data augmentation and the pre-training approach .
The evaluation shows that, even with much less data, DISCO can still outperform the state-of-the-art models in vulnerability and code clone detection tasks .
Most works on financial forecasting use information directly associated with individual companies (e.g., stock prices, news on the company) to predict stock returns for trading .
We refer to such company-specific information as local information .
Stock returns may also be influenced by global information (e.g., news on the economy in general), and inter-company relationships .
Capturing such diverse information is challenging due to the low signal-to-noise ratios, different time-scales, sparsity and distributions of global and local information from different modalities .
In this paper, we propose a model that captures both global and local multimodal information for investment and risk management-related forecasting tasks .
Our proposed Guided Attention Multimodal Multitask Network (GAME) model addresses these challenges by using novel attention modules to guide learning with global and local information from different modalities and dynamic inter-company relationship networks .
Our extensive experiments show that GAME outperforms other state-of-the-art models in several forecasting tasks and important real-world application case studies .
Previous work on multimodal machine translation (MMT) has focused on the way of incorporating vision features into translation but little attention is on the quality of vision models .
In this work, we investigate the impact of vision models on MMT .
Given the fact that Transformer is becoming popular in computer vision, we experiment with various strong models (such as Vision Transformer) and enhanced features (such as object-detection and image captioning) .
We develop a selective attention model to study the patch-level contribution of an image in MMT .
On detailed probing tasks, we find that stronger vision models are helpful for learning translation from the visual modality .
Our results also suggest the need of carefully examining MMT models, especially when current benchmarks are small-scale and biased .
Named Entity Recognition (NER) in Few-Shot setting is imperative for entity tagging in low resource domains .
Existing approaches only learn class-specific semantic features and intermediate representations from source domains .
This affects generalizability to unseen target domains, resulting in suboptimal performances .
To this end, we present CONTaiNER, a novel contrastive learning technique that optimizes the inter-token distribution distance for Few-Shot NER .
Instead of optimizing class-specific attributes, CONTaiNER optimizes a generalized objective of differentiating between token categories based on their Gaussian-distributed embeddings .
This effectively alleviates overfitting issues originating from training domains .
Our experiments in several traditional test domains (OntoNotes, CoNLL’03, WNUT ‘17, GUM) and a new large scale Few-Shot NER dataset (Few-NERD) demonstrate that on average, CONTaiNER outperforms previous methods by 3%-13% absolute F1 points while showing consistent performance trends, even in challenging scenarios where previous approaches could not achieve appreciable performance .
Plains Cree (nêhiyawêwin) is an Indigenous language that is spoken in Canada and the USA .
It is the most widely spoken dialect of Cree and a morphologically complex language that is polysynthetic, highly inflective, and agglutinative .
It is an extremely low resource language, with no existing corpus that is both available and prepared for supporting the development of language technologies .
To support nêhiyawêwin revitalization and preservation, we developed a corpus covering diverse genres, time periods, and texts for a variety of intended audiences .
The data has been verified and cleaned; it is ready for use in developing language technologies for nêhiyawêwin .
The corpus includes the corresponding English phrases or audio files where available .
We demonstrate the utility of the corpus through its community use and its use to build language technologies that can provide the types of support that community members have expressed are desirable .
The corpus is available for public use .
Visual storytelling (VIST) is a typical vision and language task that has seen extensive development in the natural language generation research domain .
However, it remains unclear whether conventional automatic evaluation metrics for text generation are applicable on VIST .
In this paper, we present the VHED (VIST Human Evaluation Data) dataset, which first re-purposes human evaluation results for automatic evaluation; hence we develop Vrank (VIST Ranker), a novel reference-free VIST metric for story evaluation .
We first show that the results from commonly adopted automatic metrics for text generation have little correlation with those obtained from human evaluation, which motivates us to directly utilize human evaluation results to learn the automatic evaluation model .
In the experiments, we evaluate the generated texts to predict story ranks using our model as well as other reference-based and reference-free metrics .
Results show that Vrank prediction is significantly more aligned to human evaluation than other metrics with almost 30% higher accuracy when ranking story pairs .
Moreover, we demonstrate that only Vrank shows human-like behavior in its strong ability to find better stories when the quality gap between two stories is high .
Finally, we show the superiority of Vrank by its generalizability to pure textual stories, and conclude that this reuse of human evaluation results puts Vrank in a strong position for continued future advances .
Pre-trained sequence-to-sequence models have significantly improved Neural Machine Translation (NMT) .
Different from prior works where pre-trained models usually adopt an unidirectional decoder, this paper demonstrates that pre-training a sequence-to-sequence model but with a bidirectional decoder can produce notable performance gains for both Autoregressive and Non-autoregressive NMT .
Specifically, we propose CeMAT, a conditional masked language model pre-trained on large-scale bilingual and monolingual corpora in many languages .
We also introduce two simple but effective methods to enhance the CeMAT, aligned code-switching & masking and dynamic dual-masking .
We conduct extensive experiments and show that our CeMAT can achieve significant performance improvement for all scenarios from low- to extremely high-resource languages, i.e., up to +14.4 BLEU on low resource and +7.9 BLEU improvements on average for Autoregressive NMT .
For Non-autoregressive NMT, we demonstrate it can also produce consistent performance gains, i.e., up to +5.3 BLEU .
To the best of our knowledge, this is the first work to pre-train a unified model for fine-tuning on both NMT tasks .
Code, data, and pre-trained models are available at https://github.com/huawei-noah/Pretrained-Language-Model/CeMAT .
We introduce CARETS, a systematic test suite to measure consistency and robustness of modern VQA models through a series of six fine-grained capability tests .
In contrast to existing VQA test sets, CARETS features balanced question generation to create pairs of instances to test models, with each pair focusing on a specific capability such as rephrasing, logical symmetry or image obfuscation .
We evaluate six modern VQA systems on CARETS and identify several actionable weaknesses in model comprehension, especially with concepts such as negation, disjunction, or hypernym invariance .
Interestingly, even the most sophisticated models are sensitive to aspects such as swapping the order of terms in a conjunction or varying the number of answer choices mentioned in the question .
We release CARETS to be used as an extensible tool for evaluating multi-modal model robustness .
Recent studies have achieved inspiring success in unsupervised grammar induction using masked language modeling (MLM) as the proxy task .
Despite their high accuracy in identifying low-level structures, prior arts tend to struggle in capturing high-level structures like clauses, since the MLM task usually only requires information from local context .
In this work, we revisit LM-based constituency parsing from a phrase-centered perspective .
Inspired by the natural reading process of human, we propose to regularize the parser with phrases extracted by an unsupervised phrase tagger to help the LM model quickly manage low-level structures .
For a better understanding of high-level structures, we propose a phrase-guided masking strategy for LM to emphasize more on reconstructing non-phrase words .
We show that the initial phrase regularization serves as an effective bootstrap, and phrase-guided masking improves the identification of high-level structures .
Experiments on the public benchmark with two different backbone models demonstrate the effectiveness and generality of our method .
Evaluation of open-domain dialogue systems is highly challenging and development of better techniques is highlighted time and again as desperately needed .
Despite substantial efforts to carry out reliable live evaluation of systems in recent competitions, annotations have been abandoned and reported as too unreliable to yield sensible results .
This is a serious problem since automatic metrics are not known to provide a good indication of what may or may not be a high-quality conversation .
Answering the distress call of competitions that have emphasized the urgent need for better evaluation techniques in dialogue, we present the successful development of human evaluation that is highly reliable while still remaining feasible and low cost .
Self-replication experiments reveal almost perfectly repeatable results with a correlation of r=0.969 .
Furthermore, due to the lack of appropriate methods of statistical significance testing, the likelihood of potential improvements to systems occurring due to chance is rarely taken into account in dialogue evaluation, and the evaluation we propose facilitates application of standard tests .
Since we have developed a highly reliable evaluation method, new insights into system performance can be revealed .
We therefore include a comparison of state-of-the-art models (i) with and without personas, to measure the contribution of personas to conversation quality, as well as (ii) prescribed versus freely chosen topics .
Interestingly with respect to personas, results indicate that personas do not positively contribute to conversation quality as expected .
We propose the task of updated headline generation, in which a system generates a headline for an updated article, considering both the previous article and headline .
The system must identify the novel information in the article update, and modify the existing headline accordingly .
We create data for this task using the NewsEdits corpus by automatically identifying contiguous article versions that are likely to require a substantive headline update .
We find that models conditioned on the prior headline and body revisions produce headlines judged by humans to be as factual as gold headlines while making fewer unnecessary edits compared to a standard headline generation model .
Our experiments establish benchmarks for this new contextual summarization task .
Current open-domain conversational models can easily be made to talk in inadequate ways .
Online learning from conversational feedback given by the conversation partner is a promising avenue for a model to improve and adapt, so as to generate fewer of these safety failures .
However, current state-of-the-art models tend to react to feedback with defensive or oblivious responses .
This makes for an unpleasant experience and may discourage conversation partners from giving feedback in the future .
This work proposes SaFeRDialogues, a task and dataset of graceful responses to conversational feedback about safety failures.We collect a dataset of 8k dialogues demonstrating safety failures, feedback signaling them, and a response acknowledging the feedback .
We show how fine-tuning on this dataset results in conversations that human raters deem considerably more likely to lead to a civil conversation, without sacrificing engagingness or general conversational ability .
Compositionality— the ability to combine familiar units like words into novel phrases and sentences— has been the focus of intense interest in artificial intelligence in recent years .
To test compositional generalization in semantic parsing, Keysers et al .
(2020) introduced Compositional Freebase Queries (CFQ) .
This dataset maximizes the similarity between the test and train distributions over primitive units, like words, while maximizing the compound divergence: the dissimilarity between test and train distributions over larger structures, like phrases .
Dependency parsing, however, lacks a compositional generalization benchmark .
In this work, we introduce a gold-standard set of dependency parses for CFQ, and use this to analyze the behaviour of a state-of-the art dependency parser (Qi et al., 2020) on the CFQ dataset .
We find that increasing compound divergence degrades dependency parsing performance, although not as dramatically as semantic parsing performance .
Additionally, we find the performance of the dependency parser does not uniformly degrade relative to compound divergence, and the parser performs differently on different splits with the same compound divergence .
We explore a number of hypotheses for what causes the non-uniform degradation in dependency parsing performance, and identify a number of syntactic structures that drive the dependency parser’s lower performance on the most challenging splits .
Generic summaries try to cover an entire document and query-based summaries try to answer document-specific questions .
But real users’ needs often fall in between these extremes and correspond to aspects, high-level topics discussed among similar types of documents .
In this paper, we collect a dataset of realistic aspect-oriented summaries, AspectNews, which covers different subtopics about articles in news sub-domains .
We annotate data across two domains of articles, earthquakes and fraud investigations, where each article is annotated with two distinct summaries focusing on different aspects for each domain .
A system producing a single generic summary cannot concisely satisfy both aspects .
Our focus in evaluation is how well existing techniques can generalize to these domains without seeing in-domain training data, so we turn to techniques to construct synthetic training data that have been used in query-focused summarization work .
We compare several training schemes that differ in how strongly keywords are used and how oracle summaries are extracted .
Our evaluation shows that our final approach yields (a) focused summaries, better than those from a generic summarization system or from keyword matching; (b) a system sensitive to the choice of keywords .
We introduce MemSum (Multi-step Episodic Markov decision process extractive SUMmarizer), a reinforcement-learning-based extractive summarizer enriched at each step with information on the current extraction history .
When MemSum iteratively selects sentences into the summary, it considers a broad information set that would intuitively also be used by humans in this task: 1) the text content of the sentence, 2) the global text context of the rest of the document, and 3) the extraction history consisting of the set of sentences that have already been extracted .
With a lightweight architecture, MemSum obtains state-of-the-art test-set performance (ROUGE) in summarizing long documents taken from PubMed, arXiv, and GovReport .
Ablation studies demonstrate the importance of local, global, and history information .
A human evaluation confirms the high quality and low redundancy of the generated summaries, stemming from MemSum’s awareness of extraction history .
Supervised learning has traditionally focused on inductive learning by observing labeled examples of a task .
In contrast, a hallmark of human intelligence is the ability to learn new concepts purely from language .
Here, we explore training zero-shot classifiers for structured data purely from language .
For this, we introduce CLUES, a benchmark for Classifier Learning Using natural language ExplanationS, consisting of a range of classification tasks over structured data along with natural language supervision in the form of explanations .
CLUES consists of 36 real-world and 144 synthetic classification tasks .
It contains crowdsourced explanations describing real-world tasks from multiple teachers and programmatically generated explanations for the synthetic tasks .
To model the influence of explanations in classifying an example, we develop ExEnt, an entailment-based model that learns classifiers using explanations .
ExEnt generalizes up to 18% better (relative) on novel tasks than a baseline that does not use explanations .
We delineate key challenges for automated learning from explanations, addressing which can lead to progress on CLUES in the future .
Code and datasets are available at: https://clues-benchmark.github.io .
We present substructure distribution projection (SubDP), a technique that projects a distribution over structures in one domain to another, by projecting substructure distributions separately .
Models for the target domain can then be trained, using the projected distributions as soft silver labels .
We evaluate SubDP on zero shot cross-lingual dependency parsing, taking dependency arcs as substructures: we project the predicted dependency arc distributions in the source language(s) to target language(s), and train a target language parser on the resulting distributions .
Given an English tree bank as the only source of human supervision, SubDP achieves better unlabeled attachment score than all prior work on the Universal Dependencies v2.2 (Nivre et al., 2020) test set across eight diverse target languages, as well as the best labeled attachment score on six languages .
In addition, SubDP improves zero shot cross-lingual dependency parsing with very few (e.g., 50) supervised bitext pairs, across a broader range of target languages .
Detecting disclosures of individuals’ employment status on social media can provide valuable information to match job seekers with suitable vacancies, offer social protection, or measure labor market flows .
However, identifying such personal disclosures is a challenging task due to their rarity in a sea of social media content and the variety of linguistic forms used to describe them .
Here, we examine three Active Learning (AL) strategies in real-world settings of extreme class imbalance, and identify five types of disclosures about individuals’ employment status (e.g .
job loss) in three languages using BERT-based classification models .
Our findings show that, even under extreme imbalance settings, a small number of AL iterations is sufficient to obtain large and significant gains in precision, recall, and diversity of results compared to a supervised baseline with the same number of labels .
We also find that no AL strategy consistently outperforms the rest .
Qualitative analysis suggests that AL helps focus the attention mechanism of BERT on core terms and adjust the boundaries of semantic expansion, highlighting the importance of interpretable models to provide greater control and visibility into this dynamic learning process .
Numerical reasoning over hybrid data containing both textual and tabular content (e.g., financial reports) has recently attracted much attention in the NLP community .
However, existing question answering (QA) benchmarks over hybrid data only include a single flat table in each document and thus lack examples of multi-step numerical reasoning across multiple hierarchical tables .
To facilitate data analytical progress, we construct a new large-scale benchmark, MultiHiertt, with QA pairs over Multi Hierarchical Tabular and Textual data .
MultiHiertt is built from a wealth of financial reports and has the following unique characteristics: 1) each document contain multiple tables and longer unstructured texts; 2) most of tables contained are hierarchical; 3) the reasoning process required for each question is more complex and challenging than existing benchmarks; and 4) fine-grained annotations of reasoning processes and supporting facts are provided to reveal complex numerical reasoning .
We further introduce a novel QA model termed MT2Net, which first applies facts retrieving to extract relevant supporting facts from both tables and text and then uses a reasoning module to perform symbolic reasoning over retrieved facts .
We conduct comprehensive experiments on various baselines .
The experimental results show that MultiHiertt presents a strong challenge for existing baselines whose results lag far behind the performance of human experts .
The dataset and code are publicly available at https://github.com/psunlpgroup/MultiHiertt .
Representation of linguistic phenomena in computational language models is typically assessed against the predictions of existing linguistic theories of these phenomena .
Using the notion of polarity as a case study, we show that this is not always the most adequate set-up .
We probe polarity via so-called ‘negative polarity items’ (in particular, English ‘any’) in two pre-trained Transformer-based models (BERT and GPT-2) .
We show that – at least for polarity – metrics derived from language models are more consistent with data from psycholinguistic experiments than linguistic theory predictions .
Establishing this allows us to more adequately evaluate the performance of language models and also to use language models to discover new insights into natural language grammar beyond existing linguistic theories .
This work contributes to establishing closer ties between psycholinguistic experiments and experiments with language models .
Back-translation is a critical component of Unsupervised Neural Machine Translation (UNMT), which generates pseudo parallel data from target monolingual data .
A UNMT model is trained on the pseudo parallel data with \text{\bf translated source}, and translates \text{\bf natural source} sentences in inference .
The source discrepancy between training and inference hinders the translation performance of UNMT models .
By carefully designing experiments, we identify two representative characteristics of the data gap in source: (1) \text{\textit{style gap}} (i.e., translated vs .
natural text style) that leads to poor generalization capability; (2) \text{\textit{content gap}} that induces the model to produce hallucination content biased towards the target language .
To narrow the data gap, we propose an online self-training approach, which simultaneously uses the pseudo parallel data {natural source, translated target} to mimic the inference scenario .
Experimental results on several widely-used language pairs show that our approach outperforms two strong baselines (XLM and MASS) by remedying the style and content gaps .
BERT based ranking models have achieved superior performance on various information retrieval tasks .
However, the large number of parameters and complex self-attention operations come at a significant latency overhead .
To remedy this, recent works propose late-interaction architectures, which allow pre-computation of intermediate document representations, thus reducing latency .
Nonetheless, having solved the immediate latency issue, these methods now introduce storage costs and network fetching latency, which limit their adoption in real-life production systems.In this work, we propose the Succinct Document Representation (SDR) scheme that computes highly compressed intermediate document representations, mitigating the storage/network issue .
Our approach first reduces the dimension of token representations by encoding them using a novel autoencoder architecture that uses the document’s textual content in both the encoding and decoding phases .
After this token encoding step, we further reduce the size of the document representations using modern quantization techniques .
Evaluation on MSMARCO’s passage re-reranking task show that compared to existing approaches using compressed document representations, our method is highly efficient, achieving 4x–11.6x higher compression rates for the same ranking quality .
Similarly, on the TREC CAR dataset, we achieve 7.7x higher compression rate for the same ranking quality .
Task-oriented dialogue systems are increasingly prevalent in healthcare settings, and have been characterized by a diverse range of architectures and objectives .
Although these systems have been surveyed in the medical community from a non-technical perspective, a systematic review from a rigorous computational perspective has to date remained noticeably absent .
As a result, many important implementation details of healthcare-oriented dialogue systems remain limited or underspecified, slowing the pace of innovation in this area .
To fill this gap, we investigated an initial pool of 4070 papers from well-known computer science, natural language processing, and artificial intelligence venues, identifying 70 papers discussing the system-level implementation of task-oriented dialogue systems for healthcare applications .
We conducted a comprehensive technical review of these papers, and present our key findings including identified gaps and corresponding recommendations .
Even though several methods have proposed to defend textual neural network (NN) models against black-box adversarial attacks, they often defend against a specific text perturbation strategy and/or require re-training the models from scratch .
This leads to a lack of generalization in practice and redundant computation .
In particular, the state-of-the-art transformer models (e.g., BERT, RoBERTa) require great time and computation resources .
By borrowing an idea from software engineering, in order to address these limitations, we propose a novel algorithm, SHIELD, which modifies and re-trains only the last layer of a textual NN, and thus it “patches” and “transforms” the NN into a stochastic weighted ensemble of multi-expert prediction heads .
Considering that most of current black-box attacks rely on iterative search mechanisms to optimize their adversarial perturbations, SHIELD confuses the attackers by automatically utilizing different weighted ensembles of predictors depending on the input .
In other words, SHIELD breaks a fundamental assumption of the attack, which is a victim NN model remains constant during an attack .
By conducting comprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and RoBERTa-based textual NNs, once patched by SHIELD, exhibit a relative enhancement of 15%–70% in accuracy on average against 14 different black-box attacks, outperforming 6 defensive baselines across 3 public datasets .
All codes are to be released .
Online alignment in machine translation refers to the task of aligning a target word to a source word when the target sequence has only been partially decoded .
Good online alignments facilitate important applications such as lexically constrained translation where user-defined dictionaries are used to inject lexical constraints into the translation model .
We propose a novel posterior alignment technique that is truly online in its execution and superior in terms of alignment error rates compared to existing methods .
Our proposed inference technique jointly considers alignment and token probabilities in a principled manner and can be seamlessly integrated within existing constrained beam-search decoding algorithms .
On five language pairs, including two distant language pairs, we achieve consistent drop in alignment error rates .
When deployed on seven lexically constrained translation tasks, we achieve significant improvements in BLEU specifically around the constrained positions .
Identifying sections is one of the critical components of understanding medical information from unstructured clinical notes and developing assistive technologies for clinical note-writing tasks .
Most state-of-the-art text classification systems require thousands of in-domain text data to achieve high performance .
However, collecting in-domain and recent clinical note data with section labels is challenging given the high level of privacy and sensitivity .
The present paper proposes an algorithmic way to improve the task transferability of meta-learning-based text classification in order to address the issue of low-resource target data .
Specifically, we explore how to make the best use of the source dataset and propose a unique task transferability measure named Normalized Negative Conditional Entropy (NNCE) .
Leveraging the NNCE, we develop strategies for selecting clinical categories and sections from source task data to boost cross-domain meta-learning accuracy .
Experimental results show that our task selection strategies improve section classification accuracy significantly compared to meta-learning algorithms .
As large Pre-trained Language Models (PLMs) trained on large amounts of data in an unsupervised manner become more ubiquitous, identifying various types of bias in the text has come into sharp focus .
Existing ‘Stereotype Detection’ datasets mainly adopt a diagnostic approach toward large PLMs .
Blodgett et .
al .
(2021) show that there are significant reliability issues with the existing benchmark datasets .
Annotating a reliable dataset requires a precise understanding of the subtle nuances of how stereotypes manifest in text .
In this paper, we annotate a focused evaluation set for ‘Stereotype Detection’ that addresses those pitfalls by de-constructing various ways in which stereotypes manifest in text .
Further, we present a multi-task model that leverages the abundance of data-rich neighboring tasks such as hate speech detection, offensive language detection, misogyny detection, etc., to improve the empirical performance on ‘Stereotype Detection’ .
We then propose a reinforcement-learning agent that guides the multi-task learning model by learning to identify the training examples from the neighboring tasks that help the target task the most .
We show that the proposed models achieve significant empirical gains over existing baselines on all the tasks .
While a great deal of work has been done on NLP approaches to lexical semantic change detection, other aspects of language change have received less attention from the NLP community .
In this paper, we address the detection of sound change through historical spelling .
We propose that a sound change can be captured by comparing the relative distance through time between the distributions of the characters involved before and after the change has taken place .
We model these distributions using PPMI character embeddings .
We verify this hypothesis in synthetic data and then test the method’s ability to trace the well-known historical change of lenition of plosives in Danish historical sources .
We show that the models are able to identify several of the changes under consideration and to uncover meaningful contexts in which they appeared .
The methodology has the potential to contribute to the study of open questions such as the relative chronology of sound shifts and their geographical distribution .
Large pretrained generative models like GPT-3 often suffer from hallucinating non-existent or incorrect content, which undermines their potential merits in real applications .
Existing work usually attempts to detect these hallucinations based on a corresponding oracle reference at a sentence or document level .
However ground-truth references may not be readily available for many free-form text generation applications, and sentence- or document-level detection may fail to provide the fine-grained signals that would prevent fallacious content in real time .
As a first step to addressing these issues, we propose a novel token-level, reference-free hallucination detection task and an associated annotated dataset named HaDeS (HAllucination DEtection dataSet) .
To create this dataset, we first perturb a large number of text segments extracted from English language Wikipedia, and then verify these with crowd-sourced annotations .
To mitigate label imbalance during annotation, we utilize an iterative model-in-loop strategy .
We conduct comprehensive data analyses and create multiple baseline models .
Classifiers in natural language processing (NLP) often have a large number of output classes .
For example, neural language models (LMs) and machine translation (MT) models both predict tokens from a vocabulary of thousands .
The Softmax output layer of these models typically receives as input a dense feature representation, which has much lower dimensionality than the output .
In theory, the result is some words may be impossible to be predicted via argmax, irrespective of input features, and empirically, there is evidence this happens in small language models (Demeter et al., 2020) .
In this paper we ask whether it can happen in practical large language models and translation models .
To do so, we develop algorithms to detect such unargmaxable tokens in public models .
We find that 13 out of 150 models do indeed have such tokens; however, they are very infrequent and unlikely to impact model quality .
We release our algorithms and code to the public .
In this paper, we propose an effective yet efficient model PAIE for both sentence-level and document-level Event Argument Extraction (EAE), which also generalizes well when there is a lack of training data .
On the one hand, PAIE utilizes prompt tuning for extractive objectives to take the best advantages of Pre-trained Language Models (PLMs) .
It introduces two span selectors based on the prompt to select start/end tokens among input texts for each role .
On the other hand, it captures argument interactions via multi-role prompts and conducts joint optimization with optimal span assignments via a bipartite matching loss .
Also, with a flexible prompt design, PAIE can extract multiple arguments with the same role instead of conventional heuristic threshold tuning .
We have conducted extensive experiments on three benchmarks, including both sentence- and document-level EAE .
The results present promising improvements from PAIE (3.5% and 2.3% F1 gains in average on three benchmarks, for PAIE-base and PAIE-large respectively) .
Further analysis demonstrates the efficiency, generalization to few-shot settings, and effectiveness of different extractive prompt tuning strategies .
Our code is available at https://github.com/mayubo2333/PAIE .
Simultaneous machine translation (SiMT) starts translating while receiving the streaming source inputs, and hence the source sentence is always incomplete during translating .
Different from the full-sentence MT using the conventional seq-to-seq architecture, SiMT often applies prefix-to-prefix architecture, which forces each target word to only align with a partial source prefix to adapt to the incomplete source in streaming inputs .
However, the source words in the front positions are always illusoryly considered more important since they appear in more prefixes, resulting in position bias, which makes the model pay more attention on the front source positions in testing .
In this paper, we first analyze the phenomenon of position bias in SiMT, and develop a Length-Aware Framework to reduce the position bias by bridging the structural gap between SiMT and full-sentence MT .
Specifically, given the streaming inputs, we first predict the full-sentence length and then fill the future source position with positional encoding, thereby turning the streaming inputs into a pseudo full-sentence .
The proposed framework can be integrated into most existing SiMT methods to further improve performance .
Experiments on two representative SiMT methods, including the state-of-the-art adaptive policy, show that our method successfully reduces the position bias and thereby achieves better SiMT performance .
Statutory article retrieval is the task of automatically retrieving law articles relevant to a legal question .
While recent advances in natural language processing have sparked considerable interest in many legal tasks, statutory article retrieval remains primarily untouched due to the scarcity of large-scale and high-quality annotated datasets .
To address this bottleneck, we introduce the Belgian Statutory Article Retrieval Dataset (BSARD), which consists of 1,100+ French native legal questions labeled by experienced jurists with relevant articles from a corpus of 22,600+ Belgian law articles .
Using BSARD, we benchmark several state-of-the-art retrieval approaches, including lexical and dense architectures, both in zero-shot and supervised setups .
We find that fine-tuned dense retrieval models significantly outperform other systems .
Our best performing baseline achieves 74.8% R@100, which is promising for the feasibility of the task and indicates there is still room for improvement .
By the specificity of the domain and addressed task, BSARD presents a unique challenge problem for future research on legal information retrieval .
Our dataset and source code are publicly available .
We present a novel pipeline for the collection of parallel data for the detoxification task .
We collect non-toxic paraphrases for over 10,000 English toxic sentences .
We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs .
We release two parallel corpora which can be used for the training of detoxification models .
To the best of our knowledge, these are the first parallel datasets for this task.We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources.We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches .
We conduct both automatic and manual evaluations .
All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin .
This suggests that our novel datasets can boost the performance of detoxification systems .
Character-level information is included in many NLP models, but evaluating the information encoded in character representations is an open issue .
We leverage perceptual representations in the form of shape, sound, and color embeddings and perform a representational similarity analysis to evaluate their correlation with textual representations in five languages .
This cross-lingual analysis shows that textual character representations correlate strongly with sound representations for languages using an alphabetic script, while shape correlates with featural scripts.We further develop a set of probing classifiers to intrinsically evaluate what phonological information is encoded in character embeddings .
Our results suggest that information on features such as voicing are embedded in both LSTM and transformer-based representations .
The introduction of immensely large Causal Language Models (CLMs) has rejuvenated the interest in open-ended text generation .
However, controlling the generative process for these Transformer-based models is at large an unsolved problem .
Earlier work has explored either plug-and-play decoding strategies, or more powerful but blunt approaches such as prompting .
There hence currently exists a trade-off between fine-grained control, and the capability for more expressive high-level instructions .
To alleviate this trade-off, we propose an encoder-decoder architecture that enables intermediate text prompts at arbitrary time steps .
We propose a resource-efficient method for converting a pre-trained CLM into this architecture, and demonstrate its potential on various experiments, including the novel task of contextualized word inclusion .
Our method provides strong results on multiple experimental settings, proving itself to be both expressive and versatile .
While neural text-to-speech systems perform remarkably well in high-resource scenarios, they cannot be applied to the majority of the over 6,000 spoken languages in the world due to a lack of appropriate training data .
In this work, we use embeddings derived from articulatory vectors rather than embeddings derived from phoneme identities to learn phoneme representations that hold across languages .
In conjunction with language agnostic meta learning, this enables us to fine-tune a high-quality text-to-speech model on just 30 minutes of data in a previously unseen language spoken by a previously unseen speaker .
Modern Irish is a minority language lacking sufficient computational resources for the task of accurate automatic syntactic parsing of user-generated content such as tweets .
Although language technology for the Irish language has been developing in recent years, these tools tend to perform poorly on user-generated content .
As with other languages, the linguistic style observed in Irish tweets differs, in terms of orthography, lexicon, and syntax, from that of standard texts more commonly used for the development of language models and parsers .
We release the first Universal Dependencies treebank of Irish tweets, facilitating natural language processing of user-generated content in Irish .
In this paper, we explore the differences between Irish tweets and standard Irish text, and the challenges associated with dependency parsing of Irish tweets .
We describe our bootstrapping method of treebank development and report on preliminary parsing experiments .
Previous length-controllable summarization models mostly control lengths at the decoding stage, whereas the encoding or the selection of information from the source document is not sensitive to the designed length .
They also tend to generate summaries as long as those in the training data .
In this paper, we propose a length-aware attention mechanism (LAAM) to adapt the encoding of the source based on the desired length .
Our approach works by training LAAM on a summary length balanced dataset built from the original training data, and then fine-tuning as usual .
Results show that this approach is effective in generating high-quality summaries with desired lengths and even those short lengths never seen in the original training set .
Multi-hop question generation focuses on generating complex questions that require reasoning over multiple pieces of information of the input passage .
Current models with state-of-the-art performance have been able to generate the correct questions corresponding to the answers .
However, most models can not ensure the complexity of generated questions, so they may generate shallow questions that can be answered without multi-hop reasoning .
To address this challenge, we propose the CQG, which is a simple and effective controlled framework .
CQG employs a simple method to generate the multi-hop questions that contain key entities in multi-hop reasoning chains, which ensure the complexity and quality of the questions .
In addition, we introduce a novel controlled Transformer-based decoder to guarantee that key entities appear in the questions .
Experiment results show that our model greatly improves performance, which also outperforms the state-of-the-art model about 25% by 5 BLEU points on HotpotQA .
Recent studies have shown that language models pretrained and/or fine-tuned on randomly permuted sentences exhibit competitive performance on GLUE, putting into question the importance of word order information .
Somewhat counter-intuitively, some of these studies also report that position embeddings appear to be crucial for models’ good performance with shuffled text .
We probe these language models for word order information and investigate what position embeddings learned from shuffled text encode, showing that these models retain a notion of word order information .
We show this is in part due to a subtlety in how shuffling is implemented in previous work – before rather than after subword segmentation .
Surprisingly, we find even Language models trained on text shuffled after subword segmentation retain some semblance of information about word order because of the statistical dependencies between sentence length and unigram probabilities .
Finally, we show that beyond GLUE, a variety of language understanding tasks do require word order information, often to an extent that cannot be learned through fine-tuning .
Recent work in Natural Language Processing has focused on developing approaches that extract faithful explanations, either via identifying the most important tokens in the input (i.e .
post-hoc explanations) or by designing inherently faithful models that first select the most important tokens and then use them to predict the correct label (i.e .
select-then-predict models) .
Currently, these approaches are largely evaluated on in-domain settings .
Yet, little is known about how post-hoc explanations and inherently faithful models perform in out-of-domain settings .
In this paper, we conduct an extensive empirical study that examines: (1) the out-of-domain faithfulness of post-hoc explanations, generated by five feature attribution methods; and (2) the out-of-domain performance of two inherently faithful models over six datasets .
Contrary to our expectations, results show that in many cases out-of-domain post-hoc explanation faithfulness measured by sufficiency and comprehensiveness is higher compared to in-domain .
We find this misleading and suggest using a random baseline as a yardstick for evaluating post-hoc explanation faithfulness .
Our findings also show that select-then predict models demonstrate comparable predictive performance in out-of-domain settings to full-text trained models .
Open Information Extraction (OpenIE) is the task of extracting (subject, predicate, object) triples from natural language sentences .
Current OpenIE systems extract all triple slots independently .
In contrast, we explore the hypothesis that it may be beneficial to extract triple slots iteratively: first extract easy slots, followed by the difficult ones by conditioning on the easy slots, and therefore achieve a better overall extraction.Based on this hypothesis, we propose a neural OpenIE system, MILIE, that operates in an iterative fashion .
Due to the iterative nature, the system is also modularit is possible to seamlessly integrate rule based extraction systems with a neural end-to-end system, thereby allowing rule based systems to supply extraction slots which MILIE can leverage for extracting the remaining slots .
We confirm our hypothesis empirically: MILIE outperforms SOTA systems on multiple languages ranging from Chinese to Arabic .
Additionally, we are the first to provide an OpenIE test dataset for Arabic and Galician .
For a natural language understanding benchmark to be useful in research, it has to consist of examples that are diverse and difficult enough to discriminate among current and near-future state-of-the-art systems .
However, we do not yet know how best to select text sources to collect a variety of challenging examples .
In this study, we crowdsource multiple-choice reading comprehension questions for passages taken from seven qualitatively distinct sources, analyzing what attributes of passages contribute to the difficulty and question types of the collected examples .
To our surprise, we find that passage source, length, and readability measures do not significantly affect question difficulty .
Through our manual annotation of seven reasoning types, we observe several trends between passage sources and reasoning types, e.g., logical reasoning is more often required in questions written for technical passages .
These results suggest that when creating a new benchmark dataset, selecting a diverse set of passages can help ensure a diverse range of question types, but that passage difficulty need not be a priority .
Simultaneous machine translation has recently gained traction thanks to significant quality improvements and the advent of streaming applications .
Simultaneous translation systems need to find a trade-off between translation quality and response time, and with this purpose multiple latency measures have been proposed .
However, latency evaluations for simultaneous translation are estimated at the sentence level, not taking into account the sequential nature of a streaming scenario .
Indeed, these sentence-level latency measures are not well suited for continuous stream translation, resulting in figures that are not coherent with the simultaneous translation policy of the system being assessed .
This work proposes a stream-level adaptation of the current latency measures based on a re-segmentation approach applied to the output translation, that is successfully evaluated on streaming conditions for a reference IWSLT task .
We present a novel rational-centric framework with human-in-the-loop – Rationales-centric Double-robustness Learning (RDL) – to boost model out-of-distribution performance in few-shot learning scenarios .
By using static semi-factual generation and dynamic human-intervened correction, RDL, acting like a sensible “inductive bias”, exploits rationales (i.e .
phrases that cause the prediction), human interventions and semi-factual augmentations to decouple spurious associations and bias models towards generally applicable underlying distributions, which enables fast and accurate generalisation .
Experimental results show that RDL leads to significant prediction benefits on both in-distribution and out-of-distribution tests, especially for few-shot learning scenarios, compared to many state-of-the-art benchmarks .
We also perform extensive ablation studies to support in-depth analyses of each component in our framework .
Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages .
However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture .
Although language and culture are tightly linked, there are important differences .
Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems .
We propose a principled framework to frame these efforts, and survey existing and potential strategies .
Prompt-based tuning for pre-trained language models (PLMs) has shown its effectiveness in few-shot learning .
Typically, prompt-based tuning wraps the input text into a cloze question .
To make predictions, the model maps the output words to labels via a verbalizer, which is either manually designed or automatically built .
However, manual verbalizers heavily depend on domain-specific prior knowledge and human efforts, while finding appropriate label words automatically still remains challenging.In this work, we propose the prototypical verbalizer (ProtoVerb) which is built directly from training data .
Specifically, ProtoVerb learns prototype vectors as verbalizers by contrastive learning .
In this way, the prototypes summarize training instances and are able to enclose rich class-level semantics .
We conduct experiments on both topic classification and entity typing tasks, and the results demonstrate that ProtoVerb significantly outperforms current automatic verbalizers, especially when training data is extremely scarce .
More surprisingly, ProtoVerb consistently boosts prompt-based tuning even on untuned PLMs, indicating an elegant non-tuning way to utilize PLMs .
Our codes are avaliable at https://github.com/thunlp/OpenPrompt .
We introduce and study the task of clickbait spoiling: generating a short text that satisfies the curiosity induced by a clickbait post .
Clickbait links to a web page and advertises its contents by arousing curiosity instead of providing an informative summary .
Our contributions are approaches to classify the type of spoiler needed (i.e., a phrase or a passage), and to generate appropriate spoilers .
A large-scale evaluation and error analysis on a new corpus of 5,000 manually spoiled clickbait posts—the Webis Clickbait Spoiling Corpus 2022—shows that our spoiler type classifier achieves an accuracy of 80%, while the question answering model DeBERTa-large outperforms all others in generating spoilers for both types .
We present Knowledge Distillation with Meta Learning (MetaDistil), a simple yet effective alternative to traditional knowledge distillation (KD) methods where the teacher model is fixed during training .
We show the teacher network can learn to better transfer knowledge to the student network (i.e., learning to teach) with the feedback from the performance of the distilled student network in a meta learning framework .
Moreover, we introduce a pilot update mechanism to improve the alignment between the inner-learner and meta-learner in meta learning algorithms that focus on an improved inner-learner .
Experiments on various benchmarks show that MetaDistil can yield significant improvements compared with traditional KD algorithms and is less sensitive to the choice of different student capacity and hyperparameters, facilitating the use of KD on different tasks and models .
How to learn a better speech representation for end-to-end speech-to-text translation (ST) with limited labeled data? Existing techniques often attempt to transfer powerful machine translation (MT) capabilities to ST, but neglect the representation discrepancy across modalities .
In this paper, we propose the Speech-TExt Manifold Mixup (STEMM) method to calibrate such discrepancy .
Specifically, we mix up the representation sequences of different modalities, and take both unimodal speech sequences and multimodal mixed sequences as input to the translation model in parallel, and regularize their output predictions with a self-learning framework .
Experiments on MuST-C speech translation benchmark and further analysis show that our method effectively alleviates the cross-modal representation discrepancy, and achieves significant improvements over a strong baseline on eight translation directions .
Lexically constrained neural machine translation (NMT), which controls the generation of NMT models with pre-specified constraints, is important in many practical scenarios .
Due to the representation gap between discrete constraints and continuous vectors in NMT models, most existing works choose to construct synthetic data or modify the decoding algorithm to impose lexical constraints, treating the NMT model as a black box .
In this work, we propose to open this black box by directly integrating the constraints into NMT models .
Specifically, we vectorize source and target constraints into continuous keys and values, which can be utilized by the attention modules of NMT models .
The proposed integration method is based on the assumption that the correspondence between keys and values in attention modules is naturally suitable for modeling constraint pairs .
Experimental results show that our method consistently outperforms several representative baselines on four language pairs, demonstrating the superiority of integrating vectorized lexical constraints .
In order to better understand the rationale behind model behavior, recent works have exploited providing interpretation to support the inference prediction .
However, existing methods tend to provide human-unfriendly interpretation, and are prone to sub-optimal performance due to one-side promotion, i.e .
either inference promotion with interpretation or vice versa .
In this paper, we propose a multi-level Mutual Promotion mechanism for self-evolved Inference and sentence-level Interpretation (MPII) .
Specifically, from the model-level, we propose a Step-wise Integration Mechanism to jointly perform and deeply integrate inference and interpretation in an autoregressive manner .
From the optimization-level, we propose an Adversarial Fidelity Regularization to improve the fidelity between inference and interpretation with the Adversarial Mutual Information training strategy .
Extensive experiments on NLI and CQA tasks reveal that the proposed MPII approach can significantly outperform baseline models for both the inference performance and the interpretation quality .
The Mixture-of-Experts (MoE) technique can scale up the model size of Transformers with an affordable computational overhead .
We point out that existing learning-to-route MoE methods suffer from the routing fluctuation issue, i.e., the target expert of the same input may change along with training, but only one expert will be activated for the input during inference .
The routing fluctuation tends to harm sample efficiency because the same input updates different experts but only one is finally used .
In this paper, we propose StableMoE with two training stages to address the routing fluctuation problem .
In the first training stage, we learn a balanced and cohesive routing strategy and distill it into a lightweight router decoupled from the backbone model .
In the second training stage, we utilize the distilled router to determine the token-to-expert assignment and freeze it for a stable routing strategy .
We validate our method on language modeling and multilingual machine translation .
The results show that StableMoE outperforms existing MoE methods in terms of both convergence speed and performance .
Neural named entity recognition (NER) models may easily encounter the over-confidence issue, which degrades the performance and calibration .
Inspired by label smoothing and driven by the ambiguity of boundary annotation in NER engineering, we propose boundary smoothing as a regularization technique for span-based neural NER models .
It re-assigns entity probabilities from annotated spans to the surrounding ones .
Built on a simple but strong baseline, our model achieves results better than or competitive with previous state-of-the-art systems on eight well-known NER benchmarks .
Further empirical analysis suggests that boundary smoothing effectively mitigates over-confidence, improves model calibration, and brings flatter neural minima and more smoothed loss landscapes .
Hierarchical text classification is a challenging subtask of multi-label classification due to its complex label hierarchy .
Existing methods encode text and label hierarchy separately and mix their representations for classification, where the hierarchy remains unchanged for all input text .
Instead of modeling them separately, in this work, we propose Hierarchy-guided Contrastive Learning (HGCLR) to directly embed the hierarchy into a text encoder .
During training, HGCLR constructs positive samples for input text under the guidance of the label hierarchy .
By pulling together the input text and its positive sample, the text encoder can learn to generate the hierarchy-aware text representation independently .
Therefore, after training, the HGCLR enhanced text encoder can dispense with the redundant hierarchy .
Extensive experiments on three benchmark datasets verify the effectiveness of HGCLR .
Natural language processing models learn word representations based on the distributional hypothesis, which asserts that word context (e.g., co-occurrence) correlates with meaning .
We propose that n-grams composed of random character sequences, or garble, provide a novel context for studying word meaning both within and beyond extant language .
In particular, randomly generated character n-grams lack meaning but contain primitive information based on the distribution of characters they contain .
By studying the embeddings of a large corpus of garble, extant language, and pseudowords using CharacterBERT, we identify an axis in the model’s high-dimensional embedding space that separates these classes of n-grams .
Furthermore, we show that this axis relates to structure within extant language, including word part-of-speech, morphology, and concept concreteness .
Thus, in contrast to studies that are mainly limited to extant language, our work reveals that meaning and primitive information are intrinsically linked .
To alleviate the data scarcity problem in training question answering systems, recent works propose additional intermediate pre-training for dense passage retrieval (DPR) .
However, there still remains a large discrepancy between the provided upstream signals and the downstream question-passage relevance, which leads to less improvement .
To bridge this gap, we propose the HyperLink-induced Pre-training (HLP), a method to pre-train the dense retriever with the text relevance induced by hyperlink-based topology within Web documents .
We demonstrate that the hyperlink-based structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval .
We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zero-shot, few-shot, multi-hop, and out-of-domain scenarios .
The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by more than 10 points in terms of top-20 retrieval accuracy under the zero-shot scenario .
Furthermore, HLP significantly outperforms other pre-training methods under the other scenarios .
Recent machine reading comprehension datasets such as ReClor and LogiQA require performing logical reasoning over text .
Conventional neural models are insufficient for logical reasoning, while symbolic reasoners cannot directly apply to text .
To meet the challenge, we present a neural-symbolic approach which, to predict an answer, passes messages over a graph representing logical relations between text units .
It incorporates an adaptive logic graph network (AdaLoGN) which adaptively infers logical relations to extend the graph and, essentially, realizes mutual and iterative reinforcement between neural and symbolic reasoning .
We also implement a novel subgraph-to-node message passing mechanism to enhance context-option interaction for answering multiple-choice questions .
Our approach shows promising results on ReClor and LogiQA .
Model ensemble is a popular approach to produce a low-variance and well-generalized model .
However, it induces large memory and inference costs, which is often not affordable for real-world deployment .
Existing work has resorted to sharing weights among models .
However, when increasing the proportion of the shared weights, the resulting models tend to be similar, and the benefits of using model ensemble diminish .
To retain ensemble benefits while maintaining a low memory cost, we propose a consistency-regularized ensemble learning approach based on perturbed models, named CAMERO .
Specifically, we share the weights of bottom layers across all models and apply different perturbations to the hidden representations for different models, which can effectively promote the model diversity .
Meanwhile, we apply a prediction consistency regularizer across the perturbed models to control the variance due to the model diversity .
Our experiments using large language models demonstrate that CAMERO significantly improves the generalization performance of the ensemble model .
Specifically, CAMERO outperforms the standard ensemble of 8 BERT-base models on the GLUE benchmark by 0.7 with a significantly smaller model size (114.2M vs .
880.6M) .
Grammatical Error Correction (GEC) should not focus only on high accuracy of corrections but also on interpretability for language learning.However, existing neural-based GEC models mainly aim at improving accuracy, and their interpretability has not been explored.A promising approach for improving interpretability is an example-based method, which uses similar retrieved examples to generate corrections .
In addition, examples are beneficial in language learning, helping learners understand the basis of grammatically incorrect/correct texts and improve their confidence in writing.Therefore, we hypothesize that incorporating an example-based method into GEC can improve interpretability as well as support language learners.In this study, we introduce an Example-Based GEC (EB-GEC) that presents examples to language learners as a basis for a correction result.The examples consist of pairs of correct and incorrect sentences similar to a given input and its predicted correction.Experiments demonstrate that the examples presented by EB-GEC help language learners decide to accept or refuse suggestions from the GEC output.Furthermore, the experiments also show that retrieved examples improve the accuracy of corrections .
Negative sampling is highly effective in handling missing annotations for named entity recognition (NER) .
One of our contributions is an analysis on how it makes sense through introducing two insightful concepts: missampling and uncertainty .
Empirical studies show low missampling rate and high uncertainty are both essential for achieving promising performances with negative sampling .
Based on the sparsity of named entities, we also theoretically derive a lower bound for the probability of zero missampling rate, which is only relevant to sentence length .
The other contribution is an adaptive and weighted sampling distribution that further improves negative sampling via our former analysis .
Experiments on synthetic datasets and well-annotated datasets (e.g., CoNLL-2003) show that our proposed approach benefits negative sampling in terms of F1 score and loss convergence .
Besides, models with improved negative sampling have achieved new state-of-the-art results on real-world datasets (e.g., EC) .
In this paper, we study the named entity recognition (NER) problem under distant supervision .
Due to the incompleteness of the external dictionaries and/or knowledge bases, such distantly annotated training data usually suffer from a high false negative rate .
To this end, we formulate the Distantly Supervised NER (DS-NER) problem via Multi-class Positive and Unlabeled (MPU) learning and propose a theoretically and practically novel CONFidence-based MPU (Conf-MPU) approach .
To handle the incomplete annotations, Conf-MPU consists of two steps .
First, a confidence score is estimated for each token of being an entity token .
Then, the proposed Conf-MPU risk estimation is applied to train a multi-class classifier for the NER task .
Thorough experiments on two benchmark datasets labeled by various external knowledge demonstrate the superiority of the proposed Conf-MPU over existing DS-NER methods .
Our code is available at Github .
Pre-trained models for programming languages have recently demonstrated great success on code intelligence .
To support both code-related understanding and generation tasks, recent works attempt to pre-train unified encoder-decoder models .
However, such encoder-decoder framework is sub-optimal for auto-regressive tasks, especially code completion that requires a decoder-only manner for efficient inference .
In this paper, we present UniXcoder, a unified cross-modal pre-trained model for programming language .
The model utilizes mask attention matrices with prefix adapters to control the behavior of the model and leverages cross-modal contents like AST and code comment to enhance code representation .
To encode AST that is represented as a tree in parallel, we propose a one-to-one mapping method to transform AST in a sequence structure that retains all structural information from the tree .
Furthermore, we propose to utilize multi-modal contents to learn representation of code fragment with contrastive learning, and then align representations among programming languages using a cross-modal generation task .
We evaluate UniXcoder on five code-related tasks over nine datasets .
To further evaluate the performance of code fragment representation, we also construct a dataset for a new task, called zero-shot code-to-code search .
Results show that our model achieves state-of-the-art performance on most tasks and analysis reveals that comment and AST can both enhance UniXcoder .
NLP research is impeded by a lack of resources and awareness of the challenges presented by underrepresented languages and dialects .
Focusing on the languages spoken in Indonesia, the second most linguistically diverse and the fourth most populous nation of the world, we provide an overview of the current state of NLP research for Indonesia’s 700+ languages .
We highlight challenges in Indonesian NLP and how these affect the performance of current NLP systems .
Finally, we provide general recommendations to help develop NLP technology not only for languages of Indonesia but also other underrepresented languages .
Modern neural language models can produce remarkably fluent and grammatical text .
So much, in fact, that recent work by Clark et al .
(2021) has reported that conventional crowdsourcing can no longer reliably distinguish between machine-authored (GPT-3) and human-authored writing .
As errors in machine generations become ever subtler and harder to spot, it poses a new challenge to the research community for robust machine text evaluation.We propose a new framework called Scarecrow for scrutinizing machine text via crowd annotation .
To support the broad range of real machine errors that can be identified by laypeople, the ten error categories of Scarecrow—such as redundancy, commonsense errors, and incoherence—are identified through several rounds of crowd annotation experiments without a predefined ontology.We then use Scarecrow to collect over 41k error spans in human-written and machine-generated paragraphs of English language news text .
We isolate factors for detailed analysis, including parameter count, training data, and various decoding-time configurations .
Our approach successfully quantifies measurable gaps between human authored text and generations from models of several sizes, including fourteen configurations of GPT-3 .
In addition, our analysis unveils new insights, with detailed rationales provided by laypeople, e.g., that the commonsense capabilities have been improving with larger models while math capabilities have not, and that the choices of simple decoding hyperparameters can make remarkable differences on the perceived quality of machine text .
We release our training material, annotation toolkit and dataset at https://yao-dou.github.io/scarecrow/ .
Transformer architecture has become the de-facto model for many machine learning tasks from natural language processing and computer vision .
As such, improving its computational efficiency becomes paramount .
One of the major computational inefficiency of Transformer based models is that they spend the identical amount of computation throughout all layers .
Prior works have proposed to augment the Transformer model with the capability of skimming tokens to improve its computational efficiency .
However, they suffer from not having effectual and end-to-end optimization of the discrete skimming predictor .
To address the above limitations, we propose the Transkimmer architecture, which learns to identify hidden state tokens that are not required by each layer .
The skimmed tokens are then forwarded directly to the final output, thus reducing the computation of the successive layers .
The key idea in Transkimmer is to add a parameterized predictor before each layer that learns to make the skimming decision .
We also propose to adopt reparameterization trick and add skim loss for the end-to-end training of Transkimmer .
Transkimmer achieves 10.97x average speedup on GLUE benchmark compared with vanilla BERT-base baseline with less than 1% accuracy degradation .
In this paper, we propose SkipBERT to accelerate BERT inference by skipping the computation of shallow layers .
To achieve this, our approach encodes small text chunks into independent representations, which are then materialized to approximate the shallow representation of BERT .
Since the use of such approximation is inexpensive compared with transformer calculations, we leverage it to replace the shallow layers of BERT to skip their runtime overhead .
With off-the-shelf early exit mechanisms, we also skip redundant computation from the highest few layers to further improve inference efficiency .
Results on GLUE show that our approach can reduce latency by 65% without sacrificing performance .
By using only two-layer transformer calculations, we can still maintain 95% accuracy of BERT .
We investigate what kind of structural knowledge learned in neural network encoders is transferable to processing natural language.We design artificial languages with structural properties that mimic natural language, pretrain encoders on the data, and see how much performance the encoder exhibits on downstream tasks in natural language.Our experimental results show that pretraining with an artificial language with a nesting dependency structure provides some knowledge transferable to natural language.A follow-up probing analysis indicates that its success in the transfer is related to the amount of encoded contextual information and what is transferred is the knowledge of position-aware context dependence of language.Our results provide insights into how neural network encoders process human languages and the source of cross-lingual transferability of recent multilingual language models .
Recent studies have shown that multilingual pretrained language models can be effectively improved with cross-lingual alignment information from Wikipedia entities.However, existing methods only exploit entity information in pretraining and do not explicitly use entities in downstream tasks.In this study, we explore the effectiveness of leveraging entity representations for downstream cross-lingual tasks.We train a multilingual language model with 24 languages with entity representations and showthe model consistently outperforms word-based pretrained models in various cross-lingual transfer tasks.We also analyze the model and the key insight is that incorporating entity representations into the input allows us to extract more language-agnostic features.We also evaluate the model with a multilingual cloze prompt task with the mLAMA dataset.We show that entity-based prompt elicits correct factual knowledge more likely than using only word representations .
Automated simplification models aim to make input texts more readable .
Such methods have the potential to make complex information accessible to a wider audience, e.g., providing access to recent medical literature which might otherwise be impenetrable for a lay reader .
However, such models risk introducing errors into automatically simplified texts, for instance by inserting statements unsupported by the corresponding original text, or by omitting key information .
Providing more readable but inaccurate versions of texts may in many cases be worse than providing no such access at all .
The problem of factual accuracy (and the lack thereof) has received heightened attention in the context of summarization models, but the factuality of automatically simplified texts has not been investigated .
We introduce a taxonomy of errors that we use to analyze both references drawn from standard simplification datasets and state-of-the-art model outputs .
We find that errors often appear in both that are not captured by existing evaluation metrics, motivating a need for research into ensuring the factual accuracy of automated simplification models .
This paper describes the motivation and development of speech synthesis systems for the purposes of language revitalization .
By building speech synthesis systems for three Indigenous languages spoken in Canada, Kanien’kéha, Gitksan & SENĆOŦEN, we re-evaluate the question of how much data is required to build low-resource speech synthesis systems featuring state-of-the-art neural models .
For example, preliminary results with English data show that a FastSpeech2 model trained with 1 hour of training data can produce speech with comparable naturalness to a Tacotron2 model trained with 10 hours of data .
Finally, we motivate future research in evaluation and classroom integration in the field of speech synthesis for language revitalization .
The allure of superhuman-level capabilities has led to considerable interest in language models like GPT-3 and T5, wherein the research has, by and large, revolved around new model architectures, training tasks, and loss objectives, along with substantial engineering efforts to scale up model capacity and dataset size .
Comparatively little work has been done to improve the generalization of these models through better optimization .
In this work, we show that Sharpness-Aware Minimization (SAM), a recently proposed optimization procedure that encourages convergence to flatter minima, can substantially improve the generalization of language models without much computational overhead .
We show that SAM is able to boost performance on SuperGLUE, GLUE, Web Questions, Natural Questions, Trivia QA, and TyDiQA, with particularly large gains when training data for these tasks is limited .
Recent advances in natural language processing have enabled powerful privacy-invasive authorship attribution .
To counter authorship attribution, researchers have proposed a variety of rule-based and learning-based text obfuscation approaches .
However, existing authorship obfuscation approaches do not consider the adversarial threat model .
Specifically, they are not evaluated against adversarially trained authorship attributors that are aware of potential obfuscation .
To fill this gap, we investigate the problem of adversarial authorship attribution for deobfuscation .
We show that adversarially trained authorship attributors are able to degrade the effectiveness of existing obfuscators from 20-30% to 5-10% .
We also evaluate the effectiveness of adversarial training when the attributor makes incorrect assumptions about whether and which obfuscator was used .
While there is a a clear degradation in attribution accuracy, it is noteworthy that this degradation is still at or above the attribution accuracy of the attributor that is not adversarially trained at all .
Our results motivate the need to develop authorship obfuscation approaches that are resistant to deobfuscation .
Word and morpheme segmentation are fundamental steps of language documentation as they allow to discover lexical units in a language for which the lexicon is unknown .
However, in most language documentation scenarios, linguists do not start from a blank page: they may already have a pre-existing dictionary or have initiated manual segmentation of a small part of their data .
This paper studies how such a weak supervision can be taken advantage of in Bayesian non-parametric models of segmentation .
Our experiments on two very low resource languages (Mboshi and Japhug), whose documentation is still in progress, show that weak supervision can be beneficial to the segmentation quality .
In addition, we investigate an incremental learning scenario where manual segmentations are provided in a sequential manner .
This work opens the way for interactive annotation tools for documentary linguists .
Existing Natural Language Inference (NLI) datasets, while being instrumental in the advancement of Natural Language Understanding (NLU) research, are not related to scientific text .
In this paper, we introduce SciNLI, a large dataset for NLI that captures the formality in scientific text and contains 107,412 sentence pairs extracted from scholarly papers on NLP and computational linguistics .
Given that the text used in scientific literature differs vastly from the text used in everyday language both in terms of vocabulary and sentence structure, our dataset is well suited to serve as a benchmark for the evaluation of scientific NLU models .
Our experiments show that SciNLI is harder to classify than the existing NLI datasets .
Our best performing model with XLNet achieves a Macro F1 score of only 78.18% and an accuracy of 78.23% showing that there is substantial room for improvement .
In lexicalist linguistic theories, argument structure is assumed to be predictable from the meaning of verbs .
As a result, the verb is the primary determinant of the meaning of a clause .
In contrast, construction grammarians propose that argument structure is encoded in constructions (or form-meaning pairs) that are distinct from verbs .
Two decades of psycholinguistic research have produced substantial empirical evidence in favor of the construction view .
Here we adapt several psycholinguistic studies to probe for the existence of argument structure constructions (ASCs) in Transformer-based language models (LMs) .
First, using a sentence sorting experiment, we find that sentences sharing the same construction are closer in embedding space than sentences sharing the same verb .
Furthermore, LMs increasingly prefer grouping by construction with more input data, mirroring the behavior of non-native language learners .
Second, in a “Jabberwocky” priming-based experiment, we find that LMs associate ASCs with meaning, even in semantically nonsensical sentences .
Our work offers the first evidence for ASCs in LMs and highlights the potential to devise novel probing methods grounded in psycholinguistic research .
Social media platforms are deploying machine learning based offensive language classification systems to combat hateful, racist, and other forms of offensive speech at scale .
However, despite their real-world deployment, we do not yet comprehensively understand the extent to which offensive language classifiers are robust against adversarial attacks .
Prior work in this space is limited to studying robustness of offensive language classifiers against primitive attacks such as misspellings and extraneous spaces .
To address this gap, we systematically analyze the robustness of state-of-the-art offensive language classifiers against more crafty adversarial attacks that leverage greedy- and attention-based word selection and context-aware embeddings for word replacement .
Our results on multiple datasets show that these crafty adversarial attacks can degrade the accuracy of offensive language classifiers by more than 50% while also being able to preserve the readability and meaning of the modified text .
Style transfer is the task of rewriting a sentence into a target style while approximately preserving content .
While most prior literature assumes access to a large style-labelled corpus, recent work (Riley et al .
2021) has attempted “few-shot” style transfer using only 3-10 sentences at inference for style extraction .
In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available .
We notice that existing few-shot methods perform this task poorly, often copying inputs verbatim .
We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases .
When compared to prior work, our model achieves 2-3x better performance in formality transfer and code-mixing addition across seven languages .
Moreover, our method is better at controlling the style transfer magnitude using an input scalar knob .
We report promising qualitative results for several attribute transfer tasks (sentiment transfer, simplification, gender neutralization, text anonymization) all without retraining the model .
Finally, we find model evaluation to be difficult due to the lack of datasets and metrics for many languages .
To facilitate future research we crowdsource formality annotations for 4000 sentence pairs in four Indic languages, and use this data to design our automatic evaluations .
Transformer architectures have achieved state- of-the-art results on a variety of natural language processing (NLP) tasks .
However, their attention mechanism comes with a quadratic complexity in sequence lengths, making the computational overhead prohibitive, especially for long sequences .
Attention context can be seen as a random-access memory with each token taking a slot .
Under this perspective, the memory size grows linearly with the sequence length, and so does the overhead of reading from it .
One way to improve the efficiency is to bound the memory size .
We show that disparate approaches can be subsumed into one abstraction, attention with bounded-memory control (ABC), and they vary in their organization of the memory .
ABC reveals new, unexplored possibilities .
First, it connects several efficient attention variants that would otherwise seem apart .
Second, this abstraction gives new insights—an established approach (Wang et al., 2020b) previously thought to not be applicable in causal attention, actually is .
Last, we present a new instance of ABC, which draws inspiration from existing ABC approaches, but replaces their heuristic memory-organizing functions with a learned, contextualized one .
Our experiments on language modeling, machine translation, and masked language model finetuning show that our approach outperforms previous efficient attention models; compared to the strong transformer baselines, it significantly improves the inference time and space efficiency with no or negligible accuracy loss .
Researchers in NLP often frame and discuss research results in ways that serve to deemphasize the field’s successes, often in response to the field’s widespread hype .
Though well-meaning, this has yielded many misleading or false claims about the limits of our best technology .
This is a problem, and it may be more serious than it looks: It harms our credibility in ways that can make it harder to mitigate present-day harms, like those involving biased systems for content moderation or resume screening .
It also limits our ability to prepare for the potentially enormous impacts of more distant future advances .
This paper urges researchers to be careful about these claims and suggests some research directions and communication strategies that will make it easier to avoid or rebut them .
Humanities scholars commonly provide evidence for claims that they make about a work of literature (e.g., a novel) in the form of quotations from the work .
We collect a large-scale dataset (RELiC) of 78K literary quotations and surrounding critical analysis and use it to formulate the novel task of literary evidence retrieval, in which models are given an excerpt of literary analysis surrounding a masked quotation and asked to retrieve the quoted passage from the set of all passages in the work .
Solving this retrieval task requires a deep understanding of complex literary and linguistic phenomena, which proves challenging to methods that overwhelmingly rely on lexical and semantic similarity matching .
We implement a RoBERTa-based dense passage retriever for this task that outperforms existing pretrained information retrieval baselines; however, experiments and analysis by human domain experts indicate that there is substantial room for improvement .
Vision and language navigation (VLN) is a challenging visually-grounded language understanding task .
Given a natural language navigation instruction, a visual agent interacts with a graph-based environment equipped with panorama images and tries to follow the described route .
Most prior work has been conducted in indoor scenarios where best results were obtained for navigation on routes that are similar to the training routes, with sharp drops in performance when testing on unseen environments .
We focus on VLN in outdoor scenarios and find that in contrast to indoor VLN, most of the gain in outdoor VLN on unseen data is due to features like junction type embedding or heading delta that are specific to the respective environment graph, while image information plays a very minor role in generalizing VLN to unseen outdoor areas .
These findings show a bias to specifics of graph representations of urban environments, demanding that VLN tasks grow in scale and diversity of geographical environments .
Neural coreference resolution models trained on one dataset may not transfer to new, low-resource domains .
Active learning mitigates this problem by sampling a small subset of data for annotators to label .
While active learning is well-defined for classification tasks, its application to coreference resolution is neither well-defined nor fully understood .
This paper explores how to actively label coreference, examining sources of model uncertainty and document reading costs .
We compare uncertainty sampling strategies and their advantages through thorough error analysis .
In both synthetic and human experiments, labeling spans within the same document is more effective than annotating spans across documents .
The findings contribute to a more realistic development of coreference resolution models .
We propose a framework for training non-autoregressive sequence-to-sequence models for editing tasks, where the original input sequence is iteratively edited to produce the output .
We show that the imitation learning algorithms designed to train such models for machine translation introduces mismatches between training and inference that lead to undertraining and poor generalization in editing scenarios .
We address this issue with two complementary strategies: 1) a roll-in policy that exposes the model to intermediate training sequences that it is more likely to encounter during inference, 2) a curriculum that presents easy-to-learn edit operations first, gradually increasing the difficulty of training samples as the model becomes competent .
We show the efficacy of these strategies on two challenging English editing tasks: controllable text simplification and abstractive summarization .
Our approach significantly improves output quality on both tasks and controls output complexity better on the simplification task .
State-of-the-art pre-trained language models have been shown to memorise facts and perform well with limited amounts of training data .
To gain a better understanding of how these models learn, we study their generalisation and memorisation capabilities in noisy and low-resource scenarios .
We find that the training of these models is almost unaffected by label noise and that it is possible to reach near-optimal results even on extremely noisy datasets .
However, our experiments also show that they mainly learn from high-frequency patterns and largely fail when tested on low-resource tasks such as few-shot learning and rare entity recognition .
To mitigate such limitations, we propose an extension based on prototypical networks that improves performance in low-resource named entity recognition tasks .
Existing automatic evaluation systems of chatbots mostly rely on static chat scripts as ground truth, which is hard to obtain, and requires access to the models of the bots as a form of “white-box testing” .
Interactive evaluation mitigates this problem but requires human involvement .
In our work, we propose an interactive chatbot evaluation framework in which chatbots compete with each other like in a sports tournament, using flexible scoring metrics .
This framework can efficiently rank chatbots independently from their model architectures and the domains for which they are trained .
Self-supervised models for speech processing form representational spaces without using any external labels .
Increasingly, they appear to be a feasible way of at least partially eliminating costly manual annotations, a problem of particular concern for low-resource languages .
But what kind of representational spaces do these models construct?Human perception specializes to the sounds of listeners’ native languages .
Does the same thing happen in self-supervised models? We examine the representational spaces of three kinds of state of the art self-supervised models: wav2vec, HuBERT and contrastive predictive coding (CPC), and compare them with the perceptual spaces of French-speaking and English-speaking human listeners, both globally and taking account of the behavioural differences between the two language groups .
We show that the CPC model shows a small native language effect, but that wav2vec and HuBERT seem to develop a universal speech perception space which is not language specific .
A comparison against the predictions of supervised phone recognisers suggests that all three self-supervised models capture relatively fine-grained perceptual phenomena, while supervised models are better at capturing coarser, phone-level effects, and effects of listeners’ native language, on perception .
A long-term goal of AI research is to build intelligent agents that can communicate with humans in natural language, perceive the environment, and perform real-world tasks .
Vision-and-Language Navigation (VLN) is a fundamental and interdisciplinary research topic towards this goal, and receives increasing attention from natural language processing, computer vision, robotics, and machine learning communities .
In this paper, we review contemporary studies in the emerging field of VLN, covering tasks, evaluation metrics, methods, etc .
Through structured analysis of current progress and challenges, we also highlight the limitations of current VLN and opportunities for future work .
This paper serves as a thorough reference for the VLN research community .
Table fact verification aims to check the correctness of textual statements based on given semi-structured data .
Most existing methods are devoted to better comprehending logical operations and tables, but they hardly study generating latent programs from statements, with which we can not only retrieve evidences efficiently but also explain reasons behind verifications naturally .
However, it is challenging to get correct programs with existing weakly supervised semantic parsers due to the huge search space with lots of spurious programs .
In this paper, we address the challenge by leveraging both lexical features and structure features for program generation .
Through analyzing the connection between the program tree and the dependency tree, we define a unified concept, operation-oriented tree, to mine structure features, and introduce Structure-Aware Semantic Parsing to integrate structure features into program generation .
Moreover, we design a refined objective function with lexical features and violation punishments to further avoid spurious programs .
Experimental results show that our proposed method generates programs more accurately than existing semantic parsers, and achieves comparable performance to the SOTA on the large-scale benchmark TABFACT .
In real-world scenarios, a text classification task often begins with a cold start, when labeled data is scarce .
In such cases, the common practice of fine-tuning pre-trained models, such as BERT, for a target classification task, is prone to produce poor performance .
We suggest a method to boost the performance of such models by adding an intermediate unsupervised classification task, between the pre-training and fine-tuning phases .
As such an intermediate task, we perform clustering and train the pre-trained model on predicting the cluster labels.We test this hypothesis on various data sets, and show that this additional classification phase can significantly improve performance, mainly for topical classification tasks, when the number of labeled instances available for fine-tuning is only a couple of dozen to a few hundred .
Although transformers are remarkably effective for many tasks, there are some surprisingly easy-looking regular languages that they struggle with .
Hahn shows that for languages where acceptance depends on a single input symbol, a transformer’s classification decisions get closer and closer to random guessing (that is, a cross-entropy of 1) as input strings get longer and longer .
We examine this limitation using two languages: PARITY, the language of bit strings with an odd number of 1s, and FIRST, the language of bit strings starting with a 1 .
We demonstrate three ways of overcoming the limitation implied by Hahn’s lemma .
First, we settle an open question by constructing a transformer that recognizes PARITY with perfect accuracy, and similarly for FIRST .
Second, we use layer normalization to bring the cross-entropy of both models arbitrarily close to zero .
Third, when transformers need to focus on a single position, as for FIRST, we find that they can fail to generalize to longer strings; we offer a simple remedy to this problem that also improves length generalization in machine translation .
Regularization methods applying input perturbation have drawn considerable attention and have been frequently explored for NMT tasks in recent years .
Despite their simplicity and effectiveness, we argue that these methods are limited by the under-fitting of training data .
In this paper, we utilize prediction difference for ground-truth tokens to analyze the fitting of token-level samples and find that under-fitting is almost as common as over-fitting .
We introduce prediction difference regularization (PD-R), a simple and effective method that can reduce over-fitting and under-fitting at the same time .
For all token-level samples, PD-R minimizes the prediction difference between the original pass and the input-perturbed pass, making the model less sensitive to small input changes, thus more robust to both perturbations and under-fitted training data .
Experiments on three widely used WMT translation tasks show that our approach can significantly improve over existing perturbation regularization methods .
On WMT16 En-De task, our model achieves 1.80 SacreBLEU improvement over vanilla transformer .
Cross-lingual transfer learning with large multilingual pre-trained models can be an effective approach for low-resource languages with no labeled training data .
Existing evaluations of zero-shot cross-lingual generalisability of large pre-trained models use datasets with English training data, and test data in a selection of target languages .
We explore a more extensive transfer learning setup with 65 different source languages and 105 target languages for part-of-speech tagging .
Through our analysis, we show that pre-training of both source and target language, as well as matching language families, writing systems, word order systems, and lexical-phonetic distance significantly impact cross-lingual performance .
The findings described in this paper can be used as indicators of which factors are important for effective zero-shot cross-lingual transfer to zero- and low-resource languages .
Previous sarcasm generation research has focused on how to generate text that people perceive as sarcastic to create more human-like interactions .
In this paper, we argue that we should first turn our attention to the question of when sarcasm should be generated, finding that humans consider sarcastic responses inappropriate to many input utterances .
Next, we use a theory-driven framework for generating sarcastic responses, which allows us to control the linguistic devices included during generation .
For each device, we investigate how much humans associate it with sarcasm, finding that pragmatic insincerity and emotional markers are devices crucial for making sarcasm recognisable .
With the rapid development of deep learning, Seq2Seq paradigm has become prevalent for end-to-end data-to-text generation, and the BLEU scores have been increasing in recent years .
However, it is widely recognized that there is still a gap between the quality of the texts generated by models and the texts written by human .
In order to better understand the ability of Seq2Seq models, evaluate their performance and analyze the results, we choose to use Multidimensional Quality Metric(MQM) to evaluate several representative Seq2Seq models on end-to-end data-to-text generation .
We annotate the outputs of five models on four datasets with eight error types and find that 1) copy mechanism is helpful for the improvement in Omission and Inaccuracy Extrinsic errors but it increases other types of errors such as Addition; 2) pre-training techniques are highly effective, and pre-training strategy and model size are very significant; 3) the structure of the dataset also influences the model’s performance greatly; 4) some specific types of errors are generally challenging for seq2seq models .
Probing has become an important tool for analyzing representations in Natural Language Processing (NLP) .
For graphical NLP tasks such as dependency parsing, linear probes are currently limited to extracting undirected or unlabeled parse trees which do not capture the full task .
This work introduces DepProbe, a linear probe which can extract labeled and directed dependency parse trees from embeddings while using fewer parameters and compute than prior methods .
Leveraging its full task coverage and lightweight parametrization, we investigate its predictive power for selecting the best transfer language for training a full biaffine attention parser .
Across 13 languages, our proposed method identifies the best source treebank 94% of the time, outperforming competitive baselines and prior work .
Finally, we analyze the informativeness of task-specific subspaces in contextual embeddings as well as which benefits a full parser’s non-linear parametrization provides .
Natural language processing (NLP) algorithms have become very successful, but they still struggle when applied to out-of-distribution examples .
In this paper we propose a controllable generation approach in order to deal with this domain adaptation (DA) challenge .
Given an input text example, our DoCoGen algorithm generates a domain-counterfactual textual example (D-con) - that is similar to the original in all aspects, including the task label, but its domain is changed to a desired one .
Importantly, DoCoGen is trained using only unlabeled examples from multiple domains - no NLP task labels or parallel pairs of textual examples and their domain-counterfactuals are required .
We show that DoCoGen can generate coherent counterfactuals consisting of multiple sentences .
We use the D-cons generated by DoCoGen to augment a sentiment classifier and a multi-label intent classifier in 20 and 78 DA setups, respectively, where source-domain labeled data is scarce .
Our model outperforms strong baselines and improves the accuracy of a state-of-the-art unsupervised DA algorithm .
Structured document understanding has attracted considerable attention and made significant progress recently, owing to its crucial role in intelligent document processing .
However, most existing related models can only deal with the document data of specific language(s) (typically English) included in the pre-training collection, which is extremely limited .
To address this issue, we propose a simple yet effective Language-independent Layout Transformer (LiLT) for structured document understanding .
LiLT can be pre-trained on the structured documents of a single language and then directly fine-tuned on other languages with the corresponding off-the-shelf monolingual/multilingual pre-trained textual models .
Experimental results on eight languages have shown that LiLT can achieve competitive or even superior performance on diverse widely-used downstream benchmarks, which enables language-independent benefit from the pre-training of document layout structure .
Code and model are publicly available at https://github.com/jpWang/LiLT .
Various models have been proposed to incorporate knowledge of syntactic structures into neural language models .
However, previous works have relied heavily on elaborate components for a specific language model, usually recurrent neural network (RNN), which makes themselves unwieldy in practice to fit into other neural language models, such as Transformer and GPT-2 .
In this paper, we introduce the Dependency-based Mixture Language Models .
In detail, we first train neural language models with a novel dependency modeling objective to learn the probability distribution of future dependent tokens given context .
We then formulate the next-token probability by mixing the previous dependency modeling probability distributions with self-attention .
Extensive experiments and human evaluations show that our method can be easily and effectively applied to different neural language models while improving neural text generation on various tasks .
Identifying argument components from unstructured texts and predicting the relationships expressed among them are two primary steps of argument mining .
The intrinsic complexity of these tasks demands powerful learning models .
While pretrained Transformer-based Language Models (LM) have been shown to provide state-of-the-art results over different NLP tasks, the scarcity of manually annotated data and the highly domain-dependent nature of argumentation restrict the capabilities of such models .
In this work, we propose a novel transfer learning strategy to overcome these challenges .
We utilize argumentation-rich social discussions from the ChangeMyView subreddit as a source of unsupervised, argumentative discourse-aware knowledge by finetuning pretrained LMs on a selectively masked language modeling task .
Furthermore, we introduce a novel prompt-based strategy for inter-component relation prediction that compliments our proposed finetuning method while leveraging on the discourse context .
Exhaustive experiments show the generalization capability of our method on these two tasks over within-domain as well as out-of-domain datasets, outperforming several existing and employed strong baselines .
In this paper, we propose an entity-based neural local coherence model which is linguistically more sound than previously proposed neural coherence models .
Recent neural coherence models encode the input document using large-scale pretrained language models .
Hence their basis for computing local coherence are words and even sub-words .
The analysis of their output shows that these models frequently compute coherence on the basis of connections between (sub-)words which, from a linguistic perspective, should not play a role .
Still, these models achieve state-of-the-art performance in several end applications .
In contrast to these models, we compute coherence on the basis of entities by constraining the input to noun phrases and proper names .
This provides us with an explicit representation of the most important items in sentences leading to the notion of focus .
This brings our model linguistically in line with pre-neural models of computing coherence .
It also gives us better insight into the behaviour of the model thus leading to better explainability .
Our approach is also in accord with a recent study (O’Connor and Andreas, 2021), which shows that most usable information is captured by nouns and verbs in transformer-based language models .
We evaluate our model on three downstream tasks showing that it is not only linguistically more sound than previous models but also that it outperforms them in end applications .
Adversarial attacks are a major challenge faced by current machine learning research .
These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications .
Extensive research in computer vision has been carried to develop reliable defense strategies .
However, the same issue remains less explored in natural language processing .
Our work presents a model-agnostic detector of adversarial text examples .
The approach identifies patterns in the logits of the target classifier when perturbing the input text .
The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks .
How can language technology address the diverse situations of the world’s languages? In one view, languages exist on a resource continuum and the challenge is to scale existing solutions, bringing under-resourced languages into the high-resource world .
In another view, presented here, the world’s language ecology includes standardised languages, local languages, and contact languages .
These are often subsumed under the label of “under-resourced languages” even though they have distinct functions and prospects .
I explore this position and propose some ecologically-aware language technology agendas .
The evolution of language follows the rule of gradual change .
Grammar, vocabulary, and lexical semantic shifts take place over time, resulting in a diachronic linguistic gap .
As such, a considerable amount of texts are written in languages of different eras, which creates obstacles for natural language processing tasks, such as word segmentation and machine translation .
Although the Chinese language has a long history, previous Chinese natural language processing research has primarily focused on tasks within a specific era .
Therefore, we propose a cross-era learning framework for Chinese word segmentation (CWS), CROSSWISE, which uses the Switch-memory (SM) module to incorporate era-specific linguistic knowledge .
Experiments on four corpora from different eras show that the performance of each corpus significantly improves .
Further analyses also demonstrate that the SM can effectively integrate the knowledge of the eras into the neural network .
Although much work in NLP has focused on measuring and mitigating stereotypical bias in semantic spaces, research addressing bias in computational argumentation is still in its infancy .
In this paper, we address this research gap and conduct a thorough investigation of bias in argumentative language models .
To this end, we introduce ABBA, a novel resource for bias measurement specifically tailored to argumentation .
We employ our resource to assess the effect of argumentative fine-tuning and debiasing on the intrinsic bias found in transformer-based language models using a lightweight adapter-based approach that is more sustainable and parameter-efficient than full fine-tuning .
Finally, we analyze the potential impact of language model debiasing on the performance in argument quality prediction, a downstream task of computational argumentation .
Our results show that we are able to successfully and sustainably remove bias in general and argumentative language models while preserving (and sometimes improving) model performance in downstream tasks .
We make all experimental code and data available at https://github.com/umanlp/FairArgumentativeLM .
End-to-end simultaneous speech-to-text translation aims to directly perform translation from streaming source speech to target text with high translation quality and low latency .
A typical simultaneous translation (ST) system consists of a speech translation model and a policy module, which determines when to wait and when to translate .
Thus the policy is crucial to balance translation quality and latency .
Conventional methods usually adopt fixed policies, e.g .
segmenting the source speech with a fixed length and generating translation .
However, this method ignores contextual information and suffers from low translation quality .
This paper proposes an adaptive segmentation policy for end-to-end ST .
Inspired by human interpreters, the policy learns to segment the source streaming speech into meaningful units by considering both acoustic features and translation history, maintaining consistency between the segmentation and translation .
Experimental results on English-German and Chinese-English show that our method achieves a good accuracy-latency trade-off over recently proposed state-of-the-art methods .
Simile interpretation is a crucial task in natural language processing .
Nowadays, pre-trained language models (PLMs) have achieved state-of-the-art performance on many tasks .
However, it remains under-explored whether PLMs can interpret similes or not .
In this paper, we investigate the ability of PLMs in simile interpretation by designing a novel task named Simile Property Probing, i.e., to let the PLMs infer the shared properties of similes .
We construct our simile property probing datasets from both general textual corpora and human-designed questions, containing 1,633 examples covering seven main categories .
Our empirical study based on the constructed datasets shows that PLMs can infer similes’ shared properties while still underperforming humans .
To bridge the gap with human performance, we additionally design a knowledge-enhanced training objective by incorporating the simile knowledge into PLMs via knowledge embedding methods .
Our method results in a gain of 8.58% in the probing task and 1.37% in the downstream task of sentiment classification .
The datasets and code are publicly available at https://github.com/Abbey4799/PLMs-Interpret-Simile .
Artificial Intelligence (AI), along with the recent progress in biomedical language understanding, is gradually offering great promise for medical practice .
With the development of biomedical language understanding benchmarks, AI applications are widely used in the medical field .
However, most benchmarks are limited to English, which makes it challenging to replicate many of the successes in English for other languages .
To facilitate research in this direction, we collect real-world biomedical data and present the first Chinese Biomedical Language Understanding Evaluation (CBLUE) benchmark: a collection of natural language understanding tasks including named entity recognition, information extraction, clinical diagnosis normalization, single-sentence/sentence-pair classification, and an associated online platform for model evaluation, comparison, and analysis .
To establish evaluation on these tasks, we report empirical results with the current 11 pre-trained Chinese models, and experimental results show that state-of-the-art neural models perform by far worse than the human ceiling .
Text summarization aims to generate a short summary for an input text .
In this work, we propose a Non-Autoregressive Unsupervised Summarization (NAUS) approach, which does not require parallel data for training .
Our NAUS first performs edit-based search towards a heuristically defined score, and generates a summary as pseudo-groundtruth .
Then, we train an encoder-only non-autoregressive Transformer based on the search result .
We also propose a dynamic programming approach for length-control decoding, which is important for the summarization task .
Experiments on two datasets show that NAUS achieves state-of-the-art performance for unsupervised summarization, yet largely improving inference efficiency .
Further, our algorithm is able to perform explicit length-transfer summary generation .
The principal task in supervised neural machine translation (NMT) is to learn to generate target sentences conditioned on the source inputs from a set of parallel sentence pairs, and thus produce a model capable of generalizing to unseen instances .
However, it is commonly observed that the generalization performance of the model is highly influenced by the amount of parallel data used in training .
Although data augmentation is widely used to enrich the training data, conventional methods with discrete manipulations fail to generate diverse and faithful training samples .
In this paper, we present a novel data augmentation paradigm termed Continuous Semantic Augmentation (CsaNMT), which augments each training instance with an adjacency semantic region that could cover adequate variants of literal expression under the same meaning .
We conduct extensive experiments on both rich-resource and low-resource settings involving various language pairs, including WMT14 English→{German,French}, NIST Chinese→English and multiple low-resource IWSLT translation tasks .
The provided empirical evidences show that CsaNMT sets a new level of performance among existing augmentation techniques, improving on the state-of-the-art by a large margin .
The core codes are contained in Appendix E .
We propose knowledge internalization (KI), which aims to complement the lexical knowledge into neural dialog models .
Instead of further conditioning the knowledge-grounded dialog (KGD) models on externally retrieved knowledge, we seek to integrate knowledge about each input token internally into the model’s parameters .
To tackle the challenge due to the large scale of lexical knowledge, we adopt the contrastive learning approach and create an effective token-level lexical knowledge retriever that requires only weak supervision mined from Wikipedia .
We demonstrate the effectiveness and general applicability of our approach on various datasets and diversified model structures .
In this paper, we propose a mixture model-based end-to-end method to model the syntactic-semantic dependency correlation in Semantic Role Labeling (SRL) .
Semantic dependencies in SRL are modeled as a distribution over semantic dependency labels conditioned on a predicate and an argument word.The semantic label distribution varies depending on Shortest Syntactic Dependency Path (SSDP) hop patterns.We target the variation of semantic label distributions using a mixture model, separately estimating semantic label distributions for different hop patterns and probabilistically clustering hop patterns with similar semantic label distributions.Experiments show that the proposed method successfully learns a cluster assignment reflecting the variation of semantic label distributions.Modeling the variation improves performance in predicting short distance semantic dependencies, in addition to the improvement on long distance semantic dependencies that previous syntax-aware methods have achieved.The proposed method achieves a small but statistically significant improvement over baseline methods in English, German, and Spanish and obtains competitive performance with state-of-the-art methods in English .
We are interested in a novel task, singing voice beautification (SVB) .
Given the singing voice of an amateur singer, SVB aims to improve the intonation and vocal tone of the voice, while keeping the content and vocal timbre .
Current automatic pitch correction techniques are immature, and most of them are restricted to intonation but ignore the overall aesthetic quality .
Hence, we introduce Neural Singing Voice Beautifier (NSVB), the first generative model to solve the SVB task, which adopts a conditional variational autoencoder as the backbone and learns the latent representations of vocal tone .
In NSVB, we propose a novel time-warping approach for pitch correction: Shape-Aware Dynamic Time Warping (SADTW), which ameliorates the robustness of existing time-warping approaches, to synchronize the amateur recording with the template pitch curve .
Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one .
To achieve this, we also propose a new dataset containing parallel singing recordings of both amateur and professional versions .
Extensive experiments on both Chinese and English songs demonstrate the effectiveness of our methods in terms of both objective and subjective metrics .
Audio samples are available at https://neuralsvb.github.io .
Codes: https://github.com/MoonInTheRiver/NeuralSVB .
Towards building intelligent dialogue agents, there has been a growing interest in introducing explicit personas in generation models .
However, with limited persona-based dialogue data at hand, it may be difficult to train a dialogue generation model well .
We point out that the data challenges of this generation task lie in two aspects: first, it is expensive to scale up current persona-based dialogue datasets; second, each data sample in this task is more complex to learn with than conventional dialogue data .
To alleviate the above data issues, we propose a data manipulation method, which is model-agnostic to be packed with any persona-based dialogue generation model to improve their performance .
The original training samples will first be distilled and thus expected to be fitted more easily .
Next, we show various effective ways that can diversify such easier distilled data .
A given base model will then be trained via the constructed data curricula, i.e .
first on augmented distilled samples and then on original ones .
Experiments illustrate the superiority of our method with two strong base dialogue models (Transformer encoder-decoder and GPT2) .
Language model (LM) pretraining captures various knowledge from text corpora, helping downstream tasks .
However, existing methods such as BERT model a single document, and do not capture dependencies or knowledge that span across documents .
In this work, we propose LinkBERT, an LM pretraining method that leverages links between documents, e.g., hyperlinks .
Given a text corpus, we view it as a graph of documents and create LM inputs by placing linked documents in the same context .
We then pretrain the LM with two joint self-supervised objectives: masked language modeling and our new proposal, document relation prediction .
We show that LinkBERT outperforms BERT on various downstream tasks across two domains: the general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain (pretrained on PubMed with citation links) .
LinkBERT is especially effective for multi-hop reasoning and few-shot QA (+5% absolute improvement on HotpotQA and TriviaQA), and our biomedical LinkBERT sets new states of the art on various BioNLP tasks (+7% on BioASQ and USMLE) .
We release our pretrained models, LinkBERT and BioLinkBERT, as well as code and data .
Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., “Who was the president of the US before Obama?”) .
These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., “Obama” instead of 2000); 2) subtle lexical differences in time relations (e.g., “before” vs “after”); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions .
In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems .
TSQA features a timestamp estimation module to infer the unwritten timestamp from the question .
We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on .
With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG .
Phonemes are defined by their relationship to words: changing a phoneme changes the word .
Learning a phoneme inventory with little supervision has been a longstanding challenge with important applications to under-resourced speech technology .
In this paper, we bridge the gap between the linguistic and statistical definition of phonemes and propose a novel neural discrete representation learning model for self-supervised learning of phoneme inventory with raw speech and word labels .
Under mild assumptions, we prove that the phoneme inventory learned by our approach converges to the true one with an exponentially low error rate .
Moreover, in experiments on TIMIT and Mboshi benchmarks, our approach consistently learns a better phoneme-level representation and achieves a lower error rate in a zero-resource phoneme recognition task than previous state-of-the-art self-supervised representation learning algorithms .
Neural language models (LMs) such as GPT-2 estimate the probability distribution over the next word by a softmax over the vocabulary .
The softmax layer produces the distribution based on the dot products of a single hidden state and the embeddings of words in the vocabulary .
However, we discover that this single hidden state cannot produce all probability distributions regardless of the LM size or training data size because the single hidden state embedding cannot be close to the embeddings of all the possible next words simultaneously when there are other interfering word embeddings between them .
In this work, we demonstrate the importance of this limitation both theoretically and practically .
Our work not only deepens our understanding of softmax bottleneck and mixture of softmax (MoS) but also inspires us to propose multi-facet softmax (MFS) to address the limitations of MoS .
Extensive empirical analyses confirm our findings and show that against MoS, the proposed MFS achieves two-fold improvements in the perplexity of GPT-2 and BERT .
Conversational question answering aims to provide natural-language answers to users in information-seeking conversations .
Existing conversational QA benchmarks compare models with pre-collected human-human conversations, using ground-truth answers provided in conversational history .
It remains unclear whether we can rely on this static evaluation for model development and whether current systems can well generalize to real-world human-machine conversations .
In this work, we conduct the first large-scale human evaluation of state-of-the-art conversational QA systems, where human evaluators converse with models and judge the correctness of their answers .
We find that the distribution of human machine conversations differs drastically from that of human-human conversations, and there is a disagreement between human and gold-history evaluation in terms of model ranking .
We further investigate how to improve automatic evaluations, and propose a question rewriting mechanism based on predicted history, which better correlates with human judgments .
Finally, we analyze the impact of various modeling strategies and discuss future directions towards building better conversational question answering systems .
When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models .
We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are “fantastic” and some not .
We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another .
While one could use a development set to determine which permutations are performant, this would deviate from the true few-shot setting as it requires additional annotated data .
Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts .
Our method yields a 13% relative improvement for GPT-family models across eleven different established text classification tasks .
We teach goal-driven agents to interactively act and speak in situated environments by training on generated curriculums .
Our agents operate in LIGHT (Urbanek et al .
2019)—a large-scale crowd-sourced fantasy text adventure game wherein an agent perceives and interacts with the world through textual natural language .
Goals in this environment take the form of character-based quests, consisting of personas and motivations .
We augment LIGHT by learning to procedurally generate additional novel textual worlds and quests to create a curriculum of steadily increasing difficulty for training agents to achieve such goals .
In particular, we measure curriculum difficulty in terms of the rarity of the quest in the original training distribution—an easier environment is one that is more likely to have been found in the unaugmented dataset .
An ablation study shows that this method of learning from the tail of a distribution results in significantly higher generalization abilities as measured by zero-shot performance on never-before-seen quests .
Translation quality evaluation plays a crucial role in machine translation .
According to the input format, it is mainly separated into three tasks, i.e., reference-only, source-only and source-reference-combined .
Recent methods, despite their promising results, are specifically designed and optimized on one of them .
This limits the convenience of these methods, and overlooks the commonalities among tasks .
In this paper, we propose , which is the first unified framework engaged with abilities to handle all three evaluation tasks .
Concretely, we propose monotonic regional attention to control the interaction among input segments, and unified pretraining to better adapt multi-task training .
We testify our framework on WMT 2019 Metrics and WMT 2020 Quality Estimation benchmarks .
Extensive analyses show that our single model can universally surpass various state-of-the-art or winner methods across tasks.Both source code and associated models are available at https://github.com/NLP2CT/UniTE .
Program induction for answering complex questions over knowledge bases (KBs) aims to decompose a question into a multi-step program, whose execution against the KB produces the final answer .
Learning to induce programs relies on a large number of parallel question-program pairs for the given KB .
However, for most KBs, the gold program annotations are usually lacking, making learning difficult .
In this paper, we propose the approach of program transfer, which aims to leverage the valuable program annotations on the rich-resourced KBs as external supervision signals to aid program induction for the low-resourced KBs that lack program annotations .
For program transfer, we design a novel two-stage parsing framework with an efficient ontology-guided pruning strategy .
First, a sketch parser translates the question into a high-level program sketch, which is the composition of functions .
Second, given the question and sketch, an argument parser searches the detailed arguments from the KB for functions .
During the searching, we incorporate the KB ontology to prune the search space .
The experiments on ComplexWebQuestions and WebQuestionSP show that our method outperforms SOTA methods significantly, demonstrating the effectiveness of program transfer and our framework .
Our codes and datasets can be obtained from https://github.com/THU-KEG/ProgramTransfer .
Complete Multi-lingual Neural Machine Translation (C-MNMT) achieves superior performance against the conventional MNMT by constructing multi-way aligned corpus, i.e., aligning bilingual training examples from different language pairs when either their source or target sides are identical .
However, since exactly identical sentences from different language pairs are scarce, the power of the multi-way aligned corpus is limited by its scale .
To handle this problem, this paper proposes “Extract and Generate” (EAG), a two-step approach to construct large-scale and high-quality multi-way aligned corpus from bilingual data .
Specifically, we first extract candidate aligned examples by pairing the bilingual examples from different language pairs with highly similar source or target sentences; and then generate the final aligned examples from the candidates with a well-trained generation model .
With this two-step pipeline, EAG can construct a large-scale and multi-way aligned corpus whose diversity is almost identical to the original bilingual corpus .
Experiments on two publicly available datasets i.e., WMT-5 and OPUS-100, show that the proposed method achieves significant improvements over strong baselines, with +1.1 and +1.4 BLEU points improvements on the two datasets respectively .
Although contextualized embeddings generated from large-scale pre-trained models perform well in many tasks, traditional static embeddings (e.g., Skip-gram, Word2Vec) still play an important role in low-resource and lightweight settings due to their low computational cost, ease of deployment, and stability .
In this paper, we aim to improve word embeddings by 1) incorporating more contextual information from existing pre-trained models into the Skip-gram framework, which we call Context-to-Vec; 2) proposing a post-processing retrofitting method for static embeddings independent of training by employing priori synonym knowledge and weighted vector distribution .
Through extrinsic and intrinsic tasks, our methods are well proven to outperform the baselines by a large margin .
Sarcasm is important to sentiment analysis on social media .
Sarcasm Target Identification (STI) deserves further study to understand sarcasm in depth .
However, text lacking context or missing sarcasm target makes target identification very difficult .
In this paper, we introduce multimodality to STI and present Multimodal Sarcasm Target Identification (MSTI) task .
We propose a novel multi-scale cross-modality model that can simultaneously perform textual target labeling and visual target detection .
In the model, we extract multi-scale visual features to enrich spatial information for different sized visual sarcasm targets .
We design a set of convolution networks to unify multi-scale visual features with textual features for cross-modal attention learning, and correspondingly a set of transposed convolution networks to restore multi-scale visual information .
The results show that visual clues can improve the performance of TSTI by a large margin, and VSTI achieves good accuracy .
The dominant paradigm for high-performance models in novel NLP tasks today is direct specialization for the task via training from scratch or fine-tuning large pre-trained models .
But does direct specialization capture how humans approach novel language tasks? We hypothesize that human performance is better characterized by flexible inference through composition of basic computational motifs available to the human language user .
To test this hypothesis, we formulate a set of novel fragmentary text completion tasks, and compare the behavior of three direct-specialization models against a new model we introduce, GibbsComplete, which composes two basic computational motifs central to contemporary models: masked and autoregressive word prediction .
We conduct three types of evaluation: human judgments of completion quality, satisfaction of syntactic constraints imposed by the input fragment, and similarity to human behavior in the structural statistics of the completions .
With no task-specific parameter tuning, GibbsComplete performs comparably to direct-specialization models in the first two evaluations, and outperforms all direct-specialization models in the third evaluation .
These results support our hypothesis that human behavior in novel language tasks and environments may be better characterized by flexible composition of basic computational motifs rather than by direct specialization .
Non-autoregressive text to speech (NAR-TTS) models have attracted much attention from both academia and industry due to their fast generation speed .
One limitation of NAR-TTS models is that they ignore the correlation in time and frequency domains while generating speech mel-spectrograms, and thus cause blurry and over-smoothed results .
In this work, we revisit this over-smoothing problem from a novel perspective: the degree of over-smoothness is determined by the gap between the complexity of data distributions and the capability of modeling methods .
Both simplifying data distributions and improving modeling methods can alleviate the problem .
Accordingly, we first study methods reducing the complexity of data distributions .
Then we conduct a comprehensive study on NAR-TTS models that use some advanced modeling methods .
Based on these studies, we find that 1) methods that provide additional condition inputs reduce the complexity of data distributions to model, thus alleviating the over-smoothing problem and achieving better voice quality .
2) Among advanced modeling methods, Laplacian mixture loss performs well at modeling multimodal distributions and enjoys its simplicity, while GAN and Glow achieve the best voice quality while suffering from increased training or model complexity .
3) The two categories of methods can be combined to further alleviate the over-smoothness and improve the voice quality .
4) Our experiments on the multi-speaker dataset lead to similar conclusions as above and providing more variance information can reduce the difficulty of modeling the target data distribution and alleviate the requirements for model capacity .
Long-range semantic coherence remains a challenge in automatic language generation and understanding .
We demonstrate that large language models have insufficiently learned the effect of distant words on next-token prediction .
We present coherence boosting, an inference procedure that increases a LM’s focus on a long context .
We show the benefits of coherence boosting with pretrained models by distributional analyses of generated ordinary text and dialog responses .
It is also found that coherence boosting with state-of-the-art models for various zero-shot NLP tasks yields performance gains with no additional training .
Uncertainty estimation (UE) of model predictions is a crucial step for a variety of tasks such as active learning, misclassification detection, adversarial attack detection, out-of-distribution detection, etc .
Most of the works on modeling the uncertainty of deep neural networks evaluate these methods on image classification tasks .
Little attention has been paid to UE in natural language processing .
To fill this gap, we perform a vast empirical investigation of state-of-the-art UE methods for Transformer models on misclassification detection in named entity recognition and text classification tasks and propose two computationally efficient modifications, one of which approaches or even outperforms computationally intensive methods .
We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V&L) models for their visio-linguistic grounding capabilities on specific linguistic phenomena .
VALSE offers a suite of six tests covering various linguistic constructs .
Solving these requires models to ground linguistic phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible .
We build VALSE using methods that support the construction of valid foils, and report results from evaluating five widely-used V&L models .
Our experiments suggest that current models have considerable difficulty addressing most phenomena .
Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V&L models from a linguistic perspective, complementing the canonical task-centred V&L evaluations .
The learning trajectories of linguistic phenomena in humans provide insight into linguistic representation, beyond what can be gleaned from inspecting the behavior of an adult speaker .
To apply a similar approach to analyze neural language models (NLM), it is first necessary to establish that different models are similar enough in the generalizations they make .
In this paper, we show that NLMs with different initialization, architecture, and training data acquire linguistic phenomena in a similar order, despite their different end performance .
These findings suggest that there is some mutual inductive bias that underlies these models’ learning of linguistic phenomena .
Taking inspiration from psycholinguistics, we argue that studying this inductive bias is an opportunity to study the linguistic representation implicit in NLMs.Leveraging these findings, we compare the relative performance on different phenomena at varying learning stages with simpler reference models .
Results suggest that NLMs exhibit consistent “developmental” stages .
Moreover, we find the learning trajectory to be approximately one-dimensional: given an NLM with a certain overall performance, it is possible to predict what linguistic generalizations it has already acquired.Initial analysis of these stages presents phenomena clusters (notably morphological ones), whose performance progresses in unison, suggesting a potential link between the generalizations behind them .
Unfamiliar terminology and complex language can present barriers to understanding science .
Natural language processing stands to help address these issues by automatically defining unfamiliar terms .
We introduce a new task and dataset for defining scientific terms and controlling the complexity of generated definitions as a way of adapting to a specific reader’s background knowledge .
We test four definition generation methods for this new task, finding that a sequence-to-sequence approach is most successful .
We then explore the version of the task in which definitions are generated at a target complexity level .
We introduce a novel reranking approach and find in human evaluations that it offers superior fluency while also controlling complexity, compared to several controllable generation baselines .
In text classification tasks, useful information is encoded in the label names .
Label semantic aware systems have leveraged this information for improved text classification performance during fine-tuning and prediction .
However, use of label-semantics during pre-training has not been extensively explored .
We therefore propose Label Semantic Aware Pre-training (LSAP) to improve the generalization and data efficiency of text classification systems .
LSAP incorporates label semantics into pre-trained generative models (T5 in our case) by performing secondary pre-training on labeled sentences from a variety of domains .
As domain-general pre-training requires large amounts of data, we develop a filtering and labeling pipeline to automatically create sentence-label pairs from unlabeled text .
We perform experiments on intent (ATIS, Snips, TOPv2) and topic classification (AG News, Yahoo! Answers) .
LSAP obtains significant accuracy improvements over state-of-the-art models for few-shot text classification while maintaining performance comparable to state of the art in high-resource settings .
Residual networks are an Euler discretization of solutions to Ordinary Differential Equations (ODE) .
This paper explores a deeper relationship between Transformer and numerical ODE methods .
We first show that a residual block of layers in Transformer can be described as a higher-order solution to ODE .
Inspired by this, we design a new architecture, ODE Transformer, which is analogous to the Runge-Kutta method that is well motivated in ODE .
As a natural extension to Transformer, ODE Transformer is easy to implement and efficient to use .
Experimental results on the large-scale machine translation, abstractive summarization, and grammar error correction tasks demonstrate the high genericity of ODE Transformer .
It can gain large improvements in model performance over strong baselines (e.g., 30.77 and 44.11 BLEU scores on the WMT’14 English-German and English-French benchmarks) at a slight cost in inference efficiency .
Data sharing restrictions are common in NLP, especially in the clinical domain, but there is limited research on adapting models to new domains without access to the original training data, a setting known as source-free domain adaptation .
We take algorithms that traditionally assume access to the source-domain training data—active learning, self-training, and data augmentation—and adapt them for source free domain adaptation .
Then we systematically compare these different strategies across multiple tasks and domains .
We find that active learning yields consistent gains across all SemEval 2021 Task 10 tasks and domains, but though the shared task saw successful self-trained and data augmented models, our systematic comparison finds these strategies to be unreliable for source-free domain adaptation .
Several high-profile events, such as the mass testing of emotion recognition systems on vulnerable sub-populations and using question answering systems to make moral judgments, have highlighted how technology will often lead to more adverse outcomes for those that are already marginalized .
At issue here are not just individual systems and datasets, but also the AI tasks themselves .
In this position paper, I make a case for thinking about ethical considerations not just at the level of individual models and datasets, but also at the level of AI tasks .
I will present a new form of such an effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the assumptions and ethical considerations hidden in how a task is commonly framed and in the choices we make regarding the data, method, and evaluation .
I will also present a template for ethics sheets with 50 ethical considerations, using the task of emotion recognition as a running example .
Ethics sheets are a mechanism to engage with and document ethical considerations before building datasets and systems .
Similar to survey articles, a small number of carefully created ethics sheets can serve numerous researchers and developers .
Negation and uncertainty modeling are long-standing tasks in natural language processing .
Linguistic theory postulates that expressions of negation and uncertainty are semantically independent from each other and the content they modify .
However, previous works on representation learning do not explicitly model this independence .
We therefore attempt to disentangle the representations of negation, uncertainty, and content using a Variational Autoencoder .
We find that simply supervising the latent representations results in good disentanglement, but auxiliary objectives based on adversarial learning and mutual information minimization can provide additional disentanglement gains .
Recently, parallel text generation has received widespread attention due to its success in generation efficiency .
Although many advanced techniques are proposed to improve its generation quality, they still need the help of an autoregressive model for training to overcome the one-to-many multi-modal phenomenon in the dataset, limiting their applications .
In this paper, we propose GLAT, which employs the discrete latent variables to capture word categorical information and invoke an advanced curriculum learning technique, alleviating the multi-modality problem .
Experiment results show that our method outperforms strong baselines without the help of an autoregressive model, which further broadens the application scenarios of the parallel decoding paradigm .
Prompts for pre-trained language models (PLMs) have shown remarkable performance by bridging the gap between pre-training tasks and various downstream tasks .
Among these methods, prompt tuning, which freezes PLMs and only tunes soft prompts, provides an efficient and effective solution for adapting large-scale PLMs to downstream tasks .
However, prompt tuning is yet to be fully explored .
In our pilot experiments, we find that prompt tuning performs comparably with conventional full-model tuning when downstream data are sufficient, whereas it is much worse under few-shot learning settings, which may hinder the application of prompt tuning .
We attribute this low performance to the manner of initializing soft prompts .
Therefore, in this work, we propose to pre-train prompts by adding soft prompts into the pre-training stage to obtain a better initialization .
We name this Pre-trained Prompt Tuning framework “PPT” .
To ensure the generalization of PPT, we formulate similar classification tasks into a unified task form and pre-train soft prompts for this unified task .
Extensive experiments show that tuning pre-trained prompts for downstream tasks can reach or even outperform full-model fine-tuning under both full-data and few-shot settings .
Our approach is effective and efficient for using large-scale PLMs in practice .
We find that existing language modeling datasets contain many near-duplicate examples and long repetitive substrings.As a result, over 1% of the unprompted output of language models trained on these datasets is copied verbatim from the training data.We develop two tools that allow us to deduplicate training datasets—for example removing from C4 a single 61 word English sentence that is repeated over 60,000 times.Deduplication allows us to train models that emit memorized text ten times less frequently and require fewer training steps to achieve the same or better accuracy.We can also reduce train-test overlap, which affects over 4% of the validation set of standard datasets, thus allowing for more accurate evaluation.Code for deduplication is released at https://github.com/google-research/deduplicate-text-datasets .
Automated methods have been widely used to identify and analyze mental health conditions (e.g., depression) from various sources of information, including social media .
Yet, deployment of such models in real-world healthcare applications faces challenges including poor out-of-domain generalization and lack of trust in black box models .
In this work, we propose approaches for depression detection that are constrained to different degrees by the presence of symptoms described in PHQ9, a questionnaire used by clinicians in the depression screening process .
In dataset-transfer experiments on three social media datasets, we find that grounding the model in PHQ9’s symptoms substantially improves its ability to generalize to out-of-distribution data compared to a standard BERT-based approach .
Furthermore, this approach can still perform competitively on in-domain data .
These results and our qualitative analyses suggest that grounding model predictions in clinically-relevant symptoms can improve generalizability while producing a model that is easier to inspect .
The largest store of continually updating knowledge on our planet can be accessed via internet search .
In this work we study giving access to this information to conversational agents .
Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue (Shuster et al., 2021); moreover, those facts are frozen in time at the point of model training .
In contrast, we propose an approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information .
We train and evaluate such models on a newly collected dataset of human-human conversations whereby one of the speakers is given access to internet search during knowledgedriven discussions in order to ground their responses .
We find that search-query based access of the internet in conversation provides superior performance compared to existing approaches that either use no augmentation or FAISS-based retrieval (Lewis et al., 2020b) .
Transfer learning has proven to be crucial in advancing the state of speech and natural language processing research in recent years .
In speech, a model pre-trained by self-supervised learning transfers remarkably well on multiple tasks .
However, the lack of a consistent evaluation methodology is limiting towards a holistic understanding of the efficacy of such models .
SUPERB was a step towards introducing a common benchmark to evaluate pre-trained models across various speech tasks .
In this paper, we introduce SUPERB-SG, a new benchmark focusing on evaluating the semantic and generative capabilities of pre-trained models by increasing task diversity and difficulty over SUPERB .
We use a lightweight methodology to test the robustness of representations learned by pre-trained models under shifts in data domain and quality across different types of tasks .
It entails freezing pre-trained model parameters, only using simple task-specific trainable heads .
The goal is to be inclusive of all researchers, and encourage efficient use of computational resources .
We also show that the task diversity of SUPERB-SG coupled with limited task supervision is an effective recipe for evaluating the generalizability of model representation .
Large-scale pretrained language models are surprisingly good at recalling factual knowledge presented in the training corpus .
In this paper, we present preliminary studies on how factual knowledge is stored in pretrained Transformers by introducing the concept of knowledge neurons .
Specifically, we examine the fill-in-the-blank cloze task for BERT .
Given a relational fact, we propose a knowledge attribution method to identify the neurons that express the fact .
We find that the activation of such knowledge neurons is positively correlated to the expression of their corresponding facts .
In our case studies, we attempt to leverage knowledge neurons to edit (such as update, and erase) specific factual knowledge without fine-tuning .
Our results shed light on understanding the storage of knowledge within pretrained Transformers .
Meta-learning, or learning to learn, is a technique that can help to overcome resource scarcity in cross-lingual NLP problems, by enabling fast adaptation to new tasks .
We apply model-agnostic meta-learning (MAML) to the task of cross-lingual dependency parsing .
We train our model on a diverse set of languages to learn a parameter initialization that can adapt quickly to new languages .
We find that meta-learning with pre-training can significantly improve upon the performance of language transfer and standard supervised learning baselines for a variety of unseen, typologically diverse, and low-resource languages, in a few-shot learning setup .
Warning: This paper contains explicit statements of offensive stereotypes which may be upsetting.Much work on biases in natural language processing has addressed biases linked to the social and cultural experience of English speaking individuals in the United States .
We seek to widen the scope of bias studies by creating material to measure social bias in language models (LMs) against specific demographic groups in France .
We build on the US-centered CrowS-pairs dataset to create a multilingual stereotypes dataset that allows for comparability across languages while also characterizing biases that are specific to each country and language .
We introduce 1,679 sentence pairs in French that cover stereotypes in ten types of bias like gender and age .
1,467 sentence pairs are translated from CrowS-pairs and 212 are newly crowdsourced .
The sentence pairs contrast stereotypes concerning underadvantaged groups with the same sentence concerning advantaged groups .
We find that four widely used language models (three French, one multilingual) favor sentences that express stereotypes in most bias categories .
We report on the translation process from English into French, which led to a characterization of stereotypes in CrowS-pairs including the identification of US-centric cultural traits .
We offer guidelines to further extend the dataset to other languages and cultural environments .
We study the problem of building text classifiers with little or no training data, commonly known as zero and few-shot text classification .
In recent years, an approach based on neural textual entailment models has been found to give strong results on a diverse range of tasks .
In this work, we show that with proper pre-training, Siamese Networks that embed texts and labels offer a competitive alternative .
These models allow for a large reduction in inference cost: constant in the number of labels rather than linear .
Furthermore, we introduce label tuning, a simple and computationally efficient approach that allows to adapt the models in a few-shot setup by only changing the label embeddings .
While giving lower performance than model fine-tuning, this approach has the architectural advantage that a single encoder can be shared by many different tasks .
In classic instruction following, language like “I’d like the JetBlue flight” maps to actions (e.g., selecting that flight) .
However, language also conveys information about a user’s underlying reward function (e.g., a general preference for JetBlue), which can allow a model to carry out desirable actions in new contexts .
We present a model that infers rewards from language pragmatically: reasoning about how speakers choose utterances not only to elicit desired actions, but also to reveal information about their preferences .
On a new interactive flight–booking task with natural language, our model more accurately infers rewards and predicts optimal actions in unseen environments, in comparison to past work that first maps language to actions (instruction following) and then maps actions to rewards (inverse reinforcement learning) .
Generating factual, long-form text such as Wikipedia articles raises three key challenges: how to gather relevant evidence, how to structure information into well-formed text, and how to ensure that the generated text is factually correct .
We address these by developing a model for English text that uses a retrieval mechanism to identify relevant supporting information on the web and a cache-based pre-trained encoder-decoder to generate long-form biographies section by section, including citation information .
To assess the impact of available web evidence on the output text, we compare the performance of our approach when generating biographies about women (for which less information is available on the web) vs .
biographies generally .
To this end, we curate a dataset of 1,500 biographies about women .
We analyze our generated text to understand how differences in available web evidence data affect generation .
We evaluate the factuality, fluency, and quality of the generated texts using automatic metrics and human evaluation .
We hope that these techniques can be used as a starting point for human writers, to aid in reducing the complexity inherent in the creation of long-form, factual text .
Handing in a paper or exercise and merely receiving “bad” or “incorrect” as feedback is not very helpful when the goal is to improve .
Unfortunately, this is currently the kind of feedback given by Automatic Short Answer Grading (ASAG) systems .
One of the reasons for this is a lack of content-focused elaborated feedback datasets .
To encourage research on explainable and understandable feedback systems, we present the Short Answer Feedback dataset (SAF) .
Similar to other ASAG datasets, SAF contains learner responses and reference answers to German and English questions .
However, instead of only assigning a label or score to the learners’ answers, SAF also contains elaborated feedback explaining the given score .
Thus, SAF enables supervised training of models that grade answers and explain where and why mistakes were made .
This paper discusses the need for enhanced feedback models in real-world pedagogical scenarios, describes the dataset annotation process, gives a comprehensive analysis of SAF, and provides T5-based baselines for future comparison .
To effectively characterize the nature of paraphrase pairs without expert human annotation, we proposes two new metrics: word position deviation (WPD) and lexical deviation (LD) .
WPD measures the degree of structural alteration, while LD measures the difference in vocabulary used .
We apply these metrics to better understand the commonly-used MRPC dataset and study how it differs from PAWS, another paraphrase identification dataset .
We also perform a detailed study on MRPC and propose improvements to the dataset, showing that it improves generalizability of models trained on the dataset .
Lastly, we apply our metrics to filter the output of a paraphrase generation model and show how it can be used to generate specific forms of paraphrases for data augmentation or robustness testing of NLP models .
We introduce SummScreen, a summarization dataset comprised of pairs of TV series transcripts and human written recaps .
The dataset provides a challenging testbed for abstractive summarization for several reasons .
Plot details are often expressed indirectly in character dialogues and may be scattered across the entirety of the transcript .
These details must be found and integrated to form the succinct plot descriptions in the recaps .
Also, TV scripts contain content that does not directly pertain to the central plot but rather serves to develop characters or provide comic relief .
This information is rarely contained in recaps .
Since characters are fundamental to TV series, we also propose two entity-centric evaluation metrics .
Empirically, we characterize the dataset by evaluating several methods, including neural models and those based on nearest neighbors .
An oracle extractive approach outperforms all benchmarked models according to automatic metrics, showing that the neural models are unable to fully exploit the input transcripts .
Human evaluation and qualitative analysis reveal that our non-oracle models are competitive with their oracle counterparts in terms of generating faithful plot events and can benefit from better content selectors .
Both oracle and non-oracle models generate unfaithful facts, suggesting future research directions .
We propose a novel method to sparsify attention in the Transformer model by learning to select the most-informative token representations during the training process, thus focusing on the task-specific parts of an input .
A reduction of quadratic time and memory complexity to sublinear was achieved due to a robust trainable top-k operator.Our experiments on a challenging long document summarization task show that even our simple baseline performs comparably to the current SOTA, and with trainable pooling we can retain its top quality, while being 1.8× faster during training, 4.5× faster during inference, and up to 13× more computationally efficient in the decoder .
In many natural language processing (NLP) tasks the same input (e.g .
source sentence) can have multiple possible outputs (e.g .
translations) .
To analyze how this ambiguity (also known as intrinsic uncertainty) shapes the distribution learned by neural sequence models we measure sentence-level uncertainty by computing the degree of overlap between references in multi-reference test sets from two different NLP tasks: machine translation (MT) and grammatical error correction (GEC) .
At both the sentence- and the task-level, intrinsic uncertainty has major implications for various aspects of search such as the inductive biases in beam search and the complexity of exact search .
In particular, we show that well-known pathologies such as a high number of beam search errors, the inadequacy of the mode, and the drop in system performance with large beam sizes apply to tasks with high level of ambiguity such as MT but not to less uncertain tasks such as GEC .
Furthermore, we propose a novel exact n-best search algorithm for neural sequence models, and show that intrinsic uncertainty affects model uncertainty as the model tends to overly spread out the probability mass for uncertain tasks and sentences .
Most previous methods for text data augmentation are limited to simple tasks and weak baselines .
We explore data augmentation on hard tasks (i.e., few-shot natural language understanding) and strong baselines (i.e., pretrained models with over one billion parameters) .
Under this setting, we reproduced a large number of previous augmentation methods and found that these methods bring marginal gains at best and sometimes degrade the performance much .
To address this challenge, we propose a novel data augmentation method FlipDA that jointly uses a generative model and a classifier to generate label-flipped data .
Central to the idea of FlipDA is the discovery that generating label-flipped data is more crucial to the performance than generating label-preserved data .
Experiments show that FlipDA achieves a good tradeoff between effectiveness and robustness—it substantially improves many tasks while not negatively affecting the others .
Speech pre-training has primarily demonstrated efficacy on classification tasks, while its capability of generating novel speech, similar to how GPT-2 can generate coherent paragraphs, has barely been explored .
Generative Spoken Language Modeling (GSLM) (CITATION) is the only prior work addressing the generative aspect of speech pre-training, which builds a text-free language model using discovered units .
Unfortunately, because the units used in GSLM discard most prosodic information, GSLM fails to leverage prosody for better comprehension and does not generate expressive speech .
In this work, we present a prosody-aware generative spoken language model (pGSLM) .
It is composed of a multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveforms .
Experimental results show that the pGSLM can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt .
Audio samples can be found at https://speechbot.github.io/pgslm .
Codes and models are available at https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm .
As a broad and major category in machine reading comprehension (MRC), the generalized goal of discriminative MRC is answer prediction from the given materials .
However, the focuses of various discriminative MRC tasks may be diverse enough: multi-choice MRC requires model to highlight and integrate all potential critical evidence globally; while extractive MRC focuses on higher local boundary preciseness for answer extraction .
Among previous works, there lacks a unified design with pertinence for the overall discriminative MRC tasks .
To fill in above gap, we propose a lightweight POS-Enhanced Iterative Co-Attention Network (POI-Net) as the first attempt of unified modeling with pertinence, to handle diverse discriminative MRC tasks synchronously .
Nearly without introducing more parameters, our lite unified design brings model significant improvement with both encoder and decoder components .
The evaluation results on four discriminative MRC benchmarks consistently indicate the general effectiveness and applicability of our model, and the code is available at https://github.com/Yilin1111/poi-net .
This work presents methods for learning cross-lingual sentence representations using paired or unpaired bilingual texts .
We hypothesize that the cross-lingual alignment strategy is transferable, and therefore a model trained to align only two languages can encode multilingually more aligned representations .
We thus introduce dual-pivot transfer: training on one language pair and evaluating on other pairs .
To study this theory, we design unsupervised models trained on unpaired sentences and single-pair supervised models trained on bitexts, both based on the unsupervised language model XLM-R with its parameters frozen .
The experiments evaluate the models as universal sentence encoders on the task of unsupervised bitext mining on two datasets, where the unsupervised model reaches the state of the art of unsupervised retrieval, and the alternative single-pair supervised model approaches the performance of multilingually supervised models .
The results suggest that bilingual training techniques as proposed can be applied to get sentence representations with multilingual alignment .
Natural language spatial video grounding aims to detect the relevant objects in video frames with descriptive sentences as the query .
In spite of the great advances, most existing methods rely on dense video frame annotations, which require a tremendous amount of human effort .
To achieve effective grounding under a limited annotation budget, we investigate one-shot video grounding and learn to ground natural language in all video frames with solely one frame labeled, in an end-to-end manner .
One major challenge of end-to-end one-shot video grounding is the existence of videos frames that are either irrelevant to the language query or the labeled frame .
Another challenge relates to the limited supervision, which might result in ineffective representation learning .
To address these challenges, we designed an end-to-end model via Information Tree for One-Shot video grounding (IT-OS) .
Its key module, the information tree, can eliminate the interference of irrelevant frames based on branch search and branch cropping techniques .
In addition, several self-supervised tasks are proposed based on the information tree to improve the representation learning under insufficient labeling .
Experiments on the benchmark dataset demonstrate the effectiveness of our model .
A release note is a technical document that describes the latest changes to a software product and is crucial in open source software development .
However, it still remains challenging to generate release notes automatically .
In this paper, we present a new dataset called RNSum, which contains approximately 82,000 English release notes and the associated commit messages derived from the online repositories in GitHub .
Then, we propose classwise extractive-then-abstractive/abstractive summarization approaches to this task, which can employ a modern transformer-based seq2seq network like BART and can be applied to various repositories without specific constraints .
The experimental results on the RNSum dataset show that the proposed methods can generate less noisy release notes at higher coverage than the baselines .
We also observe that there is a significant gap in the coverage of essential information when compared to human references .
Our dataset and the code are publicly available .
To perform well on a machine reading comprehension (MRC) task, machine readers usually require commonsense knowledge that is not explicitly mentioned in the given documents .
This paper aims to extract a new kind of structured knowledge from scripts and use it to improve MRC .
We focus on scripts as they contain rich verbal and nonverbal messages, and two relevant messages originally conveyed by different modalities during a short time period may serve as arguments of a piece of commonsense knowledge as they function together in daily communications .
To save human efforts to name relations, we propose to represent relations implicitly by situating such an argument pair in a context and call it contextualized knowledge .
To use the extracted knowledge to improve MRC, we compare several fine-tuning strategies to use the weakly-labeled MRC data constructed based on contextualized knowledge and further design a teacher-student paradigm with multiple teachers to facilitate the transfer of knowledge in weakly-labeled MRC data .
Experimental results show that our paradigm outperforms other methods that use weakly-labeled data and improves a state-of-the-art baseline by 4.3% in accuracy on a Chinese multiple-choice MRC dataset C3, wherein most of the questions require unstated prior knowledge .
We also seek to transfer the knowledge to other tasks by simply adapting the resulting student reader, yielding a 2.9% improvement in F1 on a relation extraction dataset DialogRE, demonstrating the potential usefulness of the knowledge for non-MRC tasks that require document comprehension .
We introduce an argumentation annotation approach to model the structure of argumentative discourse in student-written business model pitches .
Additionally, the annotation scheme captures a series of persuasiveness scores such as the specificity, strength, evidence, and relevance of the pitch and the individual components .
Based on this scheme, we annotated a corpus of 200 business model pitches in German .
Moreover, we trained predictive models to detect argumentative discourse structures and embedded them in an adaptive writing support system for students that provides them with individual argumentation feedback independent of an instructor, time, and location .
We evaluated our tool in a real-world writing exercise and found promising results for the measured self-efficacy and perceived ease-of-use .
Finally, we present our freely available corpus of persuasive business model pitches with 3,207 annotated sentences in German language and our annotation guidelines .
Recent studies have shown the advantages of evaluating NLG systems using pairwise comparisons as opposed to direct assessment .
Given k systems, a naive approach for identifying the top-ranked system would be to uniformly obtain pairwise comparisons from all k \choose 2 pairs of systems .
However, this can be very expensive as the number of human annotations required would grow quadratically with k .
In this work, we introduce Active Evaluation, a framework to efficiently identify the top-ranked system by actively choosing system pairs for comparison using dueling bandit algorithms .
We perform extensive experiments with 13 dueling bandits algorithms on 13 NLG evaluation datasets spanning 5 tasks and show that the number of human annotations can be reduced by 80% .
To further reduce the number of human annotations, we propose model-based dueling bandit algorithms which combine automatic evaluation metrics with human evaluations .
Specifically, we eliminate sub-optimal systems even before the human annotation process and perform human evaluations only on test examples where the automatic metric is highly uncertain .
This reduces the number of human annotations required further by 89% .
In effect, we show that identifying the top-ranked system requires only a few hundred human annotations, which grow linearly with k .
Lastly, we provide practical recommendations and best practices to identify the top-ranked system efficiently .
Our code has been made publicly available at https://github.com/akashkm99/duelnlg .
An audience’s prior beliefs and morals are strong indicators of how likely they will be affected by a given argument .
Utilizing such knowledge can help focus on shared values to bring disagreeing parties towards agreement .
In argumentation technology, however, this is barely exploited so far .
This paper studies the feasibility of automatically generating morally framed arguments as well as their effect on different audiences .
Following the moral foundation theory, we propose a system that effectively generates arguments focusing on different morals .
In an in-depth user study, we ask liberals and conservatives to evaluate the impact of these arguments .
Our results suggest that, particularly when prior beliefs are challenged, an audience becomes more affected by morally framed arguments .
Transformer-based language models such as BERT (CITATION) have achieved the state-of-the-art performance on various NLP tasks, but are computationally prohibitive .
A recent line of works use various heuristics to successively shorten sequence length while transforming tokens through encoders, in tasks such as classification and ranking that require a single token embedding for prediction.We present a novel solution to this problem, called Pyramid-BERT where we replace previously used heuristics with a core-set based token selection method justified by theoretical results .
The core-set based token selection technique allows us to avoid expensive pre-training, gives a space-efficient fine tuning, and thus makes it suitable to handle longer sequence lengths .
We provide extensive experiments establishing advantages of pyramid BERT over several baselines and existing works on the GLUE benchmarks and Long Range Arena (CITATION) datasets .
A central quest of probing is to uncover how pre-trained models encode a linguistic property within their representations .
An encoding, however, might be spurious—i.e., the model might not rely on it when making predictions .
In this paper, we try to find an encoding that the model actually uses, introducing a usage-based probing setup .
We first choose a behavioral task which cannot be solved without using the linguistic property .
Then, we attempt to remove the property by intervening on the model’s representations .
We contend that, if an encoding is used by the model, its removal should harm the performance on the chosen behavioral task .
As a case study, we focus on how BERT encodes grammatical number, and on how it uses this encoding to solve the number agreement task .
Experimentally, we find that BERT relies on a linear encoding of grammatical number to produce the correct behavioral output .
We also find that BERT uses a separate encoding of grammatical number for nouns and verbs .
Finally, we identify in which layers information about grammatical number is transferred from a noun to its head verb .
We introduce BitFit, a sparse-finetuning method where only the bias-terms of the model (or a subset of them) are being modified .
We show that with small-to-medium training data, applying BitFit on pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model .
For larger data, the method is competitive with other sparse fine-tuning methods.Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge .
Existing self-explaining models typically favor extracting the shortest possible rationales — snippets of an input text “responsible for” corresponding output — to explain the model prediction, with the assumption that shorter rationales are more intuitive to humans .
However, this assumption has yet to be validated .
Is the shortest rationale indeed the most human-understandable? To answer this question, we design a self-explaining model, LimitedInk, which allows users to extract rationales at any target length .
Compared to existing baselines, LimitedInk achieves compatible end-task performance and human-annotated rationale agreement, making it a suitable representation of the recent class of self-explaining models .
We use LimitedInk to conduct a user study on the impact of rationale length, where we ask human judges to predict the sentiment label of documents based only on LimitedInk-generated rationales with different lengths .
We show rationales that are too short do not help humans predict labels better than randomly masked text, suggesting the need for more careful design of the best human rationales .
Numerous analyses of reading time (RT) data have been undertaken in the effort to learn more about the internal processes that occur during reading comprehension .
However, data measured on words at the end of a sentence–or even clause–is often omitted due to the confounding factors introduced by so-called “wrap-up effects,” which manifests as a skewed distribution of RTs for these words .
Consequently, the understanding of the cognitive processes that might be involved in these effects is limited .
In this work, we attempt to learn more about these processes by looking for the existence–or absence–of a link between wrap-up effects and information theoretic quantities, such as word and context information content .
We find that the information distribution of prior context is often predictive of sentence- and clause-final RTs (while not of sentence-medial RTs), which lends support to several prior hypotheses about the processes involved in wrap-up effects .
Argument pair extraction (APE) aims to automatically mine argument pairs from two interrelated argumentative documents .
Existing studies typically identify argument pairs indirectly by predicting sentence-level relations between two documents, neglecting the modeling of the holistic argument-level interactions .
Towards this issue, we propose to address APE via a machine reading comprehension (MRC) framework with two phases .
The first phase employs an argument mining (AM) query to identify all arguments in two documents .
The second phase considers each identified argument as an APE query to extract its paired arguments from another document, allowing to better capture the argument-level interactions .
Also, this framework enables these two phases to be jointly trained in a single MRC model, thereby maximizing the mutual benefits of them .
Experimental results demonstrate that our approach achieves the best performance, outperforming the state-of-the-art method by 7.11% in F1 score .
When generating natural language from neural probabilistic models, high probability does not always coincide with high quality: It has often been observed that mode-seeking decoding methods, i.e., those that produce high-probability text under the model, lead to unnatural language .
On the other hand, the lower-probability text generated by stochastic methods is perceived as more human-like .
In this note, we offer an explanation for this phenomenon by analyzing language generation through an information-theoretic lens .
Specifically, we posit that human-like language should contain an amount of information (quantified as negative log-probability) that is close to the entropy of the distribution over natural strings .
Further, we posit that language with substantially more (or less) information is undesirable .
We provide preliminary empirical evidence in favor of this hypothesis; quality ratings of both human and machine-generated text—covering multiple tasks and common decoding strategies—suggest high-quality text has an information content significantly closer to the entropy than we would expect by chance .
Discovering Out-of-Domain(OOD) intents is essential for developing new skills in a task-oriented dialogue system .
The key challenge is how to transfer prior IND knowledge to OOD clustering .
Different from existing work based on shared intent representation, we propose a novel disentangled knowledge transfer method via a unified multi-head contrastive learning framework .
We aim to bridge the gap between IND pre-training and OOD clustering .
Experiments and analysis on two benchmark datasets show the effectiveness of our method .
Natural language applied to natural 2D images describes a fundamentally 3D world .
We present the Voxel-informed Language Grounder (VLG), a language grounding model that leverages 3D geometric information in the form of voxel maps derived from the visual input using a volumetric reconstruction model .
We show that VLG significantly improves grounding accuracy on SNARE, an object reference game task.At the time of writing, VLG holds the top place on the SNARE leaderboard, achieving SOTA results with a 2.0% absolute improvement .
Prompt tuning, which only tunes continuous prompts with a frozen language model, substantially reduces per-task storage and memory usage at training .
However, in the context of NLU, prior work reveals that prompt tuning does not perform well for normal-sized pretrained models .
We also find that existing methods of prompt tuning cannot handle hard sequence labeling tasks, indicating a lack of universality .
We present a novel empirical finding that properly optimized prompt tuning can be universally effective across a wide range of model scales and NLU tasks .
It matches the performance of finetuning while having only 0.1%-3% tuned parameters .
Our method P-Tuning v2 is an implementation of Deep Prompt Tuning (CITATION) optimized and adapted for NLU .
Given the universality and simplicity of P-Tuning v2, we believe it can serve as an alternative to finetuning and a strong baseline for future research .
When tasked with supporting multiple languages for a given problem, two approaches have arisen: training a model for each language with the annotation budget divided equally among them, and training on a high-resource language followed by zero-shot transfer to the remaining languages .
In this work, we show that the strategy of joint learning across multiple languages using a single model performs substantially better than the aforementioned alternatives .
We also demonstrate that active learning provides additional, complementary benefits .
We show that this simple approach enables the model to be data efficient by allowing it to arbitrate its annotation budget to query languages it is less certain on .
We illustrate the effectiveness of our proposed method on a diverse set of tasks: a classification task with 4 languages, a sequence tagging task with 4 languages and a dependency parsing task with 5 languages .
Our proposed method, whilst simple, substantially outperforms the other viable alternatives for building a model in a multilingual setting under constrained budgets .
In this work, we focus on the problem of distinguishing a human written news article from a news article that is created by manipulating entities in a human written news article (e.g., replacing entities with factually incorrect entities) .
Such manipulated articles can mislead the reader by posing as a human written news article .
We propose a neural network based detector that detects manipulated news articles by reasoning about the facts mentioned in the article .
Our proposed detector exploits factual knowledge via graph convolutional neural network along with the textual information in the news article .
We also create challenging datasets for this task by considering various strategies to generate the new replacement entity (e.g., entity generation from GPT-2) .
In all the settings, our proposed model either matches or outperforms the state-of-the-art detector in terms of accuracy .
Our code and data are available at https://github.com/UBC-NLP/manipulated_entity_detection .
The success of a natural language processing (NLP) system on a task does not amount to fully understanding the complexity of the task, typified by many deep learning models .
One such question is: can a black-box model make logically consistent predictions for transitive relations? Recent studies suggest that pre-trained BERT can capture lexico-semantic clues from words in the context .
However, to what extent BERT captures the transitive nature of some lexical relations is unclear .
From a probing perspective, we examine WordNet word senses and the IS-A relation, which is a transitive relation .
That is, for senses A, B, and C, A is-a B and B is-a C entail A is-a C .
We aim to quantify how much BERT agrees with the transitive property of IS-A relations, via a minimalist probing setting .
Our investigation reveals that BERT’s predictions do not fully obey the transitivity property of the IS-A relation .
Pretrained language models such as BERT have achieved remarkable success in several NLP tasks .
With the wide adoption of BERT in real-world applications, researchers begin to investigate the implicit biases encoded in the BERT .
In this paper, we assess the implicit stock market preferences in BERT and its finance domain-specific model FinBERT .
We find some interesting patterns .
For example, the language models are overall more positive towards the stock market, but there are significant differences in preferences between a pair of industry sectors, or even within a sector .
Given the prevalence of NLP models in financial decision making systems, this work raises the awareness of their potential implicit preferences in the stock markets .
Awareness of such problems can help practitioners improve robustness and accountability of their financial NLP pipelines  .
We present Pixie, a manually annotated dataset for preference classification comprising 8,890 sentences drawn from app reviews .
Unlike previous studies on preference classification, Pixie contains implicit (omitting an entity being compared) and indirect (lacking comparative linguistic cues) comparisons .
We find that transformer-based pretrained models, finetuned on Pixie, achieve a weighted average F1 score of 83.34% and outperform the existing state-of-the-art preference classification model (73.99%) .
A key challenge facing natural language interfaces is enabling users to understand the capabilities of the underlying system .
We propose a novel approach for generating explanations of a natural language interface based on semantic parsing .
We focus on counterfactual explanations, which are post-hoc explanations that describe to the user how they could have minimally modified their utterance to achieve their desired goal .
In particular, the user provides an utterance along with a demonstration of their desired goal; then, our algorithm synthesizes a paraphrase of their utterance that is guaranteed to achieve their goal .
In two user studies, we demonstrate that our approach substantially improves user performance, and that it generates explanations that more closely match the user’s intent compared to two ablations .
Item Response Theory (IRT) has been extensively used to numerically characterize question difficulty and discrimination for human subjects in domains including cognitive psychology and education (Primi et al., 2014; Downing, 2003) .
More recently, IRT has been used to similarly characterize item difficulty and discrimination for natural language models across various datasets (Lalor et al., 2019; Vania et al., 2021; Rodriguez et al., 2021) .
In this work, we explore predictive models for directly estimating and explaining these traits for natural language questions in a question-answering context .
We use HotpotQA for illustration .
Our experiments show that it is possible to predict both difficulty and discrimination parameters for new questions, and these traits are correlated with features of questions, answers, and associated contexts .
Our findings can have significant implications for the creation of new datasets and tests on the one hand and strategies such as active learning and curriculum learning on the other .
Several pre-training objectives, such as masked language modeling (MLM), have been proposed to pre-train language models (e.g .
BERT) with the aim of learning better language representations .
However, to the best of our knowledge, no previous work so far has investigated how different pre-training objectives affect what BERT learns about linguistics properties .
We hypothesize that linguistically motivated objectives such as MLM should help BERT to acquire better linguistic knowledge compared to other non-linguistically motivated objectives that are not intuitive or hard for humans to guess the association between the input and the label to be predicted .
To this end, we pre-train BERT with two linguistically motivated objectives and three non-linguistically motivated ones .
We then probe for linguistic characteristics encoded in the representation of the resulting models .
We find strong evidence that there are only small differences in probing performance between the representations learned by the two different types of objectives .
These surprising results question the dominant narrative of linguistically informed pre-training .
Prompt tuning has recently emerged as an effective method for adapting pre-trained language models to a number of language understanding and generation tasks .
In this paper, we investigate prompt tuning for semantic parsing—the task of mapping natural language utterances onto formal meaning representations .
On the low-resource splits of Overnight and TOPv2, we find that a prompt tuned T5-xl significantly outperforms its fine-tuned counterpart, as well as strong GPT-3 and BART baselines .
We also conduct ablation studies across different model scales and target representations, finding that, with increasing model scale, prompt tuned T5 models improve at generating target representations that are far from the pre-training distribution .
Pretrained language models are typically trained on massive web-based datasets, which are often “contaminated” with downstream test sets .
It is not clear to what extent models exploit the contaminated data for downstream tasks .
We present a principled method to study this question .
We pretrain BERT models on joint corpora of Wikipedia and labeled downstream datasets, and fine-tune them on the relevant task .
Comparing performance between samples seen and unseen during pretraining enables us to define and quantify levels of memorization and exploitation.Experiments with two models and three downstream tasks show that exploitation exists in some cases, but in others the models memorize the contaminated data, but do not exploit it .
We show that these two measures are affected by different factors such as the number of duplications of the contaminated data and the model size .
Our results highlight the importance of analyzing massive web-scale datasets to verify that progress in NLP is obtained by better language understanding and not better data exploitation .
Annotation errors that stem from various sources are usually unavoidable when performing large-scale annotation of linguistic data .
In this paper, we evaluate the feasibility of using the Transformer model to detect various types of annotator errors in morphological data sets that contain inflected word forms .
We evaluate our error detection model on four languages by introducing three different types of artificial errors in the data: (1) typographic errors, where single characters in the data are inserted, replaced, or deleted; (2) linguistic confusion errors where two inflected forms are systematically swapped; and (3) self-adversarial errors where the Transformer model itself is used to generate plausible-looking, but erroneous forms by retrieving high-scoring predictions from the search beam .
Results show that the Transformer model can with perfect, or near-perfect recall detect errors in all three scenarios, even when significant amounts of the annotated data (5%-30%) are corrupted on all languages tested .
Precision varies across the languages and types of errors, but is high enough that the model can be very effectively used to flag suspicious entries in large data sets for further scrutiny by human annotators .
Shannon entropy is often a quantity of interest to linguists studying the communicative capacity of human language .
However, entropymust typically be estimated from observed data because researchers do not have access to the underlying probability distribution .
While entropy estimation is a well-studied problem in other fields, there is not yet a comprehensive exploration of the efficacy of entropy estimators for use with linguistic data .
In this work, we fill this void, studying the empirical effectiveness of different entropy estimators for linguistic distributions .
In a replication of two recent information-theoretic linguistic studies, we find evidence that the reported effect size is over-estimated due to over-reliance on poor entropy estimators .
We end this paper with a concrete recommendation for the entropy estimators that should be used in future linguistic studies .
In recent years, a flurry of morphological datasets had emerged, most notably UniMorph, aa multi-lingual repository of inflection tables .
However, the flat structure of the current morphological annotation makes the treatment of some languages quirky, if not impossible, specifically in cases of polypersonal agreement .
In this paper we propose a general solution for such cases and expand the UniMorph annotation schema to naturally address this phenomenon, in which verbs agree with multiple arguments using true affixes .
We apply this extended schema to one such language, Georgian, and provide a human-verified, accurate and balanced morphological dataset for Georgian verbs .
The dataset has 4 times more tables and 6 times more verb forms compared to the existing UniMorph dataset, covering all possible variants of argument marking, demonstrating the adequacy of our proposed scheme .
Experiments on a reinflection task show that generalization is easy when the data is split at the form level, but extremely hard when splitting along lemma lines .
Expanding the other languages in UniMorph according to this schema is expected to improve both the coverage, consistency and interpretability of this benchmark .
Large-scale pre-trained sequence-to-sequence models like BART and T5 achieve state-of-the-art performance on many generative NLP tasks .
However, such models pose a great challenge in resource-constrained scenarios owing to their large memory requirements and high latency .
To alleviate this issue, we propose to jointly distill and quantize the model, where knowledge is transferred from the full-precision teacher model to the quantized and distilled low-precision student model .
Empirical analyses show that, despite the challenging nature of generative tasks, we were able to achieve a 16.5x model footprint compression ratio with little performance drop relative to the full-precision counterparts on multiple summarization and QA datasets .
We further pushed the limit of compression ratio to 27.7x and presented the performance-efficiency trade-off for generative tasks using pre-trained models .
To the best of our knowledge, this is the first work aiming to effectively distill and quantize sequence-to-sequence pre-trained models for language generation tasks .
Comprehending a dialogue requires a model to capture diverse kinds of key information in the utterances, which are either scattered around or implicitly implied in different turns of conversations .
Therefore, dialogue comprehension requires diverse capabilities such as paraphrasing, summarizing, and commonsense reasoning .
Towards the objective of pre-training a zero-shot dialogue comprehension model, we develop a novel narrative-guided pre-training strategy that learns by narrating the key information from a dialogue input .
However, the dialogue-narrative parallel corpus for such a pre-training strategy is currently unavailable .
For this reason, we first construct a dialogue-narrative parallel corpus by automatically aligning movie subtitles and their synopses .
We then pre-train a BART model on the data and evaluate its performance on four dialogue-based tasks that require comprehension .
Experimental results show that our model not only achieves superior zero-shot performance but also exhibits stronger fine-grained dialogue comprehension capabilities .
The data and code are available at https://github.com/zhaochaocs/Diana .
GPT is an auto-regressive Transformer-based pre-trained language model which has attracted a lot of attention in the natural language processing (NLP) domain .
The success of GPT is mostly attributed to its pre-training on huge amount of data and its large number of parameters .
Despite the superior performance of GPT, this overparameterized nature of GPT can be very prohibitive for deploying this model on devices with limited computational power or memory .
This problem can be mitigated using model compression techniques; however, compressing GPT models has not been investigated much in the literature .
In this work, we use Kronecker decomposition to compress the linear mappings of the GPT-2 model .
Our Kronecker GPT-2 model (KnGPT2) is initialized based on the Kronecker decomposed version of the GPT-2 model and then is undergone a very light pre- training on only a small portion of the training data with intermediate layer knowledge distillation (ILKD) .
Finally, our KnGPT2 is fine-tuned on downstream tasks using ILKD as well .
We evaluate our model on both language modeling and General Language Understanding Evaluation benchmark tasks and show that with more efficient pre-training and similar number of parameters, our KnGPT2 outperforms the existing DistilGPT2 model significantly .
A key challenge in attribute value extraction (AVE) from e-commerce sites is how to handle a large number of attributes for diverse products .
Although this challenge is partially addressed by a question answering (QA) approach which finds a value in product data for a given query (attribute), it does not work effectively for rare and ambiguous queries .
We thus propose simple knowledge-driven query expansion based on possible answers (values) of a query (attribute) for QA-based AVE .
We retrieve values of a query (attribute) from the training data to expand the query .
We train a model with two tricks, knowledge dropout and knowledge token mixing, which mimic the imperfection of the value knowledge in testing .
Experimental results on our cleaned version of AliExpress dataset show that our method improves the performance of AVE (+6.08 macro F1), especially for rare and ambiguous attributes (+7.82 and +6.86 macro F1, respectively) .
To understand a story with multiple events, it is important to capture the proper relations across these events .
However, existing event relation extraction (ERE) framework regards it as a multi-class classification task and do not guarantee any coherence between different relation types, such as anti-symmetry .
If a phone line “died” after “storm”, then it is obvious that the “storm” happened before the “died” .
Current framework of event relation extraction do not guarantee this coherence and thus enforces it via constraint loss function (Wang et al., 2020) .
In this work, we propose to modify the underlying ERE model to guarantee coherence by representing each event as a box representation (BERE) without applying explicit constraints .
From our experiments, BERE also shows stronger conjunctive constraint satisfaction while performing on par or better in F1 compared to previous models with constraint injection .
End-to-end speech translation relies on data that pair source-language speech inputs with corresponding translations into a target language .
Such data are notoriously scarce, making synthetic data augmentation by back-translation or knowledge distillation a necessary ingredient of end-to-end training .
In this paper, we present a novel approach to data augmentation that leverages audio alignments, linguistic properties, and translation .
First, we augment a transcription by sampling from a suffix memory that stores text and audio data .
Second, we translate the augmented transcript .
Finally, we recombine concatenated audio segments and the generated translation .
Our method delivers consistent improvements of up to 0.9 and 1.1 BLEU points on top of augmentation with knowledge distillation on five language pairs on CoVoST 2 and on two language pairs on Europarl-ST, respectively .
Document-level text simplification often deletes some sentences besides performing lexical, grammatical or structural simplification to reduce text complexity .
In this work, we focus on sentence deletions for text simplification and use a news genre-specific functional discourse structure, which categorizes sentences based on their contents and their function roles in telling a news story, for predicting sentence deletion .
We incorporate sentence categories into a neural net model in two ways for predicting sentence deletions, either as additional features or by jointly predicting sentence deletions and sentence categories .
Experimental results using human-annotated data show that incorporating the functional structure improves the recall of sentence deletion prediction by 6.5% and 10.7% respectively using the two methods, and improves the overall F1-score by 3.6% and 4.3% respectively .
We exploit the pre-trained seq2seq model mBART for multilingual text style transfer .
Using machine translated data as well as gold aligned English sentences yields state-of-the-art results in the three target languages we consider .
Besides, in view of the general scarcity of parallel data, we propose a modular approach for multilingual formality transfer, which consists of two training strategies that target adaptation to both language and task .
Our approach achieves competitive performance without monolingual task-specific parallel data and can be applied to other style transfer tasks as well as to other languages .
Transfer learning (TL) in natural language processing (NLP) has seen a surge of interest in recent years, as pre-trained models have shown an impressive ability to transfer to novel tasks .
Three main strategies have emerged for making use of multiple supervised datasets during fine-tuning: training on an intermediate task before training on the target task (STILTs), using multi-task learning (MTL) to train jointly on a supplementary task and the target task (pairwise MTL), or simply using MTL to train jointly on all available datasets (MTL-ALL) .
In this work, we compare all three TL methods in a comprehensive analysis on the GLUE dataset suite .
We find that there is a simple heuristic for when to use one of these techniques over the other: pairwise MTL is better than STILTs when the target task has fewer instances than the supporting task and vice versa .
We show that this holds true in more than 92% of applicable cases on the GLUE dataset and validate this hypothesis with experiments varying dataset size .
The simplicity and effectiveness of this heuristic is surprising and warrants additional exploration by the TL community .
Furthermore, we find that MTL-ALL is worse than the pairwise methods in almost every case .
We hope this study will aid others as they choose between TL methods for NLP tasks .
Text-to-SQL aims to parse natural language questions into SQL queries, which is valuable in providing an easy interface to access large databases .
Previous work has observed that leveraging lexico-logical alignments is very helpful to improve parsing performance .
However, current attention-based approaches can only model such alignments at the token level and have unsatisfactory generalization capability .
In this paper, we propose a new approach to leveraging explicit lexico-logical alignments .
It first identifies possible phrase-level alignments and injects them as additional contexts to guide the parsing procedure .
Experimental results on \textsc{Squall} show that our approach can make better use of such alignments and obtains an absolute improvement of 3.4% compared with the current state-of-the-art .
A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to different timestamps .
TKG reasoning aims to predict potential facts in the future given the historical KG sequences .
One key of this task is to mine and understand evolutional patterns of facts from these sequences .
The evolutional patterns are complex in two aspects, length-diversity and time-variability .
Existing models for TKG reasoning focus on modeling fact sequences of a fixed length, which cannot discover complex evolutional patterns that vary in length .
Furthermore, these models are all trained offline, which cannot well adapt to the changes of evolutional patterns from then on .
Thus, we propose a new model, called Complex Evolutional Network (CEN), which uses a length-aware Convolutional Neural Network (CNN) to handle evolutional patterns of different lengths via an easy-to-difficult curriculum learning strategy .
Besides, we propose to learn the model under the online setting so that it can adapt to the changes of evolutional patterns over time .
Extensive experiments demonstrate that CEN obtains substantial performance improvement under both the traditional offline and the proposed online settings .
Dialogue state tracking (DST) aims to extract essential information from multi-turn dialog situations and take appropriate actions .
A belief state, one of the core pieces of information, refers to the subject and its specific content, and appears in the form of domain-slot-value .
The trained model predicts “accumulated” belief states in every turn, and joint goal accuracy and slot accuracy are mainly used to evaluate the prediction; however, we specify that the current evaluation metrics have a critical limitation when evaluating belief states accumulated as the dialogue proceeds, especially in the most used MultiWOZ dataset .
Additionally, we propose relative slot accuracy to complement existing metrics .
Relative slot accuracy does not depend on the number of predefined slots, and allows intuitive evaluation by assigning relative scores according to the turn of each dialog .
This study also encourages not solely the reporting of joint goal accuracy, but also various complementary metrics in DST tasks for the sake of a realistic evaluation .
LM-BFF (CITATION) achieves significant few-shot performance by using auto-generated prompts and adding demonstrations similar to an input example .
To improve the approach of LM-BFF, this paper proposes LM-BFF-MS—better few-shot fine-tuning of language models with multiple soft demonstrations by making its further extensions, which include 1) prompts with multiple demonstrations based on automatic generation of multiple label words; and 2) soft demonstration memory which consists of multiple sequences of globally shared word embeddings for a similar context .
Experiments conducted on eight NLP tasks show that LM-BFF-MS leads to improvements over LM-BFF on five tasks, particularly achieving 94.0 and 90.4 on SST-2 and MRPC, respectively .
Dialogue State Tracking (DST) is primarily evaluated using Joint Goal Accuracy (JGA) defined as the fraction of turns where the ground-truth dialogue state exactly matches the prediction .
Generally in DST, the dialogue state or belief state for a given turn contain all the intents shown by the user till that turn .
Due to this cumulative nature of the belief state, it is difficult to get a correct prediction once a misprediction has occurred .
Thus, although being a useful metric, it can be harsh at times and underestimate the true potential of a DST model .
Moreover, an improvement in JGA can sometimes decrease the performance of turn-level or non-cumulative belief state prediction due to inconsistency in annotations .
So, using JGA as the only metric for model selection may not be ideal for all scenarios .
In this work, we discuss various evaluation metrics used for DST along with their shortcomings .
To address the existing issues, we propose a new evaluation metric named Flexible Goal Accuracy (FGA) .
FGA is a generalized version of JGA .
But unlike JGA, it tries to give penalized rewards to mispredictions that are locally correct i.e .
the root cause of the error is an earlier turn .
By doing so, FGA considers the performance of both cumulative and turn-level prediction flexibly and provides a better insight than the existing metrics .
We also show that FGA is a better discriminator of DST model performance .
As a recent development in few-shot learning, prompt-based techniques have demonstrated promising potential in a variety of natural language processing tasks .
However, despite proving competitive on most tasks in the GLUE and SuperGLUE benchmarks, existing prompt-based techniques fail on the semantic distinction task of the Word-in-Context (WiC) dataset .
Specifically, none of the existing few-shot approaches (including the in-context learning of GPT-3) can attain a performance that is meaningfully different from the random baseline.Trying to fill this gap, we propose a new prompting technique, based on similarity metrics, which boosts few-shot performance to the level of fully supervised methods .
Our simple adaptation shows that the failure of existing prompt-based techniques in semantic distinction is due to their improper configuration, rather than lack of relevant knowledge in the representations .
We also show that this approach can be effectively extended to other downstream tasks for which a single prompt is sufficient .
Abstract Meaning Representation (AMR) parsing aims to translate sentences to semantic representation with a hierarchical structure, and is recently empowered by pretrained sequence-to-sequence models .
However, there exists a gap between their flat training objective (i.e., equally treats all output tokens) and the hierarchical AMR structure, which limits the model generalization .
To bridge this gap, we propose a Hierarchical Curriculum Learning (HCL) framework with Structure-level (SC) and Instance-level Curricula (IC) .
SC switches progressively from core to detail AMR semantic elements while IC transits from structure-simple to -complex AMR instances during training .
Through these two warming-up processes, HCL reduces the difficulty of learning complex structures, thus the flat model can better adapt to the AMR hierarchy .
Extensive experiments on AMR2.0, AMR3.0, structure-complex and out-of-distribution situations verify the effectiveness of HCL .
Neural models for distantly supervised relation extraction (DS-RE) encode each sentence in an entity-pair bag separately .
These are then aggregated for bag-level relation prediction .
Since, at encoding time, these approaches do not allow information to flow from other sentences in the bag, we believe that they do not utilize the available bag data to the fullest .
In response, we explore a simple baseline approach (PARE) in which all sentences of a bag are concatenated into a passage of sentences, and encoded jointly using BERT .
The contextual embeddings of tokens are aggregated using attention with the candidate relation as query – this summary of whole passage predicts the candidate relation .
We find that our simple baseline solution outperforms existing state-of-the-art DS-RE models in both monolingual and multilingual DS-RE datasets .
We present a debiased dataset for the Person-centric Visual Grounding (PCVG) task first proposed by Cui et al .
(2021) in the Who’s Waldo dataset .
Given an image and a caption, PCVG requires pairing up a person’s name mentioned in a caption with a bounding box that points to the person in the image .
We find that the original Who’s Waldo dataset compiled for this task contains a large number of biased samples that are solvable simply by heuristic methods; for instance, in many cases the first name in the sentence corresponds to the largest bounding box, or the sequence of names in the sentence corresponds to an exact left-to-right order in the image .
Naturally, models trained on these biased data lead to over-estimation of performance on the benchmark .
To enforce models being correct for the correct reasons, we design automated tools to filter and debias the original dataset by ruling out all examples of insufficient context, such as those with no verb or with a long chain of conjunct names in their captions .
Our experiments show that our new sub-sampled dataset contains less bias with much lowered heuristic performances and widened gaps between heuristic and supervised methods .
We also demonstrate the same benchmark model trained on our debiased training set outperforms that trained on the original biased (and larger) training set on our debiased test set .
We argue our debiased dataset offers the PCVG task a more practical baseline for reliable benchmarking and future improvements .
Translate-train is a general training approach to multilingual tasks .
The key idea is to use the translator of the target language to generate training data to mitigate the gap between the source and target languages .
However, its performance is often hampered by the artifacts in the translated texts (translationese) .
We discover that such artifacts have common patterns in different languages and can be modeled by deep learning, and subsequently propose an approach to conduct translate-train using Translationese Embracing the effect of Artifacts (TEA) .
TEA learns to mitigate such effect on the training data of a source language (whose original and translationese are both available), and applies the learned module to facilitate the inference on the target language .
Extensive experiments on the multilingual QA dataset TyDiQA demonstrate that TEA outperforms strong baselines .
We consider the problem of pretraining a two-stage open-domain question answering (QA) system (retriever + reader) with strong transfer capabilities .
The key challenge is how to construct a large amount of high-quality question-answer-context triplets without task-specific annotations .
Specifically, the triplets should align well with downstream tasks by: (i) covering a wide range of domains (for open-domain applications), (ii) linking a question to its semantically relevant context with supporting evidence (for training the retriever), and (iii) identifying the correct answer in the context (for training the reader) .
Previous pretraining approaches generally fall short of one or more of these requirements .
In this work, we automatically construct a large-scale corpus that meets all three criteria by consulting millions of references cited within Wikipedia .
The well-aligned pretraining signals benefit both the retriever and the reader significantly .
Our pretrained retriever leads to 2%-10% absolute gains in top-20 accuracy .
And with our pretrained reader, the entire system improves by up to 4% in exact match .
Since the inception of crowdsourcing, aggregation has been a common strategy for dealing with unreliable data .
Aggregate ratings are more reliable than individual ones .
However, many Natural Language Processing (NLP) applications that rely on aggregate ratings only report the reliability of individual ratings, which is the incorrect unit of analysis .
In these instances, the data reliability is under-reported, and a proposed k-rater reliability (kRR) should be used as the correct data reliability for aggregated datasets .
It is a multi-rater generalization of inter-rater reliability (IRR) .
We conducted two replications of the WordSim-353 benchmark, and present empirical, analytical, and bootstrap-based methods for computing kRR on WordSim-353 .
These methods produce very similar results .
We hope this discussion will nudge researchers to report kRR in addition to IRR .
We introduce FLOTA (Few Longest Token Approximation), a simple yet effective method to improve the tokenization of pretrained language models (PLMs) .
FLOTA uses the vocabulary of a standard tokenizer but tries to preserve the morphological structure of words during tokenization .
We evaluate FLOTA on morphological gold segmentations as well as a text classification task, using BERT, GPT-2, and XLNet as example PLMs .
FLOTA leads to performance gains, makes inference more efficient, and enhances the robustness of PLMs with respect to whitespace noise .
In this paper, we propose Self-Contrastive Decorrelation (SCD), a self-supervised approach .
Given an input sentence, it optimizes a joint self-contrastive and decorrelation objective .
Learning a representation is facilitated by leveraging the contrast arising from the instantiation of standard dropout at different rates .
The proposed method is conceptually simple yet empirically powerful .
It achieves comparable results with state-of-the-art methods on multiple benchmarks without using contrastive pairs .
This study opens up avenues for efficient self-supervised learning methods that are more robust than current contrastive methods .
Cosine similarity of contextual embeddings is used in many NLP tasks (e.g., QA, IR, MT) and metrics (e.g., BERTScore) .
Here, we uncover systematic ways in which word similarities estimated by cosine over BERT embeddings are understated and trace this effect to training data frequency .
We find that relative to human judgements, cosine similarity underestimates the similarity of frequent words with other instances of the same word or other words across contexts, even after controlling for polysemy and other factors .
We conjecture that this underestimation of similarity for high frequency words is due to differences in the representational geometry of high and low frequency words and provide a formal argument for the two-dimensional case .
Compositional generalization is a fundamental trait in humans, allowing us to effortlessly combine known phrases to form novel sentences .
Recent works have claimed that standard seq-to-seq models severely lack the ability to compositionally generalize .
In this paper, we focus on one-shot primitive generalization as introduced by the popular SCAN benchmark .
We demonstrate that modifying the training distribution in simple and intuitive ways enables standard seq-to-seq models to achieve near-perfect generalization performance, thereby showing that their compositional generalization abilities were previously underestimated .
We perform detailed empirical analysis of this phenomenon .
Our results indicate that the generalization performance of models is highly sensitive to the characteristics of the training data which should be carefully considered while designing such benchmarks in future .
Open-domain question answering is a challenging task with a wide variety of practical applications .
Existing modern approaches mostly follow a standard two-stage paradigm: retriever then reader .
In this article, we focus on improving the effectiveness of the reader module and propose a novel copy-augmented generative approach that integrates the merits of both extractive and generative readers .
In particular, our model is built upon the powerful generative model FiD (CITATION) .
We enhance the original generative reader by incorporating a pointer network to encourage the model to directly copy words from the retrieved passages .
We conduct experiments on the two benchmark datasets, Natural Questions and TriviaQA, and the empirical results demonstrate the performance gains of our proposed approach .
Dense retrieval models, which aim at retrieving the most relevant document for an input query on a dense representation space, have gained considerable attention for their remarkable success .
Yet, dense models require a vast amount of labeled training data for notable performance, whereas it is often challenging to acquire query-document pairs annotated by humans .
To tackle this problem, we propose a simple but effective Document Augmentation for dense Retrieval (DAR) framework, which augments the representations of documents with their interpolation and perturbation .
We validate the performance of DAR on retrieval tasks with two benchmark datasets, showing that the proposed DAR significantly outperforms relevant baselines on the dense retrieval of both the labeled and unlabeled documents .
Signed Language Processing (SLP) concerns the automated processing of signed languages, the main means of communication of Deaf and hearing impaired individuals .
SLP features many different tasks, ranging from sign recognition to translation and production of signed speech, but has been overlooked by the NLP community thus far.In this paper, we bring to attention the task of modelling the phonology of sign languages .
We leverage existing resources to construct a large-scale dataset of American Sign Language signs annotated with six different phonological properties .
We then conduct an extensive empirical study to investigate whether data-driven end-to-end and feature-based approaches can be optimised to automatically recognise these properties .
We find that, despite the inherent challenges of the task, graph-based neural networks that operate over skeleton features extracted from raw videos are able to succeed at the task to a varying degree .
Most importantly, we show that this performance pertains even on signs unobserved during training .
Creating chatbots to behave like real people is important in terms of believability .
Errors in general chatbots and chatbots that follow a rough persona have been studied, but those in chatbots that behave like real people have not been thoroughly investigated .
We collected a large amount of user interactions of a generation-based chatbot trained from large-scale dialogue data of a specific character, i.e., target person, and analyzed errors related to that person .
We found that person-specific errors can be divided into two types: errors in attributes and those in relations, each of which can be divided into two levels: self and other .
The correspondence with an existing taxonomy of errors was also investigated, and person-specific errors that should be addressed in the future were clarified .
This paper demonstrates how a graph-based semantic parser can be applied to the task of structured sentiment analysis, directly predicting sentiment graphs from text .
We advance the state of the art on 4 out of 5 standard benchmark sets .
We release the source code, models and predictions .
Transformer-based models are widely used in natural language understanding (NLU) tasks, and multimodal transformers have been effective in visual-language tasks .
This study explores distilling visual information from pretrained multimodal transformers to pretrained language encoders .
Our framework is inspired by cross-modal encoders’ success in visual-language tasks while we alter the learning objective to cater to the language-heavy characteristics of NLU .
After training with a small number of extra adapting steps and finetuned, the proposed XDBERT (cross-modal distilled BERT) outperforms pretrained-BERT in general language understanding evaluation (GLUE), situations with adversarial generations (SWAG) benchmarks, and readability benchmarks .
We analyze the performance of XDBERT on GLUE to show that the improvement is likely visually grounded .
Omission and addition of content is a typical issue in neural machine translation .
We propose a method for detecting such phenomena with off-the-shelf translation models .
Using contrastive conditioning, we compare the likelihood of a full sequence under a translation model to the likelihood of its parts, given the corresponding source or target sequence .
This allows to pinpoint superfluous words in the translation and untranslated words in the source even in the absence of a reference translation .
The accuracy of our method is comparable to a supervised method that requires a custom quality estimation model .
This work addresses the question of the localization of syntactic information encoded in the transformers representations .
We tackle this question from two perspectives, considering the object-past participle agreement in French, by identifying, first, in which part of the sentence and, second, in which part of the representation the syntactic information is encoded .
The results of our experiments, using probing, causal analysis and feature selection method, show that syntactic information is encoded locally in a way consistent with the French grammar .
Livonian is one of the most endangered languages in Europe with just a tiny handful of speakers and virtually no publicly available corpora .
In this paper we tackle the task of developing neural machine translation (NMT) between Livonian and English, with a two-fold aim: on one hand, preserving the language and on the other – enabling access to Livonian folklore, lifestories and other textual intangible heritage as well as making it easier to create further parallel corpora .
We rely on Livonian’s linguistic similarity to Estonian and Latvian and collect parallel and monolingual data for the four languages for translation experiments .
We combine different low-resource NMT techniques like zero-shot translation, cross-lingual transfer and synthetic data creation to reach the highest possible translation quality as well as to find which base languages are empirically more helpful for transfer to Livonian .
The resulting NMT systems and the collected monolingual and parallel data, including a manually translated and verified translation benchmark, are publicly released via OPUS and Huggingface repositories .
Text-based games (TGs) are exciting testbeds for developing deep reinforcement learning techniques due to their partially observed environments and large action spaces .
In these games, the agent learns to explore the environment via natural language interactions with the game simulator .
A fundamental challenge in TGs is the efficient exploration of the large action space when the agent has not yet acquired enough knowledge about the environment .
We propose CommExpl, an exploration technique that injects external commonsense knowledge, via a pretrained language model (LM), into the agent during training when the agent is the most uncertain about its next action .
Our method exhibits improvement on the collected game scores during the training in four out of nine games from Jericho .
Additionally, the produced trajectory of actions exhibit lower perplexity, when tested with a pretrained LM, indicating better closeness to human language .
Pre-trained language models (PLMs) cannot well recall rich factual knowledge of entities exhibited in large-scale corpora, especially those rare entities .
In this paper, we propose to build a simple but effective Pluggable Entity Lookup Table (PELT) on demand by aggregating the entity’s output representations of multiple occurrences in the corpora .
PELT can be compatibly plugged as inputs to infuse supplemental entity knowledge into PLMs .
Compared to previous knowledge-enhanced PLMs, PELT only requires 0.2%-5% pre-computation with capability of acquiring knowledge from out-of-domain corpora for domain adaptation scenario .
The experiments on knowledge-related tasks demonstrate that our method, PELT, can flexibly and effectively transfer entity knowledge from related corpora into PLMs with different architectures .
Our code and models are publicly available at https://github.com/thunlp/PELT .
The emergence of multilingual pre-trained language models makes it possible to adapt to target languages with only few labeled examples.However, vanilla fine-tuning tends to achieve degenerated and unstable results, owing to the Language Interference among different languages, and Parameter Overload under the few-sample transfer learning scenarios.To address two problems elegantly, we propose S4-Tuning, a Simple Cross-lingual Sub-network Tuning method .
S4-Tuning first detects the most essential sub-network for each target language, and only updates it during fine-tuning.In this way, the language sub-networks lower the scale of trainable parameters, and hence better suit the low-resource scenarios.Meanwhile, the commonality and characteristics across languages are modeled by the overlapping and non-overlapping parts to ease the interference among languages.Simple but effective, S4-Tuning gains consistent improvements over vanilla fine-tuning on three multi-lingual tasks involving 37 different languages in total (XNLI, PAWS-X, and Tatoeba) .
Certainty calibration is an important goal on the path to interpretability and trustworthy AI .
Particularly in the context of human-in-the-loop systems, high-quality low to mid-range certainty estimates are essential .
In the presence of a dominant high-certainty class, for instance the non-entity class in NER problems, existing calibration error measures are completely insensitive to potentially large errors in this certainty region of interest .
We introduce a region-balanced calibration error metric that weights all certainty regions equally .
When low and mid certainty estimates are taken into account, calibration error is typically larger than previously reported .
We introduce a simple extension of temperature scaling, requiring no additional computation, that can reduce both traditional and region-balanced notions of calibration error over existing baselines .
Reasoning using negation is known to be difficult for transformer-based language models .
While previous studies have used the tools of psycholinguistics to probe a transformer’s ability to reason over negation, none have focused on the types of negation studied in developmental psychology .
We explore how well transformers can process such categories of negation, by framing the problem as a natural language inference (NLI) task .
We curate a set of diagnostic questions for our target categories from popular NLI datasets and evaluate how well a suite of models reason over them .
We find that models perform consistently better only on certain categories, suggesting clear distinctions in how they are processed .
Natural Language Understanding (NLU) models can be trained on sensitive information such as phone numbers, zip-codes etc .
Recent literature has focused on Model Inversion Attacks (ModIvA) that can extract training data from model parameters .
In this work, we present a version of such an attack by extracting canaries inserted in NLU training data .
In the attack, an adversary with open-box access to the model reconstructs the canaries contained in the model’s training set .
We evaluate our approach by performing text completion on canaries and demonstrate that by using the prefix (non-sensitive) tokens of the canary, we can generate the full canary .
As an example, our attack is able to reconstruct a four digit code in the training dataset of the NLU model with a probability of 0.5 in its best configuration .
As countermeasures, we identify several defense mechanisms that, when combined, effectively eliminate the risk of ModIvA in our experiments .
Multiple metrics have been introduced to measure fairness in various natural language processing tasks .
These metrics can be roughly categorized into two categories: 1) extrinsic metrics for evaluating fairness in downstream applications and 2) intrinsic metrics for estimating fairness in upstream contextualized language representation models .
In this paper, we conduct an extensive correlation study between intrinsic and extrinsic metrics across bias notions using 19 contextualized language models .
We find that intrinsic and extrinsic metrics do not necessarily correlate in their original setting, even when correcting for metric misalignments, noise in evaluation datasets, and confounding factors such as experiment configuration for extrinsic metrics .
AMR parsing is the task that maps a sentence to an AMR semantic graph automatically .
The difficulty comes from generating the complex graph structure .
The previous state-of-the-art method translates the AMR graph into a sequence, then directly fine-tunes a pretrained sequence-to-sequence Transformer model (BART) .
However, purely treating the graph as a sequence does not take advantage of structural information about the graph .
In this paper, we design several strategies to add the important ancestor information into the Transformer Decoder .
Our experiments show that we can improve the performance for both AMR 2.0 and AMR 3.0 dataset and achieve new state-of-the-art results .
Large multilingual pretrained language models such as mBERT and XLM-RoBERTa have been found to be surprisingly effective for cross-lingual transfer of syntactic parsing models Wu and Dredze (2019), but only between related languages .
However, source and training languages are rarely related, when parsing truly low-resource languages .
To close this gap, we adopt a method from multi-task learning, which relies on automated curriculum learning, to dynamically optimize for parsing performance on outlier languages .
We show that this approach is significantly better than uniform and size-proportional sampling in the zero-shot setting .
Recent advances in Automatic Speech Recognition (ASR) have made it possible to reliably produce automatic transcripts of clinician-patient conversations .
However, access to clinical datasets is heavily restricted due to patient privacy, thus slowing down normal research practices .
We detail the development of a public access, high quality dataset comprising of 57 mocked primary care consultations, including audio recordings, their manual utterance-level transcriptions, and the associated consultation notes .
Our work illustrates how the dataset can be used as a benchmark for conversational medical ASR as well as consultation note generation from transcripts .
The goal-oriented document-grounded dialogue aims at responding to the user query based on the dialogue context and supporting document .
Existing studies tackle this problem by decomposing it into two sub-tasks: knowledge identification and response generation .
However, such pipeline methods would unavoidably suffer from the error propagation issue .
This paper proposes to unify these two sub-tasks via sequentially generating the grounding knowledge and the response .
We further develop a prompt-connected multi-task learning strategy to model the characteristics and connections of different tasks and introduce linear temperature scheduling to reduce the negative effect of irrelevant document information .
Experimental results demonstrate the effectiveness of our framework .
Interpolation-based regularisation methods such as Mixup, which generate virtual training samples, have proven to be effective for various tasks and modalities.We extend Mixup and propose DMix, an adaptive distance-aware interpolative Mixup that selects samples based on their diversity in the embedding space .
DMix leverages the hyperbolic space as a similarity measure among input samples for a richer encoded representation.DMix achieves state-of-the-art results on sentence classification over existing data augmentation methods on 8 benchmark datasets across English, Arabic, Turkish, and Hindi languages while achieving benchmark F1 scores in 3 times less number of iterations.We probe the effectiveness of DMix in conjunction with various similarity measures and qualitatively analyze the different components.DMix being generalizable, can be applied to various tasks, models and modalities .
We leverage embedding duplication between aligned sub-words to extend the Parent-Child transfer learning method, so as to improve low-resource machine translation .
We conduct experiments on benchmark datasets of My-En, Id-En and Tr-En translation scenarios .
The test results show that our method produces substantial improvements, achieving the BLEU scores of 22.5, 28.0 and 18.1 respectively .
In addition, the method is computationally efficient which reduces the consumption of training time by 63.8%, reaching the duration of 1.6 hours when training on a Tesla 16GB P100 GPU .
All the models and source codes in the experiments will be made publicly available to support reproducible research .
Analyzing the temporal sequence of texts from sources such as social media, news, and parliamentary debates is a challenging problem as it exhibits time-varying scale-free properties and fine-grained timing irregularities .
We propose a Hyperbolic Hawkes Attention Network (HYPHEN), which learns a data-driven hyperbolic space and models irregular powerlaw excitations using a hyperbolic Hawkes process .
Through quantitative and exploratory experiments over financial NLP, suicide ideation detection, and political debate analysis we demonstrate HYPHEN’s practical applicability for modeling online text sequences in a geometry agnostic manner .
Recent studies have shown that social media has increasingly become a platform for users to express suicidal thoughts outside traditional clinical settings .
With advances in Natural Language Processing strategies, it is now possible to design automated systems to assess suicide risk .
However, such systems may generate uncertain predictions, leading to severe consequences .
We hence reformulate suicide risk assessment as a selective prioritized prediction problem over the Columbia Suicide Severity Risk Scale (C-SSRS) .
We propose SASI, a risk-averse and self-aware transformer-based hierarchical attention classifier, augmented to refrain from making uncertain predictions .
We show that SASI is able to refrain from 83% of incorrect predictions on real-world Reddit data .
Furthermore, we discuss the qualitative, practical, and ethical aspects of SASI for suicide risk assessment as a human-in-the-loop framework .
Because meaning can often be inferred from lexical semantics alone, word order is often a redundant cue in natural language .
For example, the words chopped, chef, and onion are more likely used to convey “The chef chopped the onion,” not “The onion chopped the chef.” Recent work has shown large language models to be surprisingly word order invariant, but crucially has largely considered natural prototypical inputs, where compositional meaning mostly matches lexical expectations .
To overcome this confound, we probe grammatical role representation in English BERT and GPT-2, on instances where lexical expectations are not sufficient, and word order knowledge is necessary for correct classification .
Such non-prototypical instances are naturally occurring English sentences with inanimate subjects or animate objects, or sentences where we systematically swap the arguments to make sentences like “The onion chopped the chef” .
We find that, while early layer embeddings are largely lexical, word order is in fact crucial in defining the later-layer representations of words in semantically non-prototypical positions .
Our experiments isolate the effect of word order on the contextualization process, and highlight how models use context in the uncommon, but critical, instances where it matters .
Triangular machine translation is a special case of low-resource machine translation where the language pair of interest has limited parallel data, but both languages have abundant parallel data with a pivot language .
Naturally, the key to triangular machine translation is the successful exploitation of such auxiliary data .
In this work, we propose a transfer-learning-based approach that utilizes all types of auxiliary data .
As we train auxiliary source-pivot and pivot-target translation models, we initialize some parameters of the pivot side with a pre-trained language model and freeze them to encourage both translation models to work in the same pivot language space, so that they can be smoothly transferred to the source-target translation model .
Experiments show that our approach can outperform previous ones .
Cognitively plausible visual dialogue models should keep a mental scoreboard of shared established facts in the dialogue context .
We propose a theory-based evaluation method for investigating to what degree models pretrained on the VisDial dataset incrementally build representations that appropriately do scorekeeping .
Our conclusion is that the ability to make the distinction between shared and privately known statements along the dialogue is moderately present in the analysed models, but not always incrementally consistent, which may partially be due to the limited need for grounding interactions in the original task .
Label smoothing and vocabulary sharing are two widely used techniques in neural machine translation models .
However, we argue that simply applying both techniques can be conflicting and even leads to sub-optimal performance .
When allocating smoothed probability, original label smoothing treats the source-side words that would never appear in the target language equally to the real target-side words, which could bias the translation model .
To address this issue, we propose Masked Label Smoothing (MLS), a new mechanism that masks the soft label probability of source-side words to zero .
Simple yet effective, MLS manages to better integrate label smoothing with vocabulary sharing .
Our extensive experiments show that MLS consistently yields improvement over original label smoothing on different datasets, including bilingual and multilingual translation from both translation quality and model’s calibration .
Our code is released at https://github.com/PKUnlp-icler/MLS .
Multi-Label Text Classification (MLTC) is a fundamental and challenging task in natural language processing .
Previous studies mainly focus on learning text representation and modeling label correlation but neglect the rich knowledge from the existing similar instances when predicting labels of a specific text .
To make up for this oversight, we propose a k nearest neighbor (kNN) mechanism which retrieves several neighbor instances and interpolates the model output with their labels .
Moreover, we design a multi-label contrastive learning objective that makes the model aware of the kNN classification process and improves the quality of the retrieved neighbors while inference .
Extensive experiments show that our method can bring consistent and significant performance improvement to multiple MLTC models including the state-of-the-art pretrained and non-pretrained ones .
Effectively finetuning pretrained language models (PLMs) is critical for their success in downstream tasks .
However, PLMs may have risks in overfitting the pretraining tasks and data, which usually have gap with the target downstream tasks .
Such gap may be difficult for existing PLM finetuning methods to overcome and lead to suboptimal performance .
In this paper, we propose a very simple yet effective method named NoisyTune to help better finetune PLMs on downstream tasks by adding some noise to the parameters of PLMs before fine-tuning .
More specifically, we propose a matrix-wise perturbing method which adds different uniform noises to different parameter matrices based on their standard deviations .
In this way, the varied characteristics of different types of parameters in PLMs can be considered .
Extensive experiments on both GLUE English benchmark and XTREME multilingual benchmark show NoisyTune can consistently empower the finetuning of different PLMs on different downstream tasks .
Modern writing assistance applications are always equipped with a Grammatical Error Correction (GEC) model to correct errors in user-entered sentences .
Different scenarios have varying requirements for correction behavior, e.g., performing more precise corrections (high precision) or providing more candidates for users (high recall) .
However, previous works adjust such trade-off only for sequence labeling approaches .
In this paper, we propose a simple yet effective counterpart – Align-and-Predict Decoding (APD) for the most popular sequence-to-sequence models to offer more flexibility for the precision-recall trade-off .
During inference, APD aligns the already generated sequence with input and adjusts scores of the following tokens .
Experiments in both English and Chinese GEC benchmarks show that our approach not only adapts a single model to precision-oriented and recall-oriented inference, but also maximizes its potential to achieve state-of-the-art results .
Our code is available at https://github.com/AutoTemp/Align-and-Predict .
Injecting desired geometric properties into text representations has attracted a lot of attention .
A property that has been argued for, due to its better utilisation of representation space, is isotropy .
In parallel, VAEs have been successful in areas of NLP, but are known for their sub-optimal utilisation of the representation space .
To address an aspect of this, we investigate the impact of injecting isotropy during training of VAEs .
We achieve this by using an isotropic Gaussian posterior (IGP) instead of the ellipsoidal Gaussian posterior .
We illustrate that IGP effectively encourages isotropy in the representations, inducing a more discriminative latent space .
Compared to vanilla VAE, this translates into a much better classification performance, robustness to input perturbation, and generative behavior .
Additionally, we offer insights about the representational properties encouraged by IGP .
Several methods have been proposed for classifying long textual documents using Transformers .
However, there is a lack of consensus on a benchmark to enable a fair comparison among different approaches .
In this paper, we provide a comprehensive evaluation of the relative efficacy measured against various baselines and diverse datasets — both in terms of accuracy as well as time and space overheads .
Our datasets cover binary, multi-class, and multi-label classification tasks and represent various ways information is organized in a long text (e.g .
information that is critical to making the classification decision is at the beginning or towards the end of the document) .
Our results show that more complex models often fail to outperform simple baselines and yield inconsistent performance across datasets .
These findings emphasize the need for future studies to consider comprehensive baselines and datasets that better represent the task of long document classification to develop robust models .
A common way to combat exposure bias is by applying scores from evaluation metrics as rewards in reinforcement learning (RL) .
Metrics leveraging contextualized embeddings appear more flexible than their n-gram matching counterparts and thus ideal as training rewards .
However, metrics such as BERTScore greedily align candidate and reference tokens, which can allow system outputs to receive excess credit relative to a reference .
Furthermore, past approaches featuring semantic similarity rewards suffer from repetitive outputs and overfitting .
We address these issues by proposing metrics that replace the greedy alignments in BERTScore with optimized ones .
We compute them on a model’s trained token embeddings to prevent domain mismatch .
Our model optimizing discrete alignment metrics consistently outperforms cross-entropy and BLEU reward baselines on AMR-to-text generation .
In addition, we find that this approach enjoys stable training compared to a non-RL setting .
This paper analyzes negation in eight popular corpora spanning six natural language understanding tasks .
We show that these corpora have few negations compared to general-purpose English, and that the few negations in them are often unimportant .
Indeed, one can often ignore negations and still make the right predictions .
Additionally, experimental results show that state-of-the-art transformers trained with these corpora obtain substantially worse results with instances that contain negation, especially if the negations are important .
We conclude that new corpora accounting for negation are needed to solve natural language understanding tasks when negation is present .
In this paper, we challenge the ACL community to reckon with historical and ongoing colonialism by adopting a set of ethical obligations and best practices drawn from the Indigenous studies literature .
While the vast majority of NLP research focuses on a very small number of very high resource languages (English, Chinese, etc), some work has begun to engage with Indigenous languages .
No research involving Indigenous language data can be considered ethical without first acknowledging that Indigenous languages are not merely very low resource languages .
The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside researchers .
To this end, we propose that the ACL draft and adopt an ethical framework for NLP researchers and computational linguists wishing to engage in research involving Indigenous languages .
Pre-trained models have shown very good performances on a number of question answering benchmarks especially when fine-tuned on multiple question answering datasets at once .
In this work, we propose an approach for generating a fine-tuning dataset thanks to a rule-based algorithm that generates questions and answers from unannotated sentences .
We show that the state-of-the-art model UnifiedQA can greatly benefit from such a system on a multiple-choice benchmark about physics, biology and chemistry it has never been trained on .
We further show that improved performances may be obtained by selecting the most challenging distractors (wrong answers), with a dedicated ranker based on a pretrained RoBERTa model .
Deep learning sequence models have been successful with morphological inflection generation .
The SIGMORPHON shared task results in the past several years indicate that such models can perform well, but only if the training data covers a good amount of different lemmata, or if the lemmata to be inflected at test time have also been seen in training, as has indeed been largely the case in these tasks .
Surprisingly, we find that standard models such as the Transformer almost completely fail at generalizing inflection patterns when trained on a limited number of lemmata and asked to inflect previously unseen lemmata—i.e .
under “wug test”-like circumstances .
This is true even though the actual number of training examples is very large .
While established data augmentation techniques can be employed to alleviate this shortcoming by introducing a copying bias through hallucinating synthetic new word forms using the alphabet in the language at hand, our experiment results show that, to be more effective, the hallucination process needs to pay attention to substrings of syllable-like length rather than individual characters .
This paper introduces an adversarial method to stress-test trained metrics for the evaluation of conversational dialogue systems .
The method leverages Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics .
We apply our method to test recently proposed trained metrics .
We find that they all are susceptible to giving high scores to responses generated by rather simple and obviously flawed strategies that our method converges on .
For instance, simply copying parts of the conversation context to form a response yields competitive scores or even outperforms responses written by humans .
Distinct is a widely used automatic metric for evaluating diversity in language generation tasks.However, we observed that the original approach to calculating distinct scores has evident biases that tend to assign higher penalties to longer sequences .
We refine the calculation of distinct scores by scaling the number of distinct tokens based on their expectations .
We provide both empirical and theoretical evidence to show that our method effectively removes the biases existing in the original distinct score .
Our experiments show that our proposed metric, Expectation-Adjusted Distinct (EAD), correlates better with human judgment in evaluating response diversity.To assist future research, we provide an example implementation at https://github.com/lsy641/Expectation-Adjusted-Distinct .
As privacy gains traction in the NLP community, researchers have started adopting various approaches to privacy-preserving methods .
One of the favorite privacy frameworks, differential privacy (DP), is perhaps the most compelling thanks to its fundamental theoretical guarantees .
Despite the apparent simplicity of the general concept of differential privacy, it seems non-trivial to get it right when applying it to NLP .
In this short paper, we formally analyze several recent NLP papers proposing text representation learning using DPText (Beigi et al., 2019a,b; Alnasser et al., 2021; Beigi et al., 2021) and reveal their false claims of being differentially private .
Furthermore, we also show a simple yet general empirical sanity check to determine whether a given implementation of a DP mechanism almost certainly violates the privacy loss guarantees .
Our main goal is to raise awareness and help the community understand potential pitfalls of applying differential privacy to text representation learning .
We consider the task of document-level entity linking (EL), where it is important to make consistent decisions for entity mentions over the full document jointly .
We aim to leverage explicit “connections” among mentions within the document itself: we propose to join EL and coreference resolution (coref) in a single structured prediction task over directed trees and use a globally normalized model to solve it .
This contrasts with related works where two separate models are trained for each of the tasks and additional logic is required to merge the outputs .
Experimental results on two datasets show a boost of up to +5% F1-score on both coref and EL tasks, compared to their standalone counterparts .
For a subset of hard cases, with individual mentions lacking the correct EL in their candidate entity list, we obtain a +50% increase in accuracy .
We present an efficient BERT-based multi-task (MT) framework that is particularly suitable for iterative and incremental development of the tasks .
The proposed framework is based on the idea of partial fine-tuning, i.e .
only fine-tune some top layers of BERT while keep the other layers frozen .
For each task, we train independently a single-task (ST) model using partial fine-tuning .
Then we compress the task-specific layers in each ST model using knowledge distillation .
Those compressed ST models are finally merged into one MT model so that the frozen layers of the former are shared across the tasks .
We exemplify our approach on eight GLUE tasks, demonstrating that it is able to achieve 99.6% of the performance of the full fine-tuning method, while reducing up to two thirds of its overhead .
We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability .
Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero .
We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning .
Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations .
Automatic ICD coding is defined as assigning disease codes to electronic medical records (EMRs).Existing methods usually apply label attention with code representations to match related text snippets.Unlike these works that model the label with the code hierarchy or description, we argue that the code synonyms can provide more comprehensive knowledge based on the observation that the code expressions in EMRs vary from their descriptions in ICD .
By aligning codes to concepts in UMLS, we collect synonyms of every code .
Then, we propose a multiple synonyms matching network to leverage synonyms for better code representation learning, and finally help the code classification .
Experiments on the MIMIC-III dataset show that our proposed method outperforms previous state-of-the-art methods .
Pretrained language models (PLMs) have achieved superhuman performance on many benchmarks, creating a need for harder tasks .
We introduce CoDA21 (Context Definition Alignment), a challenging benchmark that measures natural language understanding (NLU) capabilities of PLMs: Given a definition and a context each for k words, but not the words themselves, the task is to align the k definitions with the k contexts .
CoDA21 requires a deep understanding of contexts and definitions, including complex inference and world knowledge .
We find that there is a large gap between human and PLM performance, suggesting that CoDA21 measures an aspect of NLU that is not sufficiently covered in existing benchmarks .
Recent active learning (AL) approaches in Natural Language Processing (NLP) proposed using off-the-shelf pretrained language models (LMs) .
In this paper, we argue that these LMs are not adapted effectively to the downstream task during AL and we explore ways to address this issue .
We suggest to first adapt the pretrained LM to the target task by continuing training with all the available unlabeled data and then use it for AL .
We also propose a simple yet effective fine-tuning method to ensure that the adapted LM is properly trained in both low and high resource scenarios during AL .
Our experiments demonstrate that our approach provides substantial data efficiency improvements compared to the standard fine-tuning approach, suggesting that a poor training strategy can be catastrophic for AL .
In this paper, we leverage large language models (LLMs) to perform zero-shot text style transfer .
We present a prompting method that we call augmented zero-shot learning, which frames style transfer as a sentence rewriting task and requires only a natural language instruction, without model fine-tuning or exemplars in the target style .
Augmented zero-shot learning is simple and demonstrates promising results not just on standard style transfer tasks such as sentiment, but also on arbitrary transformations such as ‘make this melodramatic’ or ‘insert a metaphor.’ .
Our goal is to study the novel task of distant supervision for multilingual relation extraction (Multi DS-RE) .
Research in Multi DS-RE has remained limited due to the absence of a reliable benchmarking dataset .
The only available dataset for this task, RELX-Distant (Köksal and Özgür, 2020), displays several unrealistic characteristics, leading to a systematic overestimation of model performance .
To alleviate these concerns, we release a new benchmark dataset for the task, named DiS-ReX .
We also modify the widely-used bag attention models using an mBERT encoder and provide the first baseline results on the proposed task .
We show that DiS-ReX serves as a more challenging dataset than RELX-Distant, leaving ample room for future research in this domain .
In the domain of Morphology, Inflection is a fundamental and important task that gained a lot of traction in recent years, mostly via SIGMORPHON’s shared-tasks.With average accuracy above 0.9 over the scores of all languages, the task is considered mostly solved using relatively generic neural seq2seq models, even with little data provided.In this work, we propose to re-evaluate morphological inflection models by employing harder train-test splits that will challenge the generalization capacity of the models .
In particular, as opposed to the naïve split-by-form, we propose a split-by-lemma method to challenge the performance on existing benchmarks.Our experiments with the three top-ranked systems on the SIGMORPHON’s 2020 shared-task show that the lemma-split presents an average drop of 30 percentage points in macro-average for the 90 languages included .
The effect is most significant for low-resourced languages with a drop as high as 95 points, but even high-resourced languages lose about 10 points on average .
Our results clearly show that generalizing inflection to unseen lemmas is far from being solved, presenting a simple yet effective means to promote more sophisticated models .
Before entering the neural network, a token needs to be converted to its one-hot representation, which is a discrete distribution of the vocabulary .
Smoothed representation is the probability of candidate tokens obtained from the pre-trained masked language model, which can be seen as a more informative augmented substitution to the one-hot representation .
We propose an efficient data augmentation method, dub as text smoothing, by converting a sentence from its one-hot representation to controllable smoothed representation.We evaluate text smoothing on different datasets in a low-resource regime .
Experimental results show that text smoothing outperforms various mainstream data augmentation methods by a substantial margin .
Moreover, text smoothing can be combined with these data augmentation methods to achieve better performance .
    "title": "What Could Possibly Go Wrong When Interacting with Proactive Smart Speakers? A Case Study Using an ESM Application",
    "URL": "https://doi.org/10.1145/3491102.3517432"
  },
  {
    "id": "10.1145/3491102.3501977",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Taejun"
      },
      {
        "family": "Ham",
        "given": "Auejin"
      },
      {
        "family": "Ahn",
        "given": "Sunggeun"
      },
      {
        "family": "Lee",
        "given": "Geehyuk"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present Lattice Menu, a gaze-based marking menu utilizing a lattice of visual anchors that helps perform accurate gaze pointing for menu item selection. Users who know the location of the desired item can leverage target-assisted gaze gestures for multilevel item selection by looking at visual anchors over the gaze trajectories. Our evaluation showed that Lattice Menu exhibits a considerably low error rate (~1%) and a quick menu selection time (1.3-1.6 s) for expert usage across various menu structures (4 \u00d7 4 \u00d7 4 and 6 \u00d7 6 \u00d7 6) and sizes (8, 10 and 12\u00b0). In comparison with a traditional gaze-based marking menu that does not utilize visual targets, Lattice Menu showed remarkably (~5 times) fewer menu selection errors for expert usage. In a post-interview, all 12 subjects preferred Lattice Menu, and most subjects (8 out of 12) commented that the provisioning of visual targets facilitated more stable menu selections with reduced eye fatigue.",
    "call-number": "10.1145/3491102.3501977",
    "collection-number": "277",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501977",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Eye Tracking, AR/VR, Marking Menu, Gaze-Based Interaction",
    "number": "Article 277",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Lattice Menu: A Low-Error Gaze-Based Marking Menu Utilizing Target-Assisted Gaze Gestures on a Lattice of Visual Anchors",
    "URL": "https://doi.org/10.1145/3491102.3501977"
  },
  {
    "id": "10.1145/3491102.3501887",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Minfan"
      },
      {
        "family": "Ehrmann",
        "given": "Daniel"
      },
      {
        "family": "Mazwi",
        "given": "Mjaye"
      },
      {
        "family": "Eytan",
        "given": "Danny"
      },
      {
        "family": "Ghassemi",
        "given": "Marzyeh"
      },
      {
        "family": "Chevalier",
        "given": "Fanny"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Electronic health records in critical care medicine offer unprecedented opportunities for clinical reasoning and decision making. Paradoxically, these data-rich environments have also resulted in clinical decision support systems (CDSSs) that fit poorly into clinical contexts, and increase health workers cognitive load. In this paper, we introduce a novel approach to designing CDSSs that are embedded in clinical workflows, by presenting problem-based curated data views tailored for problem-driven discovery, team communication, and situational awareness. We describe the design and evaluation of one such CDSS, In-Sight, that embodies our approach and addresses the clinical problem of monitoring critically ill pediatric patients. Our work is the result of a co-design process, further informed by empirical data collected through formal usability testing, focus groups, and a simulation study with domain experts. We discuss the potential and limitations of our approach, and share lessons learned in our iterative co-design process.",
    "call-number": "10.1145/3491102.3501887",
    "collection-number": "278",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501887",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "visualization, intensive care medicine, clinical decision support systems, checklist",
    "number": "Article 278",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Get To The Point! Problem-Based Curated Data Views To Augment Care For Critically Ill Patients",
    "URL": "https://doi.org/10.1145/3491102.3501887"
  },
  {
    "id": "10.1145/3491102.3501984",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "McNaney",
        "given": "Roisin"
      },
      {
        "family": "Morgan",
        "given": "Catherine"
      },
      {
        "family": "Kulkarni",
        "given": "Pranav"
      },
      {
        "family": "Vega",
        "given": "Julio"
      },
      {
        "family": "Heidarivincheh",
        "given": "Farnoosh"
      },
      {
        "family": "McConville",
        "given": "Ryan"
      },
      {
        "family": "Whone",
        "given": "Alan"
      },
      {
        "family": "Kim",
        "given": "Mickey"
      },
      {
        "family": "Kirkham",
        "given": "Reuben"
      },
      {
        "family": "Craddock",
        "given": "Ian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In interdisciplinary spaces such as digital health, datasets that are complex to collect, require specialist facilities, and/or are collected with specific populations have value in a range of different sectors. In this study we collected a simulated free-living dataset, in a smart home, with 12 participants (six people with Parkinson\u2019s, six carers). We explored their initial perceptions of the sensors through interviews and then conducted two data exploration workshops, wherein we showed participants the collected data and discussed their views on how this data, and other data relating to their Parkinson\u2019s symptoms, might be shared across different sectors. We provide recommendations around how participants might be better engaged in considering data sharing in the early stages of research, and guidance for how research might be configured to allow for more informed data sharing practices in the future.",
    "call-number": "10.1145/3491102.3501984",
    "collection-number": "280",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501984",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Data sharing, Privacy and security, IoT, Smart home, Parkinson\u2019s",
    "number": "Article 280",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Perceptions of Cross-Sectoral Data Sharing with People with Parkinson\u2019s",
    "URL": "https://doi.org/10.1145/3491102.3501984"
  },
  {
    "id": "10.1145/3491102.3517669",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hoefer",
        "given": "Michael Jeffrey Daniel"
      },
      {
        "family": "Schumacher",
        "given": "Bryce E"
      },
      {
        "family": "Voida",
        "given": "Stephen"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present the research area of personal dream informatics: studying the self-information systems that support dream engagement and communication between the dreaming self and the wakeful self. Through a survey study of 281 individuals primarily recruited from an online community dedicated to dreaming, we develop a dream-information systems view of dreaming and dream tracking as a type of self-information system. While dream-information systems are characterized by diverse tracking processes, motivations, and outcomes, they are universally constrained by the ephemeral dreamset\u2014the short period of time between waking up and rapid memory loss of dream experiences. By developing a system dynamics model of dreaming we highlight feedback loops that serve as high leverage points for technology designers, and suggest a variety of design considerations for crafting technology that best supports dream recall, dream tracking, and dreamwork for nightmare relief and personal development.",
    "call-number": "10.1145/3491102.3517669",
    "collection-number": "281",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517669",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "dreamwork, survey, personal informatics, dream tracking, dream journaling, reddit, quantified self, mental health informatics, self-tracking, dreaming, self-information systems, dreams, system dynamics, dream informatics",
    "number": "Article 281",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Personal Dream Informatics: A Self-Information Systems Model of Dream Engagement",
    "URL": "https://doi.org/10.1145/3491102.3517669"
  },
  {
    "id": "10.1145/3491102.3517690",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Midha",
        "given": "Serena"
      },
      {
        "family": "Wilson",
        "given": "Max L"
      },
      {
        "family": "Sharples",
        "given": "Sarah"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We can now buy consumer brain-computer interface devices to help us meditate and focus, but what are we aiming to achieve? Mental workload (MWL) is an established concept, and as a form of personal data could be useful for making positive life changes. However, MWL is typically only studied for isolated tasks to avoid overload and underload. We investigated lived experiences of MWL, aiming to understand how tracking such data could implicate our everyday lives. 19 participants, that had previously experienced tracking their mental workload, took part in interviews and an Interpretive Phenomenological Analysis identified four superordinate themes. Results point towards mixed and changing perceptions of MWL and the importance of fluctuating between MWL levels in daily life in terms of performances, perceptions, and wellbeing. These findings are captured in an apparent Cycle, which outside factors can disrupt, and we discuss these cycles in terms of personal informatics and work performance.",
    "call-number": "10.1145/3491102.3517690",
    "collection-number": "282",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517690",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 282",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Lived Experiences of Mental Workload in Everyday Life",
    "URL": "https://doi.org/10.1145/3491102.3517690"
  },
  {
    "id": "10.1145/3491102.3517662",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tuli",
        "given": "Anupriya"
      },
      {
        "family": "Singh",
        "given": "Surbhi"
      },
      {
        "family": "Narula",
        "given": "Rikita"
      },
      {
        "family": "Kumar",
        "given": "Neha"
      },
      {
        "family": "Singh",
        "given": "Pushpendra"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Menstrual tracking is a mechanism widely engaged towards preserving menstrual dignity, as natural birth control, for ensuring adequate preparation for an upcoming cycle, among other motivations. We investigate the design of digital menstrual trackers towards enabling period-positive ecologies in otherwise stigmatized contexts. We examine menstrual tracking practices across ages (12\u201365 yrs.) using a combination of methods\u20143 surveys (450+ responses), a cultural probe (10 adolescents), interviews (16 adults), and a review of (9) mobile applications. Our analysis highlights the diversity across menstrual tracking practices and the role of relationships in influencing these practices throughout the menstrual journey. We also identify menstrual tracking as an avenue towards the emancipation of those who menstruate. Finally, we draw on Martha Nussbaum\u2019s central human capabilities to discuss sociotechnical implications for redesigning digital menstrual trackers towards crafting just and period-positive futures.",
    "call-number": "10.1145/3491102.3517662",
    "collection-number": "283",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517662",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Menstrual dignity, Capabilities, Period-positive futures, Menstrual journey, Digital menstrual trackers, Menstrual tracking, Liberation",
    "number": "Article 283",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Rethinking Menstrual Trackers Towards Period-Positive Ecologies",
    "URL": "https://doi.org/10.1145/3491102.3517662"
  },
  {
    "id": "10.1145/3491102.3501937",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "M\u00e4kel\u00e4",
        "given": "Ville"
      },
      {
        "family": "Winter",
        "given": "Jonas"
      },
      {
        "family": "Schwab",
        "given": "Jasmin"
      },
      {
        "family": "Koch",
        "given": "Michael"
      },
      {
        "family": "Alt",
        "given": "Florian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The COVID-19 pandemic created unprecedented questions for touch-based public displays regarding hygiene, risks, and general awareness. We study how people perceive and consider hygiene on shared touchscreens, and how touchscreens could be improved through hygiene-related functions. First, we report the results from an online survey (n = 286). Second, we present a hygiene concept for touchscreens that visualizes prior touches and provides information about the cleaning of the display and number of prior users. Third, we report the feedback for our hygiene concept from 77 participants. We find that there is demand for improved awareness of public displays\u2019 hygiene status, especially among those with stronger concerns about COVID-19. A particularly desired detail is when the display has been cleaned. For visualizing prior touches, fingerprints worked best. We present further considerations for designing for hygiene on public displays.",
    "call-number": "10.1145/3491102.3501937",
    "collection-number": "284",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501937",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Pandemic, COVID-19, Public displays, Touch interaction, Hygiene",
    "number": "Article 284",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Pandemic Displays: Considering Hygiene on Public Touchscreens in the Post-Pandemic Era",
    "URL": "https://doi.org/10.1145/3491102.3501937"
  },
  {
    "id": "10.1145/3491102.3501864",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ryan",
        "given": "Kathleen"
      },
      {
        "family": "Dockray",
        "given": "Samantha"
      },
      {
        "family": "Linehan",
        "given": "Conor"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "eHealth coaching is a promising approach for delivering effective, person-centered, digital health interventions. Yet, the way eHealth coaches \u2018tailor\u2019 interventions using technology is currently unclear. This study aims to understand how eHealth coaches tailor support to clients seeking to lose weight. Nine in-depth interviews with eHealth coaches were conducted. The data were analyzed using thematic analysis, deriving three themes: \u2018Understanding the client,\u2019 \u2018Adapting Support,\u2019 and \u2018Navigating challenges.\u2019 Coaches used both assessment tools and their growing relationship to understand client's needs. Coaches adapted the pace and nature of educational content, utilized their clients' preferred technologies, and adopted different personas to meet the needs of each individual. Providing tailored support also presented challenges for eHealth coaches, with technology eroding personal and professional boundaries. Our work interrogates what it means to \u2018tailor\u2019 support, through exploring coaching as a humanistic approach to behaviour change, with implications for the design of person-centered digital coaching interventions/systems.",
    "call-number": "10.1145/3491102.3501864",
    "collection-number": "285",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501864",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 285",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding How eHealth Coaches Tailor Support For Weight Loss: Towards the Design of Person-Centered Coaching Systems",
    "URL": "https://doi.org/10.1145/3491102.3501864"
  },
  {
    "id": "10.1145/3491102.3501950",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bagalkot",
        "given": "Naveen"
      },
      {
        "family": "Akbar",
        "given": "Syeda Zainab"
      },
      {
        "family": "Sharma",
        "given": "Swati"
      },
      {
        "family": "Mackintosh",
        "given": "Nicola"
      },
      {
        "family": "Harrington",
        "given": "Deirdre"
      },
      {
        "family": "Griffiths",
        "given": "Paula"
      },
      {
        "family": "Noronha",
        "given": "Judith Angelitta"
      },
      {
        "family": "Verdezoto",
        "given": "Nervo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Behavior change and improving health literacy based on normative ideals of motherhood is a dominant paradigm to address maternal health challenges. However, these ideals often remove women's control over their bodies overlooking how the bodily experiences of pregnancy are socially and culturally constructed. We report on 27 interviews with pregnant women and nursing mothers in rural and semi-urban areas of South India, and six focus groups with 23 frontline health workers as secondary data. We explore how the embodied pregnancy experiences are influenced and negotiated by the socio-cultural context and existing care infrastructures. Our findings highlight how the ways of seeing, knowing, and caring for a body of a pregnant woman through often conflicting norms, beliefs and practices of medicine, nourishment and care actively shape the experiences of pregnancy. We open up a space for novel opportunities for digital health technologies to enhance women's embodied experiences and pregnancy care infrastructures in the Global South.",
    "call-number": "10.1145/3491102.3501950",
    "collection-number": "286",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501950",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "care infrastructures, HCI4D, pregnancy care, embodied experiences, Maternal health, digital health, negotiation, challenges, South India",
    "number": "Article 286",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Embodied Negotiations, Practices and Experiences Interacting with Pregnancy Care Infrastructures in South India",
    "URL": "https://doi.org/10.1145/3491102.3501950"
  },
  {
    "id": "10.1145/3491102.3501935",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Jiwan"
      },
      {
        "family": "Oakley",
        "given": "Ian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The diminutive size of wrist wearables has prompted the design of many novel input techniques to increase expressivity. Finger identification, or assigning different functionality to different fingers, has been frequently proposed. However, while the value of the technique seems clear, its implementation remains challenging, often relying on external devices (e.g., worn magnets) or explicit instructions. Addressing these limitations, this paper explores a novel approach to natural and unencumbered finger identification on an unmodified smartwatch: sonar. To do this, we adapt an existing finger tracking smartphone sonar implementation\u2014rather than extract finger motion, we process raw sonar fingerprints representing the complete sonar scene recorded during a touch. We capture data from 16 participants operating a smartwatch and use their sonar fingerprints to train a deep learning recognizer that identifies taps by the thumb, index, and middle fingers with an accuracy of up to 93.7%, sufficient to support meaningful application development.",
    "call-number": "10.1145/3491102.3501935",
    "collection-number": "287",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501935",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Finger identification, smartwatch, sonar",
    "number": "Article 287",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SonarID: Using Sonar to Identify Fingers on a Smartwatch",
    "URL": "https://doi.org/10.1145/3491102.3501935"
  },
  {
    "id": "10.1145/3491102.3502015",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kimura",
        "given": "Naoki"
      },
      {
        "family": "Gemicioglu",
        "given": "Tan"
      },
      {
        "family": "Womack",
        "given": "Jonathan"
      },
      {
        "family": "Li",
        "given": "Richard"
      },
      {
        "family": "Zhao",
        "given": "Yuhui"
      },
      {
        "family": "Bedri",
        "given": "Abdelkareem"
      },
      {
        "family": "Su",
        "given": "Zixiong"
      },
      {
        "family": "Olwal",
        "given": "Alex"
      },
      {
        "family": "Rekimoto",
        "given": "Jun"
      },
      {
        "family": "Starner",
        "given": "Thad"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Speech is inappropriate in many situations, limiting when voice control can be used. Most unvoiced speech text entry systems can not be used while on-the-go due to movement artifacts. Using a dental retainer with capacitive touch sensors, SilentSpeller tracks tongue movement, enabling users to type by spelling words without voicing. SilentSpeller achieves an average 97% character accuracy in offline isolated word testing on a 1164-word dictionary. Walking has little effect on accuracy; average offline character accuracy was roughly equivalent on 107 phrases entered while walking (97.5%) or seated (96.5%). To demonstrate extensibility, the system was tested on 100 unseen words, leading to an average 94% accuracy. Live text entry speeds for seven participants averaged 37 words per minute at 87% accuracy. Comparing silent spelling to current practice suggests that SilentSpeller may be a viable alternative for silent mobile text entry.",
    "call-number": "10.1145/3491102.3502015",
    "collection-number": "288",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502015",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "wearable computing, text entry, silent speech interface",
    "number": "Article 288",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SilentSpeller: Towards mobile, hands-free, silent speech text entry using electropalatography",
    "URL": "https://doi.org/10.1145/3491102.3502015"
  },
  {
    "id": "10.1145/3491102.3517440",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Xiang"
      },
      {
        "family": "Ikematsu",
        "given": "Kaori"
      },
      {
        "family": "Kato",
        "given": "Kunihiro"
      },
      {
        "family": "Sugiura",
        "given": "Yuta"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "By sensing how a user is holding a smartphone, adaptive user interfaces are possible such as those that automatically switch the displayed content and position of graphical user interface (GUI) components following how the phone is being held. We propose ReflecTouch, a novel method for detecting how a smartphone is being held by capturing images of the smartphone screen reflected on the cornea with a built-in front camera. In these images, the areas where the user places their fingers on the screen appear as shadows, which makes it possible to estimate the grasp posture. Since most smartphones have a front camera, this method can be used regardless of the device model; in addition, no additional sensor or hardware is required. We conducted data collection experiments to verify the classification accuracy of the proposed method for six different grasp postures, and the accuracy was 85%.",
    "call-number": "10.1145/3491102.3517440",
    "collection-number": "289",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517440",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Corneal reflection images., Hand grip detection",
    "number": "Article 289",
    "number-of-pages": "8",
    "page": "1\u20138",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ReflecTouch: Detecting Grasp Posture of Smartphone Using Corneal Reflection Images",
    "URL": "https://doi.org/10.1145/3491102.3517440"
  },
  {
    "id": "10.1145/3491102.3517698",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Yuntao"
      },
      {
        "family": "Ding",
        "given": "Jiexin"
      },
      {
        "family": "Chatterjee",
        "given": "Ishan"
      },
      {
        "family": "Salemi Parizi",
        "given": "Farshid"
      },
      {
        "family": "Zhuang",
        "given": "Yuzhou"
      },
      {
        "family": "Yan",
        "given": "Yukang"
      },
      {
        "family": "Patel",
        "given": "Shwetak"
      },
      {
        "family": "Shi",
        "given": "Yuanchun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Face orientation can often indicate users\u2019 intended interaction target. In this paper, we propose FaceOri, a novel face tracking technique based on acoustic ranging using earphones. FaceOri can leverage the speaker on a commodity device to emit an ultrasonic chirp, which is picked up by the set of microphones on the user\u2019s earphone, and then processed to calculate the distance from each microphone to the device. These measurements are used to derive the user\u2019s face orientation and distance with respect to the device. We conduct a ground truth comparison and user study to evaluate FaceOri\u2019s performance. The results show that the system can determine whether the user orients to the device at a 93.5% accuracy within a 1.5 meters range. Furthermore, FaceOri can continuously track user\u2019s head orientation with a median absolute error of 10.9 mm in the distance, 3.7\u00b0 in yaw, and 5.8\u00b0 in pitch. FaceOri can allow for convenient hands-free control of devices and produce more intelligent context-aware interactions.",
    "call-number": "10.1145/3491102.3517698",
    "collection-number": "290",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517698",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "head orientation, earphone, head pose estimation., Acoustic ranging",
    "number": "Article 290",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FaceOri: Tracking Head Position and Orientation Using Ultrasonic Ranging on Earphones",
    "URL": "https://doi.org/10.1145/3491102.3517698"
  },
  {
    "id": "10.1145/3491102.3502079",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lam",
        "given": "Kevin C."
      },
      {
        "family": "Gutwin",
        "given": "Carl"
      },
      {
        "family": "Klarkowski",
        "given": "Madison"
      },
      {
        "family": "Cockburn",
        "given": "Andy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Many interactive systems are susceptible to misinterpreting the user\u2019s input actions or gestures. Interpretation errors are common when systems gather a series of signals from the user and then attempt to interpret the user\u2019s intention based on those signals \u2013 e.g., gesture identification from a touchscreen, camera, or body-worn electrodes \u2013 and previous work has shown that interpretation error can cause significant problems for learning new input commands. Error-reduction strategies from telecommunications, such as repeating a command or increasing the length of the input while reducing its expressiveness, could improve these input mechanisms \u2013 but little is known about whether longer command sequences will cause problems for users (e.g., increased effort or reduced learning). We tested performance, learning, and perceived effort in a crowd-sourced study where participants learned and used input mechanisms with different error-reduction techniques. We found that error reduction techniques are feasible, can outperform error-prone ordinary input, and do not negatively affect learning or perceived effort.",
    "call-number": "10.1145/3491102.3502079",
    "collection-number": "291",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502079",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "input error, interpretation error, error correction, input expressiveness",
    "number": "Article 291",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "More Errors vs. Longer Commands: The Effects of Repetition and Reduced Expressiveness on Input Interpretation Error, Learning, and Effort",
    "URL": "https://doi.org/10.1145/3491102.3502079"
  },
  {
    "id": "10.1145/3491102.3517682",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Stemasov",
        "given": "Evgeny"
      },
      {
        "family": "Wagner",
        "given": "Tobias"
      },
      {
        "family": "Gugenheimer",
        "given": "Jan"
      },
      {
        "family": "Rukzio",
        "given": "Enrico"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Personal fabrication is made more accessible through repositories like Thingiverse, as they replace modeling with retrieval. However, they require users to translate spatial requirements to keywords, which paints an incomplete picture of physical artifacts: proportions or morphology are non-trivially encoded through text only. We explore a vision of in-situ spatial search for (future) physical artifacts, and present ShapeFindAR, a mixed-reality tool to search for 3D models using in-situ sketches blended with textual queries. With ShapeFindAR, users search for geometry, and not necessarily precise labels, while coupling the search process to the physical environment (e.g., by sketching in-situ, extracting search terms from objects present, or tracing them). We developed ShapeFindAR for HoloLens 2, connected to a database of 3D-printable artifacts. We specify in-situ spatial search, describe its advantages, and present walkthroughs using ShapeFindAR, which highlight novel ways for users to articulate their wishes, without requiring complex modeling tools or profound domain knowledge.",
    "call-number": "10.1145/3491102.3517682",
    "collection-number": "292",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517682",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "3D-Printing, Personal Fabrication, Spatial Search, In-Situ Search, Mixed Reality, Model Repositories, Physical Artifact Retrieval",
    "number": "Article 292",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ShapeFindAR: Exploring In-Situ Spatial Search for Physical Artifact Retrieval using Mixed Reality",
    "URL": "https://doi.org/10.1145/3491102.3517682"
  },
  {
    "id": "10.1145/3491102.3517632",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Johansen",
        "given": "Stine S"
      },
      {
        "family": "Merritt",
        "given": "Timothy"
      },
      {
        "family": "Jacobsen",
        "given": "Rune M\u00f8berg"
      },
      {
        "family": "Nielsen",
        "given": "Peter Axel"
      },
      {
        "family": "Kjeldskov",
        "given": "Jesper"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this paper, we investigate the use of shape-change for interaction with sound zones. A core challenge to designing interaction with sound zone systems is to support users\u2019 understanding of the unique spatial properties of sound zones. Shape-changing interfaces present new opportunities for addressing this. We present a structured investigation into this. We leveraged the knowledge of 12 sound experts to define a set of basic shapes and movements. Then, we constructed a prototype and conducted an elicitation study with 17 novice users, investigating the experience of these shapes and movements. Our findings show that physical visualizations of sound zones can be useful in supporting users\u2019 experience of sound zones. We present a framework of 4 basic pattern categories that prompt different sound zone experiences and outline further research directions for shape-change in supporting sound zone interaction.",
    "call-number": "10.1145/3491102.3517632",
    "collection-number": "293",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517632",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "shape-changing interfaces, soundscape, Sound zone",
    "number": "Article 293",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Potentials of Shape-Changing\u00a0Displays for Sound\u00a0Zones",
    "URL": "https://doi.org/10.1145/3491102.3517632"
  },
  {
    "id": "10.1145/3491102.3501938",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jacobsen",
        "given": "Rune M\u00f8berg"
      },
      {
        "family": "van Berkel",
        "given": "Niels"
      },
      {
        "family": "Skov",
        "given": "Mikael B."
      },
      {
        "family": "Johansen",
        "given": "Stine S"
      },
      {
        "family": "Kjeldskov",
        "given": "Jesper"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sound zone technology allows multiple simultaneous sound experiences for multiple people in the same room without interference. However, given the inherent invisible and intangible nature of sound zones, it is unclear how to communicate the position and size of sound zones to users. This paper compares two visualisation techniques; absolute visualisation, relational visualisation, as well as a baseline condition without visualisations. In a within-subject experiment (N\u00a0=\u00a033), we evaluated these techniques for effectiveness and efficiency across four representative tasks. Our findings show that the absolute and relational visualisation techniques increase effectiveness in multi-user tasks but not in single-user tasks. The efficiency for all tasks was improved using visualisations. We discuss the potential of visualisations for sound zones and highlight future research opportunities for sound zone interaction.",
    "call-number": "10.1145/3491102.3501938",
    "collection-number": "294",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501938",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "visualisation, ubiquitous computing, sound visualisation, sound interaction, Sound zones",
    "number": "Article 294",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Do You See What I Hear? \u2014 Peripheral Absolute and Relational Visualisation Techniques for Sound Zones",
    "URL": "https://doi.org/10.1145/3491102.3501938"
  },
  {
    "id": "10.1145/3491102.3502140",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rixen",
        "given": "Jan Ole"
      },
      {
        "family": "Colley",
        "given": "Mark"
      },
      {
        "family": "Askari",
        "given": "Ali"
      },
      {
        "family": "Gugenheimer",
        "given": "Jan"
      },
      {
        "family": "Rukzio",
        "given": "Enrico"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Social Media (SM) has shown that we adapt our communication and disclosure behaviors to available technological opportunities. Head-mounted Augmented Reality (AR) will soon allow to effortlessly display the information we disclosed not isolated from our physical presence (e.g., on a smartphone) but visually attached to the human body. In this work, we explore how the medium (AR vs. Smartphone), our role (being augmented vs. augmenting), and characteristics of information types (e.g., level of intimacy, self-disclosed vs. non-self-disclosed) impact the users\u2019 comfort when displaying personal information. Conducting an online survey (N=148), we found that AR technology and being augmented negatively impacted this comfort. Additionally, we report that AR mitigated the effects of information characteristics compared to those they had on smartphones. In light of our results, we discuss that information augmentation should be built on consent and openness, focusing more on the comfort of the augmented rather than the technological possibilities.",
    "call-number": "10.1145/3491102.3502140",
    "collection-number": "295",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502140",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Mixed Reality, Consent, Data Glasses, Personal Information, Augmented Reality, Public Experiences, Comfort, Social Acceptability, User Acceptance, Disclosure",
    "number": "Article 295",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Consent in the Age of AR: Investigating The Comfort With Displaying Personal Information in Augmented Reality",
    "URL": "https://doi.org/10.1145/3491102.3502140"
  },
  {
    "id": "10.1145/3491102.3517575",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yadav",
        "given": "Deepika"
      },
      {
        "family": "Dabas",
        "given": "Kirti"
      },
      {
        "family": "Malik",
        "given": "Prerna"
      },
      {
        "family": "Bhandari",
        "given": "Anushka"
      },
      {
        "family": "Singh",
        "given": "Pushpendra"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Limited interaction with professionals, infrastructural, and social constraints put barriers in providing holistic support to expectant and new mothers in low-resource settings. We examine the use of digital support groups facilitated through WhatsApp by a non-government organization in India. Complementing prior research, these digital peer support groups inform about an open public space created over a chat platform where rural communities and health professionals can engage. By qualitatively analyzing six months of interaction among 588 group members and collecting the experiences of the group moderators, we inform about how the support groups acted as an important source for compensating the gaps in the existing healthcare, providing reassurance support on routine health, explanation on test reports, validation and counseling support in ongoing treatments. We also derive implications for the future of digital support groups and the need for further research on the use of unplatformed design models in resource-constrained settings.",
    "call-number": "10.1145/3491102.3517575",
    "collection-number": "296",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517575",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Social support, Maternal health, WhatsApp, Digital support group",
    "number": "Article 296",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cShould I visit the clinic\u201d: Analyzing WhatsApp-mediated Online Health Support for Expectant and New Mothers in Rural India",
    "URL": "https://doi.org/10.1145/3491102.3517575"
  },
  {
    "id": "10.1145/3491102.3517634",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tang",
        "given": "Ningjing"
      },
      {
        "family": "Tao",
        "given": "Lei"
      },
      {
        "family": "Wen",
        "given": "Bo"
      },
      {
        "family": "Lu",
        "given": "Zhicong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "China has witnessed rapid growth in its e-commerce markets and livestreaming communities in recent years. The commercialization of livestreaming has led to the rise of e-commerce livestreamers, among which rural women constitute a substantial portion. To understand the motivations underlying these women's choices to engage in livestreaming activities and probe the extent to which they are empowered by this new form of entrepreneurship, we conducted an interview-based study with rural female livestreamers. We found that these women chose to be livestreamers for practical and self-presentation purposes and they gained a sense of self-empowerment through economic, social, intellectual, psychological, and spiritual dimensions. At the same time, however, they experienced and confronted social stigmas rooted in rural societies and the strategies they used to deal with these biases were vastly different. Our work contributes to the HCI community by providing a nuanced understanding of the motives and lived experiences of rural female livestreamers and offers design implications that could improve the everyday experiences of these livestreamers.",
    "call-number": "10.1145/3491102.3517634",
    "collection-number": "297",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517634",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "empowerment, livestreaming, rural computing, feminism",
    "number": "Article 297",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Dare to Dream, Dare to Livestream: How E-Commerce Livestreaming Empowers Chinese Rural Women",
    "URL": "https://doi.org/10.1145/3491102.3517634"
  },
  {
    "id": "10.1145/3491102.3501834",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Varanasi",
        "given": "Rama Adithya"
      },
      {
        "family": "Siddarth",
        "given": "Divya"
      },
      {
        "family": "Seshadri",
        "given": "Vivek"
      },
      {
        "family": "Bali",
        "given": "Kalika"
      },
      {
        "family": "Vashistha",
        "given": "Aditya"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Women\u2019s economic empowerment is central to gender equality. However, work opportunities available to low-income women in patriarchal societies are infrequent. While crowd work has the potential to increase labor participation of such women, much remains unknown about their engagement with crowd work and the resultant opportunities and tensions. To fill this gap, we critically examined the adoption and use of a crowd work platform by low-income women in India. Through a qualitative study, we found that women faced tremendous challenges, for example, in seeking permission from family members to do crowd work, lack of family support and encouragement, and often working in unfavorable environments where they had to hide their work lives. While crowd work took a toll on their physical and emotional wellbeing, it also led to increased confidence, agency, and autonomy. We discuss ways to reduce frictions and tensions in participation of low-income women on crowd work platforms.",
    "call-number": "10.1145/3491102.3501834",
    "collection-number": "298",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501834",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "HCI4D, Women, crowdsourcing work, mobile crowdsourcing, crowd work, crowdsourcing app",
    "number": "Article 298",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Feeling Proud, Feeling Embarrassed: Experiences of Low-income Women with Crowd Work",
    "URL": "https://doi.org/10.1145/3491102.3501834"
  },
  {
    "id": "10.1145/3491102.3517628",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cai",
        "given": "Jie"
      },
      {
        "family": "Wohn",
        "given": "Donghee Yvette"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Volunteer moderators (mods) play significant roles in developing moderation standards and dealing with harmful content in their micro-communities. However, little work explores how volunteer mods work as a team. In line with prior work about understanding volunteer moderation, we interview 40 volunteer mods on Twitch \u2014 a leading live streaming platform. We identify how mods collaborate on tasks (off-streaming coordination and preparation, in-stream real-time collaboration, and relationship building both off-stream and in-stream to reinforce collaboration) and how mods contribute to moderation standards (collaboratively working on the community rulebook and individually shaping community norms). We uncover how volunteer mods work as an effective team. We also discuss how the affordances of multi-modal communication and informality of volunteer moderation contribute to task collaboration, standards development, and mod\u2019s roles and responsibilities.",
    "call-number": "10.1145/3491102.3517628",
    "collection-number": "300",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517628",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Teamwork, live streaming, online community, collaboration, rules and norms, content moderation, volunteer mods, coordination",
    "number": "Article 300",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Coordination and Collaboration: How do Volunteer Moderators Work as a Team in Live Streaming Communities?",
    "URL": "https://doi.org/10.1145/3491102.3517628"
  },
  {
    "id": "10.1145/3491102.3517495",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Moge",
        "given": "Clara"
      },
      {
        "family": "Wang",
        "given": "Katherine"
      },
      {
        "family": "Cho",
        "given": "Youngjun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As an emerging interaction paradigm, physiological computing is increasingly being used to both measure and feed back information about our internal psychophysiological states. While most applications of physiological computing are designed for individual use, recent research has explored how biofeedback can be socially shared between multiple users to augment human-human communication. Reflecting on the empirical progress in this area of study, this paper presents a systematic review of 64 studies to characterize the interaction contexts and effects of social biofeedback systems. Our findings highlight the importance of physio-temporal and social contextual factors surrounding physiological data sharing as well as how it can promote social-emotional competences on three different levels: intrapersonal, interpersonal, and task-focused. We also present the Social Biofeedback Interactions framework to articulate the current physiological-social interaction space. We use this to frame our discussion of the implications and ethical considerations for future research and design of social biofeedback interfaces.",
    "call-number": "10.1145/3491102.3517495",
    "collection-number": "301",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517495",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "physiological data sharing, Physiological computing, systematic review, computer-mediated communication, emotion communication, social biofeedback",
    "number": "Article 301",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Shared User Interfaces of Physiological Data: Systematic Review of Social Biofeedback Systems and Contexts in HCI",
    "URL": "https://doi.org/10.1145/3491102.3517495"
  },
  {
    "id": "10.1145/3491102.3517470",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kang",
        "given": "Hyeonsu B"
      },
      {
        "family": "Kocielnik",
        "given": "Rafal"
      },
      {
        "family": "Head",
        "given": "Andrew"
      },
      {
        "family": "Yang",
        "given": "Jiangjiang"
      },
      {
        "family": "Latzke",
        "given": "Matt"
      },
      {
        "family": "Kittur",
        "given": "Aniket"
      },
      {
        "family": "Weld",
        "given": "Daniel S"
      },
      {
        "family": "Downey",
        "given": "Doug"
      },
      {
        "family": "Bragg",
        "given": "Jonathan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The ever-increasing pace of scientific publication necessitates methods for quickly identifying relevant papers. While neural recommenders trained on user interests can help, they still result in long, monotonous lists of suggested papers. To improve the discovery experience we introduce multiple new methods for augmenting recommendations with textual relevance messages that highlight knowledge-graph connections between recommended papers and a user\u2019s publication and interaction history. We explore associations mediated by author entities and those using citations alone. In a large-scale, real-world study, we show how our approach significantly increases engagement\u2014and future engagement when mediated by authors\u2014without introducing bias towards highly-cited authors. To expand message coverage for users with less publication or interaction history, we develop a novel method that highlights connections with proxy authors of interest to users and evaluate it in a controlled lab study. Finally, we synthesize design implications for future graph-based messages.",
    "call-number": "10.1145/3491102.3517470",
    "collection-number": "302",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517470",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 302",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "From Who You Know to What You Read: Augmenting Scientific Recommendations with Implicit Social Networks",
    "URL": "https://doi.org/10.1145/3491102.3517470"
  },
  {
    "id": "10.1145/3491102.3517516",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hergueux",
        "given": "J\u00e9r\u00f4me"
      },
      {
        "family": "Kessler",
        "given": "Samuel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We conduct the first comprehensive study of the behavioral factors which predict leader emergence within open source software (OSS) virtual teams. We leverage the full history of developers\u2019 interactions with their teammates and projects at github.com between January 2010 and April 2017 (representing about 133 million interactions) to establish that \u2013 contrary to a common narrative describing open source as a pure \u201ctechnical meritocracy\u201d \u2013 developers\u2019 communication abilities and community building skills are significant predictors of whether they emerge as team leaders. Inspirational communication therefore appears as central to the process of leader emergence in virtual teams, even in a setting like OSS, where technical contributions have often been conceptualized as the sole pathway to gaining community recognition. Those results should be of interest to researchers and practitioners theorizing about OSS in particular and, more generally, leadership in geographically dispersed virtual teams, as well as to online community managers.",
    "call-number": "10.1145/3491102.3517516",
    "collection-number": "303",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517516",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Communication, Leadership, Open Source Software, Virtual Teams",
    "number": "Article 303",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Follow the Leader: Technical and Inspirational Leadership in Open Source Software",
    "URL": "https://doi.org/10.1145/3491102.3517516"
  },
  {
    "id": "10.1145/3491102.3502005",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ding",
        "given": "Zijian"
      },
      {
        "family": "Kang",
        "given": "Jiawen"
      },
      {
        "family": "HO",
        "given": "Tinky Oi Ting"
      },
      {
        "family": "Wong",
        "given": "Ka Ho"
      },
      {
        "family": "Fung",
        "given": "Helene H"
      },
      {
        "family": "Meng",
        "given": "Helen"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Conversational agents (CAs) have the great potential in mitigating the clinicians\u2019 burden in screening for neurocognitive disorders among older adults. It is important, therefore, to develop CAs that can be engaging, to elicit conversational speech input from older adult participants for supporting assessment of cognitive abilities. As an initial step, this paper presents research in developing the backchanneling ability in CAs in the form of a verbal response to engage the speaker. We analyzed 246 conversations of cognitive assessments between older adults and human assessors, and derived the categories of reactive backchannels (e.g. \u201chmm\u201d) and proactive backchannels (e.g. \u201cplease keep going\u201d). This is used in the development of TalkTive, a CA which can predict both timing and form of backchanneling during cognitive assessments. The study then invited 36 older adult participants to evaluate the backchanneling feature. Results show that proactive backchanneling is more appreciated by participants than reactive backchanneling.",
    "call-number": "10.1145/3491102.3502005",
    "collection-number": "304",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502005",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Older Adults, Backchanneling, Conversational Agents",
    "number": "Article 304",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TalkTive: A Conversational Agent Using Backchannels to Engage Older Adults in Neurocognitive Disorders Screening",
    "URL": "https://doi.org/10.1145/3491102.3502005"
  },
  {
    "id": "10.1145/3491102.3502020",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jain",
        "given": "Dhruv"
      },
      {
        "family": "Huynh Anh Nguyen",
        "given": "Khoa"
      },
      {
        "family": "M. Goodman",
        "given": "Steven"
      },
      {
        "family": "Grossman-Kahn",
        "given": "Rachel"
      },
      {
        "family": "Ngo",
        "given": "Hung"
      },
      {
        "family": "Kusupati",
        "given": "Aditya"
      },
      {
        "family": "Du",
        "given": "Ruofei"
      },
      {
        "family": "Olwal",
        "given": "Alex"
      },
      {
        "family": "Findlater",
        "given": "Leah"
      },
      {
        "family": "E. Froehlich",
        "given": "Jon"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent advances have enabled automatic sound recognition systems for deaf and hard of hearing (DHH) users on mobile devices. However, these tools use pre-trained, generic sound recognition models, which do not meet the diverse needs of DHH users. We introduce ProtoSound, an interactive system for customizing sound recognition models by recording a few examples, thereby enabling personalized and fine-grained categories. ProtoSound is motivated by prior work examining sound awareness needs of DHH people and by a survey we conducted with 472 DHH participants. To evaluate ProtoSound, we characterized performance on two real-world sound datasets, showing significant improvement over state-of-the-art (e.g., +9.7% accuracy on the first dataset). We then deployed ProtoSound's end-user training and real-time recognition through a mobile application and recruited 19 hearing participants who listened to the real-world sounds and rated the accuracy across 56 locations (e.g., homes, restaurants, parks). Results show that ProtoSound personalized the model on-device in real-time and accurately learned sounds across diverse acoustic contexts. We close by discussing open challenges in personalizable sound recognition, including the need for better recording interfaces and algorithmic improvements.",
    "call-number": "10.1145/3491102.3502020",
    "collection-number": "305",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502020",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Deaf, sound recognition, Accessibility, hard of hearing, sound awareness, deaf",
    "number": "Article 305",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ProtoSound: A Personalized and Scalable Sound Recognition System for Deaf and Hard-of-Hearing Users",
    "URL": "https://doi.org/10.1145/3491102.3502020"
  },
  {
    "id": "10.1145/3491102.3501987",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Glasser",
        "given": "Abraham"
      },
      {
        "family": "Watkins",
        "given": "Matthew"
      },
      {
        "family": "Hart",
        "given": "Kira"
      },
      {
        "family": "Lee",
        "given": "Sooyeon"
      },
      {
        "family": "Huenerfauth",
        "given": "Matt"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As voice-based personal assistant technologies proliferate, e.g., smart speakers in homes, and more generally as voice-control of technology becomes increasingly ubiquitous, new accessibility barriers are emerging for many Deaf and Hard of Hearing (DHH) users. Progress in sign-language recognition may enable devices to respond to sign-language commands and potentially mitigate these barriers, but research is needed to understand how DHH users would interact with these devices and what commands they would issue. In this work, we directly engage with the DHH community, using a Wizard-of-Oz prototype that appears to understand American Sign Language (ASL) commands. Our analysis of video recordings of DHH participants revealed how they woke-up the device to initiate commands, structured commands in ASL, and responded to device errors, providing guidance to future designers and researchers. We share our dataset of over 1400 commands, which may be of interest to sign-language-recognition researchers.",
    "call-number": "10.1145/3491102.3501987",
    "collection-number": "306",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501987",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Accessibility, Sign Language, Deaf and Hard of Hearing, Personal Assistants",
    "number": "Article 306",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Analyzing Deaf and Hard-of-Hearing Users\u2019 Behavior, Usage, and Interaction with a Personal Assistant Device that Understands Sign-Language Input",
    "URL": "https://doi.org/10.1145/3491102.3501987"
  },
  {
    "id": "10.1145/3491102.3517525",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hu",
        "given": "Yaxin"
      },
      {
        "family": "Qu",
        "given": "Yuxiao"
      },
      {
        "family": "Maus",
        "given": "Adam"
      },
      {
        "family": "Mutlu",
        "given": "Bilge"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Conversational interfaces increasingly rely on human-like dialogue to offer a natural experience. However, relying on dialogue involving multiple exchanges for even simple tasks can overburden users, particularly older adults. In this paper, we explored the use of politeness theory in conversation design to alleviate this burden and improve user experience. To achieve this goal, we categorized the voice interaction offered by a smart display application designed for older adults into seven major speech acts: request, suggest, instruct, comment, welcome, farewell, and repair. We identified face needs for each speech act, applied politeness strategies that best address these needs, and tested the ability of these strategies to shape the perceived politeness of a voice assistant in an online study (n = 64). Based on the findings of this study, we designed direct and polite versions of the system and conducted a field study (n = 15) in which participants used each of the versions for five days at their homes. Based on five factors merged from our qualitative findings, we identified four distinctive user personas\u2014socially oriented follower, socially oriented leader, utility oriented follower, and utility oriented leader\u2014that can inform personalized design of smart displays.",
    "call-number": "10.1145/3491102.3517525",
    "collection-number": "307",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517525",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "older adults, smart displays, Conversation design, politeness theory, multimodal interaction",
    "number": "Article 307",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Polite or Direct? Conversation Design of a Smart Display for Older Adults Based on Politeness Theory",
    "URL": "https://doi.org/10.1145/3491102.3517525"
  },
  {
    "id": "10.1145/3491102.3501854",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Kevin Gonyop"
      },
      {
        "family": "Davis",
        "given": "Richard Lee"
      },
      {
        "family": "Coppi",
        "given": "Alessia Eletta"
      },
      {
        "family": "Cattaneo",
        "given": "Alberto"
      },
      {
        "family": "Dillenbourg",
        "given": "Pierre"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The ability to consider a wide range of solutions to a design problem is a crucial skill for designers, and is a major differentiator between experts and novices. One reason for this is that novices are unaware of the full extent of the design space in which solutions are situated. To support novice designers with design space exploration, we introduce Mixplorer, a system that allows designers to take an initial design and mix it with other designs. Mixplorer differs from existing tools by supporting the exploration of ill-defined design spaces through social design space exploration. To evaluate Mixplorer, we conducted (1) an interview study with design instructors who reported that Mixplorer would \u201chelp to open the minds\u201d of novice designers and (2) a controlled experiment with novices, finding that the design-mixing functionality of Mixplorer provided significantly better support for creativity, and that participants who mixed designs produced more novel designs.",
    "call-number": "10.1145/3491102.3501854",
    "collection-number": "308",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501854",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design exploration, creativity support, design support system",
    "number": "Article 308",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mixplorer: Scaffolding Design Space Exploration through Genetic Recombination of Multiple Peoples\u2019 Designs to Support Novices\u2019 Creativity",
    "URL": "https://doi.org/10.1145/3491102.3501854"
  },
  {
    "id": "10.1145/3491102.3501905",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Portenoy",
        "given": "Jason"
      },
      {
        "family": "Radensky",
        "given": "Marissa"
      },
      {
        "family": "West",
        "given": "Jevin D"
      },
      {
        "family": "Horvitz",
        "given": "Eric"
      },
      {
        "family": "Weld",
        "given": "Daniel S"
      },
      {
        "family": "Hope",
        "given": "Tom"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Isolated silos of scientific research and the growing challenge of information overload limit awareness across the literature and hinder innovation. Algorithmic curation and recommendation, which often prioritize relevance, can further reinforce these informational \u201cfilter bubbles.\u201d In response, we describe Bridger, a system for facilitating discovery of scholars and their work. We construct a faceted representation of authors with information gleaned from their papers and inferred author personas, and use it to develop an approach that locates commonalities and contrasts between scientists to balance relevance and novelty. In studies with computer science researchers, this approach helps users discover authors considered useful for generating novel research directions. We also demonstrate an approach for displaying information about authors, boosting the ability to understand the work of new, unfamiliar scholars. Our analysis reveals that Bridger connects authors who have different citation profiles and publish in different venues, raising the prospect of bridging diverse scientific communities.",
    "call-number": "10.1145/3491102.3501905",
    "collection-number": "309",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501905",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "author discovery, filter bubbles, scholarly recommendation",
    "number": "Article 309",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Bursting Scientific Filter Bubbles: Boosting Innovation via Novel Author Discovery",
    "URL": "https://doi.org/10.1145/3491102.3501905"
  },
  {
    "id": "10.1145/3491102.3517714",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Krau\u00df",
        "given": "Veronika"
      },
      {
        "family": "Nebeling",
        "given": "Michael"
      },
      {
        "family": "Jasche",
        "given": "Florian"
      },
      {
        "family": "Boden",
        "given": "Alexander"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Current research in augmented, virtual, and mixed reality (XR) reveals a lack of tool support for designing and, in particular, prototyping XR applications. While recent tools research is often motivated by studying the requirements of non-technical designers and end-user developers, the perspective of industry practitioners is less well understood. In an interview study with 17 practitioners from different industry sectors working on professional XR projects, we establish the design practices in industry, from early project stages to the final product. To better understand XR design challenges, we characterize the different methods and tools used for prototyping and describe the role and use of key prototypes in the different projects. We extract common elements of XR prototyping, elaborating on the tools and materials used for prototyping and establishing different views on the notion of fidelity. Finally, we highlight key issues for future XR tools research.",
    "call-number": "10.1145/3491102.3517714",
    "collection-number": "310",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517714",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "XR, prototyping, mixed reality, interface design., virtual reality, interaction design, authoring, augmented reality",
    "number": "Article 310",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Elements of XR Prototyping: Characterizing the Role and Use of Prototypes in Augmented and Virtual Reality Design",
    "URL": "https://doi.org/10.1145/3491102.3517714"
  },
  {
    "id": "10.1145/3491102.3501914",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Chao"
      },
      {
        "family": "Yao",
        "given": "Cheng"
      },
      {
        "family": "Wu",
        "given": "Jiayi"
      },
      {
        "family": "Lin",
        "given": "Weijia"
      },
      {
        "family": "Liu",
        "given": "Lijuan"
      },
      {
        "family": "Yan",
        "given": "Ge"
      },
      {
        "family": "Ying",
        "given": "Fangtian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Visual storytelling is a new approach to creative expression based on verbal and figural creativity. The keys to visual storytelling are narrating and drawing over a period of time, which can be beneficial but also demanding on creativity for children. Informed by need-finding investigations, we developed StoryDrawer, a co-creative system that supports visual storytelling for children aged 6\u201310 years through collaborative drawing between children and artificial intelligence (AI). The system includes a context-based voice agent and two AI-driven collaborative strategies: the real-time transformation of children's telling into drawings, and the generation of abstract sketches with semantic similarity to existing story content. We conducted a 2 \u00d7 2 study with 64 children to evaluate the efficacy of StoryDrawer by varying the two strategies in four conditions. The results suggest that StoryDrawer provoked participants\u2019 creative and elaborate ideas and contributed to their creative outcomes during an engaging visual storytelling experience.",
    "call-number": "10.1145/3491102.3501914",
    "collection-number": "311",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501914",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Creativity support tool, Child\u2013AI collaboration, Children, Drawing, Visual storytelling, Co-creative system",
    "number": "Article 311",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "StoryDrawer: A Child\u2013AI Collaborative Drawing System to Support Children's Creative Visual Storytelling",
    "URL": "https://doi.org/10.1145/3491102.3501914"
  },
  {
    "id": "10.1145/3491102.3502120",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ibrahim",
        "given": "Seray"
      },
      {
        "family": "Vasalou",
        "given": "Asimina"
      },
      {
        "family": "Benton",
        "given": "Laura"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "School-driven technological innovation has the potential to positively impact on classroom practice, yet it can also be disrupted by incompatibilities between the existing school ecology and new educational technologies. To help mitigate this disruption a particular staff member often takes on a facilitative leadership role to champion new technology initiatives. However little is known about how this technology leader role impacts on the adoption of new technologies in the classroom. Taking a situated lens, we embarked on a multiple case study of four schools who were aiming to adopt a new literacy game in the classroom. Through interviews with technology leaders and fieldnotes from our site observations, we systematically analysed their actions and concerns over two academic terms. This highlighted an overwhelming concern with managing the material dimension of the technology, teacher agency and division of labour and mechanisms for communication and monitoring. Our findings raise important considerations for HCI researchers seeking to embed their technologies into practice alongside recommendations for supporting leaders tasked with coordinating this process.",
    "call-number": "10.1145/3491102.3502120",
    "collection-number": "312",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502120",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Adoption, Technology Leader, Situated Practice, Educational Technology",
    "number": "Article 312",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding the Situated Practices of School Technology Leaders in the Early Stages of Educational Technology Adoption",
    "URL": "https://doi.org/10.1145/3491102.3502120"
  },
  {
    "id": "10.1145/3491102.3517482",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ma",
        "given": "Shuai"
      },
      {
        "family": "Zhou",
        "given": "Taichang"
      },
      {
        "family": "Nie",
        "given": "Fei"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Synchronous online learning has become a trend in recent years. However, instructors often face the challenge of inferring audiences\u2019 reactions and learning status without seeing their faces in video feeds, which prevents instructors from establishing connections with students. To solve this problem, based on a need-finding survey with 67 college instructors, we propose Glancee, a real-time interactive system with adaptable configurations, sidebar-based visual displays, and comprehensive learning status detection algorithms. Then, we conduct a within-subject user study in which 18 college instructors deliver lectures online with Glancee and two baselines, EngageClass and ZoomOnly. Results show that Glancee can effectively support online teaching and is perceived to be significantly more helpful than the baselines. We further investigate how instructors\u2019 emotions, behaviors, attention, cognitive load, and trust are affected during the class. Finally, we offer design recommendations for future online teaching assistant systems.",
    "call-number": "10.1145/3491102.3517482",
    "collection-number": "313",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517482",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Affective Computing, Videoconferencing, Human-centered Design, Online Class, E-Learning",
    "number": "Article 313",
    "number-of-pages": "25",
    "page": "1\u201325",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Glancee: An Adaptable System for Instructors to Grasp Student Learning Status in Synchronous Online Classes",
    "URL": "https://doi.org/10.1145/3491102.3517482"
  },
  {
    "id": "10.1145/3491102.3517693",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Biehl",
        "given": "Jacob T."
      },
      {
        "family": "Farzan",
        "given": "Rosta"
      },
      {
        "family": "Zhou",
        "given": "Yingfan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The COVID-19 global pandemic has ignited lightning-fast adoption of digital tools in our communities, organizations, and systems of governance. It also inspired an unprecedented level of providing access to digital devices to communities and individuals lacking prior access. The situation and circumstances provide a unique opportunity to understand digital divides through a new lens. In this work, we contribute a contemporaneous understanding of digital divides beyond access by qualitatively analyzing over 300 calls made to a volunteer-based community IT help desk. We highlight the intertwined network of challenges leading to ecosystem digital divides and contribute new insights into how the complex socio-technical systems of practice, and the tools to support them, must adapt to bridge digital divides more effectively.",
    "call-number": "10.1145/3491102.3517693",
    "collection-number": "314",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517693",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "pandemic response, digital divides, ICT use",
    "number": "Article 314",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Can Anybody Help Me?: Using Community Help Desk Call Records to Examine the Impact of Digital Divides During a Global Pandemic",
    "URL": "https://doi.org/10.1145/3491102.3517693"
  },
  {
    "id": "10.1145/3491102.3502126",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wani",
        "given": "Asra Sakeen"
      },
      {
        "family": "Singh",
        "given": "Divyanshu Kumar"
      },
      {
        "family": "Singh",
        "given": "Pushpendra"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sustainable Development Goal 4 promotes inclusive and equitable quality education and lifelong learning opportunities for all. However, regions with ongoing socio-political conflict suffer disruption to education and learning. We situate our work in Kashmir, India, affected by socio-political conflict for more than three decades. We did multiple field visits and conducted 21 semi-structured interviews with parents, teachers, students, and members of a non-government organization that runs Community Learning Centers in Kashmir. Our findings present the barriers in education caused by disruption and the role of community learning centers in overcoming the barriers within these contextual constraints. Further, we discuss engaging researchers and policymakers to leverage human infrastructure, embedding uncertainty into the design, infrastructuring trust, and content usability to develop solutions to make education more accessible. Despite significant research in HCI and Education, research in this particular context is under-explored, and our work contributes to filling this gap.",
    "call-number": "10.1145/3491102.3502126",
    "collection-number": "315",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502126",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Education, Disruption, Trust and Uncertainty, Culture, Conflict, Technology, Kashmir, Internet shutdown, India.",
    "number": "Article 315",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cHartal (Strike) Happens Here Everyday\u201d: Understanding Impact of Disruption on Education in Kashmir",
    "URL": "https://doi.org/10.1145/3491102.3502126"
  },
  {
    "id": "10.1145/3491102.3502086",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Vacca",
        "given": "Ralph"
      },
      {
        "family": "DesPortes",
        "given": "Kayla"
      },
      {
        "family": "Tes",
        "given": "Marian"
      },
      {
        "family": "Silander",
        "given": "Megan"
      },
      {
        "family": "Matuk",
        "given": "Camillia"
      },
      {
        "family": "Amato",
        "given": "Anna"
      },
      {
        "family": "Woods",
        "given": "Peter J."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Effective data literacy instruction requires that learners move beyond understanding statistics to being able to humanize data through a contextual understanding of argumentation and reasoning in the real-world. In this paper, we explore the implementation of a co-designed data comic unit about adolescent friendships. The 7th grade unit involved students analyzing data graphs about adolescent friendships and crafting comic narratives to convey perspectives on that data. Findings from our analysis of 33 student comics, and interviews with two teachers and four students, show that students engaged in various forms of data reasoning and social-emotional reasoning. These findings contribute an understanding of how students make sense of data about personal, everyday experiences; and how an arts-integrated curriculum can be designed to support their mutual engagement in both data and social-emotional reasoning.",
    "call-number": "10.1145/3491102.3502086",
    "collection-number": "316",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502086",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "data comics, data literacy, data reasoning, math education, social-emotional learning, arts education",
    "number": "Article 316",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dI happen to be one of 47.8%\u201d: Social-Emotional and Data Reasoning in Middle School Students\u2019 Comics about Friendship",
    "URL": "https://doi.org/10.1145/3491102.3502086"
  },
  {
    "id": "10.1145/3491102.3502207",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sundar",
        "given": "S. Shyam"
      },
      {
        "family": "Jia",
        "given": "Haiyan"
      },
      {
        "family": "Bellur",
        "given": "Saraswathi"
      },
      {
        "family": "Oh",
        "given": "Jeeyun"
      },
      {
        "family": "Kim",
        "given": "Hyang-Sook"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper introduces the concept of \u201cnews informatics\u201d to refer to journalistic presentation of big data in online sites. For users to be engaged with such data-driven public information, it is important to incorporate interactive tools so that each person can extract personally relevant information. Drawing upon a communication model of interactivity, we designed a data-rich site with three different types of interactive features\u2014namely, modality interactivity, message interactivity, and source interactivity\u2014and empirically tested their relative and combined effects on user engagement and user experience with a 2 (modality) \u00d7 3 (source) \u00d7 2 (message) field experiment (N =166). Findings shed light on how interface designers, online news editors and journalists can maximize user engagement with data-rich news content. Certain interactivity combinations are found to be better than others, with a structural equation model (SEM) revealing the underlying theoretical mechanisms and providing implications for the design of news informatics.",
    "call-number": "10.1145/3491102.3502207",
    "collection-number": "317",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502207",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "News Informatics, Website Interactivity, User Engagement",
    "number": "Article 317",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "News Informatics: Engaging Individuals with Data-Rich News Content through Interactivity in Source, Medium, and Message",
    "URL": "https://doi.org/10.1145/3491102.3502207"
  },
  {
    "id": "10.1145/3491102.3517647",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kuang",
        "given": "Emily"
      },
      {
        "family": "Jin",
        "given": "Xiaofu"
      },
      {
        "family": "Fan",
        "given": "Mingming"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Analysis is a key part of usability testing where UX practitioners seek to identify usability problems and generate redesign suggestions. Although previous research reported how analysis was conducted, the findings were typically focused on individual analysis or based on a small number of professionals in specific geographic regions. We conducted an online international survey of 279 UX practitioners on their practices and challenges while collaborating during data analysis. We found that UX practitioners were often under time pressure to conduct analysis and adopted three modes of collaboration: independently analyze different portions of the data and then collaborate, collaboratively analyze the session with little or no independent analysis, and independently analyze the same set of data and then collaborate. Moreover, most encountered challenges related to lack of resources, disagreements with colleagues regarding usability problems, and difficulty merging analysis from multiple practitioners. We discuss design implications to better support collaborative data analysis.",
    "call-number": "10.1145/3491102.3517647",
    "collection-number": "318",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517647",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "UX, User experience, Collaboration, Survey, Data analysis, Usability testing",
    "number": "Article 318",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cMerging Results Is No Easy Task\u201d: An International Survey Study of Collaborative Data Analysis Practices Among UX Practitioners",
    "URL": "https://doi.org/10.1145/3491102.3517647"
  },
  {
    "id": "10.1145/3491102.3517788",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ahmed",
        "given": "Shameem"
      },
      {
        "family": "Monsur Hossain",
        "given": "Md"
      },
      {
        "family": "Pragner",
        "given": "Cody"
      },
      {
        "family": "Kimball",
        "given": "Mitch"
      },
      {
        "family": "Shrivastava",
        "given": "Ashima"
      },
      {
        "family": "Gildner",
        "given": "Joseph"
      },
      {
        "family": "McCulloch",
        "given": "Sean"
      },
      {
        "family": "Sharmin",
        "given": "Moushumi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "For many students, attending college is a dramatic but necessary change. To gain a better understanding of experiences that are unique to autistic college students, we conducted a mixed-method study with 20 students (10 autistic and 10 neurotypical). We collected physiological, contextual, experience, and environmental data from their natural environment using Fitbit and smartphones. We found that stress patterns, emotional states, and physical states are similar for both groups. Our autistic participants prioritized academic success over everything else, often intentionally confining their movements among academic, resident, and work locations to engage themselves with academic work as much as possible. They had a small number of friends, always preferring quality over quantity and sometimes regarding friends as close as family members. To maintain a better social life, they extensively used social media. They slept more than neurotypical participants per day; however, they experienced lower sleep quality.",
    "call-number": "10.1145/3491102.3517788",
    "collection-number": "320",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517788",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 320",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Constrained Life in a Multifarious Environment - A Closer Look at the Lives of Autistic College Students",
    "URL": "https://doi.org/10.1145/3491102.3517788"
  },
  {
    "id": "10.1145/3491102.3517684",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Haas",
        "given": "Gabriel"
      },
      {
        "family": "Rietzler",
        "given": "Michael"
      },
      {
        "family": "Jones",
        "given": "Matt"
      },
      {
        "family": "Rukzio",
        "given": "Enrico"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Voice assistants (VAs) are present in homes, smartphones, and cars. They allow users to perform tasks without graphical or tactile user interfaces, as they are designed for natural language interaction. However, we found that currently, VAs are emulating human behavior by responding in complete sentences, limiting the design options, and preventing VAs from meeting their full potential as a utilitarian tool. We implemented a VA that handles requests in three response styles: two differing short keyword-based response styles and a full-sentence baseline. In a user study, 72 participants interacted with our VA by issuing eight requests. Results show that the short responses were perceived similarly useful and likable while being perceived as more efficient, especially for commands, and sometimes better to comprehend than the baseline. To achieve widespread adoption, we argue that VAs should be customizable and adapt to users instead of always responding in full sentences.",
    "call-number": "10.1145/3491102.3517684",
    "collection-number": "321",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517684",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "voice assistant, virtual assistant, voice user interface",
    "number": "Article 321",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Keep it Short: A Comparison of Voice Assistants\u2019 Response Behavior",
    "URL": "https://doi.org/10.1145/3491102.3517684"
  },
  {
    "id": "10.1145/3491102.3501868",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Thakkar",
        "given": "Divy"
      },
      {
        "family": "Ismail",
        "given": "Azra"
      },
      {
        "family": "Kumar",
        "given": "Pratyush"
      },
      {
        "family": "Hanna",
        "given": "Alex"
      },
      {
        "family": "Sambasivan",
        "given": "Nithya"
      },
      {
        "family": "Kumar",
        "given": "Neha"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data-driven approaches that form the foundation of advancements in machine learning (ML) are powered in large part by human infrastructures that enable the collection of large datasets. We study the movement of data through multiple stages of data processing in the context of public health in India, examining the data work performed by frontline health workers, data stewards, and ML developers. We conducted interviews with these stakeholders to understand their varied perspectives on valuing data across stages, working with data to attain this value, and challenges arising throughout. We discuss the tensions in valuing and how they might be addressed, as we emphasize the need for improved transparency and accountability when data are transformed from one stage of processing to the next.",
    "call-number": "10.1145/3491102.3501868",
    "collection-number": "322",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501868",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "public health, valuation, Data work, India",
    "number": "Article 322",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "When is Machine Learning Data Good?: Valuing in Public Health Datafication",
    "URL": "https://doi.org/10.1145/3491102.3501868"
  },
  {
    "id": "10.1145/3491102.3517644",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Muller",
        "given": "Michael"
      },
      {
        "family": "Strohmayer",
        "given": "Angelika"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "HCI engages with data science through many topics and themes. Researchers have addressed biased dataset problems, arguing that bad data can cause innocent software to produce bad outcomes. But what if our software is not so innocent? What if the human decisions that shape our data-processing software, inadvertently contribute their own sources of bias? And what if our data-work technology causes us to forget those decisions and operations? Based in feminisms and critical computing, we analyze forgetting practices in data work practices. We describe diverse beneficial and harmful motivations for forgetting. We contribute: (1) a taxonomy of data silences in data work, which we use to analyze how data workers forget, erase, and unknow aspects of data; (2) a detailed analysis of forgetting practices in machine learning; and (3) an analytic vocabulary for future work in remembering, forgetting, and erasing in HCI and the data sciences.",
    "call-number": "10.1145/3491102.3517644",
    "collection-number": "323",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517644",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "neural networks, datasets, gaze detection, text tagging",
    "number": "Article 323",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Forgetting Practices in the Data Sciences",
    "URL": "https://doi.org/10.1145/3491102.3517644"
  },
  {
    "id": "10.1145/3491102.3501930",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sabie",
        "given": "Samar"
      },
      {
        "family": "Jackson",
        "given": "Steven J."
      },
      {
        "family": "Ju",
        "given": "Wendy"
      },
      {
        "family": "Parikh",
        "given": "Tapan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Design has been used to contest existing socio-technical arrangements, provoke conversations around matters of concern, and operationalize radical theories such as agonism, which embraces difference and contention. However, the focus is usually on creating something new: a product, interface or artifact. In this paper, we investigate what happens when critical unmaking is deployed as a deliberate design strategy in an intergenerational, agonistic urban context. Specifically, we report on how youth in a six-week design internship used unmaking as a design move to subvert conventional narratives about their surrounding urban context. We analyze how this led to conflictual encounters at the local senior center, and compare it to the other, making-centric proposals which received favorable feedback but failed to raise the same important discussions. Through this ethnographic account, we argue that critical unmaking is important yet overlooked, and should be in the repertoire of design moves available for agonism and provocation.",
    "call-number": "10.1145/3491102.3501930",
    "collection-number": "324",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501930",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "unmaking, civic engagement, critical unmaking, youth, virtual reality, making, older adults, agonism, participatory design",
    "number": "Article 324",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Unmaking as Agonism: Using Participatory Design with Youth to Surface Difference in an Intergenerational Urban Context",
    "URL": "https://doi.org/10.1145/3491102.3501930"
  },
  {
    "id": "10.1145/3491102.3502101",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Soden",
        "given": "Robert"
      },
      {
        "family": "Chilton",
        "given": "Lydia"
      },
      {
        "family": "Miles",
        "given": "Scott"
      },
      {
        "family": "Bicksler",
        "given": "Rebecca"
      },
      {
        "family": "Villanueva",
        "given": "Kaira Ray"
      },
      {
        "family": "Bica",
        "given": "Melissa"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Communicating risk to the public in the lead-up to tropical storms has the potential to significantly reduce the impacts on both livelihood and property. While significant research has been conducted in the storm risk community on how people receive, seek, and utilize risk information, given the importance of computing technologies and social media in these activities, human-centered design stands to make important contributions to this area. Drawing on an extensive literature review and 48 interviews with hurricane experts and members of the public, this paper makes three contributions. First, we provide a broad overview of hurricane risk communication. We then offer a set of guiding insights to inform HCI research work in this domain. Finally, we identify 6 opportunities that future human centered design work might pursue. In sum, this paper offers an invitation and a starting point for HCI to take up the problem of hurricane risk communication.",
    "call-number": "10.1145/3491102.3502101",
    "collection-number": "325",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502101",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Hurricane Risk Communication, Crisis Informatics",
    "number": "Article 325",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Insights and Opportunities for HCI Research into Hurricane Risk Communication",
    "URL": "https://doi.org/10.1145/3491102.3502101"
  },
  {
    "id": "10.1145/3491102.3502001",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gould",
        "given": "Sandy J. J."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data collection is often a laborious enterprise that forms part of the wider craft skill of doing research. In this essay, I try to understand whether parts of research processes in Human-Centred Computing (HCC) have been commodified, with a particular focus on data collection. If data collection has been commodified, do researchers act as producers or consumers in the process? And if researchers are consumers, has data collection become a consumption experience? If so, what are the implications of this? I explore these questions by considering the status of craft and consumption in the research process and by developing examples of consumption experiences. I note the benefits of commodity research artefacts, while highlighting the potentially deleterious effects consumption experiences could have on our ability to generate insights into the relations between people and technology. I finish the paper by relating consumption experiences to contemporary issues in HCC and lay out a programme of empirical work that would help answer some of the questions this paper raises.",
    "call-number": "10.1145/3491102.3502001",
    "collection-number": "326",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502001",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "research methods, consumption, data, data collection, commodification, craft, science and technology studies, commodity data, crowdsourcing",
    "number": "Article 326",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Consumption experiences in the research process",
    "URL": "https://doi.org/10.1145/3491102.3502001"
  },
  {
    "id": "10.1145/3491102.3502027",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Howe",
        "given": "Esther"
      },
      {
        "family": "Suh",
        "given": "Jina"
      },
      {
        "family": "Bin Morshed",
        "given": "Mehrab"
      },
      {
        "family": "McDuff",
        "given": "Daniel"
      },
      {
        "family": "Rowan",
        "given": "Kael"
      },
      {
        "family": "Hernandez",
        "given": "Javier"
      },
      {
        "family": "Abdin",
        "given": "Marah Ihab"
      },
      {
        "family": "Ramos",
        "given": "Gonzalo"
      },
      {
        "family": "Tran",
        "given": "Tracy"
      },
      {
        "family": "Czerwinski",
        "given": "Mary P"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Workplace stress-reduction interventions have produced mixed results due to engagement and adherence barriers. Leveraging technology to integrate such interventions into the workday may address these barriers and help mitigate the mental, physical, and monetary effects of workplace stress. To inform the design of a workplace stress-reduction intervention system, we conducted a four-week longitudinal study with 86 participants, examining the effects of intervention type and timing on usage, stress reduction impact, and user preferences. We compared three intervention types and two delivery timing conditions: Pre-scheduled (PS) by users and Just-in-time (JIT) prompted by the system-identified user stress-levels. We found JIT participants completed significantly more interventions than PS participants, but post-intervention and study-long stress reduction was not significantly different between conditions. Participants rated low-effort interventions highest, but high-effort interventions reduced the most stress. Participants felt JIT provided accountability but desired partial agency over timing. We present type and timing implications.",
    "call-number": "10.1145/3491102.3502027",
    "collection-number": "327",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502027",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "stress reduction, just-in-time, psychotherapy, digital micro-interventions, Workplace stress",
    "number": "Article 327",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design of Digital Workplace Stress-Reduction Intervention Systems: Effects of Intervention Type and Timing",
    "URL": "https://doi.org/10.1145/3491102.3502027"
  },
  {
    "id": "10.1145/3491102.3501976",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kruzan",
        "given": "Kaylee Payne"
      },
      {
        "family": "Meyerhoff",
        "given": "Jonah"
      },
      {
        "family": "Nguyen",
        "given": "Theresa"
      },
      {
        "family": "Reddy",
        "given": "Madhu"
      },
      {
        "family": "Mohr",
        "given": "David C."
      },
      {
        "family": "Kornfield",
        "given": "Rachel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Young adults have high rates of mental health conditions, yet they are the age group least likely to seek traditional treatment. They do, however, seek information about their mental health online, including by filling out online mental health screeners. To better understand online self-screening, and its role in help-seeking, we conducted focus groups with 50 young adults who voluntarily completed a mental health screener hosted on an advocacy website. We explored (1) catalysts for taking the screener, (2) anticipated outcomes, (3) reactions to the results, and (4) desired next steps. For many participants, the screener results validated their lived experiences of symptoms, but they were nevertheless unsure how to use the information to improve their mental health moving forward. Our findings suggest that online screeners can serve as a transition point in young people\u2019s mental health journeys. We discuss design implications for online screeners, post-screener feedback, and digital interventions broadly.",
    "call-number": "10.1145/3491102.3501976",
    "collection-number": "328",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501976",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "anxiety, help-seeking, mental health, online screening, depression, digital intervention",
    "number": "Article 328",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Wanted to See How Bad it Was\u201d: Online Self-screening as a Critical Transition Point Among Young Adults with Common Mental Health Conditions",
    "URL": "https://doi.org/10.1145/3491102.3501976"
  },
  {
    "id": "10.1145/3491102.3502046",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kornfield",
        "given": "Rachel"
      },
      {
        "family": "Meyerhoff",
        "given": "Jonah"
      },
      {
        "family": "Studd",
        "given": "Hannah"
      },
      {
        "family": "Bhattacharjee",
        "given": "Ananya"
      },
      {
        "family": "Williams",
        "given": "Joseph Jay"
      },
      {
        "family": "Reddy",
        "given": "Madhu"
      },
      {
        "family": "Mohr",
        "given": "David C."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Young adults have high rates of mental health conditions, but most do not want or cannot access formal treatment. We therefore recruited young adults with depression or anxiety symptoms to co-design a digital tool for self-managing their mental health concerns. Through study activities\u2014consisting of an online discussion group and a series of design workshops\u2014participants highlighted the importance of easy-to-use digital tools that allow them to exercise independence in their self-management. They described ways that an automated messaging tool might benefit them by: facilitating experimentation with diverse concepts and experiences; allowing variable depth of engagement based on preferences, availability, and mood; and collecting feedback to personalize the tool. While participants wanted to feel supported by an automated tool, they cautioned against incorporating an overtly human-like motivational tone. We discuss ways to apply these findings to improve the design and dissemination of digital mental health tools for young adults.",
    "call-number": "10.1145/3491102.3502046",
    "collection-number": "329",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502046",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mental health, automated messaging, young adults, digital mental health tools, co-design",
    "number": "Article 329",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Meeting Users Where They Are: User-centered Design of an Automated Text Messaging Tool to Support the Mental Health of Young Adults",
    "URL": "https://doi.org/10.1145/3491102.3502046"
  },
  {
    "id": "10.1145/3491102.3517710",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sien",
        "given": "Sang-Wha"
      },
      {
        "family": "Mohan",
        "given": "Shalini"
      },
      {
        "family": "McGrenere",
        "given": "Joanna"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Amidst increasing reports of mental health problems in Canadian university students, those of Asian descent have particularly struggled to seek out services due to cultural barriers. Counselling practices have long noted that culture influences how mental health is perceived and treated, yet the design of mental health technologies is limited with respect to how users\u2019 backgrounds influence usability and adoption. To identify inclusive design opportunities, we interviewed 20 East Asian university students in Canada. We found that they struggle to engage with technologies for mental health due to cultural stigma which have led them to prefer apps that support self-help though still valuing social help. We present inclusive design opportunities for mental health technologies that sensitively consider these challenges, including supporting learning opportunities with peers through storytelling and skill-sharing to promote literacy, empowerment, and advocacy for their own health. We conclude by discussing how universities can promote mental wellbeing more inclusively.",
    "call-number": "10.1145/3491102.3517710",
    "collection-number": "330",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517710",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "culture, mobile applications, mental wellbeing, social media, mental health",
    "number": "Article 330",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Design Opportunities for Supporting Mental Wellbeing Among East Asian University Students in Canada",
    "URL": "https://doi.org/10.1145/3491102.3517710"
  },
  {
    "id": "10.1145/3491102.3502135",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Daud\u00e9n Roquet",
        "given": "Claudia"
      },
      {
        "family": "Theofanopoulou",
        "given": "Nikki"
      },
      {
        "family": "Freeman",
        "given": "Jaimie L"
      },
      {
        "family": "Schleider",
        "given": "Jessica"
      },
      {
        "family": "Gross",
        "given": "James J"
      },
      {
        "family": "Davis",
        "given": "Katie"
      },
      {
        "family": "Townsend",
        "given": "Ellen"
      },
      {
        "family": "Slovak",
        "given": "Petr"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The ability to manage emotions effectively is critical to healthy psychological and social development in youth. Prior work has focused on investigating the design of mental health technologies for this population, yet it is still unclear how to help them cope with emotionally difficult situations in-the-moment. In this paper, we aim to explore the appropriation, naturally emerging engagement patterns, and perceived psychological impact of an exemplar interactive tangible device intervention designed to provide in-situ support, when deployed with n=109 youth for 1.5 months. Our findings from semi-structured interviews and co-design workshops with a subset of participants (n=44 and n=25, respectively) suggest the potential of using technology-enabled objects to aid with down-regulation and self-compassion in moments of heightened emotion, to facilitate the practice of cognitive strategies, and to act as emotional companions. Lastly, we discuss design opportunities for integrating situated and embodied support in mental health interventions for youth.",
    "call-number": "10.1145/3491102.3502135",
    "collection-number": "331",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502135",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mental health, youth, emotion regulation, embodiment, situated support, tangible interaction",
    "number": "Article 331",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Situated & Embodied Support for Youth\u2019s Mental Health: Design Opportunities for Interactive Tangible Device",
    "URL": "https://doi.org/10.1145/3491102.3502135"
  },
  {
    "id": "10.1145/3491102.3517518",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Scuri",
        "given": "Sabrina"
      },
      {
        "family": "Ferreira",
        "given": "Marta"
      },
      {
        "family": "Jardim Nunes",
        "given": "Nuno"
      },
      {
        "family": "Nisi",
        "given": "Valentina"
      },
      {
        "family": "Mulligan",
        "given": "Cathy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sustainable Development (SD) in its dimensions \u2013 environment, economy, and society \u2013 is a growing area of concern within the HCI community. This paper advances a systematic literature review on sustainability across the Sustainable Human-Computer Interaction (SHCI) body of work. The papers were classified according to the Triple Bottom Line (TBL) framework to understand how the pillars of SD play into the HCI discourse on sustainability. The economic angle was identified as a gap in SHCI literature. To meet the TBL of SD, however, a balance needs to be sought across all \u2018lines\u2019. In this paper, we propose that HCI can advance the discussion and the understanding of the economic concepts around sustainability through taking a sociology perspective on the economic angle of the TBL. We sustain this claim by discussing economic concepts and the role that digital can play in redefining the established foundations of our economic system.",
    "call-number": "10.1145/3491102.3517518",
    "collection-number": "332",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517518",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Systematic Literature Review, Sustainable HCI, Sustainable Development, Triple Bottom Line",
    "number": "Article 332",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Hitting the Triple Bottom Line: Widening the HCI Approach to Sustainability",
    "URL": "https://doi.org/10.1145/3491102.3517518"
  },
  {
    "id": "10.1145/3491102.3517597",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hasselqvist",
        "given": "Hanna"
      },
      {
        "family": "Renstr\u00f6m",
        "given": "Sara"
      },
      {
        "family": "H\u00e5kansson",
        "given": "Maria"
      },
      {
        "family": "Str\u00f6mberg",
        "given": "Helena"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "A transition to renewable energy increases the risks of disruptions when electricity supply does not meet demand.\u00a0HCI\u00a0has explored how digital technologies can mitigate such problems in households through support for reducing or shifting electricity use. However, faster transitions may be possible if some disturbances can be\u00a0acceptable\u00a0and households are supported in adapting to them. In this paper, we present a study of 21 Swedish households and their experiences of and ideas on how to manage disruptions in electricity supply. We call this perspective\u00a0household energy resilience\u00a0and identify three strategies for resilience: (1)\u00a0response diversity, i.e., diversity in ways of carrying out normally electricity-dependent practices, (2) creating\u00a0opportunities to develop resilience, and (3) building\u00a0community energy resilience. Furthermore, we suggest how\u00a0HCI\u00a0can support these strategies, both by providing tools to increase resilience and by carefully designing technology and services to be more resilient in themselves.\u00a0",
    "call-number": "10.1145/3491102.3517597",
    "collection-number": "333",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517597",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Energy resilience, Renewable energy, Sustainable HCI, Households, Energy futures",
    "number": "Article 333",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Renewable Energy Futures through Household Energy Resilience",
    "URL": "https://doi.org/10.1145/3491102.3517597"
  },
  {
    "id": "10.1145/3491102.3501929",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chopra",
        "given": "Simran"
      },
      {
        "family": "Clarke",
        "given": "Rachel E"
      },
      {
        "family": "Clear",
        "given": "Adrian K"
      },
      {
        "family": "Heitlinger",
        "given": "Sara"
      },
      {
        "family": "Dilaver",
        "given": "Ozge"
      },
      {
        "family": "Vasiliou",
        "given": "Christina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper responds to sustainable HCI\u2019s call to design long-term participatory projects with grassroots communities to counter the local effects of climate change and support more viable practices. We contribute a methodological approach to participatory speculative design as a series of interrelated experiments in living, working in symbiosis with a food-growing community moving towards collective resilience and food sovereignty. As an example of sustainability research within HCI, community food-growing has predominantly focused on collaborative acts of growing rather than disagreements, divergences and frictions. Limited attention has been paid to the challenges of effectively negotiating collaborative, sustainable speculative futures in this context. This paper reports on a workshop series on sustainable community food-growing using situated participatory speculation to address potential tensions when working collaboratively towards socio-technical alternatives.",
    "call-number": "10.1145/3491102.3501929",
    "collection-number": "334",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501929",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Food Growing, Sustainability, Participatory Speculative Design, Grassroots Communities, Visioning",
    "number": "Article 334",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Negotiating sustainable futures in communities through participatory speculative design and experiments in living",
    "URL": "https://doi.org/10.1145/3491102.3501929"
  },
  {
    "id": "10.1145/3491102.3517679",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rossitto",
        "given": "Chiara"
      },
      {
        "family": "Comber",
        "given": "Rob"
      },
      {
        "family": "Tholander",
        "given": "Jakob"
      },
      {
        "family": "Jacobsson",
        "given": "Mattias"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper discusses Digital Environmental Stewardship as an analytical framework that can help HCI scholarship to understand, design, and assess sociotechnical interventions concerned with sustainable waste management practices. Drawing on environmental studies, we outline key concepts of environmental stewardship \u2013 namely actors, capacity, and motivations \u2013 to unpack how different initiatives for handling waste are organised, both through grassroots and top-down interventions, and through varying sociotechnical configurations. We use these dimensions to analyse three different cases of waste management that illustrate how actions of care for the environment are ecologically organised, and what challenges might hinder them beyond \u2013or besides\u2013 behavioural motivations. We conclude with a discussion on the orientation to action that the suggested framework provides, and its role in understanding, designing and assessing digital technologies in this domain. We argue that examining how stewardship actions fold into each other helps design sociotechnical interventions for managing waste from within a relational perspective.",
    "call-number": "10.1145/3491102.3517679",
    "collection-number": "335",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517679",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "community-led initiatives, waste management, digital environmental stewardship, theory, Environmental sustainability",
    "number": "Article 335",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Digital Environmental Stewardship: the Work of Caring for the Environment in Waste Management",
    "URL": "https://doi.org/10.1145/3491102.3517679"
  },
  {
    "id": "10.1145/3491102.3501988",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Romat",
        "given": "Hugo"
      },
      {
        "family": "Marquardt",
        "given": "Nicolai"
      },
      {
        "family": "Hinckley",
        "given": "Ken"
      },
      {
        "family": "Henry Riche",
        "given": "Nathalie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Structured note-taking forms such as sketchnoting, self-tracking journals, and bullet journaling go beyond immediate capture of information scraps. Instead, hand-drawn pride-in-craftmanship increases perceived value for sharing and display. But hand-crafting lists, tables, and calendars is tedious and repetitive. To support these practices digitally, Style Blink (\u201cStyle-Blocks+Ink\u201d) explores handcrafted styling as a first-class object. Style-blocks encapsulate digital ink, enabling people to craft, modify, and reuse embellishments and decorations for larger structures, and apply custom layouts. For example, we provide interaction instruments that style ink for personal expression, inking palettes that afford creative experimentation, fillable pens that can be \u201cloaded\u201d with commands and actions to replace menu selections, techniques to customize inked structures post-creation by modifying the underlying handcrafted style-blocks and to re-layout the overall structure to match users\u2019 preferred template. In effect, any ink stroke, notation, or sketch can be encapsulated as a style-object and re-purposed as a tool. Feedback from 13 users show the potential of style adaptation and re-use in individual sketching practices.",
    "call-number": "10.1145/3491102.3501988",
    "collection-number": "336",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501988",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "pen+touch, bullet journaling, note-taking",
    "number": "Article 336",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Style Blink: Exploring Digital Inking of Structured Information via Handcrafted Styling as a First-Class Object",
    "URL": "https://doi.org/10.1145/3491102.3501988"
  },
  {
    "id": "10.1145/3491102.3501838",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "He",
        "given": "Zhenyi"
      },
      {
        "family": "Lutteroth",
        "given": "Christof"
      },
      {
        "family": "Perlin",
        "given": "Ken"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While using VR, efficient text entry is a challenge: users cannot easily locate standard physical keyboards, and keys are often out of reach, e.g. when standing. We present TapGazer, a text entry system where users type by tapping their fingers in place. Users can tap anywhere as long as the identity of each tapping finger can be detected with sensors. Ambiguity between different possible input words is resolved by selecting target words with gaze. If gaze tracking is unavailable, ambiguity is resolved by selecting target words with additional taps. We evaluated TapGazer for seated and standing VR: seated novice users using touchpads as tap surfaces reached 44.81 words per minute (WPM), 79.17% of their QWERTY typing speed. Standing novice users tapped on their thighs with touch-sensitive gloves, reaching 45.26 WPM (71.91%). We analyze TapGazer with a theoretical performance model and discuss its potential for text input in future AR scenarios.",
    "call-number": "10.1145/3491102.3501838",
    "collection-number": "337",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501838",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Text Entry, Typing, Virtual Reality, Eye Tracking, Input Techniques",
    "number": "Article 337",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TapGazer: Text Entry with Finger Tapping and Gaze-directed Word Selection",
    "URL": "https://doi.org/10.1145/3491102.3501838"
  },
  {
    "id": "10.1145/3491102.3502052",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Han",
        "given": "Han L."
      },
      {
        "family": "Yu",
        "given": "Junhang"
      },
      {
        "family": "Bournet",
        "given": "Raphael"
      },
      {
        "family": "Ciorascu",
        "given": "Alexandre"
      },
      {
        "family": "Mackay",
        "given": "Wendy E."
      },
      {
        "family": "Beaudouin-Lafon",
        "given": "Michel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "A key aspect of knowledge work is the analysis and manipulation of sets of related documents. We conducted interviews with 12 patent examiners and 12 scientists and found that all face difficulties using specialized tools for managing text from multiple documents across interconnected activities, including searching, collecting, annotating, organizing, writing and reviewing, while manually tracking their provenance. We introduce Passages, interactive objects that reify text selections and can then be manipulated, reused, and shared across multiple tools. Passages directly supports the above-listed activities as well as fluid transitions among them. Two user studies show that participants found Passages both elegant and powerful, facilitating their work practices and enabling greater reuse and novel strategies for analyzing and composing documents. We argue that Passages offers a general approach applicable to a wide variety of text-based interactions.",
    "call-number": "10.1145/3491102.3502052",
    "collection-number": "338",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502052",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Reification, Knowledge Work, Sensemaking, Provenance, Document Management, Active Reading",
    "number": "Article 338",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Passages: Interacting with Text Across Documents",
    "URL": "https://doi.org/10.1145/3491102.3502052"
  },
  {
    "id": "10.1145/3491102.3501871",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Hyejin"
      },
      {
        "family": "Jiang",
        "given": "Ruixi"
      },
      {
        "family": "Yoo",
        "given": "Yongjae"
      },
      {
        "family": "Henry",
        "given": "Max"
      },
      {
        "family": "Cooperstock",
        "given": "Jeremy R."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The need to generate convincing simulation of voices often arises in the context of avatar therapy, a treatment approach for disorders such as schizophrenia. This treatment involves patients interacting with simulations of the entity they imagine to be responsible for the voices they hear, for which there is often no external reference available. However, in such scenarios, there is little knowledge of how to design and reproduce these voices in a convincing manner. Existing voice manipulation interfaces are often complex to use, and highly limited in their ability to modify vocal characteristics beyond small adjustments. To address these challenges, we designed a framework that allows users to explore and select from a large set of voices, and thereafter manipulate the voice(s) to converge towards an effective match for one they have in mind. We demonstrated both the usability and superior performance of this system compared to existing voice manipulation interfaces.",
    "call-number": "10.1145/3491102.3501871",
    "collection-number": "340",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501871",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Voice Transformation Interface, Avatar Therapy, Speech Synthesis",
    "number": "Article 340",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Sound of Hallucinations: Toward a more convincing emulation of internalized voices",
    "URL": "https://doi.org/10.1145/3491102.3501871"
  },
  {
    "id": "10.1145/3491102.3502041",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shin",
        "given": "Jaemin"
      },
      {
        "family": "Lee",
        "given": "Seungjoo"
      },
      {
        "family": "Gong",
        "given": "Taesik"
      },
      {
        "family": "Yoon",
        "given": "Hyungjun"
      },
      {
        "family": "Roh",
        "given": "Hyunchul"
      },
      {
        "family": "Bianchi",
        "given": "Andrea"
      },
      {
        "family": "Lee",
        "given": "Sung-Ju"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Various automated eating detection wearables have been proposed to monitor food intakes. While these systems overcome the forgetfulness of manual user journaling, they typically show low accuracy at outside-the-lab environments or have intrusive form-factors (e.g., headgear). Eyeglasses are emerging as a socially-acceptable eating detection wearable, but existing approaches require custom-built frames and consume large power. We propose MyDJ, an eating detection system that could be attached to any eyeglass frame. MyDJ achieves accurate and energy-efficient eating detection by capturing complementary chewing signals on a piezoelectric sensor and an accelerometer. We evaluated the accuracy and wearability of MyDJ with 30 subjects in uncontrolled environments, where six subjects attached MyDJ on their own eyeglasses for a week. Our study shows that MyDJ achieves 0.919 F1-score in eating episode coverage, with 4.03 \u00d7 battery time over the state-of-the-art systems. In addition, participants reported wearing MyDJ was almost as comfortable (94.95%) as wearing regular eyeglasses.",
    "call-number": "10.1145/3491102.3502041",
    "collection-number": "341",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502041",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "automated dietary monitoring, eating detection, multimodal sensing, wearable computing",
    "number": "Article 341",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "MyDJ: Sensing Food Intakes with\u00a0an\u00a0Attachable\u00a0on\u00a0Your\u00a0Eyeglass\u00a0Frame",
    "URL": "https://doi.org/10.1145/3491102.3502041"
  },
  {
    "id": "10.1145/3491102.3517727",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sallam",
        "given": "Samar"
      },
      {
        "family": "Sakamoto",
        "given": "Yumiko"
      },
      {
        "family": "Leboe-McGowan",
        "given": "Jason"
      },
      {
        "family": "Latulipe",
        "given": "Celine"
      },
      {
        "family": "Irani",
        "given": "Pourang"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data Videos (DVs), or animated infographics that tell stories with data, are becoming increasingly popular. Despite their potential to induce attitude change, little is explored about how to produce effective DVs. This paper describes two studies that explored factors linked to the potential of health DVs to improve viewers\u2019 behavioural change intentions. We investigated: 1) how viewers\u2019 affect is linked to their behavioural change intentions; 2) how these affect are linked to the viewers\u2019 personality traits; 3) which attributes of DVs are linked to their persuasive potential. Results from both studies indicated that viewers\u2019 negative affect lowered their behavioural change intentions. Individuals with higher neuroticism exhibited higher negative affect and were harder to convince. Finally, Study 2 proved that providing any solutions to the health problem, presented in the DV, made the viewers perceive the videos as more actionable while lowering their negative affect, and importantly, induced higher behavioural change intentions.",
    "call-number": "10.1145/3491102.3517727",
    "collection-number": "342",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517727",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "data storytelling, actionable, personality, narrative visualization, affect, persuasive technology, solution, physical activity, attitude change, Data Video",
    "number": "Article 342",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Design Guidelines for Effective Health-Related Data Videos: An Empirical Investigation of Affect, Personality, and Video Content",
    "URL": "https://doi.org/10.1145/3491102.3517727"
  },
  {
    "id": "10.1145/3491102.3517631",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Habeeb",
        "given": "Dana"
      },
      {
        "family": "Clawson",
        "given": "James"
      },
      {
        "family": "Zakeresfahani",
        "given": "Arash"
      },
      {
        "family": "Holtz",
        "given": "Zebulon"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Individuals and communities around the world are increasingly exposed to extreme heat as a result of climate change. Urban residents are particularly vulnerable to extreme heat due to the urban heat island effect. However, understanding an individual\u2019s heat exposure and risk is difficult to assess due to variations in temperature within an urban environment. In this paper, we examine the potential for wearable temperature sensors to accurately measure personal heat exposure. We synthesize literature from fields spanning urban planning to public health and present the results of a user study validating a set of four commonly used off-the-shelf temperature sensors in two different urban settings across five on-body locations. Our investigation found that wearable temperature sensors are less reliable in highly urban areas and when worn in direct sunlight. We discuss important design considerations for wearable temperature sensors and identify actionable ways to improve future studies.",
    "call-number": "10.1145/3491102.3517631",
    "collection-number": "343",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517631",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "personal heat exposures, wearable sensors, extreme heat, urban heat island",
    "number": "Article 343",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating and Validating On-body Temperature Sensors for Personal Heat Exposure Tracking.",
    "URL": "https://doi.org/10.1145/3491102.3517631"
  },
  {
    "id": "10.1145/3491102.3517629",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Maeng",
        "given": "Wookjae"
      },
      {
        "family": "Lee",
        "given": "Joonhwan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Image-based sexual abuse (IBSA) is a severe social problem that causes survivors tremendous pain. IBSA survivors may encounter a lack of information and victim blame when seeking online and offline assistance. While institutions support survivors, they cannot be available 24 hours a day. Because the immediate reaction to IBSA is crucial to remove intimate images and prevent further distribution, survivors need first responders who are always accessible and do not blame them. Chatbots are constantly available, do not judge the conversation partner, and may deliver structured information and words of comfort. Therefore, we developed a chatbot to provide information and emotional support to IBSA survivors in dealing with their abuse. We analyzed nine chatbots for sexual violence survivors to identify common design elements. In addition, we sought advice from five professional counselors about the challenges survivors have while responding to their harm. We conducted a user study with 25 participants to determine the chatbot\u2019s effectiveness in providing information and emotional support compared to internet search. The chatbot was better than the internet search regarding information organization, accessibility, and conciseness. Furthermore, the chatbot excels in providing emotional support to survivors. We discuss the survivor-centered information structure and design consideration of emotionally supportive conversation.",
    "call-number": "10.1145/3491102.3517629",
    "collection-number": "344",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517629",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "revenge porn, chatbot, emotional support, image-based sexual abuse, information support",
    "number": "Article 344",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing and Evaluating a Chatbot for Survivors of Image-Based Sexual Abuse",
    "URL": "https://doi.org/10.1145/3491102.3517629"
  },
  {
    "id": "10.1145/3491102.3517655",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Sanghoon"
      },
      {
        "family": "Ko",
        "given": "In-Young"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Existing conversational approaches for Internet of Things (IoT) service mashup do not support modification because of the usability challenge, although it is common for users to modify the service mashups in IoT environments. To support the modification of IoT service mashups through conversational interfaces in a usable manner, we propose the conversational mashup modification agent (CoMMA). Users can modify IoT service mashups using CoMMA through natural language conversations. CoMMA has a two-step mashup modification interaction, an implicature-based localization step, and a modification step with a disambiguation strategy. The localization step allows users to easily search for a mashup by vocalizing their expressions in the environment. The modification step supports users to modify mashups by speaking simple modification commands. We conducted a user study and the results show that CoMMA is as effective as visual approaches in terms of task completion time and perceived task workload for modifying IoT service mashups.",
    "call-number": "10.1145/3491102.3517655",
    "collection-number": "345",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517655",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "IoT Service Mashup, Smart Home, Conversational Interface, Conversational Mashup Modification",
    "number": "Article 345",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Conversational Approach for Modifying Service Mashups in IoT Environments",
    "URL": "https://doi.org/10.1145/3491102.3517655"
  },
  {
    "id": "10.1145/3491102.3502100",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Singhal",
        "given": "Yatharth"
      },
      {
        "family": "Noeske",
        "given": "Richard Huynh"
      },
      {
        "family": "Bhardwaj",
        "given": "Ayush"
      },
      {
        "family": "Kim",
        "given": "Jin Ryong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We examine mid-air typing data collected from touch typists to evaluate the features and classification models for recognizing finger stroke. A large number of finger movement traces have been collected using finger motion capture systems, labeled into individual finger strokes, and classified into several key features. We test finger kinematic features, including 3D position, velocity, acceleration, and temporal features, including previous fingers and keys. Based on this analysis, we assess the performance of various classifiers, including Naive Bayes, Random Forest, Support Vector Machines, and Deep Neural Networks, in terms of the accuracy for correctly classifying the keystroke. We finally incorporate a linguistic heuristic to explore the effectiveness of the character prediction model and improve the total accuracy.",
    "call-number": "10.1145/3491102.3502100",
    "collection-number": "346",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502100",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Deep Neural Network, Eyes-free Typing, Mid-Air Typing, Keystroke Classification, Text Entry",
    "number": "Article 346",
    "number-of-pages": "9",
    "page": "1\u20139",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Improving Finger Stroke Recognition Rate for Eyes-Free Mid-Air Typing in VR",
    "URL": "https://doi.org/10.1145/3491102.3502100"
  },
  {
    "id": "10.1145/3491102.3502069",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shultz",
        "given": "Craig"
      },
      {
        "family": "Kim",
        "given": "Daehwa"
      },
      {
        "family": "Ahuja",
        "given": "Karan"
      },
      {
        "family": "Harrison",
        "given": "Chris"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Touchscreen tracking latency, often 80ms or more, creates a rubber-banding effect in everyday direct manipulation tasks such as dragging, scrolling, and drawing. This has been shown to decrease system preference, user performance, and overall realism of these interfaces. In this research, we demonstrate how the addition of a thin, 2D micro-patterned surface with 5 micron spaced features can be used to reduce motor-visual touchscreen latency. When a finger, stylus, or tangible is translated across this textured surface frictional forces induce acoustic vibrations which naturally encode sliding velocity. This acoustic signal is sampled at 192kHz using a conventional audio interface pipeline with an average latency of 28ms. When fused with conventional low-speed, but high-spatial-accuracy 2D touch position data, our machine learning model can make accurate predictions of real time touch location.",
    "call-number": "10.1145/3491102.3502069",
    "collection-number": "347",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502069",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Input Techniques, Tribology, Touchscreens, Sensors, Latency",
    "number": "Article 347",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TriboTouch: Micro-Patterned Surfaces for Low Latency Touchscreens",
    "URL": "https://doi.org/10.1145/3491102.3502069"
  },
  {
    "id": "10.1145/3491102.3502045",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yang",
        "given": "Jackie (Junrui)"
      },
      {
        "family": "Chen",
        "given": "Tuochao"
      },
      {
        "family": "Qin",
        "given": "Fang"
      },
      {
        "family": "Lam",
        "given": "Monica S."
      },
      {
        "family": "Landay",
        "given": "James A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Full-body tracking in virtual reality improves presence, allows interaction via body postures, and facilitates better social expression among users. However, full-body tracking systems today require a complex setup fixed to the environment (e.g., multiple lighthouses/cameras) and a laborious calibration process, which goes against the desire to make VR systems more portable and integrated. We present HybridTrak, which provides accurate, real-time full-body tracking by augmenting inside-out1 upper-body VR tracking systems with a single external off-the-shelf RGB web camera. HybridTrak uses a full-neural solution to convert and transform users\u2019 2D full-body poses from the webcam to 3D poses leveraging the inside-out upper-body tracking data. We showed HybridTrak is more accurate than RGB or depth-based tracking methods on the MPI-INF-3DHP dataset. We also tested HybridTrak in the popular VRChat app and showed that body postures presented by HybridTrak are more distinguishable and more natural than a solution using an RGBD camera.",
    "call-number": "10.1145/3491102.3502045",
    "collection-number": "348",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502045",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "computer vision., virtual reality, full-body tracking",
    "number": "Article 348",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "HybridTrak: Adding Full-Body Tracking to VR Using an Off-the-Shelf Webcam",
    "URL": "https://doi.org/10.1145/3491102.3502045"
  },
  {
    "id": "10.1145/3491102.3502134",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Khan",
        "given": "Anam Ahmad"
      },
      {
        "family": "Newn",
        "given": "Joshua"
      },
      {
        "family": "Bailey",
        "given": "James"
      },
      {
        "family": "Velloso",
        "given": "Eduardo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Gaze and speech are rich contextual sources of information that, when combined, can result in effective and rich multimodal interactions. This paper proposes a machine learning-based pipeline that leverages and combines users\u2019 natural gaze activity, the semantic knowledge from their vocal utterances and the synchronicity between gaze and speech data to facilitate users\u2019 interaction. We evaluated our proposed approach on an existing dataset, which involved 32 participants recording voice notes while reading an academic paper. Using a Logistic Regression classifier, we demonstrate that our proposed multimodal approach maps voice notes with accurate text passages with an average F1-Score of 0.90. Our proposed pipeline motivates the design of multimodal interfaces that combines natural gaze and speech patterns to enable robust interactions.",
    "call-number": "10.1145/3491102.3502134",
    "collection-number": "349",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502134",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "voice interfaces, natural gaze, implicit annotation, semantic similarity, natural language processing",
    "number": "Article 349",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Integrating Gaze and Speech for Enabling Implicit Interactions",
    "URL": "https://doi.org/10.1145/3491102.3502134"
  },
  {
    "id": "10.1145/3491102.3501989",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Seals",
        "given": "Ayanna"
      },
      {
        "family": "Pilloni",
        "given": "Giuseppina"
      },
      {
        "family": "Kim",
        "given": "Jin"
      },
      {
        "family": "Sanchez",
        "given": "Raul"
      },
      {
        "family": "Rizzo",
        "given": "John-Ross"
      },
      {
        "family": "Charvet",
        "given": "Leigh"
      },
      {
        "family": "Nov",
        "given": "Oded"
      },
      {
        "family": "Dove",
        "given": "Graham"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Walking impairment is a debilitating symptom of Multiple Sclerosis (MS), a disease affecting 2.8 million people worldwide. While clinicians\u2019 in-person observational gait assessments are important, research suggests that data from wearable sensors can indicate early onset of gait impairment, track patients\u2019 responses to treatment, and support remote and longitudinal assessment. We present an inquiry into supporting the transition from research to clinical practice. Co-design by HCI, biomedical, neurology and rehabilitation researchers resulted in a data-rich interface prototype for augmented gait analysis based on visualized sensor data. We used this as a prompt in interviews with ten experienced clinicians from a range of MS rehabilitation roles. We find that clinicians value quantitative sensor data within a whole patient narrative, to help track specific rehabilitation goals, but identify a tension between grasping critical information quickly and more detailed understanding. Based on the findings we make design recommendations for data-rich remote rehabilitation interfaces.",
    "call-number": "10.1145/3491102.3501989",
    "collection-number": "350",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501989",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "wearables, transition to clinical practice, data visualization, gait assessments, remote care, multiple sclerosis",
    "number": "Article 350",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u2018Are They Doing Better In The Clinic Or At Home?\u2019: Understanding Clinicians\u2019 Needs When Visualizing Wearable Sensor Data Used In Remote Gait Assessments For People With Multiple Sclerosis",
    "URL": "https://doi.org/10.1145/3491102.3501989"
  },
  {
    "id": "10.1145/3491102.3517512",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cronin",
        "given": "Sean"
      },
      {
        "family": "Freeman",
        "given": "Euan"
      },
      {
        "family": "Doherty",
        "given": "Gavin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Touchless input could transform clinical activity by allowing health professionals direct control over medical imaging systems in a sterile manner. Currently, users face the issues of being unable to directly manipulate imaging in aseptic environments, as well as needing to touch shared surfaces in other hospital areas. Unintended input is a key challenge for touchless interaction and could be especially disruptive in medical contexts. We evaluated four clutching techniques with 34 health professionals, measuring interaction performance and interviewing them to obtain insight into their views on clutching, and touchless control of medical imaging. As well as exploring the performance of the different clutching techniques, our analysis revealed an appetite for reliable touchless interfaces, a strong desire to reduce shared surface contact, and suggested potential improvements such as combined authentication and touchless control. Our findings can inform the development of novel touchless medical systems and identify challenges for future research.",
    "call-number": "10.1145/3491102.3517512",
    "collection-number": "351",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517512",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Touchless Interaction, Gestures, Clutching, Medical Imaging Systems, Midas Touch, PACS",
    "number": "Article 351",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Clutching Interactions for Touchless Medical Imaging Systems",
    "URL": "https://doi.org/10.1145/3491102.3517512"
  },
  {
    "id": "10.1145/3491102.3502206",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jo",
        "given": "Eunkyung"
      },
      {
        "family": "Ryu",
        "given": "Myeonghan"
      },
      {
        "family": "Kenderova",
        "given": "Georgia"
      },
      {
        "family": "So",
        "given": "Samuel"
      },
      {
        "family": "Shapiro",
        "given": "Bryan"
      },
      {
        "family": "Papoutsaki",
        "given": "Alexandra"
      },
      {
        "family": "Epstein",
        "given": "Daniel A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Clinical decision support tools have typically focused on one-time support for diagnosis or prognosis, but have the ability to support providers in longitudinal planning of patient care regimens amidst infrastructural challenges. We explore an opportunity for technology support for discontinuing antidepressants, where clinical guidelines increasingly recommend gradual discontinuation over abruptly stopping to avoid withdrawal symptoms, but providers have varying levels of experience and diverse strategies for supporting patients through discontinuation. We conducted two studies with 12 providers, identifying providers\u2019 needs in developing discontinuation plans and deriving design guidelines. We then iteratively designed and implemented AT Planner, instantiating the guidelines by projecting taper schedules and providing flexibility for adjustment. Provider feedback on AT Planner highlighted that discontinuation plans required balancing interpersonal and infrastructural constraints and surfaced the need for different technological support based on clinical experience. We discuss the benefits and challenges of incorporating flexibility and advice into clinical planning tools.",
    "call-number": "10.1145/3491102.3502206",
    "collection-number": "352",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502206",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Clinical decision support systems, Psychiatric drugs, Antidepressants, Planning",
    "number": "Article 352",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing Flexible Longitudinal Regimens: Supporting Clinician Planning for Discontinuation of Psychiatric Drugs",
    "URL": "https://doi.org/10.1145/3491102.3502206"
  },
  {
    "id": "10.1145/3491102.3517519",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Caldeira",
        "given": "Clara"
      },
      {
        "family": "Bhowmick",
        "given": "Pallabi"
      },
      {
        "family": "Komarlingam",
        "given": "Priya"
      },
      {
        "family": "Siek",
        "given": "Katie A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Forgetfulness is a primary factor of medication nonadherence, a problem that contributes to worse health outcomes and increased mortality among people with chronic conditions. Common strategies to address forgetfulness, such as timed reminders, have limited effectiveness. However, there is limited information about why these strategies fail. To address this gap, we conducted interviews with people who take medications daily and miss doses at least twice a month. We contribute a state-based Medication Routine Framework composed of four states (Wellness, New Task, Erratic, and Disruption) in two axes (regularity and time scale). Because most nonadherence due to forgetfulness occurs in nonroutine states (i.e., Erratic and Disruption state), we argue that improving technology for medication adherence requires designing for these states. In this paper, we describe each state in detail and discuss opportunities for adapting medication reminder strategies to overcome the challenges of nonroutine states.",
    "call-number": "10.1145/3491102.3517519",
    "collection-number": "353",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517519",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "health, adherence, medication",
    "number": "Article 353",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A State-Based Medication Routine Framework",
    "URL": "https://doi.org/10.1145/3491102.3517519"
  },
  {
    "id": "10.1145/3491102.3501884",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhou",
        "given": "Qian"
      },
      {
        "family": "Fitzmaurice",
        "given": "George"
      },
      {
        "family": "Anderson",
        "given": "Fraser"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Virtual Reality (VR) has potential for productive knowledge work, however, midair pointing with controllers or hand gestures does not offer the precision and comfort of traditional 2D mice. Directly integrating mice into VR is difficult as selecting targets in a 3D space is negatively impacted by binocular rivalry, perspective mismatch, and improperly calibrated control-display (CD) gain. To address these issues, we developed Depth-Adaptive Cursor\u00a0, a 2D-mouse driven pointing technique for 3D selection with depth-adaptation that continuously interpolates the cursor depth by inferring what users intend to select based on the cursor position, the viewpoint, and the selectable objects. Depth-Adaptive Cursor\u00a0uses a novel CD gain tool to compute a usable range of CD gains for general mouse-based pointing in VR. A user study demonstrated that Depth-Adaptive Cursor\u00a0significantly improved performance compared with an existing mouse-based pointing technique without depth-adaption in terms of time (21.2%), error (48.3%), perceived workload, and user satisfaction.",
    "call-number": "10.1145/3491102.3501884",
    "collection-number": "354",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501884",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "3D pointing, target selection, virtual workspace, Virtual Reality",
    "number": "Article 354",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "In-Depth Mouse: Integrating Desktop Mouse into Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3501884"
  },
  {
    "id": "10.1145/3491102.3501873",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Schjerlund",
        "given": "Jonas"
      },
      {
        "family": "Hornb\u00e6k",
        "given": "Kasper"
      },
      {
        "family": "Bergstr\u00f6m",
        "given": "Joanna"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We introduce OVRlap, a VR interaction technique that lets the user perceive multiple places at the same time from a first-person perspective. OVRlap achieves this by overlapping viewpoints. At any time, only one viewpoint is active, meaning that the user may interact with objects therein. Objects seen from the active viewpoint are opaque, whereas objects seen from passive viewpoints are transparent. This allows users to perceive multiple locations at once and easily switch to the one in which they want to interact. We compare OVRlap and a single-viewpoint technique in a study where 20 participants complete object-collection and monitoring tasks. We find that in both tasks, participants are significantly faster and move their head significantly less with OVRlap. We propose how the technique might be improved through automated switching of the active viewpoint and intelligent viewpoint rendering.",
    "call-number": "10.1145/3491102.3501873",
    "collection-number": "355",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501873",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "user studies, virtual reality, large environments, interaction techniques",
    "number": "Article 355",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "OVRlap: Perceiving Multiple Locations Simultaneously to Improve Interaction in VR",
    "URL": "https://doi.org/10.1145/3491102.3501873"
  },
  {
    "id": "10.1145/3491102.3501971",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tsai",
        "given": "Hsin-Ruey"
      },
      {
        "family": "Liao",
        "given": "Yu-So"
      },
      {
        "family": "Tsai",
        "given": "Chieh"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Rendering instant and intense impact feedback on users\u2019 hands, limbs and head to enhance realism in virtual reality (VR) has been proposed in previous works, but impact on the body is still less discussed. With the body\u2019s large surface area to utilize, numerous impact patterns can be rendered in versatile VR applications, e.g.,\u00a0being shot, blasted, punched or slashed on body in VR games. Herein we propose ImpactVest to render spatio-temporal multilevel impact force feedback on body. By independently controlling nine impactors in a 3 \u00d7 3 layout using elastic force, impact is generated at different levels, positions and time sequences for versatile spatial and temporal combinations. We conducted a just-noticeable difference (JND) study to understand users\u2019 impact level distinguishability on the body. A time interval threshold study was then performed to ascertain what time interval thresholds between two impact stimuli should be used to distinguish from simultaneous impact, a continuous impact stroke and two discrete impact stimuli. Based on the results, we conducted a VR experience study to verify that impact feedback from ImpactVest enhances VR realism.",
    "call-number": "10.1145/3491102.3501971",
    "collection-number": "356",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501971",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "virtual reality., force feedback, wearable device, impact, Haptics",
    "number": "Article 356",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ImpactVest: Rendering Spatio-Temporal Multilevel Impact Force Feedback on Body in VR",
    "URL": "https://doi.org/10.1145/3491102.3501971"
  },
  {
    "id": "10.1145/3491102.3517725",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Choi",
        "given": "Myungguen"
      },
      {
        "family": "Sakamoto",
        "given": "Daisuke"
      },
      {
        "family": "Ono",
        "given": "Tetsuo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The maximum physical range of horizontal human eye movement is approximately 45\u00b0. However, in a natural gaze shift, the difference in the direction of the gaze relative to the frontal direction of the head rarely exceeds 25\u00b0. We name this region of 25\u00b0 \u2212 45\u00b0 the \u201cKuiper Belt\u201d in the eye-gaze interaction. We try to utilize this region to solve the Midas touch problem to enable a search task while reducing false input in the Virtual Reality environment. In this work, we conduct two studies to figure out the design principle of how we place menu items in the Kuiper Belt as an \u201cout-of-natural angle\u201d region of the eye-gaze movement, and determine the effectiveness and workload of the Kuiper Belt-based method. The results indicate that the Kuiper Belt-based method facilitated the visual search task while reducing false input. Finally, we present example applications utilizing the findings of these studies.",
    "call-number": "10.1145/3491102.3517725",
    "collection-number": "357",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517725",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Eye Tracking, Menu Item Selection, Virtual Reality, Eye-gaze Interface",
    "number": "Article 357",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Kuiper Belt: Utilizing the \u201cOut-of-natural Angle\u201d Region in the Eye-gaze Interaction for Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517725"
  },
  {
    "id": "10.1145/3491102.3517706",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Abtahi",
        "given": "Parastoo"
      },
      {
        "family": "Hough",
        "given": "Sidney Q."
      },
      {
        "family": "Landay",
        "given": "James A."
      },
      {
        "family": "Follmer",
        "given": "Sean"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We can create Virtual Reality (VR) interactions that have no equivalent in the real world by remapping spacetime or altering users\u2019 body representation, such as stretching the user\u2019s virtual arm for manipulation of distant objects or scaling up the user\u2019s avatar to enable rapid locomotion. Prior research has leveraged such approaches, what we call beyond-real techniques, to make interactions in VR more practical, efficient, ergonomic, and accessible. We present a survey categorizing prior movement-based VR interaction literature as reality-based, illusory, or beyond-real interactions. We survey relevant conferences (CHI, IEEE VR, VRST, UIST, and DIS) while focusing on selection, manipulation, locomotion, and navigation in VR. For beyond-real interactions, we describe the transformations that have been used by prior works to create novel remappings. We discuss open research questions through the lens of the human sensorimotor control system and highlight challenges that need to be addressed for effective utilization of beyond-real interactions in future VR applications, including plausibility, control, long-term adaptation, and individual differences.",
    "call-number": "10.1145/3491102.3517706",
    "collection-number": "358",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517706",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "framework, interaction design, virtual reality, sensorimotor control",
    "number": "Article 358",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Beyond Being Real: A Sensorimotor Control Perspective on Interactions in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517706"
  },
  {
    "id": "10.1145/3491102.3517447",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hoppe",
        "given": "Matthias"
      },
      {
        "family": "Baumann",
        "given": "Andrea"
      },
      {
        "family": "Tamunjoh",
        "given": "Patrick Chofor"
      },
      {
        "family": "Machulla",
        "given": "Tonja-Katrin"
      },
      {
        "family": "Wo\u017aniak",
        "given": "Pawe\u0142 W."
      },
      {
        "family": "Schmidt",
        "given": "Albrecht"
      },
      {
        "family": "Welsch",
        "given": "Robin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Modern games make creative use of First- and Third-person perspectives (FPP and TPP) to allow the player to explore virtual worlds. Traditionally, FPP and TPP perspectives are seen as distinct concepts. Yet, Virtual Reality (VR) allows for flexibility in choosing perspectives. We introduce the notion of a perspective continuum in VR, which is technically related to the camera position and conceptually to how users perceive their environment in VR. A perspective continuum enables adapting and manipulating the sense of agency and involvement in the virtual world. This flexibility of perspectives broadens the design space of VR experiences through deliberately manipulating perception. In a study, we explore users\u2019 attitudes, experiences and perceptions while controlling a virtual character from the two known perspectives. Statistical analysis of the empirical results shows the existence of a perspective continuum in VR. Our findings can be used to design experiences based on shifts of perception.",
    "call-number": "10.1145/3491102.3517447",
    "collection-number": "360",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517447",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Embodiment, Perspective, Virtual Reality, Third Person, First Person",
    "number": "Article 360",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "There Is No First- or Third-Person View in Virtual Reality: Understanding the Perspective Continuum",
    "URL": "https://doi.org/10.1145/3491102.3517447"
  },
  {
    "id": "10.1145/3491102.3501830",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Guo",
        "given": "Qingyu"
      },
      {
        "family": "Zhou",
        "given": "Siyuan"
      },
      {
        "family": "Wu",
        "given": "Yifeng"
      },
      {
        "family": "Peng",
        "given": "Zhenhui"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online medical crowdfunding campaigns (OMCCs) help patients seek financial support. First impressions (FIs) of an OMCC, including perceived empathy, credibility, justice, impact, and attractiveness, could affect viewers\u2019 donation decisions. Images play a crucial role in manifesting FIs, and it is beneficial for fundraisers to understand how viewers may judge their selected images for OMCCs beforehand. This work proposes a data-driven approach to assessing whether an OMCC image conveys appropriate FIs. We first crowdsource viewers\u2019 perception of OMCC images. Statistical analysis confirms that agreement on all five dimensions of FIs exists, and these FIs positively correlate with donation intention. We compute image content, color, texture, and composition features, then analyze the correlation between these visual features and FIs. We further predict FIs based on these features, and the best model achieves an overall F1-score of 0.727. Finally, we discuss how our insights could benefit fundraisers and possible ethical concerns.",
    "call-number": "10.1145/3491102.3501830",
    "collection-number": "361",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501830",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "computational assessment, first impression, Online medical crowdfunding campaign",
    "number": "Article 361",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding and Modeling Viewers\u2019 First Impressions with Images in Online Medical Crowdfunding Campaigns",
    "URL": "https://doi.org/10.1145/3491102.3501830"
  },
  {
    "id": "10.1145/3491102.3501992",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liao",
        "given": "Yi-Chi"
      },
      {
        "family": "Todi",
        "given": "Kashyap"
      },
      {
        "family": "Acharya",
        "given": "Aditya"
      },
      {
        "family": "Keurulainen",
        "given": "Antti"
      },
      {
        "family": "Howes",
        "given": "Andrew"
      },
      {
        "family": "Oulasvirta",
        "given": "Antti"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Affordance refers to the perception of possible actions allowed by an object. Despite its relevance to human\u2013computer interaction, no existing theory explains the mechanisms that underpin affordance-formation; that is, how affordances are discovered and adapted via interaction. We propose an integrative theory of affordance-formation based on the theory of reinforcement learning in cognitive sciences. The key assumption is that users learn to associate promising motor actions to percepts via experience when reinforcement signals (success/failure) are present. They also learn to categorize actions (e.g., \u201crotating\u201d a dial), giving them the ability to name and reason about affordance. Upon encountering novel widgets, their ability to generalize these actions determines their ability to perceive affordances. We implement this theory in a virtual robot model, which demonstrates human-like adaptation of affordance in interactive widgets tasks. While its predictions align with trends in human data, humans are able to adapt affordances faster, suggesting the existence of additional mechanisms.",
    "call-number": "10.1145/3491102.3501992",
    "collection-number": "362",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501992",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Robotics, Design, Reinforcement Learning, Adaptation, Modeling, Interaction, Motion Planning, Affordance, Theory, Action, Perception, Machine Learning",
    "number": "Article 362",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Rediscovering Affordance: A Reinforcement Learning Perspective",
    "URL": "https://doi.org/10.1145/3491102.3501992"
  },
  {
    "id": "10.1145/3491102.3502089",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mohaddesi",
        "given": "Omid"
      },
      {
        "family": "Griffin",
        "given": "Jacqueline"
      },
      {
        "family": "Ergun",
        "given": "Ozlem"
      },
      {
        "family": "Kaeli",
        "given": "David"
      },
      {
        "family": "Marsella",
        "given": "Stacy"
      },
      {
        "family": "Harteveld",
        "given": "Casper"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Understanding decision-making in dynamic and complex settings is a challenge yet essential for preventing, mitigating, and responding to adverse events (e.g., disasters, financial crises). Simulation games have shown promise to advance our understanding of decision-making in such settings. However, an open question remains on how we extract useful information from these games. We contribute an approach to model human-simulation interaction by leveraging existing methods to characterize: (1) system states of dynamic simulation environments (with Principal Component Analysis), (2) behavioral responses from human interaction with simulation (with Hidden Markov Models), and (3) behavioral responses across system states (with Sequence Analysis). We demonstrate this approach with our game simulating drug shortages in a supply chain context. Results from our experimental study with 135 participants show different player types (hoarders, reactors, followers), how behavior changes in different system states, and how sharing information impacts behavior. We discuss how our findings challenge existing literature.",
    "call-number": "10.1145/3491102.3502089",
    "collection-number": "363",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502089",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "supply chain, human-simulation interaction, hidden markov models, sequence analysis, gamette, principal component analysis",
    "number": "Article 363",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "To Trust or to Stockpile: Modeling Human-Simulation Interaction in Supply Chain Shortages",
    "URL": "https://doi.org/10.1145/3491102.3502089"
  },
  {
    "id": "10.1145/3491102.3517733",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Epp",
        "given": "Felix Anand"
      },
      {
        "family": "Kantosalo",
        "given": "Anna"
      },
      {
        "family": "Jain",
        "given": "Nehal"
      },
      {
        "family": "Lucero",
        "given": "Andr\u00e9s"
      },
      {
        "family": "Mekler",
        "given": "Elisa D."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Social wearables promise to augment and enhance social interactions. However, despite two decades of HCI research on wearables, we are yet to see widespread adoption of social wearables into everyday life. More in-situ investigations into the social dynamics and cultural practices afforded by wearing interactive technology are needed to understand the drivers and barriers to adoption. To this end, we study social wearables in the context of Nordic student culture and the students\u2019 practice of adorning boiler suits. Through a co-creation process, we designed Digi Merkki, a personalised interactive clothing patch. In a two-week elicitation diary study, we captured how 16 students adopted Digi Merkki into their social practices. We found that Digi Merkki afforded a variety of social interaction strategies, including sharing, spamming, and stealing pictures, which supported meaning-making and community-building. Based on our findings, we articulate \u201cMemetic Expression\u201d as a strong concept for designing social wearables.",
    "call-number": "10.1145/3491102.3517733",
    "collection-number": "364",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517733",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Wearable Computing, Co-design, Digital Expression, Memes, Field Study, Research through Design, Social Computing, Nordic Student Culture, Social Wearables, Adornment, Social Practices",
    "number": "Article 364",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Adorned in Memes: Exploring the Adoption of Social Wearables in Nordic Student Culture",
    "URL": "https://doi.org/10.1145/3491102.3517733"
  },
  {
    "id": "10.1145/3491102.3517604",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Park",
        "given": "So Yeon"
      },
      {
        "family": "Redmond",
        "given": "Emily"
      },
      {
        "family": "Berger",
        "given": "Jonathan"
      },
      {
        "family": "Kaneshiro",
        "given": "Blair"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Through collaborative playlists (CPs), streaming platform users have co-curated music together for various purposes for over a decade. As the COVID-19 pandemic has transformed how people come together through technology and engage with music, CPs have also taken on new roles and value. To understand how CP usage and perception have evolved since the onset of COVID-19, we conducted a mixed-methods investigation of CPs in the United States. Survey results from primarily CP users (N=142) revealed that interest in and usage of CPs have mostly increased since the pandemic, and that the role of music in connecting with others is positively correlated with the perceived impact of COVID-19. Follow-up interviews (N=9) provided additional insights into changing perceptions and usage patterns of CPs during COVID-19; for instance, fewer collaborators per playlist reflects users\u2019 greater focus on strengthening social connections and relationships. Taken together, findings and design implications on digitally mediated co-curation further elucidate the necessity for social and collaborative experiences with music supported by CPs during COVID-19.",
    "call-number": "10.1145/3491102.3517604",
    "collection-number": "365",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517604",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Shared music, Collaborative playlist, Pandemic, Computer-mediated collaboration, Collaboration, Perception, Shared playlist, Social connection, COVID-19, Computer-mediated communication",
    "number": "Article 365",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Hitting Pause: How User Perceptions of Collaborative Playlists Evolved in the United States During the COVID-19 Pandemic",
    "URL": "https://doi.org/10.1145/3491102.3517604"
  },
  {
    "id": "10.1145/3491102.3517560",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Matviienko",
        "given": "Andrii"
      },
      {
        "family": "M\u00fcller",
        "given": "Florian"
      },
      {
        "family": "Sch\u00f6n",
        "given": "Dominik"
      },
      {
        "family": "Seesemann",
        "given": "Paul"
      },
      {
        "family": "G\u00fcnther",
        "given": "Sebastian"
      },
      {
        "family": "M\u00fchlh\u00e4user",
        "given": "Max"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Cycling has become increasingly popular as a means of transportation. However, cyclists remain a highly vulnerable group of road users. According to accident reports, one of the most dangerous situations for cyclists are uncontrolled intersections, where cars approach from both directions. To address this issue and assist cyclists in crossing decision-making at uncontrolled intersections, we designed two visualizations that: (1) highlight occluded cars through an X-ray vision and (2) depict the remaining time the intersection is safe to cross via a Countdown. To investigate the efficiency of these visualizations, we proposed an Augmented Reality simulation as a novel evaluation method, in which the above visualizations are represented as AR, and conducted a controlled experiment with 24 participants indoors. We found that the X-ray ensures a fast selection of shorter gaps between cars, while the Countdown facilitates a feeling of safety and provides a better intersection overview.",
    "call-number": "10.1145/3491102.3517560",
    "collection-number": "366",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517560",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "cyclist safety, crossing decision-making, augmented reality",
    "number": "Article 366",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "BikeAR: Understanding Cyclists\u2019 Crossing Decision-Making at Uncontrolled Intersections using Augmented Reality",
    "URL": "https://doi.org/10.1145/3491102.3517560"
  },
  {
    "id": "10.1145/3491102.3517571",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Colley",
        "given": "Mark"
      },
      {
        "family": "Bajrovic",
        "given": "Elvedin"
      },
      {
        "family": "Rukzio",
        "given": "Enrico"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Automated vehicles are expected to substitute driver-pedestrian communication via LED strips or displays. This communication is expected to improve trust and the crossing process in general. However, numerous factors such as other pedestrians\u2019 behavior, perceived time pressure, or previous experience influence crossing decisions. Therefore, we report the results of a triply subdivided Virtual Reality study (N=18) evaluating these. Results show that external communication was perceived as hedonically pleasing, increased perceived safety and trust, and also that pedestrians\u2019 behavior affected participants\u2019 behavior. A timer did not alter crossing behavior, however, repeated exposure increased trust and reduced crossing times, showing a habituation effect. Our work helps better to integrate research on external communication in ecologically valid settings.",
    "call-number": "10.1145/3491102.3517571",
    "collection-number": "367",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517571",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "eHMI., Chicken Game, Autonomous vehicles, Pedestrian Behavior, External communication",
    "number": "Article 367",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Effects of Pedestrian Behavior, Time Pressure, and Repeated Exposure on Crossing Decisions in Front of Automated Vehicles Equipped with External Communication",
    "URL": "https://doi.org/10.1145/3491102.3517571"
  },
  {
    "id": "10.1145/3491102.3502051",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Katharina Willamowski",
        "given": "Jutta"
      },
      {
        "family": "Gonzalez-Jimenez",
        "given": "Shreepriya"
      },
      {
        "family": "Legras",
        "given": "Christophe"
      },
      {
        "family": "Gallo",
        "given": "Danilo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Runners want to actively explore unknown environments without the fear of getting lost. We conducted a survey to better understand runners\u2019 needs and practices in this context. The survey results emphasized the interest in flexible exploration. To address this interest, we designed FlexNav, a system that supports exploratory running through flexible tours that link the best runnable zones in a neighbourhood. FlexNav provides adaptive navigation support enabling runners to follow such tours without continually getting disruptive directions. We tested it with runners to assess its usability. The results confirm the usefulness of the system and the users' preference for flexible tours over fully specified tours with turn-by-turn guidance. Our study highlights the subjective nature of runnable zones and the subtle balance between guidance and exploration.",
    "call-number": "10.1145/3491102.3502051",
    "collection-number": "368",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502051",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Sports, Route Recommendation, Pedestrian Navigation, Running",
    "number": "Article 368",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FlexNav: Flexible Navigation and Exploration through Connected Runnable Zones",
    "URL": "https://doi.org/10.1145/3491102.3502051"
  },
  {
    "id": "10.1145/3491102.3517487",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chen",
        "given": "Zhilong"
      },
      {
        "family": "Cao",
        "given": "Hancheng"
      },
      {
        "family": "Lan",
        "given": "Xiaochong"
      },
      {
        "family": "Lu",
        "given": "Zhicong"
      },
      {
        "family": "Li",
        "given": "Yong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The disadvantaged population is often underserved and marginalized in technology engagement: prior works show they are generally more reluctant and experience more barriers in adopting and engaging with mainstream technology. Here, we contribute to the HCI4D and ICTD literature through a novel \u201ccounter\u201d case study on Chinese social commerce (e.g., Pinduoduo), which 1) first prospers among the traditionally underserved community from developing regions ahead of the more technologically advantaged communities, and 2) has been heavily engaged by this community. Through 12 in-depth interviews with social commerce users from the traditionally underserved community in Chinese developing regions, we demonstrate how social commerce, acting as a \u201cvirtual bazaar\u201d, brings online the traditional offline socioeconomic lives the community has lived for ages, fits into the community\u2019s social, cultural, and economic context, and thus effectively promotes technology inclusivity. Our work provides novel insights and implications for building inclusive technology for the \u201cnext billion\u201d population.",
    "call-number": "10.1145/3491102.3517487",
    "collection-number": "369",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517487",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "underserved, bazaar, social commerce, inclusive, HCI4D",
    "number": "Article 369",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Beyond Virtual Bazaar: How Social Commerce Promotes Inclusivity for the Traditionally Underserved Community in Chinese Developing Regions",
    "URL": "https://doi.org/10.1145/3491102.3517487"
  },
  {
    "id": "10.1145/3491102.3517502",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mlynar",
        "given": "Jakub"
      },
      {
        "family": "Bahrami",
        "given": "Farzaneh"
      },
      {
        "family": "Ourednik",
        "given": "Andr\u00e9"
      },
      {
        "family": "Mutzner",
        "given": "Nico"
      },
      {
        "family": "Verma",
        "given": "Himanshu"
      },
      {
        "family": "Alavi",
        "given": "Hamed"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The current mechanisms that drive the development of AI technologies are widely criticized for being tech-oriented and market-led instead of stemming from societal challenges. In Human-Centered AI discourses, and more broadly in Human-Computer Interaction research, initiatives have been proposed to engage experts from various domains of social science in determining how AI should reach our societies, predominantly through informing the adoption policies. Our contribution, however, seeks a more essential role for social sciences, namely to introduce discursive standpoints around what we need AI to be. With a focus on the domain of urbanism, the specific goal has been to elicit \u2013 from interviews with 16 urban experts \u2013 the imaginaries of how AI can and should impact future cities. Drawing on the social science literature, we present how the notion of \u201cimaginary\u201d has essentially framed this research and how it could reveal an alternative vision of non-human intelligent actors in future cities.",
    "call-number": "10.1145/3491102.3517502",
    "collection-number": "370",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517502",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Artificial Intelligence, Sociology, Urban Sciences, Smart City",
    "number": "Article 370",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AI beyond Deus ex Machina \u2013 Reimagining Intelligence in Future Cities with Urban Experts",
    "URL": "https://doi.org/10.1145/3491102.3517502"
  },
  {
    "id": "10.1145/3491102.3517664",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Maheshwari",
        "given": "Aditi"
      },
      {
        "family": "Kumar Aggarwal",
        "given": "Abhay"
      },
      {
        "family": "Danielescu",
        "given": "Andreea"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As interest within the HCI community expands beyond urban settings, novel tools and devices are being developed to support more sustainable interactions with natural environments and inform conservation action. Yet little is known about the users of these devices, and how their requirements and priorities might affect the usability or operationalization of the devices in the real world. Using the \u2018e-seed\u2019, a biomimetic self-drilling interface as a \u2018research probe\u2019, we conducted a qualitative user study with 14 subject matter experts in areas like forestry and agriculture to understand the value and limits for devices and systems in ecological restoration and monitoring. We highlight unique challenges in existing ecological practices, opportunities for technological interventions, and the policies and economic constraints affecting the feasibility of such interventions. We present a set of critical design considerations for building and deploying novel devices in natural and semi-natural ecosystems and discuss implications for future research.",
    "call-number": "10.1145/3491102.3517664",
    "collection-number": "371",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517664",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sustainability, environmental monitoring, human-computer-nature interaction, natural ecosystems, ecological restoration, precision agriculture",
    "number": "Article 371",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing Tools and Interfaces for Ecological Restoration: An Investigation into the Opportunities and Constraints for Technological Interventions",
    "URL": "https://doi.org/10.1145/3491102.3517664"
  },
  {
    "id": "10.1145/3491102.3517464",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Khan",
        "given": "Hassan Ali"
      },
      {
        "family": "Iqbal",
        "given": "Hassan"
      },
      {
        "family": "Shahzad",
        "given": "Muhammad"
      },
      {
        "family": "Jin",
        "given": "Guoliang"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Ridesharing services do not make data of their availability (supply, utilization, idle time, and idle distance) and surge pricing publicly available. It limits the opportunities to study the spatiotemporal trends of the availability and surge pricing of these services. Only a few research studies conducted in North America analyzed these features for only Uber and Lyft. Despite the interesting observations, the results of prior works are not generalizable or reproducible because: i) the datasets collected in previous publications are spatiotemporally sensitive, i.e., previous works do not represent the current availability and surge pricing of ridesharing services in different parts of the world; and ii) the analyses presented in previous works are limited in scope (in terms of countries and ridesharing services they studied). Hence, prior works are not generally applicable to ridesharing services operating in different countries. This paper addresses the issue of ridesharing-data unavailability by presenting Ridesharing Measurement Suite (RMS). RMS removes the barrier of entry for analyzing the availability and surge pricing of ridesharing services for ridesharing users, researchers from various scientific domains, and regulators. RMS continuously collects the data of the availability and surge pricing of ridesharing services. It exposes real-time data of these services through i) graphical user interfaces and ii) public APIs to assist various stakeholders of these services and simplify the data collection and analysis process for future ridesharing research studies. To signify the utility of RMS, we deployed RMS to collect and analyze the availability and surge pricing data of 10 ridesharing services operating in nine countries for eight weeks in pre and during pandemic periods. Using the data collected and analyzed by RMS, we identify that previous articles miscalculated the utilization of ridesharing services as they did not count in the vehicles driving in multiple categories of the same service. We observe that during COVID-19, the supply of ridesharing services decreased by 54%, utilization of available vehicles increased by 6%, and a 5 \u00d7 increase in the surge frequency of services. We also find that surge occurs in a small geographical region, and its intensity reduces by 50% in about 0.5 miles away from the location of a surge. We present several other interesting observations on ridesharing services\u2019 availability and surge pricing.",
    "call-number": "10.1145/3491102.3517464",
    "collection-number": "372",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517464",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Surge, COVID 19, Gig economy, Uber, Ridesharing services",
    "number": "Article 372",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "RMS: Removing Barriers to Analyze the Availability and Surge Pricing of Ridesharing Services",
    "URL": "https://doi.org/10.1145/3491102.3517464"
  },
  {
    "id": "10.1145/3491102.3507656",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jones",
        "given": "Michael D"
      },
      {
        "family": "Von Feldt",
        "given": "Meredith"
      },
      {
        "family": "Andrus",
        "given": "Natalie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We found significant gaps in the climates and built environments used as settings for studies of HCI outdoors. The experience of using a computer outdoors varies widely depending on location-specific factors such as weather and the availability of electricity. We surveyed 699 papers from CHI venues and found 101 studies involving a person and a computer interacting outdoors for which we could determine the study location. We categorized each study location by climate using the K\u00f6ppen-Geiger scheme and by built environment using the Recreation Opportunity Spectrum. 91 of 101 studies took place in temperate or continental climates and 82 took place in urban settings. Emerging understanding of the ongoing impacts of climate change increases the importance of investigating HCI outdoors in a wider range of weather conditions. While some primitive natural settings have been preserved against development at great cost, we found no studies of HCI outdoors in those settings.",
    "call-number": "10.1145/3491102.3507656",
    "collection-number": "373",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3507656",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human-computer interaction, built environment, HCI outdoors",
    "number": "Article 373",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Outside Where? A Survey of Climates and Built Environments in Studies of HCI outdoors",
    "URL": "https://doi.org/10.1145/3491102.3507656"
  },
  {
    "id": "10.1145/3491102.3502037",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Das Swain",
        "given": "Vedant"
      },
      {
        "family": "Chen",
        "given": "Victor"
      },
      {
        "family": "Mishra",
        "given": "Shrija"
      },
      {
        "family": "Mattingly",
        "given": "Stephen M."
      },
      {
        "family": "Abowd",
        "given": "Gregory D."
      },
      {
        "family": "De Choudhury",
        "given": "Munmun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "When modeling passive data to infer individual mental wellbeing, a common source of ground truth is self-reports. But these tend to represent the psychological facet of mental states, which might not align with the physiological facet of that state. Our paper demonstrates that when what people \u201cfeel\u201d differs from what people \u201csay they feel\u201d, we witness a semantic gap that limits predictions. We show that predicting mental wellbeing with passive data (offline sensors or online social media) is related to how the ground-truth is measured (objective arousal or self-report). Features with psycho-social signals (e.g., language) were better at predicting self-reported anxiety and stress. Conversely, features with behavioral signals (e.g., sleep), were better at predicting stressful arousal. Regardless of the source of ground truth, integrating both signals boosted prediction. To reduce the semantic gap, we provide recommendations to evaluate ground truth measures and adopt parsimonious sensing.",
    "call-number": "10.1145/3491102.3502037",
    "collection-number": "374",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502037",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Activity Patterns, Social Media, Mental Wellbeing, Passive Sensing",
    "number": "Article 374",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Semantic Gap in Predicting Mental Wellbeing through Passive Sensing",
    "URL": "https://doi.org/10.1145/3491102.3502037"
  },
  {
    "id": "10.1145/3491102.3501852",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nguyen",
        "given": "Huy Anh"
      },
      {
        "family": "Hofman",
        "given": "Jake M"
      },
      {
        "family": "Goldstein",
        "given": "Daniel G"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Scientists and journalists strive to report numbers with high precision to keep readers well-informed. Our work investigates whether this practice can backfire due to the cognitive costs of processing multi-digit precise numbers. In a pre-registered randomized experiment, we presented readers with several news stories containing numbers in either precise or round versions. We then measured their ability to approximately recall these numbers and make estimates based on what they read. Our results revealed a counter-intuitive effect where reading round numbers helped people better approximate the precise values, while seeing precise numbers made them worse. We also conducted two surveys to elicit individual preferences for the ideal degree of rounding for numbers spanning seven orders of magnitude in various contexts. From the surveys, we found that people tended to prefer more precision when the rounding options contained only digits (e.g., \u201d2,500,000\u201d) than when they contained modifier terms (e.g., \u201d2.5 million\u201d). We conclude with a discussion of how these findings can be leveraged to enhance numeracy in digital content consumption.",
    "call-number": "10.1145/3491102.3501852",
    "collection-number": "375",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501852",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "number representation, estimation, experimentation, cognitive effect, recall, measurement, round numbers",
    "number": "Article 375",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Round Numbers Can Sharpen Cognition",
    "URL": "https://doi.org/10.1145/3491102.3501852"
  },
  {
    "id": "10.1145/3491102.3517477",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cockburn",
        "given": "Andy"
      },
      {
        "family": "Quinn",
        "given": "Philip"
      },
      {
        "family": "Gutwin",
        "given": "Carl"
      },
      {
        "family": "Chen",
        "given": "Zhe"
      },
      {
        "family": "Suwanaposee",
        "given": "Pang"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The effective use of assistive interfaces (i.e. those that offer suggestions or reform the user\u2019s input to match inferred intentions) depends on users making good decisions about whether and when to engage or ignore assistive features. However, prior work from economics and psychology shows systematic decision-making biases in which people overreact to low probability events and underreact to high probability events \u2013 modelled using a probability weighting function. We examine the theoretical implications of this probability weighting for interaction, including its suggestion that users will overuse inaccurate interface assistance and underuse accurate assistance. We then conduct a new analysis of data from a previously published study, quantifying the degree of bias users exhibited, and demonstrating conformance with these predictions. We discuss implications for design, including strategies that could be used to mitigate the deleterious effects of the observed biases.",
    "call-number": "10.1145/3491102.3517477",
    "collection-number": "376",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517477",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "prospect theory, overuse, probability weighting, underuse., Interface suggestions",
    "number": "Article 376",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Probability Weighting in Interactive Decisions: Evidence for Overuse of Bad Assistance, Underuse of Good Assistance",
    "URL": "https://doi.org/10.1145/3491102.3517477"
  },
  {
    "id": "10.1145/3491102.3517601",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bennett",
        "given": "Dan"
      },
      {
        "family": "Roudaut",
        "given": "Anne"
      },
      {
        "family": "Metatla",
        "given": "Oussama"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The philosophical construct readiness-to-hand describes focused, intuitive, tool use, and has been linked to tool-embodiment and immersion. The construct has been influential in HCI and design for decades, but researchers currently lack appropriate measures and tools to investigate it empirically. To support such empirical work we investigate the possibility of operationalising readiness-to-hand in measurements of multfractality in movement, building on recent work in cognitive science. We conduct two experiments (N=44, N=30) investigating multifractality in mouse movements during a computer game, replicating prior results and contributing new findings. Our results show that multifractality correlates with dimensions associated with readiness-to-hand, including skill and task-engagement, during tool breakdown, task learning and normal play. We describe future possibilities for the application of these methods in HCI, supporting such work by sharing scripts and data (https://osf.io/2hm9u/), and introducing a new data-driven approach to parameter selection.",
    "call-number": "10.1145/3491102.3517601",
    "collection-number": "377",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517601",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "engagement, cognitive science, complex systems, phenomenology, readiness to hand, embodiment, user experience",
    "number": "Article 377",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Multifractal Mice: Operationalising Dimensions of Readiness-to-hand via a Feature of Hand Movement",
    "URL": "https://doi.org/10.1145/3491102.3517601"
  },
  {
    "id": "10.1145/3491102.3501908",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rodrigues",
        "given": "Andr\u00e9"
      },
      {
        "family": "Nicolau",
        "given": "Hugo"
      },
      {
        "family": "Santos",
        "given": "Andr\u00e9"
      },
      {
        "family": "Branco",
        "given": "Diogo"
      },
      {
        "family": "Rainey",
        "given": "Jay"
      },
      {
        "family": "Verweij",
        "given": "David"
      },
      {
        "family": "Smeddinck",
        "given": "Jan David"
      },
      {
        "family": "Montague",
        "given": "Kyle"
      },
      {
        "family": "Guerreiro",
        "given": "Tiago"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Typing on mobile devices is a common and complex task. The act of typing itself thereby encodes rich information, such as the typing method, the context it is performed in, and individual traits of the person typing. Researchers are increasingly using a selection or combination of experience sampling and passive sensing methods in real-world settings to examine typing behaviours. However, there is limited understanding of the effects these methods have on measures of input speed, typing behaviours, compliance, perceived trust and privacy. In this paper, we investigate the tradeoffs of everyday data collection methods. We contribute empirical results from a four-week field study (N=26). Here, participants contributed by transcribing, composing, passively having sentences analyzed and reflecting on their contributions. We present a tradeoff analysis of these data collection methods, discuss their impact on text-entry applications, and contribute a flexible research platform for in the wild text-entry studies.",
    "call-number": "10.1145/3491102.3501908",
    "collection-number": "378",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501908",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "user experience, touch behaviours, trade-offs, in-the-wild, text-entry, data collection, performance",
    "number": "Article 378",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating the Tradeoffs of Everyday Text-Entry Collection Methods",
    "URL": "https://doi.org/10.1145/3491102.3501908"
  },
  {
    "id": "10.1145/3491102.3502075",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yan",
        "given": "Chuan"
      },
      {
        "family": "Chung",
        "given": "John Joon Young"
      },
      {
        "family": "Kiheon",
        "given": "Yoon"
      },
      {
        "family": "Gingold",
        "given": "Yotam"
      },
      {
        "family": "Adar",
        "given": "Eytan"
      },
      {
        "family": "Hong",
        "given": "Sungsoo Ray"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Creating digital comics involves multiple stages, some creative and some menial. For example, coloring a comic requires a labor-intensive stage known as \u2018flatting,\u2019 or masking segments of continuous color, as well as creative shading, lighting, and stylization stages. The use of AI can automate the colorization process, but early efforts have revealed limitations\u2014technical and UX\u2014to full automation. Via a formative study of professionals, we identify flatting as a bottleneck and key target of opportunity for human-guided AI-driven automation. Based on this insight, we built FlatMagic, an interactive, AI-driven flat colorization support tool for Photoshop. Our user studies found that using FlatMagic significantly reduced professionals\u2019 real and perceived effort versus their current practice. While participants effectively used FlatMagic, we also identified potential constraints in interactions with AI and partially automated workflows. We reflect on implications for comic-focused tools and the benefits and pitfalls of intermediate representations and partial automation in designing human-AI collaboration tools for professionals.",
    "call-number": "10.1145/3491102.3502075",
    "collection-number": "380",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502075",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human-AI collaboration, digital comic colorization, Intermediate Representation, system for professionals, automation and control",
    "number": "Article 380",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FlatMagic: Improving Flat Colorization through AI-driven Design for Digital Comic Professionals",
    "URL": "https://doi.org/10.1145/3491102.3502075"
  },
  {
    "id": "10.1145/3491102.3501895",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Masson",
        "given": "Damien"
      },
      {
        "family": "Vermeulen",
        "given": "Jo"
      },
      {
        "family": "Fitzmaurice",
        "given": "George"
      },
      {
        "family": "Matejka",
        "given": "Justin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Despite an abundance of carefully-crafted tutorials, trial-and-error remains many people\u2019s preferred way to learn complex software. Yet, approaches to facilitate trial-and-error (such as tooltips) have evolved very little since the 1980s. While existing mechanisms work well for simple software, they scale poorly to large feature-rich applications. In this paper, we explore new techniques to support trial-and-error in complex applications. We identify key benefits and challenges of trial-and-error, and introduce a framework with a conceptual model and design space. Using this framework, we developed three techniques: ToolTrack to keep track of trial-and-error progress; ToolTrip to go beyond trial-and-error of single commands by highlighting related commands that are frequently used together; and ToolTaste to quickly and safely try commands. We demonstrate how these techniques facilitate trial-and-error, as illustrated through a proof-of-concept implementation in the CAD software Fusion\u00a0360. We conclude by discussing possible scenarios and outline directions for future research on trial-and-error.",
    "call-number": "10.1145/3491102.3501895",
    "collection-number": "381",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501895",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "conceptual model, trial-and-error, learning by exploration, software learning, technique, design space",
    "number": "Article 381",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supercharging Trial-and-Error for Learning Complex Software Applications",
    "URL": "https://doi.org/10.1145/3491102.3501895"
  },
  {
    "id": "10.1145/3491102.3517486",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rajaram",
        "given": "Shwetha"
      },
      {
        "family": "Nebeling",
        "given": "Michael"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Prior work has demonstrated augmented reality\u2019s benefits to education, but current tools are difficult to integrate with traditional instructional methods. We present Paper Trail, an immersive authoring system designed to explore how to enable instructors to create AR educational experiences, leaving paper at the core of the interaction and enhancing it with various forms of digital media, animations for dynamic illustrations, and clipping masks to guide learning. To inform the system design, we developed five scenarios exploring the benefits that hand-held and head-worn AR can bring to STEM instruction and developed a design space of AR interactions enhancing paper based on these scenarios and prior work. Using the example of an AR physics handout, we assessed the system\u2019s potential with PhD-level instructors and its usability with XR design experts. In an elicitation study with high-school teachers, we study how Paper Trail could be used and extended to enable flexible use cases across various domains. We discuss benefits of immersive paper for supporting diverse student needs and challenges for making effective use of AR for learning.",
    "call-number": "10.1145/3491102.3517486",
    "collection-number": "382",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517486",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "STEM., augmented reality, educational technology, immersive paper",
    "number": "Article 382",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Paper Trail: An Immersive Authoring System for Augmented Reality Instructional Experiences",
    "URL": "https://doi.org/10.1145/3491102.3517486"
  },
  {
    "id": "10.1145/3491102.3501894",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ma",
        "given": "Jiaju"
      },
      {
        "family": "Wei",
        "given": "Li-Yi"
      },
      {
        "family": "Kazi",
        "given": "Rubaiat Habib"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Guided by the 12 principles of animation, stylization is a core 2D animation feature but has been utilized mainly by experienced animators. Although there are tools for stylizing 2D animations, creating stylized 3D animations remains a challenging problem due to the additional spatial dimension and the need for responsive actions like contact and collision. We propose a system that helps users create stylized casual 3D animations. A layered authoring interface is employed to balance between ease of use and expressiveness. Our surface level UI is a timeline sequencer that lets users add preset stylization effects such as squash and stretch and follow through to plain motions. Users can adjust spatial and temporal parameters to fine-tune these stylizations. These edits are propagated to our node-graph-based second level UI, in which the users can create custom stylizations after they are comfortable with the surface level UI. Our system also enables the stylization of interactions among multiple objects like force, energy, and collision. A pilot user study has shown that our fluid layered UI design allows for both ease of use and expressiveness better than existing tools.",
    "call-number": "10.1145/3491102.3501894",
    "collection-number": "383",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501894",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "3D, animation, stylization",
    "number": "Article 383",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Layered Authoring Tool for Stylized 3D animations",
    "URL": "https://doi.org/10.1145/3491102.3501894"
  },
  {
    "id": "10.1145/3491102.3501825",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Vivian"
      },
      {
        "family": "Chilton",
        "given": "Lydia B"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.",
    "call-number": "10.1145/3491102.3501825",
    "collection-number": "384",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501825",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design guidelines, prompt engineering., text-to-image, computational creativity, multimodal generative models, AI co-creation",
    "number": "Article 384",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models",
    "URL": "https://doi.org/10.1145/3491102.3501825"
  },
  {
    "id": "10.1145/3491102.3517582",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wu",
        "given": "Tongshuang"
      },
      {
        "family": "Terry",
        "given": "Michael"
      },
      {
        "family": "Cai",
        "given": "Carrie Jun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by \u201cunit-testing\u201d sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.",
    "call-number": "10.1145/3491102.3517582",
    "collection-number": "385",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517582",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human-AI Interaction, Natural Language Processing, Large Language Models",
    "number": "Article 385",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts",
    "URL": "https://doi.org/10.1145/3491102.3517582"
  },
  {
    "id": "10.1145/3491102.3501870",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jiang",
        "given": "Ellen"
      },
      {
        "family": "Toh",
        "given": "Edwin"
      },
      {
        "family": "Molina",
        "given": "Alejandra"
      },
      {
        "family": "Olson",
        "given": "Kristen"
      },
      {
        "family": "Kayacik",
        "given": "Claire"
      },
      {
        "family": "Donsbach",
        "given": "Aaron"
      },
      {
        "family": "Cai",
        "given": "Carrie J"
      },
      {
        "family": "Terry",
        "given": "Michael"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this paper, we present a natural language code synthesis tool, GenLine, backed by 1) a large generative language model and 2) a set of task-specific prompts that create or change code. To understand the user experience of natural language code synthesis with these new types of models, we conducted a user study in which participants applied GenLine to two programming tasks. Our results indicate that while natural language code synthesis can sometimes provide a magical experience, participants still faced challenges. In particular, participants felt that they needed to learn the model\u2019s \u201csyntax,\u201d despite their input being natural language. Participants also struggled to form an accurate mental model of the types of requests the model can reliably translate and developed a set of strategies to debug model input. From these findings, we discuss design implications for future natural language code synthesis tools built using large generative language models.",
    "call-number": "10.1145/3491102.3501870",
    "collection-number": "386",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501870",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "generative language models, code synthesis, prompt programming",
    "number": "Article 386",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Discovering the Syntax and Strategies of Natural Language Programming with Generative Language Models",
    "URL": "https://doi.org/10.1145/3491102.3501870"
  },
  {
    "id": "10.1145/3491102.3502073",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chen",
        "given": "Jieshan"
      },
      {
        "family": "Swearngin",
        "given": "Amanda"
      },
      {
        "family": "Wu",
        "given": "Jason"
      },
      {
        "family": "Barik",
        "given": "Titus"
      },
      {
        "family": "Nichols",
        "given": "Jeffrey"
      },
      {
        "family": "Zhang",
        "given": "Xiaoyi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Accurately recognizing icon types in mobile applications is integral to many tasks, including accessibility improvement, UI design search, and conversational agents. Existing research focuses on recognizing the most frequent icon types, but these technologies fail when encountering an unrecognized low-frequency icon. In this paper, we work towards complete coverage of icons in the wild. After annotating a large-scale icon dataset (327,879 icons) from iPhone apps, we found a highly uneven distribution: 98 common icon types covered 92.8% of icons, while 7.2% of icons were covered by more than 331 long-tail icon types. In order to label icons with widely varying occurrences in apps, our system uses an image classification model to recognize common icon types with an average of 3,000 examples each (96.3% accuracy) and applies a few-shot learning model to classify long-tail icon types with an average of 67 examples each (78.6% accuracy). Our system also detects contextual information that helps characterize icon semantics, including nearby text (95.3% accuracy) and modifier symbols added to the icon (87.4% accuracy). In a validation study with workers (n = 23), we verified the usefulness of our generated icon labels. The icon types supported by our work cover 99.5% of collected icons, improving on the previously highest 78% coverage in icon classification work.",
    "call-number": "10.1145/3491102.3502073",
    "collection-number": "387",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502073",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 387",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Complete Icon Labeling in Mobile Applications",
    "URL": "https://doi.org/10.1145/3491102.3502073"
  },
  {
    "id": "10.1145/3491102.3502030",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Mina"
      },
      {
        "family": "Liang",
        "given": "Percy"
      },
      {
        "family": "Yang",
        "given": "Qian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Large language models (LMs) offer unprecedented language generation capabilities and exciting opportunities for interaction design. However, their highly context-dependent capabilities are difficult to grasp and are often subjectively interpreted. In this paper, we argue that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs\u2019 generative capabilities. Exemplifying this approach, we present CoAuthor, a dataset designed for revealing GPT-3\u2019s capabilities in assisting creative and argumentative writing. CoAuthor captures rich interactions between 63 writers and four instances of GPT-3 across 1445 writing sessions. We demonstrate that CoAuthor can address questions about GPT-3\u2019s language, ideation, and collaboration capabilities, and reveal its contribution as a writing \u201ccollaborator\u201d under various definitions of good collaboration. Finally, we discuss how this work may facilitate a more principled discussion around LMs\u2019 promises and pitfalls in relation to interaction design. The dataset and an interface for replaying the writing sessions are publicly available at https://coauthor.stanford.edu.",
    "call-number": "10.1145/3491102.3502030",
    "collection-number": "388",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502030",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human-AI collaborative writing, language models, dataset, writing assistants., natural language generation, GPT-3, crowdsourcing",
    "number": "Article 388",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities",
    "URL": "https://doi.org/10.1145/3491102.3502030"
  },
  {
    "id": "10.1145/3491102.3517668",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nittala",
        "given": "Aditya Shekhar"
      },
      {
        "family": "Steimle",
        "given": "J\u00fcrgen"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Skin is a promising interaction medium and has been widely explored for mobile, and expressive interaction. Recent research in HCI has seen the development of Epidermal Computing Devices: ultra-thin and non-invasive devices which reside on the user\u2019s skin, offering intimate integration with the curved surfaces of the body, while having physical and mechanical properties that are akin to skin, expanding the horizon of on-body interaction. However, with rapid technological advancements in multiple disciplines, we see a need to synthesize the main open research questions and opportunities for the HCI community to advance future research in this area. By systematically analyzing Epidermal Devices contributed in the HCI community, physical sciences research and from our experiences in designing and building Epidermal Devices, we identify opportunities and challenges for advancing research across five themes. This multi-disciplinary synthesis enables multiple research communities to facilitate progression towards more coordinated endeavors for advancing Epidermal Computing.",
    "call-number": "10.1145/3491102.3517668",
    "collection-number": "389",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517668",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "epidermal devices, soft wearables, survey, wearable devices",
    "number": "Article 389",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Next Steps in Epidermal Computing: Opportunities and Challenges for Soft On-Skin Devices",
    "URL": "https://doi.org/10.1145/3491102.3517668"
  },
  {
    "id": "10.1145/3491102.3502119",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Takahashi",
        "given": "Ryo"
      },
      {
        "family": "Yukita",
        "given": "Wakako"
      },
      {
        "family": "Yokota",
        "given": "Tomoyuki"
      },
      {
        "family": "Someya",
        "given": "Takao"
      },
      {
        "family": "Kawahara",
        "given": "Yoshihiro"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Wearable devices for life-logging and healthcare have been studied, but the need for frequent charging imposes inconvenience for long-term use. Integrating textile-based wireless chargers (i.e., coil) into clothing enables sustainable wearable computing by charging the on-body devices in use. However, the electromagnetic field generated by conventional coil chargers strongly interferes with human body, and the high resistance of conductive threads leads to inefficient power delivery. This paper presents Meander Coil++, enabling safe, energy-efficient, and body-scale wireless power delivery. Meander Coil++ uses a wiring pattern that suppresses electromagnetic exposure to the human body without compromising power delivery performance and a liquid-metal-based low-loss conductive cord. With these advancements, Meander Coil++ transmits a few watts of power to on-body devices at 25% DC-to-DC efficiency while complying with international safety guidelines regarding electromagnetic exposure. We envision Meander Coil++ can maintain multiple devices on body for weeks beyond the confines of their small battery capacity.",
    "call-number": "10.1145/3491102.3502119",
    "collection-number": "390",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502119",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "liquid metal, knit, magnetic resonant coupling, wireless power transfer, coil",
    "number": "Article 390",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Meander Coil++:\u00a0A Body-scale Wireless Power Transmission Using Safe-to-body and Energy-efficient Transmitter Coil",
    "URL": "https://doi.org/10.1145/3491102.3502119"
  },
  {
    "id": "10.1145/3491102.3502142",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Jin Hee (Heather)"
      },
      {
        "family": "Patil",
        "given": "Shreyas Dilip"
      },
      {
        "family": "Matson",
        "given": "Sarina"
      },
      {
        "family": "Conroy",
        "given": "Melissa"
      },
      {
        "family": "Kao",
        "given": "Cindy Hsin-Liu"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present KnitSkin, a bio-inspired sleeve that can traverse diverse cylindrical terrains, ranging from a user\u2019s forearm at a wearable scale, to pipes and tree branches at an environmental scale. Fabricated with a machine knitted substrate, the sleeve configures a stepped array of knitted scales that exhibit anisotropic friction. Coupled with the extension of actuators enclosed in the sleeve, the scales enable effective directional locomotion on cylindrical surfaces with varying slopes, textures, and curvatures. KnitSkin\u2019s substrates are characterized by scales whose geometries and materials can be fine-tuned and channels that can accommodate diverse actuators. We introduce the design elements of KnitSkin in which we characterize a series of substrate parameters and their resulting anisotropic behaviors. In evaluating the locomotion, we examine the variables associated with the surface and actuator characteristics. KnitSkin obtains diverse applications across different scales, including wearable interfaces, industrial pipe-monitoring, to agricultural robots.",
    "call-number": "10.1145/3491102.3502142",
    "collection-number": "391",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502142",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Machine Knitting, Mobile Robots, Smart Textiles, Wearable Robots",
    "number": "Article 391",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "KnitSkin: Machine-Knitted Scaled Skin for Locomotion",
    "URL": "https://doi.org/10.1145/3491102.3502142"
  },
  {
    "id": "10.1145/3491102.3517590",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Schauss",
        "given": "Gabriella"
      },
      {
        "family": "Arquilla",
        "given": "Katya"
      },
      {
        "family": "Anderson",
        "given": "Allison"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Wearable biosignal monitoring systems are becoming increasingly ubiquitous as tools for autonomous health monitoring and other real-world applications. Despite the continual advancements in this field, anthropometric considerations for women\u2019s form are often overlooked in the design process, making systems ill fit and less effective. In this paper, we present a full garment assembly, ARGONAUT, with integrated textile electrocardiogram (ECG) electrodes in a 3-lead configuration that is designed specifically for women\u2019s form. Through the exploration of materials, anthropometry, and garment assembly, we designed and tested ARGONAUT against the laboratory standard to determine performance through R-peak detection and noise interference. We investigated common issues faced when designing a wearable ECG garment, such as fit, motion artifact mitigation, and social wearability, to develop a dynamic design process that can be used to expand the advancing technology sensor integrated garments to all individuals in order to allow for equal access to potential health benefits.",
    "call-number": "10.1145/3491102.3517590",
    "collection-number": "392",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517590",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Electrocardiogram (ECG), iterative design, smart textiles, technological integration, motion artifact",
    "number": "Article 392",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ARGONAUT: An Inclusive Design Process for Wearable Health Monitoring Systems",
    "URL": "https://doi.org/10.1145/3491102.3517590"
  },
  {
    "id": "10.1145/3491102.3502096",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Morita",
        "given": "Takafumi"
      },
      {
        "family": "Kuwajima",
        "given": "Yu"
      },
      {
        "family": "Minaminosono",
        "given": "Ayato"
      },
      {
        "family": "Maeda",
        "given": "Shingo"
      },
      {
        "family": "Kakehi",
        "given": "Yasuaki"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In recent years, actuators that handle fluids such as gases and liquids have been attracting attention for their applications in soft robots and shape-changing interfaces. In the field of HCI, there have been various inflatable prototyping tools that utilize air control, however, very few tools for liquid control have been developed. In this study, we propose HydroMod, new constructive modules that can easily generate liquid flow and programmatically control liquid flow, with the aim of lowering the barrier to entry for prototyping with liquids. HydroMod consists of palm-sized small modules, which can generate liquid flow with the electrohydrodynamics (EHD) phenomenon by simply connecting the modules. Moreover, users can configure and control the flow path by simply recombining the modules. In this paper, we propose the design of the modules, evaluate the performance of HydroMod as a fluid system, and also show the possible application scenarios of fluid prototyping using this system.",
    "call-number": "10.1145/3491102.3502096",
    "collection-number": "393",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502096",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Programmable Materials, Wearables, Electrohydrodynamics, Fluid Interface, Toolkit, Prototyping",
    "number": "Article 393",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "HydroMod : Constructive Modules for Prototyping Hydraulic Physical Interfaces",
    "URL": "https://doi.org/10.1145/3491102.3502096"
  },
  {
    "id": "10.1145/3491102.3517624",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cui",
        "given": "Yichao"
      },
      {
        "family": "Yamashita",
        "given": "Naomi"
      },
      {
        "family": "Liu",
        "given": "Mingjie"
      },
      {
        "family": "Lee",
        "given": "Yi-Chieh"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sexual-minority women (SMWs) in China are often subject to strong stigmatization and tend to have limited opportunities to connect with other SMWs in offline contexts. Although dating apps help them connect and seek social support, little is known about SMWs\u2019 practices of self-disclosure and connection-building through those apps. To address this gap, we interviewed 43 SMW dating-app users in China. We found that these SMWs developed distinctive self-disclosure strategies, such as posting non-facial photos and implicitly disclosing their whereabouts by blending location information into photos that only those in the know could understand, to avoid interference from aggressive acquaintances and other risks of unintentional disclosure of their SMW identities. Moreover, they used dating apps not only to recognize other SMWs offline and build relationships with them, but to exchange emotional support in the process of SMW identity development. Our findings have design implications for supporting SMWs and improving their online dating experiences.",
    "call-number": "10.1145/3491102.3517624",
    "collection-number": "394",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517624",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Relationship Building, Online Dating, Sexual-minority Women",
    "number": "Article 394",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cSo Close, yet So Far\u201d: Exploring Sexual-minority Women\u2019s Relationship-building via Online Dating in China",
    "URL": "https://doi.org/10.1145/3491102.3517624"
  },
  {
    "id": "10.1145/3491102.3517627",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Brooke",
        "given": "Sian JM"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper investigates how the conceptions of gender in memes are central to socializing at hackathons. Drawing on a multi-sited ethnography of seven hackathons, I provide insight into how references to memes and informal technology culture shape interaction in local manifestations of this culture. The contribution of this paper is twofold. First, I show how vocabularies and artifacts of technology culture move between on and offline spaces. These findings have implications for HCI research that investigates questions of materiality in computer-mediated communication. Second, I show how even the mundane memes of technology culture can reveal the toxic masculinity and ideology of Incels. By tying these internet memes to a physical context, I unpack how humor can reveal and perpetuate the enduring masculine dominance of technology. I end with recommendations for increasing inclusivity at hackathons, based on how HCI is uniquely positioned to understand how Internet symbols and interactions manifest offline.",
    "call-number": "10.1145/3491102.3517627",
    "collection-number": "395",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517627",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Sexism, Programming, Gender, Memes, Ethnography, Culture, Hackathons",
    "number": "Article 395",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Nice Guys, Virgins, and Incels: Gender in Remixing and Sharing Memes at Hackathons",
    "URL": "https://doi.org/10.1145/3491102.3517627"
  },
  {
    "id": "10.1145/3491102.3502106",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "McKay",
        "given": "Dana"
      },
      {
        "family": "Zhang",
        "given": "Huiwen"
      },
      {
        "family": "Buchanan",
        "given": "George"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Conference authorship, attendance and presentation is a key measure of quality in the HCI academic, yet we know conferences are not equally accessible for reasons that have nothing to do with quality. In this paper we examine two axes of diversity: gender, and geographic location (of both authors and conferences) and examine how they affect participation at major HCI conferences. Diversity in a group is associated with better outcomes from its work, and HCI has made numerous contributions to increasing representation in other communities. Reflecting on our own situation can produce recommendations for the planning of future HCI conferences, and identify challenges of representation that the HCI community should endeavor to address.",
    "call-number": "10.1145/3491102.3502106",
    "collection-number": "396",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502106",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "geography, gender, authorship in HCI, diversity, Equity",
    "number": "Article 396",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Who am I, and who are you, and who are we? A Scientometric Analysis of Gender and Geography in HCI",
    "URL": "https://doi.org/10.1145/3491102.3502106"
  },
  {
    "id": "10.1145/3491102.3517524",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ma",
        "given": "Ning F."
      },
      {
        "family": "Rivera",
        "given": "Veronica A."
      },
      {
        "family": "Yao",
        "given": "Zheng"
      },
      {
        "family": "Yoon",
        "given": "Dongwook"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Women make up approximately half of the workforce in ride-hailing, food delivery, and home service platforms in North America. While studies have reported that gig workers face bias, harassment, and a gender pay gap, we have limited understanding of women\u2019s perspectives of these issues and their coping mechanisms. We interviewed 20 women gig workers to hear their unique experiences with these challenges. We found that gig platforms are gender-agnostic, meaning they do not acknowledge women\u2019s experiences and the value they bring. By not enforcing anti-harassment policies in design, gig platforms also leave women workers vulnerable to bias and harassment. Due to the lack of support for immediate actions and in fear of losing access to work, women workers \u201cbrush off\u201d harassment. In addition, the platforms\u2019 dispatching and recommendation mechanisms do not acknowledge women\u2019s contributions in perceived safety for customers and social support for peer workers.",
    "call-number": "10.1145/3491102.3517524",
    "collection-number": "397",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517524",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Labor, Gender, Uber, Harassment, TaskRabbit, Bias, Women, DoorDash, Gig work",
    "number": "Article 397",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cBrush it Off\u201d: How Women Workers Manage and Cope with Bias and Harassment in Gender-agnostic Gig Platforms",
    "URL": "https://doi.org/10.1145/3491102.3517524"
  },
  {
    "id": "10.1145/3491102.3502114",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sun",
        "given": "Jiao"
      },
      {
        "family": "Wu",
        "given": "Tongshuang"
      },
      {
        "family": "Jiang",
        "given": "Yue"
      },
      {
        "family": "Awalegaonkar",
        "given": "Ronil"
      },
      {
        "family": "Lin",
        "given": "Xi Victoria"
      },
      {
        "family": "Yang",
        "given": "Diyi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People write personalized greeting cards on various occasions. While prior work has studied gender roles in greeting card messages, systematic analysis at scale and tools for raising the awareness of gender stereotyping remain under-investigated. To this end, we collect a large greeting card message corpus covering three different occasions (birthday, Valentine\u2019s Day and wedding) from three sources (exemplars from greeting message websites, real-life greetings from social media and language model generated ones). We uncover a wide range of gender stereotypes in this corpus via topic modeling, odds ratio and Word Embedding Association Test (WEAT). We further conduct a survey to understand people\u2019s perception of gender roles in messages from this corpus and if gender stereotyping is a concern. The results show that people want to be aware of gender roles in the messages, but remain unconcerned unless the perceived gender roles conflict with the recipient\u2019s true personality. In response, we developed GreetA, an interactive visualization and writing assistant tool to visualize fine-grained topics in greeting card messages drafted by the users and the associated gender perception scores, but without suggesting text changes as an intervention.",
    "call-number": "10.1145/3491102.3502114",
    "collection-number": "398",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502114",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "greeting card messages, visualization system, gender role awareness",
    "number": "Article 398",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Pretty Princess vs. Successful Leader: Gender Roles in Greeting Card Messages",
    "URL": "https://doi.org/10.1145/3491102.3502114"
  },
  {
    "id": "10.1145/3491102.3517531",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Abdrabou",
        "given": "Yasmeen"
      },
      {
        "family": "Sch\u00fctte",
        "given": "Johannes"
      },
      {
        "family": "Shams",
        "given": "Ahmed"
      },
      {
        "family": "Pfeuffer",
        "given": "Ken"
      },
      {
        "family": "Buschek",
        "given": "Daniel"
      },
      {
        "family": "Khamis",
        "given": "Mohamed"
      },
      {
        "family": "Alt",
        "given": "Florian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "A significant drawback of text passwords for end-user authentication is password reuse. We propose a novel approach to detect password reuse by leveraging gaze as well as typing behavior and study its accuracy. We collected gaze and typing behavior from 49 users while creating accounts for 1) a webmail client and 2) a news website. While most participants came up with a new password, 32% reported having reused an old password when setting up their accounts. We then compared different ML models to detect password reuse from the collected data. Our models achieve an accuracy of up to 87.7% in detecting password reuse from gaze, 75.8% accuracy from typing, and 88.75% when considering both types of behavior. We demonstrate that using gaze, password reuse can already be detected during the registration process, before users entered their password. Our work paves the road for developing novel interventions to prevent password reuse.",
    "call-number": "10.1145/3491102.3517531",
    "collection-number": "400",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517531",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Gaze Behavior, Machine Learning, Passwords, Keystroke Dynamics",
    "number": "Article 400",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dYour Eyes Tell You Have Used This Password Before\u201d: Identifying Password Reuse from Gaze and Keystroke Dynamics",
    "URL": "https://doi.org/10.1145/3491102.3517531"
  },
  {
    "id": "10.1145/3491102.3501980",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Pearson",
        "given": "Jennifer"
      },
      {
        "family": "Bailey",
        "given": "Gavin"
      },
      {
        "family": "Robinson",
        "given": "Simon"
      },
      {
        "family": "Jones",
        "given": "Matt"
      },
      {
        "family": "Owen",
        "given": "Tom"
      },
      {
        "family": "Zhang",
        "given": "Chi"
      },
      {
        "family": "Reitmaier",
        "given": "Thomas"
      },
      {
        "family": "Steer",
        "given": "Cameron"
      },
      {
        "family": "Carter",
        "given": "Anna"
      },
      {
        "family": "Sahoo",
        "given": "Deepak Ranjan"
      },
      {
        "family": "Raju",
        "given": "Dani Kalarikalayil"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "What do pedestrian crossings, ATMs, elevators and ticket machines have in common? These are just a few of the ubiquitous yet essential elements of public-space infrastructure that rely on physical buttons or touchscreens; common interactions that, until recently, were considered perfectly safe to perform. This work investigates how we might integrate touchless technologies into public-space infrastructure in order to minimise physical interaction with shared devices in light of the ongoing COVID-19 pandemic. Drawing on an ethnographic exploration into how public utilities are being used, adapted or avoided, we developed and evaluated a suite of technology probes that can be either retrofitted into, or replace, these services. In-situ community deployments of our probes demonstrate strong uptake and provide insight into how hands-free technologies can be adapted and utilised for the public domain; and, in turn, used to inform the future of walk-up-and use public technologies.",
    "call-number": "10.1145/3491102.3501980",
    "collection-number": "401",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501980",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "prototyping/implementation., Public displays, field studies",
    "number": "Article 401",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Can\u2019t Touch This: Rethinking Public Technology in a COVID-19 Era",
    "URL": "https://doi.org/10.1145/3491102.3501980"
  },
  {
    "id": "10.1145/3491102.3502022",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Serrano",
        "given": "Marcos"
      },
      {
        "family": "Finch",
        "given": "Jolee"
      },
      {
        "family": "Irani",
        "given": "Pourang"
      },
      {
        "family": "Lucero",
        "given": "Andr\u00e9s"
      },
      {
        "family": "Roudaut",
        "given": "Anne"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Advanced technologies are increasingly enabling the creation of interactive devices with non-rectangular form-factors but it is currently unclear what alternative form-factors are desirable for end-users. We contribute an understanding of the interplay between the rationale for the form factors of such devices and their interactive content through think-aloud design sessions in which participants could mold devices as they wished using clay. We analysed their qualitative reflections on how the shapes affected interaction. Using thematic analysis, we identified shape features desirable on handheld freeform devices and discuss the particularity of three themes central to the choice of form factors: freeform dexterity, shape features discoverability and shape adaptability (to the task and context). In a second study following the same experimental set-up, we focused on the trade off between dexterity and discoverability and the relation to the concept of affordance. Our work reveals the shape features that impact the most the choice of grasps on freeform devices from which we derive design guidelines for the design of such devices.",
    "call-number": "10.1145/3491102.3502022",
    "collection-number": "402",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502022",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Freeform interfaces, device form factor, handheld devices",
    "number": "Article 402",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mold-It: Understanding how Physical Shapes affect Interaction with Handheld Freeform Devices",
    "URL": "https://doi.org/10.1145/3491102.3502022"
  },
  {
    "id": "10.1145/3491102.3501835",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wampfler",
        "given": "Rafael"
      },
      {
        "family": "Klingler",
        "given": "Severin"
      },
      {
        "family": "Solenthaler",
        "given": "Barbara"
      },
      {
        "family": "Schinazi",
        "given": "Victor R."
      },
      {
        "family": "Gross",
        "given": "Markus"
      },
      {
        "family": "Holz",
        "given": "Christian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Knowledge of users\u2019 affective states can improve their interaction with smartphones by providing more personalized experiences (e.g., search results and news articles). We present an affective state classification model based on data gathered on smartphones in real-world environments. From touch events during keystrokes and the signals from the inertial sensors, we extracted two-dimensional heat maps as input into a convolutional neural network to predict the affective states of smartphone users. For evaluation, we conducted a data collection in the wild with 82 participants over 10\u00a0weeks. Our model accurately predicts three levels (low, medium, high) of valence (AUC up to 0.83), arousal (AUC up to 0.85), and dominance (AUC up to 0.84). We also show that using the inertial sensor data alone, our model achieves a similar performance (AUC up to 0.83), making our approach less privacy-invasive. By personalizing our model to the user, we show that performance increases by an additional 0.07\u00a0AUC.",
    "call-number": "10.1145/3491102.3501835",
    "collection-number": "403",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501835",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Deep Learning, Classification, Smartphone, Affective Computing",
    "number": "Article 403",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Affective State Prediction from Smartphone Touch and Sensor Data in the Wild",
    "URL": "https://doi.org/10.1145/3491102.3501835"
  },
  {
    "id": "10.1145/3491102.3502137",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Thakkar",
        "given": "Parth Kirankumar"
      },
      {
        "family": "He",
        "given": "Shijing"
      },
      {
        "family": "Xu",
        "given": "Shiyu"
      },
      {
        "family": "Huang",
        "given": "Danny Yuxing"
      },
      {
        "family": "Yao",
        "given": "Yaxing"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The opaque data practices in smart home devices have raised significant privacy concerns for smart home users and bystanders. One way to learn about the data practices is through privacy-related notifications. However, how to deliver these notifications to users and bystanders and increase their awareness of data practices is not clear. We surveyed 136 users and 123 bystanders to understand their preferences of receiving privacy-related notifications in smart homes. We further collected their responses to four mechanisms that improve privacy awareness (e.g., Data Dashboard) as well as their selections of mechanisms in four different scenarios (e.g., friend visiting). Our results showed the pros and cons of each privacy awareness mechanism, e.g., Data Dashboard can help reduce bystanders\u2019 dependence on users. We also found some unique benefits of each mechanism (e.g., Ambient Light could provide unobtrusive privacy awareness). We summarized four key design dimensions for future privacy awareness mechanisms design.",
    "call-number": "10.1145/3491102.3502137",
    "collection-number": "404",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502137",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Smart Homes, Multi-Stakeholder, Bystanders, Notifications, Privacy, Privacy Awareness",
    "number": "Article 404",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt would probably turn into a social faux-pas\u201d: Users\u2019 and Bystanders\u2019 Preferences of Privacy Awareness Mechanisms in Smart Homes",
    "URL": "https://doi.org/10.1145/3491102.3502137"
  },
  {
    "id": "10.1145/3491102.3517515",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ramokapane",
        "given": "Kopo Marvin"
      },
      {
        "family": "Bird",
        "given": "Caroline"
      },
      {
        "family": "Rashid",
        "given": "Awais"
      },
      {
        "family": "Chitchyan",
        "given": "Ruzanna"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Home energy management systems (HEMS) offer control and the ability to manage energy, generating and collecting energy consumption data at the most detailed level. However, data at this level poses various privacy concerns, including, for instance, profiling consumer behaviors and large-scale surveillance. The question of how utility providers can get value from such data without infringing consumers\u2019 privacy has remained under-investigated. We address this gap by exploring the pro-sharing attitudes and privacy perceptions of 30 HEMS users and non-users through an interview study. While participants are concerned about data misuse and stigmatization, our analysis also reveals that incentives, altruism, trust, security and privacy, transparency and accountability encourage data sharing. From this analysis, we derive privacy design strategies for HEMS that can both improve privacy and engender adoption.",
    "call-number": "10.1145/3491102.3517515",
    "collection-number": "405",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517515",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Smart Home, Smart Home Energy Management Systems, Energy Data, User Perceptions, Security and Privacy protections",
    "number": "Article 405",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Privacy Design Strategies for Home Energy Management Systems (HEMS)",
    "URL": "https://doi.org/10.1145/3491102.3517515"
  },
  {
    "id": "10.1145/3491102.3517652",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Alsoubai",
        "given": "Ashwaq"
      },
      {
        "family": "Ghaiumy Anaraky",
        "given": "Reza"
      },
      {
        "family": "Li",
        "given": "Yao"
      },
      {
        "family": "Page",
        "given": "Xinru"
      },
      {
        "family": "Knijnenburg",
        "given": "Bart"
      },
      {
        "family": "Wisniewski",
        "given": "Pamela J."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We conducted a user study with 380 Android users, profiling them according to two key privacy behaviors: the number of apps installed and the Dangerous permissions granted to those apps. We identified four unique privacy profiles: 1) Privacy Balancers (49.74% of participants), 2) Permission Limiters (28.68%), 3) App Limiters (14.74%), and 4) the Privacy Unconcerned (6.84%). App and Permission Limiters were significantly more concerned about perceived surveillance than Privacy Balancers and the Privacy Unconcerned. App Limiters had the lowest number of apps installed on their devices with the lowest intention of using apps and sharing information with them, compared to Permission Limiters who had the highest number of apps installed and reported higher intention to share information with apps. The four profiles reflect the differing privacy management strategies, perceptions, and intentions of Android users that go beyond the binary decision to share or withhold information via mobile apps.",
    "call-number": "10.1145/3491102.3517652",
    "collection-number": "406",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517652",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "privacy preferences, users profiling, user behaviors, smartphone users\u2019 privacy",
    "number": "Article 406",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Permission vs. App Limiters: Profiling Smartphone Users to Understand Differing Strategies for Mobile Privacy Management",
    "URL": "https://doi.org/10.1145/3491102.3517652"
  },
  {
    "id": "10.1145/3491102.3517504",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Frik",
        "given": "Alisa"
      },
      {
        "family": "Kim",
        "given": "Juliann"
      },
      {
        "family": "Sanchez",
        "given": "Joshua Rafael"
      },
      {
        "family": "Ma",
        "given": "Joanne"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With the growing smartphone penetration rate, smartphone settings remain one of the main models for information privacy and security controls. Yet, their usability is largely understudied, especially with respect to the usability impact on underrepresented socio-economic and low-tech groups. In an online survey with 178 users, we find that many people are not aware of smartphone privacy and security settings, their defaults, and have not configured them in the past, but are willing to do it in the future. Some participants perceive low self-efficacy and expect difficulties and usability issues with configuring those settings. Finally, we find that certain socio-demographic groups are more vulnerable to risks and feel less prepared to use smartphone settings to protect their online privacy and security.",
    "call-number": "10.1145/3491102.3517504",
    "collection-number": "407",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517504",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "SES, self-efficacy, information architecture, cognitive interviews, security settings, digital divide, Privacy settings",
    "number": "Article 407",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Users\u2019 Expectations About and Use of Smartphone Privacy and Security Settings",
    "URL": "https://doi.org/10.1145/3491102.3517504"
  },
  {
    "id": "10.1145/3491102.3501823",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "G\u00f6rtler",
        "given": "Jochen"
      },
      {
        "family": "Hohman",
        "given": "Fred"
      },
      {
        "family": "Moritz",
        "given": "Dominik"
      },
      {
        "family": "Wongsuphasawat",
        "given": "Kanit"
      },
      {
        "family": "Ren",
        "given": "Donghao"
      },
      {
        "family": "Nair",
        "given": "Rahul"
      },
      {
        "family": "Kirchner",
        "given": "Marc"
      },
      {
        "family": "Patel",
        "given": "Kayur"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The confusion matrix, a ubiquitous visualization for helping people evaluate machine learning models, is a tabular layout that compares predicted class labels against actual class labels over all data instances. We conduct formative research with machine learning practitioners at Apple and find that conventional confusion matrices do not support more complex data-structures found in modern-day applications, such as hierarchical and multi-output labels. To express such variations of confusion matrices, we design an algebra that models confusion matrices as probability distributions. Based on this algebra, we develop Neo, a visual analytics system that enables practitioners to flexibly author and interact with hierarchical and multi-output confusion matrices, visualize derived metrics, renormalize confusions, and share matrix specifications. Finally, we demonstrate Neo\u2019s utility with three model evaluation scenarios that help people better understand model performance and reveal hidden confusions.",
    "call-number": "10.1145/3491102.3501823",
    "collection-number": "408",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501823",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "machine learning, Confusion matrices, interactive systems, visual analytics, model evaluation",
    "number": "Article 408",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Neo: Generalizing Confusion Matrix Visualization to Hierarchical and Multi-Output Labels",
    "URL": "https://doi.org/10.1145/3491102.3501823"
  },
  {
    "id": "10.1145/3491102.3502048",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Haotian"
      },
      {
        "family": "Wang",
        "given": "Yong"
      },
      {
        "family": "Wu",
        "given": "Aoyu"
      },
      {
        "family": "Wei",
        "given": "Huan"
      },
      {
        "family": "Qu",
        "given": "Huamin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With the wide usage of data visualizations, a huge number of Scalable Vector Graphic\u00a0(SVG)-based visualizations have been created and shared online. Accordingly, there has been an increasing interest in exploring how to retrieve perceptually similar visualizations from a large corpus, since it can benefit various downstream applications such as visualization recommendation. Existing methods mainly focus on the visual appearance of visualizations by regarding them as bitmap images. However, the structural information intrinsically existing in SVG-based visualizations is ignored. Such structural information can delineate the spatial and hierarchical relationship among visual elements, and characterize visualizations thoroughly from a new perspective. This paper presents a structure-aware method to advance the performance of visualization retrieval by collectively considering both the visual and structural information. We extensively evaluated our approach through quantitative comparisons, a user study and case studies. The results demonstrate the effectiveness of our approach and its advantages over existing methods.",
    "call-number": "10.1145/3491102.3502048",
    "collection-number": "409",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502048",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Visualization Retrieval, Visualization Similarity, Representation Learning, Visualization Embedding, Data Visualization",
    "number": "Article 409",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Structure-aware Visualization Retrieval",
    "URL": "https://doi.org/10.1145/3491102.3502048"
  },
  {
    "id": "10.1145/3491102.3517618",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wu",
        "given": "Aoyu"
      },
      {
        "family": "Tong",
        "given": "Wai"
      },
      {
        "family": "Li",
        "given": "Haotian"
      },
      {
        "family": "Moritz",
        "given": "Dominik"
      },
      {
        "family": "Wang",
        "given": "Yong"
      },
      {
        "family": "Qu",
        "given": "Huamin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data visualizations are created and shared on the web at an unprecedented speed, raising new needs and questions for processing and analyzing visualizations after they have been generated and digitized. However, existing formalisms focus on operating on a single visualization instead of multiple visualizations, making it challenging to perform analysis tasks such as sorting and clustering visualizations. Through a systematic analysis of previous work, we abstract visualization-related tasks into mathematical operators such as union and propose a design space of visualization operations. We realize the design by developing ComputableViz, a library that supports operations on multiple visualization specifications. To demonstrate its usefulness and extensibility, we present multiple usage scenarios concerning processing and analyzing visualization, such as generating visualization embeddings and automatically making visualizations accessible. We conclude by discussing research opportunities and challenges for managing and exploiting the massive visualizations on the web.",
    "call-number": "10.1145/3491102.3517618",
    "collection-number": "410",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517618",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Data Model, Visualization, Visualization Library",
    "number": "Article 410",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ComputableViz: Mathematical Operators as a Formalism for Visualisation Processing and Analysis",
    "URL": "https://doi.org/10.1145/3491102.3517618"
  },
  {
    "id": "10.1145/3491102.3501891",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bao",
        "given": "Calvin S."
      },
      {
        "family": "Li",
        "given": "Siyao"
      },
      {
        "family": "Flores",
        "given": "Sarah G"
      },
      {
        "family": "Correll",
        "given": "Michael"
      },
      {
        "family": "Battle",
        "given": "Leilani"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The promise of visualization recommendation systems is that analysts will be automatically provided with relevant and high-quality visualizations that will reduce the work of manual exploration or chart creation. However, little research to date has focused on what analysts value in the design of visualization recommendations. We interviewed 18 analysts in the public health sector and explored how they made sense of a popular in-domain dataset1 in service of generating visualizations to recommend to others. We also explored how they interacted with a corpus of both automatically- and manually-generated visualization recommendations, with the goal of uncovering how the design values of these analysts are reflected in current visualization recommendation systems. We find that analysts champion simple charts with clear takeaways that are nonetheless connected with existing semantic information or domain hypotheses. We conclude by recommending that visualization recommendation designers explore ways of integrating context and expectation into their systems.",
    "call-number": "10.1145/3491102.3501891",
    "collection-number": "411",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501891",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "algorithmic trust, recommendation source, Visualization recommendation systems, automation",
    "number": "Article 411",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Recommendations for Visualization Recommendations: Exploring Preferences and Priorities in Public Health",
    "URL": "https://doi.org/10.1145/3491102.3501891"
  },
  {
    "id": "10.1145/3491102.3517648",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cao",
        "given": "Yu-Rong"
      },
      {
        "family": "Li",
        "given": "Xiao-Han"
      },
      {
        "family": "Pan",
        "given": "Jia-Yu"
      },
      {
        "family": "Lin",
        "given": "Wen-Chieh"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data exploration systems have become popular tools with which data analysts and others can explore raw data and organize their observations. However, users of such systems who are unfamiliar with their datasets face several challenges when trying to extract data events of interest to them. Those challenges include progressively discovering informative charts, organizing them into a logical order to depict a meaningful fact, and arranging one or more facts to illustrate a data event. To alleviate them, we propose VisGuide\u2014a data exploration system that generates personalized recommendations to aid users\u2019 discovery of data events in breadth and depth by incrementally learning their data exploration preferences and recommending meaningful charts tailored to them. As well as user preferences, VisGuide\u2019s recommendations simultaneously consider sequence organization and chart presentation. We conducted two user studies to evaluate 1) the usability of VisGuide and 2) user satisfaction with its recommendation system. The results of those studies indicate that VisGuide can effectively help users create coherent and user-oriented visualization trees that represent meaningful data events.",
    "call-number": "10.1145/3491102.3517648",
    "collection-number": "412",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517648",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Visualization Recommendation, Visualization Sequencing, Visualization Trees",
    "number": "Article 412",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "VisGuide: User-Oriented Recommendations for Data Event Extraction",
    "URL": "https://doi.org/10.1145/3491102.3517648"
  },
  {
    "id": "10.1145/3491102.3517460",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Saha",
        "given": "Manaswi"
      },
      {
        "family": "Patil",
        "given": "Siddhant"
      },
      {
        "family": "Cho",
        "given": "Emily"
      },
      {
        "family": "Cheng",
        "given": "Evie Yu-Yen"
      },
      {
        "family": "Horng",
        "given": "Chris"
      },
      {
        "family": "Chauhan",
        "given": "Devanshi"
      },
      {
        "family": "Kangas",
        "given": "Rachel"
      },
      {
        "family": "McGovern",
        "given": "Richard"
      },
      {
        "family": "Li",
        "given": "Anthony"
      },
      {
        "family": "Heer",
        "given": "Jeffrey"
      },
      {
        "family": "Froehlich",
        "given": "Jon E."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Urban accessibility assessments are challenging: they involve varied stakeholders across decision-making contexts while serving a diverse population of people with disabilities. To better support urban accessibility assessment using data visualizations, we conducted a three-part interview study with 25 participants across five stakeholder groups using map visualization probes. We present a multi-stakeholder analysis of visualization needs and sensemaking processes to explore how interactive visualizations can support stakeholder decision making. In particular, we elaborate how stakeholders\u2019 varying levels of familiarity with accessibility, geospatial analysis, and specific geographic locations influences their sensemaking needs. We then contribute 10 design considerations for geovisual analytic tools for urban accessibility communication, planning, policymaking, and advocacy.",
    "call-number": "10.1145/3491102.3517460",
    "collection-number": "413",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517460",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "urban tech, decision-making, geovisual analysis, visualization, sensemaking, physical accessibility",
    "number": "Article 413",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Visualizing Urban Accessibility: Investigating Multi-Stakeholder Perspectives through a Map-based Design Probe Study",
    "URL": "https://doi.org/10.1145/3491102.3517460"
  },
  {
    "id": "10.1145/3491102.3501956",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Waycott",
        "given": "Jenny"
      },
      {
        "family": "Kelly",
        "given": "Ryan M."
      },
      {
        "family": "Baker",
        "given": "Steven"
      },
      {
        "family": "Barbosa Neves",
        "given": "Barbara"
      },
      {
        "family": "Thach",
        "given": "Kong Saoane"
      },
      {
        "family": "Lederman",
        "given": "Reeva"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Immersive virtual reality (VR) is being used as an enriching experience for people living in residential aged care, or nursing homes, where care staff play a critical role supporting clients to use VR. In HCI research concerned with technology use in aged care, however, the role of formal caregivers has received limited attention. We conducted interviews with 11 caregivers working in care homes that have implemented VR as part of the social program offered to residents. Our findings highlight tensions between the opportunities created by the immersive VR experience and the risks and challenges full immersion presents for people in aged care. In this paper, we draw on an ethics of care framework to make visible the care practices involved in facilitating VR in aged care homes, highlighting the care required to ensure that older adults experience benefits when using immersive VR, while risks and challenges are carefully managed.",
    "call-number": "10.1145/3491102.3501956",
    "collection-number": "414",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501956",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Aging, Virtual Reality, Aged Care, Ethics of Care",
    "number": "Article 414",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Role of Staff in Facilitating Immersive Virtual Reality for Enrichment in Aged Care: An Ethic of Care Perspective",
    "URL": "https://doi.org/10.1145/3491102.3501956"
  },
  {
    "id": "10.1145/3491102.3502072",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Holloway",
        "given": "Leona"
      },
      {
        "family": "Butler",
        "given": "Matthew"
      },
      {
        "family": "Marriott",
        "given": "Kim"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The ability to cross the street at intersections is an essential skill, often taught to people who are blind or have low vision (BLV) with the aid of tactile maps and kits or toys. However, each of the existing mapping tools has shortcomings. We investigated whether co-designed 3D printed components can offer benefits. Guided by consultation with 11 Orientation and Mobility (O&M) professionals, we co-designed a series of 3D printed kits that they then used in their practice with BLV children who showed high levels of engagement and learning. The 3D materials were found to demonstrate the key concepts for street crossings in a portable, engaging and professional manner. They will be released for free download, enabling O&M professionals to access or modify the materials as required. We hope that use of our co-designed 3D printed tools will contribute to the safety, independence and inclusion of BLV people.",
    "call-number": "10.1145/3491102.3502072",
    "collection-number": "415",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502072",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Intersections, Maps, Blind, Orientation & Mobility, 3D Printing",
    "number": "Article 415",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "3D Printed Street Crossings: Supporting Orientation and Mobility Training with People who are Blind or have Low Vision",
    "URL": "https://doi.org/10.1145/3491102.3502072"
  },
  {
    "id": "10.1145/3491102.3517457",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Young-Ho"
      },
      {
        "family": "Chou",
        "given": "Diana"
      },
      {
        "family": "Lee",
        "given": "Bongshin"
      },
      {
        "family": "Danilovich",
        "given": "Margaret"
      },
      {
        "family": "Lazar",
        "given": "Amanda"
      },
      {
        "family": "Conroy",
        "given": "David E."
      },
      {
        "family": "Kacorri",
        "given": "Hernisa"
      },
      {
        "family": "Choe",
        "given": "Eun Kyoung"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Current activity tracking technologies are largely trained on younger adults\u2019 data, which can lead to solutions that are not well-suited for older adults. To build activity trackers for older adults, it is crucial to collect training data with them. To this end, we examine the feasibility and challenges with older adults in collecting activity labels by leveraging speech. Specifically, we built MyMove, a speech-based smartwatch app to facilitate the in-situ labeling with a low capture burden. We conducted a 7-day deployment study, where 13 older adults collected their activity labels and smartwatch sensor data, while wearing a thigh-worn activity monitor. Participants were highly engaged, capturing 1,224 verbal reports in total. We extracted 1,885 activities with corresponding effort level and timespan, and examined the usefulness of these reports as activity labels. We discuss the implications of our approach and the collected dataset in supporting older adults through personalized activity tracking technologies.",
    "call-number": "10.1145/3491102.3517457",
    "collection-number": "416",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517457",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "older adults, experience sampling method, activity labeling, speech interaction, smartwatch",
    "number": "Article 416",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "MyMove: Facilitating Older Adults to Collect In-Situ Activity Labels on a Smartwatch with Speech",
    "URL": "https://doi.org/10.1145/3491102.3517457"
  },
  {
    "id": "10.1145/3491102.3517699",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rueben",
        "given": "Matthew"
      },
      {
        "family": "Horrocks",
        "given": "Matthew R"
      },
      {
        "family": "Martinez",
        "given": "Jennifer Eleanor"
      },
      {
        "family": "Cormier",
        "given": "Michelle V"
      },
      {
        "family": "LaLone",
        "given": "Nicolas"
      },
      {
        "family": "Fraune",
        "given": "Marlena"
      },
      {
        "family": "Toups Dugas",
        "given": "Z"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As artificial agents proliferate, there will be more and more situations in which they must communicate their capabilities to humans, including what they can \u201csee.\u201d Artificial agents have existed for decades in the form of computer-controlled agents in videogames. We analyze videogames in order to not only inspire the design of better agents, but to stop agent designers from replicating research that has already been theorized, designed, and tested in-depth. We present a qualitative thematic analysis of sight cues in videogames and develop a framework to support human-agent interaction design. The framework identifies the different locations and stimulus types \u2013 both visualizations and sonifications \u2013 available to designers and the types of information they can convey as sight cues. Insights from several other cue properties are also presented. We close with suggestions for implementing such cues with existing technologies to improve the safety, privacy, and efficiency of human-agent interactions.",
    "call-number": "10.1145/3491102.3517699",
    "collection-number": "417",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517699",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "qualitative methodologies, videogames, human-robot interaction, thematic analysis, sight cues",
    "number": "Article 417",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI See You!\u201d: A Design Framework for Interface Cues about Agent Visual Perception from a Thematic Analysis of Videogames",
    "URL": "https://doi.org/10.1145/3491102.3517699"
  },
  {
    "id": "10.1145/3491102.3517484",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Hyeok"
      },
      {
        "family": "Hwang",
        "given": "Youjin"
      },
      {
        "family": "Lee",
        "given": "Jieun"
      },
      {
        "family": "Kwon",
        "given": "Youngjin"
      },
      {
        "family": "Park",
        "given": "Yujin"
      },
      {
        "family": "Lee",
        "given": "Joonhwan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The lack of reliable, personalized information often complicates sexual violence survivors\u2019 support-seeking. Recently, there is an emerging approach to conversational information systems for support-seeking of sexual violence survivors, featuring personalization with wide availability and anonymity. However, a single best solution might not exist as sexual violence survivors have different needs and purposes in seeking support channels. To better envision conversational support-seeking systems for sexual violence survivors, we explore personalization trade-offs in designing such information systems. We implement a high-fidelity prototype dialogue-based information system through four design workshop sessions with three professional caregivers and interviewed with four self-identified survivors using our prototype. We then identify two forms of personalization trade-offs for conversational support-seeking systems: (1) specificity and sensitivity in understanding users and (2) relevancy and inclusiveness in providing information. To handle these trade-offs, we propose a reversed approach that starts from designing information and inclusive tailoring that considers unspecified needs, respectively.",
    "call-number": "10.1145/3491102.3517484",
    "collection-number": "418",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517484",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "human-centered design, Sexual violence survivors",
    "number": "Article 418",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Personalization Trade-offs in Designing a Dialogue-based Information System for Support-Seeking of Sexual Violence Survivors",
    "URL": "https://doi.org/10.1145/3491102.3517484"
  },
  {
    "id": "10.1145/3491102.3517500",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cila",
        "given": "Nazli"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With the advancements in AI, agents (i.e., smart products, robots, software agents) are increasingly capable of working closely together with humans in a variety of ways while benefiting from each other. These human-agent collaborations have gained growing attention in the HCI community; however, the field lacks clear guidelines on how to design the agents\u2019 behaviors in collaborations. In this paper, the qualities that are relevant for designers to create robust and pleasant human-agent collaborations were investigated. Bratman's Shared Cooperative Activity framework was used to identify the core characteristics of collaborations and survey the most important issues in the design of human-agent collaborations, namely code-of-conduct, task delegation, autonomy and control, intelligibility, common ground, offering help and requesting help. The aim of this work is to add structure to this growing and important facet of HCI research and operationalize the concept of human-agent collaboration with concrete design considerations.",
    "call-number": "10.1145/3491102.3517500",
    "collection-number": "420",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517500",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "human-agent collaboration, autonomous agent, Shared Cooperative Activity, design",
    "number": "Article 420",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing Human-Agent Collaborations: Commitment, responsiveness, and support",
    "URL": "https://doi.org/10.1145/3491102.3517500"
  },
  {
    "id": "10.1145/3491102.3517593",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Huang",
        "given": "Ann"
      },
      {
        "family": "Knierim",
        "given": "Pascal"
      },
      {
        "family": "Chiossi",
        "given": "Francesco"
      },
      {
        "family": "Chuang",
        "given": "Lewis L"
      },
      {
        "family": "Welsch",
        "given": "Robin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Augmented Reality (AR) embeds virtual content in physical spaces, including virtual agents that are known to exert a social presence on users. Existing design guidelines for AR rarely consider the social implications of an agent\u2019s personal space (PS) and that it can impact user behavior and arousal. We report an experiment (N=54) where participants interacted with agents in an AR art gallery scenario. When participants approached six virtual agents (i.e., two males, two females, a humanoid robot, and a pillar) to ask for directions, we found that participants respected the agents\u2019 PS and modulated interpersonal distances according to the human-like agents\u2019 perceived gender. When participants were instructed to walk through the agents, we observed heightened skin-conductance levels that indicate physiological arousal. These results are discussed in terms of proxemic theory that result in design recommendations for implementing pervasive AR experiences with virtual agents.",
    "call-number": "10.1145/3491102.3517593",
    "collection-number": "421",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517593",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Perception, Virtual Agents, Personal Space, Augmented Reality, Human-Agent Interaction, Proxemics",
    "number": "Article 421",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Proxemics for Human-Agent Interaction in Augmented Reality",
    "URL": "https://doi.org/10.1145/3491102.3517593"
  },
  {
    "id": "10.1145/3491102.3517625",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Schmidt",
        "given": "Susanne"
      },
      {
        "family": "Zimmermann",
        "given": "Sven"
      },
      {
        "family": "Mason",
        "given": "Celeste"
      },
      {
        "family": "Steinicke",
        "given": "Frank"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Research on intelligent virtual agents (IVAs) often concerns the implementation of human-like behavior by integrating artificial intelligence algorithms. Thus far, few studies focused on mimicry of cognitive imperfections inherent to humans in IVAs. Neglecting to implement such imperfect behavior in IVAs might result in less believable or engaging human-agent interactions. In this paper, we simulate human imprecision in conversational IVAs\u2019 temporal statements. We conducted a survey to identify temporal statement patterns, transferred them to a conversational IVA, and conducted a user study evaluating the effects of time precision on perceived anthropomorphism and usefulness. Statistical analyses reveal significant interaction between time precision and agents\u2019 use of memory aids, indicating that (i) imprecise agents are perceived as more human-like than precise agents when responding immediately, and (ii) unnaturally high levels of temporal precision can be compensated for by memory aid use. Further findings underscore the value of continued inquiry into cultural variations.",
    "call-number": "10.1145/3491102.3517625",
    "collection-number": "422",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517625",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "time perception, conversational agents, intelligent virtual agents",
    "number": "Article 422",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Simulating Human Imprecision in Temporal Statements of Intelligent Virtual Agents",
    "URL": "https://doi.org/10.1145/3491102.3517625"
  },
  {
    "id": "10.1145/3491102.3517594",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Williamson",
        "given": "Julie R."
      },
      {
        "family": "O'Hagan",
        "given": "Joseph"
      },
      {
        "family": "Guerra-Gomez",
        "given": "John Alexis"
      },
      {
        "family": "Williamson",
        "given": "John H"
      },
      {
        "family": "Cesar",
        "given": "Pablo"
      },
      {
        "family": "Shamma",
        "given": "David A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Behaviour in virtual environments might be informed by our experiences in physical environments, but virtual environments are not constrained by the same physical, perceptual, or social cues. Instead of replicating the properties of physical spaces, one can create virtual experiences that diverge from reality by dynamically manipulating environmental, aural, and social properties. This paper explores digital proxemics, which describe how we use space in virtual environments and how the presence of others influences our behaviours, interactions, and movements. First, we frame the open challenges of digital proxemics in terms of activity, social signals, audio design, and environment. We explore a subset of these challenges through an evaluation that compares two audio designs and two displays with different social signal affordances: head-mounted display (HMD) versus desktop PC. We use quantitative methods using instrumented tracking to analyse behaviour, demonstrating how personal space, proximity, and attention compare between desktop PC and HMDs.",
    "call-number": "10.1145/3491102.3517594",
    "collection-number": "423",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517594",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Environments, Digital Proxemics, Quantitative Methods., Social Signal Processing",
    "number": "Article 423",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Digital Proxemics: Designing Social and Collaborative Interaction in Virtual Environments",
    "URL": "https://doi.org/10.1145/3491102.3517594"
  },
  {
    "id": "10.1145/3491102.3517564",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Do",
        "given": "Tiffany D."
      },
      {
        "family": "McMahan",
        "given": "Ryan P."
      },
      {
        "family": "Wisniewski",
        "given": "Pamela J."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Virtual humans can be used to deliver persuasive arguments; yet, those with synthetic text-to-speech (TTS) have been perceived less favorably than those with recorded human speech. In this paper, we investigate standard concatenative TTS and more advanced neural TTS. We conducted a 3x2 between-subjects experiment (n=79) to evaluate the effect of a virtual human\u2019s speech fidelity at three levels (Standard TTS, Neural TTS, and Human speech) and the listener\u2019s gender (male or female) on perceptions and persuasion. We found that the virtual human was perceived as significantly less trustworthy by both genders, if they used neural TTS compared to human speech, while male listeners (but not females) also perceived standard TTS as less trustworthy than human speech. Our findings indicate that neural TTS may not be an effective choice for persuasive virtual humans and that gender of the listener plays a role in how virtual humans are perceived.",
    "call-number": "10.1145/3491102.3517564",
    "collection-number": "424",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517564",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "text-to-speech, speech fidelity, social perception, virtual humans",
    "number": "Article 424",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A New Uncanny Valley? The Effects of Speech Fidelity and Human Listener Gender on Social Perceptions of a Virtual-Human Speaker",
    "URL": "https://doi.org/10.1145/3491102.3517564"
  },
  {
    "id": "10.1145/3491102.3517451",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Sueyoon"
      },
      {
        "family": "El Ali",
        "given": "Abdallah"
      },
      {
        "family": "Wijntjes",
        "given": "Maarten"
      },
      {
        "family": "Cesar",
        "given": "Pablo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Visualizing biosignals can be important for social Virtual Reality (VR), where avatar non-verbal cues are missing. While several biosignal representations exist, designing effective visualizations and understanding user perceptions within social VR entertainment remains unclear. We adopt a mixed-methods approach to design biosignals for social VR entertainment. Using survey (N=54), context-mapping (N=6), and co-design (N=6) methods, we derive four visualizations. We then ran a within-subjects study (N=32) in a virtual jazz-bar to investigate how heart rate (HR) and breathing rate (BR) visualizations, and signal rate, influence perceived avatar arousal, user distraction, and preferences. Findings show that skeuomorphic visualizations for both biosignals allow differentiable arousal inference; skeuomorphic and particles were least distracting for HR, whereas all were similarly distracting for BR; biosignal perceptions often depend on avatar relations, entertainment type, and emotion inference of avatars versus spaces. We contribute HR and BR visualizations, and considerations for designing social VR entertainment biosignal visualizations.",
    "call-number": "10.1145/3491102.3517451",
    "collection-number": "425",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517451",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "visualization, Biosignals, design, entertainment, social VR, perception, virtual reality",
    "number": "Article 425",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding and Designing Avatar Biosignal Visualizations for Social Virtual Reality Entertainment",
    "URL": "https://doi.org/10.1145/3491102.3517451"
  },
  {
    "id": "10.1145/3491102.3502077",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "McDonald",
        "given": "Denisa Qori"
      },
      {
        "family": "Mahajan",
        "given": "Shruti"
      },
      {
        "family": "Vallett",
        "given": "Richard"
      },
      {
        "family": "Dion",
        "given": "Genevieve"
      },
      {
        "family": "Shokoufandeh",
        "given": "Ali"
      },
      {
        "family": "Solovey",
        "given": "Erin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent work has investigated the construction of touch-sensitive knitted fabrics, capable of being manufactured at scale, and having only two connections to external hardware. Additionally, several sensor design patterns and application prototypes have been introduced. Our aim is to start shaping the future of this technology according to user expectations. Through a formative focus group study, we explore users\u2019 views of using these fabrics in different contexts and discuss potential concerns and application areas. Subsequently, we take steps toward addressing relevant questions, by first providing design guidelines for application designers. Furthermore, in one user study, we demonstrate that it is possible to distinguish different swipe gestures and identify accidental contact with the sensor, a common occurrence in everyday life. We then present experiments investigating the effect of stretching and laundering of the sensors on their resistance, providing insights about considerations necessary to include in computational models.",
    "call-number": "10.1145/3491102.3502077",
    "collection-number": "426",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502077",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "smart fabrics, focus groups, knitted sensors, touch sensors, quantitative study, design guidelines, sensor stretching, everyday use, gesture identification, qualitative study, sensor laundering, distance metric, formative study",
    "number": "Article 426",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Interaction with Touch-Sensitive Knitted Fabrics: User Perceptions and Everyday Use Experiments",
    "URL": "https://doi.org/10.1145/3491102.3502077"
  },
  {
    "id": "10.1145/3491102.3501872",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bernard",
        "given": "Corentin"
      },
      {
        "family": "Monnoyer",
        "given": "Jocelyn"
      },
      {
        "family": "Ystad",
        "given": "S\u00f8lvi"
      },
      {
        "family": "Wiertlewski",
        "given": "Michael"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Moving a slider to set the music volume or control the air conditioning is a familiar task that requires little attention. However, adjusting a virtual slider on a featureless touchscreen is much more demanding and can be dangerous in situations such as driving. Here, we study how a gradual tactile feedback, provided by a haptic touchscreen, can replace visual cues. As users adjust a setting with their finger, they feel a continuously changing texture, which spatial frequency correlates to the value of the setting. We demonstrate that, after training with visual and auditory feedback, users are able to adjust a setting on a haptic touchscreen without looking at the screen, thereby reducing visual distraction. Every learning strategy yielded similar performance, suggesting an amodal integration. This study shows that surface haptics can provide intuitive and precise tuning possibilities for tangible interfaces on touchscreens.",
    "call-number": "10.1145/3491102.3501872",
    "collection-number": "427",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501872",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "surface haptics, learning, multimodality, Haptic feedback",
    "number": "Article 427",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Eyes-Off Your Fingers: Gradual Surface Haptic Feedback Improves Eyes-Free Touchscreen Interaction",
    "URL": "https://doi.org/10.1145/3491102.3501872"
  },
  {
    "id": "10.1145/3491102.3502003",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Feng",
        "given": "Feng"
      },
      {
        "family": "Bennett",
        "given": "Dan"
      },
      {
        "family": "Fan",
        "given": "Zhi-jun"
      },
      {
        "family": "Metatla",
        "given": "Oussama"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With the proliferation of shape-change research in affective computing, there is a need to deepen understandings of affective responses to shape-change display. Little research has focused on affective reactions to tactile experiences in shape-change, particularly in the absence of visual information. It is also rare to study response to the shape-change as it unfolds, isolated from a final shape-change outcome. We report on two studies on touch-affect associations, using the crossmodal \u201cBouba-Kiki\u201d paradigm, to understand affective responses to shape-change as it unfolds. We investigate experiences with a shape-change gadget, as it moves between rounded (\u201cBouba\u201d) and spiky (\u201cKiki\u201d) forms. We capture affective responses via the circumplex model, and use a motion analysis approach to understand the certainty of these responses. We find that touch-affect associations are influenced by both the size and the frequency of the shape-change and may be modality-dependent, and that certainty in affective associations is influenced by association-consistency.",
    "call-number": "10.1145/3491102.3502003",
    "collection-number": "428",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502003",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "crossmodal, emotion, Bouba/Kiki, affect, certainty, shape-change as it unfolds, Tactile",
    "number": "Article 428",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "It\u2019s Touching: Understanding Touch-Affect Association in Shape-Change with Kinematic Features",
    "URL": "https://doi.org/10.1145/3491102.3502003"
  },
  {
    "id": "10.1145/3491102.3501898",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Pei",
        "given": "Siyou"
      },
      {
        "family": "Chen",
        "given": "Alexander"
      },
      {
        "family": "Lee",
        "given": "Jaewook"
      },
      {
        "family": "Zhang",
        "given": "Yang"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Augmented reality (AR) and virtual reality (VR) technologies create exciting new opportunities for people to interact with computing resources and information. Less exciting is the need for holding hand controllers, which limits applications that demand expressive, readily available interactions. Prior research investigated freehand AR/VR input by transforming the user\u2019s body into an interaction medium. In contrast to previous work that has users\u2019 hands grasp virtual objects, we propose a new interaction technique that lets users\u2019 hands become virtual objects by imitating the objects themselves. For example, a thumbs-up hand pose is used to mimic a joystick. We created a wide array of interaction designs around this idea to demonstrate its applicability in object retrieval and interactive control tasks. Collectively, we call these interaction designs Hand Interfaces. From a series of user studies comparing Hand Interfaces against various baseline techniques, we collected quantitative and qualitative feedback, which indicates that Hand Interfaces are effective, expressive, and fun to use.",
    "call-number": "10.1145/3491102.3501898",
    "collection-number": "429",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501898",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Imitation, Free-hand interactions, AR/VR, On-body interactions, Interaction design, Embodiment",
    "number": "Article 429",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Hand Interfaces: Using Hands to Imitate Objects in AR/VR for Expressive Interactions",
    "URL": "https://doi.org/10.1145/3491102.3501898"
  },
  {
    "id": "10.1145/3491102.3517489",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tsai",
        "given": "Hsin-Ruey"
      },
      {
        "family": "Tsai",
        "given": "Chieh"
      },
      {
        "family": "Liao",
        "given": "Yu-So"
      },
      {
        "family": "Chiang",
        "given": "Yi-Ting"
      },
      {
        "family": "Zhang",
        "given": "Zhong-Yi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Interacting with not only virtual but also real objects, or even virtual objects augmented by real objects becomes a trend of virtual reality (VR) interactions and is common in augmented reality (AR). However, current haptic shape rendering devices generally focus on feedback of virtual objects, and require the users to put down or take off those devices to perceive real objects. Therefore, we propose FingerX to render haptic shapes and enable users to touch, grasp and interact with virtual and real objects simultaneously. An extender on the fingertip extends to a corresponding height to support between the fingertip and the real objects or the hand, to render virtual shapes. A ring rotates and withdraws the extender behind the fingertip when touching real objects. By independently controlling four extenders and rings on each finger with the exception of the pinky finger, FingerX renders feedback in three common scenarios, including touching virtual objects augmented by real environments (e.g.,\u00a0a desk), grasping virtual objects augmented by real objects (e.g.,\u00a0a bottle) and grasping virtual objects in the hand. We conducted a shape recognition study to evaluate the recognition rates for these three scenarios and obtained an average recognition rate of 76.59% with shape visual feedback. We then performed a VR study to observe how users interact with virtual and real objects simultaneously and verify that FingerX significantly enhances VR realism, compared to current vibrotactile methods.",
    "call-number": "10.1145/3491102.3517489",
    "collection-number": "430",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517489",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "augmented reality., shape rendering, Haptic feedback, virtual reality, wearable device",
    "number": "Article 430",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FingerX: Rendering Haptic Shapes of Virtual Objects Augmented by Real Objects using Extendable and Withdrawable Supports on Fingers",
    "URL": "https://doi.org/10.1145/3491102.3517489"
  },
  {
    "id": "10.1145/3491102.3501953",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Muender",
        "given": "Thomas"
      },
      {
        "family": "Bonfert",
        "given": "Michael"
      },
      {
        "family": "Reinschluessel",
        "given": "Anke Verena"
      },
      {
        "family": "Malaka",
        "given": "Rainer"
      },
      {
        "family": "D\u00f6ring",
        "given": "Tanja"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Providing haptic feedback in virtual reality to make the experience more realistic has become a strong focus of research in recent years. The resulting haptic feedback systems differ greatly in their technologies, feedback possibilities, and overall realism making it challenging to compare different systems. We propose the Haptic Fidelity Framework providing the means to describe, understand and compare haptic feedback systems. The framework locates a system in the spectrum of providing realistic or abstract haptic feedback using the Haptic Fidelity dimension. It comprises 14 criteria that either describe foundational or limiting factors. A second Versatility dimension captures the current trade-off between highly realistic but application-specific and more abstract but widely applicable feedback. To validate the framework, we compared the Haptic Fidelity score to the perceived feedback realism of evaluations from 38 papers and found a strong correlation suggesting the framework accurately describes the realism of haptic feedback.",
    "call-number": "10.1145/3491102.3501953",
    "collection-number": "431",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501953",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "virtual environment, framework, user experience, versatility, fidelity, realism, immersion, feedback, haptics, haptic feedback",
    "number": "Article 431",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Haptic Fidelity Framework: Defining the Factors of Realistic Haptic Feedback for Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3501953"
  },
  {
    "id": "10.1145/3491102.3517687",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhang",
        "given": "Xinlei"
      },
      {
        "family": "Su",
        "given": "Zixiong"
      },
      {
        "family": "Rekimoto",
        "given": "Jun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Voice interactive devices often use keyword spotting for device activation. However, this approach suffers from misrecognition of keywords and can respond to keywords not intended for calling the device (e.g., \u201dYou can ask Alexa about it.\u201d), causing accidental device activations. We propose a method that leverages prosodic features to differentiate calling/not-calling voices (F1 score: 0.869), allowing devices to respond only when called upon to avoid misactivation. As a proof of concept, we built a prototype smart speaker called Aware that allows users to control the device activation by speaking the keyword in specific prosody patterns. These patterns are chosen to represent people\u2019s natural calling/not-calling voices, which are uncovered in a study to collect such voices and investigate their prosodic difference. A user study comparing Aware with Amazon Echo shows Aware can activate more correctly (F1 score 0.93 vs. 0.56) and is easy to learn and use.",
    "call-number": "10.1145/3491102.3517687",
    "collection-number": "432",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517687",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Keyword Spotting, Conversational Interface, Voice Interaction, Prosody, Device Activation, Intention",
    "number": "Article 432",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Aware: Intuitive Device Activation Using Prosody for Natural Voice Interactions",
    "URL": "https://doi.org/10.1145/3491102.3517687"
  },
  {
    "id": "10.1145/3491102.3517724",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Myung Jin"
      },
      {
        "family": "Ryu",
        "given": "Neung"
      },
      {
        "family": "Chang",
        "given": "Wooje"
      },
      {
        "family": "Pahud",
        "given": "Michel"
      },
      {
        "family": "Sinclair",
        "given": "Mike"
      },
      {
        "family": "Bianchi",
        "given": "Andrea"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper\u2019s goal is to understand the haptic-visual congruency perception of skin-slip on the fingertips given visual cues in Virtual Reality (VR). We developed SpinOcchio (Spin for the spinning mechanism used, Occhio for the Italian word \u201ceye\u201d), a handheld haptic controller capable of rendering the thickness and slipping of a virtual object pinched between two fingers. This is achieved using a mechanism with spinning and pivoting disks that apply a tangential skin-slip movement to the fingertips. With SpinOcchio, we determined the baseline haptic discrimination threshold for skin-slip, and, using these results, we tested how haptic realism of motion and thickness is perceived with varying visual cues in VR. Surprisingly, the results show that in all cases, visual cues dominate over haptic perception. Based on these results, we suggest applications that leverage skin-slip and grip interaction, contributing further to realistic experiences in VR.",
    "call-number": "10.1145/3491102.3517724",
    "collection-number": "433",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517724",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Reality, Haptics, controller, skin-slip, normal force",
    "number": "Article 433",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SpinOcchio: Understanding Haptic-Visual Congruency of Skin-Slip in VR with a Dynamic Grip Controller",
    "URL": "https://doi.org/10.1145/3491102.3517724"
  },
  {
    "id": "10.1145/3491102.3502062",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zimmerer",
        "given": "Chris"
      },
      {
        "family": "Krop",
        "given": "Philipp"
      },
      {
        "family": "Fischbach",
        "given": "Martin"
      },
      {
        "family": "Latoschik",
        "given": "Marc Erich"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Multimodal Interfaces (MMIs) combining speech and spatial input have the potential to elicit minimal cognitive load. Low cognitive load increases effectiveness as well as user satisfaction and is regarded as an important aspect of intuitive use. While this potential has been extensively theorized in the research community, experiments that provide supporting observations based on functional interfaces are still scarce. In particular, there is a lack of studies comparing the commonly used Unimodal Interfaces (UMIs) with theoretically superior synergistic MMI alternatives. Yet, these studies are an essential prerequisite for generalizing results, developing practice-oriented guidelines, and ultimately exploiting the potential of MMIs in a broader range of applications. This work contributes a novel observation towards the resolution of this shortcoming in the context of the following combination of applied interaction techniques, tasks, application domain, and technology: We present a comprehensive evaluation of a synergistic speech & touch MMI and a touch-only menu-based UMI (interaction techniques) for selection and system control tasks in a digital tabletop game (application domain) on an interactive surface (technology). Cognitive load, user experience, and intuitive use are evaluated, with the former being assessed by means of the dual-task paradigm. Our experiment shows that the implemented MMI causes significantly less cognitive load and is perceived significantly more usable and intuitive than the UMI. Based on our results, we derive recommendations for the interface design of digital tabletop games on interactive surfaces. Further, we argue that our results and design recommendations are suitable to be generalized to other application domains on interactive surfaces for selection and system control tasks.",
    "call-number": "10.1145/3491102.3502062",
    "collection-number": "434",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502062",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Speech and Touch, Cognitive Load, Multimodal Interface, Interactive Surface, Comparative Study",
    "number": "Article 434",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Reducing the Cognitive Load of Playing a Digital Tabletop Game with a Multimodal Interface",
    "URL": "https://doi.org/10.1145/3491102.3502062"
  },
  {
    "id": "10.1145/3491102.3501849",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Park",
        "given": "Chaeyong"
      },
      {
        "family": "Kim",
        "given": "Jeongwoo"
      },
      {
        "family": "Kim",
        "given": "Dong-Geun"
      },
      {
        "family": "Oh",
        "given": "Seungjae"
      },
      {
        "family": "Choi",
        "given": "Seungmoon"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "One can embed a vibration actuator to a physical button and augment the physical button\u2019s original kinesthetic response with a programmable vibration generated by the actuator. Such vibration-augmented buttons inherit the advantages of both physical and virtual buttons. This paper reports the information transmission capacity of vibration-augmented buttons. It was obtained by conducting a series of absolute identification experiments while increasing the number of augmented buttons. The information transmission capacity found was 2.6 bits, and vibration-augmented and physical buttons showed similar abilities in rendering easily recognizable haptic responses. In addition, we showcase a VR text entry application that utilizes vibration-augmented buttons. Our method provides several error messages to the user during text entry using a VR controller that includes an augmented button. We validate that the variable haptic feedback improves task performance, cognitive workload, and user experience for a transcription task.",
    "call-number": "10.1145/3491102.3501849",
    "collection-number": "435",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501849",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Vibrotactile, Haptics, Information Theory, Augmentation, Button",
    "number": "Article 435",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Vibration-Augmented Buttons: Information Transmission Capacity and Application to Interaction Design",
    "URL": "https://doi.org/10.1145/3491102.3501849"
  },
  {
    "id": "10.1145/3491102.3517553",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhou",
        "given": "Shuo"
      },
      {
        "family": "Bickmore",
        "given": "Timothy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We describe an automated, multimodal embodied conversational agent that plays the role of a genetic counselor, designed to communicate breast cancer risk and the recommended medical guidelines to women. The counselor's dialogue is driven by intelligent tutoring systems techniques, risk communication principles, and information processing theories. The virtual counselor dynamically tailors its counseling based on user traits, preferred information processing methods, and dynamic comprehension assessments. We conducted a between-subject evaluation study with 30 women, comparing the adaptive counselor to a non-adaptive version of the counselor and a control condition. Women in the adaptive condition demonstrated a significantly greater increase in breast cancer genetics knowledge compared to women in the other conditions. Our results demonstrate the effectiveness of the multidimensional adaptation mechanisms for improving cancer genetic risk communication.",
    "call-number": "10.1145/3491102.3517553",
    "collection-number": "436",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517553",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Embodied conversational agent, Risk communication, Health education, Pedagogical agent, Genetic counseling, Intelligent tutoring system",
    "number": "Article 436",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Virtual Counselor for Breast Cancer Genetic Counseling: Adaptive Pedagogy Leads to Greater Knowledge Gain",
    "URL": "https://doi.org/10.1145/3491102.3517553"
  },
  {
    "id": "10.1145/3491102.3501824",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lin",
        "given": "Georgianna E"
      },
      {
        "family": "Mynatt",
        "given": "Elizabeth D"
      },
      {
        "family": "Kumar",
        "given": "Neha"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Human-Computer Interaction (HCI) research on menstrual tracking has emphasized the need for more inclusive design of mechanisms for tracking and sharing information on menstruation. We investigate menstrual tracking and data-sharing attitudes and practices in educated, young (20-30 years old) menstruating individuals based in the United States, with self-identified minimal menstrual education backgrounds. Using interviews (N=18), a survey (N=62), and participatory design (N=7), we find that existing mechanisms for tracking and sharing data on menstruation are not adequately responsive to the needs of those who seek relevant menstrual education, are not in the sexual majority, and/or wish to customize what menstrual data they share and with whom. Our analysis highlights a design gap for participants with minimal sexual education backgrounds who wish to better understand their cycles. We also contribute a deepened understanding of structural health inequities that impact menstrual tracking and sharing practices, making recommendations for technology-mediated menstrual care.",
    "call-number": "10.1145/3491102.3501824",
    "collection-number": "437",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501824",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Menstrual tracking, culturally responsive design, health equity, menstrual health",
    "number": "Article 437",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Culturally Responsive Design for Menstrual Tracking and Sharing Practices Among Individuals with Minimal Sexual Education",
    "URL": "https://doi.org/10.1145/3491102.3501824"
  },
  {
    "id": "10.1145/3491102.3517620",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tang",
        "given": "Kymeng"
      },
      {
        "family": "Gerling",
        "given": "Kathrin"
      },
      {
        "family": "Geurts",
        "given": "Luc"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Breastfeeding can be challenging, but it is difficult for antenatal education to convey issues associated with the lived experience of breastfeeding. In our work, we explore the potential of interactive simulations to support antenatal education, and present Virtual Feed, a Virtual Reality breastfeeding simulation for parents-to-be developed following a three-step process. (1) We created an experience prototype that features basic VR scenarios and a tangible baby, (2) we engaged in design sessions with 19 parents and parents-to-be to derive design implications to further refine the simulation, and (3) we evaluated the system through case studies to examine the perspectives of parents and parents-to-be on the simulation. Our results show that the simulation successfully engaged users and sparked curiosity, while also encouraging reflection about the challenges of breastfeeding. On this basis, we discuss challenges for the design of simulations with the purpose of supplementing antenatal education.",
    "call-number": "10.1145/3491102.3517620",
    "collection-number": "438",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517620",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "co-design, qualitative research, breastfeeding, virtual reality",
    "number": "Article 438",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Virtual Feed: Design and Evaluation of a Virtual Reality Simulation Addressing the Lived Experience of Breastfeeding",
    "URL": "https://doi.org/10.1145/3491102.3517620"
  },
  {
    "id": "10.1145/3491102.3501886",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mitchell",
        "given": "Elliot"
      },
      {
        "family": "Elhadad",
        "given": "Noemie"
      },
      {
        "family": "Mamykina",
        "given": "Lena"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Conversational interaction, for example through chatbots, is well-suited to enable automated health coaching tools to support self-management and prevention of chronic diseases. However, chatbots in health are predominantly scripted or rule-based, which can result in a stagnant and repetitive user experience in contrast with more dynamic, data-driven chatbots in other domains. Consequently, little is known about the tradeoffs of pursuing data-driven approaches for health chatbots. We examined multiple artificial intelligence (AI) approaches to enable micro-coaching dialogs in nutrition \u2014 brief coaching conversations related to specific meals, to support achievement of nutrition goals \u2014 and compared, reinforcement learning (RL), rule-based, and scripted approaches for dialog management. While the data-driven RL chatbot succeeded in shorter, more efficient dialogs, surprisingly the simplest, scripted chatbot was rated as higher quality, despite not fulfilling its task as consistently. These results highlight tensions between scripted and more complex, data-driven approaches for chatbots in health.",
    "call-number": "10.1145/3491102.3501886",
    "collection-number": "440",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501886",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Health coaching, self-management, conversational agents, reinforcement learning, chatbots",
    "number": "Article 440",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Examining AI Methods for Micro-Coaching Dialogs",
    "URL": "https://doi.org/10.1145/3491102.3501886"
  },
  {
    "id": "10.1145/3491102.3517603",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hamid",
        "given": "Aleesha"
      },
      {
        "family": "Arshad",
        "given": "Rabiah"
      },
      {
        "family": "Shahid",
        "given": "Suleman"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Depression and anxiety among college students have been on the rise globally. Cognitive Behavioural Therapy has emerged as an empirically reinforced and effective treatment. However, factors like cost, lack of resources, misguided prioritization and stigmatization of mental health issues in the Global South limit students\u2019 access to psychotherapy. While technology can bridge this gap, research shows current self-guided mHealth apps for CBT are not always evidence-based and have limited efficacy compared to therapist-guided alternatives. In this paper, we explore whether interactive storytelling and other gamification mechanisms can increase the efficacy of a self-guided mHealth app, while drawing from empirically supported CBT protocols. We designed an mHealth application with contextualised storylines to help students learn psychological concepts and better identify the negative patterns in their thoughts. We present the results of a 3-arm randomized controlled trial conducted to assess the effect of this application compared to active and inactive control conditions.",
    "call-number": "10.1145/3491102.3517603",
    "collection-number": "441",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517603",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "storytelling, mental health, CBT, mHealth application",
    "number": "Article 441",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "What are you thinking?: Using CBT and Storytelling to Improve Mental Health Among College Students",
    "URL": "https://doi.org/10.1145/3491102.3517603"
  },
  {
    "id": "10.1145/3491102.3517476",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Xu",
        "given": "Xuhai"
      },
      {
        "family": "Zou",
        "given": "Tianyuan"
      },
      {
        "family": "Xiao",
        "given": "Han"
      },
      {
        "family": "Li",
        "given": "Yanzhang"
      },
      {
        "family": "Wang",
        "given": "Ruolin"
      },
      {
        "family": "Yuan",
        "given": "Tianyi"
      },
      {
        "family": "Wang",
        "given": "Yuntao"
      },
      {
        "family": "Shi",
        "given": "Yuanchun"
      },
      {
        "family": "Mankoff",
        "given": "Jennifer"
      },
      {
        "family": "Dey",
        "given": "Anind K"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Smartphone overuse is related to a variety of issues such as lack of sleep and anxiety. We explore the application of Self-Affirmation Theory on smartphone overuse intervention in a just-in-time manner. We present TypeOut, a just-in-time intervention technique that integrates two components: an in-situ typing-based unlock process to improve user engagement, and self-affirmation-based typing content to enhance effectiveness. We hypothesize that the integration of typing and self-affirmation content can better reduce smartphone overuse. We conducted a 10-week within-subject field experiment (N=54) and compared TypeOut against two baselines: one only showing the self-affirmation content (a common notification-based intervention), and one only requiring typing non-semantic content (a state-of-the-art method). TypeOut reduces app usage by over 50%, and both app opening frequency and usage duration by over 25%, all significantly outperforming baselines. TypeOut can potentially be used in other domains where an intervention may benefit from integrating self-affirmation exercises with an engaging just-in-time mechanism.",
    "call-number": "10.1145/3491102.3517476",
    "collection-number": "442",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517476",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "intervention design, Smartphone overuse, self-affirmation",
    "number": "Article 442",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TypeOut: Leveraging Just-in-Time Self-Affirmation for Smartphone Overuse Reduction",
    "URL": "https://doi.org/10.1145/3491102.3517476"
  },
  {
    "id": "10.1145/3491102.3517513",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Evans",
        "given": "Hayley Irene"
      },
      {
        "family": "Deeter",
        "given": "Catherine R"
      },
      {
        "family": "Zhou",
        "given": "Jiawei"
      },
      {
        "family": "Do",
        "given": "Kimberly"
      },
      {
        "family": "Sherrill",
        "given": "Andrew M"
      },
      {
        "family": "Arriaga",
        "given": "Rosa I."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Past research has demonstrated that accounts of trusted others can provide additional context into real world behavior relevant to clinical decision-making and patient engagement. Our research investigates the Social Sensing System, a concept which leverages trusted other feedback for veterans in therapy for PTSD. In our two phase study, we work with 10 clinicians to develop text-message queries and realistic scenarios to present to patients and trusted others. We then present the results in the form of a storyboard to 10 veterans with PTSD and 10 trusted others and gather feedback via semi-structured interview and survey. We find that while trusted other feedback may provide a unique and useful perspective, key design features and considerations of underlying relationships must be considered. We present our findings and utilize the mechanisms and conditions framework to assess the power dynamics of systems such as social sensing in the mental health realm.",
    "call-number": "10.1145/3491102.3517513",
    "collection-number": "443",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517513",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Veterans, Text messages, Post-Traumatic Stress Disorder, Trusted Others, Social Feedback",
    "number": "Article 443",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Perspectives on Integrating Trusted Other Feedback in Therapy for Veterans with PTSD",
    "URL": "https://doi.org/10.1145/3491102.3517513"
  },
  {
    "id": "10.1145/3491102.3517573",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Smith",
        "given": "Wally"
      },
      {
        "family": "Wadley",
        "given": "Greg"
      },
      {
        "family": "Webber",
        "given": "Sarah"
      },
      {
        "family": "Tag",
        "given": "Benjamin"
      },
      {
        "family": "Kostakos",
        "given": "Vassilis"
      },
      {
        "family": "Koval",
        "given": "Peter"
      },
      {
        "family": "Gross",
        "given": "James J."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Two decades of focus on User Experience has yielded an array of digital technologies that help people experience, understand and share emotions. Although the effects of specific technologies upon emotion have been well studied, less is known about how people actively appropriate and combine the full range of devices, apps and services at their disposal to deliberately manage emotions in everyday life. We conducted a one-week diary study in which 23 adults recorded interactions between their emotions and technology use. They reported using a diverse range of emotion-shaping tools and strategies as part of coping with daily challenges, managing routines, and pursuing work and social goals. We analyse these data in the light of psychological theories of emotion. Our findings point to the significance of digital emotion regulation as a powerful perspective to inform wider debates about the impacts of technology on social and emotional well-being.",
    "call-number": "10.1145/3491102.3517573",
    "collection-number": "444",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517573",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 444",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Digital Emotion Regulation in Everyday Life",
    "URL": "https://doi.org/10.1145/3491102.3517573"
  },
  {
    "id": "10.1145/3491102.3517437",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tochilnikova",
        "given": "Elina"
      },
      {
        "family": "Patnaik",
        "given": "Amrit"
      },
      {
        "family": "Alsebayel",
        "given": "Ghada"
      },
      {
        "family": "Narayan",
        "given": "Uttkarsh"
      },
      {
        "family": "Coeytaux",
        "given": "Andrew"
      },
      {
        "family": "Ramdin",
        "given": "Valeria"
      },
      {
        "family": "Kim",
        "given": "Miso"
      },
      {
        "family": "Harteveld",
        "given": "Casper"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Traditionally, game designers have driven the development process of psychotherapeutic games with psychotherapists playing a consultant role. In contrast, our study explores psychotherapists independently designing digitally gamified psychotherapy. Our workshop participants consisted of six psychotherapists who created gamified digital therapies with the design prompt of anxiety disorder. We analyze the resulting six prototypes from a game design and psychotherapy perspective. We present insights into strategies for digitally gamifying therapy and identify challenges and opportunities for the future of gamified psychotherapy, grounded in the experiences of psychotherapists designing such therapies. This study also reflects on the use of user-friendly development tools for independently curating gamified digital therapies, especially by non-technical users such as psychotherapists.",
    "call-number": "10.1145/3491102.3517437",
    "collection-number": "445",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517437",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "research-through-design, digital psychotherapy, meta-design, anxiety disorder, Game design, mental health, games for health",
    "number": "Article 445",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cGuilty of Talking Too Much\u201d: How Psychotherapists Gamify Therapy",
    "URL": "https://doi.org/10.1145/3491102.3517437"
  },
  {
    "id": "10.1145/3491102.3502097",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Albayaydh",
        "given": "Wael S"
      },
      {
        "family": "Flechais",
        "given": "Ivan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Smart homes continue to raise concerns about privacy and encroachment of businesses into intimate spaces. Prior research has focused on families and device owners in western contexts (Europe and North America), and has identified the importance of bystanders: individuals who are subjected to smart device use of others. Given the cultural and contextual aspects of accommodating bystanders, we identify a gap where bystanders in non-western societies have been insufficiently researched. To address this we conduct 20 interviews with domestic workers and household employers in Jordan, exploring privacy attitudes and practices. Our analysis uncovers a complex interplay between religious and social norms; legal and regulatory perspectives on privacy; and tensions between households and their domestic workers. We explore issues arising from smart homes coexisting as a residence and workplace, and highlight how workplace protections are ill-suited. We structure our findings to help inform public awareness, policy makers, manufacturers, and future research.",
    "call-number": "10.1145/3491102.3502097",
    "collection-number": "446",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502097",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Smart Home, Privacy, Smart Device, Bystanders",
    "number": "Article 446",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Bystanders\u2019 Privacy Concerns with Smart Homes in Jordan",
    "URL": "https://doi.org/10.1145/3491102.3502097"
  },
  {
    "id": "10.1145/3491102.3517510",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sabir",
        "given": "Aafaq"
      },
      {
        "family": "Lafontaine",
        "given": "Evan"
      },
      {
        "family": "Das",
        "given": "Anupam"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The Amazon Alexa voice assistant provides convenience through automation and control of smart home appliances using voice commands. Amazon allows third-party applications known as skills to run on top of Alexa to further extend Alexa\u2019s capability. However, as multiple skills can share the same invocation phrase and request access to sensitive user data, growing security and privacy concerns surround third-party skills. In this paper, we study the availability and effectiveness of existing security indicators or a lack thereof to help users properly comprehend the risk of interacting with different types of skills. We conduct an interactive user study (inviting active users of Amazon Alexa) where participants listen to and interact with real-world skills using the official Alexa app. We find that most participants fail to identify the skill developer correctly (i.e., they assume Amazon also develops the third-party skills) and cannot correctly determine which skills will be automatically activated through the voice interface. We also propose and evaluate a few voice-based skill type indicators, showcasing how users would benefit from such voice-based indicators.",
    "call-number": "10.1145/3491102.3517510",
    "collection-number": "447",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517510",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Third-party skills, Security indicators, Voice assistant",
    "number": "Article 447",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Hey Alexa, Who Am I Talking to?: Analyzing Users\u2019 Perception and Awareness Regarding Third-party Alexa Skills",
    "URL": "https://doi.org/10.1145/3491102.3517510"
  },
  {
    "id": "10.1145/3491102.3502136",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mink",
        "given": "Jaron"
      },
      {
        "family": "Yuile",
        "given": "Amanda Rose"
      },
      {
        "family": "Pal",
        "given": "Uma"
      },
      {
        "family": "Aviv",
        "given": "Adam J"
      },
      {
        "family": "Bates",
        "given": "Adam"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Fitness tracking applications allow athletes to record and share their exercises online, including GPS routes of their activities. However, sharing mobility data potentially raises real-world privacy and safety risks. One strategy to mitigate that risk is a \u201cPrivacy Zone,\u201d which conceals portions of the exercise routes that fall within a certain radius of a user-designated sensitive location. A pressing concern is whether privacy zones are an effective deterrent against common attackers, such as a bike thief that carefully scrutinizes online exercise activities in search of their next target. Further, little is known about user perceptions of privacy zones or how they fit into the broader landscape of available privacy precautions. This work presents an online user study (N=603) that investigates the privacy concerns of fitness tracking users and evaluates the efficacy of privacy zones. Participants were first asked about their privacy behaviors with respect to fitness tracking applications. Next, participants completed an interactive task in which they attempted to deduce hidden locations protected by a privacy zone; we manipulated the number of displayed exercise activities that interacted with the privacy zone, as well as its size. Finally, participants were asked further questions about their impressions of privacy zones and use of other privacy precautions. We found that participants successfully inferred protected locations; for the most common privacy zone size, 68% of guesses fell within 50 meters of the hidden location when participants were shown just 3 activities. Further, we found that participants who viewed 3 activities were more confident about their success in the task compared to participants who viewed 1 activity. Combined, these results indicate that users\u2019 privacy-sensitive locations are at risk even when using a privacy zone. We conclude by considering the implications of our findings on related privacy features and discuss recommendations to fitness tracking users and services to improve the privacy and safety of fitness trackers.",
    "call-number": "10.1145/3491102.3502136",
    "collection-number": "448",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502136",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "data sharing, Fitness trackers, online survey, privacy, privacy zones",
    "number": "Article 448",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Users Can Deduce Sensitive Locations Protected by Privacy Zones on Fitness Tracking Apps",
    "URL": "https://doi.org/10.1145/3491102.3502136"
  },
  {
    "id": "10.1145/3491102.3517602",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jin",
        "given": "Haojian"
      },
      {
        "family": "Guo",
        "given": "Boyuan"
      },
      {
        "family": "Roychoudhury",
        "given": "Rituparna"
      },
      {
        "family": "Yao",
        "given": "Yaxing"
      },
      {
        "family": "Kumar",
        "given": "Swarun"
      },
      {
        "family": "Agarwal",
        "given": "Yuvraj"
      },
      {
        "family": "Hong",
        "given": "Jason I."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this paper, we studied people\u2019s smart home privacy-protective behaviors (SH-PPBs), to gain a better understanding of their privacy management do\u2019s and don\u2019ts in this context. We first surveyed 159 participants and elicited 33 unique SH-PPB practices, revealing that users heavily rely on ad hoc approaches at the physical layer (e.g., physical blocking, manual powering off). We also characterized the types of privacy concerns users wanted to address through SH-PPBs, the reasons preventing users from doing SH-PPBs, and privacy features they wished they had to support SH-PPBs. We then storyboarded 11 privacy protection concepts to explore opportunities to better support users\u2019 needs, and asked another 227 participants to criticize and rank these design concepts. Among the 11 concepts, Privacy Diagnostics, which is similar to security diagnostics in anti-virus software, was far preferred over the rest. We also witnessed rich evidence of four important factors in designing SH-PPB tools, as users prefer (1) simple, (2) proactive, (3) preventative solutions that can (4) offer more control.",
    "call-number": "10.1145/3491102.3517602",
    "collection-number": "449",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517602",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Smart Home, privacy protective behaviors",
    "number": "Article 449",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring the Needs of Users for Supporting Privacy-Protective Behaviors in Smart Homes",
    "URL": "https://doi.org/10.1145/3491102.3517602"
  },
  {
    "id": "10.1145/3491102.3502118",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Harrington",
        "given": "Christina N."
      },
      {
        "family": "Klassen",
        "given": "Shamika"
      },
      {
        "family": "Rankin",
        "given": "Yolanda A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Traditional approaches to technology design have historically ignored Blackness in both who engages and conceptualizes future technologies. Design contributions of groups marginalized along race and class are often othered, and rarely considered the design standard. While frameworks have emerged to encourage attention to gender and social justice in design, little work has acknowledged evidence of the Black imaginary in this process. The current canon of design defines futuring and speculation as stemming from a narrow view of science fiction, one which does not include Black futurist perspectives. In this essay, we expand the canon of design by arguing that frameworks such as Afrofuturism, Afrofuturist feminism, and Black feminism be considered instrumental in design\u2019s imagining of our future technological landscape. We contribute to the larger conversation of who gets to future in design, suggesting a dialogic relationship between those who conceptualize design and those who consider design\u2019s societal impact.",
    "call-number": "10.1145/3491102.3502118",
    "collection-number": "450",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502118",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "speculative design, design canon, Afrofuturism, futuring",
    "number": "Article 450",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cAll that You Touch, You Change\u201d: Expanding the Canon of Speculative Design Towards Black Futuring",
    "URL": "https://doi.org/10.1145/3491102.3502118"
  },
  {
    "id": "10.1145/3491102.3517579",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rubambiza",
        "given": "Gloire"
      },
      {
        "family": "Sengers",
        "given": "Phoebe"
      },
      {
        "family": "Weatherspoon",
        "given": "Hakim"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Rural infrastructure is known to be more prone to breakdown than urban infrastructure. This paper explores how the fragility of rural infrastructure is reproduced through the process of engineering design. Building on values in design, we examine how eventual use is anticipated by engineering researchers building on emerging infrastructure for digital agriculture (DA). Our approach combines critically reflective technical systems-building with interviews with other practitioners to understand and address moments early in the design process where the eventual effects of DA systems may be being built-in. Our findings contrast researchers\u2019 visions of seamless farming technologies with the seamful realities of their work to produce them. We trace how, when anticipating future use, the seams that researchers themselves experience disappear, other seams are hidden from view by institutional support, and seams end users may face are too distant to be in sight. We develop suggestions for the design of these technologies grounded in a more artful management of seamfulness and seamlessness during the process of design and development.",
    "call-number": "10.1145/3491102.3517579",
    "collection-number": "451",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517579",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "critical technical practice, digital agriculture, values in design, computer networking, infrastructure, seamlessness",
    "number": "Article 451",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Seamless Visions, Seamful Realities: Anticipating Rural Infrastructural Fragility in Early Design of Digital Agriculture",
    "URL": "https://doi.org/10.1145/3491102.3517579"
  },
  {
    "id": "10.1145/3491102.3501945",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bray",
        "given": "Kirsten E"
      },
      {
        "family": "Harrington",
        "given": "Christina"
      },
      {
        "family": "Parker",
        "given": "Andrea G"
      },
      {
        "family": "Diakhate",
        "given": "N'Deye"
      },
      {
        "family": "Roberts",
        "given": "Jennifer"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "When considering the democratic intentions of co-design, designers and design researchers must evaluate the impact of power imbalances embedded in common design and research dynamics. This holds particularly true in work with and for marginalized communities, who are frequently excluded in design processes. To address this issue, we examine how existing design tools and methods are used to support communities in processes of community building or reimagining, considering the influence of race and identity. This paper describes our findings from 27 interviews with community design practitioners conducted to evaluate the Building Utopia toolkit, which employs an Afrofuturist lens for speculative design processes. Our research findings support the importance of design tools that prompt conversations on race in design, and tensions between the desire for imaginative design practice and the immediacy of social issues, particularly when designing with Black and brown communities.",
    "call-number": "10.1145/3491102.3501945",
    "collection-number": "452",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501945",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design methods, method, qualitative methods, participatory design, design research methods",
    "number": "Article 452",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Radical Futures: Supporting Community-Led Design Engagements through an Afrofuturist Speculative Design Toolkit",
    "URL": "https://doi.org/10.1145/3491102.3501945"
  },
  {
    "id": "10.1145/3491102.3502044",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "To",
        "given": "Alexandra"
      },
      {
        "family": "Carey",
        "given": "Hillary"
      },
      {
        "family": "Shrivastava",
        "given": "Riya"
      },
      {
        "family": "Hammer",
        "given": "Jessica"
      },
      {
        "family": "Kaufman",
        "given": "Geoff"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Reducing uncertainty around the nature of racist interactions is one of the key motivations driving individual behaviors for coping with those incidents. However, there are few appropriate technologies to support BIPOC (Black, Indigenous, People of Color) in engaging in social uncertainty reduction around this vulnerable, sensitive topic. This paper reports on an exploratory design study investigating how social technology might facilitate uncertainty reduction through three \u201cprovotypes\u201d - provocative prototypes of user-generated speculative design concepts. U.S.-based participants engaged with the provotypes through an interactive fiction to explore their usefulness in the context of a racist microaggression. Results showed that engaging the provotypes through interactive fiction facilitated complex and productive interactions and critiques. This work contributes a novel method for conducting exploratory design, remote user studies using interactive fiction as well as priorities, tensions, and further information what role, if any, technology might play in managing racist interactions.",
    "call-number": "10.1145/3491102.3502044",
    "collection-number": "453",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502044",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "microaggressions, provotype, racism, interactive fiction",
    "number": "Article 453",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Interactive Fiction Provotypes for Coping with Interpersonal Racism",
    "URL": "https://doi.org/10.1145/3491102.3502044"
  },
  {
    "id": "10.1145/3491102.3517711",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bell",
        "given": "Fiona"
      },
      {
        "family": "Ofer",
        "given": "Netta"
      },
      {
        "family": "Alistar",
        "given": "Mirela"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this work, we use composted food waste to create ReClaym: a personal biomaterial, made at home, that reflects the makers\u2019 relationship with food. We combine our personal compost with non-toxic binders to create a biomaterial that can completely biodegrade. We propose Intimate Making as an approach for working with ReClaym that leverages familiar, hands-on techniques to enhance maker-material communication, which in turn leads to a deeper material understanding. We explore methods to customize ReClaym via color, texture, sensing, and conductivity. We apply manual fabrication techniques (sculpting, molding, and hand-held extruding) and design explorations to create a collection of applications that include garden paraphernalia, games, and personal items found in the home. We then examine the entire life cycle of ReClaym, which both begins and ends with composting\u2014giving food waste a second life and providing a sustainable end of life for ReClaym artifacts, thus making the process truly circular.",
    "call-number": "10.1145/3491102.3517711",
    "collection-number": "454",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517711",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Biomaterials, Biodesign, Sustainability, Intimacy, Bio-HCI",
    "number": "Article 454",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ReClaym our Compost: Biodegradable Clay for Intimate Making",
    "URL": "https://doi.org/10.1145/3491102.3517711"
  },
  {
    "id": "10.1145/3491102.3502080",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Benford",
        "given": "Steve"
      },
      {
        "family": "Sundnes L\u00f8vlie",
        "given": "Anders"
      },
      {
        "family": "Ryding",
        "given": "Karin"
      },
      {
        "family": "Rajkowska",
        "given": "Paulina"
      },
      {
        "family": "Bodiaj",
        "given": "Edgar"
      },
      {
        "family": "Paris Darzentas",
        "given": "Dimitrios"
      },
      {
        "family": "Cameron",
        "given": "Harriet"
      },
      {
        "family": "Spence",
        "given": "Jocelyn"
      },
      {
        "family": "Egede",
        "given": "Joy"
      },
      {
        "family": "Spanjevic",
        "given": "Bogdan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Museums are interested in designing emotional visitor experiences to complement traditional interpretations. HCI is interested in the relationship between Affective Computing and Affective Interaction. We describe Sensitive Pictures, an emotional visitor experience co-created with the Munch art museum. Visitors choose emotions, locate associated paintings in the museum, experience an emotional story while viewing them, and self-report their response. A subsequent interview with a portrayal of the artist employs computer vision to estimate emotional responses from facial expressions. Visitors are given a souvenir postcard visualizing their emotional data. A study of 132 members of the public (39 interviewed) illuminates key themes: designing emotional provocations; capturing emotional responses; engaging visitors with their data; a tendency for them to align their views with the system's interpretation; and integrating these elements into emotional trajectories. We consider how Affective Computing can hold up a mirror to our emotions during Affective Interaction",
    "call-number": "10.1145/3491102.3502080",
    "collection-number": "455",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502080",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Affective Interaction, Museum, Ambiguity, Affect, Emotion, Computer Vision, Affective Computing, Interpretation, Data Souvenir",
    "number": "Article 455",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Sensitive Pictures: Emotional Interpretation in the Museum",
    "URL": "https://doi.org/10.1145/3491102.3502080"
  },
  {
    "id": "10.1145/3491102.3517651",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Khot",
        "given": "Rohit Ashok"
      },
      {
        "family": "Aggarwal",
        "given": "Deepti"
      },
      {
        "family": "Pasumarthy",
        "given": "Nandini"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Our eating practices are increasingly overshadowed by the presence of screen-based media technologies that conflict with the ideologies of mindful eating. However, little is known about whether and how screens influence our eating behaviors. To contribute to this understanding, we present a rich account of dining practices of ten participants with and without screen. Our study revealed that eating with screens was found more enjoyable than eating alone. Screens can influence one's awareness of hunger and other behaviors like chewing rate and food gaze, whereas screen-media did not trigger any judgements for food. Drawing on the study insights, we highlight the role of technology to support bodily awareness, savoring, a non-judgmental attitude to eating and on rethinking distractions as companions. The outlined considerations encourage a creative yet careful take on making mindful eating more accessible within the realities of screen-based dining cultures.",
    "call-number": "10.1145/3491102.3517651",
    "collection-number": "456",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517651",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Screen-based dining, Human-Food Interaction, mindful eating",
    "number": "Article 456",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Screen-based Dining Practices through the Lens of Mindful Eating",
    "URL": "https://doi.org/10.1145/3491102.3517651"
  },
  {
    "id": "10.1145/3491102.3517557",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kuznetsov",
        "given": "Stacey"
      },
      {
        "family": "Rodriguez Vega",
        "given": "Alejandra"
      },
      {
        "family": "Long",
        "given": "Elenore"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As parts of our planet continue to experience extreme heat waves, it is more urgent than ever for human-food interaction research to examine climate-resilient and sustainable food practices. Our work, conducted in the hottest city in the USA, focuses on solar cooking as a set of creative DIY activities that use extreme heat and mitigate human impact on the environment. We report on a summer-long study whereby 7 enthusiasts built solar ovens from scratch and experimented with solar recipes ranging from slow-cooked pork and chicken to bread, kale chips, brownies, jerky, and fruit rollups. Our findings depict solar cooking as a form of iterative DIY, which, through its challenges and creative workarounds, serves as a point of engagement with both food and extreme heat. We reflect on solar cooking as a climate-resilient food practice and conclude with design considerations for HCI to support solar cooking as a habitual community practice.",
    "call-number": "10.1145/3491102.3517557",
    "collection-number": "457",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517557",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "food science, Solar cooking, DIY, sustainable HCI",
    "number": "Article 457",
    "number-of-pages": "8",
    "page": "1\u20138",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Study of Solar Cooking: Exploring Climate-Resilient Food Preparation and Opportunities for HCI",
    "URL": "https://doi.org/10.1145/3491102.3517557"
  },
  {
    "id": "10.1145/3491102.3517547",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gaver",
        "given": "William"
      },
      {
        "family": "Boucher",
        "given": "Andy"
      },
      {
        "family": "Brown",
        "given": "Dean"
      },
      {
        "family": "Chatting",
        "given": "David"
      },
      {
        "family": "Matsuda",
        "given": "Naho"
      },
      {
        "family": "Ovalle",
        "given": "Liliana"
      },
      {
        "family": "Sheen",
        "given": "Andy"
      },
      {
        "family": "Vanis",
        "given": "Michail"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Yo\u2013Yo Machines are playful communication devices designed to help people feel socially connected while physically separated. We designed them to reach as many people as possible, both to make a positive impact during the COVID-19 pandemic and to assess a self-build approach to circulating research products and the appeal of peripheral and expressive communication devices. A portfolio of four distinct designs, based on over 30 years of research, were made available for people to make by following simple online instructions (yoyomachines.io). Each involves connecting a pair of identical devices over the internet to allow simple communication at a distance. This paper describes our motivation for the project, previous work in the area, the design of the devices, supporting website and publicity, and how users have made and used Yo-Yo Machines. Finally, we reflect on what we learned about peripheral and expressive communication devices and implications for the self-build approach.",
    "call-number": "10.1145/3491102.3517547",
    "collection-number": "458",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517547",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "research through design, peripheral and expressive communication, open source, design research, self-build, IoT",
    "number": "Article 458",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Yo\u2013Yo Machines: Self-Build Devices that Support Social Connections During the Pandemic",
    "URL": "https://doi.org/10.1145/3491102.3517547"
  },
  {
    "id": "10.1145/3491102.3501843",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Seita",
        "given": "Matthew"
      },
      {
        "family": "Lee",
        "given": "Sooyeon"
      },
      {
        "family": "Andrew",
        "given": "Sarah"
      },
      {
        "family": "Shinohara",
        "given": "Kristen"
      },
      {
        "family": "Huenerfauth",
        "given": "Matt"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Deaf and Hard-of-Hearing (DHH) users face accessibility challenges during in-person and remote meetings. While emerging use of applications incorporating automatic speech recognition (ASR) is promising, more user-interface and user-experience research is needed. While co-design methods could elucidate designs for such applications, COVID-19 has interrupted in-person research. This study describes a novel methodology for conducting online co-design workshops with 18 DHH and hearing participant pairs to investigate ASR-supported mobile and videoconferencing technologies along two design dimensions: Correcting errors in ASR output and implementing notification systems for influencing speaker behaviors. Our methodological findings include an analysis of communication modalities and strategies participants used, use of an online collaborative whiteboarding tool, and how participants reconciled differences in ideas. Finally, we present guidelines for researchers interested in online DHH co-design methodologies, enabling greater geographically diversity among study participants even beyond the current pandemic.",
    "call-number": "10.1145/3491102.3501843",
    "collection-number": "460",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501843",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Automatic Speech Recognition, Deaf and Hard-of-Hearing, Participatory Design, Videoconferencing, Accessibility",
    "number": "Article 460",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Remotely Co-Designing Features for Communication Applications using Automatic Captioning with Deaf and Hearing Pairs",
    "URL": "https://doi.org/10.1145/3491102.3501843"
  },
  {
    "id": "10.1145/3491102.3502143",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fok",
        "given": "Raymond"
      },
      {
        "family": "Zhong",
        "given": "Mingyuan"
      },
      {
        "family": "Ross",
        "given": "Anne Spencer"
      },
      {
        "family": "Fogarty",
        "given": "James"
      },
      {
        "family": "Wobbrock",
        "given": "Jacob O."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present the first large-scale longitudinal analysis of missing label accessibility failures in Android apps. We developed a crawler and collected monthly snapshots of 312 apps over 16 months. We use this unique dataset in empirical examinations of accessibility not possible in prior datasets. Key large-scale findings include missing label failures in 55.6% of unique image-based elements, longitudinal improvement in ImageButton elements but not in more prevalent ImageView elements, that 8.8% of unique screens are unreachable without navigating at least one missing label failure, that app failure rate does not improve with number of downloads, and that effective labeling is neither limited to nor guaranteed by large software organizations. We then examine longitudinal data in individual apps, presenting illustrative examples of accessibility impacts of systematic improvements, incomplete improvements, interface redesigns, and accessibility regressions. We discuss these findings and potential opportunities for tools and practices to improve label-based accessibility.",
    "call-number": "10.1145/3491102.3502143",
    "collection-number": "461",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502143",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "large-scale longitudinal analysis, mobile app accessibility",
    "number": "Article 461",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Large-Scale Longitudinal Analysis of Missing Label Accessibility Failures in Android Apps",
    "URL": "https://doi.org/10.1145/3491102.3502143"
  },
  {
    "id": "10.1145/3491102.3501966",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Jaewook"
      },
      {
        "family": "Herskovitz",
        "given": "Jaylin"
      },
      {
        "family": "Peng",
        "given": "Yi-Hao"
      },
      {
        "family": "Guo",
        "given": "Anhong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Blind users rely on alternative text (alt-text) to understand an image; however, alt-text is often missing. AI-generated captions are a more scalable alternative, but they often miss crucial details or are completely incorrect, which users may still falsely trust. In this work, we sought to determine how additional information could help users better judge the correctness of AI-generated captions. We developed\u00a0ImageExplorer, a touch-based multi-layered image exploration system that allows users to explore the spatial layout and information hierarchies of images, and compared it with popular text-based (Facebook) and touch-based (Seeing AI) image exploration systems in a study with 12 blind participants. We found that exploration was generally successful in encouraging skepticism towards imperfect captions. Moreover, many participants preferred\u00a0ImageExplorer for its multi-layered and spatial information presentation, and Facebook for its summary and ease of use. Finally, we identify design improvements for effective and explainable image exploration systems for blind users.",
    "call-number": "10.1145/3491102.3501966",
    "collection-number": "462",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501966",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Automatic image captioning, alt text, imperfect AI, Blind, visual impairment, screen reader, alternative text, accessibility, touch exploration, encourage skepticism",
    "number": "Article 462",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ImageExplorer: Multi-Layered Touch Exploration to Encourage Skepticism Towards Imperfect AI-Generated Image Captions",
    "URL": "https://doi.org/10.1145/3491102.3501966"
  },
  {
    "id": "10.1145/3491102.3501881",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Herdel",
        "given": "Viviane"
      },
      {
        "family": "Yamin",
        "given": "Lee J."
      },
      {
        "family": "Cauchard",
        "given": "Jessica R."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Interacting with flying objects has fueled people\u2019s imagination throughout history. Over the past decade, the Human-Drone Interaction (HDI) community has been working towards making this dream a reality. Despite notable findings, we lack a high-level perspective on the current and future use cases for interacting with drones. We present a holistic view of domains and applications of use that are described, studied, and envisioned in the HDI body of work. To map the extent and nature of the prior research, we performed a scoping review (N=217). We identified 16 domains and over 100 applications where drones and people interact together. We then describe in depth the main domains and applications reported in the literature and further present under-explored use cases with great potential. We conclude with fundamental challenges and opportunities for future research in the field. This work contributes a systematic step towards increased replicability and generalizability of HDI research.",
    "call-number": "10.1145/3491102.3501881",
    "collection-number": "463",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501881",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Classification., Human-Drone Interaction, Domains, Scoping Review, Robot, UAV, Applications, Context",
    "number": "Article 463",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Above and Beyond: A Scoping Review of Domains and Applications for Human-Drone Interaction",
    "URL": "https://doi.org/10.1145/3491102.3501881"
  },
  {
    "id": "10.1145/3491102.3517726",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cherng",
        "given": "Fu-Yin"
      },
      {
        "family": "Fang",
        "given": "Jingchao"
      },
      {
        "family": "Jiang",
        "given": "Yinhao"
      },
      {
        "family": "Chen",
        "given": "Xin"
      },
      {
        "family": "Choi",
        "given": "Taejun"
      },
      {
        "family": "Wang",
        "given": "Hao-Chuan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online platforms commonly collect and display user-generated information to support subsequent users\u2019 decision-making. However, studies have noticed that presenting collective information can pose social influences on individuals\u2019 opinions and alter their preferences accordingly. It is essential to deepen understanding of people\u2019s preferences when exposed to others\u2019 opinions and the underlying cognitive mechanisms to address potential biases. Hence, we conducted a laboratory study to investigate how products\u2019 ratings and reviews influence participants\u2019 stated preferences and cognitive responses assessed by their Electroencephalography (EEG) signals. The results showed that social ratings and reviews could alter participants\u2019 preferences and affect their status of attention, working memory, and emotion. We further conducted predictive analyses to show that participants\u2019 Electroencephalography-based measures can achieve higher power than behavioral measures to discriminate how collective information is displayed to users. We discuss the design implications informed by the results to shed light on the design of collective rating systems.",
    "call-number": "10.1145/3491102.3517726",
    "collection-number": "464",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517726",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "EEG, Social Influence, Social Conformity, Brain-Computer Interface, Online Rating",
    "number": "Article 464",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Social Influence in Collective Product Ratings Using Behavioral and Cognitive Metrics",
    "URL": "https://doi.org/10.1145/3491102.3517726"
  },
  {
    "id": "10.1145/3491102.3501876",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dutta",
        "given": "Senjuti"
      },
      {
        "family": "Linder",
        "given": "Rhema"
      },
      {
        "family": "Lowe",
        "given": "Doug"
      },
      {
        "family": "Rosenbalm",
        "given": "Richard"
      },
      {
        "family": "Kuzminykh",
        "given": "Anastasia"
      },
      {
        "family": "Williams",
        "given": "Alex C"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "There is a growing interest in extending crowdwork beyond traditional desktop-centric design to include mobile devices (e.g., smartphones). However, mobilizing crowdwork remains significantly tedious due to a lack of understanding about the mobile usability requirements of human intelligence tasks (HITs). We present a taxonomy of characteristics that defines the mobile usability of HITs for smartphone devices. The taxonomy is developed based on findings from a study of three consecutive steps. In Step 1, we establish an initial design of our taxonomy through a targeted literature analysis. In Step 2, we verify and extend the taxonomy through an online survey with Amazon Mechanical Turk crowdworkers. Finally, in Step 3 we demonstrate the taxonomy\u2019s utility by applying it to analyze the mobile usability of a dataset of scraped HITs. In this paper, we present the iterative development of the taxonomy, highlighting the observed practices and preferences around mobile crowdwork. We conclude with the implications of our taxonomy for accessibly and ethically mobilizing crowdwork not only within the context of smartphone devices, but beyond them.",
    "call-number": "10.1145/3491102.3501876",
    "collection-number": "465",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501876",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Taxonomy, Human Intelligence Tasks., Crowdwork, Mobile Usability",
    "number": "Article 465",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Mobilizing Crowdwork:A Systematic Assessment of the Mobile Usability of HITs",
    "URL": "https://doi.org/10.1145/3491102.3501876"
  },
  {
    "id": "10.1145/3491102.3502098",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Schankin",
        "given": "Andrea"
      },
      {
        "family": "Budde",
        "given": "Matthias"
      },
      {
        "family": "Riedel",
        "given": "Till"
      },
      {
        "family": "Beigl",
        "given": "Michael"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "User experience (UX) summarizes user perceptions and responses resulting from the interaction with a product, system, or service. The User Experience Questionnaire (UEQ) is one standardized instrument for measuring UX. With six scales, it identifies areas in which product improvements will have the highest impact. In this paper, we evaluate the reliability and validity of this questionnaire. The data of N = 1, 121 participants who interacted with one of 23 products indicated an acceptable to good reliability of all scales. The results show, however, that the scales were not independent of each other. Combining perspicuity, efficiency, and dependability to pragmatic aspects as well as novelty and stimulation to hedonic aspects of UX improved the model fit significantly. The systematic variations of product properties and correlations with the System Usability Scale (SUS) in a second experiment with N=499 participants supported the validity of these two factors. Practical implications of the results are discussed.",
    "call-number": "10.1145/3491102.3502098",
    "collection-number": "466",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502098",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "psychometric properties, user experience, UEQ",
    "number": "Article 466",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Psychometric Properties of the User Experience Questionnaire (UEQ)",
    "URL": "https://doi.org/10.1145/3491102.3502098"
  },
  {
    "id": "10.1145/3491102.3501897",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Abbott",
        "given": "Jacob"
      },
      {
        "family": "Kaye",
        "given": "Jofish"
      },
      {
        "family": "Clawson",
        "given": "James"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In the last decade, interest in accessible and eyes-free text entry has continued to grow. However, little research has been done to explore the feasibility of using audibly distinct phrases for text entry tasks. To better understand whether preexisting phrases used in text entry research are sufficiently distinct for eyes-free text entry tasks, we used Microsoft\u2019s and Apple\u2019s desktop text-to-speech systems to generate all 500 phrases from MacKenzie and Soukoreff\u2019s set [32] using the default male and female voices. We then asked 392 participants recruited through Amazon\u2019s Mechanical Turk to transcribe the generated audio clips. We report participant transcription errors and present the 96 phrases that were observed with no comprehension errors. These phrases were further tested with 80 participants who identified as low-vision and/or blind recruited through Twitter. We contribute the 92 phrases that were observed to maintain no comprehension errors across both experiments.",
    "call-number": "10.1145/3491102.3501897",
    "collection-number": "467",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501897",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "input techniques, TTS, text entry, synthesized speech, accessibility, text-to-speech",
    "number": "Article 467",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Identifying an Aurally Distinct Phrase Set for Text Entry Techniques",
    "URL": "https://doi.org/10.1145/3491102.3501897"
  },
  {
    "id": "10.1145/3491102.3502014",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dechant",
        "given": "Martin Johannes"
      },
      {
        "family": "Welsch",
        "given": "Robin"
      },
      {
        "family": "Frommel",
        "given": "Julian"
      },
      {
        "family": "Mandryk",
        "given": "Regan L"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Social interactions are an essential part of many digital games, and provide benefits to players; however, problematic social interactions also lead to harm. To inform our understanding of the origins of harmful social behaviours in gaming contexts, we examine how trait psychopathy influences player perceptions and behaviours within a gaming task. After measuring participants\u2019 (n=385) trait-level boldness, meanness, and disinhibition, we expose them to neutral and angry social interactions with a non-player character (NPC) in a gaming task and assess their perceptions, verbal responses, and movement behaviours. Our findings demonstrate that the traits significantly influence interpretation of NPC emotion, verbal responses to the NPC, and movement behaviours around the NPC. These insights can inform the design of social games and communities and can help designers and researchers better understand how social functioning translates into gaming contexts.",
    "call-number": "10.1145/3491102.3502014",
    "collection-number": "468",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502014",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "interpersonal distance, psychopathy, disinhibition, personality traits, social interaction, meanness, boldness, gaming, behaviour",
    "number": "Article 468",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "(Don\u2019t) stand by me: How trait psychopathy and NPC emotion influence player perceptions, verbal responses, and movement behaviours in a gaming task",
    "URL": "https://doi.org/10.1145/3491102.3502014"
  },
  {
    "id": "10.1145/3491102.3502019",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Arrambide",
        "given": "Karina"
      },
      {
        "family": "Yoon",
        "given": "John"
      },
      {
        "family": "MacArthur",
        "given": "Cayley"
      },
      {
        "family": "Rogers",
        "given": "Katja"
      },
      {
        "family": "Luz",
        "given": "Alessandra"
      },
      {
        "family": "Nacke",
        "given": "Lennart E."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In interactive story games, players make decisions that advance and modify the unfolding story. In many cases, these decisions have a moral component. Examining decision-making in these games illuminates whether players mobilize their real-life morality to make in-game decisions and what impact this has in both the game world and real life. Using mixed-methods consisting of semi-structured interviews and the Moral Foundations Questionnaire (MFQ30), we collected data from 19 participants who played the game Detroit: Become Human. We analyzed how participants applied their real-life morals toward in-game decisions using thematic analysis and statistical analysis of the MFQ30 results. Qualitative findings indicate that participants mobilize their moral intuitions to make in-game decisions and how much participants cared about their game characters influenced their choices. We contribute a better understanding of how players react to moral dilemmas in interactive story games for game designers to help them improve player experience.",
    "call-number": "10.1145/3491102.3502019",
    "collection-number": "469",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502019",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "choice, morality, moral foundations questionnaire, interactive story, moral foundations theory, interactive narrative, games, decision-making, thematic analysis",
    "number": "Article 469",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI Don\u2019t Want To Shoot The Android\u201d: Players Translate Real-Life Moral Intuitions to In-Game Decisions in Detroit: Become Human",
    "URL": "https://doi.org/10.1145/3491102.3502019"
  },
  {
    "id": "10.1145/3491102.3502002",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cole",
        "given": "Tom"
      },
      {
        "family": "Gillies",
        "given": "Marco"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Research on the emotional experience of playing videogames has increased in recent years, yet much of this work is focused on the hedonistic player experience (PX) commonly associated with the nebulous concept of \u2018fun\u2019 and positive affect. Researchers are increasingly paying more attention to the eudaimonic PX commonly associated with \u2018appreciation\u2019, mixed-affect and reflection. To further investigate eudaimonic PX we interviewed 24 games players about \u2018significant or memorable emotional experiences\u2019 from their games playing and used grounded theory to analyse their responses. This led to the construction of the concept of \u2018emotional exploration\u2019 which is used to help explain (i) why players would seek out a eudaimonic PX, (ii) how eudaimonic PX is constituted and (iii) how developers can design for a eudaimonic PX. We further make the case for the \u2018eudaimonic gameplay experience\u2019 to be realised as different and separate to pre-existing notions of eudaimonic entertainment.",
    "call-number": "10.1145/3491102.3502002",
    "collection-number": "470",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502002",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mixed affect, grounded theory, emotions, gameplay, eudaimonia, videogames",
    "number": "Article 470",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Emotional Exploration and the Eudaimonic Gameplay Experience: A Grounded Theory",
    "URL": "https://doi.org/10.1145/3491102.3502002"
  },
  {
    "id": "10.1145/3491102.3501858",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ballou",
        "given": "Nick"
      },
      {
        "family": "Deterding",
        "given": "Sebastian"
      },
      {
        "family": "Iacovides",
        "given": "Ioanna"
      },
      {
        "family": "Helsby",
        "given": "Laura"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Do people use games to cope with adverse life events and crises? Research informed by self-determination theory proposes that people might compensate for thwarted basic psychological needs in daily life by seeking out games that satisfy those lacking needs. To test this, we conducted a preregistered mixed-method survey study (n = 285) on people\u2019s gaming behaviours and need states during early stages of the COVID-19 pandemic (May 2020). We found qualitative evidence that gaming was an often actively sought out and successful means of replenishing particular needs, but one that could \u2018backfire\u2019 for some through an appraisal process discounting gaming as \u2018unreal\u2019. Meanwhile, contrary to our predictions, the quantitative data showed a \u201crich get richer, poor get poorer\u201d pattern: need satisfaction in daily life positively correlated with need satisfaction in games. We derive methodological considerations and propose three potential explanations for this contradictory data pattern to pursue in future research.",
    "call-number": "10.1145/3491102.3501858",
    "collection-number": "471",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501858",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mixed methods, coping, Covid-19, compensation, basic needs, video games",
    "number": "Article 471",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Do People Use Games to Compensate for Psychological Needs During Crises? A Mixed-Methods Study of Gaming During COVID-19 Lockdowns",
    "URL": "https://doi.org/10.1145/3491102.3501858"
  },
  {
    "id": "10.1145/3491102.3501954",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "M\u00fcller",
        "given": "Philipp"
      },
      {
        "family": "Staal",
        "given": "Sander"
      },
      {
        "family": "B\u00e2ce",
        "given": "Mihai"
      },
      {
        "family": "Bulling",
        "given": "Andreas"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Desktop notifications should be noticeable but are also subject to a number of design choices, e.g. concerning their size, placement, or opacity. It is currently unknown, however, how these choices interact with the desktop background and their influence on noticeability. To address this limitation, we introduce a software tool to automatically synthesize realistically looking desktop images for major operating systems and applications. Using these images, we present a user study (N=34) to investigate the noticeability of notifications during a primary task. We are first to show that visual importance of the background at the notification location significantly impacts whether users detect notifications. We analyse the utility of visual importance to compensate for suboptimal design choices with respect to noticeability, e.g. small notification size. Finally, we introduce noticeability maps - 2D maps encoding the predicted noticeability across the desktop and inform designers how to trade-off notification design and noticeability.",
    "call-number": "10.1145/3491102.3501954",
    "collection-number": "472",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501954",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "notifications, attention, graphical user interfaces, dual task performance",
    "number": "Article 472",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing for Noticeability: Understanding the Impact of Visual Importance on Desktop Notifications",
    "URL": "https://doi.org/10.1145/3491102.3501954"
  },
  {
    "id": "10.1145/3491102.3501909",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Viswanathan",
        "given": "Sruthi"
      },
      {
        "family": "Boulard",
        "given": "Cecile"
      },
      {
        "family": "Bruyat",
        "given": "Adrien"
      },
      {
        "family": "Maria Grasso",
        "given": "Antonietta"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "When people engage in urban exploration, the tool they are most likely to use today is a mobile phone. In this paper, we present observations of users\u2019 \u201chome\u201d and \u201caway\u201d conducted to refine our understanding of situational Point-of-Interest (POI) needs. Our findings suggest three distinct categories of situations in which users seek POI information: On-the-spot, Refining plans, and Moments of boredom. Based on the similarities and differences of these three situations in five observed underlying constraints \u2013 distance of interest, engagement threshold, ambiguity of the search, profile matching, and other imperative constraints, we derive implications for designing and ranking POIs for a Situational Recommender. To further access our concept, we designed and prototyped Situational Recommender by providing an interactional representation of the situation, and ran a Wizard-of-Oz concept validation study. Our results suggest that participants understood the concept without much effort and appreciated its usefulness.",
    "call-number": "10.1145/3491102.3501909",
    "collection-number": "473",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501909",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "POI Recommender System, CAI, Situation modelling, Situation Aware, User Studies, Mobile Devices, Prototyping, Interaction Design",
    "number": "Article 473",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Situational Recommender: Are You On the Spot, Refining Plans, or Just Bored?",
    "URL": "https://doi.org/10.1145/3491102.3501909"
  },
  {
    "id": "10.1145/3491102.3517731",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Yihe"
      },
      {
        "family": "Mittal",
        "given": "Anushk"
      },
      {
        "family": "Yang",
        "given": "Diyi"
      },
      {
        "family": "Bruckman",
        "given": "Amy"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Large language models are increasingly mediating, modifying, and even generating messages for users, but the receivers of these messages may not be aware of the involvement of AI. To examine this emerging direction of AI-Mediated Communication (AI-MC), we investigate people\u2019s perceptions of AI written messages. We analyze how such perceptions change in accordance with the interpersonal emphasis of a given message. We conducted both large-scale surveys and in-depth interviews to investigate how a diverse set of factors influence people\u2019s perceived trust in AI-mediated writing of emails. We found that people\u2019s trust in email writers decreased when they were told that AI was involved in the writing process. Surprisingly trust increased when AI was used for writing more interpersonal emails (as opposed to more transactional ones). Our study provides insights regarding how people perceive AI-MC and has practical design implications on building AI-based products to aid human interlocutors in communication1.",
    "call-number": "10.1145/3491102.3517731",
    "collection-number": "474",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517731",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Computer-Mediated Communication (CMC), Artificial Intelligence, Trust, Artificial Intelligence-Mediated Communication (AI-MC)",
    "number": "Article 474",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Will AI Console Me when I Lose my Pet? Understanding Perceptions of AI-Mediated Email Writing",
    "URL": "https://doi.org/10.1145/3491102.3517731"
  },
  {
    "id": "10.1145/3491102.3502088",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "M. DiCosola III",
        "given": "Blake"
      },
      {
        "family": "Neff",
        "given": "Gina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper revisits concepts of nudge in the context of helping consumers to make healthier food choices. We introduce a novel form of social influence nudge not yet investigated by HCI scholars, the out-group social comparison, and test whether this form of nudging works at the point of checkout rather than the more conventional point of product consideration. Across two online experiments, we measure the effectiveness of using nutritional information nudges with added in-group (people like you) and out-group (people not like you) social comparisons. Our preliminary findings suggest that out-group social comparison nudges can be effective in encouraging both normal weight and overweight adults to reduce calories, even when these adults indicate that they do not typically change their diet behaviors. This research has implications for digital information design, interactive marketing, and public health.",
    "call-number": "10.1145/3491102.3502088",
    "collection-number": "475",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502088",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "food, social influence, health, information design, Consumer behavior, intervention, choice, nudging, decision making, diet, digital shopping, online, nutrition, persuasive communication",
    "number": "Article 475",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Nudging Behavior Change: Using In-Group and Out-Group Social Comparisons to Encourage Healthier Choices",
    "URL": "https://doi.org/10.1145/3491102.3502088"
  },
  {
    "id": "10.1145/3491102.3517678",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Siu",
        "given": "Alexa"
      },
      {
        "family": "S-H Kim",
        "given": "Gene"
      },
      {
        "family": "O'Modhrain",
        "given": "Sile"
      },
      {
        "family": "Follmer",
        "given": "Sean"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Online data visualizations play an important role in informing public opinion but are often inaccessible to screen reader users. To address the need for accessible data representations on the web that provide direct, multimodal, and up-to-date access to the data, we investigate audio data narratives \u2013which combine textual descriptions and sonification (the mapping of data to non-speech sounds). We conduct two co-design workshops with screen reader users to define design principles that guide the structure, content, and duration of a data narrative. Based on these principles and relevant auditory processing characteristics, we propose a dynamic programming approach to automatically generate an audio data narrative from a given dataset. We evaluate our approach with 16 screen reader users. Findings show with audio narratives, users gain significantly more insights from the data. Users describe data narratives help them better extract and comprehend the information in both the sonification and description.",
    "call-number": "10.1145/3491102.3517678",
    "collection-number": "476",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517678",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sonification, data narratives, accessibility, data visualization",
    "number": "Article 476",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting Accessible Data Visualization Through Audio Data Narratives",
    "URL": "https://doi.org/10.1145/3491102.3517678"
  },
  {
    "id": "10.1145/3491102.3517790",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fan",
        "given": "Danyang"
      },
      {
        "family": "Siu",
        "given": "Alexa Fay"
      },
      {
        "family": "Law",
        "given": "Wing-Sum Adrienne"
      },
      {
        "family": "Zhen",
        "given": "Raymond Ruihong"
      },
      {
        "family": "O'Modhrain",
        "given": "Sile"
      },
      {
        "family": "Follmer",
        "given": "Sean"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We increasingly rely on up-to-date, data-driven graphs to understand our environments and make informed decisions. However, many of the methods blind and visually impaired users (BVI) rely on to access data-driven information do not convey important shape-characteristics of graphs, are not refreshable, or are prohibitively expensive. To address these limitations, we introduce two refreshable, 1-DOF audio-haptic interfaces based on haptic cues fundamental to object shape perception. Slide-tone uses finger position with sonification, and Tilt-tone uses fingerpad contact inclination with sonification to provide shape feedback to users. Through formative design workshops (n = 3) and controlled evaluations (n = 8), we found that BVI participants appreciated the additional shape information, versatility, and reinforced understanding these interfaces provide; and that task accuracy was comparable to using interactive tactile graphics or sonification alone. Our research offers insight into the benefits, limitations, and considerations for adopting these haptic cues into a data visualization context.",
    "call-number": "10.1145/3491102.3517790",
    "collection-number": "477",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517790",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "haptic data visualization, accessible data visualization, accessibility",
    "number": "Article 477",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Slide-Tone and Tilt-Tone: 1-DOF Haptic Techniques for Conveying Shape Characteristics of Graphs to Blind Users",
    "URL": "https://doi.org/10.1145/3491102.3517790"
  },
  {
    "id": "10.1145/3491102.3517431",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sharif",
        "given": "Ather"
      },
      {
        "family": "Wang",
        "given": "Olivia H."
      },
      {
        "family": "Muongchan",
        "given": "Alida T."
      },
      {
        "family": "Reinecke",
        "given": "Katharina"
      },
      {
        "family": "Wobbrock",
        "given": "Jacob O."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "JavaScript visualization libraries are widely used to create online data visualizations but provide limited access to their information for screen-reader users. Building on prior findings about the experiences of screen-reader users with online data visualizations, we present VoxLens, an open-source JavaScript plug-in that\u2014with a single line of code\u2014improves the accessibility of online data visualizations for screen-reader users using a multi-modal approach. Specifically, VoxLens enables screen-reader users to obtain a holistic summary of presented information, play sonified versions of the data, and interact with visualizations in a \u201cdrill-down\u201d manner using voice-activated commands. Through task-based experiments with 21 screen-reader users, we show that VoxLens improves the accuracy of information extraction and interaction time by 122% and 36%, respectively, over existing conventional interaction with online data visualizations. Our interviews with screen-reader users suggest that VoxLens is a \u201cgame-changer\u201d in making online data visualizations accessible to screen-reader users, saving them time and effort.",
    "call-number": "10.1145/3491102.3517431",
    "collection-number": "478",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517431",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Visualizations, screen readers, low-vision., blind, accessibility, voice-based interaction",
    "number": "Article 478",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "VoxLens: Making Online Data Visualizations Accessible with an Interactive JavaScript Plug-In",
    "URL": "https://doi.org/10.1145/3491102.3517431"
  },
  {
    "id": "10.1145/3491102.3517465",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Holloway",
        "given": "Leona M"
      },
      {
        "family": "Goncu",
        "given": "Cagatay"
      },
      {
        "family": "Ilsar",
        "given": "Alon"
      },
      {
        "family": "Butler",
        "given": "Matthew"
      },
      {
        "family": "Marriott",
        "given": "Kim"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data visualisations are increasingly used online to engage readers and enable independent analysis of the data underlying news stories. However, access to such infographics is problematic for readers who are blind or have low vision (BLV). Equitable access to information is a basic human right and essential for independence and inclusion. We introduce infosonics, the audio equivalent of infographics, as a new style of interactive sonification that uses a spoken introduction and annotation, non-speech audio and sound design elements to present data in an understandable and engaging way. A controlled user evaluation with 18 BLV adults found a COVID-19 infosonic enabled a clearer mental image than a traditional sonification. Further, infosonics prove complementary to text descriptions and facilitate independent understanding of the data. Based on our findings, we provide preliminary suggestions for infosonics design, which we hope will enable BLV people to gain equitable access to online news and information.",
    "call-number": "10.1145/3491102.3517465",
    "collection-number": "480",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517465",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sonification, low vision, Blind, information access, accessible graphics",
    "number": "Article 480",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Infosonics: Accessible Infographics for People who are Blind using Sonification and Voice",
    "URL": "https://doi.org/10.1145/3491102.3517465"
  },
  {
    "id": "10.1145/3491102.3517537",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Subramonyam",
        "given": "Hariharan"
      },
      {
        "family": "Im",
        "given": "Jane"
      },
      {
        "family": "Seifert",
        "given": "Colleen"
      },
      {
        "family": "Adar",
        "given": "Eytan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In conventional software development, user experience (UX) designers and engineers collaborate through separation of concerns (SoC): designers create human interface specifications, and engineers build to those specifications. However, we argue that Human-AI systems thwart SoC because human needs must shape the design of the AI interface, the underlying AI sub-components, and training data. How do designers and engineers currently collaborate on AI and UX design? To find out, we interviewed 21 industry professionals (UX researchers, AI engineers, data scientists, and managers) across 14 organizations about their collaborative work practices and associated challenges. We find that hidden information encapsulated by SoC challenges collaboration across design and engineering concerns. Practitioners describe inventing ad-hoc representations exposing low-level design and implementation details (which we characterize as leaky abstractions) to \u201cpuncture\u201d SoC and share information across expertise boundaries. We identify how leaky abstractions are employed to collaborate at the AI-UX boundary and formalize a process of creating and using leaky abstractions.",
    "call-number": "10.1145/3491102.3517537",
    "collection-number": "481",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517537",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design processes, UX design, Industry practices, Human-AI systems, AI applications",
    "number": "Article 481",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Solving Separation-of-Concerns Problems in Collaborative Design of Human-AI Systems through Leaky Abstractions",
    "URL": "https://doi.org/10.1145/3491102.3517537"
  },
  {
    "id": "10.1145/3491102.3501916",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fran\u00e7oise",
        "given": "Jules"
      },
      {
        "family": "Fdili Alaoui",
        "given": "Sarah"
      },
      {
        "family": "Candau",
        "given": "Yves"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present a performance-led inquiry that involved a live coder programming movement-based interactive sound and two dance improvisers. During two years of collaboration, we developed a joint improvisation practice where the interactions between the dancers\u2019 movement and the sound feedback are programmed on the fly through live coding and movement sensing. To that end, we designed a new live coding environment called CO/DA that facilitates the real-time manipulation of continuous streams of the dancers\u2019 motion data for interactive sound synthesis. Through an autoethnographic inquiry, we describe our practice of sound and movement improvisation where live coding dynamically changes how the dancers\u2019 movements generate sound, which in turn influences the dancers\u2019 improvisation. We then discuss the value, potential and challenges of our dance/code improvisation practice, along with its implications as a design method.",
    "call-number": "10.1145/3491102.3501916",
    "collection-number": "482",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501916",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Improvisation, Live Coding, Movement, Design., Embodied Interaction, Dance",
    "number": "Article 482",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CO/DA: Live-Coding Movement-Sound Interactions for Dance Improvisation",
    "URL": "https://doi.org/10.1145/3491102.3501916"
  },
  {
    "id": "10.1145/3491102.3517491",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yildirim",
        "given": "Nur"
      },
      {
        "family": "Kass",
        "given": "Alex"
      },
      {
        "family": "Tung",
        "given": "Teresa"
      },
      {
        "family": "Upton",
        "given": "Connor"
      },
      {
        "family": "Costello",
        "given": "Donnacha"
      },
      {
        "family": "Giusti",
        "given": "Robert"
      },
      {
        "family": "Lacin",
        "given": "Sinem"
      },
      {
        "family": "Lovic",
        "given": "Sara"
      },
      {
        "family": "O'Neill",
        "given": "James M"
      },
      {
        "family": "Meehan",
        "given": "Rudi O'Reilly"
      },
      {
        "family": "\u00d3 Loide\u00e1in",
        "given": "Eoin"
      },
      {
        "family": "Pini",
        "given": "Azzurra"
      },
      {
        "family": "Corcoran",
        "given": "Medb"
      },
      {
        "family": "Hayes",
        "given": "Jeremiah"
      },
      {
        "family": "Cahalane",
        "given": "Diarmuid J"
      },
      {
        "family": "Shivhare",
        "given": "Gaurav"
      },
      {
        "family": "Castoro",
        "given": "Luigi"
      },
      {
        "family": "Caruso",
        "given": "Giovanni"
      },
      {
        "family": "Oh",
        "given": "Changhoon"
      },
      {
        "family": "McCann",
        "given": "James"
      },
      {
        "family": "Forlizzi",
        "given": "Jodi"
      },
      {
        "family": "Zimmerman",
        "given": "John"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "HCI research has explored AI as a design material, suggesting that designers can envision AI\u2019s design opportunities to improve UX. Recent research claimed that enterprise applications offer an opportunity for AI innovation at the user experience level. We conducted design workshops to explore the practices of experienced designers who work on cross-functional AI teams in the enterprise. We discussed how designers successfully work with and struggle with AI. Our findings revealed that designers can innovate at the system and service levels. We also discovered that making a case for an AI feature\u2019s return on investment is a barrier for designers when they propose AI concepts and ideas. Our discussions produced novel insights on designers\u2019 role on AI teams, and the boundary objects they used for collaborating with data scientists. We discuss the implications of these findings as opportunities for future research aiming to empower designers in working with data and AI.",
    "call-number": "10.1145/3491102.3517491",
    "collection-number": "483",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517491",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "User experience, artificial intelligence, design, machine learning",
    "number": "Article 483",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How Experienced Designers of Enterprise Applications Engage AI as a Design Material",
    "URL": "https://doi.org/10.1145/3491102.3517491"
  },
  {
    "id": "10.1145/3491102.3502013",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dahl",
        "given": "Yngve"
      },
      {
        "family": "Sharma",
        "given": "Kshitij"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Participatory design facilitators have a significant impact on participatory activities, processes, and outcomes. However, the facilitator role has not yet been thoroughly debated in existing design discourse, and support for role-related reflections is limited. As the first steps towards an enriched collective understanding of this specific role and its realization, we interviewed 14 respondents with an academic background in participatory design and extensive facilitation experience. Based on a content analysis of the interviews, we identified six facets of the role: (1) trust builder, (2) enabler, (3) inquirer, (4) direction setter, (5) value provider, and (6) users\u2019 advocate. Each facet is presented as consisting of the respondents\u2019 perceived associated responsibilities and corresponding strategies. Our results paint a complex picture of participatory design facilitation. We propose the multi-faceted understanding of the facilitator role emerging from this work as a basis for problematized reflection on the role and its realization.",
    "call-number": "10.1145/3491102.3502013",
    "collection-number": "484",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502013",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "role, Participation, facilitation, reflection",
    "number": "Article 484",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Six Facets of Facilitation: Participatory Design Facilitators\u2019 Perspectives on Their Role and Its Realization",
    "URL": "https://doi.org/10.1145/3491102.3502013"
  },
  {
    "id": "10.1145/3491102.3502109",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "H. Tan",
        "given": "Neilly"
      },
      {
        "family": "Kinnee",
        "given": "Brian"
      },
      {
        "family": "Langseth",
        "given": "Dana"
      },
      {
        "family": "A. Munson",
        "given": "Sean"
      },
      {
        "family": "Desjardins",
        "given": "Audrey"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Smart home cameras present new challenges for understanding behaviors and relationships surrounding always-on, domestic recording systems. We designed a series of discursive activities involving 16 individuals from ten households for six weeks in their everyday settings. These activities functioned as speculative probes\u2014prompting participants to reflect on themes of privacy and power through filming with cameras in their households. Our research design foregrounded critical-playful enactments that allowed participants to speculate potentials for relationships with cameras in the home beyond everyday use. We present four key dynamics with participants and home cameras by examining their relationships to: the camera's eye, filming, their data, and camera's societal contexts. We contribute discussions about the mundane, information privacy, and post-hoc reflection with one's camera footage. Overall, our findings reveal the camera as a strange, yet banal entity in the home\u2014interrogating how participants compose and handle their own and others\u2019 video data.",
    "call-number": "10.1145/3491102.3502109",
    "collection-number": "485",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502109",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "domestic technology, privacy, smart cameras, personal data, Internet of Things, home, Design research, speculative, enactments",
    "number": "Article 485",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Critical-Playful Speculations with Cameras in the Home",
    "URL": "https://doi.org/10.1145/3491102.3502109"
  },
  {
    "id": "10.1145/3491102.3501936",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liao",
        "given": "Mengqi"
      },
      {
        "family": "Sundar",
        "given": "S. Shyam"
      },
      {
        "family": "B. Walther",
        "given": "Joseph"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Three of the most common approaches used in recommender systems are content-based filtering (matching users\u2019 preferences with products\u2019 characteristics), collaborative filtering (matching users with similar preferences), and demographic filtering (catering to users based on demographic characteristics). Do users\u2019 intuitions lead them to trust one of these approaches over others, independent of the actual operations of these different systems? Does their faith in one type or another depend on the quality of the recommendation, rather than how the recommendation appears to have been derived? We conducted an empirical study with a prototype of a movie recommender system to find out. A 3 (Ostensible Recommender Type: Content vs. Collaborative vs. Demographic Filtering) x 2 (Recommendation Quality: Good vs. Bad) experiment (N=226) investigated how users evaluate systems and attribute responsibility for the recommendations they receive. We found that users trust systems that use collaborative filtering more, regardless of the system's performance. They think that they themselves are responsible for good recommendations but that the system is responsible for bad recommendations (reflecting a self-serving bias). Theoretical insights, design implications and practical solutions for the cold start problem are discussed.",
    "call-number": "10.1145/3491102.3501936",
    "collection-number": "486",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501936",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Empirical study that tells us about how people use a system, User Experience Design, Personalization",
    "number": "Article 486",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "User Trust in Recommendation Systems: A comparison of Content-Based, Collaborative and Demographic Filtering",
    "URL": "https://doi.org/10.1145/3491102.3501936"
  },
  {
    "id": "10.1145/3491102.3517650",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hadash",
        "given": "Sophia"
      },
      {
        "family": "Willemsen",
        "given": "Martijn C."
      },
      {
        "family": "Snijders",
        "given": "Chris"
      },
      {
        "family": "IJsselsteijn",
        "given": "Wijnand A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Model-agnostic explainable AI tools explain their predictions by means of \u2019local\u2019 feature contributions. We empirically investigate two potential improvements over current approaches. The first one is to always present feature contributions in terms of the contribution to the outcome that is perceived as positive by the user (\u201cpositive framing\u201d). The second one is to add \u201csemantic labeling\u201d, that explains the directionality of each feature contribution (\u201cthis feature leads to +5% eligibility\u201d), reducing additional cognitive processing steps. In a user study, participants evaluated the understandability of explanations for different framing and labeling conditions for loan applications and music recommendations. We found that positive framing improves understandability even when the prediction is negative. Additionally, adding semantic labels eliminates any framing effects on understandability, with positive labels outperforming negative labels. We implemented our suggestions in a package ArgueView[11].",
    "call-number": "10.1145/3491102.3517650",
    "collection-number": "487",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517650",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "argumentation, interpretable machine learning, natural language, explanations",
    "number": "Article 487",
    "number-of-pages": "9",
    "page": "1\u20139",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Improving understandability of feature contributions in model-agnostic explainable AI tools",
    "URL": "https://doi.org/10.1145/3491102.3517650"
  },
  {
    "id": "10.1145/3491102.3501941",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yeh",
        "given": "Su-Fang"
      },
      {
        "family": "Wu",
        "given": "Meng-Hsin"
      },
      {
        "family": "Chen",
        "given": "Tze-Yu"
      },
      {
        "family": "Lin",
        "given": "Yen-Chun"
      },
      {
        "family": "Chang",
        "given": "XiJing"
      },
      {
        "family": "Chiang",
        "given": "You-Hsuan"
      },
      {
        "family": "Chang",
        "given": "Yung-Ju"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The popularity of task-oriented chatbots is constantly growing, but smooth conversational progress with them remains profoundly challenging. In recent years, researchers have argued that chatbot systems should include guidance for users on how to converse with them. Nevertheless, empirical evidence about what to place in such guidance, and when to deliver it, has been lacking. Using a mixed-methods approach that integrates results from a between-subjects experiment and a reflection session, this paper compares the effectiveness of eight combinations of two guidance types (example-based and rule-based) at four guidance timings (service-onboarding, task-intro, after-failure, and upon-request), as measured by users\u2019 task performance, improvement on subsequent tasks, and subjective experience. It establishes that each guidance type and timing has particular strengths and weaknesses, thus that each type/timing combination has a unique impact on performance metrics, learning outcomes, and user experience. On that basis, it presents guidance-design recommendations for future task-oriented chatbots.",
    "call-number": "10.1145/3491102.3501941",
    "collection-number": "488",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501941",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "non-progress, chatbot, guidance, lab study",
    "number": "Article 488",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How to Guide Task-oriented Chatbot Users, and When: A Mixed-methods Study of Combinations of Chatbot Guidance Types and Timings",
    "URL": "https://doi.org/10.1145/3491102.3501941"
  },
  {
    "id": "10.1145/3491102.3517471",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cai",
        "given": "Wanling"
      },
      {
        "family": "Jin",
        "given": "Yucheng"
      },
      {
        "family": "Chen",
        "given": "Li"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Conversational recommender systems (CRSs) imitate human advisors to assist users in finding items through conversations and have recently gained increasing attention in domains such as media and e-commerce. Like in human communication, building trust in human-agent communication is essential given its significant influence on user behavior. However, inspiring user trust in CRSs with a \u201cone-size-fits-all\u201d design is difficult, as individual users may have their own expectations for conversational interactions (e.g., who, user or system, takes the initiative), which are potentially related to their personal characteristics. In this study, we investigated the impacts of three personal characteristics, namely personality traits, trust propensity, and domain knowledge, on user trust in two types of text-based CRSs, i.e., user-initiative and mixed-initiative. Our between-subjects user study (N=148) revealed that users\u2019 trust propensity and domain knowledge positively influenced their trust in CRSs, and that users with high conscientiousness tended to trust the mixed-initiative system.",
    "call-number": "10.1145/3491102.3517471",
    "collection-number": "489",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517471",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "trust, Conversational recommender systems, mixed-initiative interaction, personal characteristics",
    "number": "Article 489",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Impacts of Personal Characteristics on User Trust in Conversational Recommender Systems",
    "URL": "https://doi.org/10.1145/3491102.3517471"
  },
  {
    "id": "10.1145/3491102.3501888",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jun",
        "given": "Eunice"
      },
      {
        "family": "Seo",
        "given": "Audrey"
      },
      {
        "family": "Heer",
        "given": "Jeffrey"
      },
      {
        "family": "Just",
        "given": "Ren\u00e9"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Proper statistical modeling incorporates domain theory about how concepts relate and details of how data were measured. However, data analysts currently lack tool support for recording and reasoning about domain assumptions, data collection, and modeling choices in an integrated manner, leading to mistakes that can compromise scientific validity. For instance, generalized linear mixed-effects models (GLMMs) help answer complex research questions, but omitting random effects impairs the generalizability of results. To address this need, we present Tisane, a mixed-initiative system for authoring generalized linear models with and without mixed-effects. Tisane introduces a study design specification language for expressing and asking questions about relationships between variables. Tisane contributes an interactive compilation process that represents relationships in a graph, infers candidate statistical models, and asks follow-up questions to disambiguate user queries to construct a valid model. In case studies with three researchers, we find that Tisane helps them focus on their goals and assumptions while avoiding past mistakes.",
    "call-number": "10.1145/3491102.3501888",
    "collection-number": "490",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501888",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "statistical analysis, end-user programming, transparent statistics, domain-specific language, validity, linear modeling, end-user elicitation",
    "number": "Article 490",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Tisane: Authoring Statistical Models via Formal Reasoning from Conceptual and Data Relationships",
    "URL": "https://doi.org/10.1145/3491102.3501888"
  },
  {
    "id": "10.1145/3491102.3501932",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Head",
        "given": "Andrew"
      },
      {
        "family": "Xie",
        "given": "Amber"
      },
      {
        "family": "Hearst",
        "given": "Marti A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With the increasing growth and impact of machine learning and other math-intensive fields, it is more important than ever to broaden access to mathematical notation. Can new visual and interactive displays help a wider readership successfully engage with notation? This paper provides the first detailed qualitative analysis of math augmentation\u2014the practice of embellishing notation with novel visual design patterns to improve its readability. We present two qualitative studies of the practice of math augmentation. First is an analysis of 1.1k augmentations to 281 formulas in 47 blogs, textbooks, and other documents containing mathematical expressions. Second is an interview study with 12 authors who had previously designed custom math augmentations (\u201cmaugs\u201d). This paper contributes a comprehensive inventory of the kinds of maugs that appear in math documents, and a detailed account of how authors\u2019 tools ought to be redesigned to support efficient creation of math augmentations. These studies open a critical new design space for HCI researchers and interface designers.",
    "call-number": "10.1145/3491102.3501932",
    "collection-number": "491",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501932",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "visual links, mathematical notation, details-on-demand, authoring",
    "number": "Article 491",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Math Augmentation: How Authors Enhance the Readability of Formulas using Novel Visual Design Practices",
    "URL": "https://doi.org/10.1145/3491102.3501932"
  },
  {
    "id": "10.1145/3491102.3502064",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Borowski",
        "given": "Marcel"
      },
      {
        "family": "Murray",
        "given": "Luke"
      },
      {
        "family": "Bagge",
        "given": "Rolf"
      },
      {
        "family": "Kristensen",
        "given": "Janus Bager"
      },
      {
        "family": "Satyanarayan",
        "given": "Arvind"
      },
      {
        "family": "Klokmose",
        "given": "Clemens Nylandsted"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Most modern applications are immutable and turn-key despite the acknowledged benefits of empowering users to modify their software. Writing extensible software remains challenging, even for expert programmers. Reprogramming or extending existing software is often laborious or wholly blocked, requiring sophisticated knowledge of application architecture or setting up a development environment. We present Varv, a programming model representing reprogrammable interactive software as a declarative data structure. Varv defines interactive applications as a set of concepts that consist of a schema and actions. Applications in Varv support incremental modification, allowing users to reprogram through addition and selectively suppress, modify, or add behavior. Users can define high-level concepts, creating an abstraction layer and effectively a domain-specific language for their application domain, emphasizing reuse and modification. We demonstrate the reprogramming and collaboration capabilities of Varv in two case studies and illustrate how the event engine allows for extensive tooling support.",
    "call-number": "10.1145/3491102.3502064",
    "collection-number": "492",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502064",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "declarative programming, reprogramming, real-time collaboration, interactive software, liveness",
    "number": "Article 492",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Varv: Reprogrammable Interactive Software as a Declarative Data Structure",
    "URL": "https://doi.org/10.1145/3491102.3502064"
  },
  {
    "id": "10.1145/3491102.3501940",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "An",
        "given": "Pengcheng"
      },
      {
        "family": "Zhou",
        "given": "Ziqi"
      },
      {
        "family": "Liu",
        "given": "Qing"
      },
      {
        "family": "Yin",
        "given": "Yifei"
      },
      {
        "family": "Du",
        "given": "Linghao"
      },
      {
        "family": "Huang",
        "given": "Da-Yuan"
      },
      {
        "family": "Zhao",
        "given": "Jian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Emoticons are indispensable in online communications. With users\u2019 growing needs for more customized and expressive emoticons, recent messaging applications begin to support (limited) multi-modal emoticons:, enhancing emoticons with animations or vibrotactile feedback. However, little empirical knowledge has been accumulated concerning how people create, share and experience multi-modal emoticons in everyday communication, and how to better support them through design. To tackle this, we developed VibEmoji, a user-authoring multi-modal emoticon interface for mobile messaging. Extending existing designs, VibEmoji grants users greater flexibility to combine various emoticons, vibrations, and animations on-the-fly, and offers non-aggressive recommendations based on these components\u2019 emotional relevance. Using VibEmoji as a probe, we conducted a four-week field study with 20 participants, to gain new understandings from in-the-wild usage and experience, and extract implications for design. We thereby contribute to both a novel system and various insights for supporting users\u2019 creation and communication of multi-modal emoticons.",
    "call-number": "10.1145/3491102.3501940",
    "collection-number": "493",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501940",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "animation, mobile interfaces., emoticons, Social communication, haptic feedback, multi-modal interaction, emotional expression",
    "number": "Article 493",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "VibEmoji: Exploring User-authoring Multi-modal Emoticons in Social Communication",
    "URL": "https://doi.org/10.1145/3491102.3501940"
  },
  {
    "id": "10.1145/3491102.3517472",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Zhi"
      },
      {
        "family": "Zhao",
        "given": "Maozheng"
      },
      {
        "family": "Das",
        "given": "Dibyendu"
      },
      {
        "family": "ZHAO",
        "given": "HANG"
      },
      {
        "family": "Ma",
        "given": "Yan"
      },
      {
        "family": "Liu",
        "given": "Wanyu"
      },
      {
        "family": "Beaudouin-Lafon",
        "given": "Michel"
      },
      {
        "family": "Wang",
        "given": "Fusheng"
      },
      {
        "family": "Ramakrishnan",
        "given": "IV"
      },
      {
        "family": "Bi",
        "given": "Xiaojun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Suggesting multiple target candidates based on touch input is a possible option for high-accuracy target selection on small touchscreen devices. But it can become overwhelming if suggestions are triggered too often. To address this, we propose SATS, a Suggestion-based Accurate Target Selection method, where target selection is formulated as a sequential decision problem. The objective is to maximize the utility: the negative time cost for the entire target selection procedure. The SATS decision process is dictated by a policy generated using reinforcement learning. It automatically decides when to provide suggestions and when to directly select the target. Our user studies show that SATS reduced error rate and selection time over Shift\u00a0[51], a magnification-based method, and MUCS, a suggestion-based alternative that optimizes the utility for the current selection. SATS also significantly reduced error rate over BayesianCommand\u00a0[58], which directly selects targets based on posteriors, with only a minor increase in selection time.",
    "call-number": "10.1145/3491102.3517472",
    "collection-number": "494",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517472",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Touch interaction, decision theory, target selection, reinforcement learning",
    "number": "Article 494",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Select or Suggest? Reinforcement Learning-based Method for High-Accuracy Target Selection on Touchscreens",
    "URL": "https://doi.org/10.1145/3491102.3517472"
  },
  {
    "id": "10.1145/3491102.3517738",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bonaker",
        "given": "Nicholas Ryan"
      },
      {
        "family": "Nel",
        "given": "Emli-Mari"
      },
      {
        "family": "Vertanen",
        "given": "Keith"
      },
      {
        "family": "Broderick",
        "given": "Tamara"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Some individuals with motor impairments communicate using a single switch \u2014 such as a button click, air puff, or blink. Row-column scanning provides a method for choosing items arranged in a grid using a single switch. An alternative, Nomon, allows potential selections to be arranged arbitrarily rather than requiring a grid (as desired for gaming, drawing, etc.) \u2014 and provides an alternative probabilistic selection method. While past results suggest that Nomon may be faster and easier to use than row-column scanning, no work has yet quantified performance of the two methods over longer time periods or in tasks beyond writing. In this paper, we also develop and validate a webcam-based switch that allows a user without a motor impairment to approximate the response times of a motor-impaired single switch user; although the approximation is not a replacement for testing with single-switch users, it allows us to better initialize, calibrate, and evaluate our method. Over 10 sessions with the webcam switch, we found users typed faster and more easily with Nomon than with row-column scanning. The benefits of Nomon were even more pronounced in a picture-selection task. Evaluation and feedback from a motor-impaired switch user further supports the promise of Nomon.",
    "call-number": "10.1145/3491102.3517738",
    "collection-number": "495",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517738",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "accessibility, text entry;, single-switch scanning systems, Augmentative and alternative communication",
    "number": "Article 495",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Performance Evaluation of Nomon: A Flexible Interface for Noisy Single-Switch Users",
    "URL": "https://doi.org/10.1145/3491102.3517738"
  },
  {
    "id": "10.1145/3491102.3501904",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Xu",
        "given": "Xuhai"
      },
      {
        "family": "Gong",
        "given": "Jun"
      },
      {
        "family": "Brum",
        "given": "Carolina"
      },
      {
        "family": "Liang",
        "given": "Lilian"
      },
      {
        "family": "Suh",
        "given": "Bongsoo"
      },
      {
        "family": "Gupta",
        "given": "Shivam Kumar"
      },
      {
        "family": "Agarwal",
        "given": "Yash"
      },
      {
        "family": "Lindsey",
        "given": "Laurence"
      },
      {
        "family": "Kang",
        "given": "Runchang"
      },
      {
        "family": "Shahsavari",
        "given": "Behrooz"
      },
      {
        "family": "Nguyen",
        "given": "Tu"
      },
      {
        "family": "Nieto",
        "given": "Heriberto"
      },
      {
        "family": "Hudson",
        "given": "Scott E"
      },
      {
        "family": "Maalouf",
        "given": "Charlie"
      },
      {
        "family": "Mousavi",
        "given": "Jax Seyed"
      },
      {
        "family": "Laput",
        "given": "Gierad"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present a framework for gesture customization requiring minimal examples from users, all without degrading the performance of existing gesture sets. To achieve this, we first deployed a large-scale study (N=500+) to collect data and train an accelerometer-gyroscope recognition model with a cross-user accuracy of 95.7% and a false-positive rate of 0.6 per hour when tested on everyday non-gesture data. Next, we design a few-shot learning framework which derives a lightweight model from our pre-trained model, enabling knowledge transfer without performance degradation. We validate our approach through a user study (N=20) examining on-device customization from 12 new gestures, resulting in an average accuracy of 55.3%, 83.1%, and 87.2% on using one, three, or five shots when adding a new gesture, while maintaining the same recognition accuracy and false-positive rate from the pre-existing gesture set. We further evaluate the usability of our real-time implementation with a user experience study (N=20). Our results highlight the effectiveness, learnability, and usability of our customization framework. Our approach paves the way for a future where users are no longer bound to pre-existing gestures, freeing them to creatively introduce new gestures tailored to their preferences and abilities.",
    "call-number": "10.1145/3491102.3501904",
    "collection-number": "496",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501904",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "transfer learning, Gesture customization, few-shot learning",
    "number": "Article 496",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Enabling Hand Gesture Customization on Wrist-Worn Devices",
    "URL": "https://doi.org/10.1145/3491102.3501904"
  },
  {
    "id": "10.1145/3491102.3501878",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Streli",
        "given": "Paul"
      },
      {
        "family": "Jiang",
        "given": "Jiaxi"
      },
      {
        "family": "Fender",
        "given": "Andreas Rene"
      },
      {
        "family": "Meier",
        "given": "Manuel"
      },
      {
        "family": "Romat",
        "given": "Hugo"
      },
      {
        "family": "Holz",
        "given": "Christian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Despite the advent of touchscreens, typing on physical keyboards remains most efficient for entering text, because users can leverage all fingers across a full-size keyboard for convenient typing. As users increasingly type on the go, text input on mobile and wearable devices has had to compromise on full-size typing. In this paper, we present TapType, a mobile text entry system for full-size typing on passive surfaces\u2014without an actual keyboard. From the inertial sensors inside a band on either wrist, TapType decodes and relates surface taps to a traditional QWERTY keyboard layout. The key novelty of our method is to predict the most likely character sequences by fusing the finger probabilities from our Bayesian neural network classifier with the characters\u2019 prior probabilities from an n-gram language model. In our online evaluation, participants on average typed 19 words per minute with a character error rate of 0.6% after 30 minutes of training. Expert typists thereby consistently achieved more than 25\u00a0WPM at a similar error rate. We demonstrate applications of TapType in mobile use around smartphones and tablets, as a complement to interaction in situated Mixed Reality outside visual control, and as an eyes-free mobile text input method using an audio feedback-only interface.",
    "call-number": "10.1145/3491102.3501878",
    "collection-number": "497",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501878",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Bayesian inference, Bayesian neural network, n-gram language model, virtual reality, invisible interfaces, mobile text entry",
    "number": "Article 497",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TapType: Ten-finger text entry on everyday surfaces via Bayesian inference",
    "URL": "https://doi.org/10.1145/3491102.3501878"
  },
  {
    "id": "10.1145/3491102.3501942",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tsandilas",
        "given": "Theophanis"
      },
      {
        "family": "Dragicevic",
        "given": "Pierre"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Gesture elicitation studies are commonly used for designing novel gesture-based interfaces. There is a rich methodology literature on metrics and analysis methods that helps researchers understand and characterize data arising from such studies. However, deriving concrete gesture vocabularies from this data, which is often the ultimate goal, remains largely based on heuristics and ad hoc methods. In this paper, we treat the problem of deriving a gesture vocabulary from gesture elicitation data as a computational optimization problem. We show how to formalize it as an optimal assignment problem and discuss how to express objective functions and custom design constraints through integer programs. In addition, we introduce a set of tools for assessing the uncertainty of optimization outcomes due to random sampling, and for supporting researchers\u2019 decisions on when to stop collecting data from a gesture elicitation study. We evaluate our methods on a large number of simulated studies.",
    "call-number": "10.1145/3491102.3501942",
    "collection-number": "498",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501942",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Gesture elicitation, optimization uncertainty, assignment problems, bootstrap, design optimization, learning curves",
    "number": "Article 498",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Gesture Elicitation as a Computational Optimization Problem",
    "URL": "https://doi.org/10.1145/3491102.3501942"
  },
  {
    "id": "10.1145/3491102.3517461",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yang",
        "given": "Saelyne"
      },
      {
        "family": "Yim",
        "given": "Jisu"
      },
      {
        "family": "Kim",
        "given": "Juho"
      },
      {
        "family": "Shin",
        "given": "Hijung Valentina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Live streams usually last several hours with many viewers joining in the middle. Viewers who join in the middle often want to understand what has happened in the stream. However, catching up with the earlier parts is challenging because it is difficult to know which parts are important in the long, unedited stream while also keeping up with the ongoing stream. We present CatchLive, a system that provides a real-time summary of ongoing live streams by utilizing both the stream content and user interaction data. CatchLive provides viewers with an overview of the stream along with summaries of highlight moments with multiple levels of detail in a readable format. Results from deployments of three streams with 67 viewers show that CatchLive helps viewers grasp the overview of the stream, identify important moments, and stay engaged. Our findings provide insights into designing summarizations of live streams reflecting their characteristics.",
    "call-number": "10.1145/3491102.3517461",
    "collection-number": "500",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517461",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "video summarization, user interaction data, live summarization, live streaming",
    "number": "Article 500",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CatchLive: Real-time Summarization of Live Streams with Stream Content and Interaction Data",
    "URL": "https://doi.org/10.1145/3491102.3517461"
  },
  {
    "id": "10.1145/3491102.3501948",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Jeongyeon"
      },
      {
        "family": "Choi",
        "given": "Yubin"
      },
      {
        "family": "Kahng",
        "given": "Minsuk"
      },
      {
        "family": "Kim",
        "given": "Juho"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Mobile video-based learning attracts many learners with its mobility and ease of access. However, most lectures are designed for desktops. Our formative study reveals mobile learners\u2019 two major needs: more readable content and customizable video design. To support mobile-optimized learning, we present FitVid, a system that provides responsive and customizable video content. Our system consists of (1) an adaptation pipeline that reverse-engineers pixels to retrieve design elements (e.g., text, images) from videos, leveraging deep learning with a custom dataset, which powers (2) a UI that enables resizing, repositioning, and toggling in-video elements. The content adaptation improves the guideline compliance rate by 24% and 8% for word count and font size. The content evaluation study (n=198) shows that the adaptation significantly increases readability and user satisfaction. The user study (n=31) indicates that FitVid significantly improves learning experience, interactivity, and concentration. We discuss design implications for responsive and customizable video adaptation.",
    "call-number": "10.1145/3491102.3501948",
    "collection-number": "501",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501948",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Video-Based Learning, Responsive Design, Content Adaptation, Mobile Learning",
    "number": "Article 501",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FitVid: Responsive and Flexible Video Content Adaptation",
    "URL": "https://doi.org/10.1145/3491102.3501948"
  },
  {
    "id": "10.1145/3491102.3517741",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jahanlou",
        "given": "Amir"
      },
      {
        "family": "Chilana",
        "given": "Parmit K"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Explainer motion graphics videos that use a combination of graphical elements and movement to convey a visual message are becoming increasingly popular among amateur creators in different domains. But, to author motion graphics videos, amateurs either have to face a steep learning curve with professional design tools or struggle with re-purposing slide-sharing tools that are easier to access but have limited animation capabilities. To simplify the process of motion graphics authoring, we present the design and implementation of Katika, an end-to-end system for creating shots based on a script, adding artworks and animation from a crowdsourced library, and editing the video using semi-automated transitions. Our observational study illustrates that participants (N=11) enjoyed using Katika and, within a one-hour session, managed to create an explainer motion graphics video. We identify opportunities for future HCI research to lower the barriers to entry and democratize the authoring of motion graphics videos.",
    "call-number": "10.1145/3491102.3517741",
    "collection-number": "502",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517741",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Infographics, Motion Design, Motion Graphics, Explainer Videos",
    "number": "Article 502",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Katika: An End-to-End System for Authoring Amateur Explainer Motion Graphics Videos",
    "URL": "https://doi.org/10.1145/3491102.3517741"
  },
  {
    "id": "10.1145/3491102.3517567",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mahieux",
        "given": "Pierre"
      },
      {
        "family": "Biannic",
        "given": "Romain"
      },
      {
        "family": "Kubicki",
        "given": "S\u00e9bastien"
      },
      {
        "family": "Querrec",
        "given": "Ronan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Historians use spatio-temporal navigation for their models and studies of historical evolutions and events. Their findings can then be exhibited in cultural mediation centers or museums. The latter, both to facilitate the transmission of knowledge and to make their exhibitions more attractive, are now exploiting new technologies. Indeed, digital systems allow, among other things, visitors to navigate spatially and temporally in virtual reconstructions of historical environments. We propose to combine these virtual representations with a tangible interface to provide visitors with an immersive experience and engaging interactions. To do so, we have set up a co-design process involving cultural mediation actors (museum directors, historians, etc.). The result is SABLIER, a tangible interactor to navigate through space and time based on the interaction metaphors and natural affordance of an hourglass. Finally, we have conducted an evaluation of the acceptability of our interactor, whose results are positive.",
    "call-number": "10.1145/3491102.3517567",
    "collection-number": "503",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517567",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Cultural Mediation, Virtual Reality, Tangible User Interface",
    "number": "Article 503",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SABLIER : a Tangible Interactor to Navigate through Space and Time",
    "URL": "https://doi.org/10.1145/3491102.3517567"
  },
  {
    "id": "10.1145/3491102.3517674",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Olwal",
        "given": "Alex"
      },
      {
        "family": "Dementyev",
        "given": "Artem"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Consumer electronics are increasingly using everyday materials to blend into home environments, often using LEDs or symbol displays under textile meshes. Our surveys (n=1499 and n=1501) show interest in interactive graphical displays for hidden interfaces \u2014 however, covering such displays significantly limits brightness, material possibilities and legibility. To overcome these limitations, we leverage parallel rendering to enable ultrabright graphics that can pass through everyday materials. We unlock expressive hidden interfaces using rectilinear graphics on low-cost, mass-produced passive-matrix OLED displays. A technical evaluation across materials, shapes and display techniques, suggests 3.6\u201340X brightness increase compared to more complex active-matrix OLEDs. We present interactive prototypes that blend into wood, textile, plastic and mirrored surfaces. Survey feedback (n=1572) on our prototypes suggests that smart mirrors are particularly desirable. A lab evaluation (n=11) reinforced these findings and allowed us to also characterize performance from hands-on interaction with different content, materials and under varying lighting conditions.",
    "call-number": "10.1145/3491102.3517674",
    "collection-number": "504",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517674",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "passive-matrix OLED, parallel rendering, hidden interfaces, calm computing, ubiquitous computing, ambient computing, rectilinear",
    "number": "Article 504",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Hidden Interfaces for Ambient Computing: Enabling Interaction in Everyday Materials through High-brightness Visuals on Low-cost Matrix Displays",
    "URL": "https://doi.org/10.1145/3491102.3517674"
  },
  {
    "id": "10.1145/3491102.3517715",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Satriadi",
        "given": "Kadek Ananta"
      },
      {
        "family": "Smiley",
        "given": "Jim"
      },
      {
        "family": "Ens",
        "given": "Barrett"
      },
      {
        "family": "Cordeil",
        "given": "Maxime"
      },
      {
        "family": "Czauderna",
        "given": "Tobias"
      },
      {
        "family": "Lee",
        "given": "Benjamin"
      },
      {
        "family": "Yang",
        "given": "Ying"
      },
      {
        "family": "Dwyer",
        "given": "Tim"
      },
      {
        "family": "Jenny",
        "given": "Bernhard"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Head-mounted augmented reality (AR) displays allow for the seamless integration of virtual visualisation with contextual tangible references, such as physical (tangible) globes. We explore the design of immersive geospatial data visualisation with AR and tangible globes. We investigate the \u201ctangible-virtual interplay\u201d of tangible globes with virtual data visualisation, and propose a conceptual approach for designing immersive geospatial globes. We demonstrate a set of use cases, such as augmenting a tangible globe with virtual overlays, using a physical globe as a tangible input device for interacting with virtual globes and maps, and linking an augmented globe to an abstract data visualisation. We gathered qualitative feedback from experts about our use case visualisations, and compiled a summary of key takeaways as well as ideas for envisioned future improvements. The proposed design space, example visualisations and lessons learned aim to guide the design of tangible globes for data visualisation in AR.",
    "call-number": "10.1145/3491102.3517715",
    "collection-number": "505",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517715",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "geographic visualisation, augmented reality, immersive analytics, tangible user interface",
    "number": "Article 505",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Tangible Globes for Data Visualisation in Augmented Reality",
    "URL": "https://doi.org/10.1145/3491102.3517715"
  },
  {
    "id": "10.1145/3491102.3501906",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Nakagaki",
        "given": "Ken"
      },
      {
        "family": "Tappa",
        "given": "Jordan L"
      },
      {
        "family": "Zheng",
        "given": "Yi"
      },
      {
        "family": "Forman",
        "given": "Jack"
      },
      {
        "family": "Leong",
        "given": "Joanne"
      },
      {
        "family": "Koenig",
        "given": "Sven"
      },
      {
        "family": "Ishii",
        "given": "Hiroshi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "(Dis)Appearables is an approach for actuated Tangible User Interfaces (TUIs) to appear and disappear. This technique is supported by Stages: physical platforms inspired by theatrical stages. Self-propelled TUI\u2019s autonomously move between front and back stage allowing them to dynamically appear and disappear from users\u2019 attention. This platform opens up a novel interaction design space for expressive displays with dynamic physical affordances. We demonstrate and explore this approach based on a proof-of-concept implementation using two-wheeled robots, and multiple stage design examples. We have implemented a stage design pipeline which allows users to plan and design stages that are composed with front and back stages, and transition portals such as trap doors or lifts. The pipeline includes control of the robots, which guides them on and off stage. With this proof-of-concept prototype, we demonstrated a range of applications including interactive mobility simulation, self re-configuring desktops, remote hockey, and storytelling/gaming. Inspired by theatrical stage designs, this is a new take on \u2018controlling the existence of matter\u2019 for user experience design.",
    "call-number": "10.1145/3491102.3501906",
    "collection-number": "506",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501906",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Dynamic Physical Affordance, Stage, Actuated Tangible User Interfaces, Swarm User Interface",
    "number": "Article 506",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "(Dis)Appearables: A Concept and Method for Actuated Tangible UIs to Appear and Disappear based on Stages",
    "URL": "https://doi.org/10.1145/3491102.3501906"
  },
  {
    "id": "10.1145/3491102.3517449",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zuckerman",
        "given": "Oren"
      },
      {
        "family": "Press",
        "given": "Viva Sarah"
      },
      {
        "family": "Barda",
        "given": "Ehud"
      },
      {
        "family": "Megidish",
        "given": "Benny"
      },
      {
        "family": "Erel",
        "given": "Hadas"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Autonomous actuated-interfaces provide a unique research opportunity for shared-control interfaces, as the human and the interface collaborate using the physical interaction modality, manipulating the same physical elements at the same time. Prior studies show that sharing control with physical modality interfaces often results in frustration and low sense-of-control. We designed and implemented adaptive behavior for shared-control actuated-interfaces that extends prior work by providing humans the ability to anticipate the autonomous action, and then accept or override it. Results from a controlled study with 24 participants indicate better collaboration in the Adaptive condition compared with the Non-adaptive one, with improved sense-of-control, feelings of teamwork, and overall collaboration quality. Our work contributes to shared-control tangible, shape-change, and actuated interfaces. We show that leveraging minimal non-verbal social cues to physically communicate the actuated-interface\u2019s intent, coupled with providing autonomy to the human to physically accept or override the shift-in-control, improves the shared-control collaboration.",
    "call-number": "10.1145/3491102.3517449",
    "collection-number": "507",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517449",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human-centered., Tangible collaboration, Shape change, Shared-control, Actuated interface, Qualitative Methods",
    "number": "Article 507",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Tangible Collaboration: A Human-Centered Approach for Sharing Control With an Actuated-Interface",
    "URL": "https://doi.org/10.1145/3491102.3517449"
  },
  {
    "id": "10.1145/3491102.3501840",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ankenbauer",
        "given": "Sam Addison"
      },
      {
        "family": "Lu",
        "given": "Alex Jiahong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Independent movie theaters (IMTs) are a part of the cultural infrastructure that offers shared spaces for patron communities to access, share, and engage with cultural artifacts. In light of the COVID-19 pandemic, IMTs were mandated to shut down, resulting in unanticipated infrastructural breakdown. Drawing insights from a preliminary survey and interviews with staff members from 18 IMTs in the U.S., this paper attends to how this breakdown disrupted art and community engagement within patron communities. We investigate the sociotechnical practices of maintaining cultural infrastructure through 1) collaborating with community partners and external stakeholders, 2) screening films through online virtual cinema platforms, and 3) retaining community members through online platforms. Our work highlights the tensions and invisible human labor in this maintenance work. Together, this work intends to foreground cultural infrastructure and discuss how HCI can support and contribute to the design and oft-invisible maintenance of cultural infrastructure.",
    "call-number": "10.1145/3491102.3501840",
    "collection-number": "508",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501840",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "cultural spaces, COVID-19, materiality, Infrastructure, symbolic meaning, infrastructuring work, cultural infrastructure",
    "number": "Article 508",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Making Space for Cultural Infrastructure: The Breakdown and Maintenance Work of Independent Movie Theaters During Crisis",
    "URL": "https://doi.org/10.1145/3491102.3501840"
  },
  {
    "id": "10.1145/3491102.3517509",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ding",
        "given": "Xianghua(Sharon)"
      },
      {
        "family": "Kou",
        "given": "Yubo"
      },
      {
        "family": "Xu",
        "given": "Yiwen"
      },
      {
        "family": "Zhang",
        "given": "Peng"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The prevalence of social media blurs the boundaries between consumer and producer, work and play, and leads to new social roles, professions, and identities (e.g. blogger, YouTuber, micro-celebrity). However, we still lack a clear understanding of how people come to identify with these new roles and how individual professional development is digitally mediated. This paper presents a study based on Bilibili, a popular Chinese social media platform featuring user-generated videos, and highlights a professionalization process through which individuals consciously distinguish between the roles of uploaders and consumers, develop a shared work ethos around the role of the uploader, and, as uploaders, improve their technical-professional expertise. We conclude by discussing individualized professionalization as a concept that describes the bottom-up and community-based process of professional development for User Generated Content (UGC) taking place in contemporary digital media environments.",
    "call-number": "10.1145/3491102.3517509",
    "collection-number": "509",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517509",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Professionalization, Profession, Online Creative Media, User Generated Content (UGC)",
    "number": "Article 509",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cAs Uploaders, We Have the Responsibility\u201d: Individualized Professionalization of Bilibili Uploaders",
    "URL": "https://doi.org/10.1145/3491102.3517509"
  },
  {
    "id": "10.1145/3491102.3517546",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hsieh",
        "given": "Jane"
      },
      {
        "family": "Hong",
        "given": "Yili"
      },
      {
        "family": "Burtch",
        "given": "Gordon"
      },
      {
        "family": "Zhu",
        "given": "Haiyi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As more individuals consider permanently working from home, the online labor market continues to grow as an alternative working environment. While the flexibility and autonomy of these online gigs attracts many workers, success depends critically upon self-management and workers\u2019 efficient allocation of scarce resources. To achieve this, freelancers may develop alternative work strategies, employing highly standardized schedules and communication patterns while taking on large work volumes, or engaging in smaller numbers of jobs whilst tailoring their activities to build relationships with individual employers. In this study, we consider this contrast in relation to worker communication patterns. We demonstrate the heterogeneous effects of standardization versus personalization across different stages of a project and examine the relative impact on job acquisition, project completion, and earnings. Our findings can inform the design of platforms and various worker support tools for the gig economy.",
    "call-number": "10.1145/3491102.3517546",
    "collection-number": "510",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517546",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "online labor markets, Online freelancing, personalization, digitally-mediated communication, standardization",
    "number": "Article 510",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A Little Too Personal: Effects of Standardization versus Personalization on Job Acquisition, Work Completion, and Revenue for Online Freelancers",
    "URL": "https://doi.org/10.1145/3491102.3517546"
  },
  {
    "id": "10.1145/3491102.3517558",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hu",
        "given": "Erzhen"
      },
      {
        "family": "Azim",
        "given": "Md Aashikur Rahman"
      },
      {
        "family": "Heo",
        "given": "Seongkook"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People often form small conversation groups during physical gatherings to have ad-hoc and informal conversations. As these groups are loosely defined, others can often overhear and join the conversation. However, current video-conferencing tools only allow for strict boundaries between small conversation groups, inhibiting fluid group formations and between-group conversations. This isolates small-group conversations from others and leads to inefficient transitions between conversations. We present FluidMeet, a virtual breakout meeting system that employs flexible conversation boundaries and cross-group conversation visualizations to enable fluid conversation group formations and ad-hoc, informal conversations. FluidMeet enables out-group members to overhear group conversations while allowing conversation groups to control their shared level of context. Users within conversation groups can also quickly switch between in-group and private conversations. A study of FluidMeet showed that it encouraged users to break group boundaries, made them feel less isolated in group conversations, and facilitated communication across different groups.",
    "call-number": "10.1145/3491102.3517558",
    "collection-number": "511",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517558",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Remote Meetings, Breakout Rooms, Private Conversations, Proxemics",
    "number": "Article 511",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FluidMeet: Enabling Frictionless Transitions Between In-Group, Between-Group, and Private Conversations During Virtual Breakout Meetings",
    "URL": "https://doi.org/10.1145/3491102.3517558"
  },
  {
    "id": "10.1145/3491102.3517463",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Marchetti",
        "given": "Emanuela"
      },
      {
        "family": "Grimme",
        "given": "Sophie"
      },
      {
        "family": "Hornecker",
        "given": "Eva"
      },
      {
        "family": "Kollakidou",
        "given": "Avgi"
      },
      {
        "family": "Graf",
        "given": "Philipp"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Any active entity that shares space with people is interpreted as a social actor. Based on this notion, we explore how robots that integrate functional utility with a social role and character can integrate meaningfully into daily practice. Informed by interviews and observations, we designed a zoomorphic floor cleaning robot which playfully interacts with care home residents affected by dementia. A field study shows that playful interaction can facilitate the introduction of utilitarian robots in care homes, being nonthreatening and easy to make sense of. Residents previously reacted with distress to a Roomba robot, but were now amused by and played with our cartoonish cat robot or simply tolerated its presence. They showed awareness of the machine-nature of the robot, even while engaging in pretend-play. A playful approach to the design of functional robots can thus explicitly conceptualize such robots as social actors in their context of use.",
    "call-number": "10.1145/3491102.3517463",
    "collection-number": "512",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517463",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "field study, character design, social robot, playful design, toy, pretend-play, assistive robot, care home, dementia",
    "number": "Article 512",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Pet-Robot or Appliance? Care Home Residents with Dementia Respond to a Zoomorphic Floor Washing Robot",
    "URL": "https://doi.org/10.1145/3491102.3517463"
  },
  {
    "id": "10.1145/3491102.3517554",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dixon",
        "given": "Emma"
      },
      {
        "family": "Anderson",
        "given": "Jesse"
      },
      {
        "family": "Blackwelder",
        "given": "Diana"
      },
      {
        "family": "L. Radnofsky",
        "given": "Mary"
      },
      {
        "family": "Lazar",
        "given": "Amanda"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "There is growing interest in HCI to study ways to support access to accurate, accessible, relevant online health information for different populations. Yet, there remains a need to understand the barriers that are posed by the way our platforms are designed as well as how we might overcome these barriers for people with dementia. To address this, we conducted sixteen interviews and observation sessions with people with mild to moderate dementia. Our analysis uncovered four barriers to online health information and corresponding mitigation strategies that participants employed. We discuss how HCI researchers may apply these findings towards new technical approaches and standards concerning information accessibility and credibility for neurodiverse populations. Finally, we broaden the scope of HCI research to include investigations of the accessibility and credibility of online information for people with age-related cognitive impairment independent of proxies.",
    "call-number": "10.1145/3491102.3517554",
    "collection-number": "513",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517554",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Dementia, Misleading Information, Online Health Information, Scams, Cognitive Accessibility",
    "number": "Article 513",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Barriers to Online Dementia Information and Mitigation",
    "URL": "https://doi.org/10.1145/3491102.3517554"
  },
  {
    "id": "10.1145/3491102.3501993",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Houben",
        "given": "Maarten"
      },
      {
        "family": "Brankaert",
        "given": "Rens"
      },
      {
        "family": "Kenning",
        "given": "Gail"
      },
      {
        "family": "Bongers",
        "given": "Inge"
      },
      {
        "family": "Eggen",
        "given": "Berry"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People with dementia and their caregivers aging in place have expressed the need for social, emotional, and recreational interventions at home. Listening to everyday sounds evokes memories and provides conversational cues to support social relations and elicit emotional responses for people with dementia. However, research has yet to explore how these meaningful experiences can be transferred into home settings. This paper presents the insights from our co-design study that involved three people with dementia and their partners in developing an interactive sound player for listening to everyday sounds at home. We report on the motivations of people with dementia and their caregivers to engage in meaningful sound-based activities at home and present the Tumbler as a prototype to foster initiative and agency in exploring familiar everyday sounds. We present design implications of how sound can enrich the everyday experiences of dementia by facilitating social and pleasurable moments at home.",
    "call-number": "10.1145/3491102.3501993",
    "collection-number": "514",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501993",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Design, Home, Everyday Sounds, Informal Caregiver, Dementia",
    "number": "Article 514",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing for Everyday Sounds at Home with People with Dementia and their Partners",
    "URL": "https://doi.org/10.1145/3491102.3501993"
  },
  {
    "id": "10.1145/3491102.3517430",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Thoolen",
        "given": "Myrte"
      },
      {
        "family": "Toso",
        "given": "Francesca"
      },
      {
        "family": "T.M. Peek",
        "given": "Sebastiaan"
      },
      {
        "family": "Lu",
        "given": "Yuan"
      },
      {
        "family": "Brankaert",
        "given": "Rens"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Dementia can hinder a person's ability to engage with their relatives. Existing communication technologies do not support people with dementia in maintaining social contact since they are not designed for their abilities and needs. This paper presents LivingMoments, a communication system that enables the engagement of people with dementia with their relatives. The system uses digital and physical interaction design considering people's different and changing abilities. Over a six-week field evaluation of LivingMoments, involving six participants living at home with different levels of dementia, we collected qualitative and quantitative data about the experiences of them and their relatives. Based on the data analysis, we found the need to adapt communication to individual abilities, lowering barriers through content calibration and establishing habits for continuous use. We evinced a set of design considerations for technologies to support a lasting engagement of people with dementia with different and changing abilities.",
    "call-number": "10.1145/3491102.3517430",
    "collection-number": "515",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517430",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 515",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "LivingMoments: Bespoke Social Communication for People living with Dementia and their Relatives",
    "URL": "https://doi.org/10.1145/3491102.3517430"
  },
  {
    "id": "10.1145/3491102.3501983",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Matviienko",
        "given": "Andrii"
      },
      {
        "family": "M\u00fcller",
        "given": "Florian"
      },
      {
        "family": "Schmitz",
        "given": "Martin"
      },
      {
        "family": "Fendrich",
        "given": "Marco"
      },
      {
        "family": "M\u00fchlh\u00e4user",
        "given": "Max"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Teleportation has become the de facto standard of locomotion in Virtual Reality (VR) environments. However, teleportation with parabolic and linear target aiming methods is restricted to horizontal 2D planes and it is unknown how they transfer to the 3D space. In this paper, we propose six 3D teleportation methods in virtual environments based on the combination of two existing aiming methods (linear and parabolic) and three types of transitioning to a target (instant, interpolated and continuous). To investigate the performance of the proposed teleportation methods, we conducted a controlled lab experiment (N = 24) with a mid-air coin collection task to assess accuracy, efficiency and VR sickness. We discovered that the linear aiming method leads to faster and more accurate target selection. Moreover, a combination of linear aiming and instant transitioning leads to the highest efficiency and accuracy without increasing VR sickness.",
    "call-number": "10.1145/3491102.3501983",
    "collection-number": "516",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501983",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "virtual reality, teleportation, locomotion, virtual environments",
    "number": "Article 516",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SkyPort: Investigating 3D Teleportation Methods in Virtual Environments",
    "URL": "https://doi.org/10.1145/3491102.3501983"
  },
  {
    "id": "10.1145/3491102.3501975",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tan",
        "given": "Chek Tien"
      },
      {
        "family": "Foo",
        "given": "Leon Cewei"
      },
      {
        "family": "Yeo",
        "given": "Adriel"
      },
      {
        "family": "Lee",
        "given": "Jeannie Su Ann"
      },
      {
        "family": "Wan",
        "given": "Edmund"
      },
      {
        "family": "Kok",
        "given": "Xiao-Feng Kenan"
      },
      {
        "family": "Rajendran",
        "given": "Megani"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Navigating large-scale virtual spaces is a major challenge in Virtual Reality (VR) applications due to real-world spatial limitations. Walking-in-place (WIP) locomotion solutions may provide a natural approach for VR use cases that require locomotion to share similar qualities with walking in real-life. However, there is limited knowledge on the range of experiences across common WIP methods to inform the design of usable WIP solutions using consumer-accessible components. This paper contributes to this knowledge via a user study with 40 participants that experienced several easy-to-setup WIP methods in a VR commuting simulation. A nuanced understanding of cybersickness and exertion relationships and walking affordances based on different tracker setups were among the findings derived from a corroborated analysis of think-aloud, interview, and observational data, supplemented with self-reports of VR sickness, presence and flow. Practical design insights were then constructed along the dimensions of cybersickness, affordances, space and user interfaces.",
    "call-number": "10.1145/3491102.3501975",
    "collection-number": "517",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501975",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Reality, Locomotion, Walking-In-Place, Immersion",
    "number": "Article 517",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding User Experiences Across VR Walking-in-place Locomotion Methods",
    "URL": "https://doi.org/10.1145/3491102.3501975"
  },
  {
    "id": "10.1145/3491102.3501890",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tseng",
        "given": "Chun-Miao"
      },
      {
        "family": "Chen",
        "given": "Po-Yu"
      },
      {
        "family": "Lin",
        "given": "Shih Chin"
      },
      {
        "family": "Wang",
        "given": "Yu-Wei"
      },
      {
        "family": "Lin",
        "given": "Yu-Hsin"
      },
      {
        "family": "Kuo",
        "given": "Mu-An"
      },
      {
        "family": "Yu",
        "given": "Neng-Hao"
      },
      {
        "family": "Chen",
        "given": "Mike Y."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Teleportation, which instantly moves users from their current location to the target location, has become the most popular locomotion technique in VR games. It enables fast navigation with reduced VR sickness but results in significantly reduced immersion. We present HeadWind, a novel approach to improve the experience of teleportation by simulating the haptic sensation of air drag when rapidly moving through the air in real life. Specifically, HeadWind modulates bursts of compressed air to the face and uses multiple nozzles to provide directional cues. To design the wearable device and to model airflow speed and duration for teleportation, we conducted three formative studies and a design session. User experience evaluation with 24 participants showed that HeadWind significantly improved realism, immersion, and enjoyment of teleportation in VR (p<.01) with large effect sizes (r>0.5), and was preferred by 96% of participants.",
    "call-number": "10.1145/3491102.3501890",
    "collection-number": "518",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501890",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Motion perception, Air drag, VR Haptics, Teleportation",
    "number": "Article 518",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "HeadWind: Enhancing Teleportation Experience in VR by Simulating Air Drag during Rapid Motion",
    "URL": "https://doi.org/10.1145/3491102.3501890"
  },
  {
    "id": "10.1145/3491102.3517540",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kang",
        "given": "Jimoon"
      },
      {
        "family": "Yoon",
        "given": "June Seop"
      },
      {
        "family": "Lee",
        "given": "Byungjoo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In this study, we analyzed how the performance of professional Go players has changed since the advent of AlphaGo, the first artificial intelligence (AI) application to defeat a human world Go champion. We interviewed and surveyed professional Go players and found that AI has been actively introduced into the Go training process since the advent of AlphaGo. The significant impact of AI-based training was confirmed in a subsequent analysis of 6,292 games in Korean Go tournaments and Elo rating data of 1,362 Go players worldwide. Overall, the tendency of players to make moves similar to those recommended by AI has sharply increased since 2017. The degree to which players\u2019 expected win rates fluctuate during a game has also decreased significantly since 2017. We also found that AI-based training has provided more benefits to senior players and allowed them to achieve Elo ratings higher than those of junior players.",
    "call-number": "10.1145/3491102.3517540",
    "collection-number": "520",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517540",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "AlphaGo, game of Go, Artificial Intelligence, neural network, deep learning",
    "number": "Article 520",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How AI-Based Training Affected the Performance of Professional Go Players",
    "URL": "https://doi.org/10.1145/3491102.3517540"
  },
  {
    "id": "10.1145/3491102.3502494",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dillahunt",
        "given": "Tawanna R"
      },
      {
        "family": "Maestre",
        "given": "Juan F."
      },
      {
        "family": "Kameswaran",
        "given": "Vaishnav"
      },
      {
        "family": "Poon",
        "given": "Erica"
      },
      {
        "family": "Osorio Torres",
        "given": "John"
      },
      {
        "family": "Gallardo",
        "given": "Mia"
      },
      {
        "family": "Rasmussen",
        "given": "Samantha E."
      },
      {
        "family": "Shih",
        "given": "Patrick C."
      },
      {
        "family": "Bagley",
        "given": "Alice"
      },
      {
        "family": "Young",
        "given": "Samuel L. A."
      },
      {
        "family": "Veinot",
        "given": "Tiffany C."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Millions of Americans forego medical care due to a lack of non-emergency transportation, particularly minorities, older adults, and those who have disabilities or chronic conditions. Our study investigates the potential for using timebanks\u2014community-based voluntary services that encourage exchanges of services for \u201ctime dollars\u201d rather than money\u2014in interventions to address healthcare transportation barriers to seed design implications for a future affordable ridesharing platform. In partnership with a timebank and a federally qualified healthcare center (FQHC), 30 participants completed activity packets and 29 of them attended online workshop sessions. Our findings suggest that promoting trust between drivers and riders requires systems that prioritize safety and reliability; yet, there were discrepancies in the ability of the timebank and FQHC to moderate trust. We also found that timebank supports reciprocity, but healthcare transportation requires additional support to ensure balanced reciprocity. We explain these findings drawing from network closure and trust literature. Finally, we contribute design implications for systems that promote trust and facilitate relational over transactional interactions, which help to promote reciprocity and reflect participants\u2019 values.",
    "call-number": "10.1145/3491102.3502494",
    "collection-number": "521",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502494",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "transportation, timebanks, mobility, healthcare access, design",
    "number": "Article 521",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Trust, Reciprocity, and the Role of Timebanks as Intermediaries: Design Implications for Addressing Healthcare Transportation Barriers",
    "URL": "https://doi.org/10.1145/3491102.3502494"
  },
  {
    "id": "10.1145/3491102.3502055",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cha",
        "given": "Yoon Jeong"
      },
      {
        "family": "Saxena",
        "given": "Arpita"
      },
      {
        "family": "Wou",
        "given": "Alice"
      },
      {
        "family": "Lee",
        "given": "Joyce"
      },
      {
        "family": "Newman",
        "given": "Mark W"
      },
      {
        "family": "Park",
        "given": "Sun Young"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Although child participation is required for successful Type 1 Diabetes (T1D) management, it is challenging because the child\u2019s young age and immaturity make it difficult to perform self-care. Thus, parental caregivers are expected to be heavily involved in their child\u2019s everyday illness management. Our study aims to investigate how children and parents collaborate to manage T1D and examine how the children become more independent in their self-management through the support of their parents. Through semi-structured interviews with children with T1D and their parents (N=41), our study showed that children\u2019s knowledge of illness management and motivation for self-care were crucial for their transition towards independence. Based on these two factors, we identified four types of children\u2019s collaboration (i.e., dependent, resistant, eager, and independent) and parents\u2019 strategies for supporting their children\u2019s independence. We suggest design implications for technologies to support collaborative care by improving children\u2019s transition to independent illness management.",
    "call-number": "10.1145/3491102.3502055",
    "collection-number": "522",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502055",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "child self-care, type 1 diabetes, child independence, chronic illness management, pediatric patient, child-parent collaboration, collaborative healthcare technology",
    "number": "Article 522",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Transitioning Toward Independence: Enhancing Collaborative Self-Management of Children with Type 1 Diabetes",
    "URL": "https://doi.org/10.1145/3491102.3502055"
  },
  {
    "id": "10.1145/3491102.3517544",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "A. Ankrah",
        "given": "Elizabeth"
      },
      {
        "family": "Bhattacharya",
        "given": "Arpita"
      },
      {
        "family": "Donjuan",
        "given": "Lissamarie"
      },
      {
        "family": "L. Cibrian",
        "given": "Franceli"
      },
      {
        "family": "Torno",
        "given": "Lilibeth"
      },
      {
        "family": "Ritt Olson",
        "given": "Anamara"
      },
      {
        "family": "Milam",
        "given": "Joel"
      },
      {
        "family": "Hayes",
        "given": "Gillian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Adolescent and young adult childhood cancer survivors experience health complications, late or long-term biomedical complications, as well as economic and psychosocial challenges that can have a lifelong impact on their quality-of-life. As childhood cancer survivors transition into adulthood, they must learn to balance their identity development with demands of everyday life and the near- and long-term consequences of their cancer experience, all of which have implications for the ways they use existing technologies and the design of novel technologies. In this study, we interviewed 24 childhood cancer survivors and six caregivers about their cancer survivorship experiences. The results of our analysis indicate that the challenges of transitioning to adulthood as a cancer survivor necessitate the development and management of multiple societal, relational, and personal boundaries, processes that social computing technologies can help or hinder. This paper contributes to the empirical understanding of adolescent and young adult cancer survivors\u2019 social experiences. We further contribute sociotechnical design provocations for researchers, designers, and community members to support survivors.",
    "call-number": "10.1145/3491102.3517544",
    "collection-number": "523",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517544",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Childhood Cancer Survivors, Disclosure, Transitions, Survivorship, Boundaries",
    "number": "Article 523",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "When Worlds Collide: Boundary Management of Adolescent and Young Adult Childhood Cancer Survivors and Caregivers",
    "URL": "https://doi.org/10.1145/3491102.3517544"
  },
  {
    "id": "10.1145/3491102.3501970",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Claisse",
        "given": "Caroline"
      },
      {
        "family": "Kasadha",
        "given": "Bakita"
      },
      {
        "family": "Stumpf",
        "given": "Simone"
      },
      {
        "family": "Durrant",
        "given": "Abigail C."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We report on a Diary Study investigating daily practices of Self-care by seven UK adults living with Human Immunodeficiency Virus (HIV), to understand their routines, experiences, needs and concerns, informing Self-care technology design to support living well. We advance a developing HCI literature evidencing how digital tools for self-managing health do not meet the complex needs of those living with long-term conditions, especially those from marginalised communities. Our evaluation of using a Self-care Diary as Design Probe responds to calls to study Self-care practices so that future digital health tools are better grounded in lived experiences of managing multi-morbidity. We contribute to HCI discourses including Personal Health Informatics, Lived Informatics and Reflection by illuminating psychosocial challenges for practicing and self-reporting on Self-care. We offer design implications from a Critical Digital Health perspective, addressing barriers to technology use related to trust, privacy, and representation, gaining new significance during the COVID-19 pandemic.",
    "call-number": "10.1145/3491102.3501970",
    "collection-number": "524",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501970",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Long-term condition, Personal Health Informatics, Self-care, Diary Study",
    "number": "Article 524",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating Daily Practices of Self-care to Inform the Design of Supportive Health Technologies for Living and Ageing Well with HIV",
    "URL": "https://doi.org/10.1145/3491102.3501970"
  },
  {
    "id": "10.1145/3491102.3502132",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mequanint Bezabih",
        "given": "Alemitu"
      },
      {
        "family": "Gerling",
        "given": "Kathrin"
      },
      {
        "family": "Abebe",
        "given": "Workeabeba"
      },
      {
        "family": "Vanden Abeele",
        "given": "Vero"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Adolescents in sub-Saharan Africa are at the epicenter of the global HIV epidemic. Yet, technology to support HIV management overwhelmingly focuses on adult medication adherence, neglecting the complex lives of adolescents in low-income regions. We present findings from interviews and focus groups that included twelve HIV-positive adolescents in Ethiopia, and eleven adults from their care circles. We leverage the Integrated Behavioral Model to examine the lived experience of HIV and the space for technology. Additionally, we present an inductive thematic analysis, which highlights non-disclosure as a central theme, i.e., adolescents remaining unaware of their HIV status. Drawing from these findings, we discuss how to account for (the lack of) disclosure in the design of technology to support HIV management, and reflect on whether technology could (and should) support the process. We further highlight the risks that researchers and designers need to be aware of when designing HIV management technology for this audience.",
    "call-number": "10.1145/3491102.3502132",
    "collection-number": "525",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502132",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 525",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Challenge of (Non-)Disclosure: Exploring the Lived Experience of Ethiopian Adolescents with HIV and Their Attitudes Toward Technology",
    "URL": "https://doi.org/10.1145/3491102.3502132"
  },
  {
    "id": "10.1145/3491102.3517496",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chou",
        "given": "Yu-Ling"
      },
      {
        "family": "Lin",
        "given": "Yi-Hsiu"
      },
      {
        "family": "Lin",
        "given": "Tzu-Yi"
      },
      {
        "family": "You",
        "given": "Hsin Ying"
      },
      {
        "family": "Chang",
        "given": "Yung-Ju"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We investigate instant-messaging (IM) users\u2019 sense-making and practices around read-receipts: a feature of IM apps for supporting the awareness of turn-taking, i.e., whether a message recipient has read a message. Using a grounded-theory approach, we highlight the importance of five contextual factors \u2013 situational, relational, interactional, conversational, and personal \u2013 that shape the variety of IM users\u2019 sense-making about read-receipts and strategies for utilizing them in different settings. This approach yields a 21-part typology comprising five types of senders\u2019 speculation about why their messages with read-receipts have not been answered; eight types of recipients\u2019 causes/reasons behind such non-response; and four types of senders\u2019 and recipients\u2019 subsequent strategies, respectively. Mismatches between senders\u2019 speculations about un-responded-to read-receipted messages (URRMs) and recipients\u2019 self-reported explanations are also discussed as sources of communicative friction. The findings reveal that, beyond indicating turn-taking, read-receipts have been leveraged as a strategic tool for various purposes in interpersonal relations.",
    "call-number": "10.1145/3491102.3517496",
    "collection-number": "526",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517496",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "turn-taking, responsiveness, seen function, sense-making, explanation, texting, Read receipt, instant messaging",
    "number": "Article 526",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Why Did You/I Read but Not Reply? IM Users\u2019 Unresponded-to Read-receipt Practices and Explanations of Them",
    "URL": "https://doi.org/10.1145/3491102.3517496"
  },
  {
    "id": "10.1145/3491102.3501920",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Aoki",
        "given": "Toshiki"
      },
      {
        "family": "Chujo",
        "given": "Rintaro"
      },
      {
        "family": "Matsui",
        "given": "Katsufumi"
      },
      {
        "family": "Choi",
        "given": "Saemi"
      },
      {
        "family": "Hautasaari",
        "given": "Ari"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Text chat applications are an integral part of daily social and professional communication. However, messages sent over text chat applications do not convey vocal or nonverbal information from the sender, and detecting the emotional tone in text-only messages is challenging. In this paper, we explore the effects of speech balloon shapes on the sender-receiver agreement regarding the emotionality of a text message. We first investigated the relationship between the shape of a speech balloon and the emotionality of speech text in Japanese manga. Based on these results, we created a system that automatically generates speech balloons matching linear emotional arousal intensity by Auxiliary Classifier Generative Adversarial Networks (ACGAN). Our evaluation results from a controlled experiment suggested that the use of emotional speech balloons outperforms the use of emoticons in decreasing the differences between message senders\u2019 and receivers\u2019 perceptions about the level of emotional arousal in text messages.",
    "call-number": "10.1145/3491102.3501920",
    "collection-number": "527",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501920",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "text chat, speech balloon, voice input, emotion",
    "number": "Article 527",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "EmoBalloon - Conveying Emotional Arousal in Text Chats with Speech Balloons",
    "URL": "https://doi.org/10.1145/3491102.3501920"
  },
  {
    "id": "10.1145/3491102.3517514",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Shandilya",
        "given": "Esha"
      },
      {
        "family": "Fan",
        "given": "Mingming"
      },
      {
        "family": "Tigwell",
        "given": "Garreth W."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Virtual workspaces rapidly increased during the COVID-19 pandemic, and for many new collaborators, working remotely was their first introduction to their colleagues. Building rapport is essential for a healthy work environment, and while this can be achieved through non-textual responses within chat-based systems (e.g., emoji, GIF, stickers, memes), those non-textual responses are typically associated with personal relationships and informal settings. We studied the experiences of new collaborators (questionnaire N=49; interview N=14) in using non-textual responses to communicate with unacquainted teams and the effect of non-textual responses on new collaborators\u2019 interpersonal bonds. We found new collaborators selectively and progressively use non-textual responses to establish interpersonal bonds. Moreover, the use of non-textual responses has exposed several limitations when used on various platforms. We conclude with design recommendations such as expanding the scope of interpretable non-textual responses and reducing selection time.",
    "call-number": "10.1145/3491102.3517514",
    "collection-number": "528",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517514",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Non-textual Communication, Virtual workspaces, Computer-mediated Communication",
    "number": "Article 528",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI need to be professional until my new team uses emoji, GIFs, or memes first\u2019\u2019: New Collaborators\u2019 Perspectives on Using Non-Textual Communication in Virtual Workspaces",
    "URL": "https://doi.org/10.1145/3491102.3517514"
  },
  {
    "id": "10.1145/3491102.3517616",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chou",
        "given": "Yu-Ling"
      },
      {
        "family": "Chien",
        "given": "Yu-Ling"
      },
      {
        "family": "Lin",
        "given": "Yu-Hsin"
      },
      {
        "family": "Lin",
        "given": "Kung-Pai"
      },
      {
        "family": "Shih",
        "given": "Faye"
      },
      {
        "family": "Chang",
        "given": "Yung-Ju"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Attention-management tools can restrict online communication, but may cause collateral damage to their users\u2019 fulfillment of communication expectations. This paper explores the idea of integrating attention management into instant messaging (IM), by 1) disclosing restriction status via an online status indicator (OSI) to manage contacts\u2019 expectations, and 2) imposing communication limits to reduce communication distraction. We used a speed-dating design method to allow 43 participants to rapidly compare 48 types of OSI restriction in various conversational contexts. We identified two \u201ctug-of-wars\u201d that take place when attention management is integrated into IM apps: one between fulfilling one\u2019s contacts\u2019 expectations and protecting one\u2019s own attention, and the other, between protecting one\u2019s privacy and asserting the justifiability of using communication restrictions. We also highlighted the participants\u2019 desire to be diplomatic for sustaining their positive images and maintaining relational connectedness. Finally, we provide design recommendations for integrating attention management into IM apps.",
    "call-number": "10.1145/3491102.3517616",
    "collection-number": "529",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517616",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "restriction, response expectation, Attention management, instant messaging, online status indicator, design research, availability",
    "number": "Article 529",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Because I\u2019m Restricted, 2 \u2013 4 PM Unable to See Messages: Exploring Users\u2019 Perceptions and Likely Practices around Exposing Attention Management Use on IM Online Status",
    "URL": "https://doi.org/10.1145/3491102.3517616"
  },
  {
    "id": "10.1145/3491102.3502128",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Jung-Joo"
      },
      {
        "family": "Yap",
        "given": "Christine Ee Ling"
      },
      {
        "family": "Roto",
        "given": "Virpi"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Service design has gained tractions in Human-Computer Interaction (HCI) as an approach to deal with changes of technology design scopes. In the meantime, there are confusions around definitions of service design and its relevance to HCI. Despite the co-existence of interests and confusions, little research has been done for a comprehensive overview of how HCI interprets and adopts service design. This research performed a systematic literature review on extant HCI publications that claim to use service design. The review findings from the 179 publications revealed varying dimensions of service design taken up in HCI, relations between service design scopes and emerging technologies, as well as unclarity to service design in HCI and HCI's current tendency to use service design for the interaction level rather than the system level. We discuss future design and research opportunities for HCI by integrating the system level dimensions of service design.",
    "call-number": "10.1145/3491102.3502128",
    "collection-number": "530",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502128",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Design methods, Value co-creation, Value constellation, Service design",
    "number": "Article 530",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How HCI Adopts Service Design: Unpacking current perceptions and scopes of service design in HCI and identifying future opportunities",
    "URL": "https://doi.org/10.1145/3491102.3502128"
  },
  {
    "id": "10.1145/3491102.3517607",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zdanowska",
        "given": "Sabah"
      },
      {
        "family": "Taylor",
        "given": "Alex S"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Opportunities for AI and machine learning (ML) are vast in current interactive systems development. However, comparatively little is known about how functionality for the system behind the interface is designed and how design methodologies such as user-centered design have influence. This research focuses on how interdisciplinary teams that include UX practitioners design real-world enterprise ML systems outside of big technology companies. We conducted a survey with product managers, and interviews with interdisciplinary teams and individual UX practitioners. The findings show that nontechnical UX practitioners are highly capable in designing AI/ML systems. In addition to applying UX and interaction design expertise to make decisions regarding functionality, they employ skills that aid collaboration across interdisciplinary teams. However, our findings suggest existing HCI design techniques such as prototyping and simulating complexity of enterprise ML systems are insufficient. We propose adaptations to design practices and conclude that some existing research should be reconsidered.",
    "call-number": "10.1145/3491102.3517607",
    "collection-number": "531",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517607",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "AI, Design, Machine Learning, Human-Centred Design",
    "number": "Article 531",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A study of UX practitioners roles in designing real-world, enterprise ML systems",
    "URL": "https://doi.org/10.1145/3491102.3517607"
  },
  {
    "id": "10.1145/3491102.3517506",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kang",
        "given": "Laewoo"
      },
      {
        "family": "Jackson",
        "given": "Steven"
      },
      {
        "family": "Pinch",
        "given": "Trevor"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper offers a theoretical and methodological framework of \u2018techno-aesthetic encounters\u2019 that supports nonlinear (situated, materially-driven, and multi-sensory) and art-based modes of inquiry in HCI and the broader STEM fields. We first investigate recent literatures in HCI and science and technology studies (STS) that explore nonlinear modes of practice and creativity in processes of technology design, and argue that better recognition of these dynamics may open space for art-based and nonlinear leaners and makers to more actively engage in HCI research and design. To meet this need, we study three renowned art-and-engineering practitioners (Kl\u00fcver, Paik, Moog) and our own experimental project titled \u2018The Electronicists\u2019 in which participants from different disciplines collaborated to produce three hybrid works. Based on this work, we propose a framework of \u2018techno-aesthetic encounters\u2019 that pursues event-based creativity through the mediation of engineering, art, and humanistic engagements. We suggest trust-based experiments, error-engaged studio, and art-based ethnography as promising methodological tenets of this approach.",
    "call-number": "10.1145/3491102.3517506",
    "collection-number": "532",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517506",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Art, Music, Nonlinear Engineering, Ethnography, Techno-aesthetic",
    "number": "Article 532",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Electronicists: Techno-aesthetic Encounters for Nonlinear and Art-based Inquiry in HCI",
    "URL": "https://doi.org/10.1145/3491102.3517506"
  },
  {
    "id": "10.1145/3491102.3517538",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Schlosser",
        "given": "Paul"
      },
      {
        "family": "Matthews",
        "given": "Ben"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Designing technology for emergency medical services (EMS) can be difficult, for example, due to limited access to domain experts. To support designers who aim to engage in a participatory design process in EMS environments, we created and evaluated the Contextual Secondary Video Toolkit (CSVT). This method uses secondary video material and design cards that allow domain experts to identify and prioritise challenges in their work environment and generate design ideas that address them. We illustrate the effects of the CSVT on design processes by analysing four workshops during which aeromedical EMS staff explored the potential of augmented reality to support their work. Our results indicate that the CSVT can support reflection about work practices, aid the generation of design ideas, and facilitate genuine participation. Furthermore, our data indicates that the use of secondary video in design projects is appropriate and even has certain advantages compared to primary field video.",
    "call-number": "10.1145/3491102.3517538",
    "collection-number": "533",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517538",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Head-worn display, Augmented reality, Secondary video, Participatory design, Design method, Emergency medical services",
    "number": "Article 533",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing for Inaccessible Emergency Medical Service Contexts: Development and Evaluation of the Contextual Secondary Video Toolkit",
    "URL": "https://doi.org/10.1145/3491102.3517538"
  },
  {
    "id": "10.1145/3491102.3501860",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Altarriba Bertran",
        "given": "Ferran"
      },
      {
        "family": "Bisbe Armengol",
        "given": "Laura"
      },
      {
        "family": "Cooke",
        "given": "Cameron"
      },
      {
        "family": "Chen",
        "given": "Ivy"
      },
      {
        "family": "Dong",
        "given": "Victor"
      },
      {
        "family": "Dastoor",
        "given": "Binaisha"
      },
      {
        "family": "Tadano",
        "given": "Kelsea"
      },
      {
        "family": "Dean",
        "given": "Fyez"
      },
      {
        "family": "Wang",
        "given": "Jessalyn"
      },
      {
        "family": "Altarriba Bertran",
        "given": "Adri\u00e0"
      },
      {
        "family": "Duval",
        "given": "Jared"
      },
      {
        "family": "Isbister",
        "given": "Katherine"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Here we present a co-design exploration into the potential of technology to playfully re-signify urban spaces. We created a speculative catalog of urban tech and used it to facilitate multi-stakeholder discussions about the playful potential of smart cities. The learnings from our co-design engagements embody different people's ideas of how tech might and might not support rich forms of urban play, and contribute to ongoing efforts at exploring how to playfully reconfigure our cities. We present: (1) a list of inspirational play potentials of urban spaces\u2014i.e. playful things already people do, and enjoy, in the public space; (2) a portfolio of speculative ideas that show how tech might help to realize that potential; and (3) a discussion of stakeholders\u2019 responses to these ideas. Our work can provide designers with inspiration and actionable advice for cultivating forms of urban play that cater to people's socio-emotional needs.",
    "call-number": "10.1145/3491102.3501860",
    "collection-number": "534",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501860",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Smart cities, Play, Fun, Co-design, Situated Play Design, Urban technology, Speculative design",
    "number": "Article 534",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Co-Imagining the Future of Playable Cities: A Bottom-Up, Multi-Stakeholder Speculative Inquiry into the Playful Potential of Urban Technology",
    "URL": "https://doi.org/10.1145/3491102.3501860"
  },
  {
    "id": "10.1145/3491102.3501967",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rechkemmer",
        "given": "Amy"
      },
      {
        "family": "Yin",
        "given": "Ming"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Previous research shows that laypeople\u2019s trust in a machine learning model can be affected by both performance measurements of the model on the aggregate level and performance estimates on individual predictions. However, it is unclear how people would trust the model when multiple performance indicators are presented at the same time. We conduct an exploratory human-subject experiment to answer this question. We find that while the level of model confidence significantly affects people\u2019s belief in model accuracy, both the model\u2019s stated and observed accuracy generally have a larger impact on people\u2019s willingness to follow the model\u2019s predictions as well as their self-reported levels of trust in the model, especially after observing the model\u2019s performance in practice. We hope the empirical evidence reported in this work could open doors to further studies to advance understanding of how people perceive, process, and react to performance-related information of machine learning.",
    "call-number": "10.1145/3491102.3501967",
    "collection-number": "535",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501967",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "trust, accuracy, human-subject experiments, Machine learning, confidence",
    "number": "Article 535",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models",
    "URL": "https://doi.org/10.1145/3491102.3501967"
  },
  {
    "id": "10.1145/3491102.3502057",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Ge"
      },
      {
        "family": "Zhao",
        "given": "Jun"
      },
      {
        "family": "Van Kleek",
        "given": "Max"
      },
      {
        "family": "Shadbolt",
        "given": "Nigel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "AI systems are becoming increasingly pervasive within children\u2019s devices, apps, and services. However, it is not yet well-understood how risks and ethical considerations of AI relate to children. This paper makes three contributions to this area: first, it identifies ten areas of alignment between general AI frameworks and codes for age-appropriate design for children. Then, to understand how such principles relate to real application contexts, we conducted a landscape analysis of children\u2019s AI systems, via a systematic literature review including 188 papers. This analysis revealed a wide assortment of applications, and that most systems\u2019 designs addressed only a small subset of principles among those we identified. Finally, we synthesised our findings in a framework to inform a new \u201cCode for Age-Appropriate AI\u201d, which aims to provide timely input to emerging policies and standards, and inspire increased interactions between the AI and child-computer interaction communities.",
    "call-number": "10.1145/3491102.3502057",
    "collection-number": "536",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502057",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "systematic literature review, age appropriate design, AI for children",
    "number": "Article 536",
    "number-of-pages": "29",
    "page": "1\u201329",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Informing Age-Appropriate AI: Examining Principles and Practices of AI for Children",
    "URL": "https://doi.org/10.1145/3491102.3502057"
  },
  {
    "id": "10.1145/3491102.3517511",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mozaffari",
        "given": "Mohammad Amin"
      },
      {
        "family": "Zhang",
        "given": "Xinyuan"
      },
      {
        "family": "Cheng",
        "given": "Jinghui"
      },
      {
        "family": "Guo",
        "given": "Jin L.C."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Inspiration from design examples plays a crucial role in the creative process of user interface design. However, current tools and techniques that support inspiration usually only focus on example browsing with limited user control or similarity-based example retrieval, leading to undesirable design outcomes such as focus drift and design fixation. To address these issues, we propose the GANSpiration approach that suggests design examples for both targeted and serendipitous inspiration, leveraging a style-based Generative Adversarial Network. A quantitative evaluation revealed that the outputs of GANSpiration-based example suggestion approaches are relevant to the input design, and at the same time include diverse instances. A user study with professional UI/UX practitioners showed that the examples suggested by our approach serve as viable sources of inspiration for overall design concepts and specific design elements. Overall, our work paves the road of using advanced generative machine learning techniques in supporting the creative design practice.",
    "call-number": "10.1145/3491102.3517511",
    "collection-number": "537",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517511",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "StyleGAN, inspiration, User interface design, creativity support",
    "number": "Article 537",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "GANSpiration: Balancing Targeted and Serendipitous Inspiration in User Interface Design with Style-Based Generative Adversarial Network",
    "URL": "https://doi.org/10.1145/3491102.3517511"
  },
  {
    "id": "10.1145/3491102.3502047",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mahajan",
        "given": "Shruti"
      },
      {
        "family": "Walker",
        "given": "Zoey"
      },
      {
        "family": "Boll",
        "given": "Rachel"
      },
      {
        "family": "Santacreu",
        "given": "Michelle"
      },
      {
        "family": "Salvino",
        "given": "Ally"
      },
      {
        "family": "Westfort",
        "given": "Michael"
      },
      {
        "family": "Reis",
        "given": "Jeanne"
      },
      {
        "family": "Solovey",
        "given": "Erin"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Questionnaires are fundamental learning and research tools for gathering insights and information from individuals, and now can be created easily using online tools. However, existing resources for creating questionnaires are designed for written languages (e.g. English) and do not support sign languages (e.g. American Sign Language). Sign languages (SLs) have unique visual characteristics that do not fit into user interface paradigms designed for written, text-based languages. Through a series of formative studies with the ASL signing community, this paper takes steps towards understanding the viability, potential benefit, challenges, and user interest in SL-centric surveys, a novel approach for creating questionnaires that meet the needs of deaf individuals using sign languages, without obligatory reliance on a written language to complete a questionnaire.",
    "call-number": "10.1145/3491102.3502047",
    "collection-number": "538",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502047",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "ASL, American Sign Language",
    "number": "Article 538",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Sign Language-Centric Design of ASL Survey Tools",
    "URL": "https://doi.org/10.1145/3491102.3502047"
  },
  {
    "id": "10.1145/3491102.3502029",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sanches",
        "given": "Pedro"
      },
      {
        "family": "Howell",
        "given": "Noura"
      },
      {
        "family": "Tsaknaki",
        "given": "Vasiliki"
      },
      {
        "family": "Jenkins",
        "given": "Tom"
      },
      {
        "family": "Helms",
        "given": "Karey"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent design research has shown an interest in diffraction and agential realism, which promise to offer generative alternatives when designing with data that resist treating data as objective or neutral. We explore engaging diffractively with \u2018lived data\u2019 to surface felt and prospective aspects of data as it is entangled in everyday lives of designers. This paper presents five biodata-based case studies demonstrating how design researchers can create knowledge about human bodies and behaviors via strategies that allow them to engage data diffractively. These studies suggest that designers can find insights for designing with data as it is lived by working with it in a slow, open-ended fashion that leaves room for messiness and time for discovering difference. Finally, we discuss the role of ambiguous, open-ended data interpretations to help surface different meanings and entanglements of data in everyday lives.",
    "call-number": "10.1145/3491102.3502029",
    "collection-number": "540",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502029",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "data, collaboration, material, empathy, bodies, being-with, more-than-human, design research, design, Biodata",
    "number": "Article 540",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Diffraction-in-action: Designerly Explorations of Agential Realism Through Lived Data",
    "URL": "https://doi.org/10.1145/3491102.3502029"
  },
  {
    "id": "10.1145/3491102.3517789",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zimmerman",
        "given": "John"
      },
      {
        "family": "Steinfeld",
        "given": "Aaron"
      },
      {
        "family": "Tomasic",
        "given": "Anthony"
      },
      {
        "family": "J. Romero",
        "given": "Oscar"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Design produces valuable knowledge by offering new perspectives that reframe problematic situations. Research through Design (RtD) contributes new frames along with design work demonstrating a frame's value. Interestingly, RtD papers rarely describe how reframing happens. This gap in documentation unintentionally implies a romantic account of design, it implies that the first step of an RtD project is to have a brilliant idea. This is especially problematic in cases where the reframing causes a pivot that leads to a new research program. To help address this gap, we describe a case where through a series of three design experiments we experienced a research pivot. We describe how our work to improve web-table navigation for screen-reader users broke our frame. The break led to a new research program focused on constructing a conversational internet. This paper offers our case along with reflection on reporting design work that drives reframing.",
    "call-number": "10.1145/3491102.3517789",
    "collection-number": "541",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517789",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Research through Design, drifting with intention, visually impaired, design experiment, design research program, reframe, accessibility",
    "number": "Article 541",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Recentering Reframing as an RtD Contribution: The Case of Pivoting from Accessible Web Tables to a Conversational Internet",
    "URL": "https://doi.org/10.1145/3491102.3517789"
  },
  {
    "id": "10.1145/3491102.3517584",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ivanov",
        "given": "Alexander"
      },
      {
        "family": "Au Yeung",
        "given": "Tim"
      },
      {
        "family": "Blair",
        "given": "Kathryn"
      },
      {
        "family": "Danyluk",
        "given": "Kurtis"
      },
      {
        "family": "Freeman",
        "given": "Georgina"
      },
      {
        "family": "Friedel",
        "given": "Marcus"
      },
      {
        "family": "Hull",
        "given": "Carmen"
      },
      {
        "family": "Hung",
        "given": "Michael Yuk-Shing"
      },
      {
        "family": "Pratte",
        "given": "Sydney"
      },
      {
        "family": "Willett",
        "given": "Wesley"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We explore the use of cinematic \u201cpre-visualization\u201d (previs) techniques as a rapid ideation and design futuring method for human computer interaction (HCI) research. Previs approaches, which are widely used in animation and film production, use digital design tools to create medium-fidelity videos that capture richer interaction, motion, and context than sketches or static illustrations. When used as a design futuring method, previs can facilitate rapid, iterative discussions that reveal tensions, challenges, and opportunities for new research. We performed eight one-week design futuring sprints, in which individual HCI researchers collaborated with a lead designer to produce concept sketches, storyboards, and videos that examined future applications of their research. From these experiences, we identify recurring themes and challenges and present a One Week Futuring Workbook that other researchers can use to guide their own futuring sprints. We also highlight how variations of our approach could support other speculative design practices.",
    "call-number": "10.1145/3491102.3517584",
    "collection-number": "542",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517584",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "prototyping, previsualization, design futuring",
    "number": "Article 542",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "One Week in the Future: Previs Design Futuring for HCI Research",
    "URL": "https://doi.org/10.1145/3491102.3517584"
  },
  {
    "id": "10.1145/3491102.3517589",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Salminen",
        "given": "Joni"
      },
      {
        "family": "Wenyun Guan",
        "given": "Kathleen"
      },
      {
        "family": "Jung",
        "given": "Soon-Gyo"
      },
      {
        "family": "Jansen",
        "given": "Bernard"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Personas represent the needs of users in diverse populations and impact design by endearing empathy and improving communication. While personas have been lauded for their benefits, we could locate no prior review of persona use cases in design, prompting the question: how are personas actually used to achieve these benefits? To address this question, we review 95 articles containing persona application across multiple domains, and identify software development, healthcare, and higher education as the top domains that employ personas. We then present a three-stage design hierarchy of persona usage to describe how personas are used in design tasks. Finally, we assess the increasing trend of persona initiatives aimed towards social good rather than solely commercial interests. Our findings establish a roadmap of best practices for how practitioners can innovatively employ personas to increase the value of designs and highlight avenues of using personas for socially impactful purposes.",
    "call-number": "10.1145/3491102.3517589",
    "collection-number": "543",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517589",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 543",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Use Cases for Design Personas: A Systematic Review and New Frontiers",
    "URL": "https://doi.org/10.1145/3491102.3517589"
  },
  {
    "id": "10.1145/3491102.3517475",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chen",
        "given": "Janet X."
      },
      {
        "family": "McDonald",
        "given": "Allison"
      },
      {
        "family": "Zou",
        "given": "Yixin"
      },
      {
        "family": "Tseng",
        "given": "Emily"
      },
      {
        "family": "Roundy",
        "given": "Kevin A"
      },
      {
        "family": "Tamersoy",
        "given": "Acar"
      },
      {
        "family": "Schaub",
        "given": "Florian"
      },
      {
        "family": "Ristenpart",
        "given": "Thomas"
      },
      {
        "family": "Dell",
        "given": "Nicola"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Trauma is the physical, emotional, or psychological harm caused by deeply distressing experiences. Research with communities that may experience high rates of trauma has shown that digital technologies can create or exacerbate traumatic experiences. Via three vignettes, we discuss how considering the possible effects of trauma and traumatic stress reactions provides an explanatory lens with new insights into people\u2019s technology experiences. Then, we present a framework\u2014trauma-informed computing\u2014in which we adapt and show how to apply six key principles of trauma-informed approaches to computing: safety, trust, peer support, collaboration, enablement, and intersectionality. Through specific examples, we describe how to apply trauma-informed computing in four areas of computing research and practice: user experience research & design, security & privacy, artificial intelligence & machine learning, and organizational culture in tech companies. We conclude by discussing how adopting trauma-informed computing will lead to benefits for all users, not only those experiencing trauma.",
    "call-number": "10.1145/3491102.3517475",
    "collection-number": "544",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517475",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "trauma, intimate partner violence, transgender, gender-based violence, computer security and privacy, trauma-informed computing",
    "number": "Article 544",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Trauma-Informed Computing: Towards\u00a0Safer\u00a0Technology\u00a0Experiences\u00a0for\u00a0All",
    "URL": "https://doi.org/10.1145/3491102.3517475"
  },
  {
    "id": "10.1145/3491102.3502059",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Vaghela",
        "given": "Palashi"
      },
      {
        "family": "Jackson",
        "given": "Steven J"
      },
      {
        "family": "Sengers",
        "given": "Phoebe"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent work in HCI has shed light on structural issues of inequality in computing. Building on this work, this study analyzes the relatively understudied phenomenon of caste in computing. Contrary to common rhetorics of \u2018castelessness,\u2019 we show how computing worlds in India and Indian diasporic communities continue to be shaped and inflected by caste relations. We study how, when and where Dalits (formerly \u2018untouchables\u2019) encounter caste in computing. We show how they artfully navigate these caste inscriptions by interpreting, interrupting and ambiguating caste and by finding caste communities. Drawing on the life stories of 16 Dalit engineers and anti-caste, queer-feminist and critical race theories, we argue that a dynamic and performative approach to caste, and other forms of inequality in HCI and computing, emphasizes the artfulness and agency of those at the margins as they challenge structural inequality in everyday life. Lastly, we suggest practical ways of addressing caste to build more open and inclusive cultures of global computing.",
    "call-number": "10.1145/3491102.3502059",
    "collection-number": "545",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502059",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "caste, merit, feminist HCI, postcolonial computing, technology and inequality",
    "number": "Article 545",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Interrupting Merit, Subverting Legibility: Navigating Caste In \u2018Casteless\u2019 Worlds of Computing",
    "URL": "https://doi.org/10.1145/3491102.3502059"
  },
  {
    "id": "10.1145/3491102.3501853",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Vandenberghe",
        "given": "Bert"
      },
      {
        "family": "Gerling",
        "given": "Kathrin"
      },
      {
        "family": "Geurts",
        "given": "Luc"
      },
      {
        "family": "Vanden Abeele",
        "given": "Vero"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Maker culture encourages do-it-yourself practices to create, repair, and repurpose technology. In Human-Computer Interaction (HCI) research, it is seen as a means of empowering people, providing affordable and customisable technology with potential to enrich areas such as education or assistive technology. To investigate this alleged potential, we performed an anthropological inquiry at an elementary school for disabled children that lasted one year, participating in everyday activities with students, teachers, and therapists. We observed \u2018heterogeneity in a fluid environment\u2019 and \u2018creativity in the moment\u2019 in an \u2018endemically underfunded\u2019 setting. We saw how technology is \u2018injecting dependencies\u2019, \u2018reinforcing disability\u2019, and \u2018occupying time and space\u2019, changing our view on the role that making can have. Leveraging Empowerment Theory, we highlight how (making) technology risks ignoring the intertwined dynamics between the individual, the organisational, and the community, and articulate points for reflection for technology in schools for disabled children for the HCI research community.",
    "call-number": "10.1145/3491102.3501853",
    "collection-number": "546",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501853",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "ethnography, school for disabled children, physical therapy, making technology, non-use, anthropology, disability, occupational therapy, empowerment",
    "number": "Article 546",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Maker Technology and the Promise of Empowerment in a Flemish School for Disabled Children",
    "URL": "https://doi.org/10.1145/3491102.3501853"
  },
  {
    "id": "10.1145/3491102.3517592",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Spiel",
        "given": "Katta"
      },
      {
        "family": "Hornecker",
        "given": "Eva"
      },
      {
        "family": "Williams",
        "given": "Rua Mae"
      },
      {
        "family": "Good",
        "given": "Judith"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Technology research for neurodivergent conditions is largely shaped by research aims which privilege neuro-normative outcomes. As such, there is an epistemic imbalance in meaning making about these technologies. We conducted a critical literature review of technologies designed for people with ADHD, focusing on how ADHD is framed, the research aims and approaches, the role of people with ADHD within the research process, and the types of systems being developed within Computing and HCI. Our analysis and review is conducted explicitly from an insider perspective, bringing our perspectives as neurodivergent researchers to the topic of technologies in the context of ADHD. We found that 1) technologies are largely used to \u2018mitigate\u2019 the experiences of ADHD which are perceived as disruptive to neurotypical standards of behaviour; 2) little HCI research in the area invites this population to co-construct the technologies or to leverage neurodivergent experiences in the construction of research aims; and 3) participant resistance to deficit frames can be read within the researchers\u2019 own accounts of participant actions. We discuss the implications of this status quo for disabled people and technology researchers alike, and close with a set of recommendations for future work in this area.",
    "call-number": "10.1145/3491102.3517592",
    "collection-number": "547",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517592",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "ADHD, neurodivergence, methodology, literature review, cripping, disability studies, neurodiversity, critical theory",
    "number": "Article 547",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ADHD and Technology Research \u2013 Investigated by Neurodivergent Readers",
    "URL": "https://doi.org/10.1145/3491102.3517592"
  },
  {
    "id": "10.1145/3491102.3501982",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Pendse",
        "given": "Sachin R"
      },
      {
        "family": "Nkemelu",
        "given": "Daniel"
      },
      {
        "family": "Bidwell",
        "given": "Nicola J"
      },
      {
        "family": "Jadhav",
        "given": "Sushrut"
      },
      {
        "family": "Pathare",
        "given": "Soumitra"
      },
      {
        "family": "De Choudhury",
        "given": "Munmun"
      },
      {
        "family": "Kumar",
        "given": "Neha"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The field of digital mental health is making strides in the application of technology to broaden access to care. We critically examine how these technology-mediated forms of care might amplify historical injustices, and erase minoritized experiences and expressions of mental distress and illness. We draw on decolonial thought and critiques of identity-based algorithmic bias to analyze the underlying power relations impacting digital mental health technologies today, and envision new pathways towards a decolonial digital mental health. We argue that a decolonial digital mental health is one that centers lived experience over rigid classification, is conscious of structural factors that influence mental wellbeing, and is fundamentally designed to deter the creation of power differentials that prevent people from having agency over their care. Stemming from this vision, we make recommendations for how researchers and designers can support more equitable futures for people experiencing mental distress and illness.",
    "call-number": "10.1145/3491102.3501982",
    "collection-number": "548",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501982",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "artificial intelligence, decolonial theory, medical pluralism, digital mental health, health inequities",
    "number": "Article 548",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "From Treatment to Healing:Envisioning a Decolonial Digital Mental Health",
    "URL": "https://doi.org/10.1145/3491102.3501982"
  },
  {
    "id": "10.1145/3491102.3517452",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cheng",
        "given": "Yi Fei"
      },
      {
        "family": "Yin",
        "given": "Hang"
      },
      {
        "family": "Yan",
        "given": "Yukang"
      },
      {
        "family": "Gugenheimer",
        "given": "Jan"
      },
      {
        "family": "Lindlbauer",
        "given": "David"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Diminished reality (DR) refers to the concept of removing content from a user\u2019s visual environment. While its implementation is becoming feasible, it is still unclear how users perceive and interact in DR-enabled environments and what applications it benefits. To address this challenge, we first conduct a formative study to compare user perceptions of DR and mediated reality effects (e.\u00a0g., changing the color or size of target elements) in four example scenarios. Participants preferred removing objects through opacity reduction (i.\u00a0e., the standard DR implementation) and appreciated mechanisms for maintaining a contextual understanding of diminished items (e.\u00a0g., outlining). In a second study, we explore the user experience of performing tasks within DR-enabled environments. Participants selected which objects to diminish and the magnitude of the effects when performing two separate tasks (video viewing, assembly). Participants were comfortable with decreased contextual understanding, particularly for less mobile tasks. Based on the results, we define guidelines for creating general DR-enabled environments.",
    "call-number": "10.1145/3491102.3517452",
    "collection-number": "549",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517452",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Empirical study, Mediated Reality, Diminished Reality",
    "number": "Article 549",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Understanding Diminished Reality",
    "URL": "https://doi.org/10.1145/3491102.3517452"
  },
  {
    "id": "10.1145/3491102.3517723",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lu",
        "given": "Feiyu"
      },
      {
        "family": "Xu",
        "given": "Yan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Imagine in the future people comfortably wear augmented reality (AR) displays all day, how do we design interfaces that adapt to the contextual changes as people move around? In current operating systems, the majority of AR content defaults to staying at a fixed location until being manually moved by the users. However, this approach puts the burden of user interface (UI) transition solely on users. In this paper, we first ran a bodystorming design workshop to capture the limitations of existing manual UI transition approaches in spatially diverse tasks. Then we addressed these limitations by designing and evaluating three UI transition mechanisms with different levels of automation and controllability (low-effort manual, semi-automated, fully-automated). Furthermore, we simulated imperfect contextual awareness by introducing prediction errors with different costs to correct them. Our results provide valuable lessons about the trade-offs between UI automation levels, controllability, user agency, and the impact of prediction errors.",
    "call-number": "10.1145/3491102.3517723",
    "collection-number": "550",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517723",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "automation, controllability, adaptive interfaces, agency",
    "number": "Article 550",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring Spatial UI Transition Mechanisms with Head-Worn Augmented Reality",
    "URL": "https://doi.org/10.1145/3491102.3517723"
  },
  {
    "id": "10.1145/3491102.3502127",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Janaka",
        "given": "Nuwan"
      },
      {
        "family": "Haigh",
        "given": "Chloe"
      },
      {
        "family": "Kim",
        "given": "Hyeongcheol"
      },
      {
        "family": "Zhang",
        "given": "Shan"
      },
      {
        "family": "Zhao",
        "given": "Shengdong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Optical see-through Head-Mounted Displays (OST HMDs, OHMDs) are known to facilitate situational awareness while accessing secondary information. However, information displayed on OHMDs can cause attention shifts, which distract users from natural social interactions. We hypothesize that information displayed in paracentral and near-peripheral vision can be better perceived while the user is maintaining eye contact during face-to-face conversations. Leveraging this idea, we designed a circular progress bar to provide progress updates in paracentral and near-peripheral vision. We compared it with textual and linear progress bars under two conversation settings: a simulated one with a digital conversation partner and a realistic one with a real partner. Results show that a circular progress bar can effectively reduce notification distractions without losing eye contact and is more preferred by users. Our findings highlight the potential of utilizing the paracentral and near-peripheral vision for secondary information presentation on OHMDs.",
    "call-number": "10.1145/3491102.3502127",
    "collection-number": "551",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502127",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "interruption, reminder notification, circular progress, paracentral, conversation, smart glasses, social interaction, HMD, near-peripheral",
    "number": "Article 551",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Paracentral and near-peripheral visualizations: Towards attention-maintaining secondary information presentation on OHMDs during in-person social interactions",
    "URL": "https://doi.org/10.1145/3491102.3502127"
  },
  {
    "id": "10.1145/3491102.3502026",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Qian",
        "given": "Jing"
      },
      {
        "family": "Sun",
        "given": "Qi"
      },
      {
        "family": "Wigington",
        "given": "Curtis"
      },
      {
        "family": "Han",
        "given": "Han L."
      },
      {
        "family": "Sun",
        "given": "Tong"
      },
      {
        "family": "Healey",
        "given": "Jennifer"
      },
      {
        "family": "Tompkin",
        "given": "James"
      },
      {
        "family": "Huang",
        "given": "Jeff"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Sharing annotations encourages feedback, discussion, and knowledge passing among readers and can be beneficial for personal and public use. Prior augmented reality (AR) systems have expanded these benefits to both digital and printed documents. However, despite smartphone AR now being widely available, there is a lack of research about how to use AR effectively for interactive document annotation. We propose Dually Noted, a smartphone-based AR annotation system that recognizes the layout of structural elements in a printed document for real-time authoring and viewing of annotations. We conducted experience prototyping with eight users to elicit potential benefits and challenges within smartphone AR, and this informed the resulting Dually Noted system and annotation interactions with the document elements. AR annotation is often unwieldy, but during a 12-user empirical study our novel structural understanding component allows Dually Noted to improve precise highlighting and annotation interaction accuracy by 13%, increase interaction speed by 42%, and significantly lower cognitive load over a baseline method without document layout understanding. Qualitatively, participants commented that Dually Noted was a swift and portable annotation experience. Overall, our research provides new methods and insights for how to improve AR annotations for physical documents.",
    "call-number": "10.1145/3491102.3502026",
    "collection-number": "552",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502026",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "augmented reality, layout structure, smartphone, Annotation, text, paper, document interaction",
    "number": "Article 552",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Dually Noted: Layout-Aware Annotations with Smartphone Augmented Reality",
    "URL": "https://doi.org/10.1145/3491102.3502026"
  },
  {
    "id": "10.1145/3491102.3517719",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Suzuki",
        "given": "Ryo"
      },
      {
        "family": "Karim",
        "given": "Adnan"
      },
      {
        "family": "Xia",
        "given": "Tian"
      },
      {
        "family": "Hedayati",
        "given": "Hooman"
      },
      {
        "family": "Marquardt",
        "given": "Nicolai"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "This paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics.",
    "call-number": "10.1145/3491102.3517719",
    "collection-number": "553",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517719",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "augmented reality, robotics, AR-HRI, human-robot interaction, shape-changing UI, VAM-HRI, actuated tangible UI, mixed reality",
    "number": "Article 553",
    "number-of-pages": "33",
    "page": "1\u201333",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces",
    "URL": "https://doi.org/10.1145/3491102.3517719"
  },
  {
    "id": "10.1145/3491102.3517494",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gobert",
        "given": "Camille"
      },
      {
        "family": "Beaudouin-Lafon",
        "given": "Michel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Document description languages such as LaTeX are used extensively to author scientific and technical documents, but editing them is cumbersome: code-based editors only provide generic features, while WYSIWYG interfaces only support a subset of the language. Our interviews with 11 LaTeX users highlighted their difficulties dealing with textually-encoded abstractions and with the mappings between source code and document output. To address some of these issues, we introduce Transitional Representations for document description languages, which enable the visualisation and manipulation of fragments of code in relation to their generated output. We present i-LaTeX, a LaTeX editor equipped with Transitional Representations of formulae, tables, images, and grid layouts. A 16-participant experiment shows that Transitional Representations let them complete common editing tasks significantly faster, with fewer compilations, and with a lower workload. We discuss how Transitional Representations affect editing strategies and conclude with directions for future work.",
    "call-number": "10.1145/3491102.3517494",
    "collection-number": "554",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517494",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Code editor, document, Transitional Representation",
    "number": "Article 554",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "i-LaTeX : Manipulating Transitional Representations between LaTeX Code and Generated Documents",
    "URL": "https://doi.org/10.1145/3491102.3517494"
  },
  {
    "id": "10.1145/3491102.3517549",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Arendttorp",
        "given": "Emilie Maria Nybo"
      },
      {
        "family": "Rodil",
        "given": "Kasper"
      },
      {
        "family": "Winschiers-Theophilus",
        "given": "Heike"
      },
      {
        "family": "Magoath",
        "given": "Christof"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent improvements in hand-tracking technologies support novel applications and developments of gesture interactions in virtual reality (VR). Current implementations are mostly convention-based, originating in a Western technological context, thereby creating a legacy bias in gesture interaction implementations. With expanding application contexts and growing user groups and contexts, the design and selection of gestures need to be diversified. In this paper we present an exploration of natural gestures, followed by their implementation in a VR application and co-design of new gestures with a marginalized San community in Namibia. This study contributes to the still scarce empirical work in user-driven gesture design research, aiming to reduce legacy bias, on a methodological and technical level as well as through engaging non-WEIRD participants. Our findings confirm the applicability of our method, combined with Partner and Priming suggested by Morris et al., to the design of gestures inspired by natural interactions. We also consider the implementation of user-designed gestures to be necessary to asses usability, usefulness and technical issues in VR. Furthermore, the research directly advances the HCI agenda for diversity, through an ongoing research and design partnership with an indigenous community in Southern Africa, thereby challenging systemic bias and promoting design for the pluriverse.",
    "call-number": "10.1145/3491102.3517549",
    "collection-number": "555",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517549",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Community, Hand Gestures, Namibia, San, Indigenous People, Natural Interaction, Virtual Reality, User Experiences, Diversity",
    "number": "Article 555",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Overcoming Legacy Bias: Re-Designing Gesture Interactions in Virtual Reality With a San Community in Namibia",
    "URL": "https://doi.org/10.1145/3491102.3517549"
  },
  {
    "id": "10.1145/3491102.3502000",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Taranta",
        "given": "Eugene Matthew"
      },
      {
        "family": "Maslych",
        "given": "Mykola"
      },
      {
        "family": "Ghamandi",
        "given": "Ryan"
      },
      {
        "family": "LaViola",
        "given": "Joseph"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Gesture recognition systems using nearest neighbor pattern matching are able to distinguish gesture from non-gesture actions by rejecting input whose recognition scores are poor. However, in the context of gesture customization, where training data is sparse, learning a tight rejection threshold that maximizes accuracy in the presence of continuous high activity (HA) data is a challenging problem. To this end, we present the Voight-Kampff Machine (VKM), a novel approach for rejection threshold selection. VKM uses new synthetic data techniques to select an initial threshold that the system thereafter adjusts based on the training set size and expected gesture production variability. We pair VKM with a state-of-the-art custom gesture segmenter and recognizer to evaluate our system across several HA datasets, where gestures are interleaved with non-gesture actions. Compared to alternative rejection threshold selection techniques, we show that our approach is the only one that consistently achieves high performance.",
    "call-number": "10.1145/3491102.3502000",
    "collection-number": "556",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502000",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "customization, gesture, rejection, recognition",
    "number": "Article 556",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Voight-Kampff Machine for Automatic Custom Gesture Rejection Threshold Selection",
    "URL": "https://doi.org/10.1145/3491102.3502000"
  },
  {
    "id": "10.1145/3491102.3501903",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Liu",
        "given": "Zhe"
      },
      {
        "family": "Chen",
        "given": "Chunyang"
      },
      {
        "family": "Wang",
        "given": "Junjie"
      },
      {
        "family": "Huang",
        "given": "Yuekai"
      },
      {
        "family": "Hu",
        "given": "Jun"
      },
      {
        "family": "Wang",
        "given": "Qing"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Mobile apps are indispensable for people\u2019s daily life. Complementing with automated GUI testing, manual testing is the last line of defence for app quality. However, the repeated actions and easily missing of functionalities make manual testing time-consuming and inefficient. Inspired by the game candy crush with flashy candies as hint moves for players, we propose an approach named NaviDroid for navigating testers via highlighted next operations for more effective and efficient testing. Within NaviDroid, we construct an enriched state transition graph with the triggering actions as the edges for two involved states. Based on it, we utilize the dynamic programming algorithm to plan the exploration path, and augment the GUI with visualized hints for testers to quickly explore untested activities and avoid duplicate explorations. The automated experiments demonstrate the high coverage and efficient path planning of NaviDroid and a user study further confirms its usefulness. The NaviDroid can help us develop more robust software that works in more mission-critical settings, not only by performing more thorough testing with the same effort that has been put in before, but also by integrating these techniques into different parts of development pipeline.",
    "call-number": "10.1145/3491102.3501903",
    "collection-number": "557",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501903",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Quality Assurance, Android App, Software Engineering, GUI testing",
    "number": "Article 557",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Guided Bug Crush: Assist Manual GUI Testing of Android Apps via Hint Moves",
    "URL": "https://doi.org/10.1145/3491102.3501903"
  },
  {
    "id": "10.1145/3491102.3501962",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Danielescu",
        "given": "Andreea"
      },
      {
        "family": "Piorkowski",
        "given": "David"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Previous gesture elicitation studies have found that user proposals are influenced by legacy bias which may inhibit users from proposing gestures that are most appropriate for an interaction. Increasing production during elicitation studies has shown promise moving users beyond legacy gestures. However, variety decreases as more symbols are produced. While several studies have used increased production since its introduction, little research has focused on understanding the effect on the proposed gesture quality, on why variety decreases, and on whether increased production should be limited. In this paper, we present a gesture elicitation study aimed at understanding the impact of increased production. We show that users refine the most promising gestures and that how long it takes to find promising gestures varies by participant. We also show that gestural refinements provide insight into the gestural features that matter for users to assign semantic meaning and discuss implications for training gesture classifiers.",
    "call-number": "10.1145/3491102.3501962",
    "collection-number": "558",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501962",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "user's mental models, public displays, full-body gestures, free-space gestures, fatigue, walk-up-and-use displays, Gesture elicitation",
    "number": "Article 558",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Iterative Design of Gestures During Elicitation: Understanding the Role of Increased Production",
    "URL": "https://doi.org/10.1145/3491102.3501962"
  },
  {
    "id": "10.1145/3491102.3502056",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Petrovskaya",
        "given": "Elena"
      },
      {
        "family": "Deterding",
        "given": "Sebastian"
      },
      {
        "family": "Zendle",
        "given": "David I"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Microtransactions have become a major monetisation model in digital games, shaping their design, impacting player experience, and raising ethical concerns. Research in this area has chiefly focused on loot boxes. This begs the question whether other microtransactions might actually be more relevant and problematic for players. We therefore conducted a content analysis of negative player reviews (n=801) of top-grossing mobile and desktop games to determine which problematic microtransactions are most prevalent and salient for players. We found that problematic microtransactions with mobile games featuring more frequent and different techniques compared to desktop games. Across both, players minded issues related to fairness, transparency, and degraded user experience, supporting prior theoretical work, and importantly take issue with monetisation-driven design as such. We identify future research needs on why microtransactions in particular spark this critique, and which player communities it may be more or less representative of.",
    "call-number": "10.1145/3491102.3502056",
    "collection-number": "560",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502056",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "mobile games, microtransactions, dark patterns, player experience, ethics",
    "number": "Article 560",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Prevalence and Salience of Problematic Microtransactions in Top-Grossing Mobile and PC Games: A Content Analysis of User Reviews",
    "URL": "https://doi.org/10.1145/3491102.3502056"
  },
  {
    "id": "10.1145/3491102.3517438",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fern\u00e1ndez Galeote",
        "given": "Daniel"
      },
      {
        "family": "Legaki",
        "given": "Nikoletta-Zampeta"
      },
      {
        "family": "Hamari",
        "given": "Juho"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Games are considered promising for engaging people with climate change. In virtual worlds, players can adopt empowering roles to mitigate greenhouse gas emissions and/or adapt to climate impacts. However, the lack of a comprehensive exploration of existing climate-related identities and actions prevents understanding their potential. Here, we analyze 80 video games and classify avatar identities, or expected player roles, into six types. Climate selves encourage direct life changes; climate citizens are easy to identify with and imitate; climate heroes are inspirational figures upholding environmental values; empowered individuals deliberate to avoid a tragedy of the commons; authorities should consider stakeholders and the environment; and faction leaders engage in bi- or multilateral relations. Adaptation is often for decision-making profiles, while empowered individuals, authorities, and faction leaders usually face conflicting objectives. We discuss our results in relation to avatar research and provide suggestions for researchers, designers, and educators.",
    "call-number": "10.1145/3491102.3517438",
    "collection-number": "561",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517438",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "role, mitigation, adaptation, gamification, games, game-based learning, climate change engagement, identity, avatars, global warming, sustainability",
    "number": "Article 561",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Avatar Identities and Climate Change Action in Video Games: Analysis of Mitigation and Adaptation Practices",
    "URL": "https://doi.org/10.1145/3491102.3517438"
  },
  {
    "id": "10.1145/3491102.3501934",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Robinson",
        "given": "Raquel Breejon"
      },
      {
        "family": "Rheeder",
        "given": "Ricardo"
      },
      {
        "family": "Klarkowski",
        "given": "Madison"
      },
      {
        "family": "Mandryk",
        "given": "Regan L"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Now more than ever, people are using online platforms to communicate. Twitch, the foremost platform for live game streaming, offers many communication modalities. However, the platform lacks representation of social cues and signals of the audience experience, which are innately present in live events. To address this, we present a technology probe that captures the audience energy and response in a game streaming context. We designed a game and integrated a custom-communication modality\u2014Commons Sense\u2014in which the audience members\u2019 heart rates are sensed via webcam, averaged, and fed into a video game to affect sound, lighting, and difficulty. We conducted an \u2018in-the-wild\u2019 evaluation with four Twitch streamers and their audience members (N=55) to understand how these groups interacted through Commons Sense. Audience members and streamers indicated high levels of enjoyment and engagement with Commons Sense, suggesting the potential of physiological interaction as a beneficial communication tool in live streaming.",
    "call-number": "10.1145/3491102.3501934",
    "collection-number": "562",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501934",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Twitch, heart rate, live streaming, physiology, affective games, audience participation",
    "number": "Article 562",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201dChat Has No Chill\u201d: A Novel Physiological Interaction For Engaging Live Streaming Audiences",
    "URL": "https://doi.org/10.1145/3491102.3501934"
  },
  {
    "id": "10.1145/3491102.3517542",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jin",
        "given": "Qiao"
      },
      {
        "family": "Liu",
        "given": "Yu"
      },
      {
        "family": "Yarosh",
        "given": "Svetlana"
      },
      {
        "family": "Han",
        "given": "Bo"
      },
      {
        "family": "Qian",
        "given": "Feng"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "VR has received increased attention as an educational tool and many argue it is destined to influence educational practices, especially with the emergence of the Metaverse. Most prior research on educational VR reports on applications or systems designed for specified educational or training objectives. However, it is also crucial to understand current practices and attitudes across disciplines, having a holistic view to extend the body of knowledge in terms of VR adoption in an authentic setting. Taking a higher-level perception of people in different roles, we conducted a qualitative analysis based on 23 interviews with major stakeholders and a series of participatory design workshops with instructors and students. We identified the stakeholders who need to be considered for using VR in higher education, and highlighted the challenges and opportunities critical for VR current and potential practices in the university classroom. Finally, we discussed the design implications based on our findings. This study contributes a detailed description of current perceptions and considerations from a multi-stakeholder perspective, providing new empirical insights for designing novel VR and HCI technologies in higher education.",
    "call-number": "10.1145/3491102.3517542",
    "collection-number": "563",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517542",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Reality, social VR, collaboration, multi-stakeholder, higher education, educational VR",
    "number": "Article 563",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How Will VR Enter University Classrooms? Multi-stakeholders Investigation of VR in Higher Education",
    "URL": "https://doi.org/10.1145/3491102.3517542"
  },
  {
    "id": "10.1145/3491102.3517736",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fernandez-Nieto",
        "given": "Gloria"
      },
      {
        "family": "An",
        "given": "Pengcheng"
      },
      {
        "family": "Zhao",
        "given": "Jian"
      },
      {
        "family": "Buckingham Shum",
        "given": "Simon"
      },
      {
        "family": "Martinez-Maldonado",
        "given": "Roberto"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Despite the digital revolution, physical space remains the site for teaching and learning embodied knowledge and skills. Both teachers and students must develop spatial competencies to effectively use classroom spaces, enabling fluid verbal and non-verbal interaction. While video permits rich activity capture, it provides no support for quickly seeing activity patterns that can assist learning. In contrast, position tracking systems permit the automated modelling of spatial behaviour, opening new possibilities for feedback. This paper introduces the design rationale for \u201dDandelion Diagrams\u201d that integrate participant location, trajectory and body orientation over a variable period. Applied in two authentic teaching contexts (a science laboratory, and a nursing simulation) we show how heatmaps showing only teacher/student location led to misinterpretations that were resolved by overlaying Dandelion Diagrams. Teachers also identified a variety of ways they could aid professional development. We conclude Dandelion Diagrams assisted sensemaking, but discuss the ethical risks of over-interpretation.",
    "call-number": "10.1145/3491102.3517736",
    "collection-number": "564",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517736",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Multimodal, Learning analytics, Teamwork, Indoor positioning, Teaching",
    "number": "Article 564",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Classroom Dandelions: Visualising Participant Position, Trajectory and Body Orientation Augments Teachers\u2019 Sensemaking",
    "URL": "https://doi.org/10.1145/3491102.3517736"
  },
  {
    "id": "10.1145/3491102.3517562",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhou",
        "given": "Guoyang"
      },
      {
        "family": "Nagle",
        "given": "Amy"
      },
      {
        "family": "Takahashi",
        "given": "George"
      },
      {
        "family": "Hornbeck",
        "given": "Tera"
      },
      {
        "family": "Loomis",
        "given": "Ann"
      },
      {
        "family": "Smith",
        "given": "Beth"
      },
      {
        "family": "Duerstock",
        "given": "Bradley"
      },
      {
        "family": "Yu",
        "given": "Denny"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Mannequin-based simulations are widely used to train novice nurses. However, current mannequins have no dynamic facial expressions, which decreases the mannequins\u2019 fidelity and impacts students\u2019 learning outcomes and experience. This study proposes a projection-based AR system for overlaying dynamic facial expressions on a mannequin and implements the system in a stroke simulation. Thirty-six undergraduate nursing students participated in the study and were equally divided into the control (without the system) and experimental group (with the system). The participants\u2019 gaze behavior, simulation performance, and subjective evaluation were measured. Results illustrated that the participants focused more on the face-animated mannequin than the traditional mannequin during the simulation. Nursing experts believed that the face-animated mannequin increased the participants\u2019 performance in recognizing deviations but decreased their performance in seeking additional information. Moreover, the participants reported that the face-animated mannequin was more interactive and helpful for performing appropriate assessments than the traditional mannequin.",
    "call-number": "10.1145/3491102.3517562",
    "collection-number": "565",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517562",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "nursing simulation, interactive mannequin, mixed/augmented reality",
    "number": "Article 565",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Bringing Patient Mannequins to Life: 3D Projection Enhances Nursing Simulation",
    "URL": "https://doi.org/10.1145/3491102.3517562"
  },
  {
    "id": "10.1145/3491102.3517696",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ipsita",
        "given": "Ananya"
      },
      {
        "family": "Erickson",
        "given": "Levi"
      },
      {
        "family": "Dong",
        "given": "Yangzi"
      },
      {
        "family": "Huang",
        "given": "Joey"
      },
      {
        "family": "Bushinski",
        "given": "Alexa K"
      },
      {
        "family": "Saradhi",
        "given": "Sraven"
      },
      {
        "family": "Villanueva",
        "given": "Ana M"
      },
      {
        "family": "Peppler",
        "given": "Kylie A"
      },
      {
        "family": "Redick",
        "given": "Thomas S"
      },
      {
        "family": "Ramani",
        "given": "Karthik"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The US manufacturing industry is currently facing a welding workforce shortage which is largely due to inadequacy of widespread welding training. To address this challenge, we present a Virtual Reality (VR)-based training system aimed at transforming state-of-the-art-welding simulations and in-person instruction into a widely accessible and engaging platform. We applied backward design principles to design a low-cost welding simulator in the form of modularized units through active consulting with welding training experts. Using a minimum viable prototype, we conducted a user study with 24 novices to test the system\u2019s usability. Our findings show (1) greater effectiveness of the system in transferring skills to real-world environments as compared to accessible video-based alternatives and, (2) the visuo-haptic guidance during virtual welding enhances performance and provides a realistic learning experience to users. Using the solution, we expect inexperienced users to achieve competencies faster and be better prepared to enter actual work environments.",
    "call-number": "10.1145/3491102.3517696",
    "collection-number": "566",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517696",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual Reality Welding Simulators, Manufacturing, Virtual Reality Training, Backward design, Welding, Virtual Reality",
    "number": "Article 566",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Modeling of Virtual Reality Welding Simulators to Promote Accessible and Scalable Training",
    "URL": "https://doi.org/10.1145/3491102.3517696"
  },
  {
    "id": "10.1145/3491102.3502035",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Feinberg",
        "given": "Rachel R."
      },
      {
        "family": "Lakshmi",
        "given": "Udaya"
      },
      {
        "family": "Golino",
        "given": "Matthew J."
      },
      {
        "family": "Arriaga",
        "given": "Rosa I."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Meditation has become a popular option to manage stress. Though studies examine technologies to assist in meditation, few explore how technology supports development of such skills for independent practice. From a two-phase mixed-methods study, we contribute learner-centered insights from 36 participants in a virtual reality environment designed to teach meditation skills to novices. In Phase I, we gathered affective and behavioral learner needs from 21 meditation novices, experts, and instructors to synthesize insights for learning. We then designed ZenVR: an interactive system to deliver an eight-lesson meditation curriculum to support learners\u2019 progress. In Phase II, we conducted a 6-week longitudinal lab-based evaluation with 15 novice meditation learners. We found statistically significant improvements in mindfulness and self-reported meditation ability. Their insights from a self-managed practice, two weeks after the study ended, offered opportunities to understand how technology can be designed to offer progressive support without creating dependence in technology-mediated meditation practice.",
    "call-number": "10.1145/3491102.3502035",
    "collection-number": "567",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502035",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Virtual reality, wellness, interaction design, self-guided learning, meditation",
    "number": "Article 567",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ZenVR: Design Evaluation of a Virtual Reality Learning System for Meditation",
    "URL": "https://doi.org/10.1145/3491102.3502035"
  },
  {
    "id": "10.1145/3491102.3502104",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Panigutti",
        "given": "Cecilia"
      },
      {
        "family": "Beretta",
        "given": "Andrea"
      },
      {
        "family": "Giannotti",
        "given": "Fosca"
      },
      {
        "family": "Pedreschi",
        "given": "Dino"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The field of eXplainable Artificial Intelligence (XAI) focuses on providing explanations for AI systems\u2019 decisions. XAI applications to AI-based Clinical Decision Support Systems (DSS) should increase trust in the DSS by allowing clinicians to investigate the reasons behind its suggestions. In this paper, we present the results of a user study on the impact of advice from a clinical DSS on healthcare providers\u2019 judgment in two different cases: the case where the clinical DSS explains its suggestion and the case it does not. We examined the weight of advice, the behavioral intention to use the system, and the perceptions with quantitative and qualitative measures. Our results indicate a more significant impact of advice when an explanation for the DSS decision is provided. Additionally, through the open-ended questions, we provide some insights on how to improve the explanations in the diagnosis forecasts for healthcare assistants, nurses, and doctors.",
    "call-number": "10.1145/3491102.3502104",
    "collection-number": "568",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502104",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Clinical Decision Support System, eXplainable AI, Advice-taking, Behavioral intention, XAI, Trust, User Study, HCI",
    "number": "Article 568",
    "number-of-pages": "9",
    "page": "1\u20139",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding the impact of explanations on advice-taking: a user study for AI-based clinical Decision Support Systems",
    "URL": "https://doi.org/10.1145/3491102.3502104"
  },
  {
    "id": "10.1145/3491102.3502141",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dang",
        "given": "Hai"
      },
      {
        "family": "Mecke",
        "given": "Lukas"
      },
      {
        "family": "Buschek",
        "given": "Daniel"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We investigate how multiple sliders with and without feedforward visualizations influence users\u2019 control of generative models. In an online study (N=138), we collected a dataset of people interacting with a generative adversarial network (StyleGAN2) in an image reconstruction task. We found that more control dimensions (sliders) significantly increase task difficulty and user actions. Visual feedforward partly mitigates this by enabling more goal-directed interaction. However, we found no evidence of faster or more accurate task performance. This indicates a tradeoff between feedforward detail and implied cognitive costs, such as attention. Moreover, we found that visualizations alone are not always sufficient for users to understand individual control dimensions. Our study quantifies fundamental UI design factors and resulting interaction behavior in this context, revealing opportunities for improvement in the UI design for interactive applications of generative models. We close by discussing design directions and further aspects.",
    "call-number": "10.1145/3491102.3502141",
    "collection-number": "569",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502141",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "generative adversarial network, interactive AI, image manipulation, dataset, user study",
    "number": "Article 569",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information",
    "URL": "https://doi.org/10.1145/3491102.3502141"
  },
  {
    "id": "10.1145/3491102.3501855",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zheng",
        "given": "Qingxiao"
      },
      {
        "family": "Tang",
        "given": "Yiliu"
      },
      {
        "family": "Liu",
        "given": "Yiren"
      },
      {
        "family": "Liu",
        "given": "Weizi"
      },
      {
        "family": "Huang",
        "given": "Yun"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Early conversational agents (CAs) focused on dyadic human-AI interaction between humans and the CAs, followed by the increasing popularity of polyadic human-AI interaction, in which CAs are designed to mediate human-human interactions. CAs for polyadic interactions are unique because they encompass hybrid social interactions, i.e., human-CA, human-to-human, and human-to-group behaviors. However, research on polyadic CAs is scattered across different fields, making it challenging to identify, compare, and accumulate existing knowledge. To promote the future design of CA systems, we conducted a literature review of ACM publications and identified a set of works that conducted UX (user experience) research. We qualitatively synthesized the effects of polyadic CAs into four aspects of human-human interactions, i.e., communication, engagement, connection, and relationship maintenance. Through a mixed-method analysis of the selected polyadic and dyadic CA studies, we developed a suite of evaluation measurements on the effects. Our findings show that designing with social boundaries, such as privacy, disclosure, and identification, is crucial for ethical polyadic CAs. Future research should also advance usability testing methods and trust-building guidelines for conversational AI.",
    "call-number": "10.1145/3491102.3501855",
    "collection-number": "570",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501855",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Conversational AI, Conversational Agent, UX Research, Literature Review, Chatbot",
    "number": "Article 570",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "UX Research on Conversational Human-AI Interaction: A Literature Review of the ACM Digital Library",
    "URL": "https://doi.org/10.1145/3491102.3501855"
  },
  {
    "id": "10.1145/3491102.3517670",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Zhu",
        "given": "Xinyu"
      },
      {
        "family": "Zhang",
        "given": "Xingguo"
      },
      {
        "family": "Chen",
        "given": "Zinan"
      },
      {
        "family": "Dong",
        "given": "Zhanxun"
      },
      {
        "family": "Gu",
        "given": "Zhenyu"
      },
      {
        "family": "Chang",
        "given": "Danni"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Nowadays, social robots have become human's important companions. The anthropomorphic features of robots, which are important in building natural user experience and trustable human-robot partnership, have attracted increasing attention. Among these features, eyes attract most audience's attention and are particularly important. This study aims to investigate the influence of robot eye design on users\u2019 trustworthiness perception. Specifically, a simulation robot model was developed. Three sets of experiments involving sixty-six participants were conducted to investigate the effects of (i) visual complexity of eye design, (ii) blink rate, and (iii) gaze aversion of social robots on users\u2019 perceived trustworthiness. Results indicate that high visual complexity and gaze aversion lead to higher perceived trustworthiness and reveal a positive correlation between the perceived anthropomorphic effect of eye design and users\u2019 perceived trust, while a non-significant effect of blink rate has been found. Preliminary suggestions are provided for the design of social robots in future works.",
    "call-number": "10.1145/3491102.3517670",
    "collection-number": "571",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517670",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "User's trustworthiness perception, Robot eye design, Social robot, Anthropomorphic design, Human-robot interaction",
    "number": "Article 571",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Trusted Listener: The Influence of Anthropomorphic Eye Design of Social Robots on User's Perception of Trustworthiness",
    "URL": "https://doi.org/10.1145/3491102.3517670"
  },
  {
    "id": "10.1145/3491102.3501998",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Cambo",
        "given": "Scott Allen"
      },
      {
        "family": "Gergle",
        "given": "Darren"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data science and machine learning provide indispensable techniques for understanding phenomena at scale, but the discretionary choices made when doing this work are often not recognized. Drawing from qualitative research practices, we describe how the concepts of positionality and reflexivity can be adapted to provide a framework for understanding, discussing, and disclosing the discretionary choices and subjectivity inherent to data science work. We first introduce the concepts of model positionality and computational reflexivity that can help data scientists to reflect on and communicate the social and cultural context of a model\u2019s development and use, the data annotators and their annotations, and the data scientists themselves. We then describe the unique challenges of adapting these concepts for data science work and offer annotator fingerprinting and position mining as promising solutions. Finally, we demonstrate these techniques in a case study of the development of classifiers for toxic commenting in online communities.",
    "call-number": "10.1145/3491102.3501998",
    "collection-number": "572",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501998",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Computational reflexivity, model positionality, human-centered data science, critical data studies, position mining, human-centered machine learning, annotator fingerprinting, data science",
    "number": "Article 572",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science",
    "URL": "https://doi.org/10.1145/3491102.3501998"
  },
  {
    "id": "10.1145/3491102.3501857",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Docherty",
        "given": "Niall"
      },
      {
        "family": "Biega",
        "given": "Asia J."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The psychological costs of the attention economy are often considered through the binary of harmful design and healthy use, with digital well-being chiefly characterised as a matter of personal responsibility. This article adopts an interdisciplinary approach to highlight the empirical, ideological, and political limits of embedding this individualised perspective in computational discourses and designs of digital well-being measurement. We will reveal well-being to be a culturally specific and environmentally conditioned concept and will problematize user engagement as a universal proxy for well-being. Instead, the contributing factors of user well-being will be located in environing social, cultural, and political conditions far beyond the control of individual users alone. In doing so, we hope to reinvigorate the issue of digital well-being measurement as a nexus point of political concern, through which multiple disciplines can study experiences of digital ill as symptomatic of wider social inequalities and (capitalist) relations of power.",
    "call-number": "10.1145/3491102.3501857",
    "collection-number": "573",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501857",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "power, well-being, measurement, user engagement, time well-spent",
    "number": "Article 573",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "(Re)Politicizing Digital Well-Being: Beyond User Engagements",
    "URL": "https://doi.org/10.1145/3491102.3501857"
  },
  {
    "id": "10.1145/3491102.3501949",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dillahunt",
        "given": "Tawanna R"
      },
      {
        "family": "Lu",
        "given": "Alex Jiahong"
      },
      {
        "family": "Israni",
        "given": "Aarti"
      },
      {
        "family": "Lodha",
        "given": "Ruchita"
      },
      {
        "family": "Brewer",
        "given": "Savana"
      },
      {
        "family": "Robinson",
        "given": "Tiera S"
      },
      {
        "family": "Wilson",
        "given": "Angela Brown"
      },
      {
        "family": "Wheeler",
        "given": "Earnest"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Mentorship and other social and relational support have been vital to poverty alleviation and transformative change. It is crucial to understand the underlying factors in the success of mentoring models and subsequent programs to support them. Thus, we conducted a mixed-methods study consisting of longitudinal surveys of community participants followed by semi-structured interviews with 28 community members, eight mentors, and two coaches participating in a community-based mentorship program. Drawing from community-based participatory research in partnership with a non-profit located in a Midwestern United States (U.S.) city, we unpack how the program supported self-sufficiency and economic mobility among adults experiencing financial hardships. Through an infrastructural lens, we attend to individuals\u2019 infrastructuring work in social support, flexibility, and trust to support a \u201cvillage\u201d model of community-based mentorship. Our results show how the village model differs from traditional mentorship models that assume dyadic, one-to-one, often didactic, and hierarchical relationships (e.g., expert and prot\u00e9g\u00e9, adult and child) and are used primarily in the workplace and educational settings. The village mentorship model advocates for less hierarchical and more balanced relationships in non-institutional settings and flexible communication and technological needs. We discuss new research opportunities and design strategies for rethinking technology-mediated mentorship to support poverty-stricken adults in the U.S.",
    "call-number": "10.1145/3491102.3501949",
    "collection-number": "574",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501949",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "economic mobility, infrastructuring, social support, community-based participatory research, community-based mentorship, infrastructure, mentorship",
    "number": "Article 574",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Village: Infrastructuring Community-based Mentoring to Support Adults Experiencing Poverty",
    "URL": "https://doi.org/10.1145/3491102.3501949"
  },
  {
    "id": "10.1145/3491102.3502122",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Erete",
        "given": "Sheena"
      },
      {
        "family": "Dickinson",
        "given": "Jessa"
      },
      {
        "family": "Gonzalez",
        "given": "Alejandra C."
      },
      {
        "family": "Rankin",
        "given": "Yolanda A."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "With increased public scrutiny of policing and growing calls for community-based violence prevention, street outreach programs that hire residents to mediate conflicts in their neighborhoods are gaining support. To understand how street outreach workers (SOWs) use information and communication technologies (ICTs) and how they envision future ICTs that better support their work, we interviewed 25 SOWs across three organizations. Results suggest that SOWs leverage ICTs to: 1) identify and mediate conflict; 2) support collaboration and teamwork; and 3) invoke community connections and trust. SOWs posit that new ICTs could provide a seamless infrastructure for communication among SOWs and between community members, assist with training to sharpen conflict negotiation skills, and provide insight on effective conflict mediation strategies.",
    "call-number": "10.1145/3491102.3502122",
    "collection-number": "575",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502122",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "public safety, support tools, community-led violence prevention, community justice initiatives, assets-based design",
    "number": "Article 575",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Unpacking the Complexities of Community-led Violence Prevention Work",
    "URL": "https://doi.org/10.1145/3491102.3502122"
  },
  {
    "id": "10.1145/3491102.3502006",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rifat",
        "given": "Mohammad Rashidujjaman"
      },
      {
        "family": "Prottoy",
        "given": "Hasan Mahmud"
      },
      {
        "family": "Ahmed",
        "given": "Syed Ishtiaque"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "While the presence of religious content is rapidly increasing over digital media, the HCI literature on digital media production has remained mostly limited by its focus on secular contents and analyses. Hence, the production, politics, and impact of such religious videos from the Global South have remained understudied in HCI. In this paper, we shed light on this topic through our nine-month-long ethnographic study on the production, sharing, and consumption of Islamic sermon videos (locally known as Waz) in Bangladesh. We report how faith, informal learning, local collaboration, creativity, and care play crucial roles in creating Islamic sermon videos and their proliferation online. We discuss how the sermon videos create a religious counterpublic in Bangladesh. We further discuss how such faith-based media production makes important lessons pertinent to the national grassroots politics in the Global South, politics of social media platforms, and HCI4D scholarship.",
    "call-number": "10.1145/3491102.3502006",
    "collection-number": "576",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502006",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "politics, counterpublic, waz, Islamic media, content creation, infrastructuring, grassroots",
    "number": "Article 576",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Putting the Waz on Social Media: Infrastructuring Online Islamic Counterpublic through Digital Sermons in Bangladesh",
    "URL": "https://doi.org/10.1145/3491102.3502006"
  },
  {
    "id": "10.1145/3491102.3517543",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sultana",
        "given": "Sharifa"
      },
      {
        "family": "Pritha",
        "given": "Sadia Tasnuva"
      },
      {
        "family": "Tasnim",
        "given": "Rahnuma"
      },
      {
        "family": "Das",
        "given": "Anik"
      },
      {
        "family": "Akter",
        "given": "Rokeya"
      },
      {
        "family": "Hasan",
        "given": "Shaid"
      },
      {
        "family": "Alam",
        "given": "S.M. Raihanul"
      },
      {
        "family": "Kabir",
        "given": "Muhammad Ashad"
      },
      {
        "family": "Ahmed",
        "given": "Syed Ishtiaque"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The challenge of designing against child sexual abuse becomes more complicated in conservative societies where talking about sex is tabooed. Our mix-method study, comprised of an online survey, five FGDs, and 20 semi-structured interviews in Bangladesh, investigates the common nature, location, and time of the abuse, post-incident support, and possible combating strategies. Besides revealing important facts, our findings highlight the need of decentering the design from the victims (children and/or guardians) to the community. Hence, building on the theory of transformative justice, we prototyped and evaluated \u2018ShishuShurokkha\u2019 \u2013 an online tool that involves the whole community by allowing anonymous bystander reporting, visualizing case-maps, connecting with legal, medical, and social support, and raising awareness. The evaluation of ShishuShurokkha shows the promise for such a communal approach toward combating child sexual abuse, and highlights the needs for sincere involvement of the government, NGOs, the legal, educational, and religious services in this.",
    "call-number": "10.1145/3491102.3517543",
    "collection-number": "577",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517543",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Social Media, Gender Harassment, Transformative Justice, ShishuShurokkha, Community Driven Design, Shame, Solidarity, Bangladesh, Child Sexual abuse",
    "number": "Article 577",
    "number-of-pages": "23",
    "page": "1\u201323",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u2018ShishuShurokkha\u2019: A Transformative Justice Approach for Combating Child Sexual Abuse in Bangladesh",
    "URL": "https://doi.org/10.1145/3491102.3517543"
  },
  {
    "id": "10.1145/3491102.3517565",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mahmood",
        "given": "Amama"
      },
      {
        "family": "Fung",
        "given": "Jeanie W"
      },
      {
        "family": "Won",
        "given": "Isabel"
      },
      {
        "family": "Huang",
        "given": "Chien-Ming"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Interactive AI systems such as voice assistants are bound to make errors because of imperfect sensing and reasoning. Prior human-AI interaction research has illustrated the importance of various strategies for error mitigation in repairing the perception of an AI following a breakdown in service. These strategies include explanations, monetary rewards, and apologies. This paper extends prior work on error mitigation by exploring how different methods of apology conveyance may affect people\u2019s perceptions of AI agents; we report an online study (N=37) that examines how varying the sincerity of an apology and the assignment of blame (on either the agent itself or others) affects participants\u2019 perceptions and experience with erroneous AI agents. We found that agents that openly accepted the blame and apologized sincerely for mistakes were thought to be more intelligent, likeable, and effective in recovering from errors than agents that shifted the blame to others.",
    "call-number": "10.1145/3491102.3517565",
    "collection-number": "578",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517565",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "blame assignment, error mitigation, voice interactions, Human-AI interaction, apologies",
    "number": "Article 578",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Owning Mistakes Sincerely: Strategies for Mitigating AI Errors",
    "URL": "https://doi.org/10.1145/3491102.3517565"
  },
  {
    "id": "10.1145/3491102.3517606",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lyons",
        "given": "Henrietta"
      },
      {
        "family": "Wijenayake",
        "given": "Senuri"
      },
      {
        "family": "Miller",
        "given": "Tim"
      },
      {
        "family": "Velloso",
        "given": "Eduardo"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "If you were significantly impacted by an algorithmic decision, how would you want the decision to be reviewed? In this study, we explore perceptions of review processes for algorithmic decisions that differ across three dimensions: the reviewer, how the review is conducted, and how long the review takes. Using a choice-based conjoint analysis we find that people prefer review processes that provide for human review, the ability to participate in the review process, and a timely outcome. Using a survey, we find that people also see human review that provides for participation to be the fairest review process. Our qualitative analysis indicates that the fairest review process provides the greatest likelihood of a favourable outcome, an opportunity for the decision subject and their situation to be fully and accurately understood, human involvement, and dignity. These findings have implications for the design of contestation procedures and also the design of algorithmic decision-making processes.",
    "call-number": "10.1145/3491102.3517606",
    "collection-number": "580",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517606",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "and transparency, algorithmic fairness, reviewability, algorithmic decision-making, contestability, accountability",
    "number": "Article 580",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "What\u2019s the Appeal? Perceptions of Review Processes for Algorithmic Decisions",
    "URL": "https://doi.org/10.1145/3491102.3517606"
  },
  {
    "id": "10.1145/3491102.3517527",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Langer",
        "given": "Markus"
      },
      {
        "family": "Hunsicker",
        "given": "Tim"
      },
      {
        "family": "Feldkamp",
        "given": "Tina"
      },
      {
        "family": "K\u00f6nig",
        "given": "Cornelius J."
      },
      {
        "family": "Grgi\u0107-Hla\u010da",
        "given": "Nina"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "In the media, in policy-making, but also in research articles, algorithmic decision-making (ADM) systems are referred to as algorithms, artificial intelligence, and computer programs, amongst other terms. We hypothesize that such terminological differences can affect people\u2019s perceptions of properties of ADM systems, people\u2019s evaluations of systems in application contexts, and the replicability of research as findings may be influenced by terminological differences. In two studies (N = 397, N = 622), we show that terminology does indeed affect laypeople\u2019s perceptions of system properties (e.g., perceived complexity) and evaluations of systems (e.g., trust). Our findings highlight the need to be mindful when choosing terms to describe ADM systems, because terminology can have unintended consequences, and may impact the robustness and replicability of HCI research. Additionally, our findings indicate that terminology can be used strategically (e.g., in communication about ADM systems) to influence people\u2019s perceptions and evaluations of these systems.",
    "call-number": "10.1145/3491102.3517527",
    "collection-number": "581",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517527",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "replicability, research methodology, terminology, human-centered AI",
    "number": "Article 581",
    "number-of-pages": "28",
    "page": "1\u201328",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cLook! It\u2019s a Computer Program! It\u2019s an Algorithm! It\u2019s AI!\u201d: Does Terminology Affect Human Perceptions and Evaluations of Algorithmic Decision-Making Systems?",
    "URL": "https://doi.org/10.1145/3491102.3517527"
  },
  {
    "id": "10.1145/3491102.3502121",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Ding"
      },
      {
        "family": "Prabhat",
        "given": "Shantanu"
      },
      {
        "family": "Sambasivan",
        "given": "Nithya"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Data is fundamental to AI/ML models. This paper investigates the work practices concerning data annotation as performed in the industry, in India. Previous human-centred investigations have largely focused on annotators\u2019 subjectivity, bias and efficiency. We present a wider perspective of the data annotation: following a grounded approach, we conducted three sets of interviews with 25 annotators, 10 industry experts and 12 ML/AI practitioners. Our results show that the work of annotators is dictated by the interests, priorities and values of others above their station. More than technical, we contend that data annotation is a systematic exercise of power through organizational structure and practice. We propose a set of implications for how we can cultivate and encourage better practice to balance the tension between the need for high quality data at low cost and the annotators\u2019 aspiration for well-being, career perspective, and active participation in building the AI dream.",
    "call-number": "10.1145/3491102.3502121",
    "collection-number": "582",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502121",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "future of work, qualitative study, data annotation, AI labour",
    "number": "Article 582",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Whose AI Dream? In search of the aspiration in data annotation.",
    "URL": "https://doi.org/10.1145/3491102.3502121"
  },
  {
    "id": "10.1145/3491102.3517481",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chounta",
        "given": "Irene-Angelica"
      },
      {
        "family": "Nolte",
        "given": "Alexander"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We explore the impact of Casual Affective Triggers (CAT) on response rates of online surveys. As CAT, we refer to objects that can be included in survey participation invitations and trigger participants\u2019 affect. The hypothesis is that participants who receive CAT-enriched invitations are more likely to respond to a survey. We conducted a study where the control condition received invitations without affective triggers, and the experimental condition received CAT-enriched invitations. We differentiated the triggers within the experimental condition: one-third of the population received a personalized invitation, one-third received a picture of the surveyor\u2019s cat, and one-third received both. We followed up with a survey to validate our findings. Our results suggest that CATs have a positive impact on response rates. We did not find CATs to induce response bias.",
    "call-number": "10.1145/3491102.3517481",
    "collection-number": "583",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517481",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "affect, user experience, online surveys, response rate",
    "number": "Article 583",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The CAT Effect: Exploring the Impact of Casual Affective Triggers on Online Surveys\u2019 Response Rates",
    "URL": "https://doi.org/10.1145/3491102.3517481"
  },
  {
    "id": "10.1145/3491102.3502103",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rainey",
        "given": "Jay"
      },
      {
        "family": "Macfarlane",
        "given": "Siobhan"
      },
      {
        "family": "Puussaar",
        "given": "Aare"
      },
      {
        "family": "Vlachokyriakos",
        "given": "Vasilis"
      },
      {
        "family": "Burrows",
        "given": "Roger"
      },
      {
        "family": "Smeddinck",
        "given": "Jan David"
      },
      {
        "family": "Briggs",
        "given": "Pamela"
      },
      {
        "family": "Montague",
        "given": "Kyle"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Academics and community organisations are increasingly adopting co-research practices where participants contribute to qualitative data collection, analysis, and dissemination. These qualitative practices can often lack transparency that can present a problem for stakeholders (such as funding agencies) who seek evidence of the rigour and accountability in these decision-making processes. When qualitative research is done digitally, paradata is available as interaction logs that reveal the underlying processes, such as the time spent engaging with different segments of an interview. In practice, paradata is seldom used to examine the decisions associated with undertaking qualitative research. This paper explores the role of paradata arising from a four-month engagement with a community-led charity that used a digital platform to support their qualitative co-research project. Through observations of platform use and reflective post-deployment interviews, our findings highlight examples of paradata generated through digital tools in qualitative research, e.g., listening coverage, engagement rate, thematic maps and data discards. From this, we contribute a conceptualisation of paradata and discuss its role in qualitative research to improve process transparency, enhance data sharing, and to create feedback loops with research participants.",
    "call-number": "10.1145/3491102.3502103",
    "collection-number": "584",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502103",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Citizen Research, Co-Research, Qualitative Practices, Paradata, Research Methods, Ethnography",
    "number": "Article 584",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring the Role of Paradata in Digitally Supported Qualitative Co-Research",
    "URL": "https://doi.org/10.1145/3491102.3502103"
  },
  {
    "id": "10.1145/3491102.3501833",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Chalhoub",
        "given": "George"
      },
      {
        "family": "Sarkar",
        "given": "Advait"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Despite efforts to augment or replace the 2-dimensional spreadsheet grid with formal data structures such as arrays and tables to ease formula authoring and reduce errors, the flexible grid remains overwhelmingly successful. Why? We interviewed a diverse sample of 21 spreadsheet users about their use of structure in spreadsheets. It emerges that data structuring is subject to a complex network of incentives and constraints, including factors extrinsic to spreadsheets such as the user\u2019s expertise, auxiliary tools, and collaborator needs. Moreover, we find that table columns are an important abstraction, and that operations such as conditional formatting, data validation, and formula authoring can be implemented on table columns, rather than cell ranges. To probe this, we designed 4 click-through prototypes for a follow-up study with 20 participants. We found that although column operations improved the value proposition of structured tables, they are unlikely to supplant the advantages of the flexible grid.",
    "call-number": "10.1145/3491102.3501833",
    "collection-number": "585",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501833",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "spreadsheets, data, user experience, structure",
    "number": "Article 585",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt\u2019s Freedom to Put Things Where My Mind Wants\u201d: Understanding and Improving the User Experience of Structuring Data in Spreadsheets",
    "URL": "https://doi.org/10.1145/3491102.3501833"
  },
  {
    "id": "10.1145/3491102.3517637",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Yao",
        "given": "Yuan"
      },
      {
        "family": "Cai",
        "given": "Junai"
      },
      {
        "family": "Du",
        "given": "Kexin"
      },
      {
        "family": "Hou",
        "given": "Yuxuan"
      },
      {
        "family": "Mi",
        "given": "Haipeng"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Integration of online and offline retail faces challenges in technology adoption, interaction style evolution and customer behavior shifts, while also being complicated by diverse perspectives from different stakeholders of consumers, retail staff, and retail business unit people. To explore how we can tackle the aforementioned challenges, this work applied the data-enabled design method and participatory data analysis to a case study, where 400 student consumers\u2019 shopping behavior data was collected, cross-analyzed, and visualized in a campus chain store. We then invited 13 stakeholders to join a co-creation workshop for a further participatory data analysis. In the workshop, the different stakeholders came to a design consensuses which we summarized into a series of practical design recommendations for improving the current store. Finally, we generalized the case study process as a contextual-informed-aware model, which can contribute to professional design practice for the retail industry.",
    "call-number": "10.1145/3491102.3517637",
    "collection-number": "586",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517637",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Design in Retail, Customer Behavior Understanding, Data-enabled Design, Participatory Data Analysis",
    "number": "Article 586",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Establishing Design Consensus toward Next-Generation Retail: Data-Enabled Design Exploration and Participatory Analysis",
    "URL": "https://doi.org/10.1145/3491102.3517637"
  },
  {
    "id": "10.1145/3491102.3517578",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sambasivan",
        "given": "Nithya"
      },
      {
        "family": "Veeraraghavan",
        "given": "Rajesh"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Field workers, like farmers and radiologists, play a crucial role in dataset collection for AI models in low-resource settings. However, we know little about how field workers\u2019 expertise is leveraged in dataset and model development. Based on 68 interviews with AI developers building for low-resource contexts, we find that developers reduced field workers to data collectors. Attributing poor data quality to worker practices, developers conceived of workers as corrupt, lazy, non-compliant, and as datasets themselves, pursuing surveillance and gamification to discipline workers to collect better quality data. Even though models sought to emulate the expertise of field workers, AI developers treated workers as non-essential and deskilled their expertise in service of building machine intelligence. We make the case for why field workers should be recognised as domain experts and re-imagine domain expertise as an essential partnership for AI development.",
    "call-number": "10.1145/3491102.3517578",
    "collection-number": "587",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517578",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "ML, field workers, Taylorism, deskilling, labour studies, data collection, domain expertise, data quality",
    "number": "Article 587",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Deskilling of Domain Expertise in AI Development",
    "URL": "https://doi.org/10.1145/3491102.3517578"
  },
  {
    "id": "10.1145/3491102.3502012",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Li",
        "given": "Tianshi"
      },
      {
        "family": "Reiman",
        "given": "Kayla"
      },
      {
        "family": "Agarwal",
        "given": "Yuvraj"
      },
      {
        "family": "Cranor",
        "given": "Lorrie Faith"
      },
      {
        "family": "Hong",
        "given": "Jason I."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Apple announced the introduction of app privacy details to their App Store in December 2020, marking the first ever real-world, large-scale deployment of the privacy nutrition label concept, which had been introduced by researchers over a decade earlier. The Apple labels are created by app developers, who self-report their app\u2019s data practices. In this paper, we present the first study examining the usability and understandability of Apple\u2019s privacy nutrition label creation process from the developer\u2019s perspective. By observing and interviewing 12 iOS app developers about how they created the privacy label for a real-world app that they developed, we identified common challenges for correctly and efficiently creating privacy labels. We discuss design implications both for improving Apple\u2019s privacy label design and for future deployment of other standardized privacy notices.",
    "call-number": "10.1145/3491102.3502012",
    "collection-number": "588",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502012",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Privacy, iOS Development, Interview, Privacy Nutrition Label, Developer Study",
    "number": "Article 588",
    "number-of-pages": "24",
    "page": "1\u201324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding Challenges for Developers to Create Accurate Privacy Nutrition Labels",
    "URL": "https://doi.org/10.1145/3491102.3502012"
  },
  {
    "id": "10.1145/3491102.3517559",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Stevens",
        "given": "Rock"
      },
      {
        "family": "Votipka",
        "given": "Daniel"
      },
      {
        "family": "Dykstra",
        "given": "Josiah"
      },
      {
        "family": "Tomlinson",
        "given": "Fernando"
      },
      {
        "family": "Quartararo",
        "given": "Erin"
      },
      {
        "family": "Ahern",
        "given": "Colin"
      },
      {
        "family": "Mazurek",
        "given": "Michelle L."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Incident response playbooks provide step-by-step guidelines to help security operations personnel quickly respond to specific threat scenarios. Although playbooks are common in the security industry, they have not been empirically evaluated for effectiveness. This paper takes a first step toward measuring playbooks and the frameworks used to design them, using two studies conducted in an enterprise environment. In the first study, twelve security professionals created two playbooks each, using two standard playbook design frameworks; the resulting playbooks were evaluated by experts for accuracy. In the second, we observed five personnel using the created playbooks in no-notice threat exercises within a live security-operations center. We find that playbooks can help simplify and support incident response efforts. However, playbooks designed using the frameworks we examined often lack sufficient detail for real-world use, particularly for more junior technicians. We provide recommendations for improving playbooks, playbook frameworks, and organizational processes surrounding playbook use.",
    "call-number": "10.1145/3491102.3517559",
    "collection-number": "589",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517559",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "incident response, security operations, usability of frameworks",
    "number": "Article 589",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How Ready is Your Ready? Assessing the Usability of Incident Response Playbook Frameworks",
    "URL": "https://doi.org/10.1145/3491102.3517559"
  },
  {
    "id": "10.1145/3491102.3501957",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tahaei",
        "given": "Mohammad"
      },
      {
        "family": "Vaniea",
        "given": "Kami"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Reliably recruiting participants with programming skills is an ongoing challenge for empirical studies involving software development technologies, often leading to the use of crowdsourcing platforms and computer science (CS) students. In this work, we use five existing survey instruments to explore the programming skills, privacy and security attitudes, and secure development self-efficacy of participants from a CS student mailing list and four crowdsourcing platforms (Appen, Clickworker, MTurk, and Prolific). We recruited 613 participants who claimed to have programming skills and assessed recruitment channels regarding costs, quality, programming skills, as well as privacy and security attitudes. We find that 27% of crowdsourcing participants, 40% of crowdsourcing participants who self-report to be developers, and 89% of CS students answered all programming skill questions correctly. CS students were the most cost-effective recruitment channel and rated themselves lower than crowdsourcing participants about secure development self-efficacy.",
    "call-number": "10.1145/3491102.3501957",
    "collection-number": "590",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501957",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "recruitment, datasets, usable privacy and security, developers, empirical software engineering, programming, crowdsourcing",
    "number": "Article 590",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Recruiting Participants With Programming Skills: A Comparison of Four Crowdsourcing Platforms and a CS Student Mailing List",
    "URL": "https://doi.org/10.1145/3491102.3501957"
  },
  {
    "id": "10.1145/3491102.3517585",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Ye"
      },
      {
        "family": "Zuest",
        "given": "Patrick"
      },
      {
        "family": "Yao",
        "given": "Yaxing"
      },
      {
        "family": "Lu",
        "given": "Zhicong"
      },
      {
        "family": "Wattenhofer",
        "given": "Roger"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Decentralized finance (DeFi) enables crypto-asset holders to conduct complex financial transactions, while maintaining control over their assets in the blockchain ecosystem. However, the transparency of blockchain networks and the open mechanism of DeFi applications also cause new security issues. In this paper, we focus on sandwich attacks, where attackers take advantage of the transaction confirmation delay and cause financial losses for victims. We evaluate the impact and investigate users\u2019 perceptions of sandwich attacks through a mix-method study. We find that due to users\u2019 lack of technical background and insufficient notifications from the markets, many users were not aware of the existence and the impact of sandwich attacks. They also had a limited understanding of how to resolve the security issue. Interestingly, users showed high tolerance for the impact of sandwich attacks on individuals and the ecosystem, despite potential financial losses. We discuss general implications for users, DeFi applications, and the community.",
    "call-number": "10.1145/3491102.3517585",
    "collection-number": "591",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517585",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "number": "Article 591",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Impact and User Perception of Sandwich Attacks in the DeFi Ecosystem",
    "URL": "https://doi.org/10.1145/3491102.3517585"
  },
  {
    "id": "10.1145/3491102.3517436",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hofmann",
        "given": "Megan"
      },
      {
        "family": "Mack",
        "given": "Kelly"
      },
      {
        "family": "Birchfield",
        "given": "Jessica"
      },
      {
        "family": "Cao",
        "given": "Jerry"
      },
      {
        "family": "Hughes",
        "given": "Autumn G"
      },
      {
        "family": "Kurpad",
        "given": "Shriya"
      },
      {
        "family": "Lum",
        "given": "Kathryn J"
      },
      {
        "family": "Warnock",
        "given": "Emily"
      },
      {
        "family": "Caspi",
        "given": "Anat"
      },
      {
        "family": "Hudson",
        "given": "Scott E"
      },
      {
        "family": "Mankoff",
        "given": "Jennifer"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Tactile maps can help people who are blind or have low-vision navigate and familiarize themselves with unfamiliar locations. Ideally, tactile maps can be customized to an individual\u2019s unique needs and abilities because of their limited space for representation. We present Maptimizer, a tool that generates tactile maps based on users\u2019 preferences and requirements. Maptimizer uses a two stage optimization process to pair representations with geographic information and tune those representations to present that information more clearly. In a small user study, Maptimizer helped participants more successfully and efficiently identify locations of interest in unknown areas. These results demonstrate the utility of optimization techniques and generative design in complex accessibility domains.",
    "call-number": "10.1145/3491102.3517436",
    "collection-number": "592",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517436",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "low-vision, ability based design, blind, navigation, optimization, generative design, tactile graphics, 3D printing",
    "number": "Article 592",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Maptimizer: Using Optimization to Tailor Tactile Maps to Users Needs",
    "URL": "https://doi.org/10.1145/3491102.3517436"
  },
  {
    "id": "10.1145/3491102.3517574",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Choi",
        "given": "Dasom"
      },
      {
        "family": "Lee",
        "given": "Uichin"
      },
      {
        "family": "Hong",
        "given": "Hwajung"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "YouTube is a space where people with disabilities can reach a wider online audience to present what it is like to have disabilities. Thus, it is imperative to understand how content creators with disabilities strategically interact with algorithms to draw viewers around the world. However, considering that the algorithm carries the risk of making less inclusive decisions for users with disabilities, whether the current algorithmic experiences (AXs) on video platforms is inclusive for creators with disabilities is an open question. To address that, we conducted semi-structured interviews with eight YouTubers with disabilities. We found that they aimed to inform the public of diverse representations of disabilities, which led them to work with algorithms by strategically portraying disability identities. However, they were disappointed that the way the algorithms work did not sufficiently support their goals. Based on findings, we suggest implications for designing inclusive AXs that could embrace creators\u2019 subtle needs.",
    "call-number": "10.1145/3491102.3517574",
    "collection-number": "593",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517574",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "people with disabilities, YouTube, inclusive design, content creators, algorithmic experience",
    "number": "Article 593",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt\u2019s not wrong, but I\u2019m quite disappointed\u201d: Toward an Inclusive Algorithmic Experience for Content Creators with Disabilities",
    "URL": "https://doi.org/10.1145/3491102.3517574"
  },
  {
    "id": "10.1145/3491102.3517483",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Senaratne",
        "given": "Hashini"
      },
      {
        "family": "Ananthanarayan",
        "given": "Swamy"
      },
      {
        "family": "Ellis",
        "given": "Kirsten"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Engagement with electronic toolkits enhances people\u2019s creative abilities, self-esteem, problem-solving skills and enables the creation of personally meaningful artifacts. A variety of simplified electronics toolkits are increasingly available to help different user groups engage with technology. However, they are often inaccessible for people with intellectual disabilities (IDs), who experience a range of cognitive and physical impairments. We designed and developed TronicBoards, a curated set of accessible electronic modules, to address this gap. We evaluated it one-on-one with 10 participants using a guided exploration approach. Our analysis revealed that participants were able to create simple sensor-based interactive circuits with varying levels of assistance. We report the strengths and weaknesses of TronicBoards, considering participants\u2019 successes and challenges in manipulating and comprehending toolkit components, circuit building activities, and troubleshooting processes. We discuss implications for designing inclusive electronics toolkits for people with IDs, particularly in considering design elements that improve functionality, comprehensibility and agency.",
    "call-number": "10.1145/3491102.3517483",
    "collection-number": "594",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517483",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Electronics Toolkit, Intellectual Disabilities, Accessibility, Computational toolkit",
    "number": "Article 594",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TronicBoards: An Accessible Electronics Toolkit for People with Intellectual Disabilities",
    "URL": "https://doi.org/10.1145/3491102.3517483"
  },
  {
    "id": "10.1145/3491102.3517469",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Wang",
        "given": "Yanan"
      },
      {
        "family": "Wang",
        "given": "Ruobin"
      },
      {
        "family": "Jung",
        "given": "Crescentia"
      },
      {
        "family": "Kim",
        "given": "Yea-Seul"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The data table is a basic but versatile representation to communicate data. From government reports to bank statements, tables effectively carry essential data-driven information by visually organizing data using rows, columns, and other arrangements (e.g., merged cells). However, many tables online neglect the accessibility requirements for people who rely on screen readers, such as people who are blind or have low vision (BLV). First, we consolidated guidelines to understand what makes a table inaccessible for BLV people. We conducted an interview study to understand the importance of tables and identify further design requirements for an accessible table. We built a tool that automatically detects HTML formatted tables online and transforms them into accessible tables. Our evaluative study demonstrates how our tool can help participants understand the table\u2019s structure and layout and support smooth navigation when the table is large and complex.",
    "call-number": "10.1145/3491102.3517469",
    "collection-number": "595",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517469",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Individuals with Disabilities & Assistive Technologies, Data Tables, Accessibility, Artifact or System, Empirical study that tells us about how people use a system",
    "number": "Article 595",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "What makes web data tables accessible? Insights and a tool for rendering accessible tables for people with visual impairments",
    "URL": "https://doi.org/10.1145/3491102.3517469"
  },
  {
    "id": "10.1145/3491102.3517635",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Cheuk Yin Phipson"
      },
      {
        "family": "Zhang",
        "given": "Zhuohao"
      },
      {
        "family": "Herskovitz",
        "given": "Jaylin"
      },
      {
        "family": "Seo",
        "given": "JooYoung"
      },
      {
        "family": "Guo",
        "given": "Anhong"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Collaborative document editing tools are widely used in professional and academic workplaces. While these tools provide basic accessibility support, it is challenging for blind users to gain collaboration awareness that sighted people can easily obtain using visual cues (e.g., who is editing where and what). Through a series of co-design sessions with a blind coauthor, we identified the current practices and challenges in collaborative editing, and iteratively designed CollabAlly, a system that makes collaboration awareness in document editing accessible to blind users. CollabAlly extracts collaborator, comment, and text-change information and their context from a document and presents them in a dialog box to provide easy access and navigation. CollabAlly uses earcons to communicate background events unobtrusively, voice fonts to differentiate collaborators, and spatial audio to convey the location of document activity. In a study with 11 blind participants, we demonstrate that CollabAlly provides improved access to collaboration awareness by centralizing scattered information, sonifying visual information, and simplifying complex operations.",
    "call-number": "10.1145/3491102.3517635",
    "collection-number": "596",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517635",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Blind, voice font, earcon, accessibility, spatial audio, screen reader, visual impairment, collaboration awareness, Collaborative writing",
    "number": "Article 596",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CollabAlly: Accessible Collaboration Awareness in Document Editing",
    "URL": "https://doi.org/10.1145/3491102.3517635"
  },
  {
    "id": "10.1145/3491102.3517737",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Bressa",
        "given": "Nathalie"
      },
      {
        "family": "Vermeulen",
        "given": "Jo"
      },
      {
        "family": "Willett",
        "given": "Wesley"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We explore the design and utility of situated manual self-tracking visualizations on dedicated displays that integrate data tracking into existing practices and physical environments. Situating self-tracking tools in relevant locations is a promising approach to enable reflection on and awareness of data without needing to rely on sensorized tracking or personal devices. In both a long-term autobiographical design process and a co-design study with six participants, we rapidly prototyped and deployed 30 situated self-tracking applications over a ten month period. Grounded in the experience of designing and living with these trackers, we contribute findings on logging and data entry, the use of situated displays, and the visual design and customization of trackers. Our results demonstrate the potential of customizable dedicated self-tracking visualizations that are situated in relevant physical spaces, and suggest future research opportunities and new potential applications for situated visualizations.",
    "call-number": "10.1145/3491102.3517737",
    "collection-number": "597",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517737",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "situated visualization, self-tracking, personal data",
    "number": "Article 597",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Data Every Day: Designing and Living with Personal Situated Visualizations",
    "URL": "https://doi.org/10.1145/3491102.3517737"
  },
  {
    "id": "10.1145/3491102.3502078",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fu",
        "given": "Yu"
      },
      {
        "family": "Stasko",
        "given": "John"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Basketball writers and journalists report on the sport that millions of fans follow and love. However, the recent emergence of pervasive data about the sport and the growth of new forms of sports analytics is changing writers\u2019 jobs. While these writers seek to leverage the data and analytics to create engaging, data-driven stories, they typically lack the technical background to perform analytics or efficiently explore data. We investigated and analyzed the work and context of basketball writers, interviewed nine stakeholders to understand the challenges from a holistic view. Based on what we learned, we designed and constructed two interactive visualization systems that support rapid and in-depth sports data exploration and sense-making to enhance their articles and reporting. We deployed the systems during the recent NBA playoffs to gather initial feedback. This article describes the visualization design study we conducted, the resulting visualization systems, and what we learned to potentially help basketball writers in the future.",
    "call-number": "10.1145/3491102.3502078",
    "collection-number": "598",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502078",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "user interface, sports data visualization, data-driven journalism",
    "number": "Article 598",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting Data-Driven Basketball Journalism through Interactive Visualization",
    "URL": "https://doi.org/10.1145/3491102.3502078"
  },
  {
    "id": "10.1145/3491102.3517455",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Hyeok"
      },
      {
        "family": "Rossi",
        "given": "Ryan"
      },
      {
        "family": "Du",
        "given": "Fan"
      },
      {
        "family": "Koh",
        "given": "Eunyee"
      },
      {
        "family": "Guo",
        "given": "Shunan"
      },
      {
        "family": "Hullman",
        "given": "Jessica"
      },
      {
        "family": "Hoffswell",
        "given": "Jane"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Designing responsive visualizations can be cast as applying transformations to a source view to render it suitable for a different screen size. However, designing responsive visualizations is often tedious as authors must manually apply and reason about candidate transformations. We present Cicero, a declarative grammar for concisely specifying responsive visualization transformations which paves the way for more intelligent responsive visualization authoring tools. Cicero\u2019s flexible specifier syntax allows authors to select visualization elements to transform, independent of the source view\u2019s structure. Cicero encodes a concise set of actions to encode a diverse set of transformations in both desktop-first and mobile-first design processes. Authors can ultimately reuse design-agnostic transformations across different visualizations. To demonstrate the utility of Cicero, we develop a compiler to an extended version of Vega-Lite, and provide principles for our compiler. We further discuss the incorporation of Cicero into responsive visualization authoring tools, such as a design recommender.",
    "call-number": "10.1145/3491102.3517455",
    "collection-number": "600",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517455",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Visualization, responsive visualization, grammar",
    "number": "Article 600",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Cicero: A Declarative Grammar for Responsive Visualization",
    "URL": "https://doi.org/10.1145/3491102.3517455"
  },
  {
    "id": "10.1145/3491102.3501845",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Latulipe",
        "given": "Celine"
      },
      {
        "family": "Dsouza",
        "given": "Ronnie"
      },
      {
        "family": "Cumbers",
        "given": "Murray"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present results of a survey (n=42) investigating how close others (family members, friends, or other community members) assist older adults with banking tasks in Canada. We asked what types of banking tasks they help with and what modalities they used. Our results show many close others help older adults by leveraging online banking, and this is especially true when the close other is an older adult themselves. We also found that close others who help older adults via online banking often know the online banking credentials for the older adults they assist, which presents privacy and security issues and could open the door to financial exploitation. Our results demonstrate the need for the design of online banking mechanisms that more explicitly acknowledge the nuanced and temporally changing role of close others in helping older adults with banking.",
    "call-number": "10.1145/3491102.3501845",
    "collection-number": "601",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501845",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "banking, security, close others, older adults, aging, proxy account, privacy, caregivers, finance, passwords",
    "number": "Article 601",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Unofficial Proxies: How Close Others Help Older Adults with Banking",
    "URL": "https://doi.org/10.1145/3491102.3501845"
  },
  {
    "id": "10.1145/3491102.3502011",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dai",
        "given": "Jiamin"
      },
      {
        "family": "Moffatt",
        "given": "Karyn"
      },
      {
        "family": "Lin",
        "given": "Jinglan"
      },
      {
        "family": "Truong",
        "given": "Khai"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "AAC research has traditionally focused on input speed, leaving higher-level communication goals such as relational maintenance under-explored. Through semi-structured interviews with AAC users with motor and speech impairments and their primary family caregivers, we offer a nuanced understanding of AAC\u2019s roles in maintaining close relationships. Our inductive analysis reveals emerging themes including how AAC users and their partners share the physical and mental workload to overcome communication barriers in complex situations. Our deductive application of the Relational Maintenance Strategies framework exposes the efforts made and the challenges encountered in managing social engagements, providing mutual support, and decoding implicit expressions. From these insights, we propose novel research directions for better supporting maintenance strategies and social purposes of communication, including notably mediating relational tensions, leveraging empowerment and identity, and supporting interactions for social closeness and etiquette, which we hope will motivate discussion in HCI communities on expanding AAC research space.",
    "call-number": "10.1145/3491102.3502011",
    "collection-number": "602",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502011",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "relationship maintenance, ALS, accessibility, Augmentative and alternative communication (AAC), cerebral palsy, assistive technology",
    "number": "Article 602",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing for Relational Maintenance: New Directions for AAC Research",
    "URL": "https://doi.org/10.1145/3491102.3502011"
  },
  {
    "id": "10.1145/3491102.3501882",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Mack",
        "given": "Kelly"
      },
      {
        "family": "McDonnell",
        "given": "Emma"
      },
      {
        "family": "Potluri",
        "given": "Venkatesh"
      },
      {
        "family": "Xu",
        "given": "Maggie"
      },
      {
        "family": "Zabala",
        "given": "Jailyn"
      },
      {
        "family": "Bigham",
        "given": "Jeffrey"
      },
      {
        "family": "Mankoff",
        "given": "Jennifer"
      },
      {
        "family": "Bennett",
        "given": "Cynthia"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Methods are fundamental to doing research and can directly impact who is included in scientific advances. Given accessibility research's increasing popularity and pervasive barriers to conducting and participating in research experienced by people with disabilities, it is critical to ask how methods are made accessible. Yet papers rarely describe their methods in detail. This paper reports on 17 interviews with accessibility experts about how they include both facilitators and participants with disabilities in popular user research methods. Our findings offer strategies for anticipating access needs while remaining flexible and responsive to unexpected access barriers. We emphasize the importance of considering accessibility at all stages of the research process, and contextualize access work in recent disability and accessibility literature. We explore how technology or processes could reflect a norm of accessibility. Finally, we discuss how various needs intersect and conflict and offer a practical structure for planning accessible research.",
    "call-number": "10.1145/3491102.3501882",
    "collection-number": "603",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501882",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human-Centered methods, user research, disability, accessibility",
    "number": "Article 603",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Anticipate and Adjust: Cultivating Access in Human-Centered Methods",
    "URL": "https://doi.org/10.1145/3491102.3501882"
  },
  {
    "id": "10.1145/3491102.3501995",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Harrington",
        "given": "Christina N."
      },
      {
        "family": "Garg",
        "given": "Radhika"
      },
      {
        "family": "Woodward",
        "given": "Amanda"
      },
      {
        "family": "Williams",
        "given": "Dimitri"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Black older adults from lower socioeconomic environments are often neglected in health technology interventions. Voice assistants have a potential to make healthcare more accessible to older adults, yet, little is known about their experiences with this type of health information seeking, especially Black older adults. Through a three-phase exploratory study, we explored health information seeking with 30 Black older adults in lower-income environments to understand how they ask health-related questions, and their perceptions of the Google Home being used for that purpose. Through our analysis, we identified the health information needs and common search topics, and discussed the communication breakdowns and types of repair performed. We contribute an understanding of cultural code-switching that has to be done by these older adults when interacting with voice assistants, and the importance of such phenomenon when designing for historically excluded groups.",
    "call-number": "10.1145/3491102.3501995",
    "collection-number": "604",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501995",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "speech recognition, identity, cultural relevance, voice assistants, older adults, code-switching, health information seeking, race",
    "number": "Article 604",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIt\u2019s Kind of Like Code-Switching\u201d: Black Older Adults\u2019 Experiences with a Voice Assistant for Health Information Seeking",
    "URL": "https://doi.org/10.1145/3491102.3501995"
  },
  {
    "id": "10.1145/3491102.3517568",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Garcia",
        "given": "J\u00e9r\u00e9mie"
      },
      {
        "family": "Brock",
        "given": "Anke M."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Flying drones is an increasingly popular activity. However, it is challenging due to the required perceptual and motor skills for following and stabilizing the drone, especially for people with special needs. This paper describes CandyFly, an application supporting people with diverse sensory, cognitive and motor impairments to pilot drones. We observed an existing accessible piloting workshop and evaluated CandyFly during eight additional workshops over three and a half years using a research-through-design process and ability-based design methods. We identified users\u2019 needs, formulated requirements and explored adaptive interactions such as using pressure-sensitive keys, adjusting controls to the pilots\u2019 range of motion, or limiting the drone\u2019s degrees of freedom to cope with a broad range of disabilities. Our results show that the pilots and their caregivers enjoyed flying and emphasized CandyFly\u2019s ability to be tailored to specific needs. Our findings offer a framework for designing adaptable systems and can support the design of future assistive and recreational systems.",
    "call-number": "10.1145/3491102.3517568",
    "collection-number": "605",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517568",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Automation, Accessibility, Drones, Piloting, Human-Drone Interaction, Unmanned Aerial Vehicles",
    "number": "Article 605",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CandyFly: Bringing fun to drone pilots with disabilities through adapted and adaptable interactions",
    "URL": "https://doi.org/10.1145/3491102.3517568"
  },
  {
    "id": "10.1145/3491102.3502017",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Neate",
        "given": "Timothy"
      },
      {
        "family": "Kladouchou",
        "given": "Vasiliki"
      },
      {
        "family": "Wilson",
        "given": "Stephanie"
      },
      {
        "family": "Shams",
        "given": "Shehzmani"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "People with language impairments, such as aphasia, use a range of total communication strategies. These go beyond spoken language to include non-verbal utterances, props and gestures. The uptake of videoconferencing platforms necessitated by the Covid-19 pandemic means that people with aphasia now use these communication strategies online. However, no data exists on the impact of videoconferencing on communication for this population. Working with an aphasia charity that moved its conversation support sessions online, we investigated the experience of communication via a videoconferencing platform. We report a study which investigated this through: 1) observations of online conversation support sessions; 2) interviews with speech and language therapists and volunteers; and 3) interviews with people with aphasia. Our findings reveal the unique and creative ways that the charity and its members with aphasia adapted their communication to videoconferencing. We unpack specific, novel challenges relating to total communication via videoconferencing and the related impacts on social and privacy issues.",
    "call-number": "10.1145/3491102.3502017",
    "collection-number": "606",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502017",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Videoconferencing, Covid-19 Pandemic, Accessibility, Aphasia, Total Communication",
    "number": "Article 606",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cJust Not Together\u201d: The Experience of Videoconferencing for People with Aphasia during the Covid-19 Pandemic",
    "URL": "https://doi.org/10.1145/3491102.3502017"
  },
  {
    "id": "10.1145/3491102.3502081",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Huh",
        "given": "Mina"
      },
      {
        "family": "Lee",
        "given": "YunJung"
      },
      {
        "family": "Choi",
        "given": "Dasom"
      },
      {
        "family": "Kim",
        "given": "Haesoo"
      },
      {
        "family": "Oh",
        "given": "Uran"
      },
      {
        "family": "Kim",
        "given": "Juho"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Webtoon is a type of digital comics read online where readers can leave comments to share their thoughts on the story. While it has experienced a surge in popularity internationally, people with visual impairments cannot enjoy webtoon with the lack of an accessible format. While traditional image description practices can be adopted, resulting descriptions cannot preserve webtoons\u2019 unique values such as control over the reading pace and social engagement through comments. To improve the webtoon reading experience for BLV users, we propose Cocomix, an interactive webtoon reader that leverages comments into the design of novel webtoon interactions. Since comments can identify story highlights and provide additional context, we designed a system that provides 1) comments-based adaptive descriptions with selective access to details and 2) panel-anchored comments for easy access to relevant descriptive comments. Our evaluation (N=12) showed that Cocomix users could adapt the description for various needs and better utilize comments.",
    "call-number": "10.1145/3491102.3502081",
    "collection-number": "607",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502081",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Comments, Accessibility, Webtoons, Image description, Digital comics",
    "number": "Article 607",
    "number-of-pages": "18",
    "page": "1\u201318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Cocomix: Utilizing Comments to Improve Non-Visual Webtoon Accessibility",
    "URL": "https://doi.org/10.1145/3491102.3502081"
  },
  {
    "id": "10.1145/3491102.3501958",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lee",
        "given": "Hae-Na"
      },
      {
        "family": "Ashok",
        "given": "Vikas"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Most people who are blind interact with social media content with the assistance of a screen reader, a software that converts text to speech. However, the language used in social media is well-known to contain several informal out-of-vocabulary words (e.g., abbreviations, wordplays, slang), many of which do not have corresponding standard pronunciations. The narration behavior of screen readers for such out-of-vocabulary words and the corresponding impact on the social media experience of blind screen reader users are still uncharted research territories. Therefore we seek to plug this knowledge gap by examining how current popular screen readers narrate different types of out-of-vocabulary words found on Twitter, and also, how the presence of such words in tweets influences the interaction behavior and comprehension of blind screen reader users. Our investigation showed that screen readers rarely autocorrect out-of-vocabulary words, and moreover they do not always exhibit ideal behavior for certain prolific types of out-of-vocabulary words such as acronyms and initialisms. We also observed that blind users often rely on tedious and taxing workarounds to comprehend actual meanings of out-of-vocabulary words. Informed by the observations, we finally discuss methods that can potentially reduce this interaction burden for blind users on social media.",
    "call-number": "10.1145/3491102.3501958",
    "collection-number": "608",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501958",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "OOV Word, Out-of-Vocabulary Word, Blind, Social Media, User Experience, Twitter, Visual Impairment, Screen Reader",
    "number": "Article 608",
    "number-of-pages": "20",
    "page": "1\u201320",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Impact of Out-of-Vocabulary Words on the Twitter Experience of Blind Users",
    "URL": "https://doi.org/10.1145/3491102.3501958"
  },
  {
    "id": "10.1145/3491102.3517488",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rui Xia Ang",
        "given": "Jazz"
      },
      {
        "family": "Liu",
        "given": "Ping"
      },
      {
        "family": "McDonnell",
        "given": "Emma"
      },
      {
        "family": "Coppola",
        "given": "Sarah"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "As video conferencing (VC) has become increasingly necessary for many aspects of daily life, many d/Deaf and hard of hearing people, particularly those who communicate via sign language (signers), face distinct accessibility barriers. To better understand the unique requirements for participating in VC using a visual-gestural language, such as ASL, and to identify practical design considerations for signer-inclusive videoconferencing, we conducted 12 interviews and four co-design sessions with a total of eight d/Deaf signers and eight ASL interpreters. We found that participants\u2019 access needs regarding consuming information (e.g., visual clarity of signs), communicating (e.g., getting attention of others), and collaborating (e.g., working with interpreter teams) are not well-met on existing VC platforms. We share novel insights into attending and conducting signer-accessible video conferences, outline considerations for future VC design, and provide guidelines for conducting remote research with d/Deaf signers.",
    "call-number": "10.1145/3491102.3517488",
    "collection-number": "609",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517488",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sign language interpreting, American Sign Language, d/Deaf and hard-of-hearing, accessible groupware, accessible research methods, accessibility and inclusive design",
    "number": "Article 609",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cIn this online environment, we're limited\u201d: Exploring Inclusive Video Conferencing Design for Signers",
    "URL": "https://doi.org/10.1145/3491102.3517488"
  },
  {
    "id": "10.1145/3491102.3517641",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Drey",
        "given": "Tobias"
      },
      {
        "family": "Albus",
        "given": "Patrick"
      },
      {
        "family": "der Kinderen",
        "given": "Simon"
      },
      {
        "family": "Milo",
        "given": "Maximilian"
      },
      {
        "family": "Segschneider",
        "given": "Thilo"
      },
      {
        "family": "Chanzab",
        "given": "Linda"
      },
      {
        "family": "Rietzler",
        "given": "Michael"
      },
      {
        "family": "Seufert",
        "given": "Tina"
      },
      {
        "family": "Rukzio",
        "given": "Enrico"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Pair-learning is beneficial for learning outcome, motivation, and social presence, and so is virtual reality (VR) by increasing immersion, engagement, motivation, and interest of students. Nevertheless, there is a research gap if the benefits of pair-learning and VR can be combined. Furthermore, it is not clear which influence it has if only one or both peers use VR. To investigate these aspects, we implemented two types of VR pair-learning systems, a symmetric system with both peers using VR and an asymmetric system with one using a tablet. In a user study (N=46), the symmetric system statistically significantly provided higher presence, immersion, player experience, and lower intrinsic cognitive load, which are all important for learning. Symmetric and asymmetric systems performed equally well regarding learning outcome, highlighting that both are valuable learning systems. We used these findings to define guidelines on how to design co-located VR pair-learning applications, including characteristics for symmetric and asymmetric systems.",
    "call-number": "10.1145/3491102.3517641",
    "collection-number": "610",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517641",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "virtual reality, signaling, collaborative learning, pair-learning, symmetric and asymmetric system",
    "number": "Article 610",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards Collaborative Learning in Virtual Reality: A Comparison of Co-Located Symmetric and Asymmetric Pair-Learning",
    "URL": "https://doi.org/10.1145/3491102.3517641"
  },
  {
    "id": "10.1145/3491102.3501821",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Gruenefeld",
        "given": "Uwe"
      },
      {
        "family": "Auda",
        "given": "Jonas"
      },
      {
        "family": "Mathis",
        "given": "Florian"
      },
      {
        "family": "Schneegass",
        "given": "Stefan"
      },
      {
        "family": "Khamis",
        "given": "Mohamed"
      },
      {
        "family": "Gugenheimer",
        "given": "Jan"
      },
      {
        "family": "Mayer",
        "given": "Sven"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Cross-reality systems empower users to transition along the reality-virtuality continuum or collaborate with others experiencing different manifestations of it. However, prototyping these systems is challenging, as it requires sophisticated technical skills, time, and often expensive hardware. We present VRception, a concept and toolkit for quick and easy prototyping of cross-reality systems. By simulating all levels of the reality-virtuality continuum entirely in Virtual Reality, our concept overcomes the asynchronicity of realities, eliminating technical obstacles. Our VRception Toolkit leverages this concept to allow rapid prototyping of cross-reality systems and easy remixing of elements from all continuum levels. We replicated six cross-reality papers using our toolkit and presented them to their authors. Interviews with them revealed that our toolkit sufficiently replicates their core functionalities and allows quick iterations. Additionally, remote participants used our toolkit in pairs to collaboratively implement prototypes in about eight minutes that they would have otherwise expected to take days.",
    "call-number": "10.1145/3491102.3501821",
    "collection-number": "611",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501821",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Cross-Reality Systems, Augmented Reality, Prototyping, Transitional Interfaces, Virtual Reality",
    "number": "Article 611",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "VRception: Rapid Prototyping of Cross-Reality Systems in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3501821"
  },
  {
    "id": "10.1145/3491102.3517728",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Tseng",
        "given": "Wen-Jie"
      },
      {
        "family": "Bonnail",
        "given": "Elise"
      },
      {
        "family": "McGill",
        "given": "Mark"
      },
      {
        "family": "Khamis",
        "given": "Mohamed"
      },
      {
        "family": "Lecolinet",
        "given": "Eric"
      },
      {
        "family": "Huron",
        "given": "Samuel"
      },
      {
        "family": "Gugenheimer",
        "given": "Jan"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "\u201cVirtual-Physical Perceptual Manipulations\u201d (VPPMs) such as redirected walking and haptics expand the user\u2019s capacity to interact with Virtual Reality (VR) beyond what would ordinarily physically be possible. VPPMs leverage knowledge of the limits of human perception to effect changes in the user\u2019s physical movements, becoming able to (perceptibly and imperceptibly) nudge their physical actions to enhance interactivity in VR. We explore the risks posed by the malicious use of VPPMs. First, we define, conceptualize and demonstrate the existence of VPPMs. Next, using speculative design workshops, we explore and characterize the threats/risks posed, proposing mitigations and preventative recommendations against the malicious use of VPPMs. Finally, we implement two sample applications to demonstrate how existing VPPMs could be trivially subverted to create the potential for physical harm. This paper aims to raise awareness that the current way we apply and publish VPPMs can lead to malicious exploits of our perceptual vulnerabilities.",
    "call-number": "10.1145/3491102.3517728",
    "collection-number": "612",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517728",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "VPPM, virtual-physical perceptual manipulation, physical harm, VR security",
    "number": "Article 612",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Dark Side of Perceptual Manipulations in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517728"
  },
  {
    "id": "10.1145/3491102.3517548",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Masnadi",
        "given": "Sina"
      },
      {
        "family": "Pfeil",
        "given": "Kevin"
      },
      {
        "family": "Sera-Josef",
        "given": "Jose-Valentin T"
      },
      {
        "family": "LaViola",
        "given": "Joseph"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We performed a mixed-design study with 56 participants to compare the effect of horizontal FOV (hfov) and vertical FOV (vfov) on egocentric distance perception in four different realistic virtual environments (VEs). We also compared VE attributes of indoor/outdoor and cluttered/uncluttered. The participants blind-walked towards four different targets at 3m, 4m, 5m, and 6m distance while wearing a backpack computer and a wide FOV head-mounted display (HMD). The combinations of 165\u00b0, 110\u00b0 and 45\u00b0 hfovs, and 110\u00b0 and 35\u00b0 vfovs was simulated in the same HMD. The results indicated more accurate distance judgement with larger hfov with no significant effect of vfov. More accurate distance judgement in indoor VEs compared to outdoor VEs was observed. Also, participants judged distances more accurately in cluttered environments versus uncluttered environments. These results highlight that the environment is important in distance-critical VR applications and wider hfov should be considered for an improved distance judgment.",
    "call-number": "10.1145/3491102.3517548",
    "collection-number": "613",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517548",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "outdoor, VR, virtual reality, field of view, vertical FOV, horizontal FOV, clutter, virtual environment, indoor, FOV, distance perception",
    "number": "Article 613",
    "number-of-pages": "10",
    "page": "1\u201310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Effects of Field of View on Egocentric Distance Perception in Virtual Reality",
    "URL": "https://doi.org/10.1145/3491102.3517548"
  },
  {
    "id": "10.1145/3491102.3517539",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Jung",
        "given": "Heekyoung"
      },
      {
        "family": "Cho",
        "given": "Sookyung"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The computer as a creative medium has largely influenced how we make, use, and share images. This study investigates how similarly or distinctively human designers and the computers see (i.e., process visual information from the activity of seeing) in creative practice. Based on the review of the perspectives relevant to seeing (e.g., visual experience, visual creativity, visual computing), we practiced a visual inquiry by marking how we see photographic images in comparison to what computer vision processes from the same images. Taking a researcher-introspective approach, two authors reflectively analyzed the processes and outcomes of the inquiry. The findings revealed that during the creative practice, the activity of seeing is a meaning-making process that is guided, shifted, and diffracted through visual conversations between visible and invisible qualities suggested by compositional rules and computer vision. We discuss potentials of computational visual intelligence as creative agents and conclude with methodological and practical implications.",
    "call-number": "10.1145/3491102.3517539",
    "collection-number": "614",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517539",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Artificial visual intelligence, Meaning-making, Creative agents, Seeing",
    "number": "Article 614",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Methodological Reflections on Ways of Seeing",
    "URL": "https://doi.org/10.1145/3491102.3517539"
  },
  {
    "id": "10.1145/3491102.3517633",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Ku",
        "given": "Pin-Sung"
      },
      {
        "family": "Huang",
        "given": "Kunpeng"
      },
      {
        "family": "Kao",
        "given": "Cindy Hsin-Liu"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "We present Patch-O, a novel deformable interface devised as a woven patch that enables diverse movement-based interactions adaptive to garments or on-skin wearing. Patch-O interfaces are uniquely detachable and relocatable soft actuation units that can be sewn or attached to clothing or skin at various locations. To optimize the morphing effect while preserving a slim form factor, we introduce a construction approach that integrates actuators at a structural level and varies the texture and stiffness of the woven substrate locally. We implement three basic actuation primitives, including bending, expanding, and shrinking, and experiment with aggregation parameters to exhaustively extend the design space. A final workshop study inviting textile practitioners to create personalized designs of Patch-O provides insights into the expressiveness of the approach for wearable interactions. We conclude with three applications inspired by users\u2019 designs and showcase the aesthetic and functional usages enabled by the deformable woven patches.",
    "call-number": "10.1145/3491102.3517633",
    "collection-number": "615",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517633",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Fashion/Clothing, Wearable Computers, Fabrication",
    "number": "Article 615",
    "number-of-pages": "12",
    "page": "1\u201312",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Patch-O: Deformable Woven Patches for On-body Actuation",
    "URL": "https://doi.org/10.1145/3491102.3517633"
  },
  {
    "id": "10.1145/3491102.3501911",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Raphael"
      },
      {
        "family": "Linehan",
        "given": "Conor"
      },
      {
        "family": "Pschetz",
        "given": "Larissa"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "DNA-based digital data storage technology is hailed as a potential solution for the issues around exponential global data production. However, while the technology continues to strive towards its full commercialization, there is a lack of discourse on how it could be applied to facilitate interactions that are meaningful, ethical, and socially sustainable. As an approach to address this gap, we hosted a series of online workshops, soliciting 15 participants to engage in grounded speculations on plausible futures of DNA data storage. Themes drawn from the resulting imaginaries and discussions were situated within a selection of existing HCI literature, to generate an initial set of design opportunities and challenges for DNA data storage. Early analysis suggests that the system could be designed to 1) facilitate meaningful interactions that are intangible and molecular, and 2) foster better human relationship with more-than-human entities. Furthermore, we highlight the imperative for cross-disciplinary collaborations and pedagogy, to ensure fair and high quality access to the technology.",
    "call-number": "10.1145/3491102.3501911",
    "collection-number": "616",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501911",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "futures, DNA, archives, bio-design, bio-digital, biological-HCI, data",
    "number": "Article 616",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Navigating Imaginaries of DNA-Based Digital Data Storage",
    "URL": "https://doi.org/10.1145/3491102.3501911"
  },
  {
    "id": "10.1145/3491102.3517617",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "H. Tan",
        "given": "Neilly"
      },
      {
        "family": "Y. Wong",
        "given": "Richmond"
      },
      {
        "family": "Desjardins",
        "given": "Audrey"
      },
      {
        "family": "A. Munson",
        "given": "Sean"
      },
      {
        "family": "Pierce",
        "given": "James"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The increased adoption of smart home cameras (SHCs) foregrounds issues of surveillance, power, and privacy in homes and neighborhoods. However, questions remain about how people are currently using these devices to monitor and surveil, what the benefits and limitations are for users, and what privacy and security tensions arise between primary users and other stakeholders. We present an empirical study with 14 SHC users to understand how these devices are used and integrated within everyday life. Based on semi-structured qualitative interviews, we investigate users\u2019 motivations, practices, privacy concerns, and social negotiations. Our findings highlight the SHC as a perceptually powerful and spatially sensitive device that enables a variety of surveillant uses outside of basic home security\u2014from formally surveilling domestic workers, to casually spying on neighbors, to capturing memories. We categorize surveillant SHC uses, clarify distinctions between primary and non-primary users, and highlight under-considered design directions for addressing power imbalances among primary and non-primary users.",
    "call-number": "10.1145/3491102.3517617",
    "collection-number": "617",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517617",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "design, surveillance, personal data, tracking, privacy, Internet of Things (IoT), smart cameras",
    "number": "Article 617",
    "number-of-pages": "25",
    "page": "1\u201325",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Monitoring Pets, Deterring Intruders, and Casually Spying on Neighbors: Everyday Uses of Smart Home Cameras",
    "URL": "https://doi.org/10.1145/3491102.3517617"
  },
  {
    "id": "10.1145/3491102.3517555",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Maekawa",
        "given": "Azumi"
      },
      {
        "family": "Saito",
        "given": "Hiroto"
      },
      {
        "family": "Uriu",
        "given": "Daisuke"
      },
      {
        "family": "Kasahara",
        "given": "Shunichi"
      },
      {
        "family": "Inami",
        "given": "Masahiko"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Technological advancement has opened up opportunities for new sports and physical activities. We introduce a concept called machine-mediated teaming, in which a human and a surrogate machine form a team to participate in physical sports games. To understand the experience of machine-mediated teaming and the guidelines for designing the system to achieve the concept, we built a case study system based on tug-of-war. Our system is a sports game played by two against two. One team consists of a player who actually pulls the rope and another player who participates in the physical game by controlling the machine\u2019s actuators. We conducted user studies using this system to investigate the sport experience in this form and to reveal insights to inform future research on machine-mediated teaming. Based on the data obtained from the user studies, we clarified three perspectives, machine stamina, action space, and explicit feedback, that should be considered when designing future machine-mediated teaming systems. The research presented in this paper offers a first step towards exploring how humans and machines can coexist in highly dynamic physical interactions.",
    "call-number": "10.1145/3491102.3517555",
    "collection-number": "618",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517555",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "sports design, physical interaction, augmentation, human-machine collaboration",
    "number": "Article 618",
    "number-of-pages": "11",
    "page": "1\u201311",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Machine-Mediated Teaming: Mixture of Human and Machine in Physical Gaming Experience",
    "URL": "https://doi.org/10.1145/3491102.3517555"
  },
  {
    "id": "10.1145/3491102.3502125",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Hammann",
        "given": "Sven"
      },
      {
        "family": "Crabb",
        "given": "Michael"
      },
      {
        "family": "Radomirovic",
        "given": "Sasa"
      },
      {
        "family": "Sasse",
        "given": "Ralf"
      },
      {
        "family": "Basin",
        "given": "David"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "A person\u2019s online security setup is tied to the security of their individual accounts. Some accounts are particularly critical as they provide access to other online services. For example, an email account can be used for external account recovery or to assist with single-sign-on. The connections between accounts are specific to each user\u2019s setup and create unique security problems that are difficult to remedy by following generic security advice. In this paper, we develop a method to gather and analyze users\u2019 online accounts systematically. We demonstrate this in a user study with 20 participants and obtain detailed insights on how users\u2019 personal setup choices and behaviors affect their overall account security. We discuss concrete usability and privacy concerns that prevented our participants from improving their account security. Based on our findings, we provide recommendations for service providers and security experts to increase the adoption of security best practices.",
    "call-number": "10.1145/3491102.3502125",
    "collection-number": "620",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502125",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "security setup, user interviews., Account Graph",
    "number": "Article 620",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cI\u2019m Surprised So Much Is Connected\u201d",
    "URL": "https://doi.org/10.1145/3491102.3502125"
  },
  {
    "id": "10.1145/3491102.3501985",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Habib",
        "given": "Hana"
      },
      {
        "family": "Li",
        "given": "Megan"
      },
      {
        "family": "Young",
        "given": "Ellie"
      },
      {
        "family": "Cranor",
        "given": "Lorrie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Many websites have added cookie consent interfaces to meet regulatory consent requirements. While prior work has demonstrated that they often use dark patterns\u00a0\u2014\u00a0design techniques that lead users to less privacy-protective options\u00a0\u2014\u00a0other usability aspects of these interfaces have been less explored. This study contributes a comprehensive, two-stage usability assessment of cookie consent interfaces. We first inspected 191 consent interfaces against five dark pattern heuristics and identified design choices that may impact usability. We then conducted a 1,109-participant online between-subjects experiment exploring the usability impact of seven design parameters. Participants were exposed to one of 12 consent interface variants during a shopping task on a prototype e-commerce website and answered a survey about their experience. Our findings suggest that a fully-blocking consent interface with in-line cookie options accompanied by a persistent button enabling users to later change their consent decision best meets several design objectives.",
    "call-number": "10.1145/3491102.3501985",
    "collection-number": "621",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501985",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "GDPR, privacy notice, privacy choice, cookie consent",
    "number": "Article 621",
    "number-of-pages": "27",
    "page": "1\u201327",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\u201cOkay, whatever\u201d: An Evaluation of Cookie Consent Interfaces",
    "URL": "https://doi.org/10.1145/3491102.3501985"
  },
  {
    "id": "10.1145/3491102.3501869",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Dooley",
        "given": "Samuel"
      },
      {
        "family": "Turjeman",
        "given": "Dana"
      },
      {
        "family": "Dickerson",
        "given": "John P"
      },
      {
        "family": "Redmiles",
        "given": "Elissa M."
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "COVID-19 exposure-notification apps have struggled to gain adoption. Existing literature posits as potential causes of this low adoption: privacy concerns, insufficient data transparency, and the type of appeal \u2013 collective- vs. individual-good \u2013 used to frame the app. As policy guidance suggests using tailored advertising to evaluate the effects of these factors, we present the first field study of COVID-19 contact tracing apps with a randomized, control trial of 14 different advertisements for CovidDefense, Louisiana\u2019s COVID-19 exposure-notification app. We find that all three hypothesized factors \u2013 privacy, data transparency, and appeals framing \u2013 relate to app adoption, even when controlling for age, gender, and community density. Our results offer (1) the first field evidence supporting the use of collective-good appeals, (2) nuanced findings regarding the efficacy of data and privacy transparency, the effects of which are moderated by appeal framing and potential users\u2019 demographics, and (3) field-evidence-based guidance for future efforts to encourage pro-social health technology adoption.",
    "call-number": "10.1145/3491102.3501869",
    "collection-number": "622",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501869",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Pro-Social, Transparency, Field Study, Privacy, COVID-19",
    "number": "Article 622",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Field Evidence of the Effects of Privacy, Data Transparency, and Pro-social Appeals on COVID-19 App Attractiveness",
    "URL": "https://doi.org/10.1145/3491102.3501869"
  },
  {
    "id": "10.1145/3491102.3502009",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Krsek",
        "given": "Isadora"
      },
      {
        "family": "Wenzel",
        "given": "Kimi"
      },
      {
        "family": "Das",
        "given": "Sauvik"
      },
      {
        "family": "Hong",
        "given": "Jason I."
      },
      {
        "family": "Dabbish",
        "given": "Laura"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "User adoption of security and privacy (S&P) best practices remains low, despite sustained efforts by researchers and practitioners. Social influence is a proven method for guiding user S&P behavior, though most work has focused on studying peer influence, which is only possible with a known social graph. In a study of 104 Facebook users, we instead demonstrate that crowdsourced S&P suggestions are significantly influential. We also tested how reflective writing affected participants\u2019 S&P decisions, with and without suggestions. With reflective writing, participants were less likely to accept suggestions \u2014 both social and Facebook default suggestions. Of particular note, when reflective writing participants were shown the Facebook default suggestion, they not only rejected it but also (unknowingly) configured their settings in accordance with expert recommendations. Our work suggests that both non-personal social influence and reflective writing can positively influence users\u2019 S&P decisions, but have negative interactions.",
    "call-number": "10.1145/3491102.3502009",
    "collection-number": "623",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502009",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Reflective Writing, Individual Differences, Privacy, Social Cybersecurity, Social Influence, Privacy Behaviors, Qualitative Methods, Social Proof, Surveys, Quantitative Methods, Authority, Decision Making",
    "number": "Article 623",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "To Self-Persuade or be Persuaded: Examining Interventions for Users\u2019 Privacy Setting Selection",
    "URL": "https://doi.org/10.1145/3491102.3502009"
  },
  {
    "id": "10.1145/3491102.3517720",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kitkowska",
        "given": "Agnieszka"
      },
      {
        "family": "H\u00f6gberg",
        "given": "Johan"
      },
      {
        "family": "W\u00e4stlund",
        "given": "Erik"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Too often, while interacting with online technologies, we blindly agree to services\u2019 terms and conditions (T&Cs). We often disregard their content\u2014believing it is not worth engaging with the long, hard-to-understand texts. The inconspicuous display of online T&Cs on the user interface (UI) adds to our lack of engagement. Nevertheless, certain information included in T&Cs could help us make optimal decisions. In this replication research, we investigate this issue in the purchasing context. We confirm and extend previous findings through an online experiment (N = 987), showing that differently presented T&Cs (icons, scroll, and cost-cue) compared to hyperlinked text affect whether people open them, becoming aware. We also show the effect of decision-making style on the relationship between awareness and satisfaction. We discuss the possible use of these findings to improve users\u2019 informed decisions. We also highlight problems that different designs may pose, potentially increasing the information gap between users and service providers.",
    "call-number": "10.1145/3491102.3517720",
    "collection-number": "624",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517720",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "terms & conditions, replication studies, online decision-making, UI design",
    "number": "Article 624",
    "number-of-pages": "22",
    "page": "1\u201322",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Online Terms and Conditions: Improving User Engagement, Awareness, and Satisfaction through UI Design",
    "URL": "https://doi.org/10.1145/3491102.3517720"
  },
  {
    "id": "10.1145/3491102.3502053",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Kim",
        "given": "Yea-Seul"
      },
      {
        "family": "Hofman",
        "given": "Jake M"
      },
      {
        "family": "Goldstein",
        "given": "Daniel G"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "How do people form impressions of effect size when reading scientific results? We present a series of studies on how people perceive treatment effectiveness when scientific results are summarized in various ways. We first show that a prevalent form of summarizing results\u2014presenting mean differences between conditions\u2014can lead to significant overestimation of treatment effectiveness, and that including confidence intervals can exacerbate the problem. We attempt to remedy potential misperceptions by displaying information about variability in individual outcomes in different formats: statements about variance, a quantitative measure of standardized effect size, and analogies that compare the treatment with more familiar effects (e.g., height differences by age). We find that all of these formats substantially reduce potential misperceptions and that analogies can be as helpful as more precise quantitative statements of standardized effect size. These findings can be applied by scientists in HCI and beyond to improve the communication of results to laypeople.",
    "call-number": "10.1145/3491102.3502053",
    "collection-number": "625",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502053",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "perception, visualization, statistics, effect size",
    "number": "Article 625",
    "number-of-pages": "14",
    "page": "1\u201314",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Putting scientific results in perspective: Improving the communication of standardized effect sizes",
    "URL": "https://doi.org/10.1145/3491102.3502053"
  },
  {
    "id": "10.1145/3491102.3517441",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "DeVos",
        "given": "Alicia"
      },
      {
        "family": "Dhabalia",
        "given": "Aditi"
      },
      {
        "family": "Shen",
        "given": "Hong"
      },
      {
        "family": "Holstein",
        "given": "Kenneth"
      },
      {
        "family": "Eslami",
        "given": "Motahhare"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Recent work in HCI suggests that users can be powerful in surfacing harmful algorithmic behaviors that formal auditing approaches fail to detect. However, it is not well understood how users are often able to be so effective, nor how we might support more effective user-driven auditing. To investigate, we conducted a series of think-aloud interviews, diary studies, and workshops, exploring how users find and make sense of harmful behaviors in algorithmic systems, both individually and collectively. Based on our findings, we present a process model capturing the dynamics of and influences on users\u2019 search and sensemaking behaviors. We find that 1) users\u2019 search strategies and interpretations are heavily guided by their personal experiences with and exposures to societal bias; and 2) collective sensemaking amongst multiple users is invaluable in user-driven algorithm audits. We offer directions for the design of future methods and tools that can better support user-driven auditing.",
    "call-number": "10.1145/3491102.3517441",
    "collection-number": "626",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517441",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Qualitative Methods, Algorithmic Harm, Fair Machine Learning, Search, Sensemaking, Collective Work, User-Driven Algorithm Auditing, Auditing Algorithms, Algorithmic Bias",
    "number": "Article 626",
    "number-of-pages": "19",
    "page": "1\u201319",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Toward User-Driven Algorithm Auditing: Investigating users\u2019 strategies for uncovering harmful algorithmic behavior",
    "URL": "https://doi.org/10.1145/3491102.3517441"
  },
  {
    "id": "10.1145/3491102.3501946",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Luo",
        "given": "Weizhou"
      },
      {
        "family": "Lehmann",
        "given": "Anke"
      },
      {
        "family": "Widengren",
        "given": "Hjalmar"
      },
      {
        "family": "Dachselt",
        "given": "Raimund"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Future offices are likely reshaped by Augmented Reality (AR) extending the display space while maintaining awareness of surroundings, and thus promise to support collaborative tasks such as brainstorming or sensemaking. However, it is unclear how physical surroundings and co-located collaboration influence the spatial organization of virtual content for sensemaking. Therefore, we conducted a study (N=28) to investigate the effect of office environments and work styles during a document classification task using AR with regard to content placement, layout strategies, and sensemaking workflows. Results show that participants require furniture, especially tables and whiteboards, to assist sensemaking and collaboration regardless of room settings, while generous free spaces (e.g., walls) are likely used when available. Moreover, collaborating participants tend to use furniture despite personal layout preferences. We identified different placement and layout strategies, as well as the transitions in-between. Finally, we propose design implications for future immersive sensemaking applications and beyond.",
    "call-number": "10.1145/3491102.3501946",
    "collection-number": "627",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501946",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Mixed Reality, collaborative sensemaking, qualitative user study, sensemaking, content organization, spatial layout, spatiality, Augmented Reality, affordance",
    "number": "Article 627",
    "number-of-pages": "16",
    "page": "1\u201316",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Where Should We Put It? Layout and Placement Strategies of Documents in Augmented Reality for Collaborative Sensemaking",
    "URL": "https://doi.org/10.1145/3491102.3501946"
  },
  {
    "id": "10.1145/3491102.3502068",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Rahman",
        "given": "Sajjadur"
      },
      {
        "family": "Kandogan",
        "given": "Eser"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Information extraction (IE) approaches often play a pivotal role in text analysis and require significant human intervention. Therefore, a deeper understanding of existing IE practices and related challenges from a human-in-the-loop perspective is warranted. In this work, we conducted semi-structured interviews in an industrial environment and analyzed the reported IE approaches and limitations. We observed that data science workers often follow an iterative task model consisting of information foraging and sensemaking loops across all the phases of an IE workflow. The task model is generalizable and captures diverse goals across these phases (e.g., data preparation, modeling, evaluation.) We found several limitations in both foraging (e.g., data exploration) and sensemaking (e.g., qualitative debugging) loops stemming from a lack of adherence to existing cognitive engineering principles. Moreover, we identified that due to the iterative nature of an IE workflow, the requirement of provenance is often implied but rarely supported by existing systems. Based on these findings, we discuss design implications for supporting IE workflows and future research directions.",
    "call-number": "10.1145/3491102.3502068",
    "collection-number": "628",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502068",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Human-AI collaboration, Information extraction, Data science workflows",
    "number": "Article 628",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Characterizing Practices, Limitations, and Opportunities Related to Text Information Extraction Workflows: A Human-in-the-loop Perspective",
    "URL": "https://doi.org/10.1145/3491102.3502068"
  },
  {
    "id": "10.1145/3491102.3517598",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Varghese",
        "given": "Delvin"
      },
      {
        "family": "Bartindale",
        "given": "Tom"
      },
      {
        "family": "Montague",
        "given": "Kyle"
      },
      {
        "family": "Baillie Smith",
        "given": "Matt"
      },
      {
        "family": "Olivier",
        "given": "Patrick"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Telephone-driven community forums have been a widely proposed solution to address the unreliable internet connectivity and large geographic scope that characterizes many international NGO contexts. Primarily, these applications support asynchronous activities, such as information portals or forums to access rural journalism, but opportunities for real-time experience sharing remain largely under-explored. In this paper, we explore the potential of such forums to support remote mentoring of NGO volunteers, a practice that requires synchronous, dialogical formats for experience sharing and peer discussion. We engaged 28 participants from a rural Indian NGO in the design of peer-mentoring sessions that leverage synchronous audio discussions, using the structure and format of traditional talk-show radio as a starting point. The participants favored an entertaining approach to mentoring and discussed the logistics required to achieve this within their resource constraints. We conclude with design implications for designing media-driven community engagement platforms and the ethical challenges around protecting marginalized community interests.",
    "call-number": "10.1145/3491102.3517598",
    "collection-number": "629",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517598",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "volunteers, rural development, global south, mentoring, ICTD, international development, HCI4D",
    "number": "Article 629",
    "number-of-pages": "13",
    "page": "1\u201313",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting Real-time Peer-Mentoring of Rural Volunteers",
    "URL": "https://doi.org/10.1145/3491102.3517598"
  },
  {
    "id": "10.1145/3491102.3517605",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Silva",
        "given": "Rafael M. L."
      },
      {
        "family": "Principe Cruz",
        "given": "Erica"
      },
      {
        "family": "Rosner",
        "given": "Daniela K."
      },
      {
        "family": "Kelly",
        "given": "Dayton"
      },
      {
        "family": "Monroy-Hern\u00e1ndez",
        "given": "Andr\u00e9s"
      },
      {
        "family": "Liu",
        "given": "Fannie"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "The rise of consumer augmented reality (AR) technology has opened up new possibilities for interventions intended to disrupt and subvert cultural conventions. From defacing corporate logos to erecting geofenced digital monuments, more and more people are creating AR experiences for social causes. We sought to understand this new form of activism, including why people use AR for these purposes, opportunities and challenges in using it, and how well it can support activist goals. We conducted semi-structured interviews with twenty people involved in projects that used AR for a social cause across six different countries. We found that AR can overcome physical world limitations of activism to convey immersive, multilayered narratives that aim to reveal invisible histories and perspectives. At the same time, people experienced challenges in creating, maintaining, and distributing their AR experiences to audiences. We discuss open questions and opportunities for creating AR tools and experiences for social change.",
    "call-number": "10.1145/3491102.3517605",
    "collection-number": "630",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517605",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "augmented reality, activism, social change",
    "number": "Article 630",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding AR Activism: An Interview Study with Creators of Augmented Reality Experiences for Social Change",
    "URL": "https://doi.org/10.1145/3491102.3517605"
  },
  {
    "id": "10.1145/3491102.3517435",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Carros",
        "given": "Felix"
      },
      {
        "family": "Schwaninger",
        "given": "Isabel"
      },
      {
        "family": "Preussner",
        "given": "Adrian"
      },
      {
        "family": "Randall",
        "given": "Dave"
      },
      {
        "family": "Wieching",
        "given": "Rainer"
      },
      {
        "family": "Fitzpatrick",
        "given": "Geraldine"
      },
      {
        "family": "Wulf",
        "given": "Volker"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Research on social robots in care has often focused on either the care recipients or the technology itself, neglecting the care workers who, in and through their collaborative and coordinative practices, will need to work with the robots. To better understand these interactions with a social robot (Pepper), we undertook a 3 month long-term study within a care home to gain empirical insights into the way the robot was used. We observed how care workers learned to use the device, applied it to their daily work life, and encountered obstacles. Our findings show that the care workers used the robot regularly (1:07 hours/day) mostly in one-to-one interactions with residents. While the robot had a limited effect on reducing the workload of care workers, it had other positive effects, demonstrating the potential to enhance the quality of care.",
    "call-number": "10.1145/3491102.3517435",
    "collection-number": "631",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517435",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Social Robot, Robotic Support, Social Service, Long-term, Appropriation, Work Practices, Residential Care, Practice-based, CSCW, Participatory Design, Pandemic, Empirical Study, Humanoid, Usage Patterns, Covid-19, HRI, Nurse, Sustainable Technology Integration, Care Work, HCI, Care Robot, Empowerment",
    "number": "Article 631",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Care Workers Making Use of Robots: Results of a Three-Month Study on Human-Robot Interaction within a Care Home",
    "URL": "https://doi.org/10.1145/3491102.3517435"
  },
  {
    "id": "10.1145/3491102.3502008",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Sykownik",
        "given": "Philipp"
      },
      {
        "family": "Maloney",
        "given": "Divine"
      },
      {
        "family": "Freeman",
        "given": "Guo"
      },
      {
        "family": "Masuch",
        "given": "Maic"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Current Social VR literature provides limited insight on one of the most critical behaviors for developing and maintaining interpersonal relationships: self-disclosure. Therefore, we present an online survey (N = 126) investigating how users disclose personal information to each other in Social VR. Our results indicate that many participants see in Social VR access to authentic connections with others despite tending towards skepticism and privacy concerns. Most users disclose sexuality-related information, lifestyle preferences, and personal goals. In contrast, information that breaks anonymity, such as real names and more intimate aspects of oneself, are shared less commonly. Thereby, self-disclosure decisions depend on factors like the relationship to or age of disclosure recipients, the privacy of a virtual environment, the group size, or the activity context, and is driven by different goals, i.a., relational development or exploration of oneself. These insights advance the understanding of current Social VR users and their behavior by directing future research on self-disclosure-based relationship building in Social VR and outlying broader design implications for the future metaverse.",
    "call-number": "10.1145/3491102.3502008",
    "collection-number": "632",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502008",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "self-disclosure, online social interaction, social virtual reality",
    "number": "Article 632",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Something Personal from the Metaverse: Goals, Topics, and Contextual Factors of Self-Disclosure in Commercial Social VR",
    "URL": "https://doi.org/10.1145/3491102.3502008"
  },
  {
    "id": "10.1145/3491102.3502067",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Batmaz",
        "given": "Anil Ufuk"
      },
      {
        "family": "Barrera Machuca",
        "given": "Mayra Donaji"
      },
      {
        "family": "Sun",
        "given": "Junwei"
      },
      {
        "family": "Stuerzlinger",
        "given": "Wolfgang"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Previous work hypothesized that for Virtual Reality (VR) and Augmented Reality (AR) displays a mismatch between disparities and optical focus cues, known as the vergence and accommodation conflict (VAC), affects depth perception and thus limits user performance in 3D selection tasks within arm\u2019s reach (peri-personal space). To investigate this question, we built a multifocal stereo display, which can eliminate the influence of the VAC for pointing within the investigated distances. In a user study, participants performed a virtual hand 3D selection task with targets arranged laterally or along the line of sight, with and without a change in visual depth, in display conditions with and without the VAC. Our results show that the VAC influences 3D selection performance in common VR and AR stereo displays and that multifocal displays have a positive effect on 3D selection performance with a virtual hand.",
    "call-number": "10.1145/3491102.3502067",
    "collection-number": "633",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502067",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "selection, virtual hand, Fitts\u2019 Law, vergence-accommodation conflict, 3D pointing",
    "number": "Article 633",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The Effect of the Vergence-Accommodation Conflict on Virtual Hand Pointing in Immersive Displays",
    "URL": "https://doi.org/10.1145/3491102.3502067"
  },
  {
    "id": "10.1145/3491102.3501836",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Fender",
        "given": "Andreas Rene"
      },
      {
        "family": "Holz",
        "given": "Christian"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Mixed Reality is gaining interest as a platform for collaboration and focused work to a point where it may supersede current office settings in future workplaces. At the same time, we expect that interaction with physical objects and face-to-face communication will remain crucial for future work environments, which is a particular challenge in fully immersive Virtual Reality. In this work, we reconcile those requirements through a user\u2019s individual Asynchronous Reality, which enables seamless physical interaction across time. When a user is unavailable, e.g., focused on a task or in a call, our approach captures co-located or remote physical events in real-time, constructs a causality graph of co-dependent events, and lets immersed users revisit them at a suitable time in a causally accurate way. Enabled by our system AsyncReality, we present a workplace scenario that includes walk-in interruptions during a person\u2019s focused work, physical deliveries, and transient spoken messages. We then generalize our approach to a use-case agnostic concept and system architecture. We conclude by discussing the implications of Asynchronous Reality for future offices.",
    "call-number": "10.1145/3491102.3501836",
    "collection-number": "634",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3501836",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Immersive workspaces, Interruption in workplaces, Collaboration, Camera networks, Asynchronous communication, Mixed Reality",
    "number": "Article 634",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Causality-preserving Asynchronous Reality",
    "URL": "https://doi.org/10.1145/3491102.3501836"
  },
  {
    "id": "10.1145/3491102.3517671",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Feick",
        "given": "Martin"
      },
      {
        "family": "Regitz",
        "given": "Kora Persephone"
      },
      {
        "family": "Tang",
        "given": "Anthony"
      },
      {
        "family": "Kr\u00fcger",
        "given": "Antonio"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Visuo-haptic illusions are a method to expand proxy-based interactions in VR by introducing unnoticeable discrepancies between the virtual and real world. Yet how different design variables affect the illusions with proxies is still unclear. To unpack a subset of variables, we conducted two user studies with 48 participants to explore the impact of (1) different grasping types and movement trajectories, and (2) different grasping types and object masses on the discrepancy which may be introduced. Our Bayes analysis suggests that grasping types and object masses (\u2264 500 g) did not noticeably affect the discrepancy, but for movement trajectory, results were inconclusive. Further, we identified a significant difference between (un)restricted movement trajectories. Our data shows considerable differences in participants\u2019 proprioceptive accuracy, which seem to correlate with their prior VR experience. Finally, we illustrate the impact of our key findings on the visuo-haptic illusion design process by showcasing a new design workflow.",
    "call-number": "10.1145/3491102.3517671",
    "collection-number": "635",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517671",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Object Mass, Movement Trajectory, Visuo-Haptic Illusions, Grasp",
    "number": "Article 635",
    "number-of-pages": "15",
    "page": "1\u201315",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing Visuo-Haptic Illusions with Proxies in Virtual Reality: Exploration of Grasp, Movement Trajectory and Object Mass",
    "URL": "https://doi.org/10.1145/3491102.3517671"
  },
  {
    "id": "10.1145/3491102.3517508",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Thoravi Kumaravel",
        "given": "Balasaravanan"
      },
      {
        "family": "Wilson",
        "given": "Andrew D"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Today spectating and streaming virtual reality (VR) activities typically involves spectators viewing a 2D stream of the VR user\u2019s view. Streaming 2D videos of the game play is popular and well-supported by platforms such as Twitch. However, the generic streaming of full 3D representations is less explored. Thus, while the VR player\u2019s experience may be fully immersive, spectators are limited to 2D videos. This asymmetry lessens the overall experience for spectators, who themselves may be eager to spectate in VR. DreamStream puts viewers in the virtual environment of the VR application, allowing them to look \u201cover the shoulder\u201d of the VR player. Spectators can view streamed VR content immersively in 3D, independently explore the VR scene beyond what the VR player sees and ultimately cohabit the virtual environment alongside the VR player. For the VR player, DreamStream provides a spatial awareness of all their spectators. DreamStream retrofits and works with existing VR applications. We discuss the design and implementation of DreamStream, and carry out three qualitative informal evaluations. These evaluations shed light on the strengths and weakness of using DreamStream for the purpose of interactive spectating. Our participants found that DreamStream\u2019s VR viewer interface offered increased immersion, and made it easier to communicate and interact with the VR player.",
    "call-number": "10.1145/3491102.3517508",
    "collection-number": "636",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3517508",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "Streaming, Collaborative Interactions, Virtual Reality",
    "number": "Article 636",
    "number-of-pages": "17",
    "page": "1\u201317",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "DreamStream: Immersive and Interactive Spectating in VR",
    "URL": "https://doi.org/10.1145/3491102.3517508"
  },
  {
    "id": "10.1145/3491102.3502033",
    "type": "PAPER_CONFERENCE",
    "author": [
      {
        "family": "Lei",
        "given": "Yuxuan"
      },
      {
        "family": "Lu",
        "given": "Qi"
      },
      {
        "family": "Xu",
        "given": "Yingqing"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          2022,
          7,
          12
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "original-date": {
      "date-parts": [
        [
          2022,
          4,
          29
        ]
      ]
    },
    "abstract": "Constructing olfactory interfaces on demand requires significant design proficiency and engineering effort. The absence of powerful and convenient tools that reduced innovation complexity posed obstacles for future research in the area. To address this problem, we proposed O&O, a modular olfactory interface DIY toolkit. The toolkit consists of: (1) a scent generation kit, a set of electronics and accessories that supported three common scent vaporization techniques; (2) a module construction kit, a set of primitive cardboard modules for assembling permutable functional structures; (3) a design manual, a step-by-step design thinking framework that directs the decision-making and prototyping process. We organized a formal workshop with 19 participants and four solo DIY trials to evaluate the capability of the toolkit, the overall user engagement, the creations in both sessions, and the iterative suggestions. Finally, design implications and future opportunities were discussed for further research.",
    "call-number": "10.1145/3491102.3502033",
    "collection-number": "637",
    "collection-title": "CHI '22",
    "container-title": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "DOI": "10.1145/3491102.3502033",
    "event-place": "New Orleans, LA, USA",
    "ISBN": "9781450391573",
    "keyword": "cardboard toolkit, rapid prototyping, olfactory interface, olfactory display, design thinking",
    "number": "Article 637",
    "number-of-pages": "21",
    "page": "1\u201321",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "O&O: A DIY toolkit for designing and rapid prototyping olfactory interfaces",
    "URL": "https://doi.org/10.1145/3491102.3502033"
  }
]    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Sequence Gerneration, Data Augmentation",
    "Abstract": "Autoregressive sequence generation, a prevalent task in machine learning and natural language processing, generates every target token conditioned on both a source input and previously generated target tokens. Previous data augmentation methods, which have been shown to be effective for the task, mainly enhance source inputs (e.g., injecting noise into the source sequence by random swapping or masking, back translation, etc.) while overlooking the target-side augmentation. In this work, we propose a target-side augmentation method for sequence generation. In training, we use the decoder output probability distributions as soft indicators, which are multiplied with target token embeddings, to build pseudo tokens. These soft pseudo tokens are then used as target tokens to enhance the training. We conduct comprehensive experiments on various sequence generation tasks, including dialog generation, machine translation, and abstractive summarization. Without using any extra labeled data or introducing additional model parameters, our method significantly outperforms strong baselines. The code is available at https://github.com/TARGET-SIDE-DATA-AUG/TSDASG.",
    "One-sentence Summary": "We study the data augmentation for target-side conditional input of autoregressive sequence generation and propose a new method to build soft synthetic data."
  },
  {
    "title": "UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning",
    "url": "/forum?id=nBU_u6DLvoK",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Spatial-Temporal Representation Learning, 3D Convolution, Transformer",
    "Abstract": "It is a challenging task to learn rich and multi-scale spatiotemporal semantics from high-dimensional videos, due to large local redundancy and complex global dependency between video frames. The recent advances in this research have been mainly driven by 3D convolutional neural networks and vision transformers. Although 3D convolution can efficiently aggregate local context to suppress local redundancy from a small 3D neighborhood, it lacks the capability to capture global dependency because of the limited receptive field. Alternatively, vision transformers can effectively capture long-range dependency by self-attention mechanism, while having the limitation on reducing local redundancy with blind similarity comparison among all the tokens in each layer. Based on these observations, we propose a novel Unified transFormer (UniFormer) which seamlessly integrates merits of 3D convolution and spatiotemporal self-attention in a concise transformer format, and achieves a preferable balance between computation and accuracy. Different from traditional transformers, our relation aggregator can tackle both spatiotemporal redundancy and dependency, by learning local and global token affinity respectively in shallow and deep layers. We conduct extensive experiments on the popular video benchmarks, e.g., Kinetics-400, Kinetics-600, and Something-Something V1&V2. With only ImageNet-1K pretraining, our UniFormer achieves 82.9%/84.8% top-1 accuracy on Kinetics-400/Kinetics-600, while requiring 10x fewer GFLOPs than other state-of-the-art methods. For Something-Something V1 and V2, our UniFormer achieves new state-of-the-art performances of 60.9% and 71.2% top-1 accuracy respectively. Code is available at https://github.com/Sense-X/UniFormer.",
    "One-sentence Summary": "We introduce a novel Unified transFormer (UniFormer) which seamlessly integrates merits of 3D convolution and spatial-temporal self-attention in a concise transformer format, and achieves new state-of-the-art performances on Something-Something."
  },
  {
    "title": "Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies",
    "url": "/forum?id=DYypjaRdph2",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Decision Modelling, Imitation Learning, Inverse Online Learning",
    "Abstract": "Human decision making is well known to be imperfect and the ability to analyse such processes individually is crucial when attempting to aid or improve a decision-maker's ability to perform a task, e.g. to alert them to potential biases or oversights on their part. To do so, it is necessary to develop interpretable representations of how agents make decisions and how this process changes over time as the agent learns online in reaction to the accrued experience. To then understand the decision-making processes underlying a set of observed trajectories, we cast the policy inference problem as the inverse to this online learning problem. By interpreting actions within a potential outcomes framework, we introduce a meaningful mapping based on agents choosing an action they believe to have the greatest treatment effect. We introduce a practical algorithm for retrospectively estimating such perceived effects, alongside the process through which agents update them, using a novel architecture built upon an expressive family of deep state-space models. Through application to the analysis of UNOS organ donation acceptance decisions, we demonstrate that our approach can bring valuable insights into the factors that govern decision processes and how they change over time."
  },
  {
    "title": "Multi-Mode Deep Matrix and Tensor Factorization",
    "url": "/forum?id=6YVIk0sAkF_",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Recently, deep linear and nonlinear matrix factorizations gain increasing attention in the area of machine learning. Existing deep nonlinear matrix factorization methods can only exploit partial nonlinearity of the data and are not effective in handling matrices of which the number of rows is comparable to the number of columns. On the other hand, there is still a gap between deep learning and tensor decomposition. This paper presents a framework of multi-mode deep matrix and tensor factorizations to explore and exploit the full nonlinearity of the data in matrices and tensors. We use the factorization methods to solve matrix and tensor completion problems and prove that our methods have tighter generalization error bounds than conventional matrix and tensor factorization methods. The experiments on synthetic data and real datasets showed that the proposed methods have much higher recovery accuracy than many baselines."
  },
  {
    "title": "LORD: Lower-Dimensional Embedding of Log-Signature in Neural Rough Differential Equations",
    "url": "/forum?id=fCG75wd39ze",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "The problem of processing very long time-series data (e.g., a length of more than 10,000) is a long-standing research problem in machine learning. Recently, one breakthrough, called neural rough differential equations (NRDEs), has been proposed and has shown that it is able to process such data. Their main concept is to use the log-signature transform, which is known to be more efficient than the Fourier transform for irregular long time-series, to convert a very long time-series sample into a relatively shorter series of feature vectors. However, the log-signature transform causes non-trivial spatial overheads. To this end, we present the method of LOweR-Dimensional embedding of log-signature (LORD), where we define an NRDE-based autoencoder to implant the higher-depth log-signature knowledge into the lower-depth log-signature. We show that the encoder successfully combines the higher-depth and the lower-depth log-signature knowledge, which greatly stabilizes the training process and increases the model accuracy. In our experiments with benchmark datasets, the improvement ratio by our method is up to 75\\% in terms of various classification and forecasting evaluation metrics.",
    "One-sentence Summary": "We reduce the complexity of processing higher depth log-signatures in NRDE."
  },
  {
    "title": "Generalized Natural Gradient Flows in Hidden Convex-Concave Games and GANs",
    "url": "/forum?id=bsycpMi00R1",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Game-theoretic formulations in machine learning have recently risen in prominence, whereby entire modeling paradigms are best captured as zero-sum games. Despite their popularity, however, their dynamics are still poorly understood. This lack of theory is often substantiated with painful empirical observations of volatile training dynamics and even divergence. Such results highlight the need to develop an appropriate theory with convergence guarantees that are powerful enough to inform practice. This paper studies the generalized Gradient Descent-Ascent (GDA) flow in a large class of non-convex non-concave Zero-Sum games dubbed Hidden Convex-Concave games, a class of games that includes GANs. We focus on two specific geometries: a novel geometry induced by the hidden convex-concave structure that we call the hidden mapping geometry and the Fisher information geometry. For the hidden mapping geometry, we prove global convergence under mild assumptions. In the case of Fisher information geometry, we provide a complete picture of the dynamics in an interesting special setting of team competition via invariant function analysis."
  },
  {
    "title": "Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization",
    "url": "/forum?id=sPIFuucA3F",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "offline policy learning, offline contextual bandits, neural network function approximation",
    "Abstract": "Offline policy learning (OPL) leverages existing data collected a priori for policy optimization without any active exploration. Despite the prevalence and recent interest in this problem, its theoretical and algorithmic foundations in function approximation settings remain under-developed. In this paper, we consider this problem on the axes of distributional shift, optimization, and generalization in offline contextual bandits with neural networks. In particular, we propose a provably efficient offline contextual bandit with neural network function approximation that does not require any functional assumption on the reward. We show that our method provably generalizes over unseen contexts under a milder condition for distributional shift than the existing OPL works. Notably, unlike any other OPL method, our method learns from the offline data in an online manner using stochastic gradient descent, allowing us to leverage the benefits of online learning into an offline setting. Moreover, we show that our method is more computationally efficient and has a better dependence on the effective dimension of the neural network than an online counterpart. Finally, we demonstrate the empirical effectiveness of our method in a range of synthetic and real-world OPL problems.",
    "One-sentence Summary": "Provably efficient offline contextual bandits with neural network function approximation"
  },
  {
    "title": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
    "url": "/forum?id=QDdJhACYrlX",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Trajectory prediction, Multi-agent, Motion forecasting, Motion estimation, Autonomous driving",
    "Abstract": "In this paper, we propose THOMAS, a joint multi-agent trajectory prediction framework allowing for an efficient and consistent prediction of multi-agent multi-modal trajectories. We present a unified model architecture for simultaneous agent future heatmap estimation, in which we leverage hierarchical and sparse image generation for fast and memory-efficient inference. We propose a learnable trajectory recombination model that takes as input a set of predicted trajectories for each agent and outputs its consistent reordered recombination. This recombination module is able to realign the initially independent modalities so that they do no collide and are coherent with each other.  We report our results on the Interaction multi-agent prediction challenge and rank $1^{st}$ on the online test leaderboard.",
    "One-sentence Summary": "We propose a solution for multi-agent coherent multimodal trajectory prediction by learning a recombination of each agent predicted modalities."
  },
  {
    "title": "CLEVA-Compass: A Continual Learning Evaluation Assessment Compass to Promote Research Transparency and Comparability",
    "url": "/forum?id=rHMaBYbkkRJ",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "continual learning, lifelong learning, machine learning evaluation",
    "Abstract": "What is the state of the art in continual machine learning? Although a natural question for predominant static benchmarks, the notion to train systems in a lifelong manner entails a plethora of additional challenges with respect to set-up and evaluation.  The latter have recently sparked a growing amount of critiques on prominent algorithm-centric perspectives and evaluation protocols being too narrow, resulting in several attempts at constructing guidelines in favor of specific desiderata or arguing against the validity of prevalent assumptions.  In this work, we depart from this mindset and argue that the goal of a precise formulation of desiderata is an ill-posed one, as diverse applications may always warrant distinct scenarios. Instead, we introduce the Continual Learning EValuation Assessment Compass: the CLEVA-Compass. The compass provides the visual means to both identify how approaches are practically reported and how works can simultaneously be contextualized in the broader literature landscape.  In addition to promoting compact specification in the spirit of recent replication trends, it thus provides an intuitive chart to understand the priorities of individual systems, where they resemble each other, and what elements are missing towards a fair comparison.",
    "One-sentence Summary": "We introduce the Continual Learning EValuation Assessment Compass, which provides the visual means to both identify how approaches are practically reported and how they can simultaneously be contextualized in the broader literature landscape."
  },
  {
    "title": "Neural Stochastic Dual Dynamic Programming",
    "url": "/forum?id=aisKPsMM3fg",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "data-driven algorithm design, learning to optimize, multi-stage stochastic optimization, primal-dual dynamic programming",
    "Abstract": "Stochastic dual dynamic programming (SDDP) is a state-of-the-art method for solving multi-stage stochastic optimization, widely used for modeling real-world process optimization tasks. Unfortunately, SDDP has a worst-case complexity that scales exponentially in the number of decision variables, which severely limits applicability to only low dimensional problems. To overcome this limitation, we extend SDDP by introducing a trainable neural model that learns to map problem instances to a piece-wise linear value function within intrinsic low-dimension space, which is architected specifically to interact with a base SDDP solver, so that can accelerate optimization performance on new instances. The proposed Neural Stochastic Dual Dynamic Programming ($$\\nu$$-SDDP) continually self-improves by solving successive problems. An empirical investigation demonstrates that $$\\nu$$-SDDP can significantly reduce problem solving cost without sacrificing solution quality over competitors such as SDDP and reinforcement learning algorithms, across a range of synthetic and real-world process optimization problems.",
    "One-sentence Summary": "We proposed neural-SDDP pushing the frontier of multi-stage stochastic optimization solver towards practical problem size."
  },
  {
    "title": "DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations",
    "url": "/forum?id=BrPdX1bDZkQ",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "imitation learning, offline imitation learning, imperfect demonstration, non-expert demonstration",
    "Abstract": "We consider offline imitation learning (IL), which aims to mimic the expert's behavior from its demonstration without further interaction with the environment. One of the main challenges in offline IL is to deal with the narrow support of the data distribution exhibited by the expert demonstrations that cover only a small fraction of the state and the action spaces. As a result, offline IL algorithms that rely only on expert demonstrations are very unstable since the situation easily deviates from those in the expert demonstrations. In this paper, we assume additional demonstration data of unknown degrees of optimality, which we call imperfect demonstrations. Under this setting, we propose DemoDICE, which effectively utilizes imperfect demonstrations by matching the stationary distribution of a policy with experts' distribution while penalizing its deviation from the overall demonstrations. Compared with the recent IL algorithms that adopt adversarial minimax training objectives, we substantially stabilize overall learning process by reducing minimax optimization to a direct convex optimization in a principled manner. Using extensive tasks, we show that DemoDICE achieves promising results in the offline IL from expert and imperfect demonstrations."
  },
  {
    "title": "Learning to Extend Molecular Scaffolds with Structural Motifs",
    "url": "/forum?id=ZTsoE8G3GG",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "molecules, graph neural networks, scaffold, generative model",
    "Abstract": "Recent advancements in deep learning-based modeling of molecules promise to accelerate in silico drug discovery. A plethora of generative models is available, building molecules either atom-by-atom and bond-by-bond or fragment-by-fragment. However, many drug discovery projects require a fixed scaffold to be present in the generated molecule, and incorporating that constraint has only recently been explored. Here, we propose MoLeR, a graph-based model that naturally supports scaffolds as initial seed of the generative procedure, which is possible because it is not conditioned on the generation history. Our experiments show that MoLeR performs comparably to state-of-the-art methods on unconstrained molecular optimization tasks, and outperforms them on scaffold-based tasks, while being an order of magnitude faster to train and sample from than existing approaches. Furthermore, we show the influence of a number of seemingly minor design choices on the overall performance.",
    "One-sentence Summary": "We propose a new fragment-based generative model of molecules that can be constrained to include an arbitrary subgraph (scaffold)."
  },
  {
    "title": "Discrepancy-Based Active Learning for Domain Adaptation",
    "url": "/forum?id=p98WJxUC3Ca",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "active learning, domain adaptation, discrepancy, kmedoids, single batch, covariate shift",
    "Abstract": "The goal of the paper is to design active learning strategies which lead to domain adaptation under an assumption of Lipschitz functions. Building on previous work by Mansour et al. (2009) we adapt the concept of discrepancy distance between source and target distributions to restrict the maximization over the hypothesis class to a localized class of functions which are performing accurate labeling on the source domain. We derive generalization error bounds for such active learning strategies in terms of Rademacher average and localized discrepancy for general loss functions which satisfy a regularity condition. A practical K-medoids algorithm that can address the case of large data set is inferred from the theoretical bounds. Our numerical experiments show that the proposed algorithm is competitive against other state-of-the-art active learning techniques in the context of domain adaptation, in particular on large data sets of around one hundred thousand images.",
    "One-sentence Summary": "This paper presents an active learning for domain adaptation method based on a localized discrepancy between source and target distributions."
  },
  {
    "title": "Gradient Matching for Domain Generalization",
    "url": "/forum?id=vDwBW49HmO",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Domain generalization, multi-source domain adaptation",
    "Abstract": "Machine learning systems typically assume that the distributions of training and test sets match closely. However, a critical requirement of such systems in the real world is their ability to generalize to unseen domains. Here, we propose an _inter-domain gradient matching_ objective that targets domain generalization by maximizing the inner product between gradients from different domains. Since direct optimization of the gradient inner product can be computationally prohibitive --- it requires computation of second-order derivatives \u2013-- we derive a simpler first-order algorithm named Fish that approximates its optimization. We perform experiments on the Wilds benchmark, which captures distribution shift in the real world, as well as the DomainBed benchmark that focuses more on synthetic-to-real transfer. Our method produces competitive results on both benchmarks, demonstrating its effectiveness across a wide range of domain generalization tasks.",
    "One-sentence Summary": "We propose to learn features that are invariant across domains by maximizing the gradient inner product between domains."
  },
  {
    "title": "Objects in Semantic Topology",
    "url": "/forum?id=d5SCUJ5t1k",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "A more realistic object detection paradigm, Open-World Object Detection, has arised increasing research interests in the community recently. A qualified open-world object detector can not only identify objects of known categories, but also discover unknown objects, and incrementally learn to categorize them when their annotations progressively arrive. Previous works rely on independent modules to recognize unknown categories and perform incremental learning, respectively. In this paper, we provide a unified perspective: Semantic Topology. During the life-long learning of an open-world object detector, all object instances from the same category are assigned to their corresponding pre-defined node in the semantic topology, including the `unknown' category. This constraint builds up discriminative feature representations and consistent relationships among objects, thus enabling the detector to distinguish unknown objects out of the known categories, as well as making learned features of known objects undistorted when learning new categories incrementally. Extensive experiments demonstrate that semantic topology, either randomly-generated or derived from a well-trained language model, could outperform the current state-of-the-art open-world object detectors by a large margin, e.g., the absolute open-set error (the number of unknown instances that are wrongly labeled as known) is reduced from 7832 to 2546, exhibiting the inherent superiority of semantic topology on open-world object detection."
  },
  {
    "title": "Hidden Parameter Recurrent State Space Models For Changing Dynamics Scenarios",
    "url": "/forum?id=ds8yZOUsea",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "State Space Models, Changing Dynamics, Recurrent Neural Networks, Multi Task Learning",
    "Abstract": "Recurrent State-space models (RSSMs) are highly expressive models for learning patterns in time series data and for system identification. However, these models are often based on the assumption that the dynamics are fixed and unchanging, which is rarely the case in real-world scenarios. Many control applications often exhibit tasks with similar, but not identical dynamics, that can be modelled as having a common latent structure. We introduce the Hidden Parameter Recurrent State Space Models (HiP-RSSMs), a framework that parametrizes a family of related state-space models with a low-dimensional set of latent factors. We present a simple and effective way of performing learning and inference over this Gaussian graphical model that avoids approximations like variational inference. We show that HiP-RSSMs outperforms RSSMs and competing multi-task models on several challenging robotic benchmarks both on real systems and simulations.",
    "One-sentence Summary": "A new formalism for extending Recurrent State Space Models (RSSMs) to changing dynamics scenarios."
  },
  {
    "title": "Graph Neural Network Guided Local Search for the Traveling Salesperson Problem",
    "url": "/forum?id=ar92oEosBIg",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Traveling Salesman Problem, Graph Neural Network, Metaheuristic, Guided Local Search, Hybrid",
    "Abstract": "Solutions to the Traveling Salesperson Problem (TSP) have practical applications to processes in transportation, logistics, and automation, yet must be computed with minimal delay to satisfy the real-time nature of the underlying tasks. However, solving large TSP instances quickly without sacrificing solution quality remains challenging for current approximate algorithms. To close this gap, we present a hybrid data-driven approach for solving the TSP based on Graph Neural Networks (GNNs) and Guided Local Search (GLS). Our model predicts the regret of including each edge of the problem graph in the solution; GLS uses these predictions in conjunction with the original problem graph to find solutions. Our experiments demonstrate that this approach converges to optimal solutions at a faster rate than three recent learning based approaches for the TSP. Notably, we reduce the mean optimality gap on the 100-node problem set from 1.534% to 0.705%, a 2x improvement. When generalizing from 20-node instances to the 100-node problem set, we reduce the optimality gap from 18.845% to 2.622%, a 7x improvement.",
    "One-sentence Summary": "We present a hybrid data-driven approach for solving the TSP based on Graph Neural Networks (GNNs) and Guided Local Search (GLS), which outperforms state-of-the-art learning-based approaches and non-learning GLS algorithms."
  },
  {
    "title": "On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks",
    "url": "/forum?id=aPOpXlnV1T",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Uncertainty Estimation, Probabilistic Neural Networks, Aleatoric Uncertainty, Heteroscedastic Uncertainty, Analysis",
    "Abstract": "Capturing aleatoric uncertainty is a critical part of many machine learning systems. In deep learning, a common approach to this end is to train a neural network to estimate the parameters of a heteroscedastic Gaussian distribution by maximizing the logarithm of the likelihood function under the observed data. In this work, we examine this approach and identify potential hazards associated with the use of log-likelihood in conjunction with gradient-based optimizers. First, we present a synthetic example illustrating how this approach can lead to very poor but stable parameter estimates. Second, we identify the culprit to be the log-likelihood loss, along with certain conditions that exacerbate the issue. Third, we present an alternative formulation, termed $\\beta$-NLL, in which each data point's contribution to the loss is weighted by the $\\beta$-exponentiated variance estimate. We show that using an appropriate $\\beta$ largely mitigates the issue in our illustrative example. Fourth, we evaluate this approach on a range of domains and tasks and show that it achieves considerable improvements and performs more robustly concerning hyperparameters, both in predictive RMSE and log-likelihood criteria.",
    "One-sentence Summary": "We analyse problems with the training objective of probabilistic neural networks and propose a fix in the form of a new loss function."
  },
  {
    "title": "Label-Efficient Semantic Segmentation with Diffusion Models",
    "url": "/forum?id=SlxSY2UZQT",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Denoising diffusion probabilistic models have recently received much research attention since they outperform alternative approaches, such as GANs, and currently provide state-of-the-art generative performance. The superior performance of diffusion models has made them an appealing tool in several applications, including inpainting, super-resolution, and semantic editing. In this paper, we demonstrate that diffusion models can also serve as an instrument for semantic segmentation, especially in the setup when labeled data is scarce. In particular, for several pretrained diffusion models, we investigate the intermediate activations from the networks that perform the Markov step of the reverse diffusion process. We show that these activations effectively capture the semantic information from an input image and appear to be excellent pixel-level representations for the segmentation problem. Based on these observations, we describe a simple segmentation method, which can work even if only a few training images are provided. Our approach significantly outperforms the existing alternatives on several datasets for the same amount of human supervision."
  },
  {
    "title": "Language model compression with weighted low-rank factorization",
    "url": "/forum?id=uPv9Y3gmAI5",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "model compression, low-rank approximation, transformer, language model",
    "Abstract": "Factorizing a large matrix into small matrices is a popular strategy for model compression. Singular value decomposition (SVD) plays a vital role in this compression strategy, approximating a learned matrix with fewer parameters. However, SVD minimizes the squared error toward reconstructing the original matrix without gauging the importance of the parameters, potentially giving a larger reconstruction error for those who affect the task accuracy more. In other words, the optimization objective of SVD is not aligned with the trained model's task accuracy. We analyze this previously unexplored problem, make observations, and address it by introducing Fisher information to weigh the importance of parameters affecting the model prediction. This idea leads to our method: Fisher-Weighted SVD (FWSVD). Although the factorized matrices from our approach do not result in smaller reconstruction errors, we find that our resulting task accuracy is much closer to the original model's performance. We perform analysis with the transformer-based language models, showing our weighted SVD largely alleviates the mismatched optimization objectives and can maintain model performance with a higher compression rate. Our method can directly compress a task-specific model while achieving better performance than other compact model strategies requiring expensive model pre-training. Moreover, the evaluation of compressing an already compact model shows our method can further reduce 9% to 30% parameters with an insignificant impact on task accuracy.",
    "One-sentence Summary": "Fisher-weighted SVD for language model compression"
  },
  {
    "title": "Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization",
    "url": "/forum?id=QuObT9BTWo",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multiobjective Combinatorial Optimization, Combinatorial Optimization, Neural Combinatorial Optimization, Multiobjective Optimization",
    "Abstract": "Multiobjective combinatorial optimization (MOCO) problems can be found in many real-world applications. However, exactly solving these problems would be very challenging, particularly when they are NP-hard. Many handcrafted heuristic methods have been proposed to tackle different MOCO problems over the past decades. In this work, we generalize the idea of neural combinatorial optimization, and develop a learning-based approach to approximate the whole Pareto set for a given MOCO problem without further search procedure. We propose a single preference-conditioned model to directly generate approximate Pareto solutions for any trade-off preference, and design an efficient multiobjective reinforcement learning algorithm to train this model. Our proposed method can be treated as a learning-based extension for the widely-used decomposition-based multiobjective evolutionary algorithm (MOEA/D). It uses a single model to accommodate all the possible preferences, whereas other methods use a finite number of solutions to approximate the Pareto set. Experimental results show that our proposed method significantly outperforms some other methods on the multiobjective traveling salesman problem, multiobjective vehicle routing problem, and multiobjective knapsack problem in terms of solution quality, speed, and model efficiency.",
    "One-sentence Summary": "We propose a learning-based method to approximate the whole Pareto set for multi-objective combinatorial optimization problems with a single model."
  },
  {
    "title": "Prototypical Contrastive Predictive Coding",
    "url": "/forum?id=8la28hZOwug",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Knowledge distillation, contrastive learning, self-supervised learning",
    "Abstract": "Transferring representational knowledge of a model to another is a wide-ranging topic in machine learning. Those applications include the distillation of a large supervised or self-supervised teacher model to a smaller student model or self-supervised learning via self-distillation. Knowledge distillation is an original method to solve these problems, which minimizes a cross-entropy loss between the prototypical probabilistic outputs of teacher and student networks. On the other hand, contrastive learning has shown its competency in transferring representations as they allow students to capture the information of teacher representations. In this paper, we amalgamate the advantages of knowledge distillation and contrastive learning by modeling the critic of a contrastive objective by the prototypical probabilistic discrepancy between two features. We refer to it as prototypical contrastive predictive coding and present efficient implementation using the proposed objective for three distillation tasks: supervised model compression, self-supervised model compression, and self-supervised learning via self-distillation. Through extensive experiments, we validate the effectiveness of our method and show that our method achieves state-of-the-art performance in supervised / self-supervised model compression.",
    "One-sentence Summary": "We propose prototypical contrastive predictive coding for efficient distillation of representational knowledge of one network into other network."
  },
  {
    "title": "Adversarial Robustness Through the Lens of Causality",
    "url": "/forum?id=cZAi1yWpiXQ",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial examples, Causality",
    "Abstract": "The adversarial vulnerability of deep neural networks has attracted signi\ufb01cant attention in machine learning. As causal reasoning has an instinct for modeling distribution change, it is essential to incorporate causality into analyzing this specific type of distribution change induced by adversarial attacks. However, causal formulations of the intuition of adversarial attacks and the development of robust DNNs are still lacking in the literature. To bridge this gap, we construct a causal graph to model the generation process of adversarial examples and define the adversarial distribution to formalize the intuition of adversarial attacks. From the causal perspective, we study the distinction between the natural and adversarial distribution and conclude that the origin of adversarial vulnerability is the focus of models on spurious correlations. Inspired by the causal understanding, we propose the \\emph{Causal}-inspired \\emph{Adv}ersarial distribution alignment method, CausalAdv, to eliminate the difference between natural and adversarial distributions by considering spurious correlations. Extensive experiments demonstrate the efficacy of the proposed method. Our work is the first attempt towards using causality to understand and mitigate the adversarial vulnerability.",
    "One-sentence Summary": "The first attempt towards using causality to understand and mitigate adversarial vulnerability."
  },
  {
    "title": "Distributionally Robust Fair Principal Components via Geodesic Descents",
    "url": "/forum?id=9NVd-DMtThY",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "fair principal component analysis, distributionally robust optimization, manifold optimization",
    "Abstract": "Principal component analysis is a simple yet useful dimensionality reduction technique in modern machine learning pipelines. In consequential domains such as college admission, healthcare and credit approval, it is imperative to take into account emerging criteria such as the fairness and the robustness of the learned projection. In this paper, we propose a distributionally robust optimization problem for principal component analysis which internalizes a fairness criterion in the objective function. The learned projection thus balances the trade-off between the total reconstruction error and the reconstruction error gap between subgroups, taken in the min-max sense over all distributions in a moment-based ambiguity set. The resulting optimization problem over the Stiefel manifold can be efficiently solved by a Riemannian subgradient descent algorithm with a sub-linear convergence rate. Our experimental results on real-world datasets show the merits of our proposed method over state-of-the-art baselines."
  },
  {
    "title": "Understanding and Improving Graph Injection Attack by Promoting Unnoticeability",
    "url": "/forum?id=wkMG8cdvh7-",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Adversarial Attacks, Node Classification",
    "Abstract": "Recently Graph Injection Attack (GIA) emerges as a practical attack scenario on Graph Neural Networks (GNNs), where the adversary can merely inject few malicious nodes instead of modifying existing nodes or edges, i.e., Graph Modification Attack (GMA). Although GIA has achieved promising results, little is known about why it is successful and whether there is any pitfall behind the success. To understand the power of GIA, we compare it with GMA and find that GIA can be provably more harmful than GMA due to its relatively high flexibility. However, the high flexibility will also lead to great damage to the homophily distribution of the original graph, i.e., similarity among neighbors. Consequently, the threats of GIA can be easily alleviated or even prevented by homophily-based defenses designed to recover the original homophily. To mitigate the issue, we introduce a novel constraint \u2013 homophily unnoticeability that enforces GIA to preserve the homophily, and propose Harmonious Adversarial Objective (HAO) to instantiate it. Extensive experiments verify that GIA with HAO can break homophily-based defenses and outperform previous GIA attacks by a significant margin. We believe our methods can serve for a more reliable evaluation of the robustness of GNNs.",
    "One-sentence Summary": "We find GIA can be provably more harmful than GMA while at the price of bringing more damage to the homophily distribution, which makes it can easily defendable, hence we propose a novel adversarial objective to mitigate the issue."
  },
  {
    "title": "Learning to Guide and to be Guided in the Architect-Builder Problem",
    "url": "/forum?id=swiyAeGzFhQ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Social Learning, Interactive Learning, Teacher-Student Learning, Computational Experimental Semiotics, Socially Supervised Learning",
    "Abstract": "We are interested in interactive agents that learn to coordinate, namely, a $builder$ -- which performs actions but ignores the goal of the task, i.e. has no access to rewards -- and an $architect$ which guides the builder towards the goal of the task. \n        We define and explore a formal setting where artificial agents are equipped with mechanisms that allow them to simultaneously learn a task while at the same time evolving a shared communication protocol.  \n        Ideally, such learning should only rely on high-level communication priors and be able to handle a large variety of tasks and meanings while deriving communication protocols that can be reused across tasks.\n        The field of Experimental Semiotics has shown the extent of human proficiency at learning from a priori unknown instructions meanings. Therefore, we take inspiration from it and present the Architect-Builder Problem (ABP): an asymmetrical setting in which an architect must learn to guide a builder towards constructing a specific structure. The architect knows the target structure but cannot act in the environment and can only send arbitrary messages to the builder. The builder on the other hand can act in the environment, but receives no rewards nor has any knowledge about the task, and must learn to solve it relying only on the messages sent by the architect. Crucially, the meaning of messages is initially not defined nor shared between the agents but must be negotiated throughout learning.\n        Under these constraints, we propose Architect-Builder Iterated Guiding (ABIG), a solution to the Architect-Builder Problem where the architect leverages a learned model of the builder to guide it while the builder uses self-imitation learning to reinforce its guided behavior. To palliate to the non-stationarity induced by the two agents concurrently learning, ABIG structures the sequence of interactions between the agents into interaction frames. We analyze the key learning mechanisms of ABIG and test it in a 2-dimensional instantiation of the ABP where tasks involve grasping cubes, placing them at a given location, or building various shapes. In this environment, ABIG results in a low-level, high-frequency, guiding communication protocol that not only enables an architect-builder pair to solve the task at hand, but that can also generalize to unseen tasks.",
    "One-sentence Summary": "We formulate -- and propose a solution to -- the Architect-Builder Problem, a new asymmetrical Interactive Learning setting where one agent must guide the other agent towards the goal at hand."
  },
  {
    "title": "Phase Collapse in Neural Networks",
    "url": "/forum?id=iPHLcmtietq",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "phase collapse, neural collapse, concentration, classification, imagenet, deep networks, complex networks, sparsity in deep networks",
    "Abstract": "Deep convolutional classifiers linearly separate image classes and improve accuracy as depth increases. They progressively reduce the spatial dimension whereas the number of channels grows with depth. Spatial variability is therefore transformed into variability along channels. A fundamental challenge is to understand the role of non-linearities together with convolutional filters in this transformation. ReLUs with biases are often interpreted as thresholding operators that improve discrimination through sparsity. This paper demonstrates that it is a different mechanism called \\emph{phase collapse} which eliminates spatial variability while linearly separating classes. We show that collapsing the phases of complex wavelet coefficients is sufficient to reach the classification accuracy of ResNets of similar depths. However, replacing the phase collapses with thresholding operators that enforce sparsity considerably degrades the performance. We explain these numerical results by showing that the iteration of phase collapses progressively improves separation of classes, as opposed to thresholding non-linearities.",
    "One-sentence Summary": "The classification accuracy of CNNs mostly relies on the mechanism of phase collapses to eliminate spatial variability and linearly separate class means."
  },
  {
    "title": "SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training",
    "url": "/forum?id=TBpg4PnXhYH",
    "date": "28 Sept 2021 (modified: 06 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Speech Representation Learning, Speech Pre-training, Speech Recognition, Self-supervised Representation Learning",
    "Abstract": "We introduce a new approach for speech pre-training named SPIRAL which works by learning denoising representation of perturbed data in a teacher-student framework. \n        Specifically, given a speech utterance, we first feed the utterance to a teacher network to obtain corresponding representation. Then the same utterance is perturbed and fed to a student network. The student network is trained to output representation resembling that of the teacher. At the same time, the teacher network is updated as moving average of student's weights over training steps. In order to prevent representation collapse, we apply an in-utterance contrastive loss as pre-training objective and impose position randomization on the input to the teacher. SPIRAL achieves competitive or better results compared to state-of-the-art speech pre-training method wav2vec 2.0, with significant reduction of training cost (80% for BASE model, 65% for LARGE model). \n        Furthermore, we address the problem of noise-robustness that is critical to real-world speech applications. We propose multi-condition pre-training by perturbing the student's input with various types of additive noise. We demonstrate that multi-condition pre-trained SPIRAL models are more robust to noisy speech (9.0% - 13.3% relative word error rate reduction on real noisy test data), compared to applying multi-condition training solely in the fine-tuning stage. Source code is available at https://github.com/huawei-noah/Speech-Backbones/tree/main/SPIRAL."
  },
  {
    "title": "Improving the Accuracy of Learning Example Weights for Imbalance Classification",
    "url": "/forum?id=J_PHjw4gvXJ",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Imbalance classification, Meta learning, Data weighting.",
    "Abstract": "To solve the imbalance classification, methods of weighting examples have been proposed. Recent work has studied to assign adaptive weights to training examples through learning mechanisms, that is, the weights, similar to classification models, are regarded as parameters that need to be learned. However, the algorithms in recent work use local information to approximately optimize the weights, which may lead to inaccurate learning of the weights. In this work, we first propose a novel mechanism of learning with a constraint, which can accurately train the weights and model. Then, we propose a combined method of our learning mechanism and the work by Hu et al., which can promote each other to perform better. Our proposed method can be applied to any type of deep network model. Experiments show that compared with the state-of-the-art algorithms, our method has significant improvement in varieties of settings, including text and image classification over different imbalance ratios, binary and multi-class classification."
  },
  {
    "title": "Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks",
    "url": "/forum?id=Czsdv-S4-w9",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "video generation, implicit neural representations, generative adversarial networks",
    "Abstract": "In the deep learning era, long video generation of high-quality still remains challenging due to the spatio-temporal complexity and continuity of videos. Existing prior works have attempted to model video distribution by representing videos as 3D grids of RGB values, which impedes the scale of generated videos and neglects continuous dynamics. In this paper, we found that the recent emerging paradigm of implicit neural representations (INRs) that encodes a continuous signal into a parameterized neural network effectively mitigates the issue. By utilizing INRs of video, we propose dynamics-aware implicit generative adversarial network (DIGAN), a novel generative adversarial network for video generation. Specifically, we introduce (a) an INR-based video generator that improves the motion dynamics by manipulating the space and time coordinates differently and (b) a motion discriminator that efficiently identifies the unnatural motions without observing the entire long frame sequences. We demonstrate the superiority of DIGAN under various datasets, along with multiple intriguing properties, e.g., long video synthesis, video extrapolation, and non-autoregressive video generation. For example, DIGAN improves the previous state-of-the-art FVD score on UCF-101 by 30.7% and can be trained on 128 frame videos of 128x128 resolution, 80 frames longer than the 48 frames of the previous state-of-the-art method.",
    "One-sentence Summary": "We make video generation scalable leveraging implicit neural representations."
  },
  {
    "title": "Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization",
    "url": "/forum?id=0cgU-BZp2ky",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Human in the Loop, Safe Reinforcement Learning, Autonomous Driving",
    "Abstract": "Human intervention is an effective way to inject human knowledge into the training loop of reinforcement learning, which can bring fast learning and ensured training safety. Given the very limited budget of human intervention, it remains challenging to design when and how human expert interacts with the learning agent in the training. In this work, we develop a novel human-in-the-loop learning method called Human-AI Copilot Optimization (HACO).To allow the agent's sufficient exploration in the risky environments while ensuring the training safety, the human expert can take over the control and demonstrate how to avoid probably dangerous situations or trivial behaviors. The proposed HACO then effectively utilizes the data both from the trial-and-error exploration and human's partial demonstration to train a high-performing agent. HACO extracts proxy state-action values from partial human demonstration and optimizes the agent to improve the proxy values meanwhile reduce the human interventions. The experiments show that HACO achieves a substantially high sample efficiency in the safe driving benchmark. HACO can train agents to drive in unseen traffic scenarios with a handful of human intervention budget and achieve high safety and generalizability, outperforming both reinforcement learning and imitation learning baselines with a large margin. Code and demo video are included in the supplementary materials."
  },
  {
    "title": "Enhancing Cross-lingual Transfer by Manifold Mixup",
    "url": "/forum?id=OjPmfr9GkVv",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "cross-lingual transfer, cross-lingual understanding, manifold mixup",
    "Abstract": "Based on large-scale pre-trained multilingual representations, recent cross-lingual transfer methods have achieved impressive transfer performances. However, the performance of target languages still lags far behind the source language. In this paper, our analyses indicate such a performance gap is strongly associated with the cross-lingual representation discrepancy. To achieve better cross-lingual transfer performance, we propose the cross-lingual manifold mixup (X-Mixup) method, which adaptively calibrates the representation discrepancy and gives a compromised representation for target languages. Experiments on the XTREME benchmark show X-Mixup achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and significantly reduces the cross-lingual representation discrepancy.",
    "One-sentence Summary": "We propose the cross-lingual manifold mixup method to improve the cross-lingual transfer."
  },
  {
    "title": "Evolutionary Diversity Optimization with Clustering-based Selection for Reinforcement Learning",
    "url": "/forum?id=74x5BXs4bWD",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement learning, Quality-Diversity, Evolutionary algorithms",
    "Abstract": "Reinforcement Learning (RL) has achieved significant successes, which aims to obtain a single policy maximizing the expected cumulative rewards for a given task. However, in many real-world scenarios, e.g., navigating in complex environments and controlling robots, one may need to find a set of policies having both high rewards and diverse behaviors, which can bring better exploration and robust few-shot adaptation. Recently, some methods have been developed by using evolutionary techniques, including iterative reproduction and selection of policies. However, due to the inefficient selection mechanisms, these methods cannot fully guarantee both high quality and diversity. In this paper, we propose EDO-CS, a new Evolutionary Diversity Optimization algorithm with Clustering-based Selection. In each iteration, the policies are divided into several clusters based on their behaviors, and a high-quality policy is selected from each cluster for reproduction. EDO-CS also adaptively balances the importance between quality and diversity in the reproduction process. Experiments on various (i.e., deceptive and multi-modal) continuous control tasks, show the superior performance of EDO-CS over previous methods, i.e., EDO-CS can achieve a set of policies with both high quality and diversity efficiently while previous methods cannot.",
    "One-sentence Summary": "We propose EDO-CS, a new Evolutionary Diversity Optimization algorithm with Clustering-based Selection that can achieve a set of policies with both high quality and diversity efficiently."
  },
  {
    "title": "CURVATURE-GUIDED DYNAMIC SCALE NETWORKS FOR MULTI-VIEW  STEREO",
    "url": "/forum?id=_Wzj0J2xs2D",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multi-view stereo, 3D reconstruction, dynamic scale",
    "Abstract": "Multi-view stereo (MVS) is a crucial task for precise 3D reconstruction. Most recent studies tried to improve the performance of matching cost volume in MVS by introducing a skilled design to cost formulation or cost regularization. In this paper, we focus on learning robust feature extraction to enhance the performance of matching costs, without need of heavy computation in the other steps. In particular, we present a dynamic scale feature extraction network, namely, CDSFNet. It is composed of multiple novel convolution layers, each of which can select a proper patch scale for each pixel guided by the normal curvature of image surface. As a result, CDFSNet can estimate the optimal patch scales to learn discriminative features for accurate matching computation between reference and source images. By combining the robust extracted features with an appropriate cost formulation strategy, our final MVS architecture can estimate depth maps more precisely. Extensive experiments showed that the proposed method outperforms other state-of-the-art methods on complex outdoor scenes. It significantly improves the completeness of reconstructed models. Moreover, the method can process the high resolution with faster run-time and lower memory compared to the other MVS methods.",
    "One-sentence Summary": "This paper proposes a dynamic scale feature network to address the matching ambiguity problem in Multi-view stereo (MVS) and then designs an efficient MVS network to predict the depth maps."
  },
  {
    "title": "Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism",
    "url": "/forum?id=KLaDXLAzzFT",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning theory, markov decision process theory",
    "Abstract": "Offline reinforcement learning, which seeks to utilize offline/historical data to optimize sequential decision-making strategies, has gained surging prominence in recent studies. Due to the advantage that appropriate function approximators can help mitigate the sample complexity burden in modern reinforcement learning problems, existing endeavors usually enforce powerful function representation models (e.g. neural networks) to learn the optimal policies. However, a precise understanding of the statistical limits with function representations, remains elusive, even when such a representation is linear.\n        \n        \n        Towards this goal, we study the statistical limits of offline reinforcement learning with linear model representations. To derive the tight offline learning bound, we design the variance-aware pessimistic value iteration (VAPVI), which adopts the conditional variance information of the value function for time-inhomogeneous episodic linear Markov decision processes (MDPs). VAPVI leverages estimated variances of the value functions to reweight the Bellman residuals in the least-square pessimistic value iteration and provides improved offline learning bounds over the best-known existing results (whereas the Bellman residuals are equally weighted by design). More importantly, our learning bounds are expressed in terms of system quantities, which provide natural instance-dependent characterizations that previous results are short of. We hope our results draw a clearer picture of what offline learning should look like when linear representations are provided."
  },
  {
    "title": "Exploring extreme parameter compression for pre-trained language models",
    "url": "/forum?id=RftryyYyjiG",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "pre-trained language models, tensor decomposition, compression, BERT",
    "Abstract": "Recent work explored the potential of large-scale Transformer-based pre-trained models, especially Pre-trained Language Models (PLMs) in natural language processing. This raises many concerns from various perspectives, e.g.,  financial costs and carbon emissions. \n        Compressing PLMs like BERT with negligible performance loss for faster inference and cheaper deployment has attracted much attention. In this work, we aim to explore larger compression ratios for PLMs, among which tensor decomposition is a potential but under-investigated one. By comparing existing decomposition methods, Tucker decomposition is found to be parameter-efficient for compression.  Two decomposition and reconstruction protocols are further proposed to improve the effectiveness and efficiency of Tucker decomposition in parameter compression.\n        Our compressed BERT with ${1}/{7}$ parameters in Transformer layers performs on-par with,  sometimes slightly better than the original BERT in GLUE benchmark. A tiny version achieves  96.7\\%  performance of  BERT-base with $ {1}/{48} $ encoder parameters (i.e., less than 2M parameters excluding the embedding layer) and  \\textbf{$2.7 \\times$} faster on inference. To show that the proposed method is orthogonal to existing compression methods like knowledge distillation, we also explore the benefit of the proposed method on a distilled BERT."
  },
  {
    "title": "Local Feature Swapping for Generalization in Reinforcement Learning",
    "url": "/forum?id=Sq0-tgDyHe4",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement learning, Generalization, Regularization",
    "Abstract": "Over the past few years, the acceleration of computing resources and research in Deep Learning has led to significant practical successes in a range of tasks, including in particular in computer vision. Building on these advances, reinforcement learning has also seen a leap forward with the emergence of agents capable of making decisions directly from visual observations. Despite these successes, the over-parametrization of neural architectures leads to memorization of the data used during training and thus to a lack of generalization.\n        Reinforcement learning agents based on visual inputs also suffer from this phenomenon by erroneously correlating rewards with unrelated visual features such as background elements. To alleviate this problem, we introduce a new regularization layer consisting of channel-consistent local permutations (CLOP) of the feature maps. The proposed permutations induce robustness to spatial correlations and help prevent overfitting behaviors in RL. We demonstrate, on the OpenAI Procgen Benchmark, that RL agents trained with the CLOP layer exhibit robustness to visual changes and better generalization properties than agents trained using other state-of-the-art regularization techniques.",
    "One-sentence Summary": "We propose a simple yet effective layer increasing the generalization abilities of reinforcement learning agents"
  },
  {
    "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation",
    "url": "/forum?id=lL3lnMbR4WU",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Open-vocabulary recognition, Object detection, Knowledge distillation",
    "Abstract": "We aim at advancing open-vocabulary object detection, which detects objects described by arbitrary text inputs. The fundamental challenge is the availability of training data.  It is costly to further scale up the number of classes contained in existing object detection datasets. To overcome this challenge, we propose ViLD, a training method via Vision and Language knowledge Distillation. Our method distills the knowledge from a pretrained open-vocabulary image classification model (teacher) into a two-stage detector (student). Specifically, we use the teacher model to encode category texts and image regions of object proposals. Then we train a student detector, whose region embeddings of detected boxes are aligned with the text and image embeddings inferred by the teacher. We benchmark on LVIS by holding out all rare categories as novel categories that are not seen during training. ViLD obtains 16.1 mask APr with a ResNet-50 backbone, even outperforming the supervised counterpart by 3.8. When trained with a stronger teacher model ALIGN, ViLD achieves 26.3 APr. The model can directly transfer to other datasets without finetuning, achieving 72.2 AP50 on PASCAL VOC, 36.6 AP on COCO and 11.8 AP on Objects365. On COCO, ViLD outperforms the previous state-of-the-art (Zareian et al., 2021) by 4.8 on novel AP and 11.4 on overall AP. Code and demo are open-sourced at https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild.",
    "One-sentence Summary": "We propose using knowledge distillation to train an object detector that can detect objects with arbitrary text inputs, outperforming its supervised counterparts on rare categories."
  },
  {
    "title": "Model-Based Offline Meta-Reinforcement Learning with Regularization",
    "url": "/forum?id=EBn0uInJZWh",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "offline reinforcement learning, model-based reinforcement learning, behavior policy, Meta-reinforcement learning",
    "Abstract": "Existing offline reinforcement learning (RL) methods face a few major challenges, particularly the distributional shift between the learned policy and the behavior policy. Offline Meta-RL is emerging as a promising approach to address these challenges, aiming to learn an informative meta-policy from a collection of tasks. Nevertheless, as shown in our empirical studies, offline Meta-RL  could be outperformed  by offline single-task RL methods on tasks with good quality of datasets, indicating that a right balance has to be delicately calibrated  between \"exploring\" the out-of-distribution state-actions by following the meta-policy and \"exploiting\" the offline dataset by staying close to the behavior policy. Motivated by such empirical analysis, we propose model-based offline $\\text{\\bf Me}$ta-RL with $\\text{\\bf r}$egularized $\\text{\\bf P}$olicy $\\text{\\bf O}$ptimization (MerPO), which learns a meta-model for efficient task structure inference and an informative meta-policy for safe exploration of out-of-distribution state-actions. In particular, we devise a new meta-Regularized model-based Actor-Critic (RAC) method for within-task policy optimization, as a key building block  of MerPO, using both conservative policy evaluation and regularized policy improvement; and the intrinsic tradeoff therein is achieved via striking the right balance between two regularizers, one based on the behavior policy and the other on the meta-policy. We theoretically show that the learnt policy offers guaranteed improvement over both the behavior policy and the meta-policy, thus ensuring the performance improvement on new tasks via offline Meta-RL. Our experiments corroborate the superior performance of MerPO over existing offline Meta-RL methods.",
    "One-sentence Summary": "This paper proposes a novel offline Meta-RL algorithm with regularization, which has provable performance improvement and outperforms the existing baselines empirically."
  },
  {
    "title": "Scale Mixtures of Neural Network Gaussian Processes",
    "url": "/forum?id=YVPBh4k78iZ",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Network Gaussian Processes, Infinitely-wide Neural Networks, Scale Mixtures of Gaussians, Heavy-tailed Stochastic Processes",
    "Abstract": "Recent works have revealed that infinitely-wide feed-forward or recurrent neural networks of any architecture correspond to Gaussian processes referred to as NNGP. While these works have extended the class of neural networks converging to Gaussian processes significantly, however, there has been little focus on broadening the class of stochastic processes that such neural networks converge to. In this work, inspired by the scale mixture of Gaussian random variables, we propose the scale mixture of NNGP for which we introduce a prior distribution on the scale of the last-layer parameters. We show that simply introducing a scale prior on the last-layer parameters can turn infinitely-wide neural networks of any architecture into a richer class of stochastic processes. With certain scale priors, we obtain heavy-tailed stochastic processes, and in the case of inverse gamma priors, we recover Student\u2019s $t$ processes. We further analyze the distributions of the neural networks initialized with our prior setting and trained with gradient descents and obtain similar results as for NNGP. We present a practical posterior-inference algorithm for the scale mixture of NNGP and empirically demonstrate its usefulness on regression and classification tasks. In particular, we show that in both tasks, the heavy-tailed stochastic processes obtained from our framework are robust to out-of-distribution data.",
    "One-sentence Summary": "Infinitely-wide neural networks can be equivalent to scale mixtures of Gaussian processes."
  },
  {
    "title": "A Johnson-Lindenstrauss Framework for Randomly Initialized CNNs",
    "url": "/forum?id=YX0lrvdPQc",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "convolutional neural networks, Johnson-Lindenstrauss lemma, initialization, isometry, theory.",
    "Abstract": "How does the geometric representation of a dataset change after the application of each randomly initialized layer of a neural network? The celebrated Johnson-Lindenstrauss lemma answers this question for linear fully-connected neural networks (FNNs), stating that the geometry is essentially preserved. For FNNs with the ReLU activation, the angle between two input contracts according to a known mapping. The question for non-linear convolutional neural networks (CNNs) becomes much more intricate. To answer this question, we introduce a geometric framework. For linear CNNs, we show that the Johnson--Lindenstrauss lemma continues to hold, namely, that the angle between two inputs is preserved. For CNNs with ReLU activation, on the other hand, the behavior is richer: The angle between the outputs contracts, where the level of contraction depends on the nature of the inputs. In particular, after one layer, the geometry of natural images is essentially preserved, whereas for Gaussian correlated inputs, CNNs exhibit the same contracting behavior as FNNs with ReLU activation.",
    "One-sentence Summary": "We study how the geometric representation of a dataset change after the application of each randomly initialized layer of a neural network."
  },
  {
    "title": "Hindsight: Posterior-guided training of retrievers for improved open-ended generation",
    "url": "/forum?id=Vr_BTpw3wz",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "retrieval, generation, retrieval-augmented generation, open-ended generation, informative conversations, free-form QA, posterior distribution, ELBo",
    "Abstract": "Many text generation systems benefit from retrieving passages from a textual knowledge corpus (e.g., Wikipedia) and using them to generate the output. For open-ended generation tasks, like generating informative utterances in conversations, many varied passages $z$ are relevant to the context $x$ but few are relevant to the observed next utterance $y$ (label). For such tasks, existing methods (that jointly train the retriever and generator) underperform: during training the top-k context-relevant retrieved passages might not contain the label-relevant passage and the generator may hence not learn a preference to ground its generated output in them. We propose using an additional guide-retriever that also conditions on the observed label $y$ and \u201cin hindsight\u201d retrieves label-relevant passages during training. We maximize the evidence lower bound (ELBo) to jointly train the guide-retriever $Q(z|x,y)$ with the standard retriever $P_\\eta(z|x)$ and the generator $P_\\theta(y|x,z)$ and find that ELBo has better inductive biases than prior work. For informative conversations from the Wizard of Wikipedia dataset, with our posterior-guided training, the retriever finds passages with higher relevance in the top-10 (23% relative improvement), the generator\u2019s responses are more grounded in the retrieved passage (19% relative improvement) and the end-to-end system produces better overall output (6.4% relative improvement).",
    "One-sentence Summary": "We use a posterior-guide retriever to train a retrieval-augmented generation that performs well on open-ended one-to-many generation tasks."
  },
  {
    "title": "Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis",
    "url": "/forum?id=k9bx1EfHI_-",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph neural network, Self-supervision, Interpretability, Visualization, Neuroscience, Electroencephalography, Seizure, Epilepsy, Time Series",
    "Abstract": "Automated seizure detection and classification from electroencephalography (EEG) can greatly improve seizure diagnosis and treatment. However, several modeling challenges remain unaddressed in prior automated seizure detection and classification studies: (1) representing non-Euclidean data structure in EEGs, (2) accurately classifying rare seizure types, and (3) lacking a quantitative interpretability approach to measure model ability to localize seizures. In this study, we address these challenges by (1) representing the spatiotemporal dependencies in EEGs using a graph neural network (GNN) and proposing two EEG graph structures that capture the electrode geometry or dynamic brain connectivity, (2) proposing a self-supervised pre-training method that predicts preprocessed signals for the next time period to further improve model performance, particularly on rare seizure types, and (3) proposing a quantitative model interpretability approach to assess a model\u2019s ability to localize seizures within EEGs. When evaluating our approach on seizure detection and classification on a large public dataset (5,499 EEGs), we find that our GNN with self-supervised pre-training achieves 0.875 Area Under the Receiver Operating Characteristic Curve on seizure detection and 0.749 weighted F1-score on seizure classification, outperforming previous methods for both seizure detection and classification. Moreover, our self-supervised pre-training strategy significantly improves classification of rare seizure types (e.g. 47 points increase in combined tonic seizure accuracy over baselines). Furthermore, quantitative interpretability analysis shows that our GNN with self-supervised pre-training precisely localizes 25.4% focal seizures, a 21.9 point improvement over existing CNNs. Finally, by superimposing the identified seizure locations on both raw EEG signals and EEG graphs, our approach could provide clinicians with an intuitive visualization of localized seizure regions.",
    "One-sentence Summary": "Self-supervised graph neural networks for seizure detection and classification from EEG."
  },
  {
    "title": "Group-based Interleaved Pipeline Parallelism for Large-scale DNN Training",
    "url": "/forum?id=cw-EmNq5zfD",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Model parallelism, Pipeline parallelism, Distributed training",
    "Abstract": "The recent trend of using large-scale deep neural networks (DNN) to boost performance has propelled the development of the parallel pipelining technique for efficient DNN training, which has resulted in the development of several prominent pipelines such as GPipe, PipeDream, and PipeDream-2BW. However, the current leading pipeline PipeDream-2BW still suffers from two major drawbacks, i.e., the excessive memory redundancy and the delayed weight updates across all stages. In this work, we propose a novel pipeline named WPipe, which achieves better memory efficiency and fresher weight updates. WPipe uses a novel pipelining scheme that divides model partitions into two groups. It moves the forward pass of the next period of weight updates to the front of the backward pass of the current period of weight updates in the first group, retains the order in the second group, and updates each group alternatively. This scheme can eliminate half of the delayed gradients and memory redundancy compared to PipeDream-2BW. The experiments, which train large BERT language models, show that compared to PipeDream-2BW, WPipe achieves $1.4\\times$ acceleration and reduces the memory footprint by 36%, without nearly sacrificing any final model accuracy."
  },
  {
    "title": "Minimax Optimality (Probably) Doesn't Imply Distribution Learning for GANs",
    "url": "/forum?id=nc0ETaieux",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "theory of GANs, distribution learning, pseudorandom generators, cryptography",
    "Abstract": "Arguably the most fundamental question in the theory of generative adversarial networks (GANs) is to understand when GANs can actually learn the underlying distribution. Theoretical and empirical evidence (see e.g. Arora-Risteski-Zhang '18) suggest local optimality of the empirical training objective is insufficient, yet it does not rule out the possibility that achieving a true population minimax optimal solution might imply distribution learning. In this paper, we show that standard cryptographic assumptions imply that this stronger condition is still insufficient. Namely, we show that if local pseudorandom generators (PRGs) exist, then for a large family of natural target distributions, there are ReLU network generators of constant depth and poly size which take Gaussian random seeds so that (i) the output is far in Wasserstein distance from the target distribution, but (ii) no polynomially large Lipschitz discriminator ReLU network can detect this. This implies that even achieving a population minimax optimal solution to the Wasserstein GAN objective is likely insufficient for distribution learning. Our techniques reveal a deep connection between GANs and PRGs, which we believe will lead to further insights into the computational landscape of GANs.",
    "One-sentence Summary": "Under the standard crypto assumption that local pseudorandom generators exist, we show that even a global optimizer for the population WGAN objective need not be close to the true distribution."
  },
  {
    "title": "Offline Reinforcement Learning with Value-based Episodic Memory",
    "url": "/forum?id=RCZqv9NXlZ",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Offline Learning, Episodic Memory Control",
    "Abstract": "Offline reinforcement learning (RL) shows promise of applying RL to real-world problems by effectively utilizing previously collected data. Most existing offline RL algorithms use regularization or constraints to suppress extrapolation error for actions outside the dataset. In this paper, we adopt a different framework, which learns the V-function instead of the Q-function to naturally keep the learning procedure within the support of an offline dataset. To enable effective generalization while maintaining proper conservatism in offline learning, we propose Expectile V-Learning (EVL), which smoothly interpolates between the optimal value learning and behavior cloning. Further, we introduce implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. Together, we present a new offline method called Value-based Episodic Memory (VEM). We provide theoretical analysis for the convergence properties of our proposed VEM method, and empirical results in the D4RL benchmark show that our method achieves superior performance in most tasks, particularly in sparse-reward tasks.",
    "One-sentence Summary": "We propose a new offline RL method which uses expectile value learning and memory-based planning."
  },
  {
    "title": "MonoDistill: Learning Spatial Features for Monocular 3D Object Detection",
    "url": "/forum?id=C54V-xTWfi",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "3D object detection, monocular images",
    "Abstract": "3D object detection is a fundamental and challenging task for 3D scene understanding, and the monocular-based methods can serve as an economical alternative to the stereo-based or LiDAR-based methods. However, accurately locating objects in the 3D space from a single image is extremely difficult due to the lack of spatial cues. To mitigate this issue, we propose a simple and effective scheme to introduce the spatial information from LiDAR signals to the monocular 3D detectors, without introducing any extra cost in the inference phase. In particular, we first project the LiDAR signals into the image plane and align them with the RGB images. After that, we use the resulting data to train a 3D detector (LiDAR Net) using the same architecture as the baseline model. Finally, this LiDAR Net can serve as the teacher to transfer the learned knowledge to the baseline model. Experimental results show that the proposed method can significantly boost the performance of the baseline model and ranks the $1^{st}$ place among all monocular-based methods on the KITTI benchmark. Besides, extensive ablation studies are conducted, which further prove the effectiveness of each part of our designs and illustrate what the baseline model has learned from the LiDAR Net.",
    "One-sentence Summary": "We propose the MonoDistill, which introduces spatial cues to the monocular 3D detector based on the knowledge distillation mechanism."
  },
  {
    "title": "EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression",
    "url": "/forum?id=vkaMaq95_rX",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "graph neural networks, scalable GNN training, quantization, random projection",
    "Abstract": "Training Graph Neural Networks (GNNs) on large graphs is a fundamental challenge due to the high memory usage, which is mainly occupied by activations (e.g., node embeddings). Previous works usually focus on reducing the number of nodes retained in memory.\n        In parallel, unlike what has been developed for other types of neural networks, training with compressed activation maps is less explored for GNNs. This extension is notoriously difficult to implement due to the miss of necessary tools in common graph learning packages. To unleash the potential of this direction, we provide {  an} optimized GPU implementation which supports training GNNs with compressed activations. Based on the implementation, we propose a memory-efficient framework called ``EXACT'', which for the first time demonstrate the potential and evaluate the feasibility of training GNNs with compressed activations. We systematically analyze the trade-off among the memory saving, time overhead, and accuracy drop. In practice, EXACT can reduce the memory footprint of activations by up to $32\\times$ with $0.2$-$0.5\\%$ accuracy drop and $10$-$25\\%$ time overhead across different models and datasets. We implement EXACT as an extension for Pytorch Geometric and Pytorch. In practice, for Pytorch Geometric, EXACT can trim down the hardware requirement of training a three-layer full-batch GraphSAGE on \\textit{ogbn-products} from a 48GB GPU to a 12GB GPU."
  },
  {
    "title": "Provably convergent quasistatic dynamics for mean-field two-player zero-sum games",
    "url": "/forum?id=MP904TiHqJ-",
    "date": "28 Sept 2021 (modified: 15 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "quasistatic, minimax optimization, mixed Nash equilibrium, mean-field formulation",
    "Abstract": "In this paper, we study the problem of finding mixed Nash equilibrium for mean-field two-player zero-sum games. Solving this problem requires optimizing over two probability distributions. We consider a quasistatic Wasserstein gradient flow dynamics in which one probability distribution follows the Wasserstein gradient flow, while the other one is always at the equilibrium. Theoretical analysis are conducted on this dynamics, showing its convergence to the mixed Nash equilibrium under mild conditions. Inspired by the continuous dynamics of probability distributions, we derive a quasistatic Langevin gradient descent method with inner-outer iterations, and test the method on different problems, including training mixture of GANs.",
    "One-sentence Summary": "We propose a quasistatic Wasserstein flow for finding mixed Nash equilibriums, and prove its convergence."
  },
  {
    "title": "W-CTC: a Connectionist Temporal Classification Loss with Wild Cards",
    "url": "/forum?id=0RqDp8FCW5Z",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "CTC, wild cards, dynamic programing, partial alignment",
    "Abstract": "Connectionist Temporal Classification (CTC) loss is commonly used in sequence learning applications. For example, in Automatic Speech Recognition (ASR) task, the training data consists of pairs of audio (input sequence) and text (output label),without temporal alignment information. Standard CTC computes a loss by aggregating over all possible alignment paths, that map the entire sequence to the entire label (full alignment). However, in practice, there are often cases where the label is incomplete. Specifically, we solve the partial alignment problem where the label only matches a middle part of the sequence. This paper proposes the wild-card CTC (W-CTC) to address this issue, by padding wild-cards at both ends of the labels. Consequently, the proposed W-CTC improves the standard CTC via aggregating  over even more alignment paths. Evaluations on a number of tasks in speech and vision domains, show that the proposed W-CTC consistently outperforms the standard CTC by a large margin when label is incomplete. The effectiveness of the proposed method is further confirmed in an ablation study.",
    "One-sentence Summary": "This paper proposes wild-card CTC to solve the problem that the label only matches middle part of the sequence."
  },
  {
    "title": "Bandit Learning with Joint Effect of Incentivized Sampling, Delayed Sampling Feedback, and Self-Reinforcing User Preferences",
    "url": "/forum?id=Q83vFlie_Pr",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "In this paper, we consider a new multi-armed bandit (MAB) framework motivated by three common complications in online recommender systems in practice: (i) the platform (learning agent) cannot sample an intended product directly and has to incentivize customers to select this product (e.g., promotions and coupons); (ii) customer feedbacks are often received later than their selection times; and (iii) customer preferences among products are influenced and reinforced by historical feedbacks. From the platform's perspective, the goal of the MAB framework is to maximize total reward without incurring excessive incentive costs. A major challenge of this MAB framework is that the loss of information caused by feedback delay complicates both user preference evolution and arm incentivizing decisions, both of which are already highly non-trivial even by themselves. Toward this end, we first propose a policy called ``UCB-Filtering-with-Delayed-Feedback'' (UCB-FDF) policy for this new MAB framework. In our analysis, we consider delayed feedbacks that can have either arm-independent or arm-dependent distributions. In both cases, we allow unbounded support for the random delays, i.e., the random delay can be infinite. We show that the delay impacts in both cases can still be upper bounded by an additive penalty on both the regret and total incentive costs. This further implies that logarithmic regret and incentive cost growth rates are achievable under this new MAB framework. Experimental results corroborate our theoretical analysis on both regret and incentive costs."
  },
  {
    "title": "AdaAug: Learning Class- and Instance-adaptive Data Augmentation Policies",
    "url": "/forum?id=rWXfFogxRJN",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Data Augmentation, Automated Data Augmentation",
    "Abstract": "Data augmentation is an effective way to improve the generalization capability of modern deep learning models. However, the underlying augmentation methods mostly rely on handcrafted operations. Moreover, an augmentation policy useful to one dataset may not transfer well to other datasets. Therefore, Automated Data Augmentation (AutoDA) methods, like \\textit{AutoAugment} and \\textit{Population-based Augmentation}, have been proposed recently to automate the process of searching for optimal augmentation policies. However, the augmentation policies found are not adaptive to the dataset used, hindering the effectiveness of these AutoDA methods. In this paper, we propose a novel AutoDA method called \\texttt{AdaAug} to efficiently learn adaptive augmentation policies in a class-dependent and potentially instance-dependent manner. Our experiments show that the adaptive augmentation policies learned by our method transfer well to unseen datasets such as the Oxford Flowers, Oxford-IIT Pets, FGVC Aircraft, and Stanford Cars datasets when compared with other AutoDA baselines. In addition, our method also achieves state-of-the-art performance on the CIFAR-10, CIFAR-100, and SVHN datasets.",
    "One-sentence Summary": "We propose a novel Automated Data Augmentation method called \\texttt{AdaAug} to efficiently learn adaptive augmentation policies in a class-dependent and potentially instance-dependent manner."
  },
  {
    "title": "Unsupervised Semantic Segmentation by Distilling Feature Correspondences",
    "url": "/forum?id=SaKO6z6Hl0c",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Unsupervised Semantic Segmentation, Unsupervised Learning, Deep Features, Contrastive Learning, Visual Transformers, Cocostuff, Cityscapes, Semantic Segmentation",
    "Abstract": "Unsupervised semantic segmentation aims to discover and localize semantically meaningful categories within image corpora without any form of annotation. To solve this task, algorithms must produce features for every pixel that are both semantically meaningful and compact enough to form distinct clusters. Unlike previous works which achieve this with a single end-to-end framework, we propose to separate feature learning from cluster compactification. Empirically, we show that current unsupervised feature learning frameworks already generate dense features whose correlations are semantically consistent. This observation motivates us to design STEGO ($\\textbf{S}$elf-supervised $\\textbf{T}$ransformer with $\\textbf{E}$nergy-based $\\textbf{G}$raph $\\textbf{O}$ptimization), a novel framework that distills unsupervised features into high-quality discrete semantic labels. At the core of STEGO is a novel contrastive loss function that encourages features to form compact clusters while preserving their association pattern. STEGO yields a significant improvement over the prior state of the art, on both the CocoStuff ($\\textbf{+14 mIoU}$) and Cityscapes ($\\textbf{+9 mIoU}$) semantic segmentation challenges.",
    "One-sentence Summary": "We use the correlations between self-supervised visual features to perform unsupervised semantic segmentation."
  },
  {
    "title": "Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning",
    "url": "/forum?id=TqNsv1TuCX9",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Model Interpretability, Shapley Values, Search Engines, Information Retrieval, Visual Search, Similarity Learning, Metric Learning, Black-box explanations",
    "Abstract": "Visual search, recommendation, and contrastive similarity learning power technologies that impact billions of users worldwide. Modern model architectures can be complex and difficult to interpret, and there are several competing techniques one can use to explain a search engine's behavior. We show that the theory of fair credit assignment provides a unique axiomatic solution that generalizes several existing recommendation- and metric-explainability techniques in the literature. Using this formalism, we show when existing approaches violate \"fairness\" and derive methods that sidestep these shortcomings and naturally handle counterfactual information. More specifically, we show existing approaches implicitly approximate second-order Shapley-Taylor indices and extend CAM, GradCAM, LIME, SHAP, SBSM, and other methods to search engines. These extensions can extract pairwise correspondences between images from trained opaque-box models. We also introduce a fast kernel-based method for estimating Shapley-Taylor indices that require orders of magnitude fewer function evaluations to converge. Finally, we show that these game-theoretic measures yield more consistent explanations for image similarity architectures.",
    "One-sentence Summary": "We show that cooperative game theory provides an axiomatic characterization of model interpretability for visual search, retrieval, and similarity learning architectures"
  },
  {
    "title": "Graph-Relational Domain Adaptation",
    "url": "/forum?id=kcwyXtt7yDJ",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graphs, Network Topology, Transfer Learning, Domain Adaptation, Adversarial Learning",
    "Abstract": "Existing domain adaptation methods tend to treat every domain equally and align them all perfectly. Such uniform alignment ignores topological structures among different domains; therefore it may be beneficial for nearby domains, but not necessarily for distant domains. In this work, we relax such uniform alignment by using a domain graph to encode domain adjacency, e.g., a graph of states in the US with each state as a domain and each edge indicating adjacency, thereby allowing domains to align flexibly based on the graph structure. We generalize the existing adversarial learning framework with a novel graph discriminator using encoding-conditioned graph embeddings. Theoretical analysis shows that at equilibrium, our method recovers classic domain adaptation when the graph is a clique, and achieves non-trivial alignment for other types of graphs. Empirical results show that our approach successfully generalizes uniform alignment, naturally incorporates domain information represented by graphs, and improves upon existing domain adaptation methods on both synthetic and real-world datasets."
  },
  {
    "title": "Revisit Kernel Pruning with Lottery Regulated Grouped Convolutions",
    "url": "/forum?id=LdEhiMG9WLO",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "structured pruning, efficient computing, parallel computing, grouped convolution, lottery ticket, weights shifting",
    "Abstract": "Structured pruning methods which are capable of delivering a densely pruned network are among the most popular techniques in the realm of neural network pruning, where most methods prune the original network at a filter or layer level. Although such methods may provide immediate compression and acceleration benefits, we argue that the blanket removal of an entire filter or layer may result in undesired accuracy loss. In this paper, we revisit the idea of kernel pruning (to only prune one or several $k \\times k$ kernels out of a 3D-filter), a heavily overlooked approach under the context of structured pruning. This is because kernel pruning will naturally introduce sparsity to filters within the same convolutional layer \u2014 thus, making the remaining network no longer dense. We address this problem by proposing a versatile grouped pruning framework where we first cluster filters from each convolutional layer into equal-sized groups, prune the grouped kernels we deem unimportant from each filter group, then permute the remaining filters to form a densely grouped convolutional architecture (which also enables the parallel computing capability) for fine-tuning. Specifically, we consult empirical findings from a series of literature regarding $\\textit{Lottery Ticket Hypothesis}$ to determine the optimal clustering scheme per layer, and develop a simple yet cost-efficient greedy approximation algorithm to determine which group kernels to keep within each filter group. Extensive experiments also demonstrate our method often outperforms comparable SOTA methods with lesser data augmentation needed, smaller fine-tuning budget required, and sometimes even much simpler procedure executed (e.g., one-shot v. iterative). Please refer to our GitHub repository (https://github.com/choH/lottery_regulated_grouped_kernel_pruning) for code.",
    "One-sentence Summary": "A simple yet effective structured pruning framework based on kernel pruning, weights shifting, and grouped convolutions."
  },
  {
    "title": "Bi-linear Value Networks for Multi-goal Reinforcement Learning",
    "url": "/forum?id=LedObtLmCjS",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multi-goal reinforcement learning, universal value function approximator",
    "Abstract": "Universal value functions are a core component of off-policy multi-goal reinforcement learning. \n        The de-facto paradigm is to approximate Q(s, a, g) using monolithic neural networks which lack inductive biases to produce complex interactions between the state s and the goal g. In this work, we propose a bilinear decomposition that represents the Q-value via a low-rank approximation in the form of a dot product between two vector fields. The first vector field, f(s, a), captures the environment's local dynamics at the state s; whereas the second component, \u03d5(s, g), captures the global relationship between the current state and the goal.\n        We show that our bilinear decomposition scheme improves sample efficiency over the original monolithic value approximators, and transfer better to unseen goals. We demonstrate significant learning speed-up over a variety of tasks on a simulated robot arm, and the challenging task of dexterous manipulation with a Shadow hand.",
    "One-sentence Summary": "We propose a bilinear value function for multi-goal reinforcement learning and show superior sample efficiency and generalizability."
  },
  {
    "title": "No One Representation to Rule Them All: Overlapping Features of Training Methods",
    "url": "/forum?id=BK-4qbGgIE3",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Representation Learning, Understanding Deep Learning, Deep Phenomena, Diversity, Novelty, Features, Training Methodologies, Contrastive Learning",
    "Abstract": "Despite being able to capture a range of features of the data, high accuracy models trained with supervision tend to make similar predictions. This seemingly implies that high-performing models share similar biases regardless of training methodology, which would limit ensembling benefits and render low-accuracy models as having little practical use. Against this backdrop, recent work has developed quite different training techniques, such as large-scale contrastive learning, yielding competitively high accuracy on generalization and robustness benchmarks. This motivates us to revisit the assumption that models necessarily learn similar functions. We conduct a large-scale empirical study of models across hyper-parameters, architectures, frameworks, and datasets. We find that model pairs that diverge more in training methodology display categorically different generalization behavior, producing increasingly uncorrelated errors. We show these models specialize in subdomains of the data, leading to higher ensemble performance: with just 2 models (each with ImageNet accuracy \\~76.5\\%), we can create ensembles with 83.4\\% (+7\\% boost). Surprisingly, we find that even significantly low-accuracy models can be used to improve high-accuracy models. Finally, we show diverging training methodology yield representations that capture overlapping (but not supersetting) feature sets which, when combined, lead to increased downstream performance.",
    "One-sentence Summary": "We study the effect of training methodology on prediction diversity and show that diverging training setups produce diverse features, uncorrelated errors, and more efficient ensembles."
  },
  {
    "title": "Generalized Kernel Thinning",
    "url": "/forum?id=IfNu7Dr-3fQ",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "coresets, maximum mean discrepancy, Markov chain Monte Carlo, reproducing kernel Hilbert space, thinning, compression",
    "Abstract": "The kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) compresses a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space (RKHS) and leveraging a less smooth square-root kernel. Here we provide four improvements.  First, we show that KT applied directly to the target RKHS yields tighter, dimension-free guarantees for any kernel, any distribution, and any fixed function in the RKHS. Second, we show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy (MMD) guarantees comparable to or better than those of square-root KT without making explicit use of a square-root kernel.  Third, we prove that KT with a fractional power kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth kernels, like Laplace and Matern, that do not have square-roots. Fourth, we establish that KT applied to a sum of the target and power kernels (a procedure we call KT+) simultaneously inherits the improved MMD guarantees of power KT and the tighter individual function guarantees of target KT.  In our experiments with target KT and KT+, we witness significant improvements in integration error even in 100 dimensions and when compressing challenging differential equation posteriors.",
    "One-sentence Summary": "By generalizing kernel thinning, we develop new tools for compressing distributions more effectively than i.i.d. sampling and establish new dimension-free, $O(\\sqrt{\\log n/n})$ improvements over the usual $n^{-1/4}$ Monte Carlo integration error."
  },
  {
    "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?",
    "url": "/forum?id=zf_Ll3HZWgy",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Most existing Vision-and-Language (V&L) models rely on pre-trained visual encoders, using a relatively small set of manually-annotated data (as compared to web-crawled data), to perceive the visual world. However, it has been observed that large-scale pretraining usually can result in better generalization performance, e.g., CLIP (Contrastive Language-Image Pre-training), trained on a massive amount of image-caption pairs, has shown a strong zero-shot capability on various vision tasks. To further study the advantage brought by CLIP, we propose to use CLIP as the visual encoder in various V&L models in two typical scenarios: 1) plugging CLIP into task-specific fine-tuning; 2) combining CLIP with V&L pre-training and transferring to downstream tasks. We show that CLIP significantly outperforms widely-used visual encoders trained with in-domain annotated data, such as BottomUp-TopDown. We achieve competitive or better results on diverse V&L tasks, while establishing new state-of-the-art results on Visual Question Answering, Visual Entailment, and V&L Navigation tasks."
  },
  {
    "title": "Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect",
    "url": "/forum?id=3tbDrs77LJ5",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "large learning rate, gradient descent, matrix factorization, implicit regularization, convergence, balancing, alignment",
    "Abstract": "Recent empirical advances show that training deep models with large learning rate often improves generalization performance. However, theoretical justifications on the benefits of large learning rate are highly limited, due to challenges in analysis. In this paper, we consider using Gradient Descent (GD) with a large learning rate on a homogeneous matrix factorization problem, i.e., $\\min_{X, Y} \\|A - XY^\\top\\|_{\\sf F}^2$. We prove a convergence theory for constant large learning rates well beyond $2/L$, where $L$ is the largest eigenvalue of Hessian at the initialization. Moreover, we rigorously establish an implicit bias of GD induced by such a large learning rate, termed `balancing', meaning that magnitudes of $X$ and $Y$ at the limit of GD iterations will be close even if their initialization is significantly unbalanced. Numerical experiments are provided to support our theory.",
    "One-sentence Summary": "Large learning rate well beyond 2/L provably induces an implicit regularization effect of balancing in gradient descent for matrix factorization."
  },
  {
    "title": "Demystifying Limited Adversarial Transferability in Automatic Speech Recognition Systems",
    "url": "/forum?id=l5aSHXi8jG5",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "optimization attacks, transferability, adversarial machine learning",
    "Abstract": "The targeted transferability of adversarial samples enables attackers to exploit black-box models in the real-world. The most popular method to produce these adversarial samples is optimization attacks, which have been shown to achieve a high level of transferability in some domains. However, recent research has demonstrated that these attack samples fail to transfer when applied to Automatic Speech Recognition Systems (ASRs). In this paper, we investigate factors preventing this transferability via exhaustive experimentation. To do so, we perform an ablation study on each stage of the ASR pipeline. We discover and quantify six factors (i.e., input type, MFCC, RNN, output type, and vocabulary and sequence sizes) that impact the targeted transferability of optimization attacks against ASRs. Future research can leverage our findings to build ASRs that are more robust to other transferable attack types (e.g., signal processing attacks), or to modify architectures in other domains to reduce their exposure to targeted transferability of optimization attacks.",
    "One-sentence Summary": "Uncover factors that limit transferability of the popular optimization attacks in the automatic speech recognition systems."
  },
  {
    "title": "PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks with Pipelined Feature Communication",
    "url": "/forum?id=kSwqMH0zn1F",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Graph Convolutional Networks, Distributed Training, Asynchronous Training, Full-Graph Training, Large-Graph Training, Stale Features",
    "Abstract": "Graph Convolutional Networks (GCNs) is the state-of-the-art method for learning graph-structured data, and training large-scale GCNs requires distributed training across multiple accelerators such that each accelerator is able to hold a partitioned subgraph. However, distributed GCN training incurs prohibitive overhead of communicating node features and feature gradients among partitions for every GCN layer during each training iteration, limiting the achievable training efficiency and model scalability. To this end, we propose PipeGCN, a simple yet effective scheme that hides the communication overhead by pipelining inter-partition communication with intra-partition computation. It is non-trivial to pipeline for efficient GCN training, as communicated node features/gradients will become stale and thus can harm the convergence, negating the pipeline benefit. Notably, little is known regarding the convergence rate of GCN training with both stale features and stale feature gradients. This work not only provides a theoretical convergence analysis but also finds the convergence rate of PipeGCN to be close to that of the vanilla distributed GCN training without any staleness. Furthermore, we develop a smoothing method to further improve PipeGCN's convergence. Extensive experiments show that PipeGCN can largely boost the training throughput (1.7\u00d7~28.5\u00d7) while achieving the same accuracy as its vanilla counterpart and existing full-graph training methods. The code is available at https://github.com/RICE-EIC/PipeGCN."
  },
  {
    "title": "Learning Neural Contextual Bandits through Perturbed Rewards",
    "url": "/forum?id=7inCJ3MhXt3",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "contextual bandit, neural bandit",
    "Abstract": "Thanks to the power of representation learning, neural contextual bandit algorithms demonstrate remarkable performance improvement against their classical counterparts. But because their exploration has to be performed in the entire neural network parameter space to obtain nearly optimal regret, the resulting computational cost is prohibitively high.  \n        We propose to perturb the rewards when updating the neural network to eliminate the need of explicit exploration and the corresponding computational overhead. We prove that a $\\tilde{O}(\\tilde{d}\\sqrt{T})$ regret upper bound is still achievable under standard regularity conditions, where $T$ is the number of rounds of interactions and $\\tilde{d}$ is the effective dimension of a neural tangent kernel matrix. \n        Extensive comparisons with several benchmark contextual bandit algorithms, including two recent neural contextual bandit models, demonstrate the effectiveness and computational efficiency of our proposed neural bandit algorithm."
  },
  {
    "title": "Adversarial Unlearning of Backdoors via Implicit Hypergradient",
    "url": "/forum?id=MeeQkFYVbzW",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "backdoor defense, backdoor removal, backdoor, minimax, implicit hypergradient",
    "Abstract": "We propose a minimax formulation for removing backdoors from a given poisoned model based on a small set of clean data. This formulation encompasses much of prior work on backdoor removal. We propose the Implicit Backdoor Adversarial Unlearning (I-BAU) algorithm to solve the minimax. Unlike previous work, which breaks down the minimax into separate inner and outer problems, our algorithm utilizes the implicit hypergradient to account for the interdependence between inner and outer optimization. We theoretically analyze its convergence and the generalizability of the robustness gained by solving minimax on clean data to unseen test data. In our evaluation, we compare I-BAU with six state-of-art backdoor defenses on eleven backdoor attacks over two datasets and various attack settings, including the common setting where the attacker targets one class as well as important but underexplored settings where multiple classes are targeted. I-BAU's performance is comparable to and most often significantly better than the best baseline. Particularly, its performance is more robust to the variation on triggers, attack settings, poison ratio, and clean data size. Moreover, I-BAU requires less computation to take effect; particularly, it is more than $13\\times$ faster than the most efficient baseline in the single-target attack setting. Furthermore, it can remain effective in the extreme case where the defender can only access 100 clean samples---a setting where all the baselines fail to produce acceptable results.",
    "One-sentence Summary": "A minimax formulation of backdoor removal and an implicit gradient-based solver surpasses the state-of-art methods' best results in higher efficacy, efficiency, robustness to variations in triggers, settings, poison ratio, and clean data size."
  },
  {
    "title": "Maximizing Ensemble Diversity in Deep Reinforcement Learning",
    "url": "/forum?id=hjd-kcpDpf2",
    "date": "28 Sept 2021 (modified: 06 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Ensemble Based Reinforcement Learning, Ensemble Diversity",
    "Abstract": "Modern deep reinforcement learning (DRL) has been successful in solving a range of challenging sequential decision-making problems. Most of these algorithms use an ensemble of neural networks as their backbone structure and benefit from the diversity among the neural networks to achieve optimal results. Unfortunately, the members of the ensemble can converge to the same point either the parametric space or representation space during the training phase, therefore, losing all the leverage of an ensemble. In this paper, we describe Maximize Ensemble Diversity in Reinforcement Learning (MED-RL), a set of regularization methods inspired from the economics and consensus optimization to improve diversity in the ensemble-based deep reinforcement learning methods by encouraging inequality between the networks during training. We integrated MED-RL in five of the most common ensemble-based deep RL algorithms for both continuous and discrete control tasks and evaluated on six Mujoco environments and six Atari games. Our results show that MED-RL augmented algorithms outperform their un-regularized counterparts significantly and in some cases achieved more than 300$\\%$ in performance gains.",
    "One-sentence Summary": "Maximizing diversity in neural network improves performance ensemble based reinforcement learning"
  },
  {
    "title": "Graph Neural Networks with Learnable Structural and Positional Representations",
    "url": "/forum?id=wTTjnvGphYj",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "graph neural networks, graph representation learning, transformers, positional encoding",
    "Abstract": "Graph neural networks (GNNs) have become the standard learning architectures for graphs. GNNs have been applied to numerous domains ranging from quantum chemistry, recommender systems to knowledge graphs and natural language processing. A major issue with arbitrary graphs is the absence of canonical positional information of nodes, which decreases the representation power of GNNs to distinguish e.g. isomorphic nodes and other graph symmetries. An approach to tackle this issue is to introduce Positional Encoding (PE) of nodes, and inject it into the input layer, like in Transformers. Possible graph PE are Laplacian eigenvectors. In this work, we propose to decouple structural and positional representations to make easy for the network to learn these two essential properties. We introduce a novel generic architecture which we call \\texttt{LSPE} (Learnable Structural and Positional Encodings). We investigate several sparse and fully-connected (Transformer-like) GNNs, and observe a performance increase for molecular datasets, from $1.79\\%$ up to $64.14\\%$ when considering learnable PE for both GNN classes.",
    "One-sentence Summary": "We propose a novel GNN architecture (LSPE) which decouples structural and positional representations to make easy for the network to learn the two essential properties."
  },
  {
    "title": "Zero-Shot Self-Supervised Learning for MRI Reconstruction",
    "url": "/forum?id=085y6YPaYjP",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Zero-shot learning, Self-supervised learning, MRI Reconstruction, Transfer learning, Physics-guided deep learning",
    "Abstract": "Deep learning (DL) has emerged as a powerful tool for accelerated MRI reconstruction, but often necessitates a database of fully-sampled measurements for training. Recent self-supervised and unsupervised learning approaches enable training without fully-sampled data. However, a database of undersampled measurements may not be available in many scenarios, especially for scans involving contrast or translational acquisitions in development. Moreover, recent studies show that database-trained models may not generalize well when the unseen measurements differ in terms of sampling pattern, acceleration rate, SNR, image contrast, and anatomy. Such challenges necessitate a new methodology to enable subject-specific DL MRI reconstruction without external training datasets, since it is clinically imperative to provide high-quality reconstructions that can be used to identify lesions/disease for $\\textit{every individual}$. In this work, we propose a zero-shot self-supervised learning approach to perform subject-specific accelerated DL MRI reconstruction to tackle these issues. The proposed approach partitions the available measurements from a single scan into three disjoint sets. Two of these sets are used to enforce data consistency and define loss during training for self-supervision, while the last set serves to self-validate, establishing an early stopping criterion. In the presence of models pre-trained on a database with different image characteristics, we show that the proposed approach can be combined with transfer learning for faster convergence time and reduced computational complexity.",
    "One-sentence Summary": "Zero-shot self-supervised learning to perform robust subject-specific MRI reconstruction"
  },
  {
    "title": "Policy Smoothing for Provably Robust Reinforcement Learning",
    "url": "/forum?id=mwdfai8NBrJ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Provable Adversarial Robustness, Randomized Smoothing",
    "Abstract": "The study of provable adversarial robustness for deep neural networks (DNNs) has mainly focused on $\\textit{static}$ supervised learning tasks such as image classification. However, DNNs have been used extensively in real-world $\\textit{adaptive}$ tasks such as reinforcement learning (RL), making such systems vulnerable to adversarial attacks as well. Prior works in provable robustness in RL seek to certify the behaviour of the victim policy at every time-step against a non-adaptive adversary using methods developed for the static setting. But in the real world, an RL adversary can infer the defense strategy used by the victim agent by observing the states, actions, etc. from previous time-steps and adapt itself to produce stronger attacks in future steps (e.g., by focusing more on states critical to the agent's performance). We present an efficient procedure, designed specifically to defend against an adaptive RL adversary, that can directly certify the total reward without requiring the policy to be robust at each time-step. Focusing on randomized smoothing based defenses, our main theoretical contribution is to prove an $\\textit{adaptive version}$ of the Neyman-Pearson Lemma -- a key lemma for smoothing-based certificates -- where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. Building on this result, we propose $\\textit{policy smoothing}$ where the agent adds a Gaussian noise to its observation at each time-step before passing it through the policy function. Our robustness certificates guarantee that the final total reward obtained by policy smoothing remains above a certain threshold, even though the actions at intermediate time-steps may change under the attack. We show that our certificates are $\\textit{tight}$ by constructing a worst-case scenario that achieves the bounds derived in our analysis. Our experiments on various environments like Cartpole, Pong, Freeway and Mountain Car show that our method can yield meaningful robustness guarantees in practice.",
    "One-sentence Summary": "A provable adversarial robustness technique for reinforcement learning."
  },
  {
    "title": "The Close Relationship Between Contrastive Learning and Meta-Learning",
    "url": "/forum?id=gICys3ITSmj",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "meta-learning, contrastive learning, self-supervised learning",
    "Abstract": "Contrastive learning has recently taken off as a paradigm for learning from unlabeled data. In this paper, we discuss the close relationship between contrastive learning and meta-learning under a certain task distribution. We complement this observation by showing that established meta-learning methods, such as Prototypical Networks, achieve comparable performance to SimCLR when paired with this task distribution. This relationship can be leveraged by taking established techniques from meta-learning, such as task-based data augmentation, and showing that they benefit contrastive learning as well. These tricks also benefit state-of-the-art self-supervised learners without using negative pairs such as BYOL, which achieves 94.6\\% accuracy on CIFAR-10 using a self-supervised ResNet-18 feature extractor trained with our meta-learning tricks.  We conclude that existing advances designed for contrastive learning or meta-learning can be exploited to benefit the other, and it is better for contrastive learning researchers to take lessons from the meta-learning literature (and vice-versa) than to reinvent the wheel.",
    "One-sentence Summary": "We discuss the close relationship between contrastive learning and meta-learning, and we propose a meta-learning framework for self-supervised learning (SSL) along with meta-specific methods to improve contrastive learning performance for SSL."
  },
  {
    "title": "Towards Understanding Generalization via Decomposing Excess Risk Dynamics",
    "url": "/forum?id=rS9-7AuPKWK",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "generalization, excess risk, stability, dynamics",
    "Abstract": "Generalization is one of the fundamental issues in machine learning. However, traditional techniques like uniform convergence may be unable to explain generalization under overparameterization \\citep{nagarajan2019uniform}. As alternative approaches, techniques based on stability analyze the training dynamics and derive algorithm-dependent generalization bounds. Unfortunately, the stability-based bounds are still far from explaining the surprising generalization in deep learning since neural networks usually suffer from unsatisfactory stability. This paper proposes a novel decomposition framework to improve the stability-based bounds via a more fine-grained analysis of the signal and noise, inspired by the observation that neural networks converge relatively slowly when fitting noise (which indicates better stability). Concretely, we decompose the excess risk dynamics and apply the stability-based bound only on the noise component. The decomposition framework performs well in both linear regimes (overparameterized linear regression) and non-linear regimes (diagonal matrix recovery). Experiments on neural networks verify the utility of the decomposition framework.",
    "One-sentence Summary": "This paper proposes a decomposition framework to improve the stability-based bound."
  },
  {
    "title": "Graph Auto-Encoder via Neighborhood Wasserstein Reconstruction",
    "url": "/forum?id=ATUh28lnSuW",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "graph representation learning, unsupervised learning, autoencoder, wasserstein distance",
    "Abstract": "Graph neural networks (GNNs) have drawn significant research attention recently, mostly under the setting of semi-supervised learning. When task-agnostic representations are preferred or supervision is simply unavailable, the auto-encoder framework comes in handy with a natural graph reconstruction objective for unsupervised GNN training. However, existing graph auto-encoders are designed to reconstruct the direct links, so GNNs trained in this way are only optimized towards proximity-oriented graph mining tasks, and will fall short when the topological structures matter. In this work, we revisit the graph encoding process of GNNs which essentially learns to encode the neighborhood information of each node into an embedding vector, and propose a novel graph decoder to reconstruct the entire neighborhood information regarding both proximity and structure via Neighborhood Wasserstein Reconstruction (NWR). Specifically, from the GNN embedding of each node, NWR jointly predicts its node degree and neighbor feature distribution, where the distribution prediction adopts an optimal-transport loss based on the Wasserstein distance. Extensive experiments on both synthetic and real-world network datasets show that the unsupervised node representations learned with NWR have much more advantageous in structure-oriented graph mining tasks, while also achieving competitive performance in proximity-oriented ones.",
    "One-sentence Summary": "We study unsupervised graph representation learning and propose a novel decoder based on neighborhood reconstruction with Wasserstein distance to facilitate the GNN encoding of entire neighborhood information beyond direct links."
  },
  {
    "title": "FairCal: Fairness Calibration for Face Verification",
    "url": "/forum?id=nRj0NcmSuxb",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "face verification, bias, fairness, clustering, calibration",
    "Abstract": "Despite being widely used, face recognition models suffer from bias: the probability of a false positive (incorrect face match) strongly depends on sensitive attributes such as the ethnicity of the face. As a result, these models can disproportionately and negatively impact minority groups, particularly when used by law enforcement. The majority of bias reduction methods have several drawbacks: they use an end-to-end retraining approach, may not be feasible due to privacy issues, and often reduce accuracy. An alternative approach is post-processing methods that build fairer decision classifiers using the features of pre-trained models, thus avoiding the cost of retraining. However, they still have drawbacks: they reduce accuracy (AGENDA, FTC), or require retuning for different false positive rates (FSN). In this work, we introduce the Fairness Calibration (FairCal) method, a post-training approach that simultaneously: (i) increases model accuracy (improving the state-of-the-art), (ii) produces fairly-calibrated probabilities, (iii) significantly reduces the gap in the false positive rates, (iv) does not require knowledge of the sensitive attribute, and (v) does not require retraining, training an additional model or retuning. We apply it to the task of Face Verification, and obtain state-of-the-art results with all the above advantages.",
    "One-sentence Summary": "We calibrate face verification models for fairness, without use of the sensitive attribute, without the need for retraining. This leads to SOTA accuracy, fairness calibration, and equal FPRs across subgroups."
  },
  {
    "title": "Cross-Lingual Transfer with Class-Weighted Language-Invariant Representations",
    "url": "/forum?id=k7-s5HSSPE5",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "cross-lingual transfer, unsupervised cross-lingual learning, multilingual neural language model, domain adaptation",
    "Abstract": "Recent advances in neural modeling have produced deep multilingual language models capable of extracting cross-lingual knowledge from non-parallel texts and enabling zero-shot downstream transfer. While their success is often attributed to shared representations, quantitative analyses are limited. Towards a better understanding, through empirical analyses, we show that the invariance of feature representations across languages\u2014an effect of shared representations\u2014strongly correlates with transfer performance. We also observe that distributional shifts in class priors between source and target language task data negatively affect performance, a largely overlooked issue that could cause negative transfer with existing unsupervised approaches. Based on these findings, we propose and evaluate a method for unsupervised transfer, called importance-weighted domain alignment (IWDA), that performs representation alignment with prior shift estimation and correction using unlabeled target language task data. Experiments demonstrate its superiority under large prior shifts, and show further performance gains when combined with existing semi-supervised learning techniques.",
    "One-sentence Summary": "We propose an importance-weighted domain adaptation method for unsupervised cross-lingual learning that is effective at correcting class prior shifts, a distributional property that negatively affects transfer performance."
  },
  {
    "title": "ComPhy: Compositional Physical Reasoning of Objects and Events from Videos",
    "url": "/forum?id=PgNEYaIc81Q",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Compositional, Intutive Physics, Video Reasoning, Neural-Symbolic",
    "Abstract": "Objects' motions in nature are governed by complex interactions and their properties. While some properties, such as shape and material, can be identified via the object's visual appearances, others like mass and electric charge are not directly visible. The compositionality between the visible and hidden properties poses unique challenges for AI models to reason from the physical world, whereas humans can effortlessly infer them with limited observations. Existing studies on video reasoning mainly focus on visually observable elements such as object appearance, movement, and contact interaction. In this paper, we take an initial step to highlight the importance of inferring the hidden physical properties not directly observable from visual appearances, by introducing the Compositional Physical Reasoning (ComPhy) dataset. For a given set of objects, ComPhy includes few videos of them moving and interacting under different initial conditions. The model is evaluated based on its capability to unravel the compositional hidden properties, such as mass and charge, and use this knowledge to answer a set of questions posted on one of the videos. Evaluation results of several state-of-the-art video reasoning models on ComPhy show unsatisfactory performance as they fail to capture these hidden properties. We further propose an oracle neural-symbolic framework named Compositional Physics Learner (CPL), combining visual perception, physical property learning, dynamic prediction, and symbolic execution into a unified framework. CPL can effectively identify objects' physical properties from their interactions and predict their dynamics to answer questions.",
    "One-sentence Summary": "We introduce a new dataset for Compositional Physical Reasoning"
  },
  {
    "title": "An Information Fusion Approach to Learning with Instance-Dependent Label Noise",
    "url": "/forum?id=ecH2FKaARUp",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Instance-dependent label noise, posterior transition matrix, statiscally consistent classifier",
    "Abstract": "Instance-dependent label noise (IDN) widely exists in real-world datasets and usually misleads the training of deep neural networks. Noise transition matrix (NTM) (i.e., the probability that clean labels flip into noisy labels) is used to characterize the label noise and can be adopted to bridge the gap between clean and noisy underlying data distributions. However, most instances are long-tail, i.e., the number of occurrences of each instance is usually limited, which leads to the gap between the underlying distribution and the empirical distribution. Therefore, the genuine problem caused by IDN is \\emph{empirical}, instead of underlying, \\emph{data distribution mismatch} during training. To directly tackle the empirical distribution mismatch problem, we propose \\emph{posterior transition matrix} (PTM) to posteriorly model label noise given limited observed noisy labels, which achieves \\emph{statistically consistent classifiers}. Note that even if an instance is corrupted by the same NTM, the intrinsic randomness incurs different noisy labels, and thus requires different correction methods. Motivated by this observation, we propose an \\textbf{I}nformation \\textbf{F}usion (IF) approach to fine-tune the NTM based on the estimated PTM. Specifically, we adopt the noisy labels and model predicted probabilities to estimate the PTM and then correct the NTM in \\emph{forward propagation}. Empirical evaluations on synthetic and real-world datasets demonstrate that our method is superior to the state-of-the-art approaches, and achieves more stable training for instance-dependent label noise.",
    "One-sentence Summary": "This work is the first time to realize and bridge the gap between clean and noisy empirical distribution mismatch."
  },
  {
    "title": "On Redundancy and Diversity in Cell-based Neural Architecture Search",
    "url": "/forum?id=rFJWoYoxrDB",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "NAS, machine learning architectures, AutoML",
    "Abstract": "Searching for the architecture cells is a dominant paradigm in NAS. However, little attention has been devoted to the analysis of the cell-based search spaces even though it is highly important for the continual development of NAS. \n        In this work, we conduct an empirical post-hoc analysis of architectures from the popular cell-based search spaces and find that the existing search spaces contain a high degree of redundancy: the architecture performance is less sensitive to changes at large parts of the cells, and universally adopted design rules, like the explicit search for a reduction cell, significantly increase the complexities but have very limited impact on the performance.\n        Across architectures found by a diverse set of search strategies, we consistently find that the parts of the cells that do matter for architecture performance often follow similar and simple patterns. By constraining cells to include these patterns, randomly sampled architectures can match or even outperform the state of the art.\n        These findings cast doubts into our ability to discover truly novel architectures in the existing cell-based search spaces and, inspire our suggestions for improvement to guide future NAS research.\n        Code is available at https://github.com/xingchenwan/cell-based-NAS-analysis.",
    "One-sentence Summary": "We analyse and explore the redundancies and diversity of popular cell-based search spaces in NAS."
  },
  {
    "title": "Deep Learning without Shortcuts: Shaping the Kernel with Tailored Rectifiers",
    "url": "/forum?id=U0k7XNTiFEq",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Network Training, Kernel Approximation for Neural Networks, Neural Network Initialization, Generalization",
    "Abstract": "Training very deep neural networks is still an extremely challenging task. The common solution is to use shortcut connections and normalization layers, which are both crucial ingredients in the popular ResNet architecture. However, there is strong evidence to suggest that ResNets behave more like ensembles of shallower networks than truly deep ones. Recently, it was shown that deep vanilla networks (i.e.~networks without normalization layers or shortcut connections) can be trained as fast as ResNets by applying certain transformations to their activation functions. However, this method (called Deep Kernel Shaping) isn't fully compatible with ReLUs, and produces networks that overfit significantly more than ResNets on ImageNet. In this work, we rectify this situation by developing a new type of transformation that is fully compatible with a variant of ReLUs -- Leaky ReLUs. We show in experiments that our method, which introduces negligible extra computational cost, achieves validation accuracies with deep vanilla networks that are competitive with ResNets (of the same width/depth), and significantly higher than those obtained with the Edge of Chaos (EOC) method. And unlike with EOC, the validation accuracies we obtain do not get worse with depth."
  },
  {
    "title": "Variational autoencoders in the presence of low-dimensional data: landscape and implicit bias",
    "url": "/forum?id=y_op4lLLaWL",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "variational autoencoders, encoder, optima, stability, low-dimensional manifold",
    "Abstract": "Variational Autoencoders (VAEs) are one of the most commonly used generative models, particularly for image data. A prominent difficulty in training VAEs is data that is supported on a lower dimensional manifold. Recent work by Dai and Wipf (2020) proposes a two-stage training algorithm for VAEs, based on a conjecture that in standard VAE training the generator will converge to a solution with 0 variance which is correctly supported on the ground truth manifold. They gave partial support for this conjecture by showing that some optima of the VAE loss do satisfy this property, but did not analyze the training dynamics.  In this paper, we show that for linear encoders/decoders, the conjecture is true\u2014that is the VAE training does recover a generator with support equal to the ground truth manifold\u2014and does so due to an implicit bias of gradient descent rather than merely the VAE loss itself. In the nonlinear case, we show that VAE training frequently learns a higher-dimensional manifold which is a superset of the ground truth manifold.",
    "One-sentence Summary": "We analyze the landscape and implicit optimization bias of VAEs in the presence of low-dimensional data and the implications thereof."
  },
  {
    "title": "No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models",
    "url": "/forum?id=cuvga_CiVND",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Training Large Transformer Models, Reducing Model Redundancy, Parameter Sensitivity, Adaptive Learning Rate Method, Model Generalization, Model Pruning",
    "Abstract": "Recent research has shown the existence of significant redundancy in large Transformer models. One can prune the redundant parameters without significantly sacrificing the generalization performance. However, we question whether the redundant parameters could have contributed more if they were properly trained. To answer this question, we propose a novel training strategy that encourages all parameters to be trained sufficiently. Specifically, we adaptively adjust the learning rate for each parameter according to its sensitivity, a robust gradient-based measure reflecting this parameter's contribution to the model performance. A parameter with low sensitivity is redundant, and we improve its fitting by increasing its learning rate. In contrast, a parameter with high sensitivity is well-trained, and we regularize it by decreasing its learning rate to prevent further overfitting. We conduct extensive experiments on natural language understanding, neural machine translation, and image classification to demonstrate the effectiveness of the proposed schedule. Analysis shows that the proposed schedule indeed reduces the redundancy and improves generalization performance.",
    "One-sentence Summary": "We propose a novel adaptive learning rate training strategy for large Transformer models that encourages all parameters to be trained sufficiently."
  },
  {
    "title": "SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations",
    "url": "/forum?id=aBsCjcPu_tE",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Guided image synthesis enables everyday users to create and edit photo-realistic images with minimum effort. The key challenge is balancing faithfulness to the user inputs (e.g., hand-drawn colored strokes) and realism of the synthesized images. Existing GAN-based methods attempt to achieve such balance using either conditional GANs or GAN inversions, which are challenging and often require additional training data or loss functions for individual applications. To address these issues, we introduce a new image synthesis and editing method, Stochastic Differential Editing (SDEdit), based on a diffusion model generative prior, which synthesizes realistic images by iteratively denoising through a stochastic differential equation (SDE). Given an input image with user guide in a form of manipulating RGB pixels, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism. SDEdit does not require task-specific training or inversions and can naturally achieve the balance between realism and faithfulness. SDEdit outperforms state-of-the-art GAN-based methods by up to 98.09% on realism and 91.72% on overall satisfaction scores, according to a human perception study, on multiple tasks, including stroke-based image synthesis and editing as well as image compositing."
  },
  {
    "title": "Post hoc Explanations may be Ineffective for Detecting Unknown Spurious Correlation",
    "url": "/forum?id=xNOVfCCvDpM",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "explanations, feature attributions, spurious correlation, interpretability, training point ranking",
    "Abstract": "We investigate whether three types of post hoc model explanations\u2013feature attribution, concept activation, and training point ranking\u2013are effective for detecting a model\u2019s reliance on spurious signals in the training data. Specifically, we consider the scenario where the spurious signal to be detected is unknown, at test-time, to the user of the explanation method. We design an empirical methodology that uses semi-synthetic datasets along with pre-specified spurious artifacts to obtain models that verifiably rely on these spurious training signals. We then provide a suite of metrics that assess an explanation method\u2019s reliability for spurious signal detection under various conditions. We find that the post hoc explanation methods tested are ineffective when the spurious artifact is unknown at test-time especially for non-visible artifacts like a background blur. Further, we find that feature attribution methods are susceptible to erroneously indicating dependence on spurious signals even when the model being explained does not rely on spurious artifacts. This finding casts doubt on the utility of these approaches, in the hands of a practitioner, for detecting a model\u2019s reliance on spurious signals.",
    "One-sentence Summary": "Post hoc explanation methods struggle to detect that deep nets are reliant on spurious training signals."
  },
  {
    "title": "Generalizing Few-Shot NAS with Gradient Matching",
    "url": "/forum?id=_jMtny3sMKU",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Efficient performance estimation of architectures drawn from large search spaces is essential to Neural Architecture Search. One-Shot methods tackle this challenge by training one supernet to approximate the performance of every architecture in the search space via weight-sharing, thereby drastically reducing the search cost. However, due to coupled optimization between child architectures caused by weight-sharing, One-Shot supernet's performance estimation could be inaccurate, leading to degraded search outcomes. To address this issue, Few-Shot NAS reduces the level of weight-sharing by splitting the One-Shot supernet into multiple separated sub-supernets via edge-wise (layer-wise) exhaustive partitioning. Since each partition of the supernet is not equally important, it necessitates the design of a more effective splitting criterion. In this work, we propose a gradient matching score (GM) that leverages gradient information at the shared weight for making informed splitting decisions. Intuitively, gradients from different child models can be used to identify whether they agree on how to update the shared modules, and subsequently to decide if they should share weight. Compared with exhaustive partitioning, the proposed criterion significantly reduces the branching factor per edge. This allows us to split more edges (layers) for a given budget, resulting in substantially improved performance as NAS search spaces usually include dozens of edges (layers). Extensive empirical evaluations of the proposed method on a wide range of search spaces (NASBench-201, DARTS, MobileNet Space), datasets (cifar10, cifar100, ImageNet) and search algorithms (DARTS, SNAS, RSPS, ProxylessNAS, OFA) demonstrate that it significantly outperforms its Few-Shot counterparts while surpassing previous comparable methods in terms of the accuracy of derived architectures. \n        Our code is available at https://github.com/skhu101/GM-NAS."
  },
  {
    "title": "The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training",
    "url": "/forum?id=VBZJ_3tz-t",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "random pruning, sparse training, static sparse training, layer-wise sparsities, dynamic sparse training",
    "Abstract": "Random pruning is arguably the most naive way to attain sparsity in neural networks, but has been deemed uncompetitive by either post-training pruning or sparse training. In this paper, we focus on sparse training and highlight a perhaps counter-intuitive finding, that random pruning at initialization can be quite powerful for the sparse training of modern neural networks. Without any delicate pruning criteria or carefully pursued sparsity structures, we empirically demonstrate that sparsely training a randomly pruned network from scratch can match the performance of its dense equivalent. There are two key factors that contribute to this revival: (i) $the network sizes matter$: as the original dense networks grow wider and deeper, the performance of training a randomly pruned sparse network will quickly grow to matching that of its dense equivalent, even at high sparsity ratios; (ii) $appropriate layer-wise sparsity ratios$ can be pre-chosen for sparse training, which shows to be another important performance booster. Simple as it looks,  a randomly pruned subnetwork of Wide ResNet-50 can be sparsely trained to outperforming a dense Wide ResNet-50, on ImageNet. We also observed such randomly pruned networks outperform dense counterparts in other favorable aspects, such as out-of-distribution detection, uncertainty estimation, and adversarial robustness. Overall, our results strongly suggest there is larger-than-expected room for sparse training at scale, and the benefits of sparsity might be more universal beyond carefully designed pruning. Our source code can be found at https://github.com/VITA-Group/Random_Pruning.",
    "One-sentence Summary": "We revisit the most naive baseline, random pruning, in sparse training and highlight a perhaps counter-intuitive finding: random pruning can be quite powerful for the sparse training of modern neural networks."
  },
  {
    "title": "switch-GLAT: Multilingual Parallel Machine Translation Via Code-Switch Decoder",
    "url": "/forum?id=5HvpvYd68b",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multilingual non-autoregressive machine translation, contextualized code-switching, back-translation",
    "Abstract": "Multilingual machine translation aims to develop a single model for multiple language directions. However, existing multilingual models based on Transformer are limited in terms of both translation performance and inference speed. In this paper, we propose switch-GLAT, a non-autoregressive multilingual machine translation model with a code-switch decoder. It can generate contextual code-switched translations for a given source sentence, and perform code-switch back-translation, greatly boosting multilingual translation performance. In addition, its inference is highly efficient thanks to its parallel decoder. Experiments show that our proposed switch-GLAT outperform the multilingual Transformer with as much as 0.74 BLEU improvement and 6.2x faster decoding speed in inference."
  },
  {
    "title": "DictFormer: Tiny Transformer with Shared Dictionary",
    "url": "/forum?id=GWQWAeE9EpB",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Transformer, Parameters Sharing, Tiny, On-device Transformer, Machine Translation, Attention, Dictionary Sharing",
    "Abstract": "We introduce DictFormer with the efficient shared dictionary to provide a compact, fast, and accurate transformer model. DictFormer significantly reduces the redundancy in the transformer's parameters by replacing the prior transformer's parameters with a compact, shared dictionary, few unshared coefficients, and indices. Also, DictFormer enables faster computations since expensive weights multiplications are converted into cheap shared look-ups on dictionary and few linear projections. Training dictionary and coefficients are not trivial since indices used for looking up dictionary are not differentiable. We adopt a sparse-constraint training with $l_1\\,\\,norm$ relaxation to learn coefficients and indices in DictFormer. DictFormer is flexible to support different model sizes by dynamically changing dictionary size. Compared to existing lightweight Transformers, DictFormer consistently reduces model size over Transformer on multiple tasks, e.g., machine translation, abstractive summarization, and language modeling. Extensive experiments show that DictFormer reduces $3.6\\times$ to $8.9\\times$ model size with similar accuracy over multiple tasks, compared to Transformer.",
    "One-sentence Summary": "We propose DictFormer with efficient shared dictionary to provide a compact, fast, and accurate transformer model."
  },
  {
    "title": "Training Transition Policies via Distribution Matching for Complex Tasks",
    "url": "/forum?id=6vkzF28Hur8",
    "date": "28 Sept 2021 (modified: 25 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Hierarchical Reinforcement Learning, Inverse Reinforcement Learning",
    "Abstract": "Humans decompose novel complex tasks into simpler ones to exploit previously learned skills. Analogously, hierarchical reinforcement learning seeks to leverage lower-level policies for simple tasks to solve complex ones. However, because each lower-level policy induces a different distribution of states, transitioning from one lower-level policy to another may fail due to an unexpected starting state. We introduce transition policies that smoothly connect lower-level policies by producing a distribution of states and actions that matches what is expected by the next policy. Training transition policies is challenging because the natural reward signal---whether the next policy can execute its subtask successfully---is sparse. By training transition policies via adversarial inverse reinforcement learning to match the distribution of expected states and actions, we avoid relying on task-based reward. To further improve performance, we use deep Q-learning with a binary action space to determine when to switch from a transition policy to the next pre-trained policy, using the success or failure of the next subtask as the reward. Although the reward is still sparse, the problem is less severe due to the simple binary action space. We demonstrate our method on continuous bipedal locomotion and arm manipulation tasks that require diverse skills. We show that it smoothly connects the lower-level policies, achieving higher success rates than previous methods that search for successful trajectories based on a reward function, but do not match the state distribution.",
    "One-sentence Summary": "Training transition policies via distribution matching"
  },
  {
    "title": "GDA-AM: ON THE EFFECTIVENESS OF SOLVING MIN-IMAX OPTIMIZATION VIA ANDERSON MIXING",
    "url": "/forum?id=3YqeuCVwy1d",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Many modern machine learning algorithms such as generative adversarial networks (GANs) and adversarial training can be formulated as minimax optimization.Gradient descent ascent (GDA) is the most commonly used algorithm due to its simplicity.  However, GDA can converge to non-optimal minimax points.  We propose a new minimax optimization framework,GDA-AM, that views the GDA dynamics as a fixed-point iteration and solves it using Anderson Mixing to converge to the local minimax. It addresses the diverging issue of simultaneous GDA and accelerates the convergence of alternating GDA. We show theoretically that the algorithm can achieve global convergence for bilinear problems under mildconditions. We also empirically show that GDA-AM solves a variety of minimax problems and improves GAN training on several datasets"
  },
  {
    "title": "On feature learning in neural networks with global convergence guarantees",
    "url": "/forum?id=PQTW3iG4sC-",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural networks, feature learning, gradient descent, global convergence",
    "Abstract": "We study the gradient flow optimization of over-parameterized neural networks (NNs) in a setup that allows feature learning while admitting non-asymptotic global convergence guarantees. First, we prove that for wide shallow NNs under the mean-field (MF) scaling and with a general class of activation functions, when the input dimension is at least the size of the training set, the training loss converges to zero at a linear rate under gradient flow. Building upon this analysis, we study a model of wide multi-layer NNs with random and untrained weights in earlier layers, and also prove a linear-rate convergence of the training loss to zero, regardless of the input dimension. We also show empirically that, unlike in the Neural Tangent Kernel (NTK) regime, our multi-layer model exhibits feature learning and can achieve better generalization performance than its NTK counterpart.",
    "One-sentence Summary": "Gradient flow can induce feature learning in shallow and multi-layer neural networks while admitting non-asymptotic guarantees of global convergence."
  },
  {
    "title": "The Three Stages of Learning Dynamics in High-dimensional Kernel Methods",
    "url": "/forum?id=EQmAP4F859",
    "date": "28 Sept 2021 (modified: 12 Nov 2021)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "training dynamics, kernels, SGD, deep bootstrap, gradient flow, random features, high-dimensional asymptotics, random matrix theory",
    "Abstract": "To understand how deep learning works, it is crucial to understand the training dynamics of neural networks. Several interesting hypotheses about these dynamics have been made based on empirically observed phenomena, but there exists a limited theoretical understanding of when and why such phenomena occur. \n        \n        In this paper, we consider the training dynamics of gradient flow on kernel least-squares objectives, which is a limiting dynamics of SGD trained neural networks. Using precise high-dimensional asymptotics, we characterize the dynamics of the fitted model in two \u201cworlds\u201d: in the Oracle World the model is trained on the population distribution and in the Empirical World the model is trained on an i.i.d finite dataset. We show that under mild conditions on the kernel and $L^2$ target regression function the training dynamics have three stages that are based on the behaviors of the models in the two worlds. Our theoretical results also mathematically formalize some interesting deep learning phenomena. Specifically, in our setting we show that SGD progressively learns more complex functions and that there is a \"deep bootstrap\" phenomenon: during the second stage, the test error of both worlds remain close despite the empirical training error being much smaller. Finally, we give a concrete example comparing the dynamics of two different kernels which shows that faster training is not necessary for better generalization.",
    "One-sentence Summary": "We study the training dynamics of gradient flows on the population risk and empirical risk of high-dimensional kernel least-squares problems, which we show has three learning stages."
  },
  {
    "title": "When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?",
    "url": "/forum?id=6MmiS0HUJHR",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning theory, multi-agent RL, Markov games, general-sum games",
    "Abstract": "Multi-agent reinforcement learning has made substantial empirical progresses in solving games with a large number of players. However, theoretically, the best known sample complexity for finding a Nash equilibrium in general-sum games scales exponentially in the number of players due to the size of the joint action space, and there is a matching exponential lower bound. This paper investigates what learning goals admit better sample complexities in the setting of $m$-player general-sum Markov games with $H$ steps, $S$ states, and $A_i$ actions per player. First, we design algorithms for learning an $\\epsilon$-Coarse Correlated Equilibrium (CCE) in $\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$ episodes, and an $\\epsilon$-Correlated Equilibrium (CE) in $\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$ episodes. This is the first line of results for learning CCE and CE with sample complexities polynomial in $\\max_{i\\le m} A_i$. Our algorithm for learning CE integrates an adversarial bandit subroutine which minimizes a weighted swap regret, along with several novel designs in the outer loop. Second, we consider the important special case of Markov Potential Games, and design an algorithm that learns an $\\epsilon$-approximate Nash equilibrium within $\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$ episodes (when only highlighting the dependence on $S$, $A_i$, and $\\epsilon$), which only depends linearly in $\\sum_{i\\le m} A_i$ and significantly improves over the existing efficient algorithm in the $\\epsilon$ dependence. Overall, our results shed light on what equilibria or structural assumptions on the game may enable sample-efficient learning with many players.",
    "One-sentence Summary": "We present new algorithms for several learning goals in multi-player general-sum Markov games, with mild PAC sample complexity in terms of the number of players."
  },
  {
    "title": "Neural Networks as Kernel Learners: The Silent Alignment Effect",
    "url": "/forum?id=1NvflqAdoom",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Tangent Kernel, Feature Learning, Inductive Bias of Neural Networks",
    "Abstract": "Neural networks in the lazy training regime converge to kernel machines. Can neural networks in the rich feature learning regime learn a kernel machine with a data-dependent kernel? We demonstrate that this can indeed happen due to a phenomenon we term silent alignment, which requires that the tangent kernel of a network evolves in eigenstructure while small and before the loss appreciably decreases, and grows only in overall scale afterwards. We show that such an effect takes place in homogenous neural networks with small initialization and whitened data. We provide an analytical treatment of this effect in the linear network case. In general, we find that the kernel develops a low-rank contribution in the early phase of training, and then evolves in overall scale, yielding a function equivalent to a kernel regression solution with the final network's tangent kernel. The early spectral learning of the kernel depends on the depth. We also demonstrate that non-whitened data can weaken the silent alignment effect.",
    "One-sentence Summary": "Neural networks with small initialization, trained in the rich feature learning regime, can learn kernel regression solutions for a data adaptive kernel."
  },
  {
    "title": "Learning Object-Oriented Dynamics for Planning from Text",
    "url": "/forum?id=B6EIcyp-Rb7",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Object Oriented Markov Decision Process, Reinforcement Learning, Model-Based Planning, Text-Based Games, Knowledge Extraction",
    "Abstract": "The advancement of dynamics models enables model-based planning in complex environments. Existing dynamics models commonly study image-based games with fully observable states. Generalizing these models to Text-Based Games (TBGs), which commonly describe the partially observable states with noisy text observations, is challenging. In this work, we propose an Object-Oriented Text Dynamics (OOTD) model that enables planning algorithms to solve decision-making problems in text domains. OOTD predicts a memory graph that dynamically remembers the history of object observations and filters object-irrelevant information.  To facilitate the robustness of dynamics, our OOTD model identifies the objects influenced by input actions and predicts the belief of object states with independently parameterized transition layers. We develop variational objectives under the object-supervised and self-supervised settings to model the stochasticity of predicted dynamics. Empirical results show OOTD-based planner significantly outperforms model-free baselines in terms of sample efficiency and running scores.",
    "One-sentence Summary": "We propose an Object-Oriented Text Dynamic (OOTD) model for solving decision-making problems in the text domain."
  },
  {
    "title": "An Operator Theoretic View On Pruning Deep Neural Networks",
    "url": "/forum?id=pWBNOgdeURp",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep neural network pruning, Koopman operator theory",
    "Abstract": "The discovery of sparse subnetworks that are able to perform as well as full models has found broad applied and theoretical interest. While many pruning methods have been developed to this end, the na\u00efve approach of removing parameters based on their magnitude has been found to be as robust as more complex, state-of-the-art algorithms. The lack of theory behind magnitude pruning's success, especially pre-convergence, and its relation to other pruning methods, such as gradient based pruning, are outstanding open questions in the field that are in need of being addressed. We make use of recent advances in dynamical systems theory, namely Koopman operator theory, to define a new class of theoretically motivated pruning algorithms. We show that these algorithms can be equivalent to magnitude and gradient based pruning, unifying these seemingly disparate methods, and find that they can be used to shed light on magnitude pruning's performance during the early part of training.",
    "One-sentence Summary": "Koopman operator theoretic methods are extended to deep neural network pruning and are shown to provide new insight into existing work."
  },
  {
    "title": "Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?",
    "url": "/forum?id=_4GFbtOuWq-",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "representation learning, perceptron capacity, perceptual manifolds, equivariance, cover's theorem, vc dimension",
    "Abstract": "Equivariance has emerged as a desirable property of representations of objects subject to identity-preserving transformations that constitute a group, such as translations and rotations. However, the expressivity of a representation constrained by group equivariance is still not fully understood. We address this gap by providing a generalization of Cover's Function Counting Theorem that quantifies the number of linearly separable and group-invariant binary dichotomies that can be assigned to equivariant representations of objects. We find that the fraction of separable dichotomies is determined by the dimension of the space that is fixed by the group action. We show how this relation extends to operations such as convolutions, element-wise nonlinearities, and global and local pooling. While other operations do not change the fraction of separable dichotomies, local pooling decreases the fraction, despite being a highly nonlinear operation. Finally, we test our theory on intermediate representations of randomly initialized and fully trained convolutional neural networks and find perfect agreement.",
    "One-sentence Summary": "We compute the fraction of linearly separable dichotomies of representations formed by group actions and apply these results to intermediate representations of convolutional neural networks."
  },
  {
    "title": "Tuformer: Data-driven Design of Transformers for Improved Generalization or Efficiency",
    "url": "/forum?id=V0A5g83gdQ_",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Attention Modules, Transformers, Data-driven Model Design, Trainable Heads, Expressive Power, Tensor Methods.",
    "Abstract": "Transformers are neural network architectures that achieve remarkable performance in many areas. However, the core component of Transformers, multi-head self-attention (MHSA), is mainly derived from heuristics, and the interactions across its components are not well understood. To address the problem, we first introduce a mathematically rigorous and yet intuitive tensor diagram representation of MHSA. Guided by tensor diagram representations, we propose a novel design, namely Tunable Transformers (Tuformers), by allowing data-driven weights across heads, whereas MHSA adopts pre-defined and fixed weights across heads, as will be explained in our paper. Tuformers naturally reveal a flexible design space that a user, depending on the needs, can choose a structure that has either improved performance (generalization error) or higher model efficiency. Any pre-trained Transformer can be an initialization of the corresponding Tuformer with trainable number of heads for efficient training and fine-tuning. Tuformers universally outperform Transformers on various tasks across multiple domains under a wide range of model sizes.",
    "One-sentence Summary": "We propose Tuformer, a data-driven design of theoretically guaranteed expressive Transformer with trainable heads, inspired by Tucker tensor representation."
  },
  {
    "title": "Learning Weakly-supervised Contrastive Representations",
    "url": "/forum?id=MSwEFaztwkE",
    "date": "28 Sept 2021 (modified: 18 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-supervised Learning, Weakly Supervised Learning, Learning with Auxiliary Information, Clustering-based Representation Learning",
    "Abstract": "We argue that a form of the valuable information provided by the auxiliary information is its implied data clustering information. For instance, considering hashtags as auxiliary information, we can hypothesize that an Instagram image will be semantically more similar with the same hashtags. With this intuition, we present a two-stage weakly-supervised contrastive learning approach. The first stage is to cluster data according to its auxiliary information. The second stage is to learn similar representations within the same cluster and dissimilar representations for data from different clusters. Our empirical experiments suggest the following three contributions. First, compared to conventional self-supervised representations, the auxiliary-information-infused representations bring the performance closer to the supervised representations, which use direct downstream labels as supervision signals. Second, our approach performs the best in most cases, when comparing our approach with other baseline representation learning methods that also leverage auxiliary data information. Third, we show that our approach also works well with unsupervised constructed clusters (e.g., no auxiliary information), resulting in a strong unsupervised representation learning approach.",
    "One-sentence Summary": "We present a weakly-supervised contrastive learning framework that considers auxiliary information (additional sources of information from data)."
  },
  {
    "title": "Encoding Weights of Irregular Sparsity for Fixed-to-Fixed Model Compression",
    "url": "/forum?id=Vs5NK44aP9P",
    "date": "28 Sept 2021 (modified: 30 Jan 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Sparse Neural Network, Fixed-to-fixed data compression, Unstructured Pruning",
    "Abstract": "Even though fine-grained pruning techniques achieve a high compression ratio, conventional sparsity representations (such as CSR) associated with irregular sparsity degrade parallelism significantly. Practical pruning methods, thus, usually lower pruning rates (by structured pruning) to improve parallelism. In this paper, we study fixed-to-fixed (lossless) encoding architecture/algorithm to support fine-grained pruning methods such that sparse neural networks can be stored in a highly regular structure. We first estimate the maximum compression ratio of encoding-based compression using entropy. Then, as an effort to push the compression ratio to the theoretical maximum (by entropy), we propose a sequential fixed-to-fixed encoding scheme. We demonstrate that our proposed compression scheme achieves almost the maximum compression ratio for the Transformer and ResNet-50 pruned by various fine-grained pruning methods.",
    "One-sentence Summary": "We propose a fixed-to-fixed weight compression scheme even when weights are pruned in a fine-grained manner."
  },
  {
    "title": "An Experimental Design Perspective on Model-Based Reinforcement Learning",
    "url": "/forum?id=0no8Motr-zO",
    "date": "28 Sept 2021 (modified: 05 Apr 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, acquisition function, information gain",
    "Abstract": "In many practical applications of RL, it is expensive to observe state transitions from the environment. For example, in the problem of plasma control for nuclear fusion, computing the next state for a given state-action pair requires querying an expensive transition function which can lead to many hours of computer simulation or dollars of scientific research. Such expensive data collection prohibits application of standard RL algorithms which usually require a large number of observations to learn. In this work, we address the problem of efficiently learning a policy while making a minimal number of state-action queries to the transition function. In particular, we leverage ideas from Bayesian optimal experimental design to guide the selection of state-action queries for efficient learning. We propose an \\emph{acquisition function} that quantifies how much information a state-action pair would provide about the optimal solution to a Markov decision process. At each iteration, our algorithm maximizes this acquisition function, to choose the most informative state-action pair to be queried, thus yielding a data-efficient RL approach. We experiment with a variety of simulated continuous control problems and show that our approach learns an optimal policy with up to $5$ -- $1,000\\times$ less data than model-based RL baselines and $10^3$ -- $10^5\\times$ less data than model-free RL baselines. We also provide several ablated comparisons which point to substantial improvements arising from the principled method of obtaining data.",
    "One-sentence Summary": "We draw a connection between Bayesian Optimal Experiment Design and RL to develop an acquisition function to guide data collection in model based RL leading to improved sample efficiency."
  },
  {
    "title": "BAM: Bayes with Adaptive Memory",
    "url": "/forum?id=NdOoQnYPj_",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Bayesian learning, online learning",
    "Abstract": "Online learning via Bayes' theorem allows new data to be continuously integrated into an agent's current beliefs. However, a naive application of Bayesian methods in non-stationary environments leads to slow adaptation and results in state estimates that may converge confidently to the wrong parameter value. A common solution when learning in changing environments is to discard/downweight past data; however, this simple mechanism of \"forgetting\" fails to account for the fact that many real-world environments involve revisiting similar states. We propose a new framework, Bayes with Adaptive Memory (BAM), that takes advantage of past experience by allowing the agent to choose which past observations to remember and which to forget. We demonstrate that BAM generalizes many popular Bayesian update rules for non-stationary environments. Through a variety of experiments, we demonstrate the ability of BAM to continuously adapt in an ever-changing world.",
    "One-sentence Summary": "We augment Bayes with memory to generalize many frameworks and overcome limitations of traditional methods in non-stationary settings"
  },
  {
    "title": "Unsupervised Learning of Full-Waveform Inversion: Connecting CNN and Partial Differential Equation in a Loop",
    "url": "/forum?id=izvwgBic9q",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Unsupervised Learning, Full-Waveform Inversion, Partial Differential Equation, Physics-Informed Machine Learning",
    "Abstract": "This paper investigates unsupervised learning of Full-Waveform Inversion (FWI), which has been widely used in geophysics to estimate subsurface velocity maps from seismic data. This problem is mathematically formulated by a second order partial differential equation (PDE), but is hard to solve. Moreover, acquiring velocity map is extremely expensive, making it impractical to scale up a supervised approach to train the mapping from seismic data to velocity maps with convolutional neural networks (CNN).We address these difficulties by $\\textit{integrating PDE and CNN in a loop}$, thus shifting the paradigm to unsupervised learning that only requires seismic data. In particular, we use finite difference to approximate the forward modeling of PDE as a differentiable operator (from velocity map to seismic data) and model its inversion by CNN (from seismic data to velocity map). Hence, we transform the supervised inversion task into an unsupervised seismic data reconstruction task. We also introduce a new large-scale dataset $\\textit{OpenFWI}$, to establish a more challenging benchmark for the community. Experiment results show that our model (using seismic data alone) yields comparable accuracy to the supervised counterpart (using both seismic data and velocity map). Furthermore, it outperforms the supervised model when involving more seismic data.",
    "One-sentence Summary": "We develop an unsupervised method to solve seismic full-waveform inversion in geophysics by integrating CNN and the governing partial differential equation."
  },
  {
    "title": "Conditional Contrastive Learning with Kernel",
    "url": "/forum?id=AAJLBoGt0XM",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Contrastive Learning, Conditional Sampling, Kernel methods",
    "Abstract": "Conditional contrastive learning frameworks consider the conditional sampling procedure that constructs positive or negative data pairs conditioned on specific variables. Fair contrastive learning constructs negative pairs, for example, from the same gender (conditioning on sensitive information), which in turn reduces undesirable information from the learned representations; weakly supervised contrastive learning constructs positive pairs with similar annotative attributes (conditioning on auxiliary information), which in turn are incorporated into the representations. Although conditional contrastive learning enables many applications, the conditional sampling procedure can be challenging if we cannot obtain sufficient data pairs for some values of the conditioning variable. This paper presents Conditional Contrastive Learning with Kernel (CCL-K) that converts existing conditional contrastive objectives into alternative forms that mitigate the insufficient data problem. Instead of sampling data according to the value of the conditioning variable, CCL-K uses the Kernel Conditional Embedding Operator that samples data from all available data and assigns weights to each sampled data given the kernel similarity between the values of the conditioning variable. We conduct experiments using weakly supervised, fair, and hard negatives contrastive learning, showing CCL-K outperforms state-of-the-art baselines.",
    "One-sentence Summary": "This paper presents Conditional Contrastive Learning with Kernel (CCL-K) for conditional contrastive learning tasks under the scenario when we have insufficient data for some values of the condioning variable."
  },
  {
    "title": "ConFeSS: A Framework for Single Source Cross-Domain Few-Shot Learning",
    "url": "/forum?id=zRJu6mU2BaE",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Most current few-shot learning methods train a model from abundantly labeled base category data and then transfer and adapt the model to sparsely labeled novel category data. These methods mostly generalize well on novel categories from the same domain as the base categories but perform poorly for distant domain categories. In this paper, we propose a framework for few-shot learning coined as ConFeSS (Contrastive Learning and Feature Selection System) that tackles large domain shift between base and novel categories. The first step of our framework trains a feature extracting backbone with the contrastive loss on the base category data. Since the contrastive loss does not use supervision, the features can generalize better to distant target domains. For the second step, we train a masking module to select relevant features that are more suited to target domain classification. Finally, a classifier is fine-tuned along with the backbone such that the backbone produces features similar to the relevant ones. To evaluate our framework, we tested it on a recently introduced cross-domain few-shot learning benchmark. Experimental results demonstrate that our framework outperforms all meta-learning approaches and produces competitive results against recent cross-domain methods. Additional analyses are also performed to better understand our framework."
  },
  {
    "title": "Granger causal inference on DAGs identifies genomic loci regulating transcription",
    "url": "/forum?id=nZOUYEN6Wvy",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Granger causality, causal inference, graph neural networks, gene regulation, single-cell genomics, chromatin accessibility, directed acyclic graphs, single-cell multimodal",
    "Abstract": "When a dynamical system can be modeled as a sequence of observations, Granger causality is a powerful approach for detecting predictive interactions between its variables. However, traditional Granger causal inference has limited utility in domains where the dynamics need to be represented as directed acyclic graphs (DAGs) rather than as a linear sequence, such as with cell differentiation trajectories. Here, we present GrID-Net, a framework based on graph neural networks with lagged message passing for Granger causal inference on DAG-structured systems. Our motivating application is the analysis of single-cell multimodal data to identify genomic loci that mediate the regulation of specific genes. To our knowledge, GrID-Net is the first single-cell analysis tool that accounts for the temporal lag between a genomic locus becoming accessible and its downstream effect on a target gene's expression. We applied GrID-Net on multimodal single-cell assays that profile chromatin accessibility (ATAC-seq) and gene expression (RNA-seq) in the same cell and show that it dramatically outperforms existing methods for inferring regulatory locus-gene links, achieving up to 71% greater agreement with independent population genetics-based estimates. By extending Granger causality to DAG-structured dynamical systems, our work unlocks new domains for causal analyses and, more specifically, opens a path towards elucidating gene regulatory interactions relevant to cellular differentiation and complex human diseases at unprecedented scale and resolution.",
    "One-sentence Summary": "We show how to extend Granger causality to DAG-structured dynamical systems using graph neural networks, applying it to infer noncoding regions involved in gene regulation."
  },
  {
    "title": "Energy-Inspired Molecular Conformation Optimization",
    "url": "/forum?id=7QfLW-XZTl",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "This paper studies an important problem in computational chemistry: predicting a molecule's spatial atom arrangements, or a molecular conformation. We propose a neural energy minimization formulation that casts the prediction problem into an unrolled optimization process, where a neural network is parametrized to learn the gradient fields of an implicit conformational energy landscape. Assuming different forms of the underlying potential energy function, we can not only reinterpret and unify many of the existing models but also derive new variants of SE(3)-equivariant neural networks in a principled manner. In our experiments, these new variants show superior performance in molecular conformation optimization comparing to existing SE(3)-equivariant neural networks. Moreover, our energy-inspired formulation is also suitable for molecular conformation generation, where we can generate more diverse and accurate conformers comparing to existing baselines."
  },
  {
    "title": "Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective",
    "url": "/forum?id=tT9t_ZctZRL",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Trainablity, Graph Neural Tangent Kernel, Critical DropEdge",
    "Abstract": "Graph convolutional networks (GCNs) and their variants have achieved great success in dealing with graph-structured data. Nevertheless, it is well known that deep GCNs suffer from the over-smoothing problem, where node representations tend to be indistinguishable as more layers are stacked up. The theoretical research to date on deep GCNs has focused primarily on expressive power rather than trainability, an optimization perspective. Compared to expressivity, trainability attempts to address a more fundamental question: Given a sufficiently expressive space of models, can we successfully find a good solution via gradient descent-based optimizers? This work fills this gap by exploiting the Graph Neural Tangent Kernel (GNTK), which governs the optimization trajectory under gradient descent for wide GCNs. We formulate the asymptotic behaviors of GNTK in the large depth, which enables us to reveal the dropping trainability of wide and deep GCNs at an exponential rate in the optimization process. Additionally, we extend our theoretical framework to analyze residual connection-based techniques, which are found to be merely able to mitigate the exponential decay of trainability mildly. Inspired by our theoretical insights on trainability, we propose Critical DropEdge, a connectivity-aware and graph-adaptive sampling method, to alleviate the exponential decay problem more fundamentally. Experimental evaluation consistently confirms using our proposed method can achieve better results compared to relevant counterparts with both infinite-width and finite-width.",
    "One-sentence Summary": "This work theoretically studies the trainability of deep graph neural networks, and is inspired to design algorithms to deepen the network."
  },
  {
    "title": "Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity",
    "url": "/forum?id=CJzi3dRlJE-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "connectome, latent-variable model, variational autoencoder, biophysics, whole-brain, neural activity, calcium imaging, caenorhabditis elegans, voltage, generative model, inference network",
    "Abstract": "The availability of both anatomical connectivity and brain-wide neural activity measurements in C. elegans make the worm a promising system for learning detailed, mechanistic models of an entire nervous system in a data-driven way. However, one faces several challenges when constructing such a model. We often do not have direct experimental access to important modeling details such as single-neuron dynamics and the signs and strengths of the synaptic connectivity. Further, neural activity can only be measured in a subset of neurons, often indirectly via calcium imaging, and significant trial-to-trial variability has been observed. To address these challenges, we introduce a connectome-constrained latent variable model (CC-LVM) of the unobserved voltage dynamics of the entire C. elegans nervous system and the observed calcium signals. We used the framework of variational autoencoders to fit parameters of the mechanistic simulation constituting the generative model of the LVM to calcium imaging observations. A variational approximate posterior distribution over latent voltage traces for all neurons is efficiently inferred using an inference network, and constrained by a prior distribution given by the biophysical simulation of neural dynamics. We applied this model to an experimental whole-brain dataset, and found that connectomic constraints enable our LVM to predict the activity of neurons whose activity were withheld significantly better than models unconstrained by a connectome. We explored models with different degrees of biophysical detail, and found that models with realistic conductance-based synapses provide markedly better predictions than current-based synapses for this system.",
    "One-sentence Summary": "Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity."
  },
  {
    "title": "T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis",
    "url": "/forum?id=U4uFaLyg7PV",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Time series signal analysis plays an essential role in many applications, e.g., activity recognition and healthcare monitoring.\n        Recently, features extracted with deep neural networks (DNNs) have shown to be more effective than conventional hand-crafted ones.\n        However, most existing solutions rely solely on the network to extract information carried in the raw signal, regardless of its inherent physical and statistical properties, leading to sub-optimal performance particularly under a limited amount of training data.\n        In this work, we propose a novel tree-structured wavelet neural network for time series signal analysis, namely \\emph{T-WaveNet}, taking advantage of an inherent property of various types of signals, known as the \\emph{dominant frequency range}. Specifically, with \\emph{T-WaveNet}, we first conduct frequency spectrum energy analysis of the signals to get a set of dominant frequency subbands. Then, we construct a tree-structured network that iteratively decomposes the input signal into various frequency subbands with similar energies. Each node on the tree is built with an invertible neural network (INN) based wavelet transform unit. Such a disentangled representation learning method facilitates a more effective extraction of the discriminative features, as demonstrated with the comprehensive experiments on various real-life time series classification datasets."
  },
  {
    "title": "Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations",
    "url": "/forum?id=AmUhwTOHgm",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self-supervised learning, sentence embeddings, sentence representations, knowledge distillation",
    "Abstract": "In NLP, a large volume of tasks involve pairwise comparison between two sequences (e.g. sentence similarity and paraphrase identification). Predominantly, two formulations are used for sentence-pair tasks: bi-encoders and cross-encoders. Bi-encoders produce fixed-dimensional sentence representations and are computationally efficient, however, they usually underperform cross-encoders. Cross-encoders can leverage their attention heads to exploit inter-sentence interactions for better performance but they require task fine-tuning and are computationally more expensive. In this paper, we present a completely unsupervised sentence representation model termed as Trans-Encoder that combines the two learning paradigms into an iterative joint framework to simultaneously learn enhanced bi- and cross-encoders. Specifically, on top of a pre-trained Language Model (PLM), we start with converting it to an unsupervised bi-encoder, and then alternate between the bi- and cross-encoder task formulations. In each alternation, one task formulation will produce pseudo-labels which are used as learning signals for the other task formulation. We then propose an extension to conduct such self-distillation approach on multiple PLMs in parallel and use the average of their pseudo-labels for mutual distillation. Trans-Encoder creates, to the best of our knowledge, the first completely unsupervised cross-encoder and also a state-of-the-art unsupervised bi-encoder for sentence similarity. Both the bi-encoder and cross-encoder formulations of Trans-Encoder outperform recently proposed state-of-the-art unsupervised sentence encoders such as Mirror-BERT and SimCSE by up to 5% on the sentence similarity benchmarks.",
    "One-sentence Summary": "Bootstrapping an unsupervised sentence encoder by self-distilling knowledge between its bi-encoder and cross-encoder forms, enhancing each other iteratively."
  },
  {
    "title": "Path Integral Sampler: A Stochastic Control Approach For Sampling",
    "url": "/forum?id=_uCb2ynRu7Y",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Sampling, Path Integral, Stochastic Differential Equation, MCMC",
    "Abstract": "We present Path Integral Sampler~(PIS), a novel algorithm to draw samples from unnormalized probability density functions. The PIS is built on the Schr\\\"odinger bridge problem which aims to recover the most likely evolution of a diffusion process given its initial distribution and terminal distribution. The PIS draws samples from the initial distribution and then propagates the samples through the Schr\\\"odinger bridge to reach the terminal distribution. Applying the Girsanov theorem, with a simple prior diffusion, we formulate the PIS as a stochastic optimal control problem whose running cost is the control energy and terminal cost is chosen according to the target distribution. By modeling the control as a neural network, we establish a sampling algorithm that can be trained end-to-end. We provide theoretical justification of the sampling quality of PIS in terms of Wasserstein distance when sub-optimal control is used. Moreover, the path integrals theory is used to compute importance weights of the samples to compensate for the bias induced by the sub-optimality of the controller and the time-discretization. We experimentally demonstrate the advantages of PIS compared with other start-of-the-art sampling methods on a variety of tasks.",
    "One-sentence Summary": "We present Path Integral Sampler~(PIS), an efficient algorithm to draw samples from unnormalized probability density functions."
  },
  {
    "title": "Model Zoo: A Growing Brain That Learns Continually",
    "url": "/forum?id=WfvgGBcgbE7",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Continual Learning, Learning Theory",
    "Abstract": "This paper argues that continual learning methods can benefit by splitting the capacity of the learner across multiple models. We use statistical learning theory and experimental analysis to show how multiple tasks can interact with each other in a non-trivial fashion when a single model is trained on them. The generalization error on a particular task can improve when it is trained with synergistic tasks, but can also deteriorate when trained with competing tasks. This theory motivates our method named Model Zoo which, inspired from the boosting literature, grows an ensemble of small models, each of which is trained during one episode of continual learning. We demonstrate that Model Zoo obtains large gains in accuracy on a wide variety of continual learning benchmark problems.",
    "One-sentence Summary": "Continual learning methods can benefit by splitting the capacity of the learner and we leverage this in our method Model Zoo, which demonstrates large gains in accuracy on a variety of continual learning benchmarks."
  },
  {
    "title": "Predicting Physics in Mesh-reduced Space with Temporal Attention",
    "url": "/forum?id=XctLdNfCmP",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "fluid dynamics, graph neural network, attention neural network",
    "Abstract": "Auto-regressive sequence models for physics prediction are often restricted to low-dimensional systems, as memory cost increases with both spatial extents and sequence length. On the other hand, graph-based next-step prediction models have recently been very successful in modeling complex high-dimensional physical systems on irregular meshes, but suffer from error accumulation and drift, due to their short temporal attention span. In this paper, we present a method that marries the strengths of both approaches. We use a GNN to locally summarize features and create coarsened, compact mesh representation of the system state, onto which we apply a transformer-style temporal attention module. We use a second GNN to decode these predictions back to a full-sized graph and perform fine-scale updates. Our method outperforms a competitive GNN baseline on three complex fluid dynamics prediction tasks, from sonic shocks to vascular flow. We demonstrate stable rollouts without the need for training noise and show perfectly phase-stable predictions even for very long sequences. More broadly, we believe our approach paves the way to bringing the benefits of attention-based sequence models to solving high-dimensional complex physics tasks.",
    "One-sentence Summary": "We use a GNN to locally summarize features and create coarsened, compact mesh representation of the system state, onto which we apply a transformer-style temporal attention module for physics prediction."
  },
  {
    "title": "How unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis",
    "url": "/forum?id=qiMXBIf4NfB",
    "date": "28 Sept 2021 (modified: 14 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-training, Semi-supervised learning, Convergence analysis, Generalization analysis",
    "Abstract": "Self-training, a semi-supervised learning algorithm, leverages a large amount of unlabeled data to improve learning when the labeled data are limited. Despite empirical successes, its theoretical characterization remains elusive. To the best of our knowledge, this work establishes the first theoretical analysis for the known iterative self-training paradigm and formally proves the benefits of unlabeled data in both training convergence and generalization ability. To make our theoretical analysis feasible, we focus on the case of one-hidden-layer neural networks. However, theoretical understanding of iterative self-training is non-trivial even for a shallow neural network. One of the key challenges is that existing neural network landscape analysis built upon supervised learning no longer holds in the (semi-supervised) self-training paradigm. We address this challenge and prove that iterative self-training converges linearly with both convergence rate and generalization accuracy improved in the order of $1/\\sqrt{M}$, where $M$ is the number of unlabeled samples. Extensive experiments from shallow neural networks to deep neural networks are also provided to justify the correctness of our established theoretical insights on self-training.",
    "One-sentence Summary": "Theoretical characterization of unlabeled data in improving generalization and convergence rate via iterative self-training algorithm"
  },
  {
    "title": "Learning to Dequantise with Truncated Flows",
    "url": "/forum?id=fExcSKdDo_",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "variational inference, variational bayes, dequantisation, normalizing flows",
    "Abstract": "Dequantisation is a general technique used for transforming data described by a discrete random variable $x$ into a continuous (latent) random variable $z$, for the purpose of it being modeled by likelihood-based density models. Dequantisation was first introduced in the context of ordinal data, such as image pixel values.  However, when the data is categorical, the dequantisation scheme is not obvious.\n        We learn such a dequantisation scheme $q(z | x)$, using variational inference with TRUncated FLows (TRUFL) --- a novel flow-based model that allows the dequantiser to have a learnable truncated support. Unlike previous work, the TRUFL dequantiser is (i) capable of embedding the data losslessly in certain cases, since the truncation allows the conditional distributions $q(z | x)$ to have non-overlapping bounded supports, while being (ii) trainable with back-propagation. Addtionally, since the support of the marginal $q(z)$ is bounded and the support of prior $p(z)$ is not, we propose renormalising the prior distribution over the support of $q(z)$. We derive a lower bound for training, and propose a rejection sampling scheme to account for the invalid samples during generation.\n        Experimentally, we benchmark TRUFL on constrained generation tasks, and find that it outperforms prior approaches. In addition, we find that rejection sampling results in higher validity for the constrained problems.",
    "One-sentence Summary": "Learning a variational dequantisation scheme with truncated/bounded-support distributions"
  },
  {
    "title": "Curriculum learning as a tool to uncover learning principles in the brain",
    "url": "/forum?id=TpJMvo0_pu-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "curriculum learning, neuroscience",
    "Abstract": "We present a novel approach to use curricula to identify principles by which a system learns. Previous work in curriculum learning has focused on how curricula can be designed to improve learning of a model on particular tasks. We consider the inverse problem: what can a curriculum tell us about how a learning system acquired a task? Using recurrent neural networks (RNNs) and models of common experimental neuroscience tasks, we demonstrate that curricula can be used to differentiate learning principles using target-based and a representation-based loss functions as use cases. In particular, we compare the performance of RNNs using target-based learning rules versus those using representational learning rules on three different curricula in the context of two tasks. We show that the learned state-space trajectories of RNNs trained by these two learning rules under all curricula tested are indistinguishable. However, by comparing learning times during different curricula, we can disambiguate the learning rules and challenge traditional approaches of interrogating learning systems. Although all animals in neuroscience lab settings are trained by curriculum-based procedures called shaping, almost no behavioral or neural data are collected or published on the relative successes or training times under different curricula. Our results motivate the systematic collection and curation of data during shaping by demonstrating curriculum learning in RNNs as a tool to probe and differentiate learning principles used by biological systems, over conventional statistical analyses of learned state spaces.",
    "One-sentence Summary": "We present a novel approach to use curricula to identify principles by which a system learns."
  },
  {
    "title": "Optimizer Amalgamation",
    "url": "/forum?id=VqzXzA9hjaX",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Learning to Optimize, Knowledge Amalgamation, Stability-Aware Training",
    "Abstract": "Selecting an appropriate optimizer for a given problem is of major interest for researchers and practitioners. Many analytical optimizers have been proposed using a variety of theoretical and empirical approaches; however, none can offer a universal advantage over other competitive optimizers. We are thus motivated to study a new problem named Optimizer Amalgamation: how can we best combine a pool of \"teacher\" optimizers into a single \"student\" optimizer that can have stronger problem-specific performance? In this paper, we draw inspiration from the field of \"learning to optimize\" to use a learnable amalgamation target. First, we define three differentiable amalgamation mechanisms to amalgamate a pool of analytical optimizers by gradient descent. Then, in order to reduce variance of the amalgamation process, we also explore methods to stabilize the amalgamation process by perturbing the amalgamation target. Finally, we present experiments showing the superiority of our amalgamated optimizer compared to its amalgamated components and learning to optimize baselines, and the efficacy of our variance reducing perturbations.",
    "One-sentence Summary": "We study a new problem named Optimizer Amalgamation: combining a pool of \"teacher\" optimizers into a single \"student\" optimizer which can have stronger problem-specific performance."
  },
  {
    "title": "An Agnostic Approach to Federated Learning with Class Imbalance",
    "url": "/forum?id=Xo0lbDt975",
    "date": "28 Sept 2021 (modified: 02 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, Class Imbalance",
    "Abstract": "Federated Learning (FL) has emerged as the tool of choice for training deep models over heterogeneous and decentralized datasets. \n        As a reflection of the experiences from different clients, severe class imbalance issues are observed in real-world FL problems.\n        Moreover, there exists a drastic mismatch between the imbalances from the local and global perspectives, i.e. a local majority class can be the minority of the population. Additionally, the privacy requirement of FL poses an extra challenge, as one should handle class imbalance without identifying the minority class. In this paper we propose a novel agnostic constrained learning formulation to tackle the class imbalance problem in FL, without requiring further information beyond the standard FL objective. A meta algorithm, CLIMB, is designed to solve the target optimization problem, with its convergence property analyzed under certain oracle assumptions. Through an extensive empirical study over various data heterogeneity and class imbalance configurations, we showcase that CLIMB considerably improves the performance in the minority class without compromising the overall accuracy of the classifier, which significantly outperforms previous arts. \n        In fact, we observe the greatest performance boost in the most difficult scenario where every client only holds data from one class. The code can be found here https://github.com/shenzebang/Federated-Learning-Pytorch."
  },
  {
    "title": "A Fine-Tuning Approach to Belief State Modeling",
    "url": "/forum?id=ckZY7DGa7FQ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "imperfect-information, partial observability, search, decision-time planning",
    "Abstract": "We investigate the challenge of modeling the belief state of a partially observable Markov system, given sample-access to its dynamics model. This problem setting is often approached using parametric sequential generative modeling methods. However, these methods do not leverage any additional computation at inference time to increase their accuracy. Moreover, applying these methods to belief state modeling in certain multi-agent settings would require passing policies into the belief model---at the time of writing, there have been no successful demonstrations of this. Toward addressing these shortcomings, we propose an inference-time improvement framework for parametric sequential generative modeling methods called belief fine-tuning (BFT). BFT leverages approximate dynamic programming in the form of fine-tuning to determine the model parameters at each time step. It can improve the accuracy of the belief model at test time because it specializes the model to the space of local observations. Furthermore, because this specialization occurs after the action or policy has already been decided, BFT does not require the belief model to process it as input. As a result of the latter point, BFT enables, for the first time, approximate public belief state search in imperfect-information games where the number of possible information states is too large to track tabularly. We exhibit these findings on large-scale variants of the benchmark game Hanabi.",
    "One-sentence Summary": "A method for improving the accuracy of belief state models and for approximating public belief states at scale."
  },
  {
    "title": "Differentially Private Fine-tuning of Language Models",
    "url": "/forum?id=Q42f0dfjECO",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "differential privacy, large language models, fine-tuning",
    "Abstract": "We give simpler, sparser, and faster algorithms for differentially private fine-tuning of large-scale pre-trained language models, which achieve the state-of-the-art privacy versus utility tradeoffs on many standard NLP tasks. We propose a meta-framework for this problem, inspired by the recent success of highly parameter-efficient methods for fine-tuning. Our experiments show that differentially private adaptations of these approaches outperform previous private algorithms in three important dimensions: utility, privacy, and the computational and memory cost of private training. On many commonly studied datasets, the utility of private models approaches that of non-private models. For example, on the MNLI dataset we achieve an accuracy of $87.8\\%$ using RoBERTa-Large and $83.5\\%$ using RoBERTa-Base with a privacy budget of $\\epsilon = 6.7$. In comparison, absent privacy constraints, RoBERTa-Large achieves an accuracy of $90.2\\%$. Our findings are similar for natural language generation when privately fine-tuning GPT-2. Our experiments also show that larger models are better suited for private fine-tuning: while they are well known to achieve superior accuracy non-privately, we find that they also better maintain their accuracy when privacy is introduced.",
    "One-sentence Summary": "We show that by combining recent advances in NLP, parameter-efficiency, privacy accounting, and using larger models, one can privately fine-tune models whose utility approaches that of non-private models."
  },
  {
    "title": "P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts",
    "url": "/forum?id=DhzIU48OcZh",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "NLP, Prompting, Commonsense, information extraction, factual extraction, Large Language Models",
    "Abstract": "Recent work (e.g. LAMA (Petroni et al., 2019)) has found that the quality of the factual information extracted from Large Language Models (LLMs) depends on the prompts used to query them. This inconsistency is problematic because different users will query LLMs for the same information using different wording, but should receive the same, accurate responses regardless. In this work we aim to address this shortcoming by introducing P-Adapters: lightweight models that sit between the embedding layer and first attention layer of LLMs. They take LLM embeddings as input and output continuous prompts that are used to query the LLM. Additionally, we investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (the \"experts\") and select one to query the LLM. These require a separate classifier trained on human-annotated data to map natural language prompts to the continuous ones. P-Adapters perform comparably to the more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations. P-Adapters show between 12-26% absolute improvement in precision and 36-50% absolute improvement in consistency over a baseline of just using natural language queries alone. Finally, we investigate what makes P-Adapters successful and conclude that a significant factor is access to the LLM's embeddings of the original natural language prompt, particularly the subject of the entity pair being queried.",
    "One-sentence Summary": "We make prompting large language models for factual information more robust by introducing P-Adapter models."
  },
  {
    "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming",
    "url": "/forum?id=giBFoa-uS12",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multi-agent Reinforcement Learning, Cooperation and Coordination, Policy Gradient Optimization, Mutual Information, Iterated Reasoning",
    "Abstract": "Information sharing is key in building team cognition and enables coordination and cooperation. High-performing human teams also benefit from acting strategically with hierarchical levels of iterated communication and rationalizability, meaning a human agent can reason about the actions of their teammates in their decision-making. Yet, the majority of prior work in Multi-Agent Reinforcement Learning (MARL) does not support iterated rationalizability and only encourage inter-agent communication, resulting in a suboptimal equilibrium cooperation strategy. In this work, we show that reformulating an agent's policy to be conditional on the policies of its neighboring teammates inherently maximizes Mutual Information (MI) lower-bound when optimizing under Policy Gradient (PG). Building on the idea of decision-making under bounded rationality and cognitive hierarchy theory, we show that our modified PG approach not only maximizes local agent rewards but also implicitly reasons about MI between agents without the need for any explicit ad-hoc regularization terms. Our approach, InfoPG, outperforms baselines in learning emergent collaborative behaviors and sets the state-of-the-art in decentralized cooperative MARL tasks. Our experiments validate the utility of InfoPG by achieving higher sample efficiency and significantly larger cumulative reward in several complex cooperative multi-agent domains.",
    "One-sentence Summary": "We propose a MARL framework with iterated and hierarchical rationalizability through mutual information for decision-making in fully-decentralized cooperative and Byzantine scenarios."
  },
  {
    "title": "Step-unrolled Denoising Autoencoders for Text Generation",
    "url": "/forum?id=T0GpzBQ1Fg6",
    "date": "28 Sept 2021 (modified: 24 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "generative models, text generation, denoising autoencoders",
    "Abstract": "In this paper we propose a new generative model of text, Step-unrolled Denoising Autoencoder (SUNDAE), that does not rely on autoregressive models. Similarly to denoising diffusion techniques, SUNDAE is repeatedly applied on a sequence of tokens, starting from random inputs and improving them each time until convergence. We present a simple new improvement operator that converges in fewer iterations than diffusion methods, while qualitatively producing better samples on natural language datasets. SUNDAE achieves state-of-the-art results (among non-autoregressive methods) on the WMT'14 English-to-German translation task and good qualitative results on unconditional language modeling on the Colossal Cleaned Common Crawl dataset and a dataset of Python code from GitHub. The non-autoregressive nature of SUNDAE opens up possibilities beyond left-to-right prompted generation, by filling in arbitrary blank patterns in a template.",
    "One-sentence Summary": "We propose a new generative model of text that unrolls the denoising process during training."
  },
  {
    "title": "Hindsight Foresight Relabeling for Meta-Reinforcement Learning",
    "url": "/forum?id=P7OVkHEoHOZ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Meta-Learning",
    "Abstract": "Meta-reinforcement learning (meta-RL) algorithms allow for agents to learn new behaviors from small amounts of experience, mitigating the sample inefficiency problem in RL. However, while meta-RL agents can adapt quickly to new tasks at test time after experiencing only a few trajectories, the meta-training process is still sample-inefficient. Prior works have found that in the multi-task RL setting, relabeling past transitions and thus sharing experience among tasks can improve sample efficiency and asymptotic performance. We apply this idea to the meta-RL setting and devise a new relabeling method called Hindsight Foresight Relabeling (HFR). We construct a relabeling distribution using the combination of \"hindsight\", which is used to relabel trajectories using reward functions from the training task distribution, and \"foresight\", which takes the relabeled trajectories and computes the utility of each trajectory for each task. HFR is easy to implement and readily compatible with existing meta-RL algorithms. We find that HFR improves performance when compared to other relabeling methods on a variety of meta-RL tasks.",
    "One-sentence Summary": "We present HFR, a relabeling method that can be applied to meta-reinforcement learning to boost sample efficiency and performance."
  },
  {
    "title": "LoRA: Low-Rank Adaptation of Large Language Models",
    "url": "/forum?id=nZeVKeeFYf9",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Transfer learning, Adaptation, Transformer, Fine-tuning, Low-rank, RoBERTa, DeBERTa, GPT-2, GPT-3",
    "Abstract": "An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible.\n        Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by a factor of 10,000 and the GPU memory requirement by a factor of 3. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.",
    "One-sentence Summary": "Finetuning updates have a low \"intrinsic rank\" which allows us to train only the rank decomposition matrices of certain weights, yielding better performance and practical benefits."
  },
  {
    "title": "Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective",
    "url": "/forum?id=qRDQi3ocgR3",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "shortcut learning, shortcut bias, loss geometry, simplicity bias, flat minima, generalization, wisconsin card sorting test",
    "Abstract": "Deep neural networks (DNNs) often rely on easy\u2013to\u2013learn discriminatory features, or cues, that are not necessarily essential to the problem at hand. For example, ducks in an image may be recognized based on their typical background scenery, such as lakes or streams. This phenomenon, also known as shortcut learning, is emerging as a key limitation of the current generation of machine learning models. In this work, we introduce a set of experiments to deepen our understanding of shortcut learning and its implications. We design a training setup with several shortcut cues, named WCST-ML, where each cue is equally conducive to the visual recognition problem at hand. Even under equal opportunities, we observe that (1) certain cues are preferred to others, (2) solutions biased to the easy\u2013to\u2013learn cues tend to converge to relatively flat minima on the loss surface, and (3) the solutions focusing on those preferred cues are far more abundant in the parameter space. We explain the abundance of certain cues via their Kolmogorov (descriptional) complexity: solutions corresponding to Kolmogorov-simple cues are abundant in the parameter space and are thus preferred by DNNs. Our studies are based on the synthetic dataset DSprites and the face dataset UTKFace. In our WCST-ML, we observe that the inborn bias of models leans toward simple cues, such as color and ethnicity. Our findings emphasize the importance of active human intervention to remove the inborn model biases that may cause negative societal impacts.",
    "One-sentence Summary": "When given equally likely shortcuts in data, which shortcut cue will a DNN choose, and why?"
  },
  {
    "title": "Efficient Computation of Deep Nonlinear Infinite-Width Neural Networks that Learn Features",
    "url": "/forum?id=tUMr0Iox8XW",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "infinite-width neural network, feature learning, maximal update parametrization, NTK",
    "Abstract": "While a popular limit of infinite-width neural networks, the Neural Tangent Kernel (NTK) often exhibits performance gaps from finite-width neural networks on standard datasets, due to lack of feature learning. Although the feature learning *maximal update limit*, or *\u03bc-limit* (Yang and Hu, 2020) of wide networks has closed the gap for 1-hidden-layer linear models, no one has been able to demonstrate this for deep nonlinear multi-layer perceptrons (MLP) because of \u03bc-limit\u2019s computational difficulty in this setting.  Here, we solve this problem by proposing a novel feature learning limit, the *\u03c0-limit*, that bypasses the computational issues. The \u03c0-limit, in short, is the limit of a form of projected gradient descent, and the \u03c0-limit of an MLP is roughly another MLP where gradients are appended to weights during training. We prove its almost sure convergence with width using the Tensor Programs technique. We evaluate it on CIFAR10 and Omniglot against NTK as well as finite networks, finding the \u03c0-limit outperform finite-width models trained normally (without projection) in both settings, closing the performance gap between finite- and infinite-width neural networks previously left by NTK. Code for this work is available at github.com/santacml/pilim.",
    "One-sentence Summary": "A new feature learning \u221e-width limit for deep nonlinear networks closes the performance gap between finite- and infinite-width neural networks previously left by NTK."
  },
  {
    "title": "TRAIL: Near-Optimal Imitation Learning with Suboptimal Data",
    "url": "/forum?id=6q_2b6u0BnJ",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Imitation Learning, Action Representations, Latent Dynamics Model, Offline Datasets",
    "Abstract": "In imitation learning, one aims to learn task-solving policies using access to near-optimal expert trajectories collected from the task environment. However, high-quality trajectories -- e.g., from human experts -- can be expensive to obtain in practical settings. On the contrary, it is often much easier to obtain large amounts of suboptimal trajectories which can nevertheless provide insight into the structure of the environment, showing what \\emph{could} be done in the environment even if not what \\emph{should} be done. Is it possible to formalize these conceptual benefits and devise algorithms to use offline datasets to yield \\emph{provable} improvements to the sample-efficiency of imitation learning? In this work, we answer this question affirmatively and present training objectives which use an offline dataset to learn an approximate \\emph{factored} dynamics model whose structure enables the extraction of a \\emph{latent action space}. Our theoretical analysis shows that the learned latent action space can boost the sample-efficiency of downstream imitation learning, effectively reducing the need for large near-optimal expert datasets through the use of auxiliary non-expert data. We evaluate the practicality of our objective through experiments on a set of navigation and locomotion tasks. Our results verify the benefits suggested by our theory and show that our algorithms is able to recover near-optimal policies with fewer expert trajectories.",
    "One-sentence Summary": "A provably beneficial way to learn action representations for imitation learning from suboptimal auxiliary data."
  },
  {
    "title": "On the benefits of maximum likelihood estimation for Regression and Forecasting",
    "url": "/forum?id=zrW-LVXj2k1",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Forecasting, Time-Series, Regression, MLE",
    "Abstract": "We advocate for a practical Maximum Likelihood Estimation (MLE) approach towards designing loss functions for regression and forecasting, as an alternative to the typical approach of direct empirical risk minimization on a specific target metric. The MLE approach is better suited to capture inductive biases such as prior domain knowledge in datasets, and can output post-hoc estimators at inference time that can optimize different types of target metrics. We present theoretical results to demonstrate that our approach is competitive with any estimator for the target metric under some general conditions. In two example practical settings, Poisson and Pareto regression, we show that our competitive results can be used to prove that the MLE approach has better excess risk bounds than directly minimizing the target metric. We also demonstrate empirically that our method instantiated with a well-designed general purpose mixture likelihood family can obtain superior performance for a variety of tasks across time-series forecasting and regression datasets with different data distributions.",
    "One-sentence Summary": "MLE + Post-Hoc Inference can be competitive with any estimator under some general assumptions"
  },
  {
    "title": "Effect of scale on catastrophic forgetting in neural networks",
    "url": "/forum?id=GhVS8_yPeEa",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Catastrophic forgetting, continual learning, scaling, language modeling, image classification",
    "Abstract": "Catastrophic forgetting presents a challenge in developing deep learning models capable of continual learning, i.e. learning tasks sequentially. Recently, both computer vision and natural-language processing have witnessed great progress through the use of large-scale pretrained models. In this work, we present an empirical study of catastrophic forgetting in this pretraining paradigm.\n        Our experiments indicate that large, pretrained ResNets and Transformers are significantly more resistant to forgetting than randomly-initialized, trained-from-scratch models; this robustness systematically improves with scale of both model and pretraining dataset size.\n        We take initial steps towards characterizing what aspect of model representations allows them to perform continual learning so well, finding that in the pretrained models, distinct class representations grow more orthogonal with scale.  Our results suggest that, when possible, scale and a diverse pretraining dataset can be useful ingredients in mitigating catastrophic forgetting.",
    "One-sentence Summary": "We find that large, pre-trained models are robust to catastrophic forgetting."
  },
  {
    "title": "Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks",
    "url": "/forum?id=FndDxSz3LxQ",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, GNN, GCN, Distributed Training",
    "Abstract": "Despite the recent success of Graph Neural Networks (GNNs), training GNNs on large graphs remains challenging. The limited resource capacities of the existing servers, the dependency between nodes in a graph, and the privacy concern due to the centralized storage and model learning have spurred the need to design an effective distributed algorithm for GNN training. However, existing distributed GNN training methods impose either excessive communication costs or large memory overheads that hinders their scalability. To overcome these issues, we propose a communication-efficient distributed GNN training technique named $\\text{\\textit{Learn Locally, Correct Globally}}$ (LLCG). To reduce the communication and memory overhead, each local machine in LLCG first trains a GNN on its local data by ignoring the dependency between nodes among different machines, then sends the locally trained model to the server for periodic model averaging. However, ignoring node dependency could result in significant performance degradation. To solve the performance degradation, we propose to apply $\\text{\\textit{Global Server Corrections}}$ on the server to refine the locally learned models. We rigorously analyze the convergence of distributed methods  with periodic model averaging for training GNNs and show that naively applying periodic model averaging but ignoring the dependency between nodes will suffer from an irreducible residual error. However, this residual error can be eliminated  by utilizing the proposed global corrections to entail fast convergence rate. Extensive experiments on real-world datasets show that LLCG can significantly improve the efficiency without hurting the performance.",
    "One-sentence Summary": "We propose LLCG a communication efficient distributed algorithm for training GNNs."
  },
  {
    "title": "Conditional Image Generation by Conditioning Variational Auto-Encoders",
    "url": "/forum?id=7MV6uLzOChW",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "variational auto-encoders, Bayesian inference, variational inference, amortized inference, image completion",
    "Abstract": "We present a conditional variational auto-encoder (VAE) which, to avoid the substantial cost of training from scratch, uses an architecture and training objective capable of leveraging a foundation model in the form of a pretrained unconditional VAE. To train the conditional VAE, we only need to train an artifact to perform amortized inference over the unconditional VAE's latent variables given a conditioning input. We demonstrate our approach on tasks including image inpainting, for which it outperforms state-of-the-art GAN-based approaches at faithfully representing the inherent uncertainty. We conclude by describing a possible application of our inpainting model, in which it is used to perform Bayesian experimental design for the purpose of guiding a sensor.",
    "One-sentence Summary": "We create fast-to-train conditional VAEs using amortized inference in pretrained unconditional VAEs, and demonstrate diverse samples on image completion tasks."
  },
  {
    "title": "Learning 3D Representations of Molecular Chirality with Invariance to Bond Rotations",
    "url": "/forum?id=hm2tNDdgaFK",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "geometric deep learning, equivariance, molecules",
    "Abstract": "Molecular chirality, a form of stereochemistry most often describing relative spatial arrangements of bonded neighbors around tetrahedral carbon centers, influences the set of 3D conformers accessible to the molecule without changing its 2D graph connectivity. Chirality can strongly alter (bio)chemical interactions, particularly protein-drug binding. Most 2D graph neural networks (GNNs) designed for molecular property prediction at best use atomic labels to na\u00efvely treat chirality, while E(3)-invariant 3D GNNs are invariant to chirality altogether. To enable representation learning on molecules with defined stereochemistry, we design an SE(3)-invariant model that processes torsion angles of a 3D molecular conformer. We explicitly model conformational flexibility by integrating a novel type of invariance to rotations about internal molecular bonds into the architecture, mitigating the need for multi-conformer data augmentation. We test our model on four benchmarks: contrastive learning to distinguish conformers of different stereoisomers in a learned latent space, classification of chiral centers as R/S, prediction of how enantiomers rotate circularly polarized light, and ranking enantiomers by their docking scores in an enantiosensitive protein pocket. We compare our model, Chiral InterRoto-Invariant Neural Network (ChIRo), with 2D and 3D GNNs to demonstrate that our model achieves state of the art performance when learning chiral-sensitive functions from molecular structures.",
    "One-sentence Summary": "We propose a method of processing the 3D torsion angles of a molecular conformer to learn tetrahedral chirality while integrating a novel invariance to rotations about internal molecular bonds directly into the model architecture."
  },
  {
    "title": "Neural Methods for Logical Reasoning over Knowledge Graphs",
    "url": "/forum?id=tgcAoUVHRIB",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Knowledge Graphs, Knowledge Graph Reasoning, Graph Mining, Data Mining, Machine Learning, Artificial Intelligence, Deep Learning",
    "Abstract": "Reasoning is a fundamental problem for computers and deeply studied in Artificial Intelligence. In this paper, we specifically focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which includes negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to  handle FOL queries with Conjunction, Disjunction and Negation operators. We demonstrate experimentally the performance of our models through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10% relative increase over best performing state of the art and more than 30% over the original method based on single-point vector embeddings.",
    "One-sentence Summary": "Neural Network models for answering multi-hop queris on Knowledge Graphs"
  },
  {
    "title": "Consistent Counterfactuals for Deep Models",
    "url": "/forum?id=St6eyiTEHnG",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep models, deep networks, explainability, counterfactual explanations, consistency, consistent predictions, model duplicity, random initialization",
    "Abstract": "Counterfactual examples are one of the most commonly-cited methods for explaining the predictions of machine learning models in key areas such as finance and medical diagnosis. Counterfactuals are often discussed under the assumption that the model on which they will be used is static, but in deployment models may be periodically retrained or fine-tuned. This paper studies the consistency of model prediction on counterfactual examples in deep networks under small changes to initial training conditions, such as weight initialization and leave-one-out variations in data, as often occurs during model deployment. We demonstrate experimentally that counterfactual examples for deep models are often inconsistent across such small changes, and that increasing the cost of the counterfactual, a stability-enhancing mitigation suggested by prior work in the context of simpler models, is not a reliable heuristic in deep networks. Rather, our analysis shows that a model's Lipschitz continuity around the counterfactual, along with confidence of its prediction, is key to its consistency across related models. To this end, we propose Stable Neighbor Search as a way to generate more consistent counterfactual explanations, and illustrate the effectiveness of this approach on several benchmark datasets.",
    "One-sentence Summary": "Counterfactual explanations are often inconsistent between virtually identical deep models. We introduce a new method to increase consistency while keeping costs low relative to other fixes."
  },
  {
    "title": "Unified Visual Transformer Compression",
    "url": "/forum?id=9jsZiUgkCZP",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Vision Transformer, Model Compression, Pruning, Layer Skipping, Distillation",
    "Abstract": "Vision transformers (ViTs) have gained popularity recently. Even without customized image operators such as convolutions, ViTs can yield competitive performance when properly trained on massive data. However, the computational overhead of ViTs remains prohibitive, due to stacking multi-head self-attention modules and else. Compared to the vast literature and prevailing success in compressing convolutional neural networks, the study of Vision Transformer compression has also just emerged, and existing works focused on one or two aspects of compression. This paper proposes a unified ViT compression framework that seamlessly assembles three effective techniques: pruning, layer skipping, and knowledge distillation. We formulate a budget-constrained, end-to-end optimization framework, targeting jointly learning model weights, layer-wise pruning ratios/masks, and skip configurations, under a distillation loss. The optimization problem is then solved using the primal-dual algorithm. Experiments are conducted with several ViT variants, e.g. DeiT and T2T-ViT backbones on the ImageNet dataset, and our approach consistently outperforms recent competitors. For example, DeiT-Tiny can be trimmed down to 50\\% of the original FLOPs almost without losing accuracy. Codes are available online:~\\url{https://github.com/VITA-Group/UVC}.",
    "One-sentence Summary": "This paper proposes a unified ViT compression framework that seamlessly assembles three effective techniques: pruning, layer skipping, and knowledge distillation, which outperforms existing competitors."
  },
  {
    "title": "Transformer-based Transform Coding",
    "url": "/forum?id=IDwN6xjHnK8",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "transformer, transform coding, image compression, video compression",
    "Abstract": "Neural data compression based on nonlinear transform coding has made great progress over the last few years, mainly due to improvements in prior models, quantization methods and nonlinear transforms. A general trend in many recent works pushing the limit of rate-distortion performance is to use ever more expensive prior models that can lead to prohibitively slow decoding. Instead, we focus on more expressive transforms that result in a better rate-distortion-computation trade-off. Specifically, we show that nonlinear transforms built on Swin-transformers can achieve better compression efficiency than transforms built on convolutional neural networks (ConvNets), while requiring fewer parameters and shorter decoding time. Paired with a compute-efficient Channel-wise Auto-Regressive Model prior, our SwinT-ChARM model outperforms VTM-12.1 by $3.68\\%$ in BD-rate on Kodak with comparable decoding speed. In P-frame video compression setting, we are able to outperform the popular ConvNet-based scale-space-flow model by $12.35\\%$ in BD-rate on UVG. We provide model scaling studies to verify the computational efficiency of the proposed solutions and conduct several analyses to reveal the source of coding gain of transformers over ConvNets, including better spatial decorrelation, flexible effective receptive field, and more localized response of latent pixels during progressive decoding."
  },
  {
    "title": "Object Pursuit: Building a Space of Objects via Discriminative Weight Generation",
    "url": "/forum?id=lbauk6wK2-y",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "object-centric, continual learning, representation learning, hypernetwork",
    "Abstract": "We propose a framework to continuously learn object-centric representations for visual learning and understanding. Existing object-centric representations either rely on supervisions that individualize objects in the scene, or perform unsupervised disentanglement that can hardly deal with complex scenes in the real world. To mitigate the annotation burden and relax the constraints on the statistical complexity of the data, our method leverages interactions to effectively sample diverse variations of an object and the corresponding training signals while learning the object-centric representations. Throughout learning, objects are streamed one by one in random order with unknown identities, and are associated with latent codes that can synthesize discriminative weights for each object through a convolutional hypernetwork. Moreover, re-identification of learned objects and forgetting prevention are employed to make the learning process efficient and robust. We perform an extensive study of the key features of the proposed framework and analyze the characteristics of the learned representations. Furthermore, we demonstrate the capability of the proposed framework in learning representations that can improve label efficiency in downstream tasks. Our code and trained models are made publicly available at: https://github.com/pptrick/Object-Pursuit.",
    "One-sentence Summary": "We propose a novel framework named object pursuit that can continuously learn object-centric representations using training data collected from interactions with individual objects."
  },
  {
    "title": "PAC Prediction Sets Under Covariate Shift",
    "url": "/forum?id=DhP9L8vIyLc",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "probably approximately correct, prediction set, covariate shift, importance weight, calibration, Clopper-Pearson binomial interval, rejection sampling",
    "Abstract": "An important challenge facing modern machine learning is how to rigorously quantify the uncertainty of model predictions. Conveying uncertainty is especially important when there are changes to the underlying data distribution that might invalidate the predictive model. Yet, most existing uncertainty quantification algorithms break down in the presence of such shifts. We propose a novel approach that addresses this challenge by constructing \\emph{probably approximately correct (PAC)} prediction sets in the presence of covariate shift. Our approach focuses on the setting where there is a covariate shift from the source distribution (where we have labeled training examples) to the target distribution (for which we want to quantify uncertainty). Our algorithm assumes given importance weights that encode how the probabilities of the training examples change under the covariate shift. In practice, importance weights typically need to be estimated; thus, we extend our algorithm to the setting where we are given confidence intervals for the importance weights. We demonstrate the effectiveness of our approach on covariate shifts based on DomainNet and ImageNet. Our algorithm satisfies the PAC constraint, and gives prediction sets with the smallest average normalized size among approaches that always satisfy the PAC constraint.",
    "One-sentence Summary": "We propose a novel algorithm that constructs a prediction set with probably approximated correct (PAC) guarantee under covariate shift, while minimizing the expected prediction set size."
  },
  {
    "title": "Generalization of Neural Combinatorial Solvers Through the Lens of Adversarial Robustness",
    "url": "/forum?id=vJZ7dPIjip3",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generalization, Neural Combinatorial Optimization, Adversarial Robustness",
    "Abstract": "End-to-end (geometric) deep learning has seen first successes in approximating the solution of combinatorial optimization problems. However, generating data in the realm of NP-hard/-complete tasks brings practical and theoretical challenges, resulting in evaluation protocols that are too optimistic. Specifically, most datasets only capture a simpler subproblem and likely suffer from spurious features. We investigate these effects by studying adversarial robustness -a local generalization property- to reveal hard, model-specific instances and spurious features. For this purpose, we derive perturbation models for SAT and TSP. Unlike in other applications, where perturbation models are designed around subjective notions of imperceptibility, our perturbation models are efficient and sound, allowing us to determine the true label of perturbed samples without a solver. Surprisingly, with such perturbations, a sufficiently expressive neural solver does not suffer from the limitations of the accuracy-robustness trade-off common in supervised learning. Although such robust solvers exist, we show empirically that the assessed neural solvers do not generalize well w.r.t. small perturbations of the problem instance.",
    "One-sentence Summary": "We study the generalization of combinatorial optimization w.r.t. to adversarial attacks since current evaluation protocols are too optimistic and we show that neural solvers are indeed vulnerable under label-preserving perturbations."
  },
  {
    "title": "One After Another: Learning Incremental Skills for a Changing World",
    "url": "/forum?id=dg79moSRqIo",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Skill discovery, Incremental reinforcement learning",
    "Abstract": "Reward-free, unsupervised discovery of skills is an attractive alternative to the bottleneck of hand-designing rewards in environments where task supervision is scarce or expensive. However, current skill pre-training methods, like many RL techniques, make a fundamental assumption -- stationary environments during training. Traditional methods learn all their skills simultaneously, which makes it difficult for them to both quickly adapt to changes in the environment, and to not forget earlier skills after such adaptation. On the other hand, in an evolving or expanding environment, skill learning must be able to adapt fast to new environment situations while not forgetting previously learned skills. These two conditions make it difficult for classic skill discovery to do well in an evolving environment. In this work, we propose a new framework for skill discovery, where skills are learned one after another in an incremental fashion. This framework allows newly learned skills to adapt to new environment or agent dynamics, while the fixed old skills ensure the agent doesn't forget a learned skill. We demonstrate experimentally that in both evolving and static environments, incremental skills significantly outperform current state-of-the-art skill discovery methods on both skill quality and the ability to solve downstream tasks. Videos for learned skills and code are made public on https://notmahi.github.io/disk",
    "One-sentence Summary": "We discover skills incrementally, without supervision, and it lets us learn skills in both static environments and environments with changing dynamics."
  },
  {
    "title": "Graph-Guided Network for Irregularly Sampled Multivariate Time Series",
    "url": "/forum?id=Kwm8I7dU-l5",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "time seres, irregular time series, graph neural networks, attention mechanism, time series classification, multivariate time series, representation learning, embeddings",
    "Abstract": "In many domains, including healthcare, biology, and climate science, time series are irregularly sampled with varying time intervals between successive readouts and different subsets of variables (sensors) observed at different time points. Here, we introduce RAINDROP, a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data. RAINDROP represents every sample as a separate sensor graph and models time-varying dependencies between sensors with a novel message passing operator. It estimates the latent sensor graph structure and leverages the structure together with nearby observations to predict misaligned readouts. This model can be interpreted as a graph neural network that sends messages over graphs that are optimized for capturing time-varying dependencies among sensors. We use RAINDROP to classify time series and interpret temporal dynamics on three healthcare and human activity datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4% (absolute F1-score points), including techniques that deal with irregular sampling using fixed discretization and set functions. RAINDROP shows superiority in diverse setups, including challenging leave-sensor-out settings."
  },
  {
    "title": "FILM: Following Instructions in Language with Modular Methods",
    "url": "/forum?id=qI4542Y2s1D",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Instruction Following, Visual Language Navigation, Embodied Instruction Following, VLN, ALFRED",
    "Abstract": "Recent methods for embodied instruction following are typically trained end-to-end using imitation learning. This often requires the use of expert trajectories and low-level language instructions. Such approaches assume that neural states will integrate multimodal semantics to perform state tracking, building spatial memory, exploration, and long-term planning. In contrast, we propose a modular method with structured representations that (1) builds a semantic map of the scene and (2) performs exploration with a semantic search policy, to achieve the natural language goal. Our modular method achieves SOTA performance (24.46 %) with a substantial (8.17 % absolute) gap from previous work while using less data by eschewing both expert trajectories and low-level instructions. Leveraging low-level language, however, can further increase our performance (26.49 %). Our findings suggest that an explicit spatial memory and a semantic search policy can provide a stronger and more general representation for state-tracking and guidance, even in the absence of expert trajectories or low-level instructions.",
    "One-sentence Summary": "We propose a modular method for embodied instruction following; our method achieves SOTA on the ALFRED benchmark by a large margin while using less data by eschewing both expert trajectories and low-level instructions."
  },
  {
    "title": "The Evolution of Uncertainty of Learning in Games",
    "url": "/forum?id=Fza94Y8VS4a",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "learning in games, differential entropy",
    "Abstract": "Learning in games has become an object of intense interest for ML due to its connections to numerous AI architectures. We study standard online learning in games but from a non-standard perspective. Instead of studying the behavior of a single initial condition and whether it converges to equilibrium or not, we study the behavior of a probability distribution/measure over a set of initial conditions. This initial uncertainty is well-motivated both from a standard game-theoretic perspective (e.g. a modeler's uncertainty about the agents' initial beliefs) as well as from a ML one (e.g. noisy measurements, system initialization from a dataset distribution). Despite this, little is formally known about whether and under what conditions uncertainty is amplified or reduced in these systems. We use the popular measure of differential entropy to quantify the evolution of uncertainty. We find that such analysis shares an intimate relationship with volume analysis, a technique which was recently used to demonstrate the occurrence of Lyapunov chaos when using Multiplicative Weights Update (MWU) or Follow-the-Regularized-Leader (FTRL) algorithms in zero-sum games. This allows us to show that the differential entropy of these learning-in-game systems increases linearly with time, formalizing their increased unpredictability over time. We showcase the power of the framework by applying it in the study of multiple related systems, including different standard online optimization algorithms in numerous games and dynamics of evolutionary game theory.",
    "One-sentence Summary": "We show that the differential entropy of certain learning-in-game systems increases linearly with time, formalizing their increased unpredictability over time."
  },
  {
    "title": "Explainable GNN-Based Models over Knowledge Graphs",
    "url": "/forum?id=CrCvGNHAIrz",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Graph Neural Networks (GNNs) are often used to learn transformations of graph data. While effective in practice, such approaches make predictions via numeric manipulations so their output cannot be easily explained symbolically. We propose a new family of GNN-based transformations of graph data that can be trained effectively, but where all predictions can be explained symbolically as logical inferences in Datalog\u2014a well-known rule-based formalism. In particular, we show how to encode an input knowledge graph into a graph with numeric feature vectors, process this graph using a GNN, and decode the result into an output knowledge graph. We use a new class of monotonic GNNs (MGNNs) to ensure that this process is equivalent to a round of application of a set of Datalog rules. We also show that, given an arbitrary MGNN, we can automatically extract rules that completely characterise the transformation. We evaluate our approach by applying it to classification tasks in knowledge graph completion.",
    "One-sentence Summary": "We propose a new family of graph neural network-based transformations of graph data that can be trained effectively and where all predictions can be explained symbolically as logical inferences in Datalog."
  },
  {
    "title": "Mention Memory: incorporating textual knowledge into Transformers through entity mention attention",
    "url": "/forum?id=OY1A8ejQgEX",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "NLP, Entities and Relations, Memory",
    "Abstract": "Natural language understanding tasks such as open-domain question answering often require retrieving and assimilating factual information from multiple sources. We propose to address this problem by integrating a semi-parametric representation of a large text corpus into a Transformer model as a source of factual knowledge. \n        Specifically, our method represents knowledge with ``mention memory'', a table of dense vector representations of every entity mention in a corpus. The proposed model - TOME - is a Transformer that accesses the information through internal memory layers in which each entity mention in the input passage attends to the mention memory. This approach enables synthesis of and reasoning over many disparate sources of information within a single Transformer model. \n        In experiments using a memory of 150 million Wikipedia mentions, TOME achieves strong  performance on several open-domain knowledge-intensive tasks, including the claim verification benchmarks HoVer and FEVER and several entity-based QA benchmarks. We also show that the model learns to attend to informative mentions without any direct supervision.  Finally we demonstrate that the model can generalize to new unseen entities by updating the memory without retraining.",
    "One-sentence Summary": "Incorporate information from text corpus into Transformer model through within-model attention over table of entity mention representations."
  },
  {
    "title": "Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization",
    "url": "/forum?id=dDo8druYppX",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "shape reconstruction single image, meta learning, few-shot learning, differentiable optimization, bi-level optimization",
    "Abstract": "We propose a novel 3d shape representation for 3d shape reconstruction from a single image. Rather than predicting a shape directly, we train a network to generate a training set which will be fed into another learning algorithm to define the shape. The nested optimization problem can be modeled by bi-level optimization. Specifically, the algorithms for bi-level optimization are also being used in meta learning approaches for few-shot learning. Our framework establishes a link between 3D shape analysis and few-shot learning. We combine training data generating networks with bi-level optimization algorithms to obtain a complete framework for which all components can be jointly trained. We improve upon recent work on standard benchmarks for 3d shape reconstruction."
  },
  {
    "title": "Monotonic Differentiable Sorting Networks",
    "url": "/forum?id=IcUWShptD7d",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "differentiable sorting, monotonic, sorting, ranking, sorting networks",
    "Abstract": "Differentiable sorting algorithms allow training with sorting and ranking supervision, where only the ordering or ranking of samples is known. Various methods have been proposed to address this challenge, ranging from optimal transport-based differentiable Sinkhorn sorting algorithms to making classic sorting networks differentiable. One problem of current differentiable sorting methods is that they are non-monotonic. To address this issue, we propose a novel relaxation of conditional swap operations that guarantees monotonicity in differentiable sorting networks. We introduce a family of sigmoid functions and prove that they produce differentiable sorting networks that are monotonic. Monotonicity ensures that the gradients always have the correct sign, which is an advantage in gradient-based optimization. We demonstrate that monotonic differentiable sorting networks improve upon previous differentiable sorting methods."
  },
  {
    "title": "CrowdPlay: Crowdsourcing Human Demonstrations for Offline Learning",
    "url": "/forum?id=qyTBxTztIpQ",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Crowdsourcing has been instrumental for driving AI advances that rely on large-scale data. At the same time, reinforcement learning has seen rapid progress through  benchmark environments that strike a balance between tractability and real-world complexity, such as ALE and OpenAI Gym. In this paper, we aim to fill a gap at the intersection of these two: The use of crowdsourcing to generate large-scale human demonstration data in the support of advancing research into imitation learning and offline learning.\n        To this end, we present CrowdPlay, a complete crowdsourcing pipeline for any standard RL environment including OpenAI Gym (made available under an open-source license); a large-scale publicly available crowdsourced dataset of human gameplay demonstrations in Atari 2600 games, including multimodal behavior and human-human and human-AI multiagent data; offline learning benchmarks with extensive human data evaluation; and a detailed study of incentives, including real-time feedback to drive high quality data.\n        We hope that this will drive the improvement in design of algorithms that  account for the complexity of human, behavioral data and thereby enable a step forward in direction of effective learning for real-world settings. Our code and dataset are available at https://mgerstgrasser.github.io/crowdplay/.",
    "One-sentence Summary": "We provide a crowdsourcing pipeline for arbitrary RL environments, a first dataset on Atari games, and benchmark results."
  },
  {
    "title": "Model Agnostic Interpretability for Multiple Instance Learning",
    "url": "/forum?id=KSSfF5lMIAg",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multiple instance learning, interpretability, model-agnostic",
    "Abstract": "In Multiple Instance Learning (MIL), models are trained using bags of instances, where only a single label is provided for each bag. A bag label is often only determined by a handful of key instances within a bag, making it difficult to interpret what information a classifier is using to make decisions. In this work, we establish the key requirements for interpreting MIL models. We then go on to develop several model-agnostic approaches that meet these requirements. Our methods are compared against existing inherently interpretable MIL models on several datasets, and achieve an increase in interpretability accuracy of up to 30%. We also examine the ability of the methods to identify interactions between instances and scale to larger datasets, improving their applicability to real-world problems.",
    "One-sentence Summary": "We propose and compare several methods for model-agnostic interpretability for multiple instance learning."
  },
  {
    "title": "FastSHAP: Real-Time Shapley Value Estimation",
    "url": "/forum?id=Zq2G_VTV53T",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "interpretability, shapley, amortization, explainability, game theory",
    "Abstract": "Although Shapley values are theoretically appealing for explaining black-box models, they are costly to calculate and thus impractical in settings that involve large, high-dimensional models. To remedy this issue, we introduce FastSHAP, a new method for estimating Shapley values in a single forward pass using a learned explainer model. To enable efficient training without requiring ground truth Shapley values, we develop an approach to train FastSHAP via stochastic gradient descent using a weighted least-squares objective function. In our experiments with tabular and image datasets, we compare FastSHAP to existing estimation approaches and find that it generates accurate explanations with an orders-of-magnitude speedup.",
    "One-sentence Summary": "We introduce FastSHAP, a new method for estimating Shapley values in a single forward pass using an explainer model that is learned via stochastic gradient optimization using a weighted least squares-like objective function."
  },
  {
    "title": "When, Why, and Which Pretrained GANs Are Useful?",
    "url": "/forum?id=4Ycr8oeCoIh",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "GAN, pretraining",
    "Abstract": "The literature has proposed several methods to finetune pretrained GANs on new datasets, which typically results in higher performance compared to training from scratch, especially in the limited-data regime. However, despite the apparent empirical benefits of GAN pretraining, its inner mechanisms were not analyzed in-depth, and understanding of its role is not entirely clear. Moreover, the essential practical details, e.g., selecting a proper pretrained GAN checkpoint, currently do not have rigorous grounding and are typically determined by trial and error. \n        \n        This work aims to dissect the process of GAN finetuning. First, we show that initializing the GAN training process by a pretrained checkpoint primarily affects the model's coverage rather than the fidelity of individual samples. Second, we explicitly describe how pretrained generators and discriminators contribute to the finetuning process and explain the previous evidence on the importance of pretraining both of them. Finally, as an immediate practical benefit of our analysis, we describe a simple recipe to choose an appropriate GAN checkpoint that is the most suitable for finetuning to a particular target task. Importantly, for most of the target tasks, Imagenet-pretrained GAN, despite having poor visual quality, appears to be an excellent starting point for finetuning, resembling the typical pretraining scenario of discriminative computer vision models."
  },
  {
    "title": "A global convergence theory for deep ReLU implicit networks via over-parameterization",
    "url": "/forum?id=R332S76RjxS",
    "date": "28 Sept 2021 (modified: 18 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep learning, Deep implicit learning, deep equilibrium model, gradient descent, stochastic gradient descent, over-parameterization",
    "Abstract": "Implicit deep learning has received increasing attention recently due to the fact that it generalizes the recursive prediction rule of many commonly used neural network architectures. Its prediction rule is provided implicitly based on the solution of an equilibrium equation. Although a line of recent empirical studies has demonstrated its superior performances, the theoretical understanding of implicit neural networks is limited. In general, the equilibrium equation may not be well-posed during the training. As a result, there is no guarantee that a vanilla (stochastic) gradient descent (SGD) training nonlinear implicit neural networks can converge. This paper fills the gap by analyzing the gradient flow of Rectified Linear Unit (ReLU) activated implicit neural networks. For an $m$ width implicit neural network with ReLU activation and $n$ training samples, we show that a randomly initialized gradient descent converges to a global minimum at a linear rate for the square loss function if the implicit neural network is over-parameterized. It is worth noting that, unlike existing works on the convergence of (S)GD on finite-layer over-parameterized neural networks, our convergence results hold for implicit neural networks, where the number of layers is infinite.",
    "One-sentence Summary": "For a ReLU activated implicit neural network with infinitely many layers, we prove that randomly initialized gradient descent with a fixed step-size converges to a global minimum at a linear rate if the width m is the squared sample size n."
  },
  {
    "title": "Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations",
    "url": "/forum?id=6VpeS27viTq",
    "date": "28 Sept 2021 (modified: 03 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Owing much to the revolution of information technology, recent progress of deep learning benefits incredibly from the vastly enhanced access to data available in various digital formats. Yet those publicly accessible information also raises a fundamental issue concerning Intellectual Property, that is, how to precisely control legal or illegal exploitation of a dataset for training commercial models. To tackle this issue, this paper introduces and investigates a new concept called ''learnability lock'' for securing the process of data authorization. In particular, we propose adversarial invertible transformation, that can be viewed as a mapping from image to image, to encrypt data samples so that they become ''unlearnable'' by machine learning models with negligible loss of visual features. Meanwhile, authorized clients can use a specific key to unlock the learnability of the protected dataset and train models normally. The proposed learnability lock leverages class-wise perturbation that applies a universal transformation function on data samples of the same label. This ensures that the learnability can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse-engineered. We empirically demonstrate the success and practicability of our method on visual classification tasks."
  },
  {
    "title": "Federated Learning from Only Unlabeled Data with Class-conditional-sharing Clients",
    "url": "/forum?id=WHA8009laxu",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "unsupervised federated learning, unlabeled data, class prior shift",
    "Abstract": "Supervised federated learning (FL) enables multiple clients to share the trained model without sharing their labeled data. However, potential clients might even be reluctant to label their own data, which could limit the applicability of FL in practice. In this paper, we show the possibility of unsupervised FL whose model is still a classifier for predicting class labels, if the class-prior probabilities are shifted while the class-conditional distributions are shared among the unlabeled data owned by the clients. We propose federation of unsupervised learning (FedUL), where the unlabeled data are transformed into surrogate labeled data for each of the clients, a modified model is trained by supervised FL, and the wanted model is recovered from the modified model. FedUL is a very general solution to unsupervised FL: it is compatible with many supervised FL methods, and the recovery of the wanted model can be theoretically guaranteed as if the data have been labeled. Experiments on benchmark and real-world datasets demonstrate the effectiveness of FedUL. Code is available at https://github.com/lunanbit/FedUL.",
    "One-sentence Summary": "Federated learning: no label no cry"
  },
  {
    "title": "Transformer Embeddings of Irregularly Spaced Events and Their Participants",
    "url": "/forum?id=Rty5g9imm7H",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "irregular time series, generative Transformers, neuro-symbolic architectures, logic programming",
    "Abstract": "The neural Hawkes process (Mei & Eisner, 2017) is a generative model of irregularly spaced sequences of discrete events. To handle complex domains with many event types, Mei et al. (2020a) further consider a setting in which each event in the sequence updates a deductive database of facts (via domain-specific pattern-matching rules); future events are then conditioned on the database contents. They show how to convert such a symbolic system into a neuro-symbolic continuous-time generative model, in which each database fact and possible event has a time-varying embedding that is derived from its symbolic provenance. \n        \n        In this paper, we modify both models, replacing their recurrent LSTM-based architectures with flatter attention-based architectures (Vaswani et al., 2017), which are simpler and more parallelizable. This does not appear to hurt our accuracy, which is comparable to or better than that of the original models as well as (where applicable) previous attention-based methods (Zuo et al., 2020; Zhang et al., 2020a).",
    "One-sentence Summary": "We design a generative continuous-time Transformer for embedding irregularly spaced events and their participants."
  },
  {
    "title": "Fast Model Editing at Scale",
    "url": "/forum?id=0DcZxeWfOPt",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "editing, transfomers, meta-learning",
    "Abstract": "While large pre-trained models have enabled impressive results on a variety of downstream tasks, the largest existing models still make errors, and even accurate predictions may become outdated over time. Because detecting all such failures at training time is impossible, enabling both developers and end users of such models to correct inaccurate outputs while leaving the model otherwise intact is desirable. However, the distributed, black-box nature of the representations learned by large neural networks makes producing such targeted edits difficult. If presented with only a single problematic input and new desired output, fine-tuning approaches tend to overfit; other editing algorithms are either computationally infeasible or simply ineffective when applied to very large models. To enable easy post-hoc editing at scale, we propose Model Editor Networks using Gradient Decomposition (MEND), a collection of small auxiliary editing networks that use a single desired input-output pair to make fast, local edits to a pre-trained model's behavior. MEND learns to transform the gradient obtained by standard fine-tuning, using a low-rank decomposition of the gradient to make the parameterization of this transformation tractable. MEND can be trained on a single GPU in less than a day even for 10 billion+ parameter models; once trained MEND enables rapid application of new edits to the pre-trained model. Our experiments with T5, GPT, BERT, and BART models show that MEND is the only approach to model editing that effectively edits the behavior of models with more than 10 billion parameters. Code available at https://sites.google.com/view/mend-editing.",
    "One-sentence Summary": "A computationally efficient approach for learning to edit the behavior of very large pre-trained language models (10 billion+ parameters)"
  },
  {
    "title": "Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic Objectives with Skewed Hessian Spectrums",
    "url": "/forum?id=rTAclwH46Tb",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "optimization, learning rate schedule, optimal convergence rate",
    "Abstract": "Learning rate schedulers have been widely adopted in training deep neural networks. Despite their practical importance, there is a discrepancy between its practice and its theoretical analysis. For instance, it is not known what schedules of SGD achieve best convergence, even for simple problems such as optimizing quadratic objectives. In this paper, we propose Eigencurve, the first family of learning rate schedules that can achieve minimax optimal convergence rates (up to a constant) for SGD on quadratic objectives when the eigenvalue distribution of the underlying Hessian matrix is skewed. The condition is quite common in practice. Experimental results show that Eigencurve can significantly outperform step decay in image classification tasks on CIFAR-10, especially when the number of epochs is small. Moreover, the theory inspires two simple learning rate schedulers for practical applications that can approximate eigencurve.\n         For some problems, the optimal shape of the proposed schedulers resembles that of cosine decay, which sheds light to the success of cosine decay for such situations. For other situations, the proposed schedulers are superior to cosine decay.",
    "One-sentence Summary": "A learning rate schedule which achieves minimax optimal convergence rate (up to a constant) for SGD on quadratic objectives with skewed Hessian spectrums."
  },
  {
    "title": "An Autoregressive Flow Model for 3D Molecular Geometry Generation from Scratch",
    "url": "/forum?id=C03Ajc-NS5W",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "3D molecular geometry generation, flow models, SphereNet",
    "Abstract": "We consider the problem of generating 3D molecular geometries from scratch. While multiple methods have been developed for generating molecular graphs, generating 3D molecular geometries from scratch is largely under-explored. In this work, we propose G-SphereNet, a novel autoregressive flow model for generating 3D molecular geometries. G-SphereNet employs a flexible sequential generation scheme by placing atoms in 3D space step-by-step. Instead of generating 3D coordinates directly, we propose to determine 3D positions of atoms by generating distances, angles and torsion angles, thereby ensuring both invariance and equivariance properties. In addition, we propose to use spherical message passing and attention mechanism for conditional information extraction. Experimental results show that G-SphereNet outperforms previous methods on random molecular geometry generation and targeted molecule discovery tasks. Our code is publicly available as part of the DIG package (https://github.com/divelab/DIG).",
    "One-sentence Summary": "We present a novel method for 3D molecular geometry generation from scratch."
  },
  {
    "title": "On Incorporating Inductive Biases into VAEs",
    "url": "/forum?id=nzvbBD_3J-g",
    "date": "28 Sept 2021 (modified: 14 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "VAEs, Variational autoencoders, Variational auto-encoders, Representation learning, Inductive biases",
    "Abstract": "We explain why directly changing the prior can be a surprisingly ineffective mechanism for incorporating inductive biases into variational auto-encoders (VAEs), and introduce a simple and effective alternative approach: Intermediary Latent Space VAEs (InteL-VAEs). InteL-VAEs use an intermediary set of latent variables to control the stochasticity of the encoding process, before mapping these in turn to the latent representation using a parametric function that encapsulates our desired inductive bias(es). This allows us to impose properties like sparsity or clustering on learned representations, and incorporate human knowledge into the generative model. Whereas changing the prior only indirectly encourages behavior through regularizing the encoder, InteL-VAEs are able to directly enforce desired characteristics. Moreover, they bypass the computation and encoder design issues caused by non-Gaussian priors, while allowing for additional flexibility through training of the parametric mapping function. We show that these advantages, in turn, lead to both better generative models and better representations being learned.",
    "One-sentence Summary": "A flexible and effective framework for adding inductive biases to VAEs that corrects the pathologies of previous approaches and leads to improved representations and generative models."
  },
  {
    "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools",
    "url": "/forum?id=Kef8cKdHWpP",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deformable Object Manipulation, Differentiable Physics",
    "Abstract": "We consider the problem of sequential robotic manipulation of deformable objects using tools.\n        Previous works have shown that differentiable physics simulators provide gradients to the environment state and help trajectory optimization to converge orders of magnitude faster than model-free reinforcement learning algorithms for deformable object manipulation. However, such gradient-based trajectory optimization typically requires access to the full simulator states and can only solve short-horizon, single-skill tasks due to local optima. In this work, we propose a novel framework, named DiffSkill, that uses a differentiable physics simulator for skill abstraction to solve long-horizon deformable object manipulation tasks from sensory observations. In particular, we first obtain short-horizon skills using individual tools from a gradient-based optimizer, using the full state information in a differentiable simulator; we then learn a neural skill abstractor from the demonstration trajectories which takes RGBD images as input. Finally, we plan over the skills by finding the intermediate goals and then solve long-horizon tasks. We show the advantages of our method in a new set of sequential deformable object manipulation tasks compared to previous reinforcement learning algorithms and compared to the trajectory optimizer.",
    "One-sentence Summary": "We propose DiffSkill, a novel framework for learning skill abstraction from differentiable physics and compose them to solve long-horizontal deformable object manipulations tasks from sensory observation."
  },
  {
    "title": "On the Existence of Universal Lottery Tickets",
    "url": "/forum?id=SYB4WrJql1n",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "theory, deep learning, lottery tickets, universality",
    "Abstract": "The lottery ticket hypothesis conjectures the existence of sparse subnetworks of large randomly initialized deep neural networks that can be successfully trained in isolation. Recent work has experimentally observed that some of these tickets can be practically reused across a variety of tasks, hinting at some form of universality. We formalize this concept and theoretically prove that not only do such universal tickets exist but they also do not require further training. Our proofs introduce a couple of technical innovations related to pruning for strong lottery tickets, including extensions of subset sum results and a strategy to leverage higher amounts of depth. Our explicit sparse constructions of universal function families might be of independent interest, as they highlight representational benefits induced by univariate convolutional architectures.",
    "One-sentence Summary": "We formalize a notion of strong universal lottery tickets and prove their existence as subnetworks of randomly initialized neural networks."
  },
  {
    "title": "Pre-training Molecular Graph Representation with 3D Geometry",
    "url": "/forum?id=xQUe1pOKPam",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Pre-training, SSL, Molecule, 3D Geometry, 2D representation",
    "Abstract": "Molecular graph representation learning is a fundamental problem in modern drug and material discovery. Molecular graphs are typically modeled by their 2D topological structures, but it has been recently discovered that 3D geometric information plays a more vital role in predicting molecular functionalities. However, the lack of 3D information in real-world scenarios has significantly impeded the learning of geometric graph representation. To cope with this challenge, we propose the Graph Multi-View Pre-training (GraphMVP) framework where self-supervised learning (SSL) is performed by leveraging the correspondence and consistency between 2D topological structures and 3D geometric views. GraphMVP effectively learns a 2D molecular graph encoder that is enhanced by richer and more discriminative 3D geometry. We further provide theoretical insights to justify the effectiveness of GraphMVP. Finally, comprehensive experiments show that GraphMVP can consistently outperform existing graph SSL methods. Code is available on GitHub: https://github.com/chao1224/GraphMVP.",
    "One-sentence Summary": "We proposed a new SSL framework to make 3D geomety information helpful for 2D representation, in terms of the downstream tasks with 2D info only."
  },
  {
    "title": "PER-ETD: A Polynomially Efficient Emphatic Temporal Difference Learning Method",
    "url": "/forum?id=-HSOjDPfhBJ",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "emphatic temporal difference, finite-time analysis, off-policy evaluation, reinforcement learning",
    "Abstract": "Emphatic temporal difference (ETD) learning (Sutton et al., 2016) is a successful method to conduct the off-policy value function evaluation with function approximation. Although ETD has been shown to converge asymptotically to a desirable value function, it is well-known that ETD often encounters a large variance so that its sample complexity can increase exponentially fast with the number of iterations. In this work, we propose a new ETD method, called PER-ETD (i.e., PEriodically Restarted-ETD), which restarts and updates the follow-on trace only for a finite period for each iteration of the evaluation parameter. Further, PER-ETD features a design of the logarithmical increase of the restart period with the number of iterations, which guarantees the best trade-off between the variance and bias and keeps both vanishing sublinearly. We show that PER-ETD converges to the same desirable fixed point as ETD, but improves the exponential sample complexity of ETD to be polynomials. Our experiments validate the superior performance of PER-ETD and its advantage over ETD.",
    "One-sentence Summary": "We propose a new off-policy evaluation algorithm called PER-ETD (i.e., PEriodically Restarted Emphatic TD), which improves upon its precursor ETD with reduced variance and polynomial sample efficiency."
  },
  {
    "title": "Taming Sparsely Activated Transformer with Stochastic Experts",
    "url": "/forum?id=B72HXs80q4",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts. In this paper, we propose a new expert-based model, THOR ($\\underline{\\textbf{T}}$ransformer wit$\\underline{\\textbf{H}}$ St$\\underline{\\textbf{O}}$chastic Expe$\\underline{\\textbf{R}}$ts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions.  We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts.",
    "One-sentence Summary": "We propose a new variant of MoE, Transformer with Stochastic Experts, that is more parameter efficient."
  },
  {
    "title": "Hierarchical Variational Memory for Few-shot Learning Across Domains",
    "url": "/forum?id=i3RI65sR7N",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Meta-learning, Variational hierarchical memory, Variational hierarchical prototype, Cross-domain few-shot learning",
    "Abstract": "Neural memory enables fast adaptation to new tasks with just a few training samples. Existing memory models store features only from the single last layer, which does not generalize well in presence of a domain shift between training and test distributions. Rather than relying on a flat memory, we propose a hierarchical alternative that stores features at different semantic levels. We introduce a hierarchical prototype model, where each level of the prototype fetches corresponding information from the hierarchical memory. The model is endowed with the ability to flexibly rely on features at different semantic levels if the domain shift circumstances so demand. We meta-learn the model by a newly derived hierarchical variational inference framework, where hierarchical memory and prototypes are jointly optimized. To explore and exploit the importance of different semantic levels, we further propose to learn the weights associated with the prototype at each level in a data-driven way, which enables the model to adaptively choose the most generalizable features. We conduct thorough ablation studies to demonstrate the effectiveness of each component in our model. The new state-of-the-art performance on cross-domain and competitive performance on traditional few-shot classification further substantiates the benefit of hierarchical variational memory.",
    "One-sentence Summary": "We propose a hierarchical memory that stores features at different semantic levels for the cross-domain few-shot learning."
  },
  {
    "title": "Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction",
    "url": "/forum?id=Z1Qlm11uOM",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "audio-visual speech recognition, lip reading, speech recognition, self-supervised learning",
    "Abstract": "Video recordings of speech contain correlated audio and visual information, providing a strong signal for speech representation learning from the speaker\u2019s lip movements and the produced sound. We introduce Audio-Visual Hidden Unit BERT (AV-HuBERT), a self-supervised representation learning framework for audio-visual speech, which masks multi-stream video input and predicts automatically discovered and iteratively refined multimodal hidden units. AV-HuBERT learns powerful audio-visual speech representation benefiting both lip-reading and automatic speech recognition. On the largest public lip-reading benchmark LRS3 (433 hours), AV-HuBERT achieves 32.5% WER with only 30 hours of labeled data, outperforming the former state-of-the-art approach (33.6%) trained with a thousand times more transcribed video data (31K hours) (Makino et al., 2019). The lip-reading WER is further reduced to 26.9% when using all 433 hours of labeled data from LRS3 and combined with self-training. Using our audio-visual representation on the same benchmark for audio-only speech recognition leads to a 40% relative WER reduction over the state-of-the-art performance (1.3% vs 2.3%). Our code and models are available at https://github.com/facebookresearch/av_hubert.",
    "One-sentence Summary": "A self-supervised learning framework for audio-visual speech data, which uses only 30h of labeled data to match the SOTA lip-reading model trained on 31k hours of data (34.6% vs 33.6% WER), and further outperforms the SOTA with 70x less data (30.6%)."
  },
  {
    "title": "An Explanation of In-context Learning as Implicit Bayesian Inference",
    "url": "/forum?id=RdJVFCHjUMI",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "in-context learning, language modeling, pre-training, GPT-3",
    "Abstract": "Large language models (LMs) such as GPT-3 have the surprising ability to do in-context learning, where the model learns to do a downstream task simply by conditioning on a prompt consisting of input-output examples. The LM learns from these examples without being explicitly pretrained to learn. Thus, it is unclear what enables in-context learning. In this paper, we study how in-context learning can emerge when pretraining documents have long-range coherence. Here, the LM must infer a latent document-level concept to generate coherent next tokens during pretraining. At test time, in-context learning occurs when the LM also infers a shared latent concept between examples in a prompt. We prove when this occurs despite a distribution mismatch between prompts and pretraining data in a setting where the pretraining distribution is a mixture of HMMs. In contrast to messy large-scale datasets used to train LMs capable of in-context learning, we generate a small-scale synthetic dataset (GINC) where Transformers and LSTMs both exhibit in-context learning. Beyond the theory, experiments on GINC exhibit large-scale real-world phenomena including improved in-context performance with model scaling (despite the same pretraining loss), sensitivity to example order, and instances where zero-shot is better than few-shot in-context learning.",
    "One-sentence Summary": "In-context learning emerges both theoretically and empirically when the pretraining distribution is a mixture distribution, resulting in the language model implicitly performing Bayesian inference in its forward pass."
  },
  {
    "title": "Differentiable Scaffolding Tree for Molecule Optimization",
    "url": "/forum?id=w_drCosT76",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "The structural design of functional molecules, also called molecular optimization, is an essential chemical science and engineering task with important applications, such as drug discovery. Deep generative models and combinatorial optimization methods achieve initial success but still struggle with directly modeling discrete chemical structures and often heavily rely on brute-force enumeration. The challenge comes from the discrete and non-differentiable nature of molecule structures. To address this, we propose differentiable scaffolding tree (DST) that utilizes a learned knowledge network to convert discrete chemical structures to locally differentiable ones. DST enables a gradient-based optimization on a chemical graph structure by back-propagating the derivatives from the target properties through a graph neural network (GNN). Our empirical studies show the gradient-based molecular optimizations are both effective and sample efficient (in terms of oracle calling number). Furthermore, the learned graph parameters can also provide an explanation that helps domain experts understand the model output. The code repository (including processed data, trained model, demonstration, molecules with the highest property) is available at https://github.com/futianfan/DST.",
    "One-sentence Summary": "make the molecular optimization problem differentiable at the structure level"
  },
  {
    "title": "Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise",
    "url": "/forum?id=B3Nde6lvab",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Stochastic Gradient Descent, SGD, Heavy-Tails, Generalization",
    "Abstract": "The empirical success of deep learning is often attributed to SGD\u2019s mysterious ability to avoid sharp local minima in the loss landscape, as sharp minima are  known to lead to poor generalization. Recently, empirical evidence of heavy-tailed gradient noise was reported in many deep learning tasks; and it was shown in (Simsekli et al., 2019a;b) that SGD can escape sharp local minima under the presence of such heavy-tailed gradient noise, providing a partial solution to the mystery. In this work, we analyze a popular variant of SGD where gradients are truncated above a fixed threshold. We show that it achieves a stronger notion of avoiding sharp minima: it can effectively eliminate sharp local minima entirely from its training trajectory. We characterize the dynamics of truncated SGD driven by heavy-tailed noises. First, we show that the truncation threshold and width of the attraction field dictate the order of the first exit time from the associated local minimum. Moreover, when the objective function satisfies appropriate structural conditions, we prove that as the learning rate decreases, the dynamics of the heavy-tailed truncated SGD closely resemble those of a continuous-time Markov chain that never visits any sharp minima. Real data experiments on deep learning confirm our theoretical prediction that heavy-tailed SGD with gradient clipping finds a flatter local minima and achieves better generalization.",
    "One-sentence Summary": "Empirical evidence and the first theoretical analysis that show SGD with truncated heavy-tailed gradient noise finds flatter minima and achieves better generalization."
  },
  {
    "title": "Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System",
    "url": "/forum?id=uxxFrDwrE7Y",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Continual Learning, Catastrophic Forgetting, Complementary Learning Systems Theory, Experience Replay",
    "Abstract": "Humans excel at continually learning from an ever-changing environment whereas it remains a challenge for deep neural networks which exhibit catastrophic forgetting. The complementary learning system (CLS) theory suggests that the interplay between rapid instance-based learning and slow structured learning in the brain is crucial for accumulating and retaining knowledge. Here, we propose CLS-ER, a novel dual memory experience replay (ER) method which maintains short-term and long-term semantic memories that interact with the episodic memory. Our method employs an effective replay mechanism whereby new knowledge is acquired while aligning the decision boundaries with the semantic memories. CLS-ER does not utilize the task boundaries or make any assumption about the distribution of the data which makes it versatile and suited for ``general continual learning''. Our approach achieves state-of-the-art performance on standard benchmarks as well as more realistic general continual learning settings.",
    "One-sentence Summary": "A dual memory experience replay method which aims to mimic the interplay between fast learning and slow learning mechanisms for enabling effective CL in DNNs."
  },
  {
    "title": "FedChain: Chained Algorithms for Near-optimal Communication Cost in Federated Learning",
    "url": "/forum?id=ZaVVVlcdaN",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, Optimization, Distributed Optimization",
    "Abstract": "Federated learning (FL) aims to minimize the communication complexity of training a model over heterogeneous data distributed across many clients. A common approach is local methods, where clients take multiple optimization steps over local data before communicating with the server (e.g., FedAvg).  Local methods can exploit similarity between clients' data. However, in existing analyses, this comes at the cost of slow convergence in terms of the dependence on the number of communication rounds R.  On the other hand, global methods, where clients simply return a gradient vector in each round (e.g., SGD), converge faster in terms of R but fail to exploit the similarity between clients even when clients are homogeneous.  We propose FedChain, an algorithmic framework that combines the strengths of local methods and global methods to achieve fast convergence in terms of R while  leveraging the similarity between clients.  Using FedChain, we instantiate algorithms that improve upon previously known rates in the general convex and PL settings, and are near-optimal (via an algorithm-independent lower bound that we show) for problems that satisfy strong convexity.  Empirical results support this theoretical gain over existing methods."
  },
  {
    "title": "What Do We Mean by Generalization in Federated Learning?",
    "url": "/forum?id=VimqQq-i_Q",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, generalization, heterogeneity",
    "Abstract": "Federated learning data is drawn from a distribution of distributions: clients are drawn from a meta-distribution, and their data are drawn from local data distributions. Generalization studies in federated learning should separate performance gaps from unseen client data (out-of-sample gap) from performance gaps from unseen client distributions (participation gap). In this work, we propose a framework for disentangling these performance gaps. Using this framework, we observe and explain differences in behavior across natural and synthetic federated datasets, indicating that dataset synthesis strategy can be important for realistic simulations of generalization in federated learning. We propose a semantic synthesis strategy that enables realistic simulation without naturally partitioned data. Informed by our \ufb01ndings, we call out community suggestions for future federated learning works.",
    "One-sentence Summary": "We propose a framework for better measuring generalization and heterogeneity in federated learning, apply it for extensive empirical evaluation across six tasks, and make a series of recommendations for future FL works."
  },
  {
    "title": "Frequency-aware SGD for Efficient Embedding Learning with Provable Benefits",
    "url": "/forum?id=ibqTBNfJmi",
    "date": "28 Sept 2021 (modified: 03 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Embedding learning has found widespread applications in recommendation systems and natural language modeling, among other domains. To learn quality embeddings efficiently, adaptive learning rate algorithms have demonstrated superior empirical performance over SGD, largely accredited to their token-dependent learning rate. However, the underlying mechanism for the efficiency of token-dependent learning rate remains underexplored. We show that incorporating frequency information of tokens in the embedding learning problems leads to provably efficient algorithms, and demonstrate that common adaptive algorithms implicitly exploit the frequency information to a large extent. Specifically, we propose (Counter-based) Frequency-aware Stochastic Gradient Descent, which applies a frequency-dependent learning rate for each token, and exhibits provable speed-up compared to SGD when the token distribution is imbalanced. Empirically, we show the proposed algorithms are able to improve or match the performance of adaptive algorithms on benchmark recommendation tasks and a large-scale industrial recommendation system,  closing the performance gap between SGD and adaptive algorithms. Our results are the first to show token-dependent learning rate provably improves convergence for non-convex embedding learning problems."
  },
  {
    "title": "Learning Curves for Gaussian Process Regression with Power-Law Priors and Targets",
    "url": "/forum?id=KeI9E-gsoB",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Gaussian process regression, kernel ridge regression, generalization error, power law, neural tangent kernel",
    "Abstract": "We characterize the power-law asymptotics of learning curves for Gaussian process regression (GPR) under the assumption that the eigenspectrum of the prior and the eigenexpansion coefficients of the target function follow a power law. Under similar assumptions, we leverage the equivalence between GPR and kernel ridge regression (KRR) to show the generalization error of KRR. Infinitely wide neural networks can be related to GPR with respect to the neural network GP kernel and the neural tangent kernel, which in several cases is known to have a power-law spectrum. Hence our methods can be applied to study the generalization error of infinitely wide neural networks. We present toy experiments demonstrating the theory.",
    "One-sentence Summary": "We derive the power-law decay rate of the generalization error in Gaussian process regression depending on the eigenspectrum of the prior and the target."
  },
  {
    "title": "Fast topological clustering with Wasserstein distance",
    "url": "/forum?id=0kPL3xO4R5",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Topological data analysis, cluster analysis, persistent homology, Wasserstein distance, Wasserstein barycenter, brain networks, intracranial electrophysiology, consciousness",
    "Abstract": "The topological patterns exhibited by many real-world networks motivate the development of topology-based methods for assessing the similarity of networks. However, extracting topological structure is difficult, especially for large and dense networks whose node degrees range over multiple orders of magnitude. In this paper, we propose a novel and computationally practical topological clustering method that clusters complex networks with intricate topology using principled theory from persistent homology and optimal transport. Such networks are aggregated into clusters through a centroid-based clustering strategy based on both their topological and geometric structure, preserving correspondence between nodes in different networks. The notions of topological proximity and centroid are characterized using a novel and efficient approach to computation of the Wasserstein distance and barycenter for persistence barcodes associated with connected components and cycles. The proposed method is demonstrated to be effective using both simulated networks and measured functional brain networks.",
    "One-sentence Summary": "In this paper, we propose a novel and computationally practical topological clustering method that clusters complex networks with intricate topology using principled theory from persistent homology and optimal transport."
  },
  {
    "title": "Autonomous Reinforcement Learning: Formalism and Benchmarking",
    "url": "/forum?id=nkaba3ND7B5",
    "date": "28 Sept 2021 (modified: 22 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, autonomous, reset-free reinforcement learning, continual reinforcement learning",
    "Abstract": "Reinforcement learning (RL) provides a naturalistic framing for learning through trial and error, which is appealing both because of its simplicity and effectiveness and because of its resemblance to how humans and animals acquire skills through experience. However, real-world embodied learning, such as that performed by humans and animals, is situated in a continual, non-episodic world, whereas common benchmark tasks in RL are episodic, with the environment resetting between trials to provide the agent with multiple attempts. This discrepancy presents a major challenge when we attempt to take RL algorithms developed for episodic simulated environments and run  them on real-world platforms, such as robots. In this paper, we aim to address this discrepancy by laying out a framework for Autonomous Reinforcement Learning (ARL): reinforcement learning where the agent not only learns through its own experience, but also contends with lack of human supervision to reset between trials. We introduce a simulated benchmark EARL based on this framework, containing a set of diverse and challenging simulated tasks reflective of the hurdles introduced to learning when only a minimal reliance on extrinsic intervention can be assumed. We show that standard approaches to episodic RL and existing approaches struggle as interventions are minimized, underscoring the need for developing new algorithms for reinforcement learning with a greater focus on autonomy."
  },
  {
    "title": "GRAND++: Graph Neural Diffusion with A Source Term",
    "url": "/forum?id=EMxu-dzvJk",
    "date": "28 Sept 2021 (modified: 19 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "graph deep learning, low-labeling rates, diffusion on graphs, random walk",
    "Abstract": "We propose GRAph Neural Diffusion with a source term (GRAND++) for graph deep learning with a limited number of labeled nodes, i.e., low-labeling rate. GRAND++ is a class of continuous-depth graph deep learning architectures whose theoretical underpinning is the diffusion process on graphs with a source term. The source term guarantees two interesting theoretical properties of GRAND++: (i) the representation of graph nodes, under the dynamics of GRAND++, will not converge to a constant vector over all nodes even as the time goes to infinity, which mitigates the over-smoothing issue of graph neural networks and enables graph learning in very deep architectures. (ii) GRAND++ can provide accurate classification even when the model is trained with a very limited number of labeled training data. We experimentally verify the above two advantages on various graph deep learning benchmark tasks, showing a significant improvement over many existing graph neural networks.",
    "One-sentence Summary": "We propose GRAND++ for deep graph learning with limited labeled training data"
  },
  {
    "title": "Case-based reasoning for better generalization in textual reinforcement learning",
    "url": "/forum?id=ZDaSIkWT-AP",
    "date": "28 Sept 2021 (modified: 28 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Text-based games (TBG) have emerged as promising environments for driving research in grounded language understanding and studying problems like generalization and sample efficiency. Several deep reinforcement learning (RL) methods with varying architectures and learning schemes have been proposed for TBGs. However, these methods fail to generalize efficiently, especially under distributional shifts. In a departure from deep RL approaches, in this paper, we propose a general method inspired by case-based reasoning to train agents and generalize out of the training distribution. The case-based reasoner collects instances of positive experiences from the agent's interaction with the world and later reuses the collected experiences to act efficiently. The method can be used in conjunction with any existing on-policy neural agent introduced in the literature for TBGs. Our experiments show that the proposed approach consistently improves existing methods, obtains good out-of-distribution generalization and achieves new state-of-the-art results on widely used environments."
  },
  {
    "title": "Neural Deep Equilibrium Solvers",
    "url": "/forum?id=B0oHOwT5ENL",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep learning, Implicit models, Deep equilibrium models",
    "Abstract": "A deep equilibrium (DEQ) model abandons traditional depth by solving for the fixed point of a single nonlinear layer $f_\\theta$. This structure enables decoupling the internal structure of the layer (which controls representational capacity) from how the fixed point is actually computed (which impacts inference-time efficiency), which is usually via classic techniques such as Broyden's method or Anderson acceleration.  In this paper, we show that one can exploit such decoupling and substantially enhance this fixed point computation using a custom neural solver. Specifically, our solver uses a parameterized network to both guess an initial value of the optimization and perform iterative updates, in a method that generalizes a learnable form of Anderson acceleration and can be trained end-to-end in an unsupervised manner. Such a solution is particularly well suited to the implicit model setting, because inference in these models requires repeatedly solving for a fixed point of the same nonlinear layer for different inputs, a task at which our network excels. Our experiments show that these neural equilibrium solvers are fast to train (only taking an extra 0.9-1.1% over the original DEQ's training time), require few additional parameters (1-3% of the original model size), yet lead to a $2\\times$ speedup in DEQ network inference without any degradation in accuracy across numerous domains and tasks.",
    "One-sentence Summary": "A custom and lightweight neural solver for deep equilibrium models significantly improves their efficiency with minimal training."
  },
  {
    "title": "A Theoretical Analysis on Feature Learning in Neural Networks: Emergence from Inputs and Advantage over Fixed Features",
    "url": "/forum?id=wMpS-Z_AI_E",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural networks, feature learning, provable advantage, theoretical analysis",
    "Abstract": "An important characteristic of neural networks is their ability to learn representations of the input data with effective features for prediction, which is believed to be a key factor to their superior empirical performance. To better understand the source and benefit of feature learning in neural networks, we consider learning problems motivated by practical data, where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. We prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular, the structure of the input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, then no polynomial algorithm in the Statistical Query model can learn even weakly. These results provide theoretical evidence showing that feature learning in neural networks depends strongly on the input structure and leads to the superior performance. Our preliminary experimental results on synthetic and real data also provide positive support.",
    "One-sentence Summary": "Theoretical analysis of feature learning in neural networks on practically motivated learning problems, showing it strongly depends on the structure of the input distribution and leads to the advantage over fixed feature methods like kernels."
  },
  {
    "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals",
    "url": "/forum?id=6IYp-35L-xJ",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neuroscience, EEG, Sleep staging, Automatic data augmentation",
    "Abstract": "Data augmentation is a key element of deep learning pipelines, as it informs the network during training about transformations of the input data that keep the label unchanged. Manually finding adequate augmentation methods and parameters for a given pipeline is however rapidly cumbersome. In particular, while intuition can guide this decision for images, the design and choice of augmentation policies remains unclear for more complex types of data, such as neuroscience signals. Besides, class-dependent augmentation strategies have been surprisingly unexplored in the literature, although it is quite intuitive: changing the color of a car image does not change the object class to be predicted, but doing the same to the picture of an orange does. This paper investigates gradient-based automatic data augmentation algorithms  amenable to class-wise policies with exponentially larger search spaces. Motivated by supervised learning applications using EEG signals for which good augmentation policies are mostly unknown, we propose a new differentiable relaxation of the problem. In the class-agnostic setting, results show that our new relaxation leads to optimal performance with faster training than competing gradient-based methods, while also outperforming gradient-free methods in the class-wise setting. This work proposes also novel differentiable augmentation operations relevant for sleep stage classification.",
    "One-sentence Summary": "We propose a new gradient-based automatic data augmentation technique where samples are transformed based on their labels, and demonstrate its relevance on EEG sleep staging data."
  },
  {
    "title": "Label Leakage and Protection in Two-party Split Learning",
    "url": "/forum?id=cOtBRgsf2fO",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Split Learning, label leakage, privacy, privacy protection",
    "Abstract": "Two-party split learning is a popular technique for learning a model across feature-partitioned data. In this work, we explore whether it is possible for one party to steal the private label information from the other party during split training, and whether there are methods that can protect against such attacks. Specifically, we first formulate a realistic threat model and propose a privacy loss metric to quantify label leakage in split learning. We then show that there exist two simple yet effective methods within the threat model that can allow one party to accurately recover private ground-truth labels owned by the other party. To combat these attacks, we propose several random perturbation techniques, including $\\texttt{Marvell}$, an approach that strategically finds the structure of the noise perturbation by minimizing the amount of label leakage (measured through our quantification metric) of a worst-case adversary. We empirically demonstrate the effectiveness of our protection techniques against the identified attacks, and show that $\\texttt{Marvell}$ in particular has improved privacy-utility tradeoffs relative to baseline approaches.",
    "One-sentence Summary": "We identify the label leakage threat in two-party split learning with concrete threat examples and propose random perturbation methods to protect against such threats."
  },
  {
    "title": "Semi-relaxed Gromov-Wasserstein divergence and applications on graphs",
    "url": "/forum?id=RShaMexjc-x",
    "date": "28 Sept 2021 (modified: 01 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Optimal Transport, Graph Learning",
    "Abstract": "Comparing structured objects such as graphs is a fundamental operation\n        involved in many learning tasks. To this end, the Gromov-Wasserstein (GW)\n        distance, based on Optimal Transport (OT), has proven to be successful in\n        handling the specific nature of the associated objects. More specifically,\n        through the nodes connectivity relations, GW operates on graphs, seen as\n        probability measures over specific spaces. At the core of OT is the idea of\n        conservation of mass, which imposes a coupling between all the nodes from\n        the two considered graphs. We argue in this paper that this property can be\n        detrimental for tasks such as graph dictionary or partition learning, and we\n        relax it by proposing a new semi-relaxed Gromov-Wasserstein divergence.\n        Aside from immediate computational benefits, we discuss its properties, and\n        show that it can lead to an efficient graph dictionary learning algorithm.\n        We empirically demonstrate its relevance for complex tasks on graphs such as\n        partitioning, clustering and completion.",
    "One-sentence Summary": "A new transport based divergence between structured data induced by the relaxation of a mass constraint of the Gromov-Wasserstein problem, leading to new SOTA performances for unsupervised ML applications on graphs."
  },
  {
    "title": "CodeTrek: Flexible Modeling of Code using an Extensible Relational Representation",
    "url": "/forum?id=WQc075jmBmf",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "relational database, code representation, knowledge graph reasoning, program understanding",
    "Abstract": "Designing a suitable representation for code-reasoning tasks is challenging in aspects such as the kinds of program information to model, how to combine them, and how much context to consider. We propose CodeTrek, a deep learning approach that addresses these challenges by representing codebases as databases that conform to rich relational schemas. The relational representation not only allows CodeTrek to uniformly represent diverse kinds of program information, but also to leverage program-analysis queries to derive new semantic relations, which can be readily incorporated without further architectural engineering. CodeTrek embeds this relational representation using a set of walks that can traverse different relations in an unconstrained fashion, and incorporates all relevant attributes along the way. We evaluate CodeTrek on four diverse and challenging Python tasks: variable misuse, exception prediction, unused definition, and variable shadowing. CodeTrek achieves an accuracy of 91%, 63%, 98%, and 94% on these tasks respectively, and outperforms state-of-the-art neural models by 2-19% points.",
    "One-sentence Summary": "We present a relational database representation and corresponding neural module for source code and show its potential on program understanding tasks"
  },
  {
    "title": "Bridging Recommendation and Marketing via Recurrent Intensity Modeling",
    "url": "/forum?id=TZeArecH2Nf",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Recommender systems, marketing, push notifications, temporal point processes, sequence models",
    "Abstract": "This paper studies some under-explored connections between personalized recommendation and marketing systems. Obviously, these two systems are different, in two main ways. Firstly, personalized item-recommendation (ItemRec) is user-centric, whereas marketing recommends the best user-state segments (UserRec) on behalf of its item providers. (We treat different temporal states of the same user as separate marketing opportunities.) To overcome this difference, we realize a novel connection to Marked-Temporal Point Processes (MTPPs), where we view both problems as different projections from a unified temporal intensity model for all user-item pairs. Correspondingly, we derive Recurrent Intensity Models (RIMs) to extend from recurrent ItemRec models with minimal changes. The second difference between recommendation and marketing is in the temporal domains where they operate. While recommendation demands immediate responses in real-time, marketing campaigns are often long-term, setting goals to cover a given percentage of all opportunities for a given item in a given period of time. We formulate both considerations into a constrained optimization problem we call online match (OnlnMtch) and derive a solution we call Dual algorithm. Simply put, Dual modifies the real-time ItemRec scores such that the marketing constraints can be met with least compromises in user-centric utilities. Finally, our connections between recommendation and marketing may lead to novel applications. We run experiments where we use marketing as an alternative to cold-start item exploration, by setting a minimal-exposure constraint for every item in the audience base. Our experiments are available at \\url{https://github.com/awslabs/recurrent-intensity-model-experiments}",
    "One-sentence Summary": "We repurpose an item-recommender system to recommend users for item providers for the purpose of content promotion and diversity."
  },
  {
    "title": "Sparse Attention with Learning to Hash",
    "url": "/forum?id=VGnOJhd5Q1q",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Sparse Attention, Transformer, Learning-to-Hash, Natural Language Processing",
    "Abstract": "Transformer has become ubiquitous in sequence modeling tasks. As a key component of Transformer, self-attention does not scale to long sequences due to its quadratic time and space complexity with respect to the sequence length. To tackle this problem, recent work developed dynamic attention sparsification techniques based on Approximate Nearest Neighbor (ANN) methods, where similar queries and keys are allocated to the same hash bucket with high probability. However, the effectiveness of those ANN methods relies on the assumption that queries and keys should lie in the same space, which is not well justified. Besides, some of the ANN methods such as Locality-Sensitive Hashing (LSH) are randomized and cannot fully utilize the available real data distributions. To overcome these issues, this paper proposes a new strategy for sparse attention, namely LHA (Learning-to-Hash Attention), which directly learns separate parameterized hash functions for queries and keys, respectively. Another advantage of LHA is that it does not impose extra constraints for queries and keys, which makes it applicable to the wide range of pre-trained Transformer models. Our experiments on evaluation of the WikiText-103 dataset for language modeling, the GLUE benchmark for natural language understanding, and the Lang-Range-Arena benchmark for multiple tasks (text/image classification, retrieval, etc.) show the superior performance of LHA over other strong Transformer variants.",
    "One-sentence Summary": "We propose a new strategy for sparse attention, namely LHA (Learning-to-Hash Attention), which directly learns separate parameterized hash functions for queries and keys, respectively."
  },
  {
    "title": "Controlling the Complexity and Lipschitz Constant improves Polynomial Nets",
    "url": "/forum?id=dQ7Cy_ndl1s",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Polynomial Nets, Rademacher Complexity, Lipschitz constant, Coupled CP decomposition",
    "Abstract": "While the class of Polynomial Nets demonstrates comparable performance to neural networks (NN), it currently has neither theoretical generalization characterization nor robustness guarantees. To this end, we derive new complexity bounds for the set of Coupled CP-Decomposition (CCP) and Nested Coupled CP-decomposition (NCP) models of Polynomial Nets in terms of the $\\ell_\\infty$-operator-norm and the $\\ell_2$-operator norm. In addition, we derive bounds on the Lipschitz constant for both models to establish a theoretical certificate for their robustness. The theoretical results enable us to propose a principled regularization scheme that we also evaluate experimentally and show that it improves the accuracy as well as the robustness of the models to adversarial perturbations. We showcase how this regularization can be combined with adversarial training, resulting in further improvements.",
    "One-sentence Summary": "We provide sample complexity results and bounds on the Lipschitz constant of polynomial networks, which we use to construct a regularization scheme that improves the robustness against adversarial noise."
  },
  {
    "title": "Finding an Unsupervised Image Segmenter in each of your Deep Generative Models",
    "url": "/forum?id=Ug-bgjgSlKV",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "unsupervised, generative, deep learning, segmentation, object segmentation",
    "Abstract": "Recent research has shown that numerous human-interpretable directions exist in the latent space of GANs. In this paper, we develop an automatic procedure for finding directions that lead to foreground-background image separation, and we use these directions to train an image segmentation model without human supervision. Our method is generator-agnostic, producing strong segmentation results with a wide range of different GAN architectures. Furthermore, by leveraging GANs pretrained on large datasets such as ImageNet, we are able to segment images from a range of domains without further training or finetuning. Evaluating our method on image segmentation benchmarks, we compare favorably to prior work while using neither human supervision nor access to the training data. Broadly, our results demonstrate that automatically extracting foreground-background structure from pretrained deep generative models can serve as a remarkably effective substitute for human supervision.",
    "One-sentence Summary": "We propose an entirely unsupervised method for foreground-background image segmentation based on automatically finding a direction in the latent space of a deep generative model."
  },
  {
    "title": "Solving Inverse Problems in Medical Imaging with Score-Based Generative Models",
    "url": "/forum?id=vaRCHVj0uGI",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "score-based generative modeling, inverse problems, sparse-view CT, undersampled MRI, metal artifact removal, diffusion",
    "Abstract": "Reconstructing medical images from partial measurements is an important inverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training dataset of paired images and measurements. These measurements are typically synthesized from images using a fixed physical model of the measurement process, which hinders the generalization capability of models to unknown measurement processes. To address this issue, we propose a fully unsupervised technique for inverse problem solving, leveraging the recently introduced score-based generative models. Specifically, we first train a score-based generative model on medical images to capture their prior distribution. Given measurements and a physical model of the measurement process at test time, we introduce a sampling method to reconstruct an image consistent with both the prior and the observed measurements. Our method does not assume a fixed measurement process during training, and can thus be flexibly adapted to different measurement processes at test time. Empirically, we observe comparable or better performance to supervised learning techniques in several medical imaging tasks in CT and MRI, while demonstrating significantly better generalization to unknown measurement processes."
  },
  {
    "title": "BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis",
    "url": "/forum?id=L7wzpQttNO",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Speech Synthesis, Vocoder, Generative Model, Diffusion Model",
    "Abstract": "Diffusion probabilistic models (DPMs) and their extensions have emerged as competitive generative models yet confront challenges of efficient sampling. We propose a new bilateral denoising diffusion model (BDDM) that parameterizes both the forward and reverse processes with a schedule network and a score network, which can train with a novel bilateral modeling objective. We show that the new surrogate objective can achieve a lower bound of the log marginal likelihood tighter than a conventional surrogate. We also find that BDDM allows inheriting pre-trained score network parameters from any DPMs and consequently enables speedy and stable learning of the schedule network and optimization of a noise schedule for sampling.\n        Our experiments demonstrate that BDDMs can generate high-fidelity audio samples with as few as three sampling steps. Moreover, compared to other state-of-the-art diffusion-based neural vocoders, BDDMs produce comparable or higher quality samples indistinguishable from human speech, notably with only seven sampling steps (143x faster than WaveGrad and 28.6x faster than DiffWave). We release our code at https://github.com/tencent-ailab/bddm.",
    "One-sentence Summary": "In this paper, we propose a novel bilateral denoising diffusion model (BDDM), which takes significantly fewer sampling steps than the SOTA diffusion-based vocoder to generate high-quality audio samples."
  },
  {
    "title": "Sample Efficient Stochastic Policy Extragradient Algorithm for Zero-Sum Markov Game",
    "url": "/forum?id=IvepFxYRDG",
    "date": "28 Sept 2021 (modified: 24 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Two-player Zero-sum Markov game, Entropy regularization, Policy extragradient, Nash equilibrium, Sample complexity",
    "Abstract": "Two-player zero-sum Markov game is a fundamental problem in reinforcement learning and game theory. Although many algorithms have been proposed for solving zero-sum Markov games in the existing literature, many of them either require a full knowledge of the environment or are not sample-efficient. In this paper, we develop a fully decentralized and sample-efficient stochastic policy extragradient algorithm for solving tabular zero-sum Markov games. In particular, our algorithm utilizes multiple stochastic estimators to accurately estimate the value functions involved in the stochastic updates, and leverages entropy regularization to accelerate the convergence. Specifically, with a proper entropy-regularization parameter, we prove that the stochastic policy extragradient algorithm has a sample complexity of the order $\\widetilde{\\mathcal{O}}(\\frac{A_{\\max}}{\\mu_{\\text{min}}\\epsilon^{5.5}(1-\\gamma)^{13.5}})$ for finding a solution that achieves $\\epsilon$-Nash equilibrium duality gap, where $A_{\\max}$ is the maximum number of actions between the players, $\\mu_{\\min}$ is the lower bound of state stationary distribution, and $\\gamma$ is the discount factor. Such a sample complexity result substantially improves the state-of-the-art complexity result.",
    "One-sentence Summary": "This paper proposes a fully decentralized, model-free, provably convergent, sample efficient stochastic policy extragradient algorithm with symmetric and private policy updates"
  },
  {
    "title": "The Uncanny Similarity of Recurrence and Depth",
    "url": "/forum?id=3wNcr5nq56",
    "date": "28 Sept 2021 (modified: 03 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep learning, recurrent networks, depth",
    "Abstract": "It is widely believed that deep neural networks contain layer specialization, wherein networks extract hierarchical features representing edges and patterns in shallow layers and complete objects in deeper layers. Unlike common feed-forward models that have distinct filters at each layer, recurrent networks reuse the same parameters at various depths. In this work, we observe that recurrent models exhibit the same hierarchical behaviors and the same performance benefits as depth despite reusing the same filters at every recurrence. By training models of various feed-forward and recurrent architectures on several datasets for image classification as well as maze solving, we show that recurrent networks have the ability to closely emulate the behavior of non-recurrent deep models, often doing so with far fewer parameters.",
    "One-sentence Summary": "We show quantitatively and qualitatively that recurrent models have the same behaviors as feed-forward networks despite reusing parameters at each recurrence."
  },
  {
    "title": "Implicit Bias of Adversarial Training for Deep Neural Networks",
    "url": "/forum?id=l8It-0lE5e7",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "adversarial training, adversarial examples",
    "Abstract": "We provide theoretical understandings of the implicit bias imposed by adversarial training for homogeneous deep neural networks without any explicit regularization. In particular, for deep linear networks adversarially trained by gradient descent on a linearly separable dataset, we prove that the direction of the product of weight matrices converges to the direction of the max-margin solution of the original dataset. Furthermore, we generalize this result to the case of adversarial training for non-linear homogeneous deep neural networks without the linear separability of the dataset. We show that, when the neural network is adversarially trained with  $\\ell_2$ or $\\ell_{\\infty}$ FGSM, FGM and PGD perturbations, the direction of the limit point of normalized parameters of the network along the trajectory of the gradient flow converges to a KKT point of a constrained optimization problem that aims to maximize the margin for adversarial examples. Our results theoretically justify the longstanding conjecture that adversarial training modifies the decision boundary by utilizing adversarial examples to improve robustness, and potentially provides insights for designing new robust training strategies.",
    "One-sentence Summary": "We provide theoretical understandings of the implicit bias imposed by adversarial training for homogeneous deep neural networks without explicit regularization."
  },
  {
    "title": "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning",
    "url": "/forum?id=_SJ-_yyes8",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Image-based RL, Data augmentation in RL, Continuous Control",
    "Abstract": "We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for visual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic approach that uses data augmentation to learn directly from pixels. We introduce several improvements that yield state-of-the-art results on the DeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid locomotion tasks directly from pixel observations, previously unattained by model-free RL. DrQ-v2  is conceptually simple, easy to implement, and provides significantly better computational footprint compared to prior work, with the majority of tasks taking just 8 hours to train on a single GPU. Finally, we publicly release DrQ-v2 's implementation to  provide RL practitioners with a strong and computationally efficient baseline.",
    "One-sentence Summary": "We proposed a model-free off-policy algorithm for image-based continuous control that significantly outperforms previous methods both in sample and time complexity."
  },
  {
    "title": "$\\pi$BO: Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization",
    "url": "/forum?id=MMAeCXIa89",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Bayesian Optimization, Hyperparameter Optimization, Meta-Learning",
    "Abstract": "Bayesian optimization (BO) has become an established framework and popular tool for hyperparameter optimization (HPO) of machine learning (ML) algorithms. While known for its sample-efficiency, vanilla BO can not utilize readily available prior beliefs the practitioner has on the potential location of the optimum.  Thus, BO disregards a valuable source of information, reducing its appeal to ML practitioners. To address this issue, we propose $\\pi$BO, an acquisition function generalization which incorporates prior beliefs about the location of the optimum in the form of a probability distribution, provided by the user. In contrast to previous approaches, $\\pi$BO is conceptually simple and can easily be integrated with existing libraries and many acquisition functions. We provide regret bounds when $\\pi$BO is applied to the common Expected Improvement acquisition function and prove convergence at regular rates independently of the prior. Further, our experiments show that $\\pi$BO outperforms competing approaches across a wide suite of benchmarks and prior characteristics. We also demonstrate that $\\pi$BO improves on the state-of-the-art performance for a popular deep learning task, with a $12.5\\times$ time-to-accuracy speedup over prominent BO approaches.",
    "One-sentence Summary": "We extend the Bayesian Optimization framework by allowing for arbitrary user priors over promising regions of the search space, to guide the search towards said regions."
  },
  {
    "title": "A Generalized Weighted Optimization Method for Computational Learning and Inversion",
    "url": "/forum?id=14F3fI6MGxX",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "weighted optimization, generalization error, feature regression, machine learning",
    "Abstract": "The generalization capacity of various machine learning models exhibits different phenomena in the under- and over-parameterized regimes. In this paper, we focus on regression models such as feature regression and kernel regression and analyze a generalized weighted least-squares optimization method for computational learning and inversion with noisy data. The highlight of the proposed framework is that we allow weighting in both the parameter space and the data space. The weighting scheme encodes both a priori knowledge on the object to be learned and a strategy to weight the contribution of different data points in the loss function. Here, we characterize the impact of the weighting scheme on the generalization error of the learning method, where we derive explicit generalization errors for the random Fourier feature model in both the under- and over-parameterized regimes. For more general feature maps, error bounds are provided based on the singular values of the feature matrix. We demonstrate that appropriate weighting from prior knowledge can improve the generalization capability of the learned model.",
    "One-sentence Summary": "This paper proposes a generalized weighted optimization method for computational learning and inversion with noisy data and derives generalization error bounds for various feature regression models, demonstrating better generalization capabilities."
  },
  {
    "title": "DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG Signals",
    "url": "/forum?id=d_2lcDh0Y9c",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Electrophysiology, Neuroscience, Temporal point processes, Convolutional Dictionary Learning",
    "Abstract": "The quantitative analysis of non-invasive electrophysiology signals from electroencephalography (EEG) and magnetoencephalography (MEG) boils down to the identification of temporal patterns such as evoked responses, transient bursts of neural oscillations but also blinks or heartbeats for data cleaning. Several works have shown that these patterns can be extracted efficiently in an unsupervised way, e.g., using Convolutional Dictionary Learning. This leads to an event-based description of the data. Given these events, a natural question is to estimate how their occurrences are modulated by certain cognitive tasks and experimental manipulations. To address it, we propose a point process approach. While point processes have been used in neuroscience in the past, in particular for single cell recordings (spike trains), techniques such as Convolutional Dictionary Learning make them amenable to human studies based on EEG/MEG signals. We develop a novel statistical point process model \u2013 called driven temporal point processes (DriPP) \u2013 where the intensity function of the point process model is linked to a set of point processes corresponding to stimulation events. We derive a fast and principled expectation-maximization algorithm to estimate the parameters of this model. Simulations reveal that model parameters can be identified from long enough signals. Results on standard MEG datasets demonstrate that our methodology reveals event-related neural responses \u2013 both evoked and induced \u2013 and isolates non-task specific temporal patterns.",
    "One-sentence Summary": "Model for patterns' activation using temporal point processes to reveal stimulus-induced effects in brain electrophysiology."
  },
  {
    "title": "Stiffness-aware neural network for learning Hamiltonian systems",
    "url": "/forum?id=uVXEKeqJbNa",
    "date": "28 Sept 2021 (modified: 23 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Hamiltonain systems, Neural network, Stiff dynamical systems, Data-driven method",
    "Abstract": "We propose stiffness-aware neural network (SANN), a new method for learning Hamiltonian dynamical systems from data. SANN identifies and splits the training data into stiff and nonstiff portions based on a stiffness-aware index, a simple, yet effective metric we introduce to quantify the stiffness of the dynamical system. This classification along with a resampling technique allows us to apply different time integration strategies such as step size adaptation to better capture the dynamical characteristics of the Hamiltonian vector fields. We evaluate SANN on complex physical systems including a three-body problem and  billiard model. We show that SANN is more stable and can better preserve energy when compared with the state-of-the-art methods, leading to significant improvement in accuracy."
  },
  {
    "title": "CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting",
    "url": "/forum?id=PilZY3omXV2",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Time Series, Representation Learning, Forecasting, Self-Supervised Learning",
    "Abstract": "Deep learning has been actively studied for time series forecasting, and the mainstream paradigm is based on the end-to-end training of neural network architectures, ranging from classical LSTM/RNNs to more recent TCNs and Transformers. Motivated by the recent success of representation learning in computer vision and natural language processing, we argue that a more promising paradigm for time series forecasting, is to first learn disentangled feature representations, followed by a simple regression fine-tuning step -- we justify such a paradigm from a causal perspective. Following this principle, we propose a new time series representation learning framework for long sequence time series forecasting named CoST, which applies contrastive learning methods to learn disentangled seasonal-trend representations. CoST comprises both time domain and frequency domain contrastive losses to learn discriminative trend and seasonal representations, respectively. Extensive experiments on real-world datasets show that CoST consistently outperforms the state-of-the-art methods by a considerable margin, achieving a 21.3% improvement in MSE on multivariate benchmarks. It is also robust to various choices of backbone encoders, as well as downstream regressors. Code is available at https://github.com/salesforce/CoST."
  },
  {
    "title": "CoordX: Accelerating Implicit Neural Representation with a Split MLP Architecture",
    "url": "/forum?id=oAy7yPmdNz",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Implicit neural representations with multi-layer perceptrons (MLPs) have recently gained prominence for a wide variety of tasks such as novel view synthesis and 3D object representation and rendering. However, a significant challenge with these representations is that both training and inference with an MLP over a large number of input coordinates to learn and represent an image, video, or 3D object, require large amounts of computation and incur long processing times. In this work, we aim to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, CoordX. With CoordX, the initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This significantly reduces the amount of computation required and leads to large speedups in training and inference, while achieving similar accuracy as the baseline MLP. This approach thus aims at first learning functions that are a decomposition of the original signal and then fusing them to generate the learned signal. Our proposed architecture can be generally used for many implicit neural representation tasks with no additional memory overheads. We demonstrate a speedup of up to 2.92x compared to the baseline model for image, video, and 3D shape representation and rendering tasks."
  },
  {
    "title": "Plant 'n' Seek: Can You Find the Winning Ticket?",
    "url": "/forum?id=9n9c8sf0xm",
    "date": "28 Sept 2021 (modified: 05 Apr 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "lottery tickets, ground truth, planting, LTH",
    "Abstract": "The lottery ticket hypothesis has sparked the rapid development of pruning algorithms that aim to reduce the computational costs associated with deep learning during training and model deployment. Currently, such algorithms are primarily evaluated on imaging data, for which we lack ground truth information and thus the understanding of how sparse lottery tickets could be. To fill this gap, we develop a framework that allows us to plant and hide winning tickets with desirable properties in randomly initialized neural networks. To analyze the ability of state-of-the-art pruning to identify tickets of extreme sparsity, we design and hide such tickets solving four challenging tasks. In extensive experiments, we observe similar trends as in imaging studies, indicating that our framework can provide transferable insights into realistic problems. Additionally, we can now see beyond such relative trends and highlight limitations of current pruning methods. Based on our results, we conclude that the current limitations in ticket sparsity are likely of algorithmic rather than fundamental nature. We anticipate that comparisons to planted tickets will facilitate future developments of efficient pruning algorithms.",
    "One-sentence Summary": "We derive a framework to plant ground truth lottery tickets in randomly initialized deep neural networks."
  },
  {
    "title": "Coherence-based Label Propagation over Time Series for Accelerated Active Learning",
    "url": "/forum?id=gjNcH0hj0LM",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "active learning, time series, pseudo labeling",
    "Abstract": "Time-series data are ubiquitous these days, but lack of the labels in time-series data is regarded as a hurdle for its broad applicability. Meanwhile, active learning has been successfully adopted to reduce the labeling efforts in various tasks. Thus, this paper addresses an important issue, time-series active learning. Inspired by the temporal coherence in time-series data, where consecutive data points tend to have the same label, our label propagation framework, called TCLP, automatically assigns a queried label to the data points within an accurately estimated time-series segment, thereby significantly boosting the impact of an individual query. Compared with traditional time-series active learning, TCLP is shown to improve the classification accuracy by up to 7.1 times when only 0.8% of data points in the entire time series are queried for their labels.",
    "One-sentence Summary": "We present a novel label propagation framework for time-series active learning, TCLP, that fully takes advantage of the temporal coherence inherent in time-series data."
  },
  {
    "title": "A Class of Short-term Recurrence Anderson Mixing Methods and Their Applications",
    "url": "/forum?id=_X90SIKbHa",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Anderson mixing, sequence acceleration, fixed-point iteration, nonconvex optimization, stochastic optimization",
    "Abstract": "Anderson mixing (AM) is a powerful acceleration method for fixed-point iterations, but its computation requires storing many historical iterations. The extra memory footprint can be prohibitive when solving high-dimensional problems in a resource-limited machine. To reduce the memory overhead, we propose a novel class of short-term recurrence AM methods (ST-AM). The ST-AM methods only store two previous iterations with cheap corrections. We prove that the basic version of ST-AM is equivalent to the full-memory AM in strongly convex quadratic optimization, and with minor changes it has local linear convergence for solving general nonlinear fixed-point problems. We further analyze the convergence properties of the regularized ST-AM for nonconvex (stochastic) optimization. Finally, we apply ST-AM to several applications including solving root-finding problems and training neural networks. Experimental results show that ST-AM is competitive with the long-memory AM and outperforms many existing optimizers.",
    "One-sentence Summary": "We develop a novel class of short-term recurrence Anderson mixing methods and validate its effectiveness in several applications including training neural networks."
  },
  {
    "title": "The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs",
    "url": "/forum?id=A05I5IvrdL-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "POMDPs, Memoryless Policies, Critical points, State-action frequencies, Algebraic degree",
    "Abstract": "We consider the problem of finding the best memoryless stochastic policy for an infinite-horizon partially observable Markov decision process (POMDP) with finite state and action spaces with respect to either the discounted or mean reward criterion. We show that the (discounted) state-action frequencies and the expected cumulative reward are rational functions of the policy, whereby the degree is determined by the degree of partial observability. We then describe the optimization problem as a linear optimization problem in the space of feasible state-action frequencies subject to polynomial constraints that we characterize explicitly. This allows us to address the combinatorial and geometric complexity of the optimization problem using recent tools from polynomial optimization. In particular, we demonstrate how the partial observability constraints can lead to multiple smooth and non-smooth local optimizers and we estimate the number of critical points.",
    "One-sentence Summary": "We provide an explicit description of the optimization problem and derive bounds on the number of critical points in POMDPs with memoryless stochastic policies depending on the degree of observability."
  },
  {
    "title": "Efficient Sharpness-aware Minimization for Improved Training of Neural Networks",
    "url": "/forum?id=n0OeTdNRG0Q",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Efficient learning, gengeralization, training algorithm",
    "Abstract": "Overparametrized Deep Neural Networks (DNNs) often achieve astounding performances, but may potentially result in severe generalization error. Recently, the relation between the sharpness of the loss landscape and the generalization error has been established by Foret et al. (2020), in which the Sharpness Aware Minimizer (SAM) was proposed to mitigate the degradation of the generalization. Unfortunately, SAM\u2019s computational cost is roughly double that of base optimizers, such as Stochastic Gradient Descent (SGD). This paper thus proposes Efficient Sharpness Aware Minimizer (ESAM), which boosts SAM\u2019s efficiency at no cost to its generalization performance. ESAM includes two novel and efficient training strategies\u2014StochasticWeight Perturbation and Sharpness-Sensitive Data Selection. In the former, the sharpness measure is approximated by perturbing a stochastically chosen set of weights in each iteration; in the latter, the SAM loss is optimized using only a judiciously selected subset of data that is sensitive to the sharpness. We provide theoretical explanations as to why these strategies perform well. We also show, via extensive experiments on the CIFAR and ImageNet\n        datasets, that ESAM enhances the efficiency over SAM from requiring 100% extra computations to 40% vis-`a-vis base optimizers, while test accuracies are preserved or even improved.",
    "One-sentence Summary": "An efficient sharpness aware minimizer that improves the generalization"
  },
  {
    "title": "Lipschitz-constrained Unsupervised Skill Discovery",
    "url": "/forum?id=BGvt0ghNgA",
    "date": "28 Sept 2021 (modified: 08 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement learning",
    "Abstract": "We study the problem of unsupervised skill discovery, whose goal is to learn a set of diverse and useful skills with no external reward. There have been a number of skill discovery methods based on maximizing the mutual information (MI) between skills and states. However, we point out that their MI objectives usually prefer static skills to dynamic ones, which may hinder the application for downstream tasks. To address this issue, we propose Lipschitz-constrained Skill Discovery (LSD), which encourages the agent to discover more diverse, dynamic, and far-reaching skills. Another benefit of LSD is that its learned representation function can be utilized for solving goal-following downstream tasks even in a zero-shot manner \u2014 i.e., without further training or complex planning. Through experiments on various MuJoCo robotic locomotion and manipulation environments, we demonstrate that LSD outperforms previous approaches in terms of skill diversity, state space coverage, and performance on seven downstream tasks including the challenging task of following multiple goals on Humanoid. Our code and videos are available at https://shpark.me/projects/lsd/.",
    "One-sentence Summary": "We propose Lipschitz-constrained Skill Discovery (LSD), which encourages the agent to discover more dynamic and diverse skills without external rewards and additional prior knowledge, enabling zero-shot control on goal-reaching downstream tasks."
  },
  {
    "title": "Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behavioral Similarities",
    "url": "/forum?id=zBOI9LFpESK",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep reinforcement learning, deep learning, representation learning",
    "Abstract": "How to learn an effective reinforcement learning-based model for control tasks from high-level visual observations is a practical and challenging problem. A key to solving this problem is to learn low-dimensional state representations from observations, from which an effective policy can be learned. In order to boost the learning of state encoding, recent works are focused on capturing behavioral similarities between state representations or applying data augmentation on visual observations. In this paper, we propose a novel meta-learner-based framework for representation learning regarding behavioral similarities for reinforcement learning. Specifically, our framework encodes the high-dimensional observations into two decomposed embeddings regarding reward and dynamics in a Markov Decision Process (MDP). A pair of meta-learners are developed, one of which quantifies the reward similarity and the other quantifies dynamics similarity over the correspondingly decomposed embeddings. The meta-learners are self-learned to update the state embeddings by approximating two disjoint terms in on-policy bisimulation metric. To incorporate the reward and dynamics terms, we further develop a strategy to adaptively balance their impacts based on different tasks or environments. We empirically demonstrate that our proposed framework outperforms state-of-the-art baselines on several benchmarks, including conventional DM Control Suite, Distracting DM Control Suite and a self-driving task CARLA."
  },
  {
    "title": "Effective Model Sparsification by Scheduled Grow-and-Prune Methods",
    "url": "/forum?id=xa6otUDdP2W",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Deep neural networks (DNNs) are effective in solving many real-world problems. Larger DNN models usually exhibit better quality (e.g., accuracy) but their excessive computation results in long inference time. Model sparsification can reduce the computation and memory cost while maintaining model quality. Most existing sparsification algorithms unidirectionally remove weights, while others randomly or greedily explore a small subset of weights in each layer for pruning. The limitations of these algorithms reduce the level of achievable sparsity. In addition, many algorithms still require pre-trained dense models and thus suffer from large memory footprint. In this paper, we propose a novel scheduled grow-and-prune (GaP) methodology without having to pre-train a dense model. It addresses the shortcomings of the previous works by repeatedly growing a subset of layers to dense and then pruning them back to sparse after some training. Experiments show that the models pruned using the proposed methods match or beat the quality of the highly optimized dense models at 80% sparsity on a variety of tasks, such as image classification, objective detection, 3D object part segmentation, and translation. They also outperform other state-of-the-art (SOTA) methods for model sparsification. As an example, a 90% non-uniform sparse ResNet-50 model obtained via  GaP achieves 77.9% top-1 accuracy on ImageNet, improving the previous SOTA results by 1.5%. Code available at: https://github.com/boone891214/GaP."
  },
  {
    "title": "FILIP: Fine-grained Interactive Language-Image Pre-Training",
    "url": "/forum?id=cpDhcsEDC2",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Visual-language pretraining, Language-Image Pretraining, Multi-modality model",
    "Abstract": "Unsupervised large-scale vision-language pre-training has shown promising advances on various downstream tasks. Existing methods often model the cross-modal interaction either via the similarity of the global feature of each modality which misses sufficient information, or finer-grained interactions using cross/self-attention upon visual and textual tokens. However, cross/self-attention suffers from inferior efficiency in both training and inference. In this paper, we introduce a large-scale Fine-grained Interactive Language-Image Pre-training (FILIP) to achieve finer-level alignment through a cross-modal late interaction mechanism, which uses a token-wise maximum similarity between visual and textual tokens to guide the contrastive objective. FILIP successfully leverages the finer-grained expressiveness between image patches and textual words by modifying only contrastive loss, while simultaneously gaining the ability to pre-compute image and text representations offline at inference, keeping both large-scale training and inference efficient. Furthermore, we construct a new large-scale image-text pair dataset called FILIP300M for pre-training. Experiments show that FILIP achieves state-of-the-art performance on multiple downstream vision-language tasks including zero-shot image classification and image-text retrieval. The visualization on word-patch alignment further shows that FILIP can learn meaningful fine-grained features with promising localization ability.",
    "One-sentence Summary": "We introduce a large-scale Fine-grained Interacitve Language-Image Pretraining (FILIP) to achieve finer-level alignment through a new cross-modal late interaction mechanism, which can boost the performance on more grounded vision and language tasks."
  },
  {
    "title": "Information Prioritization through Empowerment in Visual Model-based RL",
    "url": "/forum?id=DfUjyyRW90",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "model-based reinforcement learning, visual distractors, empowerment",
    "Abstract": "Model-based reinforcement learning (RL) algorithms designed for handling complex visual observations typically learn some sort of latent state representation, either explicitly or implicitly. Standard methods of this sort do not distinguish between functionally relevant aspects of the state and irrelevant distractors, instead aiming to represent all available information equally. We propose a modified objective for model-based RL that, in combination with mutual information maximization, allows us to learn representations and dynamics for visual model-based RL without reconstruction in a way that explicitly prioritizes functionally relevant factors. The key principle behind our design is to integrate a term inspired by variational empowerment into a state-space learning model based on mutual information. This term prioritizes information that is correlated with action, thus ensuring that functionally relevant factors are captured first. Furthermore, the same empowerment term also promotes faster exploration during the RL process, especially for sparse-reward tasks where the reward signal is insufficient to drive exploration in the early stages of learning. We evaluate the approach on a suite of vision-based robot control tasks with natural video backgrounds, and show that the proposed prioritized information objective outperforms state-of-the-art model based RL approaches by an average of 20\\% in terms of episodic returns at 1M environment interactions with 30\\% higher sample efficiency at 100k interactions.",
    "One-sentence Summary": "Empowerment along with mutual information maximization helps learn functionally relevant factors in visual model-based RL"
  },
  {
    "title": "Efficient Active Search for Combinatorial Optimization Problems",
    "url": "/forum?id=nO5caZwFwYu",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "heuristic search, combinatorial optimization, learning to optimize, reinforcement learning, traveling salesperson problem, vehicle routing problem, job shop scheduling problem",
    "Abstract": "Recently numerous machine learning based methods for combinatorial optimization problems have been proposed that learn to construct solutions in a sequential decision process via reinforcement learning. While these methods can be easily combined with search strategies like sampling and beam search, it is not straightforward to integrate them into a high-level search procedure offering strong search guidance. Bello et al. (2016) propose active search, which adjusts the weights of a (trained) model with respect to a single instance at test time using reinforcement learning. While active search is simple to implement, it is not competitive with state-of-the-art methods because adjusting all model weights for each test instance is very time and memory intensive. Instead of updating all model weights, we propose and evaluate three efficient active search strategies that only update a subset of parameters during the search. The proposed methods offer a simple way to significantly improve the search performance of a given model and outperform state-of-the-art machine learning based methods on combinatorial problems, even surpassing the well-known heuristic solver LKH3 on the capacitated vehicle routing problem. Finally, we show that (efficient) active search enables learned models to effectively solve instances that are much larger than those seen during training.",
    "One-sentence Summary": "We propose active search approaches for combinatorial optimization problems that search for solutions by adjusting a subset of (model) parameters to a single instance at test time."
  },
  {
    "title": "Ancestral protein sequence reconstruction using a tree-structured Ornstein-Uhlenbeck variational autoencoder",
    "url": "/forum?id=FZoZ7a31GCW",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "biological sequences, variational autoencoders, latent representations, ornstein-uhlenbeck process, evolution",
    "Abstract": "We introduce a deep generative model for representation learning of biological sequences that, unlike existing models, explicitly represents the evolutionary process. The model makes use of a tree-structured Ornstein-Uhlenbeck process, obtained from a given phylogenetic tree, as an informative prior for a variational autoencoder. We show the model performs well on the task of ancestral sequence reconstruction of single protein families. Our results and ablation studies indicate that the explicit representation of evolution using a suitable tree-structured prior has the potential to improve representation learning of biological sequences considerably. Finally, we briefly discuss extensions of the model to genomic-scale data sets and the case of a latent phylogenetic tree.",
    "One-sentence Summary": "Ancestral protein sequence reconstruction using a tree-structured Ornstein-Uhlenbeck variational autoencoder"
  },
  {
    "title": "Training Structured Neural Networks Through Manifold Identification and Variance Reduction",
    "url": "/forum?id=mdUYT5QV0O",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Structured neural networks, variance reduction, manifold identification, proximal methods",
    "Abstract": "This paper proposes an algorithm, RMDA, for training neural networks (NNs) with a regularization term for promoting desired structures. RMDA does not incur computation additional to proximal SGD with momentum, and achieves variance reduction without requiring the objective function to be of the finite-sum form. Through the tool of manifold identification from nonlinear optimization, we prove that after a finite number of iterations, all iterates of RMDA possess a desired structure identical to that induced by the regularizer at the stationary point of asymptotic convergence, even in the presence of engineering tricks like data augmentation that complicate the training process. Experiments on training NNs with structured sparsity confirm that variance reduction is necessary for such an identification, and show that RMDA thus significantly outperforms existing methods for this task. For unstructured sparsity, RMDA also outperforms a state-of-the-art pruning method, validating the benefits of training structured NNs through regularization. \n        Implementation of RMDA is available at https://www.github.com/zihsyuan1214/rmda.",
    "One-sentence Summary": "We propose a variance-reduction method for training structured deep learning models that can provably identify the optimal structure."
  },
  {
    "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization",
    "url": "/forum?id=KBQP4A_J1K",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "transformer, compositionality, systematic generalization, algorithmic reasoning, arithmetic",
    "Abstract": "Despite progress across a broad range of applications, Transformers have limited success in systematic generalization. The situation is especially frustrating in the case of algorithmic tasks, where they often fail to find intuitive solutions that route relevant information to the right node/operation at the right time in the grid represented by Transformer columns. To facilitate the learning of useful control flow, we propose two modifications to the Transformer architecture, copy gate and geometric attention. Our novel Neural Data Router (NDR) achieves 100% length generalization accuracy on the classic compositional table lookup task, as well as near-perfect accuracy on the simple arithmetic task and a new variant of ListOps testing for generalization across computational depths. NDR\u2019s attention and gating patterns tend to be interpretable as an intuitive form of neural routing",
    "One-sentence Summary": "We improve systematic generalization of Transformers on algorithmic tasks by introducing a novel attention mechanism and gating."
  },
  {
    "title": "On the Limitations of Multimodal VAEs",
    "url": "/forum?id=w-CPUXXrAj",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multimodal learning, variational autoencoder, variational information bottleneck, information theory",
    "Abstract": "Multimodal variational autoencoders (VAEs) have shown promise as efficient generative models for weakly-supervised data. Yet, despite their advantage of weak supervision, they exhibit a gap in generative quality compared to unimodal VAEs, which are completely unsupervised. In an attempt to explain this gap, we uncover a fundamental limitation that applies to a large family of mixture-based multimodal VAEs. We prove that the sub-sampling of modalities enforces an undesirable upper bound on the multimodal ELBO and thereby limits the generative quality of the respective models.  Empirically, we showcase the generative quality gap on both synthetic and real data and present the tradeoffs between different variants of multimodal VAEs. We find that none of the existing approaches fulfills all desired criteria of an effective multimodal generative model when applied on more complex datasets than those used in previous benchmarks. In summary, we identify, formalize, and validate fundamental limitations of VAE-based approaches for modeling weakly-supervised data and discuss implications for real-world applications."
  },
  {
    "title": "Recursive Disentanglement Network",
    "url": "/forum?id=CSfcOznpDY",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "disentanglement, representation learning, compositional",
    "Abstract": "Disentangled feature representation is essential for data-efficient learning. The feature space of deep models is inherently compositional. Existing $\\beta$-VAE-based methods, which only apply disentanglement regularization to the resulting embedding space of deep models, cannot effectively regularize such compositional feature space, resulting in unsatisfactory disentangled results. In this paper, we formulate the compositional disentanglement learning problem from an information-theoretic perspective and propose a recursive disentanglement network (RecurD) that propagates regulatory inductive bias recursively across the compositional feature space during disentangled representation learning. \n        Experimental studies demonstrate that RecurD outperforms $\\beta$-VAE and several of its state-of-the-art variants on disentangled representation learning and enables more data-efficient downstream machine learning tasks.",
    "One-sentence Summary": "This paper has described a solution to the compositional disentangled representation learning problem."
  },
  {
    "title": "ADAVI: Automatic Dual Amortized Variational Inference Applied To Pyramidal Bayesian Models",
    "url": "/forum?id=CgIEctmcXx1",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Bayesian inference, Hierarchical Bayesian Models, structured Variational Inference, Simulation Based Inference, Inference amortization, Neuroimaging",
    "Abstract": "Frequently, population studies feature pyramidally-organized data represented using Hierarchical Bayesian Models (HBM) enriched with plates. These models can become prohibitively large in settings such as neuroimaging, where a sample is composed of a functional MRI signal measured on 300 brain locations, across 4 measurement sessions, and 30 subjects, resulting in around 1 million latent parameters.\n        \n        Such high dimensionality hampers the usage of modern, expressive flow-based techniques.\n        \n        To infer parameter posterior distributions in this challenging class of problems, we designed a novel methodology that automatically produces a variational family dual to a target HBM. This variational family, represented as a neural network, consists in the combination of an attention-based hierarchical encoder feeding summary statistics to a set of normalizing flows. Our automatically-derived neural network exploits exchangeability in the plate-enriched HBM and factorizes its parameter space. The resulting architecture reduces by orders of magnitude its parameterization with respect to that of a typical flow-based representation, while maintaining expressivity.\n        \n        Our method performs inference on the specified HBM in an amortized setup: once trained, it can readily be applied to a new data sample to compute the parameters' full posterior.\n        \n        We demonstrate the capability and scalability of our method on simulated data, as well as a challenging high-dimensional brain parcellation experiment. We also open up several questions that lie at the intersection between normalizing flows, SBI, structured Variational Inference, and inference amortization.",
    "One-sentence Summary": "We automatically derive a variational family dual to a plate-enriched Hierarchical Bayesian Network and perform amortized inference."
  },
  {
    "title": "Distributionally Robust Models with Parametric Likelihood Ratios",
    "url": "/forum?id=a34GrNaYEcS",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "distributionally robust optimization, fairness, deep learning, robustness, adversarial learning",
    "Abstract": "As machine learning models are deployed ever more broadly, it becomes increasingly important that they are not only able to perform well on their training distribution, but also yield accurate predictions when confronted with distribution shift. The Distributionally Robust Optimization (DRO) framework proposes to address this issue by training models to minimize their expected risk under a collection of distributions, to imitate test-time shifts. This is most commonly achieved by instance-level re-weighting of the training objective to emulate the likelihood ratio with possible test distributions, which allows for estimating their empirical risk via importance sampling (assuming that they are subpopulations of the training distribution). However, re-weighting schemes in the literature are usually limited due to the difficulty of keeping the optimization problem tractable and the complexity of enforcing normalization constraints. In this paper, we show that three simple ideas -- mini-batch level normalization, a KL penalty and simultaneous gradient updates -- allow us to train models with DRO using a broader class of parametric likelihood ratios. In a series of experiments on both image and text classification benchmarks, we find that models trained with the resulting parametric adversaries are consistently more robust to subpopulation shifts when compared to other DRO approaches, and that the method performs reliably well with little hyper-parameter tuning.",
    "One-sentence Summary": "We learn adversarial parametric reweightings of the training data to reliably train more robust models"
  },
  {
    "title": "Constrained Physical-Statistics Models for Dynamical System Identification and Prediction",
    "url": "/forum?id=gbe1zHyA73",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep Learning, Hybrid Models, Differential Equations",
    "Abstract": "Modeling dynamical systems combining prior physical knowledge and machine learning (ML) is promising in scientific problems when the underlying processes are not fully understood, e.g. when the dynamics is partially known. A common practice to identify the respective parameters of the physical and ML components is to formulate the problem as supervised learning on observed trajectories. However, this formulation leads to an infinite number of possible decompositions. To solve this ill-posedness, we reformulate the learning problem by introducing an upper bound on the prediction error of a physical-statistical model. This allows us to control the contribution of both the physical and statistical components to the overall prediction. This framework generalizes several existing hybrid schemes proposed in the literature. We provide theoretical guarantees on the well-posedness of our formulation along with a proof of convergence in a simple affine setting. For more complex dynamics, we validate our framework experimentally.",
    "One-sentence Summary": "We propose to incorporate constraints in the learning of hybrid physical and data driven dynamical models."
  },
  {
    "title": "Doubly Adaptive Scaled Algorithm for Machine Learning Using Second-Order Information",
    "url": "/forum?id=HCelXXcSEuH",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Convex Optimization, Non-Convex Optimization, Stochastic Optimization, Second-Order Optimization, Deep Learning",
    "Abstract": "We present a novel adaptive optimization algorithm for large-scale machine learning problems. Equipped with a low-cost estimate of local curvature and Lipschitz smoothness, our method dynamically adapts the search direction and step-size. The search direction contains gradient information preconditioned by a well-scaled diagonal preconditioning matrix that captures the local curvature information. Our methodology does not require the tedious task of learning rate tuning, as the learning rate is updated automatically without adding an extra hyper-parameter. We provide convergence guarantees on a comprehensive collection of optimization problems, including convex, strongly convex, and nonconvex problems, in both deterministic and stochastic regimes. We also conduct an extensive empirical evaluation on standard machine learning problems, justifying our algorithm's versatility and demonstrating its strong performance compared to other start-of-the-art first-order and second-order methods.",
    "One-sentence Summary": "Second-Order Method for Large Scale Machine Learning Tasks"
  },
  {
    "title": "Understanding approximate and unrolled dictionary learning for pattern recovery",
    "url": "/forum?id=rI0LYgGeYaw",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Dictionary learning, bi-level optimization, unrolling, pattern learning",
    "Abstract": "Dictionary learning consists of finding a sparse representation from noisy data and is a common way to encode data-driven prior knowledge on signals. Alternating minimization (AM) is standard for the underlying optimization, where gradient descent steps alternate with sparse coding procedures. The major drawback of this method is its prohibitive computational cost, making it unpractical on large real-world data sets. This work studies an approximate formulation of dictionary learning based on unrolling and compares it to alternating minimization to find the best trade-off between speed and precision. We analyze the asymptotic behavior and convergence rate of gradients estimates in both methods. We show that unrolling performs better on the support of the inner problem solution and during the first iterations. Finally, we apply unrolling on pattern learning in magnetoencephalography (MEG) with the help of a stochastic algorithm and compare the performance to a state-of-the-art method."
  },
  {
    "title": "Constraining Linear-chain CRFs to Regular Languages",
    "url": "/forum?id=jbrgwbv8nD",
    "date": "28 Sept 2021 (modified: 02 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "constrained training, probabilistic graphical models, CRF, semantic role labeling, sequence labeling",
    "Abstract": "A major challenge in structured prediction is to represent the interdependencies within output structures.  When outputs are structured as sequences, linear-chain conditional random fields (CRFs) are a widely used model class which can learn local dependencies in the output. However, the CRF's Markov assumption makes it impossible for CRFs to represent distributions with nonlocal dependencies, and standard CRFs are unable to respect nonlocal constraints of the data (such as global arity constraints on output labels).  We present a generalization of CRFs that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language $\\mathcal{L}$.  The resulting regular-constrained CRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in $\\mathcal{L}$.  Notably, RegCCRFs can incorporate their constraints during training, while related models only enforce constraints during decoding.  We prove that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice.  Additionally, we demonstrate a practical benefit on downstream tasks by incorporating a RegCCRF into a deep neural model for semantic role labeling, exceeding state-of-the-art results on a standard dataset.",
    "One-sentence Summary": "CRFs can be efficiently constrained to arbitrary regular languages, enforcing nonlocal constraints on their outputs."
  },
  {
    "title": "Dive Deeper Into Integral Pose Regression",
    "url": "/forum?id=vHVcB-ak3Si",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Integral pose regression combines an implicit heatmap with end-to-end training for human body and hand pose estimation. Unlike detection-based heatmap methods, which decode final joint positions from the heatmap with a non-differentiable argmax operation, integral regression methods apply a differentiable expectation operation. This paper offers a deep dive into the inference and back-propagation of integral pose regression to better understand the differences in performance and training compared to detection-based methods. For inference, we give theoretical support as to why expectation should always be better than the argmax operation, i.e. integral regression should always outperform detection.  Yet, in practice, this is observed only in hard cases because the heatmap activation for regression shrinks in easy cases. We then experimentally show that activation shrinkage is one of the leading causes for integral regression's inferior performance.  For back-propagation, we theoretically and empirically analyze the gradients to explain the slow training speed of integral regression.  Based on these findings, we incorporate the supervision of a spatial prior to speed up training and improve performance."
  },
  {
    "title": "Evidential Turing Processes",
    "url": "/forum?id=84NMXTHYe-",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Evidential Deep Learning, Neural Processes, Attention, Neural Turing Machines",
    "Abstract": "A probabilistic classifier with reliable predictive uncertainties i) fits successfully to the target domain data, ii) provides calibrated class probabilities in difficult regions of the target domain (e.g. class overlap), and iii) accurately identifies queries coming out of the target domain and reject them. We introduce an original combination of Evidential Deep Learning, Neural Processes, and Neural Turing Machines capable of providing all three essential properties mentioned above for total uncertainty quantification. We observe our method on three image classification benchmarks to consistently improve the in-domain uncertainty quantification, out-of-domain detection, and robustness against input perturbations with one single model. Our unified solution delivers an implementation-friendly and computationally efficient recipe for safety clearance and provides intellectual economy to an investigation of algorithmic roots of epistemic awareness in deep neural nets.",
    "One-sentence Summary": "An original extension of evidential deep learning with neural processes and neural Turing machines makes it possible to attain both in-domain calibration and out-of-domain detection in a single model."
  },
  {
    "title": "Noisy Feature Mixup",
    "url": "/forum?id=vJb4I2ANmy",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Data augmentation, implicit regularization, mixup, noise injection, model robustness",
    "Abstract": "We introduce Noisy Feature Mixup (NFM), an inexpensive yet effective method for data augmentation that combines the best of interpolation based training and noise injection schemes. Rather than training with convex combinations of pairs of examples and their labels, we use noise-perturbed convex combinations of pairs of data points in both input and feature space. This method includes mixup and manifold mixup as special cases, but it has additional advantages, including better smoothing of decision boundaries and enabling improved model robustness. We provide theory to understand this as well as the implicit regularization effects of NFM. Our theory is supported by empirical results, demonstrating the advantage of NFM, as compared to mixup and manifold mixup. We show that residual networks and vision transformers trained with NFM have favorable trade-offs between predictive accuracy on clean data and robustness with respect to various types of data perturbation across a range of computer vision benchmark datasets.",
    "One-sentence Summary": "We propose and study Noisy Feature Mixup, a simple yet effective data augmentation method that leads to improved model robustness when compared to training with manifold mixup or noise injection alone."
  },
  {
    "title": "Peek-a-Boo: What (More) is Disguised in a Randomly Weighted Neural Network, and How to Find It Efficiently",
    "url": "/forum?id=moHCzz6D5H3",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Sparse Neural Network, Lottery Ticket Hypothesis, Efficient Machine Leanring",
    "Abstract": "Sparse neural networks (NNs) are intensively investigated in literature due to their appeal in saving storage, memory, and computational costs. A recent work (Ramanujan et al., 2020) showed that, different from conventional pruning-and-finetuning pipeline, there exist hidden subnetworks in randomly initialized NNs that have good performance without training the weights. However, such \"hidden subnetworks\" have mediocre performances and require an expensive edge-popup algorithm to search for them. In this work, we define an extended class of subnetworks in randomly initialized NNs called disguised subnetworks, which are not only \"hidden\" in the random networks but also \"disguised\" -- hence can only be \"unmasked\" with certain transformations on weights. We argue that the unmasking process plays an important role in enlarging the capacity of the subnetworks and thus grants two major benefits: (i) the disguised subnetworks easily outperform the hidden counterparts; (ii) the unmasking process helps to relax the quality requirement on the sparse subnetwork mask so that the expensive edge-popup algorithm can be replaced with more efficient alternatives. On top of this new concept, we propose a novel two-stage algorithm that plays a Peek-a-Boo (PaB) game to identify the disguised subnetworks with a combination of two operations: (1) searching efficiently for a subnetwork at random initialization; (2) unmasking the disguise by learning to transform the resulting subnetwork's remaining weights. Furthermore, we show that the unmasking process can be efficiently implemented (a) without referring to any latent weights or scores; and (b) by only leveraging approximated gradients, so that the whole training algorithm is computationally light. Extensive experiments with several large models (ResNet-18, ResNet-50, and WideResNet-28) and datasets (CIFAR-10, CIFAR-100 and ImageNet) demonstrate the competency of PaB over edge-popup and other counterparts. Our codes are available at: https://github.com/VITA-Group/Peek-a-Boo."
  },
  {
    "title": "How Well Does Self-Supervised Pre-Training Perform with Streaming Data?",
    "url": "/forum?id=EwqEx5ipbOu",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Pre-Training, Representation Learning, Continual Learning, Self-Supervised Learning",
    "Abstract": "Prior works on self-supervised pre-training focus on the joint training scenario, where massive unlabeled data are assumed to be given as input all at once, and only then is a learner trained. Unfortunately, such a problem setting is often impractical if not infeasible since many real-world tasks rely on sequential learning, e.g., data are decentralized or collected in a streaming fashion. In this paper, we conduct the first thorough and dedicated investigation on self-supervised pre-training with streaming data, aiming to shed light on the model behavior under this overlooked setup. Specifically, we pre-train over 500 models on four categories of pre-training streaming data from ImageNet and DomainNet and evaluate them on three types of downstream tasks and 12 different downstream datasets. Our studies show that, somehow beyond our expectation, with simple data replay or parameter regularization, sequential self-supervised pre-training turns out to be an efficient alternative for joint pre-training, as the performances of the former are mostly on par with those of the latter. Moreover, catastrophic forgetting, a common issue in sequential supervised learning, is much alleviated in sequential self-supervised learning (SSL), which is well justified through our comprehensive empirical analysis on representations and the sharpness of minima in the loss landscape. Our findings, therefore, suggest that, in practice, for SSL, the cumbersome joint training can be replaced mainly by sequential learning, which in turn enables a much broader spectrum of potential application scenarios."
  },
  {
    "title": "Subspace Regularizers for Few-Shot Class Incremental Learning",
    "url": "/forum?id=boJy41J-tnQ",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "few-shot class incremental learning, incremental learning, incremental classification, subspace regularization, manifold regularization, few-shot learning",
    "Abstract": "Few-shot class incremental learning---the problem of updating a trained classifier to discriminate among an expanded set of classes with limited labeled data---is a key challenge for machine learning systems deployed in non-stationary environments. Existing approaches to the problem rely on complex model architectures and training procedures that are difficult to tune and re-use. In this paper, we present an extremely simple approach that enables the use of ordinary logistic regression classifiers for few-shot incremental learning. The key to this approach is a new family of \\textit{subspace regularization} schemes that encourage weight vectors for new classes to lie close to the subspace spanned by the weights of existing classes. When combined with pretrained convolutional feature extractors, logistic regression models trained with subspace regularization outperform specialized, state-of-the-art approaches to few-shot incremental image classification by up to 23\\% on the \\textit{mini}ImageNet dataset. Because of its simplicity, subspace regularization can be straightforwardly configured to incorporate additional background information about the new classes (including class names and descriptions specified in natural language); this offers additional control over the trade-off between existing and new classes. Our results show that simple geometric regularization of class representations offers an effective tool for continual learning.",
    "One-sentence Summary": "We propose a simple yet highly effective set of subspace-based regularizers to address representation learning for few-shot incremental classification."
  },
  {
    "title": "Using Graph Representation Learning with Schema Encoders to Measure the Severity of Depressive Symptoms",
    "url": "/forum?id=OtEDS2NWhqa",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph neural networks sentiment analysis node-embedding algorithm  diagnostic prediction task",
    "Abstract": "Graph neural networks (GNNs) are widely used in regression and classification problems applied to text, in areas such as sentiment analysis and medical decision-making processes. We propose a novel form for node attributes within a GNN based model that captures node-specific embeddings for every word in the vocabulary. This provides a global representation at each node, coupled with node-level updates according to associations among words in a transcript. We demonstrate the efficacy of the approach by augmenting the accuracy of measuring major depressive disorder (MDD). Prior research has sought to make a diagnostic prediction of depression levels from patient data using several modalities, including audio, video, and text. On the DAIC-WOZ benchmark, our method outperforms state-of-art methods by a substantial margin, including those using multiple modalities. Moreover, we also evaluate the performance of our novel model on a Twitter sentiment dataset. We show that our model outperforms a general GNN model by leveraging our novel 2-D node attributes. These results demonstrate the generality of the proposed method.",
    "One-sentence Summary": "We encode word embeddings by using graph representation learning method, which schematizes context-level depressive features for depression state prediction."
  },
  {
    "title": "Actor-Critic Policy Optimization in a Large-Scale Imperfect-Information Game",
    "url": "/forum?id=DTXZqTNV5nW",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Policy Optimization, Nash Equilibrium, Mahjong AI",
    "Abstract": "The deep policy gradient method has demonstrated promising results in many large-scale games, where the agent learns purely from its own experience. Yet, policy gradient methods with self-play suffer convergence problems to a Nash Equilibrium (NE) in multi-agent situations. Counterfactual regret minimization (CFR) has a convergence guarantee to a NE in 2-player zero-sum games, but it usually needs domain-specific abstractions to deal with large-scale games.  Inheriting merits from both methods, in this paper we extend the actor-critic algorithm framework in deep reinforcement learning to tackle a large-scale 2-player zero-sum imperfect-information game, 1-on-1 Mahjong, whose information set size and game length are much larger than poker. The proposed algorithm, named Actor-Critic Hedge (ACH), modifies the policy optimization objective from originally maximizing the discounted returns to minimizing a type of weighted cumulative counterfactual regret. This modification is achieved by approximating the regret via a deep neural network and minimizing the regret via generating self-play policies using Hedge. ACH is theoretically justified as it is derived from a neural-based weighted CFR, for which we prove the convergence to a NE under certain conditions. Experimental results on the proposed 1-on-1 Mahjong benchmark and benchmarks from the literature demonstrate that ACH outperforms related state-of-the-art methods. Also, the agent obtained by ACH defeats a human champion in 1-on-1 Mahjong.",
    "One-sentence Summary": "A new actor-critic algorithm for approximating a Nash Equilibrium in the large-scale imperfect-information game 1v1 Mahjong."
  },
  {
    "title": "Policy Gradients Incorporating the Future",
    "url": "/forum?id=EHaUTlm2eHg",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Reasoning about the future -- understanding how decisions in the present time affect outcomes in the future -- is one of the central challenges for reinforcement learning (RL), especially in highly-stochastic or partially observable environments. While predicting the future directly is hard, in this work we introduce a method that allows an agent to ``look into the future'' without explicitly predicting it. Namely, we propose to allow an agent, during its training on past experience, to observe what \\emph{actually} happened in the future at that time, while enforcing an information bottleneck to avoid the agent overly relying on this privileged information. Coupled with recent advances in variational inference and a latent-variable autoregressive model, this gives our agent the ability to utilize rich and \\emph{useful} information about the future trajectory dynamics in addition to the present. Our method, Policy Gradients Incorporating the Future (PGIF), is easy to implement and versatile, being applicable to virtually any policy gradient algorithm. We apply our proposed method to a number of off-the-shelf RL algorithms and show that PGIF is able to achieve higher reward faster in a variety of online and offline RL domains, as well as sparse-reward and partially observable environments."
  },
  {
    "title": "Gradient Information Matters in Policy Optimization by Back-propagating through Model",
    "url": "/forum?id=rzvOQrnclO0",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Model-based RL, Policy Optimization",
    "Abstract": "Model-based reinforcement learning provides an efficient mechanism to find the optimal policy by interacting with the learned environment. In addition to treating the learned environment like a black-box simulator, a more effective way to use the model is to exploit its differentiability. Such methods require the gradient information of the learned environment model when calculating the policy gradient. However, since the error of gradient is not considered in the model learning phase, there is no guarantee for the model's accuracy. To address this problem, we first analyze the convergence rate for the policy optimization methods when the policy gradient is calculated using the learned environment model. The theoretical results show that the model gradient error matters in the policy optimization phrase. Then we propose a two-model-based learning method to control the prediction error and the gradient error. We separate the different roles of these two models at the model learning phase and coordinate them at the policy optimization phase. After proposing the method, we introduce the directional derivative projection policy optimization (DDPPO) algorithm as a practical implementation to find the optimal policy. Finally, we empirically demonstrate the proposed algorithm has better sample efficiency when achieving a comparable or better performance on benchmark continuous control tasks.",
    "One-sentence Summary": "Considering the gradient information in the model learning is crucial for the model-based policy optimization according to our theoritical results. Motivated by such conclusion, we design a novel DDPPO algorithm that can achieve the SOTA performance."
  },
  {
    "title": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
    "url": "/forum?id=xm6YD62D1Ub",
    "date": "28 Sept 2021 (modified: 08 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self-supervised learning, representation learning, computer vision",
    "Abstract": "Recent self-supervised methods for image representation learning maximize the agreement between embedding vectors produced by encoders fed with different views of the same image.  The main challenge is to prevent a collapse in which the encoders produce constant or non-informative vectors. We introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with two regularizations terms applied to both embeddings separately: (1) a term that maintains the variance of each embedding dimension above a threshold,  (2) a term that decorrelates each pair of variables. Unlike most other approaches to the same problem, VICReg does not require techniques such as: weight sharing between the branches, batch normalization, feature-wise normalization, output quantization, stop gradient, memory banks, etc., and achieves results on par with the state of the art on several downstream tasks. In addition, we show that our variance regularization term stabilizes the training of other methods and leads to performance improvements.",
    "One-sentence Summary": "Variance regularization prevents collapse in self-supervised representation learning"
  },
  {
    "title": "High Probability Generalization Bounds with Fast Rates for Minimax Problems",
    "url": "/forum?id=gI7feJ9yXPz",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Minimax problems are receiving an increasing amount of attention in a wide range of applications in machine learning (ML), for instance, reinforcement learning, robust optimization, adversarial learning, and distributed computing, to mention but a few. Current studies focus on the fundamental understanding of general minimax problems with an emphasis on convergence behavior. As a comparison, there is far less work to study the generalization performance. Additionally, existing generalization bounds are almost all derived in expectation, and the high probability bounds are all presented in the slow order $\\mathcal{O}(1/\\sqrt{n})$, where $n$ is the sample size. In this paper, we provide improved generalization analyses and obtain sharper high probability generalization bounds for most existing generalization measures of minimax problems. We then use the improved learning bounds to establish high probability generalization bounds with fast rates for classical empirical saddle point (ESP) solution and several popular gradient-based optimization algorithms, including gradient descent ascent (GDA), stochastic gradient descent ascent (SGDA), proximal point method (PPM), extra-gradient (EG), and optimistic gradient descent ascent (OGDA). In summary, we provide a systematical analysis of sharper generalization bounds of minimax problems."
  },
  {
    "title": "SUMNAS: Supernet with Unbiased Meta-Features for Neural Architecture Search",
    "url": "/forum?id=Z8FzvVU6_Kj",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural architecture search",
    "Abstract": "One-shot Neural Architecture Search (NAS) usually constructs an over-parameterized network, which we call a supernet, and typically adopts sharing parameters among the sub-models to improve computational efficiency. One-shot NAS often repeatedly samples sub-models from the supernet and trains them to optimize the shared parameters. However, this training strategy suffers from multi-model forgetting. Training a sampled sub-model overrides the previous knowledge learned by the other sub-models, resulting in an unfair performance evaluation between the sub-models. We propose Supernet with Unbiased Meta-Features for Neural Architecture Search (SUMNAS), a supernet learning strategy based on meta-learning to tackle the knowledge forgetting issue. During the training phase, we explicitly address the multi-model forgetting problem and help the supernet learn unbiased meta-features, independent from the sampled sub-models. Once training is over, sub-models can be instantly compared to get the overall ranking or the best sub-model. Our evaluation on the NAS-Bench-201 and MobileNet-based search space demonstrate that SUMNAS shows improved ranking ability and finds architectures whose performance is on par with existing state-of-the-art NAS algorithms.",
    "One-sentence Summary": "We propose a supernet learning strategy that learns unbiased meta-features to tackle multi-model forgetting problem of neural architecture search."
  },
  {
    "title": "Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting",
    "url": "/forum?id=_XNtisL32jv",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Spiking Neural Networks, Direct Training, Surrogate Gradient, Generalizability",
    "Abstract": "Recently, brain-inspired spiking neuron networks (SNNs) have attracted widespread research interest because of their event-driven and energy-efficient characteristics. It is difficult to efficiently train deep SNNs due to the non-differentiability of its activation function, which disables the typically used gradient descent approaches for traditional artificial neural networks (ANNs). Although the adoption of surrogate gradient (SG) formally allows for the back-propagation of losses, the discrete spiking mechanism actually differentiates the loss landscape of SNNs from that of ANNs, failing the surrogate gradient methods to achieve comparable accuracy as for ANNs. In this paper, we first analyze why the current direct training approach with surrogate gradient results in SNNs with poor generalizability. Then we introduce the temporal efficient training (TET) approach to compensate for the loss of momentum in the gradient descent with SG so that the training process can converge into flatter minima with better generalizability. Meanwhile, we demonstrate that TET improves the temporal scalability of SNN and induces a temporal inheritable training for acceleration. Our method consistently outperforms the SOTA on all reported mainstream datasets, including CIFAR-10/100 and ImageNet. Remarkably on DVS-CIFAR10, we obtained  83% top-1 accuracy, over 10% improvement compared to existing state of the art.",
    "One-sentence Summary": "This paper provides a novel temporal efficient training method for SNN, which significantly improves performance by modifying the optimization target."
  },
  {
    "title": "Reliable Adversarial Distillation with Unreliable Teachers",
    "url": "/forum?id=u6TRGdzhfip",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "In ordinary distillation, student networks are trained with soft labels (SLs) given by pretrained teacher networks, and students are expected to improve upon teachers since SLs are stronger supervision than the original hard labels. However, when considering adversarial robustness, teachers may become unreliable and adversarial distillation may not work: teachers are pretrained on their own adversarial data, and it is too demanding to require that teachers are also good at every adversarial data queried by students. Therefore, in this paper, we propose reliable introspective adversarial distillation (IAD) where students partially instead of fully trust their teachers. Specifically, IAD distinguishes between three cases given a query of a natural data (ND) and the corresponding adversarial data (AD): (a) if a teacher is good at AD, its SL is fully trusted; (b) if a teacher is good at ND but not AD, its SL is partially trusted and the student also takes its own SL into account; (c) otherwise, the student only relies on its own SL. Experiments demonstrate the effectiveness of IAD for improving upon teachers in terms of adversarial robustness."
  },
  {
    "title": "Neural Program Synthesis with Query",
    "url": "/forum?id=NyJ2KIN8P17",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Aiming to find a program satisfying the user intent given input-output examples, program synthesis has attracted increasing interest in the area of machine learning. Despite the promising performance of existing methods, most of their success comes from the privileged information of well-designed input-output examples. However, providing such input-output examples is unrealistic because it requires the users to have the ability to describe the underlying program with a few input-output examples under the training distribution. In this work, we propose a query-based framework that trains a query neural network to generate informative input-output examples automatically and interactively from a large query space. The quality of the query depends on the amount of the mutual information between the query and the corresponding program, which can guide the optimization of the query framework. To estimate the mutual information more accurately, we introduce the functional space (F-space) which models the relevance between the input-output examples and the programs in a differentiable way. We evaluate the effectiveness and generalization of the proposed query-based framework on the Karel task and the list processing task. Experimental results show that the query-based framework can generate informative input-output examples which achieve\n        and even outperform well-designed input-output examples.",
    "One-sentence Summary": "We propose a query-based framework for the interactive program synthesis."
  },
  {
    "title": "Delaunay Component Analysis for Evaluation of Data Representations",
    "url": "/forum?id=HTVch9AMPa",
    "date": "28 Sept 2021 (modified: 22 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Interpretation and Evaluation of Learned Representations, Generative Models, Contrastive Learning",
    "Abstract": "Advanced representation learning techniques require reliable and general evaluation methods. Recently, several algorithms based on the common idea of geometric and topological analysis of a manifold approximated from the learned data representations have been proposed. In this work, we introduce Delaunay Component Analysis (DCA) -- an evaluation algorithm which approximates the data manifold using a more suitable neighbourhood graph called Delaunay graph. This provides a reliable manifold estimation even for challenging geometric arrangements of representations such as clusters with varying shape and density as well as outliers, which is where existing methods often fail. Furthermore, we exploit the nature of Delaunay graphs and introduce a framework for assessing the quality of individual novel data representations.  We experimentally validate the proposed DCA method on representations obtained from neural networks trained with contrastive objective, supervised and generative models, and demonstrate various use cases of our extended single point evaluation framework.",
    "One-sentence Summary": "We present Delaunay Component Analysis (DCA) framework for evaluation of learned data representations which anayzes geometric and topological properties of representation spaces using Delaunay graphs."
  },
  {
    "title": "Visual hyperacuity with moving sensor and recurrent neural computations",
    "url": "/forum?id=p0rCmDEN_-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "visual system, convolutional neural networks, recurrent neural networks, active vision, active sensing, ocular drift",
    "Abstract": "Dynamical phenomena, such as recurrent neuronal activity  and perpetual motion of the eye, are typically overlooked in models of bottom-up visual perception. Recent experiments suggest that tiny inter-saccadic eye motion (\"fixational drift\") enhances visual  acuity beyond the limit imposed by the density of retinal photoreceptors. Here we hypothesize that such an enhancement is enabled by recurrent neuronal computations in early visual areas. Specifically, we explore a setting involving a low-resolution dynamical sensor that moves with respect to a static scene, with drift-like tiny steps. This setting mimics a dynamical eye viewing objects in perceptually-challenging conditions. The dynamical sensory input is classified by a convolutional neural network with recurrent connectivity added to its lower layers, in analogy to recurrent connectivity in early visual areas.  Applying our system to CIFAR-10 and CIFAR-100 datasets down-sampled via 8x8 sensor, we found that (i) classification accuracy, which is drastically reduced by this down-sampling, is mostly restored to its 32x32 baseline level when using a moving sensor and recurrent connectivity, (ii) in this setting, neurons in the early layers exhibit a wide repertoire of selectivity patterns, spanning the spatiotemporal selectivity space, with neurons preferring different combinations of spatial and temporal patterning, and (iii) curved sensor's trajectories improve  visual acuity compared to straight trajectories, echoing recent experimental findings involving eye-tracking in challenging conditions. Our work sheds light on the possible role of recurrent connectivity in early vision as well as the roles of fixational drift and temporal-frequency selective cells in the visual system. It also proposes a solution for artificial image recognition in settings with limited resolution and multiple time samples, such as in edge AI applications.",
    "One-sentence Summary": "We show how recurrent connectivity in early vision together with eye motion helps to cope with limited sensor's spatial resolution."
  },
  {
    "title": "Partial Wasserstein Adversarial Network for Non-rigid Point Set Registration",
    "url": "/forum?id=2ggNjUisGyr",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "partial Wasserstein discrepancy, partial distribution matching, point set registration",
    "Abstract": "Given two point sets, the problem of registration is to recover a transformation that matches one set to the other. This task is challenging due to the presence of large number of outliers, the unknown non-rigid deformations and the large sizes of point sets. To obtain strong robustness against outliers, we formulate the registration problem as a partial distribution matching (PDM) problem, where the goal is to partially match the distributions represented by point sets in a metric space. To handle large point sets, we propose a scalable PDM algorithm by utilizing the efficient partial Wasserstein-1 (PW) discrepancy. Specifically, we derive the Kantorovich-Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these results, we propose a partial Wasserstein adversarial network (PWAN),  which is able to approximate the PW discrepancy by a neural network, and minimize it by gradient descent. In addition,\n        it also incorporates an efficient coherence regularizer for non-rigid transformations to avoid unrealistic deformations. We evaluate PWAN on practical point set registration tasks, and show that the proposed PWAN is robust, scalable and performs more favorably than the state-of-the-art methods.",
    "One-sentence Summary": "We propose a method for large scale partial distribution matching problem, and apply it to non-rigid point set registration task."
  },
  {
    "title": "Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation",
    "url": "/forum?id=xFOyMwWPkz",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "interpretation of neural network units, computational topology, convolutional neural networks, entropy",
    "Abstract": "Identifying the status of individual network units is critical for understanding the mechanism of convolutional neural networks (CNNs). However, it is still challenging to reliably give a general indication of unit status, especially for units in different network models. To this end, we propose a novel method for quantitatively clarifying the status of single unit in CNN using algebraic topological tools. Unit status is indicated via the calculation of a defined topological-based entropy, called feature entropy, which measures the degree of chaos of the global spatial pattern hidden in the unit for a category. In this way, feature entropy could provide an accurate indication of status for units in different networks with diverse situations like weight-rescaling operation. Further, we show that feature entropy decreases as the layer goes deeper and shares almost simultaneous trend with loss during training. We show that by investigating the feature entropy of units on only training data, it could give discrimination between networks with different generalization ability from the view of the effectiveness of feature representations.",
    "One-sentence Summary": "We propose a novel method for quantitatively clarifying the status of individual units in CNNs and show its value in interpreting networks with different generalization ability."
  },
  {
    "title": "Imitation Learning by Reinforcement Learning",
    "url": "/forum?id=1zwleytEpYx",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, imitation learning, Markov Decision Process, continuous control",
    "Abstract": "Imitation learning algorithms learn a policy from demonstrations of expert behavior. We show that, for deterministic experts, imitation learning can be done by reduction to reinforcement learning with a stationary reward. Our theoretical analysis both certifies the recovery of expert reward and bounds the total variation distance between the expert and the imitation learner, showing a link to adversarial imitation learning. We conduct experiments which confirm that our reduction works well in practice for continuous control tasks.",
    "One-sentence Summary": "For deterministic experts, you can do imitation learning by calling an RL solver once, with a stationary reward signal."
  },
  {
    "title": "On-Policy Model Errors in Reinforcement Learning",
    "url": "/forum?id=81e1aeOt-sd",
    "date": "28 Sept 2021 (modified: 03 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Model-based reinforcement learning, reinforcement learning, model learning",
    "Abstract": "Model-free reinforcement learning algorithms can compute policy gradients given sampled environment transitions, but require large amounts of data. In contrast, model-based methods can use the learned model to generate new data, but model errors and bias can render learning unstable or suboptimal. In this paper, we present a novel method that combines real-world data and a learned model in order to get the best of both worlds. The core idea is to exploit the real-world data for on-policy predictions and use the learned model only to generalize to different actions. Specifically, we use the data as time-dependent on-policy correction terms on top of a learned model, to retain the ability to generate data without accumulating errors over long prediction horizons. We motivate this method theoretically and show that it counteracts an error term for model-based policy improvement. Experiments on MuJoCo- and PyBullet-benchmarks show that our method can drastically improve existing model-based approaches without introducing additional tuning parameters.",
    "One-sentence Summary": "We combine real-world data and a learned model for data-efficient reinforcement learning with reduced model-bias."
  },
  {
    "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor",
    "url": "/forum?id=O50443AsCP",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "table pre-training, sythetic pre-training, SQL execution, table-based question answering, table-based fact verification",
    "Abstract": "Recent progress in language model pre-training has achieved a great success via leveraging large-scale unstructured textual data. However, it is still a challenge to apply pre-training on structured tabular data due to the absence of large-scale high-quality tabular data. In this paper, we propose TAPEX to show that table pre-training can be achieved by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries and their execution outputs. TAPEX addresses the data scarcity challenge via guiding the language model to mimic a SQL executor on the diverse, large-scale and high-quality synthetic corpus. We evaluate TAPEX on four benchmark datasets. Experimental results demonstrate that TAPEX outperforms previous table pre-training approaches by a large margin and achieves new state-of-the-art results on all of them. This includes the improvements on the weakly-supervised WikiSQL denotation accuracy to 89.5% (+2.3%), the WikiTableQuestions denotation accuracy to 57.5% (+4.8%), the SQA denotation accuracy to 74.5% (+3.5%), and the TabFact accuracy to 84.2% (+3.2%). To our knowledge, this is the first work to exploit table pre-training via synthetic executable programs and to achieve new state-of-the-art results on various downstream tasks. Our code can be found at https://github.com/microsoft/Table-Pretraining.",
    "One-sentence Summary": "This work performs table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries and their execution results."
  },
  {
    "title": "DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning",
    "url": "/forum?id=9SDQB3b68K",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Offline reinforcement learning algorithms promise to be applicable in settings where a fixed dataset is available and no new experience can be acquired. However, such formulation is inevitably offline-data-hungry and, in practice, collecting a large offline dataset for one specific task over one specific environment is also costly and laborious. In this paper, we thus 1) formulate the offline dynamics adaptation by using (source) offline data collected from another dynamics to relax the requirement for the extensive (target) offline data, 2) characterize the dynamics shift problem in which prior offline methods do not scale well, and 3) derive a simple dynamics-aware reward augmentation (DARA) framework from both model-free and model-based offline settings. Specifically, DARA emphasizes learning from those source transition pairs that are adaptive for the target environment and mitigates the offline dynamics shift by characterizing state-action-next-state pairs instead of the typical state-action distribution sketched by prior offline RL methods. The experimental evaluation demonstrates that DARA, by augmenting rewards in the source offline dataset, can acquire an adaptive policy for the target environment and yet significantly reduce the requirement of target offline data. With only modest amounts of target offline data, our performance consistently outperforms the prior offline RL methods in both simulated and real-world tasks."
  },
  {
    "title": "Explaining Point Processes by Learning Interpretable Temporal Logic Rules",
    "url": "/forum?id=P07dq7iSAGr",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Temporal Point Process, Temporal Logic Rules, Explainable Models",
    "Abstract": "We propose a principled method to learn a set of human-readable logic rules to explain temporal point processes. \n        We assume that the generative mechanisms underlying the temporal point processes are governed by a set of first-order temporal logic rules, as a compact representation of domain knowledge. Our method formulates the rule discovery process from noisy event data as a maximum likelihood problem, and designs an efficient and tractable branch-and-price algorithm to progressively search for new rules and expand existing rules. The proposed algorithm alternates between the rule generation stage and the rule evaluation stage, and uncovers the most important collection of logic rules within a fixed time limit for both synthetic and real event data. In a real healthcare application, we also had human experts (i.e., doctors) verify the learned temporal logic rules and provide further improvements. These expert-revised interpretable rules lead to a point process model which outperforms previous state-of-the-arts for symptom prediction, both in their occurrence times and types.",
    "One-sentence Summary": "We propose a principled method to learn a set of human-readable logic rules to explain temporal point processes."
  },
  {
    "title": "On Robust Prefix-Tuning for Text Classification",
    "url": "/forum?id=eBCmOocUejf",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "prefix-tuning, pretrained language models, text classification, robustness in NLP, optimal control",
    "Abstract": "Recently, prefix-tuning has gained increasing attention as a parameter-efficient finetuning method for large-scale pretrained language models. The method keeps the pretrained models fixed and only updates the prefix token parameters for each downstream task. Despite being lightweight and modular, prefix-tuning still lacks robustness to textual adversarial attacks. However, most currently developed defense techniques necessitate auxiliary model update and storage, which inevitably hamper the modularity and low storage of prefix-tuning. In this work, we propose a robust prefix-tuning framework that preserves the efficiency and modularity of prefix-tuning. The core idea of our framework is leveraging the layerwise activations of the language model by correctly-classified training data as the standard for additional prefix finetuning. During the test phase, an extra batch-level prefix is tuned for each batch and added to the original prefix for robustness enhancement. Extensive experiments on three text classification benchmarks show that our framework substantially improves robustness over several strong baselines against five textual attacks of different types while maintaining comparable accuracy on clean texts. We also interpret our robust prefix-tuning framework from the optimal control perspective and pose several directions for future research.",
    "One-sentence Summary": "We propose a robust prefix-tuning framework that improves robustness of prefix-tuning against different types of attacks while preserving its efficiency and modularity with interpretation from the perspective of optimal control."
  },
  {
    "title": "Learning Graphon Mean Field Games and Approximate Nash Equilibria",
    "url": "/forum?id=0sgntlpKDOz",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Mean Field Games, Reinforcement Learning, Multi Agent Systems",
    "Abstract": "Recent advances at the intersection of dense large graph limits and mean field games have begun to enable the scalable analysis of a broad class of dynamical sequential games with large numbers of agents. So far, results have been largely limited to graphon mean field systems with continuous-time diffusive or jump dynamics, typically without control and with little focus on computational methods. We propose a novel discrete-time formulation for graphon mean field games as the limit of non-linear dense graph Markov games with weak interaction. On the theoretical side, we give extensive and rigorous existence and approximation properties of the graphon mean field solution in sufficiently large systems. On the practical side we provide general learning schemes for graphon mean field equilibria by either introducing agent equivalence classes or reformulating the graphon mean field system as a classical mean field system. By repeatedly finding a regularized optimal control solution and its generated mean field, we successfully obtain plausible approximate Nash equilibria in otherwise infeasible large dense graph games with many agents. Empirically, we are able to demonstrate on a number of examples that the finite-agent behavior comes increasingly close to the mean field behavior for our computed equilibria as the graph or system size grows, verifying our theory. More generally, we successfully apply policy gradient reinforcement learning in conjunction with sequential Monte Carlo methods.",
    "One-sentence Summary": "We propose, analyze and solve a novel, theoretically well-founded graph-based mean field game for Nash equilibria in discrete-time dynamical systems on otherwise infeasibly large dense graphs."
  },
  {
    "title": "Measuring CLEVRness: Black-box Testing of Visual Reasoning Models",
    "url": "/forum?id=UtGtoS4CYU",
    "date": "28 Sept 2021 (modified: 18 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Visual Reasoning, Visual Question Answering, Black Box Testing, Computer Vision",
    "Abstract": "How can we measure the reasoning capabilities of intelligence systems? Visual question answering provides a convenient framework for testing the model's abilities by interrogating the model through questions about the scene. However, despite scores of various visual QA datasets and architectures, which sometimes yield even a super-human performance, the question of whether those architectures can actually reason remains open to debate.\n        To answer this, we extend the visual question answering framework and propose the following behavioral test in the form of a two-player game. We consider black-box neural models of CLEVR. These models are trained on a diagnostic dataset benchmarking reasoning. Next, we train an adversarial player that re-configures the scene to fool the CLEVR model. We show that CLEVR models, which otherwise could perform at a ``human-level'', can easily be fooled by our agent. Our results \n        put in doubt whether data-driven approaches can do reasoning without exploiting the numerous biases that are often present in those datasets. Finally, we also propose a controlled experiment measuring the efficiency of such models to learn and perform reasoning.",
    "One-sentence Summary": "Black box testing of visual reasoning models as a two-player game."
  },
  {
    "title": "Exploiting Class Activation Value for Partial-Label Learning",
    "url": "/forum?id=qqdXHUGec9h",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Partial-label Learning, Class Activation Map",
    "Abstract": "Partial-label learning (PLL) solves the multi-class classification problem, where each training instance is assigned a set of candidate labels that include the true label. Recent advances showed that PLL can be compatible with deep neural networks, which achieved state-of-the-art performance. However, most of the existing deep PLL methods focus on designing proper training objectives under various assumptions on the collected data, which may limit their performance when the collected data cannot satisfy the adopted assumptions. In this paper, we propose to exploit the learned intrinsic representation of the model to identify the true label in the training process, which does not rely on any assumptions on the collected data. We make two key contributions. As the first contribution, we empirically show that the class activation map (CAM), a simple technique for discriminating the learning patterns of each class in images, could surprisingly be utilized to make accurate predictions on selecting the true label from candidate labels. Unfortunately, as CAM is confined to image inputs with convolutional neural networks, we are yet unable to directly leverage CAM to address the PLL problem with general inputs and models. Thus, as the second contribution, we propose the class activation value (CAV), which owns similar properties of CAM, while CAV is versatile in various types of inputs and models. Building upon CAV, we propose a novel method named CAV Learning (CAVL) that selects the true label by the class with the maximum CAV for model training. Extensive experiments on various datasets demonstrate that our proposed CAVL method achieves state-of-the-art performance.",
    "One-sentence Summary": "Class activation value is better for partial-label learning than the basic outputs of the classifier itself."
  },
  {
    "title": "Givens Coordinate Descent Methods for Rotation Matrix Learning in Trainable Embedding Indexes",
    "url": "/forum?id=9-Rfew334N",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Search index, Product quantization, Block coordinate descent",
    "Abstract": "Product quantization (PQ) coupled with a space rotation, is widely used in modern approximate nearest neighbor (ANN) search systems to significantly compress the disk storage for embeddings and speed up the inner product computation. Existing rotation learning methods, however, minimize quantization distortion for fixed embeddings, which are not applicable to an end-to-end training scenario where embeddings are updated constantly. In this paper, based on geometric intuitions from Lie group theory,  in particular the special orthogonal groupSO(n),  we propose a family of block Givens coordinate descent algorithms to learn rotation matrix that are provably convergent on any convex objectives. Compared to the state-of-the-art SVD method, the Givens algorithms are much more parallelizable, reducing runtime by orders of magnitude on modern GPUs, and converge more stably  according  to  experimental  studies.   They  further  improve  upon  vanilla product quantization significantly in an end-to-end training scenario.",
    "One-sentence Summary": "Learning orthonormal matrix in neural networks via Givens rotations"
  },
  {
    "title": "cosFormer: Rethinking Softmax In Attention",
    "url": "/forum?id=Bl8CQrx2Up4",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Linear Transformer, softmax attention",
    "Abstract": "Transformer has shown great successes in natural language processing, computer vision, and audio processing. As one of its core components, the softmax attention helps to capture long-range dependencies yet prohibits its scale-up due to the quadratic space and time complexity to the sequence length. Kernel methods are often adopted to reduce the complexity by approximating the softmax operator. Nevertheless, due to the approximation errors, their performances vary in different tasks/corpus and suffer crucial performance drops when compared with the vanilla softmax attention. In this paper, we propose a linear transformer called cosFormer that can achieve comparable or better accuracy to the vanilla transformer in both casual and cross attentions. cosFormer is based on two key properties of softmax attention: i). non-negativeness of the attention matrix; ii). a non-linear re-weighting scheme that can concentrate the distribution of the attention matrix. As its linear substitute, cosFormer fulfills these properties with a linear operator and a cosine-based distance re-weighting mechanism. Extensive experiments on language modeling and text understanding tasks demonstrate the effectiveness of our method. We further examine our method on long sequences and achieve state-of-the-art performance on the Long-Range Arena benchmark. The source code is available at https://github.com/OpenNLPLab/cosFormer.",
    "One-sentence Summary": "A new linear transformer."
  },
  {
    "title": "FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations",
    "url": "/forum?id=htWIlvDcY8",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neuro-Symbolic Reasoning, Concept Learning, Meta-Learning",
    "Abstract": "We present a meta-learning framework for learning new visual concepts quickly, from just one or a few examples, guided by multiple naturally occurring data streams: simultaneously looking at images, reading sentences that describe the objects in the scene, and interpreting supplemental sentences that relate the novel concept with other concepts. The learned concepts support downstream applications, such as answering questions by reasoning about unseen images. Our model, namely FALCON, represents individual visual concepts, such as colors and shapes, as axis-aligned boxes in a high-dimensional space (the ``box embedding space''). Given an input image and its paired sentence, our model first resolves the referential expression in the sentence and associates the novel concept with particular objects in the scene. Next, our model interprets supplemental sentences to relate the novel concept with other known concepts, such as ``X has property Y'' or ``X is a kind of Y''. Finally, it infers an optimal box embedding for the novel concept that jointly 1) maximizes the likelihood of the observed instances in the image, and 2) satisfies the relationships between the novel concepts and the known ones. We demonstrate the effectiveness of our model on both synthetic and real-world datasets."
  },
  {
    "title": "HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation",
    "url": "/forum?id=64trBbOhdGU",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Discrete-continuous hybrid action space is a natural setting in many practical problems, such as robot control and game AI. However, most previous Reinforcement Learning (RL) works only demonstrate the success in controlling with either discrete or continuous action space, while seldom take into account the hybrid action space. One naive way to address hybrid action RL is to convert the hybrid action space into a unified homogeneous action space by discretization or continualization, so that conventional RL algorithms can be applied. However, this ignores the underlying structure of hybrid action space and also induces the scalability issue and additional approximation difficulties, thus leading to degenerated results. In this paper, we propose Hybrid Action Representation (HyAR) to learn a compact and decodable latent representation space for the original hybrid action space. HyAR constructs the latent space and embeds the dependence between discrete action and continuous parameter via an embedding table and conditional Variantional Auto-Encoder (VAE). To further improve the effectiveness, the action representation is trained to be semantically smooth through unsupervised environmental dynamics prediction. Finally, the agent then learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embeddings to the original action space. We evaluate HyAR in a variety of environments with discrete-continuous action space. The results demonstrate the superiority of HyAR when compared with previous baselines, especially for high-dimensional action spaces."
  },
  {
    "title": "Transferable Adversarial Attack based on Integrated Gradients",
    "url": "/forum?id=DesNW4-5ai9",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "The vulnerability of deep neural networks to adversarial examples has drawn tremendous attention from the community. Three approaches, optimizing standard objective functions, exploiting attention maps, and smoothing decision surfaces, are commonly used to craft adversarial examples. By tightly integrating the three approaches, we propose a new and simple algorithm named Transferable Attack based on Integrated Gradients (TAIG) in this paper, which can find highly transferable adversarial examples for black-box attacks. Unlike previous methods using multiple computational terms or combining with other methods, TAIG integrates the three approaches into one single term. Two versions of TAIG that compute their integrated gradients on a straight-line path and a random piecewise linear path are studied. Both versions offer strong transferability and can seamlessly work together with the previous methods. Experimental results demonstrate that TAIG outperforms the state-of-the-art methods."
  },
  {
    "title": "How to deal with missing data in supervised deep learning?",
    "url": "/forum?id=J7b4BCtDm4",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "The issue of missing data in supervised learning has been largely overlooked, especially in the deep learning community. We investigate strategies to adapt neural architectures for handling missing values. Here, we focus on regression and classification problems where the features are assumed to be missing at random. Of particular interest are schemes that allow reusing as-is a neural discriminative architecture. To address supervised deep learning with missing values, we propose to marginalize over missing values in a joint model of covariates and outcomes. Thereby, we leverage both the flexibility of deep generative models to describe the distribution of the covariates and the power of purely discriminative models to make predictions. More precisely, a deep latent variable model can be learned jointly with the discriminative model, using importance-weighted variational inference, essentially using importance sampling to mimick averaging over multiple imputations. In low-capacity regimes, or when the discriminative model has a strong inductive bias, we find that our hybrid generative/discriminative approach generally outperforms single imputations methods.",
    "One-sentence Summary": "Marginalize over missing values in supervised learning using deep latent variable models."
  },
  {
    "title": "Topological Graph Neural Networks",
    "url": "/forum?id=oxxUMeFwEHd",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "topology, persistent homology, gnn, graph neural networks, graph classification, node classification, filtrations, topological data analysis, tda",
    "Abstract": "Graph neural networks (GNNs) are a powerful architecture for tackling graph learning tasks, yet have been shown to be oblivious to eminent substructures such as cycles. We present TOGL, a novel layer that incorporates global topological information of a graph using persistent homology. TOGL can be easily integrated into any type of GNN and is strictly more expressive (in terms the Weisfeiler\u2013Lehman graph isomorphism test) than message-passing GNNs. Augmenting GNNs with TOGL leads to improved predictive performance for graph and node classification tasks, both on synthetic data sets, which can be classified by humans using their topology but not by ordinary GNNs, and on real-world data.",
    "One-sentence Summary": "We describe a new layer for graph neural networks that incorporates multi-scale (ranging from local to global) topological information."
  },
  {
    "title": "Learning Value Functions from Undirected State-only Experience",
    "url": "/forum?id=6Pe99Juo9gd",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Offline RL, Offline RL without actions",
    "Abstract": "This paper tackles the problem of learning value functions from undirected state-only experience (state transitions without action labels i.e. (s,s',r) tuples). We first theoretically characterize the applicability of Q-learning in this setting. We show that tabular Q-learning in discrete Markov decision processes (MDPs) learns the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of Latent Action Q-learning or LAQ, an offline RL method that can learn effective value functions from state-only experience. Latent Action Q-learning (LAQ) learns value functions using Q-learning on discrete latent actions obtained through a latent-variable future prediction model. We show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. Value functions learned using LAQ lead to sample efficient acquisition of goal-directed behavior, can be used with domain-specific low-level controllers, and facilitate transfer across embodiments. Our experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments demonstrate the benefits of LAQ over simpler alternatives, imitation learning oracles, and competing methods.",
    "One-sentence Summary": "We present a method for offline value learning without action labels."
  },
  {
    "title": "The Boltzmann Policy Distribution: Accounting for Systematic Suboptimality in Human Models",
    "url": "/forum?id=_l_QjPGN5ye",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "human model, boltzmann rationality, suboptimality, HRI, human-robot collaboration, generative models, reinforcement learning, deep RL",
    "Abstract": "Models of human behavior for prediction and collaboration tend to fall into two categories: ones that learn from large amounts of data via imitation learning, and ones that assume human behavior to be noisily-optimal for some reward function. The former are very useful, but only when it is possible to gather a lot of human data in the target environment and distribution. The advantage of the latter type, which includes Boltzmann rationality, is the ability to make accurate predictions in new environments without extensive data when humans are actually close to optimal. However, these models fail when humans exhibit systematic suboptimality, i.e. when their deviations from optimal behavior are not independent, but instead consistent over time. Our key insight is that systematic suboptimality can be modeled by predicting policies, which couple action choices over time, instead of trajectories. We introduce the Boltzmann policy distribution (BPD), which serves as a prior over human policies and adapts via Bayesian inference to capture systematic deviations by observing human actions during a single episode. The BPD is difficult to compute and represent because policies lie in a high-dimensional continuous space, but we leverage tools from generative and sequence modeling to enable efficient sampling and inference. We show that the BPD enables prediction of human behavior and human-AI collaboration equally as well as imitation learning-based human models while using far less data.",
    "One-sentence Summary": "We propose modeling human behavior with a Boltzmann distribution over policies\u2014not trajectories\u2014and show it is more accurate and useful."
  },
  {
    "title": "WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection",
    "url": "/forum?id=ahi2XSHpAUZ",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Computer vision, monocular 3D object detection, weakly supervised",
    "Abstract": "Monocular 3D object detection is one of the most challenging tasks in 3D scene understanding. Due to the ill-posed nature of monocular imagery, existing monocular 3D detection methods highly rely on training with the manually annotated 3D box labels on the LiDAR point clouds. This annotation process is very laborious and expensive. To dispense with the reliance on 3D box labels, in this paper we explore the weakly supervised monocular 3D detection. Specifically, we first detect 2D boxes on the image. Then, we adopt the generated 2D boxes to select corresponding RoI LiDAR points as the weak supervision. Eventually, we adopt a network to predict 3D boxes which can tightly align with associated RoI LiDAR points. This network is learned by minimizing our newly-proposed 3D alignment loss between the 3D box estimates and the corresponding RoI LiDAR points. We will illustrate the potential challenges of the above learning problem and resolve these challenges by introducing several effective designs into our method. Codes are available at https://github.com/SPengLiang/WeakM3D.",
    "One-sentence Summary": "This paper explores the weakly supervised monocular 3D detection to dispense with the reliance on 3D box labels."
  },
  {
    "title": "Exploring Memorization in Adversarial Training",
    "url": "/forum?id=7gE9V9GBZaI",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial examples, adversarial training, memorization, robust overfitting",
    "Abstract": "Deep learning models have a propensity for fitting the entire training set even with random labels, which requires memorization of every training sample. In this paper, we explore the memorization effect in adversarial training (AT) for promoting a deeper understanding of model capacity, convergence, generalization, and especially robust overfitting of the adversarially trained models. We first demonstrate that deep networks have sufficient capacity to memorize adversarial examples of training data with completely random labels, but not all AT algorithms can converge under the extreme circumstance. Our study of AT with random labels motivates further analyses on the convergence and generalization of AT. We find that some AT approaches suffer from a gradient instability issue and the recently suggested complexity measures cannot explain robust generalization by considering models trained on random labels. Furthermore, we identify a significant drawback of memorization in AT that it could result in robust overfitting. We then propose a new mitigation algorithm motivated by detailed memorization analyses. Extensive experiments on various datasets validate the effectiveness of the proposed method.",
    "One-sentence Summary": "This paper explores the memorization effect in adversarial training and analyzes its connections with model capacity, convergence, generalization, and especially robust overfitting of the adversarially trained models."
  },
  {
    "title": "Disentanglement Analysis with Partial Information Decomposition",
    "url": "/forum?id=pETy-HVvGtt",
    "date": "28 Sept 2021 (modified: 09 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "disentangled representations, variational autoencoders, deep generative models",
    "Abstract": "We propose a framework to analyze how multivariate representations disentangle ground-truth generative factors. A quantitative analysis of disentanglement has been based on metrics designed to compare how one variable explains each generative factor. Current metrics, however, may fail to detect entanglement that involves more than two variables, e.g., representations that duplicate and rotate generative factors in high dimensional spaces. In this work, we establish a framework to analyze information sharing in a multivariate representation with Partial Information Decomposition and propose a new disentanglement metric. This framework enables us to understand disentanglement in terms of uniqueness, redundancy, and synergy. We develop an experimental protocol to assess how increasingly entangled representations are evaluated with each metric and confirm that the proposed metric correctly responds to entanglement. Through experiments on variational autoencoders, we find that models with similar disentanglement scores have a variety of characteristics in entanglement, for each of which a distinct strategy may be required to obtain a disentangled representation.",
    "One-sentence Summary": "We establish a framework to analyze information sharing in a multivariate representation with Partial Information Decomposition and propose a new disentanglement metric."
  },
  {
    "title": "Differentiable Gradient Sampling for Learning Implicit 3D Scene Reconstructions from a Single Image",
    "url": "/forum?id=U8pbd00cCWB",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Implicit shape models are promising 3D representations for modeling arbitrary locations, with Signed Distance Functions (SDFs) particularly suitable for clear mesh surface reconstruction. Existing approaches for single object reconstruction impose supervision signals based on the loss of the signed distance value from all locations in a scene, posing difficulties when extending to real-world scenarios. The spatial gradient of the signed distance field, rather than the SDF value itself, has not been typically employed as a source of supervision for single-view reconstruction, in part due to the difficulties of differentiable sampling a spatial gradient from the feature map. In this study, we derive a novel closed-form gradient sampling solution for Differentialble Gradient Sampling (DGS) that enables backpropagation of the loss of the spatial gradient back to the feature map pixels, thus allowing the imposition of the loss efficiently on the spatial gradient. As a result, we achieve high-quality single view indoor scene reconstruction results learning directly from a real-world scanned dataset (e.g. ScannetV2). Our model also performs well when generalizing to unseen images downloaded directly from the internet (Fig. 1). We comfortably advanced the state-of-the-art results with several established datasets including ShapeNet and ScannetV2; extensive quantitative analysis confirmed that our proposed DGS module plays an essential role in achieving this performance improvement. Full codes are available in MaskedURL."
  },
  {
    "title": "Learning Continuous Environment Fields via Implicit Functions",
    "url": "/forum?id=3ILxkQ7yElm",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Continuous Scene Representation, Implicit Neural Networks",
    "Abstract": "We propose a novel scene representation that encodes reaching distance -- the distance between any position in the scene to a goal along a feasible trajectory. We demonstrate that this environment field representation can directly guide the dynamic behaviors of agents in 2D mazes or 3D indoor scenes. Our environment field is a continuous representation and learned via a neural implicit function using discretely sampled training data. We showcase its application for agent navigation in 2D mazes, and human trajectory prediction in 3D indoor environments. To produce physically plausible and natural trajectories for humans, we additionally learn a generative model that predicts regions where humans commonly appear, and enforce the environment field to be defined within such regions. Extensive experiments demonstrate that the proposed method can generate both feasible and plausible trajectories efficiently and accurately.",
    "One-sentence Summary": "We propose a novel scene representation that can dynamically change behaviors of agents inside the scene."
  },
  {
    "title": "Causal Contextual Bandits with Targeted Interventions",
    "url": "/forum?id=F5Em8ASCosV",
    "date": "28 Sept 2021 (modified: 06 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "causality, contextual bandits, causal inference, bandits",
    "Abstract": "We study a contextual bandit setting where the learning agent has the ability to perform interventions on targeted subsets of the population, apart from possessing qualitative causal side-information. This novel formalism captures intricacies in real-world scenarios such as software product experimentation where targeted experiments can be conducted. However, this fundamentally changes the set of options that the agent has, compared to standard contextual bandit settings, necessitating new techniques. This is also the first work that integrates causal side-information in a contextual bandit setting, where the agent aims to learn a policy that maps contexts to arms (as opposed to just identifying one best arm). We propose a new algorithm, which we show empirically performs better than baselines on experiments that use purely synthetic data and on real world-inspired experiments. We also prove a bound on regret that theoretically guards performance.",
    "One-sentence Summary": "A new, more realistic, formalism of contextual bandits involving causal side-information and targeted interventions, along with a novel algorithm that exploits features of the new setting such as information leakage to learn good policies quickly."
  },
  {
    "title": "Sound and Complete Neural Network Repair with Minimality and Locality Guarantees",
    "url": "/forum?id=xS8AMYiEav3",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Network Repair",
    "Abstract": "We present a novel methodology for repairing neural networks that use ReLU activation functions. Unlike existing methods that rely on modifying the weights of a neural network which can induce a global change in the function space, our approach applies only a localized change in the function space while still guaranteeing the removal of the buggy behavior. By leveraging the piecewise linear nature of ReLU networks, our approach can efficiently construct a patch network tailored to the linear region where the buggy input resides, which when combined with the original network, provably corrects the behavior on the buggy input. Our method is both sound and complete -- the repaired network is guaranteed to fix the buggy input, and a patch is guaranteed to be found for any buggy input. Moreover, our approach preserves the continuous piecewise linear nature of ReLU networks, automatically generalizes the repair to all the points including other undetected buggy inputs inside the repair region, is minimal in terms of changes in the function space, and guarantees that outputs on inputs away from the repair region are unaltered. On several benchmarks, we show that our approach significantly outperforms existing methods in terms of locality and limiting negative side effects."
  },
  {
    "title": "Blaschke Product Neural Networks (BPNN): A Physics-Infused Neural Network for Phase Retrieval of Meromorphic Functions",
    "url": "/forum?id=JJxiD-kg-oK",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Blaschke Product, Neural Network, Phase Retrieval, Metamaterial, Meromorphic Functions",
    "Abstract": "Numerous physical systems are described by ordinary or partial differential equations whose solutions are given by holomorphic or meromorphic functions in the complex domain. In many cases, only the magnitude of these functions are observed on various points on the purely imaginary $j\\omega$-axis since coherent measurement of their phases is often expensive.  However, it is desirable to retrieve the lost phases from the magnitudes when possible. To this end, we propose a physics-infused deep neural network based on the Blaschke products for phase retrieval. Inspired by the Helson and Sarason Theorem,  we recover coefficients of a rational function of Blaschke products using a Blaschke Product Neural Network (BPNN), based upon the magnitude observations as input. The resulting rational function is then used for phase retrieval. We compare the BPNN to conventional deep neural networks (NNs) on several phase retrieval problems, comprising both synthetic and contemporary real-world problems (e.g., metamaterials for which data collection requires substantial expertise and is time consuming). On each phase retrieval problem, we compare against a population of conventional NNs of varying size and hyperparameter settings. Even without any hyper-parameter search, we find that BPNNs consistently outperform the population of optimized NNs in scarce data scenarios, and do so despite being much smaller models. The results can in turn be applied to calculate the refractive index of metamaterials, which is an important problem in emerging areas of material science."
  },
  {
    "title": "Automated Self-Supervised Learning for Graphs",
    "url": "/forum?id=rFbR4Fv-D6-",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-supervised learning, Graph neural networks, AutoML",
    "Abstract": "Graph self-supervised learning has gained increasing attention due to its capacity to learn expressive node representations. Many pretext tasks, or loss functions have been designed from distinct perspectives. However, we observe that different pretext tasks affect downstream tasks differently cross datasets, which suggests that searching pretext tasks is crucial for graph self-supervised learning.  Different from existing works focusing on designing single pretext tasks, this work aims to investigate how to automatically leverage multiple pretext tasks effectively. Nevertheless, evaluating representations derived from multiple pretext tasks without direct access to ground truth labels makes this problem challenging. To address this obstacle, we make use of a key principle of many real-world graphs, i.e., homophily, or the principle that ``like attracts like,'' as the guidance to effectively search various self-supervised pretext tasks. We provide theoretical understanding and empirical evidence to justify the flexibility of homophily in this  search task. Then we propose the AutoSSL framework which can automatically search over combinations of various self-supervised tasks. By evaluating the framework on 7 real-world datasets, our experimental results show that AutoSSL can significantly boost the performance on downstream tasks including node clustering and node classification compared with training under individual tasks.",
    "One-sentence Summary": "An automated self-supervised learning algorithm for graph neural networks."
  },
  {
    "title": "Creating Training Sets via Weak Indirect Supervision",
    "url": "/forum?id=m8uJvVgwRci",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "weak supervision, data programming, training label synthesis",
    "Abstract": "Creating labeled training sets has become one of the major roadblocks in machine learning. To address this, recent Weak Supervision (WS) frameworks synthesize training labels from multiple potentially noisy supervision sources. However, existing frameworks are restricted to supervision sources that share the same output space as the target task. To extend the scope of usable sources, we formulate Weak Indirect Supervision (WIS), a new research problem for automatically synthesizing training labels based on indirect supervision sources that have different output label spaces. To overcome the challenge of mismatched output spaces, we develop a probabilistic modeling approach, PLRM, which uses user-provided label relations to model and leverage indirect supervision sources. Moreover, we provide a theoretically-principled test of the distinguishability of PLRM for unseen labels, along with an generalization bound. On both image and text classification tasks as well as an industrial advertising application, we demonstrate the advantages of PLRM by outperforming baselines by a margin of 2%-9%.",
    "One-sentence Summary": "In this work, we present a new weak supervision paradigm which automatically creates training sets for training a machine learning model given unlabeled dataset and indirect supervision sources."
  },
  {
    "title": "Do Not Escape From the Manifold: Discovering the Local Coordinates on the Latent Space of GANs",
    "url": "/forum?id=aTzMi4yV_RO",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "generative adversarial network, disentanglement, semantic factorization, latent space control, image manipulation, grassmannian",
    "Abstract": "The discovery of the disentanglement properties of the latent space in GANs motivated a lot of research to find the semantically meaningful directions on it. In this paper, we suggest that the disentanglement property is closely related to the geometry of the latent space. In this regard, we propose an unsupervised method for finding the semantic-factorizing directions on the intermediate latent space of GANs based on the local geometry. Intuitively, our proposed method, called $\\textit{Local Basis}$, finds the principal variation of the latent space in the neighborhood of the base latent variable. Experimental results show that the local principal variation corresponds to the semantic factorization and traversing along it provides strong robustness to image traversal. Moreover, we suggest an explanation for the limited success in finding the global traversal directions in the latent space, especially $\\mathcal{W}$-space of StyleGAN2. We show that $\\mathcal{W}$-space is warped globally by comparing the local geometry, discovered from Local Basis, through the metric on Grassmannian Manifold. The global warpage implies that the latent space is not well-aligned globally and therefore the global traversal directions are bound to show limited success on it.",
    "One-sentence Summary": "We propose a method for finding local-geometry-aware traversal directions on the intermediate latent space of Generative Adversarial Networks (GANs)."
  },
  {
    "title": "GradSign: Model Performance Inference with Theoretical Insights",
    "url": "/forum?id=HObMhrCeAAF",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Model Performance Inference, Optimization Landscape, NAS",
    "Abstract": "A key challenge in neural architecture search (NAS) is quickly inferring the predictive performance of a broad spectrum of networks to discover statistically accurate and computationally efficient ones.  We refer to this task as model performance inference (MPI). The current practice for efficient MPI is gradient-based methods that leverage the gradients of a network at initialization to infer its performance. However, existing gradient-based methods rely only on heuristic metrics and lack the necessary theoretical foundations to consolidate their designs.  We propose GradSign, an accurate, simple, and flexible metric for model performance inference with theoretical insights. The key idea behind GradSign is a quantity \u03a8 to analyze the sample-wise optimization landscape of different networks. Theoretically, we show that  \u03a8 is an upper bound for both the training and true population losses of a neural network under reasonable assumptions. However, it is computationally prohibitive to directly calculate \u03a8 for modern neural networks. To\n        address this challenge, we design GradSign, an accurate and simple approximation of \u03a8 using the gradients of a network evaluated at a random initialization state. Evaluation on seven NAS benchmarks across three training datasets shows that GradSign generalizes well to real-world networks and consistently outperforms state-of-the-art gradient-based methods for MPI evaluated by Spearman\u2019s \u03c1 and Kendall\u2019s Tau.  Additionally, we integrate GradSign into four existing NAS algorithms and show that the GradSign-assisted NAS algorithms outperform their vanilla counterparts by improving the accuracies of best-discovered networks by up to 0.3%, 1.1%, and 1.0% on three real-world tasks. Code is available at https://github.com/JackFram/GradSign",
    "One-sentence Summary": "Model performance inference inspired by sample-wise optimization landscape analysis"
  },
  {
    "title": "You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks",
    "url": "/forum?id=hpBTIv2uy_E",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Hypergraph neural networks, multiset functions, deep sets, set transformer",
    "Abstract": "Hypergraphs are used to model higher-order interactions amongst agents and there exist many practically relevant instances of hypergraph datasets. To enable the efficient processing of hypergraph data, several hypergraph neural network platforms have been proposed for learning hypergraph properties and structure, with a special focus on node classification tasks. However, almost all existing methods use heuristic propagation rules and offer suboptimal performance on benchmarking datasets. We propose AllSet, a new hypergraph neural network paradigm that represents a highly general framework for (hyper)graph neural networks and for the first time implements hypergraph neural network layers as compositions of two multiset functions that can be efficiently learned for each task and each dataset. The proposed AllSet framework also for the first time integrates Deep Sets and Set Transformers with hypergraph neural networks for the purpose of learning multiset functions and therefore allows for significant modeling flexibility and high expressive power. To evaluate the performance of AllSet, we conduct the most extensive experiments to date involving ten known benchmarking datasets and three newly curated datasets that represent significant challenges for hypergraph node classification. The results demonstrate that our method has the unique ability to either match or outperform all other hypergraph neural networks across the tested datasets: As an example, the performance improvements over existing methods and a new method based on heterogeneous graph neural networks are close to $4\\%$ on the Yelp and Zoo datasets, and $3\\%$ on the Walmart dataset.",
    "One-sentence Summary": "We propose a multiset function framework for hypergraph neural networks."
  },
  {
    "title": "Synchromesh: Reliable Code Generation from Pre-trained Language Models",
    "url": "/forum?id=KmtVD97J43e",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "program synthesis, language models, code generation",
    "Abstract": "Large pre-trained language models have been used to generate code, providing a flexible interface for synthesizing programs from natural language specifications. However, they often violate syntactic and semantic rules of their output language, limiting their practical usability. In this paper, we propose Synchromesh: a framework for substantially improving the reliability of pre-trained models for code generation. Synchromesh comprises two components. First, it retrieves few-shot examples from a training bank using Target Similarity Tuning (TST), a novel method for semantic example selection. TST learns to recognize utterances that describe similar target programs despite of differences in surface natural language features. Then, Synchromesh feeds the examples to a pre-trained language model and samples programs using Constrained Semantic Decoding (CSD): a general framework for constraining the output to a set of valid programs in the target language. CSD leverages constraints on partial outputs to sample complete correct programs, and needs neither re-training nor fine-tuning of the language model. We evaluate our methods by synthesizing code from natural language descriptions using GPT-3 and Codex in three real-world languages: SQL queries, Vega-Lite visualizations and SMCalFlow programs. These domains showcase rich constraints that CSD is able to enforce, including syntax, scoping and typing rules. Across all languages, we observe complementary gains from CSD and TST in prediction accuracy and in effectively preventing parsing, type and run-time errors.",
    "One-sentence Summary": "A framework to generate programs from large pre-trained language models (e.g. GPT-3, Codex) while satisfying syntactic and semantic constraints."
  },
  {
    "title": "Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting",
    "url": "/forum?id=tFgdrQbbaa",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "continual learning, neural tangent kernel, statistical mechanics",
    "Abstract": "Sequential training from task to task is becoming one of the major objects in deep learning applications such as continual learning and transfer learning. Nevertheless, it remains unclear under what conditions the trained model's performance improves or deteriorates. To deepen our understanding of sequential training, this study provides a theoretical analysis of generalization performance in a solvable case of continual learning.  We consider neural networks in the neural tangent kernel (NTK) regime that continually learn target functions from task to task, and investigate the generalization by using an established statistical mechanical analysis of kernel ridge-less regression. We first show characteristic transitions from positive to negative transfer. More similar targets above a specific critical value can achieve positive knowledge transfer for the subsequent task while catastrophic forgetting occurs even with very similar targets. Next, we investigate a variant of continual learning which supposes the same target function in multiple tasks. Even for the same target,  the trained model shows some transfer and forgetting depending on the sample size of each task.  We can guarantee that the generalization error monotonically decreases from task to task for equal sample sizes while unbalanced sample sizes  deteriorate the generalization. We respectively refer to these improvement and deterioration as self-knowledge transfer and forgetting, and empirically confirm them in realistic training of deep neural networks as well.",
    "One-sentence Summary": "We analyze the generalization performance of continual learning in the NTK regime and identify key properties of knowledge transfer and forgetting."
  },
  {
    "title": "Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning",
    "url": "/forum?id=xLfAgCroImw",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Valuation problems, Shapley value, Model interpretation, Data valuation, Enegy-based learning, Attribution-based feature interpretation, Model valuation for ensembles, Feature attributions",
    "Abstract": "Valuation problems, such as feature interpretation, data valuation and model valuation for ensembles, become increasingly more important in many machine learning applications. Such problems are commonly solved by well-known game-theoretic criteria, such as Shapley value or Banzhaf value. In this work, we present a novel energy-based treatment for cooperative games, with a theoretical justification by the maximum entropy framework. Surprisingly, by conducting variational inference of the energy-based model, we recover various game-theoretic valuation criteria through conducting one-step fixed point iteration  for maximizing the mean-field ELBO objective. This observation also verifies the rationality of existing criteria, as they are all attempting to  decouple the  correlations  among  the  players  through the  mean-field approach. By running fixed point iteration for multiple steps, we achieve a trajectory of the valuations, among which we define the valuation with the best conceivable decoupling error as the Variational Index. We prove that under uniform initializations,  these variational valuations all satisfy a set of game-theoretic axioms. We experimentally demonstrate that the proposed Variational Index enjoys lower decoupling error and better valuation performance  on certain synthetic and real-world valuation problems.",
    "One-sentence Summary": "An energy-based treatment for cooperative games provides a decoupling perspective for Shapley value and others."
  },
  {
    "title": "Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage",
    "url": "/forum?id=tyrJsbKAe6",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement learning Theory, Offline reinforcement learning, PAC Bounds",
    "Abstract": "We study model-based offline Reinforcement Learning with general function approximation without a full coverage assumption on the offline data distribution. We present an algorithm named Constrained Pessimistic Policy Optimization (CPPO) which leverages a general function class and uses a constraint over the models to encode pessimism. Under the assumption that the ground truth model belongs to our function class (i.e., realizability in the function class), CPPO has a PAC guarantee with offline data only providing partial coverage, i.e., it can learn a policy that competes against any policy covered by the offline data. We then demonstrate that this algorithmic framework can be applied to many specialized Markov Decision Processes where the additional structural assumptions can further refine the concept of partial coverage. Two notable examples are: (1) low- rank MDP with representation learning where the partial coverage condition is defined using a relative condition number measured by the unknown ground truth feature representation; (2) factored MDP where the partial coverage condition is defined using density-ratio based concentrability coefficients associated with individual factors.",
    "One-sentence Summary": "We study model-based offline Reinforcement Learning with general function approximation without a full coverage assumption on the offline data distribution."
  },
  {
    "title": "Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods",
    "url": "/forum?id=1ugNpm7W6E",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Cold Start, Knowledge Distillation",
    "Abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in node classification, regression, and recommendation tasks. GNNs work well when rich and high-quality connections are available. However, their effectiveness is often jeopardized in many real-world graphs in which node degrees have power-law distributions. The extreme case of this situation, where a node may have no neighbors, is called Strict Cold Start (SCS). SCS forces the prediction to rely completely on the node's own features. We propose Cold Brew, a teacher-student distillation approach to address the SCS and noisy-neighbor challenges for GNNs. We also introduce feature contribution ratio (FCR), a metric to quantify the behavior of inductive GNNs to solve SCS. We experimentally show that FCR disentangles the contributions of different graph data components and helps select the best architecture for SCS generalization. We further demonstrate the superior performance of Cold Brew on several public benchmark and proprietary e-commerce datasets, where many nodes have either very few or noisy connections. Our source code is available at https://github.com/amazon-research/gnn-tail-generalization.",
    "One-sentence Summary": "Improve strict cold start performances for graph minings with a knowledge distillation framework."
  },
  {
    "title": "NASI: Label- and Data-agnostic Neural Architecture Search at Initialization",
    "url": "/forum?id=v-v1cpNNK_v",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Architecture Search, Initialization, Label- and Data-agnostic, Transferability, Neural Tangent Kernel",
    "Abstract": "Recent years have witnessed a surging interest in Neural Architecture Search (NAS). Various algorithms have been proposed to improve the search efficiency and effectiveness of NAS, i.e., to reduce the search cost and improve the generalization performance of the selected architectures, respectively. However, the search efficiency of these algorithms is severely limited by the need for model training during the search process. To overcome this limitation, we propose a novel NAS algorithm called NAS at Initialization (NASI) that exploits the capability of a Neural Tangent Kernel in being able to characterize the performance of candidate architectures at initialization, hence allowing model training to be completely avoided to boost the search efficiency. Besides the improved search efficiency, NASI also achieves competitive search effectiveness on various datasets like CIFAR-10/100 and ImageNet. Further, NASI is shown to be label- and data-agnostic under mild conditions, which guarantees the transferability of architectures selected by our NASI over different datasets."
  },
  {
    "title": "How to Train Your MAML to Excel in Few-Shot Classification",
    "url": "/forum?id=49h_IkpJtaE",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "meta-learning, few-shot learning, classification, MAML",
    "Abstract": "Model-agnostic meta-learning (MAML) is arguably one of the most popular meta-learning algorithms nowadays.\n        Nevertheless, its performance on few-shot classification is far behind many recent algorithms dedicated to the problem. In this paper, we point out several key facets of how to train MAML to excel in few-shot classification. First, we find that MAML needs a large number of gradient steps in its inner loop update, which contradicts its common usage in few-shot classification. Second, we find that MAML is sensitive to the class label assignments during meta-testing. Concretely, MAML meta-trains the initialization of an $N$-way classifier. These $N$ ways, during meta-testing, then have \"$N!$\" different permutations to be paired with a few-shot task of $N$ novel classes. We find that these permutations lead to a huge variance of accuracy, making MAML unstable in few-shot classification. Third, we investigate several approaches to make MAML permutation-invariant, among which meta-training a single vector to initialize all the $N$ weight vectors in the classification head performs the best. On benchmark datasets like MiniImageNet and TieredImageNet, our approach, which we name UNICORN-MAML, performs on a par with or even outperforms many recent few-shot classification algorithms, without sacrificing MAML's simplicity."
  },
  {
    "title": "Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games",
    "url": "/forum?id=xy_2w3J3kH",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multi-agent reinforcement learning, multi-agent communication",
    "Abstract": "Recent success in cooperative multi-agent reinforcement learning (MARL) relies on centralized training and policy sharing. Centralized training eliminates the issue of non-stationarity MARL yet induces large communication costs, and policy sharing is empirically crucial to efficient learning in certain tasks yet lacks theoretical justification. In this paper, we formally characterize a subclass of cooperative Markov games where agents exhibit a certain form of homogeneity such that policy sharing provably incurs no suboptimality. This enables us to develop the first consensus-based decentralized actor-critic method where the consensus update is applied to both the actors and the critics while ensuring convergence. We also develop practical algorithms based on our decentralized actor-critic method to reduce the communication cost during training, while still yielding policies comparable with centralized training."
  },
  {
    "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer",
    "url": "/forum?id=vh-0sUt8HlG",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Vision transformer, Mobile, Edge Devices, Transformer, CNN, Efficient Network, Detection, Segmentation, ImageNet",
    "Abstract": "Light-weight convolutional neural networks (CNNs) are the de-facto for mobile vision tasks. Their spatial inductive biases allow them to learn representations with fewer parameters across different vision tasks. However, these networks are spatially local. To learn global representations, self-attention-based vision trans-formers (ViTs) have been adopted. Unlike CNNs, ViTs are heavy-weight. In this paper, we ask the following question: is it possible to combine the strengths of CNNs and ViTs to build a light-weight and low latency network for mobile vision tasks? Towards this end, we introduce MobileViT, a light-weight and general-purpose vision transformer for mobile devices. MobileViT presents a different perspective for the global processing of information with transformers, i.e., transformers as convolutions. Our results show that MobileViT significantly outperforms CNN- and ViT-based networks across different tasks and datasets. On the ImageNet-1k dataset, MobileViT achieves top-1 accuracy of 78.4% with about 6 million parameters, which is 3.2% and 6.2% more accurate than MobileNetv3 (CNN-based) and DeIT (ViT-based) for a similar number of parameters. On the MS-COCO object detection task, MobileViT is 5.7% more accurate than MobileNetv3 for a similar number of parameters. \n        \n        Our source code is open-source and available at: https://github.com/apple/ml-cvnets",
    "One-sentence Summary": "Light-weight and general-purpose vision transformers for mobile devices"
  },
  {
    "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery",
    "url": "/forum?id=kavTY__jxp",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, graph neural network, molecule generation, drug discovery, curiosity-driven policy",
    "Abstract": "We developed Distilled Graph Attention Policy Network (DGAPN), a reinforcement learning model to generate novel graph-structured chemical representations that optimize user-defined objectives by efficiently navigating a physically constrained domain. The framework is examined on the task of generating molecules that are designed to bind, noncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial Graph Attention (sGAT) mechanism that leverages self-attention over both node and edge attributes as well as encoding the spatial structure --- this capability is of considerable interest in synthetic biology and drug discovery. An attentional policy network is introduced to learn the decision rules for a dynamic, fragment-based chemical environment, and state-of-the-art policy gradient techniques are employed to train the network with stability. Exploration is driven by the stochasticity of the action space design and the innovation reward bonuses learned and proposed by random network distillation. In experiments, our framework achieved outstanding results compared to state-of-the-art algorithms, while reducing the complexity of paths to chemical synthesis.",
    "One-sentence Summary": "We developed a reinforcement learning framework that advances in exploiting spatial and attributional molecular information as well as exploring novel and synthesizable chemical structures for the purpose of antiviral drug discovery."
  },
  {
    "title": "Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks",
    "url": "/forum?id=OnpFa95RVqs",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural architecture search, AutoML, benchmarking, surrogate model",
    "Abstract": "The most significant barrier to the advancement of Neural Architecture Search (NAS) is its demand for large computational resources, which hinders scientifically sound empirical evaluations of NAS methods. Tabular NAS benchmarks have alleviated this problem substantially, making it possible to properly evaluate NAS methods in seconds on commodity machines. However, an unintended consequence of tabular NAS benchmarks has been a focus on extremely small architectural search spaces since their construction relies on exhaustive evaluations of the space. This leads to unrealistic results that do not transfer to larger spaces. To overcome this fundamental limitation, we propose a methodology to create cheap NAS surrogate benchmarks for arbitrary search spaces. We exemplify this approach by creating surrogate NAS benchmarks on the existing tabular NAS-Bench-101 and on two widely used NAS search spaces with up to $10^{21}$ architectures ($10^{13}$ times larger than any previous tabular NAS benchmark). We show that surrogate NAS benchmarks can model the true performance of architectures better than tabular benchmarks (at a small fraction of the cost), that they lead to faithful estimates of how well different NAS methods work on the original non-surrogate benchmark, and that they can generate new scientific insight. We open-source all our code and believe that surrogate NAS benchmarks are an indispensable tool to extend scientifically sound work on NAS to large and exciting search spaces.",
    "One-sentence Summary": "We present surrogate benchmarks for neural architecture search and a general methodology for constructing them."
  },
  {
    "title": "Certified Robustness for Deep Equilibrium Models via Interval Bound Propagation",
    "url": "/forum?id=y1PXylgrXZ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep equilibrium models, certified robustness, interval bound propagation",
    "Abstract": "Deep equilibrium layers (DEQs) have demonstrated promising performance and are competitive with standard explicit models on many benchmarks. However, little is known about certifying robustness for these models. Inspired by interval bound propagation (IBP), we propose the IBP-MonDEQ layer, a DEQ layer whose robustness can be verified by computing upper and lower interval bounds on the output. Our key insights are that these interval bounds can be obtained as the fixed-point solution to an IBP-inspired equilibrium equation, and furthermore, that this solution always exists and is unique when the layer obeys a certain parameterization. This fixed point can be interpreted as the result of applying IBP to an infinitely deep, weight-tied neural network, which may be of independent interest, as IBP bounds are typically unstable for deeper networks. Our empirical comparison reveals that models with IBP-MonDEQ layers can achieve comparable $\\ell_{\\infty}$ certified robustness to similarly-sized fully explicit networks.",
    "One-sentence Summary": "To develop certifiably robust deep equilibrium (DEQ) models, we propose the IBP-MonDEQ layer, a DEQ layer where interval bounds on the output can be obtained by solving an additional fixed-point equation inspired by interval bound propagation."
  },
  {
    "title": "Crystal Diffusion Variational Autoencoder for Periodic Material Generation",
    "url": "/forum?id=03RLpj-tc_",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "materials, graph neural networks, periodic, diffusion models, score matching, molecule, 3D, generative",
    "Abstract": "Generating the periodic structure of stable materials is a long-standing challenge for the material design community. This task is difficult because stable materials only exist in a low-dimensional subspace of all possible periodic arrangements of atoms: 1) the coordinates must lie in the local energy minimum defined by quantum mechanics, and 2) global stability also requires the structure to follow the complex, yet specific bonding preferences between different atom types. Existing methods fail to incorporate these factors and often lack proper invariances. We propose a Crystal Diffusion Variational Autoencoder (CDVAE) that captures the physical inductive bias of material stability. By learning from the data distribution of stable materials, the decoder generates materials in a diffusion process that moves atomic coordinates towards a lower energy state and updates atom types to satisfy bonding preferences between neighbors. Our model also explicitly encodes interactions across periodic boundaries and respects permutation, translation, rotation, and periodic invariances. We significantly outperform past methods in three tasks: 1) reconstructing the input structure, 2) generating valid, diverse, and realistic materials, and 3) generating materials that optimize a specific property. We also provide several standard datasets and evaluation metrics for the broader machine learning community.",
    "One-sentence Summary": "A generative model for the 3D periodic structure of materials"
  },
  {
    "title": "Task Affinity with Maximum Bipartite Matching in Few-Shot Learning",
    "url": "/forum?id=u2GZOiUTbt",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Task Affinity, Transfer Learning, Few-Shot Learning",
    "Abstract": "We propose an asymmetric affinity score for representing the complexity of utilizing the knowledge of one task for learning another one. Our method is based on the maximum bipartite matching algorithm and utilizes the Fisher Information matrix. We provide theoretical analyses demonstrating that the proposed score is mathematically well-defined, and subsequently use the affinity score to propose a novel algorithm for the few-shot learning problem. In particular, using this score, we find relevant training data labels to the test data and leverage the discovered relevant data for episodically fine-tuning a few-shot model. Results on various few-shot benchmark datasets demonstrate the efficacy of the proposed approach by improving the classification accuracy over the state-of-the-art methods even when using smaller models.",
    "One-sentence Summary": "Task affinity and its application in few-shot learning"
  },
  {
    "title": "Latent Image Animator: Learning to Animate Images via Latent Space Navigation",
    "url": "/forum?id=7r6kDq0mK_",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Video generation, Generative Adversarial Network",
    "Abstract": "Due to the remarkable progress of deep generative models, animating images has become increasingly efficient, whereas associated results have become increasingly realistic. Current animation-approaches commonly exploit structure representation extracted from driving videos. Such structure representation is instrumental in transferring motion from driving videos to still images. However, such approaches fail in case the source image and driving video encompass large appearance variation. Moreover, the extraction of structure information requires additional modules that endow the animation-model with increased complexity. Deviating from such models, we here introduce the Latent Image Animator (LIA), a self-supervised autoencoder that evades need for structure representation. LIA is streamlined to animate images by linear navigation in the latent space. Specifically, motion in generated video is constructed by linear displacement of codes in the latent space. Towards this, we learn a set of orthogonal motion directions simultaneously, and use their linear combination, in order to represent any displacement in the latent space. Extensive quantitative and qualitative analysis suggests that our model systematically and significantly outperforms state-of-art methods on VoxCeleb, Taichi and TED-talk datasets w.r.t. generated quality.",
    "One-sentence Summary": "Image animation via latent space navigation"
  },
  {
    "title": "Know Thyself: Transferable Visual Control Policies Through Robot-Awareness",
    "url": "/forum?id=o0ehFykKVtr",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "visual foresight, dynamics models, visuomotor control, video prediction, planning, transfer",
    "Abstract": "Training visual control policies from scratch on a new robot typically requires generating large amounts of robot-specific data. How might we leverage data previously collected on another robot to reduce or even completely remove this need for robot-specific data? We propose a \"robot-aware control\" paradigm that achieves this by exploiting readily available knowledge about the robot. We then instantiate this in a robot-aware model-based RL policy by training modular dynamics models that couple a transferable, robot-aware world dynamics module with a robot-specific, potentially analytical, robot dynamics module. This also enables us to set up visual planning costs that separately consider the robot agent and the world. Our experiments on tabletop manipulation tasks with simulated and real robots demonstrate that these plug-in improvements dramatically boost the transferability of visual model-based RL policies, even permitting zero-shot transfer of visual manipulation skills onto new robots. Project website: https://www.seas.upenn.edu/~hued/rac",
    "One-sentence Summary": "We closely integrate readily available knowledge about the robot and world into a learned model to facilitate transfer."
  },
  {
    "title": "Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction",
    "url": "/forum?id=KJggliHbs8",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-supervised learning, Graph Neural Networks, Extreme multi-label classification",
    "Abstract": "Learning on graphs has attracted significant attention in the learning community due to numerous real-world applications. In particular, graph neural networks (GNNs), which take \\emph{numerical} node features and graph structure as inputs, have been shown to achieve state-of-the-art performance on various graph-related learning tasks. Recent works exploring the correlation between numerical node features and graph structure via self-supervised learning have paved the way for further performance improvements of GNNs. However, methods used for extracting numerical node features from \\emph{raw data} are still \\emph{graph-agnostic} within standard GNN pipelines. This practice is sub-optimal as it prevents one from fully utilizing potential correlations between graph topology and node attributes. To mitigate this issue, we propose a new self-supervised learning framework, Graph Information Aided Node feature exTraction (GIANT). GIANT makes use of the eXtreme Multi-label Classification (XMC) formalism, which is crucial for fine-tuning the language model based on graph information, and scales to large datasets. We also provide a theoretical analysis that justifies the use of XMC over link prediction and motivates integrating XR-Transformers, a powerful method for solving XMC problems, into the GIANT framework. We demonstrate the superior performance of GIANT over the standard GNN pipeline on Open Graph Benchmark datasets: For example, we improve the accuracy of the top-ranked method GAMLP from $68.25\\%$ to $69.67\\%$, SGC from $63.29\\%$ to $66.10\\%$ and MLP from $47.24\\%$ to $61.10\\%$ on the ogbn-papers100M dataset by leveraging GIANT.",
    "One-sentence Summary": "We design a self-supervised learning method for extracting node representations from raw data."
  },
  {
    "title": "Spherical Message Passing for 3D Molecular Graphs",
    "url": "/forum?id=givsRXsOt9r",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "We consider representation learning of 3D molecular graphs in which each atom is associated with a spatial position in 3D. This is an under-explored area of research, and a principled message passing framework is currently lacking. In this work, we conduct analyses in the spherical coordinate system (SCS) for the complete identification of 3D graph structures. Based on such observations, we propose the spherical message passing (SMP) as a novel and powerful scheme for 3D molecular learning. SMP dramatically reduces training complexity, enabling it to perform efficiently on large-scale molecules. In addition, SMP is capable of distinguishing almost all molecular structures, and the uncovered cases may not exist in practice. Based on meaningful physically-based representations of 3D information, we further propose the SphereNet for 3D molecular learning. Experimental results demonstrate that the use of meaningful 3D information in SphereNet leads to significant performance improvements in prediction tasks. Our results also demonstrate the advantages of SphereNet in terms of capability, efficiency, and scalability."
  },
  {
    "title": "Fairness Guarantees under Demographic Shift",
    "url": "/forum?id=wbPObLm6ueA",
    "date": "28 Sept 2021 (modified: 18 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Fairness and Bias in Artificial Intelligence, Machine Learning",
    "Abstract": "Recent studies have demonstrated that using machine learning for social applications can lead to injustice in the form of racist, sexist, and otherwise unfair and discriminatory outcomes. To address this challenge, recent machine learning algorithms have been designed to limit the likelihood such unfair behaviors will occur. However, these approaches typically assume the data used for training is representative of what will be encountered once the model is deployed, thus limiting their usefulness. In particular, if certain subgroups of the population become more or less probable after the model is deployed (a phenomenon we call demographic shift), the fair-ness assurances provided by prior algorithms are often invalid. We consider the impact of demographic shift and present a class of algorithms, called Shifty algorithms, that provide high-confidence behavioral guarantees that hold under demographic shift. Shifty is the first technique of its kind and demonstrates an effective strategy for designing algorithms to overcome the challenges demographic shift poses. We evaluate Shifty-ttest, an implementation of Shifty based on Student\u2019s \ud835\udc61-test, and, using a real-world data set of university entrance exams and subsequent student success, show that the models output by our algorithm avoid unfair bias under demo-graphic shift, unlike existing methods. Our experiments demonstrate that our algorithm\u2019s high-confidence fairness guarantees are valid in practice and that our algorithm is an effective tool for training models that are fair when demographic shift occurs.",
    "One-sentence Summary": "We propose a strategy for designing classification algorithms that provide high-confidence fairness guarantees that remain valid if the distribution over observations changes after the trained model is deployed."
  },
  {
    "title": "Fooling Explanations in Text Classifiers",
    "url": "/forum?id=j3krplz_4w6",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "robustness, explainability, text classification, natural language processing",
    "Abstract": "State-of-the-art text classification models are becoming increasingly reliant on deep neural networks (DNNs). Due to their black-box nature, faithful and robust explanation methods need to accompany classifiers for deployment in real-life scenarios. However, it has been shown that explanation methods in vision applications are susceptible to local, imperceptible perturbations that can significantly alter the explanations without changing the predicted classes. We show here that the existence of such perturbations extends to text classifiers as well. Specifically, we introduce TextExplanationFooler (TEF), a novel explanation attack algorithm that alters text input samples imperceptibly so that the outcome of widely-used explanation methods changes considerably while leaving classifier predictions unchanged. We evaluate the attribution robustness estimation performance of TEF on five text classification datasets, utilizing three DNN architectures and a transformer architecture for each dataset. By significantly decreasing the correlation between unchanged and perturbed input attributions, we show that all models and explanation methods are susceptible to TEF perturbations. Moreover, we evaluate how the perturbations transfer to other model architectures and attribution methods, finding better than random performance in scenarios where the exact attacked model and explanation method are unknown. Finally, we introduce a semi-universal attack that is able to compute fast, computationally light perturbations with no knowledge of the attacked classifier nor explanation method. Overall, our work shows that explanations in text classifiers are fragile and users need to carefully address their robustness before relying on them in critical applications.",
    "One-sentence Summary": "Our work shows that explanation methods in text classifiers are susceptible to imperceptible perturbations that alter the explanation outcomes without changing the predictions of the classifiers."
  },
  {
    "title": "On the Learning and Learnability of Quasimetrics",
    "url": "/forum?id=y0VvIg25yk",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "embedding learning, quasimetric learning, deep learning",
    "Abstract": "Our world is full of asymmetries. Gravity and wind can make reaching a place easier than coming back. Social artifacts such as genealogy charts and citation graphs are inherently directed. In reinforcement learning and control, optimal goal-reaching strategies are rarely reversible (symmetrical). Distance functions supported on these asymmetrical structures are called quasimetrics. Despite their common appearance, little research has been done on the learning of quasimetrics. Our theoretical analysis reveals that a common class of learning algorithms, including unconstrained multilayer perceptrons (MLPs), provably fails to learn a quasimetric consistent with training data. In contrast, our proposed Poisson Quasimetric Embedding (PQE) is the first quasimetric learning formulation that both is learnable with gradient-based optimization and enjoys strong performance guarantees. Experiments on random graphs, social graphs, and offline Q-learning demonstrate its effectiveness over many common baselines.",
    "One-sentence Summary": "We theoretically analyze various algorithms on learning quasimetrics (asymmetrical metrics), and propose an embedding-based method with strong guarantees. Experiments on graph learning and Q-learning show its effectiveness over common baselines."
  },
  {
    "title": "Learning Prototype-oriented Set Representations for Meta-Learning",
    "url": "/forum?id=WH6u2SvlLp4",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Summary Networks, Distribution Matching, Optimal Transport, Few-shot Classification, Meta Generative Models",
    "Abstract": "Learning from set-structured data is a fundamental problem that has recently attracted increasing attention, where a series of summary networks are introduced to deal with the set input. In fact, many meta-learning problems can be treated as set-input tasks. Most existing summary networks aim to design different architectures for the input set in order to enforce permutation invariance. However, scant attention has been paid to the common cases where different sets in a meta distribution are closely related and share certain statistical properties. Viewing each set as a distribution over a set of global prototypes, this paper provides a novel prototype-oriented optimal transport (POT) framework to improve existing summary networks. To learn the distribution over the global prototypes, we minimize its regularized optimal transport distance to the set empirical distribution over data points, providing a natural unsupervised way to improve the summary network. Since our plug-and-play framework can be applied to many meta learning problems, we further instantiate it to the cases of few-shot classification and implicit meta generative modeling. Extensive experiments demonstrate that our framework significantly improves the existing summary networks on learning more powerful summary statistics from sets and can be successfully integrated into metric-based few-shot classification and generative modeling applications, providing a promising tool for addressing set-input and meta-learning problems.",
    "One-sentence Summary": "A plug-and-play framework for set-structured input tasks"
  },
  {
    "title": "Embedded-model flows: Combining the inductive biases of model-free deep learning and explicit probabilistic modeling",
    "url": "/forum?id=9pEJSVfDbba",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Normalizing Flows, Probabilistic model, Probabilistic programming, Generative modeling, Variational Inference",
    "Abstract": "Normalizing flows have shown great success as general-purpose density estimators. However, many real world applications require the use of domain-specific knowledge, which normalizing flows cannot readily incorporate. We propose embedded-model flows (EMF), which alternate general-purpose transformations with structured layers that embed domain-specific inductive biases. These layers are automatically constructed by converting user-specified differentiable probabilistic models into equivalent bijective transformations. We also introduce gated structured layers, which allow bypassing the parts of the models that fail to capture the statistics of the data. We demonstrate that EMFs can be used to induce desirable properties such as multimodality and continuity. Furthermore, we show that EMFs enable a high performance form of variational inference where the structure of the prior model is embedded in the variational architecture. In our experiments, we show that this approach outperforms a large number of alternative methods in common structured inference problems.",
    "One-sentence Summary": "We introduce bijective transformations that embed domain-specific inductive biases in Normalizing Flow architectures."
  },
  {
    "title": "A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning",
    "url": "/forum?id=YRq0ZUnzKoZ",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Model-Based Reinforcement Learning, Unsupervised Dynamics Generalization",
    "Abstract": "The generalization of model-based reinforcement learning (MBRL) methods to environments with unseen transition dynamics is an important yet challenging problem.\n        Existing methods try to extract environment-specified information $Z$ from past transition segments to make the dynamics prediction model generalizable to different dynamics. However, because environments are not labelled, the extracted information inevitably contains redundant information unrelated to the dynamics in transition segments and thus fails to maintain a crucial property of $Z$: $Z$ should be similar in the same environment and dissimilar in different ones. As a result, the learned dynamics prediction function will deviate from the true one, which undermines the generalization ability. To tackle this problem, we introduce an interventional prediction module to estimate the probability of two estimated $\\hat{z}_i, \\hat{z}_j$ belonging to the same environment.\n        Furthermore, by utilizing the $Z$'s invariance within a single environment, a relational head is proposed to enforce the similarity between $\\hat{{Z}}$ from the same environment. As a result, the redundant information will be reduced in $\\hat{Z}$. We empirically show that $\\hat{{Z}}$ estimated by our method enjoy less redundant information than previous methods, and such $\\hat{{Z}}$  can significantly reduce dynamics prediction errors and improve the performance of model-based RL methods on zero-shot new environments with unseen dynamics. The codes of this method are available at \\url{https://github.com/CR-Gjx/RIA}.",
    "One-sentence Summary": "This paper proposes a new model-based RL that could generalize to new environments."
  },
  {
    "title": "Critical Points in Quantum Generative Models",
    "url": "/forum?id=2f1z55GVQN",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "loss landscapes, quantum, Wishart spin-glass model",
    "Abstract": "One of the most important properties of neural networks is the clustering of local minima of the loss function near the global minimum, enabling efficient training. Though generative models implemented on quantum computers are known to be more expressive than their traditional counterparts, it has empirically been observed that these models experience a transition in the quality of their local minima. Namely, below some critical number of parameters, all local minima are far from the global minimum in function value; above this critical parameter count, all local minima are good approximators of the global minimum. Furthermore, for a certain class of quantum generative models, this transition has empirically been observed to occur at parameter counts exponentially large in the problem size, meaning practical training of these models is out of reach. Here, we give the first proof of this transition in trainability, specializing to this latter class of quantum generative model. We use techniques inspired by those used to study the loss landscapes of classical neural networks. We also verify that our analytic results hold experimentally even at modest model sizes.",
    "One-sentence Summary": "We show using techniques from random matrix theory that, unlike typical neural networks, quantum generative models often have poor quality local minima."
  },
  {
    "title": "VOS: Learning What You Don't Know by Virtual Outlier Synthesis",
    "url": "/forum?id=TW7d65uYu5M",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Out-of-distribution (OOD) detection has received much attention lately due to its importance in the safe deployment of neural networks. One of the key challenges is that models lack supervision signals from unknown data, and as a result, can produce overconfident predictions on OOD data. Previous approaches rely on real outlier datasets for model regularization, which can be costly and sometimes infeasible to obtain in practice. In this paper, we present VOS, a novel framework for OOD detection by adaptively synthesizing virtual outliers that can meaningfully regularize the model's decision boundary during training. Specifically, VOS samples virtual outliers from the low-likelihood region of the class-conditional distribution estimated in the feature space. Alongside,  we introduce a novel unknown-aware training objective,  which contrastively shapes the uncertainty space between the ID data and synthesized outlier data. VOS achieves competitive performance on both object detection and image classification models, reducing the  FPR95 by up to 9.36% compared to the previous best method on object detectors. Code is available at https://github.com/deeplearning-wisc/vos."
  },
  {
    "title": "Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning",
    "url": "/forum?id=EcGGFkNTxdJ",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multi-Agent Reinforcement Learning, trust-region method, policy gradient method",
    "Abstract": "Trust region methods rigorously enabled reinforcement learning (RL) agents to learn monotonically improving policies, leading to superior performance on a variety of tasks. Unfortunately, when it comes to multi-agent reinforcement learning (MARL),  the property of monotonic improvement may not simply apply; this is because agents, even in cooperative games, could have conflicting directions of policy updates. As a result, achieving a guaranteed improvement on the joint policy where each agent acts individually remains an open challenge. In this paper, we extend the theory of trust region learning to MARL. Central to our findings are the multi-agent advantage decomposition lemma and the sequential policy update scheme. Based on these, we develop Heterogeneous-Agent Trust Region Policy Optimisation (HATPRO) and Heterogeneous-Agent Proximal Policy Optimisation (HAPPO) algorithms. Unlike many existing MARL algorithms, HATRPO/HAPPO do not need agents to share parameters, nor do they need any restrictive assumptions on decomposibility of the joint value function. Most importantly, we justify in theory the monotonic improvement property of HATRPO/HAPPO. We evaluate the proposed methods on a series of Multi-Agent MuJoCo and StarCraftII tasks. Results show that HATRPO and HAPPO significantly outperform strong baselines such as IPPO, MAPPO and MADDPG on all tested tasks, thereby establishing a new state of the art.",
    "One-sentence Summary": "This paper introduces the first trust region method for multi-agent reinforcement learning that enjoys theoretically-justified monotonic improvement guarantee and demonstrates the state-of-the-art performance on Mujoco benchmarks."
  },
  {
    "title": "Unsupervised Disentanglement with Tensor Product Representations on the Torus",
    "url": "/forum?id=neqU3HWDgE",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Variational Auto-Encoder, Disentanglement Learning",
    "Abstract": "The current methods for learning representations with auto-encoders almost exclusively employ vectors as the latent representations.  In this work, we propose to employ a tensor product structure for this purpose. This way, the obtained representations are naturally disentangled. In contrast to the conventional variations methods, which are targeted toward normally distributed features, the latent space in our representation is distributed uniformly over a set of unit circles. We argue that the torus structure of the latent space captures the generative factors effectively. We employ recent tools for measuring unsupervised disentanglement, and in an extensive set of experiments demonstrate the advantage of our method in terms of disentanglement, completeness, and informativeness. The code for our proposed method is available at https://github.com/rotmanmi/Unsupervised-Disentanglement-Torus.",
    "One-sentence Summary": "Decomposition of a latent space on a torus leads to a disentangled representation"
  },
  {
    "title": "Anomaly Detection for Tabular Data with Internal Contrastive Learning",
    "url": "/forum?id=_hszZbt46bT",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Anomaly detection, Tabular data",
    "Abstract": "We consider the task of finding out-of-class samples in tabular data, where little can be assumed on the structure of the data. In order to capture the structure of the samples of the single training class, we learn mappings that maximize the mutual information between each sample and the part that is masked out. The mappings are learned by employing a contrastive loss, which considers only one sample at a time. Once learned, we can score a test sample by measuring whether the learned mappings lead to a small contrastive loss using the masked parts of this sample. Our experiments show that our method leads by a sizable accuracy gap in comparison to the literature and that the same default set of hyperparameters provides state-of-the-art results across benchmarks.",
    "One-sentence Summary": "An anomaly detection method based on the ability to predict the masked out part in a vector."
  },
  {
    "title": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning",
    "url": "/forum?id=CpTuR2ECuW",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multi-agent, reinforcement learning, intrinsic rewards, exploration",
    "Abstract": "Efficient exploration is important for reinforcement learners (RL) to achieve high rewards. In multi-agent systems, coordinated exploration and behaviour is critical for agents to jointly achieve optimal outcomes. In this paper, we introduce a new general framework for improving coordination and performance of multi-agent reinforcement learners (MARL). Our framework, named Learnable Intrinsic-Reward Generation Selection algorithm (LIGS) introduces an adaptive learner, Generator that observes the agents and learns to construct intrinsic rewards online that coordinate the agents\u2019 joint exploration and joint behaviour. Using a novel combination of reinforcement learning (RL) and switching controls, LIGS determines the best states to learn to add intrinsic rewards which leads to a highly efficient learning process. LIGS can subdivide complex tasks making them easier to solve and enables systems of RL agents to quickly solve environments with sparse rewards. LIGS can seamlessly adopt existing multi-agent RL algorithms and our theory shows that it ensures convergence to joint policies that deliver higher system performance. We demonstrate the superior performance of the LIGS framework in challenging tasks in Foraging and StarCraft II and show LIGS is capable of tackling tasks previously unsolvable by MARL methods."
  },
  {
    "title": "Bayesian Modeling and Uncertainty Quantification for Learning to Optimize: What, Why, and How",
    "url": "/forum?id=EVVadRFRgL7",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Optimizing an objective function with uncertainty awareness is well-known to improve the accuracy and confidence of optimization solutions. Meanwhile, another relevant but very different question remains yet open: how to model and quantify the uncertainty of an optimization algorithm (a.k.a., optimizer) itself? To close such a gap, the prerequisite is to consider the optimizers as sampled from a distribution, rather than a few prefabricated and fixed update rules. We first take the novel angle to consider the algorithmic space of optimizers, and provide definitions for the optimizer prior and likelihood, that intrinsically determine the posterior and therefore uncertainty. We then leverage the recent advance of learning to optimize (L2O) for the space parameterization, with the end-to-end training pipeline built via variational inference, referred to as uncertainty-aware L2O (UA-L2O). Our study represents the first effort to recognize and quantify the uncertainty of the optimization algorithm. The extensive numerical results show that, UA-L2O achieves superior uncertainty calibration with accurate confidence estimation and tight confidence intervals, suggesting the improved posterior estimation thanks to considering optimizer uncertainty. Intriguingly, UA-L2O even improves optimization performances for two out of three test functions, the loss function in data privacy attack, and four of five cases of the energy function in protein docking. Our codes are released at https://github.com/Shen-Lab/Bayesian-L2O."
  },
  {
    "title": "Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity",
    "url": "/forum?id=RLtqs6pzj1-",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "efficient ensemble, FreeTickets, dynamic sparse training, deep ensemble, dynamic sparsity",
    "Abstract": "The success of deep ensembles on improving predictive performance, uncertainty estimation, and out-of-distribution robustness has been extensively studied in the machine learning literature. Albeit the promising results, naively training multiple deep neural networks and combining their predictions at inference leads to prohibitive computational costs and memory requirements. Recently proposed efficient ensemble approaches reach the performance of the traditional deep ensembles with significantly lower costs. However, the training resources required by these approaches are still at least the same as training a single dense model. In this work, we draw a unique connection between sparse neural network training and deep ensembles, yielding a novel efficient ensemble learning framework called $FreeTickets$. Instead of training multiple dense networks and averaging them, we directly train sparse subnetworks from scratch and extract diverse yet accurate subnetworks during this efficient, sparse-to-sparse training. Our framework, $FreeTickets$, is defined as the ensemble of these relatively cheap sparse subnetworks. Despite being an ensemble method, $FreeTickets$ has even fewer parameters and training FLOPs than a single dense model. This seemingly counter-intuitive outcome is due to the ultra training/inference efficiency of dynamic sparse training. $FreeTickets$ surpasses the dense baseline in all the following criteria: prediction accuracy, uncertainty estimation, out-of-distribution (OoD) robustness, as well as efficiency for both training and inference. Impressively, $FreeTickets$ outperforms the naive deep ensemble with ResNet50 on ImageNet using around only $1/5$ of the training FLOPs required by the latter. We have released our source code at https://github.com/VITA-Group/FreeTickets.",
    "One-sentence Summary": "We propose an efficient ensemble learning framework FreeTickets via dynamic spasity, which is more efficient to train and inference than a single dense model, while matching the performance of the naive dense ensemble."
  },
  {
    "title": "HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning",
    "url": "/forum?id=X0nrKAXu7g-",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "exploration, reinforcement learning",
    "Abstract": "Randomized least-square value iteration (RLSVI) is a provably efficient exploration method. However, it is limited to the case where (1) a good feature is known in advance and (2) this feature is fixed during the training. If otherwise, RLSVI suffers an unbearable computational burden to obtain the posterior samples. In this work, we present a practical algorithm named HyperDQN to address the above issues under deep RL. In addition to a non-linear neural network (i.e., base model) that predicts Q-values, our method employs a probabilistic hypermodel (i.e., meta model), which outputs the parameter of the base model. When both models are jointly optimized under a specifically designed objective, three purposes can be achieved. First, the hypermodel can generate approximate posterior samples regarding the parameter of the Q-value function. As a result, diverse Q-value functions are sampled to select exploratory action sequences. This retains the punchline of RLSVI for efficient exploration. Second, a good feature is learned to approximate Q-value functions. This addresses limitation (1). Third, the posterior samples of the Q-value function can be obtained in a more efficient way than the existing methods, and the changing feature does not affect the efficiency. This deals with limitation (2). On the Atari suite, HyperDQN with 20M frames outperforms DQN with 200M frames in terms of the maximum human-normalized score. For SuperMarioBros, HyperDQN outperforms several exploration bonus and randomized exploration methods on 5 out of 9 games.",
    "One-sentence Summary": "We design a practical randomized exploration method to address the sample efficiency issue in online reinforcement learning."
  },
  {
    "title": "Unraveling Model-Agnostic Meta-Learning via The Adaptation Learning Rate",
    "url": "/forum?id=3rULBvOJ8D2",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Meta-Learning, Learning rate, Optimization",
    "Abstract": "Model-Agnostic Meta-Learning (MAML) aims to find initial weights that allow fast adaptation to new tasks. The adaptation (inner loop) learning rate in MAML plays a central role in enabling such fast adaptation. However, how to choose this value in practice and how this choice affects the adaptation error remains less explored. In this paper, we study the effect of the adaptation learning rate in meta-learning with mixed linear regression. First, we present a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. Second, we interpret the underlying dependence between the optimal adaptation learning rate and the input data. Finally, we prove that compared with empirical risk minimization (ERM), MAML produces an initialization with a smaller average distance to the task optima, consistent with previous practical findings. These results are corroborated with numerical experiments.",
    "One-sentence Summary": "Theoretical analysis of Model-Agnostic Meta-Learning (MAML) through the inner loop (adaptation) learning rate."
  },
  {
    "title": "iFlood: A Stable and Effective Regularizer",
    "url": "/forum?id=MsHnJPaBUZE",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "overfitting, regularizer",
    "Abstract": "Various regularization methods have been designed to prevent overfitting of machine learning models. Among them, a surprisingly simple yet effective one, called Flooding, is proposed recently, which directly constrains the training loss on average to stay at a given level. However, our further studies uncover that the design of the loss function of Flooding can lead to a discrepancy between its objective and implementation, and cause the instability issue. To resolve these issues, in this paper, we propose a new regularizer, called individual Flood (denoted as iFlood). With instance-level constraints on training loss, iFlood encourages the trained models to better fit the under-fitted instances while suppressing the confidence on over-fitted ones. We theoretically show that the design of iFlood can be intrinsically connected with removing the noise or bias in training data, which makes it suitable for a variety of applications to improve the generalization performances of learned models. We also theoretically link iFlood to some other regularizers by comparing the inductive biases they introduce. Our experimental results on both image classification and language understanding tasks confirm that models learned with iFlood can stably converge to solutions with better generalization ability, and behave consistently at instance-level.",
    "One-sentence Summary": "We propose a novel regularizer named iFlood, which encourages the trained models to better fit the under-fitted instances while suppressing the confidence on over-fitted ones."
  },
  {
    "title": "FlexConv: Continuous Kernel Convolutions With Differentiable Kernel Sizes",
    "url": "/forum?id=3jooF27-0Wy",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Convolutional neural networks, learnable kernel size, continuous convolutional kernels, alias-free convolutional networks, implicit neural representations, resolution-agnostic representations, time series, sequential data, computer vision",
    "Abstract": "When designing Convolutional Neural Networks (CNNs), one must select the size of the convolutional kernels before training. Recent works show CNNs benefit from different kernel sizes at different layers, but exploring all possible combinations is unfeasible in practice. A more efficient approach is to learn the kernel size during training. However, existing works that learn the kernel size have a limited bandwidth. These approaches scale kernels by dilation, and thus the detail they can describe is limited. In this work, we propose FlexConv, a novel convolutional operation with which high bandwidth convolutional kernels of learnable kernel size can be learned at a fixed parameter cost. FlexNets model long-term dependencies without the use of pooling, achieve state-of-the-art performance on several sequential datasets, outperform recent works with learned kernel sizes, and are competitive with much deeper ResNets on image benchmark datasets. Additionally, FlexNets can be deployed at higher resolutions than those seen during training. To avoid aliasing, we propose a novel kernel parameterization with which the frequency of the kernels can be analytically controlled. Our novel kernel parameterization shows higher descriptive power and faster convergence speed than existing parameterizations. This leads to important improvements in classification accuracy.",
    "One-sentence Summary": "We provide a high bandwidth, alias-free convolutional kernel parameterization with learnable kernel size and constant parameter cost."
  },
  {
    "title": "Zero Pixel Directional Boundary by Vector Transform",
    "url": "/forum?id=nxcABL7jbQh",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Boundaries or contours are among the primary visual cues used by human and computer vision systems. One of the key problems in boundary detection is the loss formulation, which typically leads to class imbalance and, as a consequence, to thick boundaries which require non-differential post-processing steps to be thinned.\n        In this paper, we re-interpret boundaries as 1-D surfaces and formulate a one-to-one vector transform function that allows for training of boundary prediction completely avoiding the class imbalance issue. Specifically, we define the boundary representation at any point as the unit vector pointing to the closest boundary surface.\n        Our problem formulation leads to the estimation of direction as well as richer contextual information of the boundary, and, if desired, the availability of zero-pixel thin boundaries also at training time. Our method uses no hyper-parameter in the training loss and a fixed stable hyper-parameter at inference. We provide theoretical justification/discussions of the vector transform representation. We evaluate the proposed loss method using a standard architecture and show the excellent performance over other losses and representations on several datasets."
  },
  {
    "title": "A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion",
    "url": "/forum?id=wqD6TfbYkrn",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Point Cloud Completion, Denoising Diffusion Pobabilistic Model, Conditional Generation",
    "Abstract": "3D point clouds are an important data format that captures 3D information for real world objects.  Since 3D point clouds scanned in the real world are often incomplete, it is important to recover the complete point cloud for many downstreaming applications. Most existing point cloud completion methods use the Chamfer Distance (CD) loss for training. The CD loss estimates correspondences between two point clouds by searching nearest neighbors, which does not capture the overall point distribution on the generated shape, and therefore likely leads to non-uniform point cloud generation. To tackle this problem, we propose a novel Point Diffusion-Refinement (PDR) paradigm for point cloud completion. PDR consists of a Conditional Generation Network (CGNet) and a ReFinement Network (RFNet). The CGNet uses a conditional generative model called the denoising diffusion probabilistic model (DDPM) to generate a coarse completion conditioned on the partial observation. DDPM establishes a one-to-one pointwise mapping between the generated point cloud and the uniform ground truth, and then optimizes the mean squared error loss to realize uniform generation. The RFNet refines the coarse output of the CGNet and further improves quality of the completed point cloud.  In terms of the architecture, we develop a novel dual-path architecture for both networks. The architecture can (1) effectively and efficiently extract multi-level features from partially observed point clouds to guide completion, and (2) accurately manipulate spatial locations of 3D points to obtain smooth surfaces and sharp details. Extensive experimental results on various benchmark datasets show that our PDR paradigm outperforms previous state-of-the-art methods for point cloud completion. In addition, with the help of the RFNet,  we can accelerate the iterative generation process of the DDPM by up to 50 times without much performance drop."
  },
  {
    "title": "Auto-Transfer: Learning to Route Transferable Representations",
    "url": "/forum?id=SIKV0_MrZlr",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Feature routing, Transferable Representations",
    "Abstract": "Knowledge transfer between heterogeneous source and target networks and tasks has received a lot of attention in recent times as large amounts of quality labeled data can be difficult to obtain in many applications. Existing approaches typically constrain the target deep neural network (DNN) feature representations to be close to the source DNNs feature representations, which can be limiting. We, in this paper, propose a novel adversarial multi-armed bandit approach that automatically learns to route source representations to appropriate target representations following which they are combined in meaningful ways to produce accurate target models. We see upwards of 5\\% accuracy improvements compared with the state-of-the-art knowledge transfer methods on four benchmark (target) image datasets CUB200, Stanford Dogs, MIT67, and Stanford40 where the source dataset is ImageNet. We qualitatively analyze the goodness of our transfer scheme by showing individual examples of the important features focused on by our target network at different layers compared with the (closest) competitors. We also observe that our improvement over other methods is higher for smaller target datasets making it an effective tool for small data applications that may benefit from transfer learning.",
    "One-sentence Summary": "This paper offers a novel transfer method that uses a routing function to select source-target pairs as well as aggregation functions that combine source and target features (as opposed to matching source to target features)."
  },
  {
    "title": "PoNet: Pooling Network for Efficient Token Mixing in Long Sequences",
    "url": "/forum?id=9jInD9JjicF",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Transformer, Efficient Transformers, Token Mixing, Pooling, Linear, Long Range Arena, Transfer Learning, BERT, GLUE",
    "Abstract": "Transformer-based models have achieved great success in various NLP, vision, and speech tasks. However, the core of Transformer, the self-attention mechanism, has a quadratic time and memory complexity with respect to the sequence length, which hinders applications of Transformer-based models to long sequences. Many approaches have been proposed to mitigate this problem, such as sparse attention mechanisms, low-rank matrix approximations and scalable kernels, and token mixing alternatives to self-attention. We propose a novel Pooling Network (PoNet) for token mixing in long sequences with linear complexity. We design multi-granularity pooling and pooling fusion to capture different levels of contextual information and combine their interactions with tokens. On the Long Range Arena benchmark, PoNet significantly outperforms Transformer and achieves competitive accuracy, while being only slightly slower than the fastest model, FNet, across all sequence lengths measured on GPUs. We also conduct systematic studies on the transfer learning capability of PoNet and observe that PoNet achieves 95.7 percent of the accuracy of BERT on the GLUE benchmark, outperforming FNet by 4.5 percent relative. Comprehensive ablation analysis demonstrates effectiveness of the designed multi-granularity pooling and pooling fusion for token mixing in long sequences and efficacy of the designed pre-training tasks for PoNet to learn transferable contextualized language representations.",
    "One-sentence Summary": "We propose a novel Pooling Network for token mixing with linear complexity, achieve competitive performance on the Long Range Arena benchmark, and 95.7% of the accuracy of BERT on the GLUE demonstrating its transferability."
  },
  {
    "title": "Huber Additive Models for Non-stationary Time Series Analysis",
    "url": "/forum?id=9kpuB2bgnim",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Sparse additive models, variable selection, Huber, non-stationary, robust forecasting",
    "Abstract": "Sparse additive models have shown promising \ufb02exibility and interpretability in processing time series data. However, existing methods usually assume the time series data to be stationary and the innovation is sampled from a Gaussian distribution. Both assumptions are too stringent for heavy-tailed and non-stationary time series data that frequently arise in practice, such as \ufb01nance and medical \ufb01elds. To address these problems, we propose an adaptive sparse Huber additive model for robust forecasting in both non-Gaussian data and (non)stationary data. In theory, the generalization bounds of our estimator are established for both stationary and nonstationary time series data, which are independent of the widely used mixing conditions in learning theory of dependent observations. Moreover, the error bound for non-stationary time series contains a discrepancy measure for the shifts of the data distributions over time. Such a discrepancy measure can be estimated empirically and used as a penalty in our method. Experimental results on both synthetic and real-world benchmark datasets validate the effectiveness of the proposed method. The code is available at https://github.com/xianruizhong/SpHAM.",
    "One-sentence Summary": "An adaptive sparse Huber additive model for robust forecasting and  variable selection in  non-Gaussian  and (non)stationary time series data"
  },
  {
    "title": "Model-augmented Prioritized Experience Replay",
    "url": "/forum?id=WuEiafqdy9H",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "RL, Reinforcement Learning, Replay Buffer",
    "Abstract": "Experience replay is an essential component in off-policy model-free reinforcement learning (MfRL). Due to its effectiveness, various methods for calculating priority scores on experiences have been proposed for sampling. Since critic networks are crucial to policy learning, TD-error, directly correlated to $Q$-values, is one of the most frequently used features to compute the scores. However, critic networks often under- or overestimate $Q$-values, so it is often ineffective to learn to predict $Q$-values by sampled experiences based heavily on TD-error. Accordingly, it is valuable to find auxiliary features, which positively support TD-error in calculating the scores for efficient sampling. Motivated by this, we propose a novel experience replay method, which we call model-augmented prioritized experience replay (MaPER), that employs new learnable features driven from components in model-based RL (MbRL) to calculate the scores on experiences. The proposed MaPER brings the effect of curriculum learning for predicting $Q$-values better by the critic network with negligible memory and computational overhead compared to the vanilla PER. Indeed, our experimental results on various tasks demonstrate that MaPER can significantly improve the performance of the state-of-the-art off-policy MfRL and MbRL which includes off-policy MfRL algorithms in its policy optimization procedure.",
    "One-sentence Summary": "We propose a novel experience replay which employs additional auxiliary learnable features as well as TD-errors for prioritizing experiences"
  },
  {
    "title": "Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios",
    "url": "/forum?id=MSgB8D4Hy51",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "backdoor, Trojan, adversarial learning, deep neural network",
    "Abstract": "Backdoor attacks (BAs) are an emerging threat to deep neural network classifiers. A victim classifier will predict to an attacker-desired target class whenever a test sample is embedded with the same backdoor pattern (BP) that was used to poison the classifier's training set. Detecting whether a classifier is backdoor attacked is not easy in practice, especially when the defender is, e.g., a downstream user without access to the classifier's training set. This challenge is addressed here by a reverse-engineering defense (RED), which has been shown to yield state-of-the-art performance in several domains. However, existing REDs are not applicable when there are only two classes or when multiple attacks are present. These scenarios are first studied in the current paper, under the practical constraints that the defender neither has access to the classifier's training set nor to supervision from clean reference classifiers trained for the same domain. We propose a detection framework based on BP reverse-engineering and a novel expected transferability (ET) statistic. We show that our ET statistic is effective using the same detection threshold, irrespective of the classification domain, the attack configuration, and the BP reverse-engineering algorithm that is used. The excellent performance of our method is demonstrated on six benchmark datasets. Notably, our detection framework is also applicable to multi-class scenarios with multiple attacks. Code is available at https://github.com/zhenxianglance/2ClassBADetection.",
    "One-sentence Summary": "We proposed a detection framework against backdoor attacks for two-class and multi-attack scenarios, without access to the classifier's training set or any supervision from clean classifiers trained for the same domain."
  },
  {
    "title": "Multi-Task Processes",
    "url": "/forum?id=9otKVlgrpZG",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "stochastic processes, neural processes, multi-task learning, incomplete data",
    "Abstract": "Neural Processes (NPs) consider a task as a function realized from a stochastic process and flexibly adapt to unseen tasks through inference on functions. However, naive NPs can model data from only a single stochastic process and are designed to infer each task independently. Since many real-world data represent a set of correlated tasks from multiple sources (e.g., multiple attributes and multi-sensor data), it is beneficial to infer them jointly and exploit the underlying correlation to improve the predictive performance.\n        To this end, we propose Multi-Task Neural Processes (MTNPs), an extension of NPs designed to jointly infer tasks realized from multiple stochastic processes. We build MTNPs in a hierarchical way such that inter-task correlation is considered by conditioning all per-task latent variables on a single global latent variable. In addition, we further design our MTNPs so that they can address multi-task settings with incomplete data (i.e., not all tasks share the same set of input points), which has high practical demands in various applications.\n        Experiments demonstrate that MTNPs can successfully model multiple tasks jointly by discovering and exploiting their correlations in various real-world data such as time series of weather attributes and pixel-aligned visual modalities. We release our code at https://github.com/GitGyun/multi_task_neural_processes.",
    "One-sentence Summary": "We propose a new family of stochastic processes that can infer multiple heterogeneous functions jointly given a few incomplete observations (i.e., some functions may not be observed at each input)."
  },
  {
    "title": "Dynamic Token Normalization improves Vision Transformers",
    "url": "/forum?id=f9MHpAGUyMn",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "classification, Normalization, transformer",
    "Abstract": "Vision Transformer (ViT) and its variants (e.g., Swin, PVT) have achieved great success in various computer vision tasks, owing to their capability to learn long-range contextual information. Layer Normalization (LN) is an essential ingredient in these models. However, we found that the ordinary LN  makes tokens at different positions similar in magnitude because it normalizes embeddings within each token. It is difficult for Transformers to capture inductive bias such as the positional context in an image with LN. We tackle this problem by proposing a new normalizer, termed Dynamic Token Normalization (DTN), where normalization is performed both within each token (intra-token) and across different tokens (inter-token). DTN has several merits. Firstly, it is built on a unified formulation and thus can represent various existing normalization methods. Secondly, DTN learns to normalize tokens in both intra-token and inter-token manners, enabling Transformers to capture both the global contextual information and the local positional context. Thirdly, by simply replacing LN layers, DTN can be readily plugged into various vision transformers, such as ViT, Swin, and PVT. Extensive experiments show that the transformer equipped with DTN consistently outperforms baseline model with minimal extra parameters and computational overhead. For example, DTN outperforms LN on small ViT by $1.1\\%$ top-1 accuracy on ImageNet.",
    "One-sentence Summary": "The proposed DTN is a simple yet effective normalizer for vision transformers."
  },
  {
    "title": "Symbolic Learning to Optimize: Towards Interpretability and Scalability",
    "url": "/forum?id=ef0nInZHKIC",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Symbolic Regression, Learning To Optimize, Interpretability",
    "Abstract": "Recent studies on Learning to Optimize (L2O) suggest a promising path to automating and accelerating the optimization procedure for complicated tasks. Existing L2O models parameterize optimization rules by neural networks, and learn those numerical rules via meta-training. However, they face two common pitfalls: (1) scalability: the numerical rules represented by neural networks create extra memory overhead for applying L2O models, and limits their applicability to optimizing larger tasks; (2) interpretability: it is unclear what each L2O model has learned in its black-box optimization rule, nor is it straightforward to compare different L2O models in an explainable way. To avoid both pitfalls, this paper proves the concept that we can \"kill two birds by one stone\", by introducing the powerful tool of symbolic regression to L2O. In this paper, we establish a holistic symbolic representation and analysis framework for L2O, which yields a series of insights for learnable optimizers. Leveraging our findings, we further propose a lightweight L2O model that can be meta-trained on large-scale problems and outperformed human-designed and tuned optimizers. Our work is set to supply a brand-new perspective to L2O research. Codes are available at: https://github.com/VITA-Group/Symbolic-Learning-To-Optimize.",
    "One-sentence Summary": "Learning to distill learned optimization rule into symbolic math equations that bears better interpretability and scales better."
  },
  {
    "title": "Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning",
    "url": "/forum?id=ivQruZvXxtz",
    "date": "28 Sept 2021 (modified: 28 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "multilingual language model, gradient alignment",
    "Abstract": "Multilingual models jointly pretrained on multiple languages have achieved remarkable performance on various multilingual downstream tasks. Moreover, models finetuned on a single monolingual downstream task have shown to generalize to unseen languages. In this paper, we first show that it is crucial for those tasks to align gradients between them in order to maximize knowledge transfer while minimizing negative transfer. Despite its importance, the existing methods for gradient alignment either have a completely different purpose, ignore inter-task alignment, or aim to solve continual learning problems in rather inefficient ways. As a result of the misaligned gradients between tasks, the model suffers from severe negative transfer in the form of catastrophic forgetting of the knowledge acquired from the pretraining. To overcome the limitations, we propose a simple yet effective method that can efficiently align gradients between tasks. Specifically, we perform each inner-optimization by sequentially sampling batches from all the tasks, followed by a Reptile outer update. Thanks to the gradients aligned between tasks by our method, the model becomes less vulnerable to negative transfer and catastrophic forgetting. We extensively validate our method on various multi-task learning and zero-shot cross-lingual transfer tasks, where our method largely outperforms all the relevant baselines we consider.",
    "One-sentence Summary": "We propose a simple yet effective gradient alignment method for finetuning multilingual pretrained language models."
  },
  {
    "title": "Pseudo Numerical Methods for Diffusion Models on Manifolds",
    "url": "/forum?id=PlKWVd2yBkY",
    "date": "28 Sept 2021 (modified: 20 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "diffusion model, generative model, numerical method, manifold",
    "Abstract": "Denoising Diffusion Probabilistic Models (DDPMs) can generate high-quality samples such as image and audio samples. However, DDPMs require hundreds to thousands of iterations to produce a sample. Several prior works have successfully accelerated DDPMs through adjusting the variance schedule (e.g., Improved Denoising Diffusion Probabilistic Models) or the denoising equation (e.g., Denoising Diffusion Implicit Models (DDIMs)). However, these acceleration methods cannot maintain the quality of samples and even introduce new noise at high speedup rate, which limit their practicability. To accelerate the inference process while keeping the sample quality, we provide a new perspective that DDPMs should be treated as solving differential equations on manifolds. Under such a perspective, we propose pseudo numerical methods for diffusion models (PNDMs). Specifically, we figure out how to solve differential equations on manifolds and show that DDIMs are simple cases of pseudo numerical methods. We change several classical numerical methods to corresponding pseudo numerical methods and find that pseudo linear multi-step method is the best method in most situations. According to our experiments, by directly using pre-trained models on Cifar10, CelebA and LSUN, PNDMs can generate higher quality synthetic images with only 50 steps compared with 1000-step DDIMs (20x speedup), significantly outperform DDIMs with 250 steps (by around 0.4 in FID) and have good generalization on different variance schedules.",
    "One-sentence Summary": "We propose PNDMs, a new kind of numerical method, to accelerate diffusion models on manifolds."
  },
  {
    "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image  Pre-training Paradigm",
    "url": "/forum?id=zq1iJkNk3uN",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Recently, large-scale Contrastive Language-Image Pre-training (CLIP) has attracted unprecedented attention for its impressive zero-shot recognition ability and excellent transferability to downstream tasks. However, CLIP is quite data-hungry and requires 400M image-text pairs for pre-training, thereby restricting its adoption. This work proposes a novel training paradigm, Data efficient CLIP (DeCLIP), to alleviate this limitation. We demonstrate that by carefully utilizing the widespread supervision among the image-text pairs, our De-CLIP can learn generic visual features more efficiently. Instead of using the single image-text contrastive supervision, we fully exploit data potential through the use of (1) self-supervision within each modality; (2) multi-view supervision across modalities; (3) nearest-neighbor supervision from other similar pairs. Benefiting from intrinsic supervision, our DeCLIP-ResNet50 can achieve 60.4% zero-shot top1 accuracy on ImageNet, which is 0.8% above the CLIP-ResNet50 while using 7.1\u00d7fewer data. Our DeCLIP-ResNet50 outperforms its counterpart in 8 out of 11 visual datasets when transferred to downstream tasks. Moreover, Scaling up the model and computing also works well in our framework."
  },
  {
    "title": "Environment Predictive Coding for Visual Navigation",
    "url": "/forum?id=DBiQQYWykyy",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-supervised learning, visual navigation, representation learning",
    "Abstract": "We introduce environment predictive coding, a self-supervised approach to learn environment-level representations for embodied agents. In contrast to prior work on self-supervised learning for individual images, we aim to encode a 3D environment using a series of images observed by an agent moving in it. We learn these representations via a masked-zone prediction task, which segments an agent\u2019s trajectory into zones and then predicts features of randomly masked zones, conditioned on the agent\u2019s camera poses. This explicit spatial conditioning encourages learning representations that capture the geometric and semantic regularities of 3D environments. We learn such representations on a collection of video walkthroughs and demonstrate successful transfer to multiple downstream navigation tasks. Our experiments on the real-world scanned 3D environments of Gibson and Matterport3D show that our method obtains 2 - 6\u00d7 higher sample-ef\ufb01ciency and up to 57% higher performance over standard image-representation learning.",
    "One-sentence Summary": "We introduce environment predicting coding, a self-supervised approach for learning environment-level representations for navigation-like tasks."
  },
  {
    "title": "Topological Experience Replay",
    "url": "/forum?id=OXRZeMmOI7a",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep reinforcement learning, experience replay",
    "Abstract": "State-of-the-art deep Q-learning methods update Q-values using state transition tuples sampled from the experience replay buffer. This strategy often randomly samples or prioritizes data sampling based on measures such as the temporal difference (TD) error. Such sampling strategies can be inefficient at learning Q-function since a state's correct Q-value preconditions on the accurate successor states' Q-value. Disregarding such a successor's value dependency leads to useless updates and even learning wrong values.\n        To expedite Q-learning, we maintain states' dependency by organizing the agent's experience into a graph. Each edge in the graph represents a transition between two connected states. We perform value backups via a breadth-first search that expands vertices in the graph starting from the set of terminal states successively moving backward. We empirically show that our method is substantially more data-efficient than several baselines on a diverse range of goal-reaching tasks. Notably, the proposed method also outperforms baselines that consume more batches of training experience.",
    "One-sentence Summary": "We rearrange the update order of experience for training the Q-function by a dependency graph."
  },
  {
    "title": "Sparsity Winning Twice: Better Robust Generalization from More Efficient Training",
    "url": "/forum?id=SYuJXrXq8tw",
    "date": "28 Sept 2021 (modified: 27 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Recent studies demonstrate the deep networks, even robustified by the state-of-the-art adversarial training (AT), still suffer from large robust generalization gaps, in addition to the much more expensive training costs than standard training. In this paper, we investigate this intriguing problem from a new perspective, i.e., $\\textit{injecting appropriate forms of sparsity}$ during adversarial training. We introduce two alternatives for sparse adversarial training: (i) $\\textit{static sparsity}$, by leveraging recent results from the lottery ticket hypothesis to identify critical sparse subnetworks arising from the early training; (ii) $\\textit{dynamic sparsity}$, by allowing the sparse subnetwork to adaptively adjust its connectivity pattern (while sticking to the same sparsity ratio) throughout training. We find both static and dynamic sparse methods to yield win-win: substantially shrinking the robust generalization gap and alleviating the robust overfitting, meanwhile significantly saving training and inference FLOPs. Extensive experiments validate our proposals with multiple network architectures on diverse datasets, including CIFAR-10/100 and Tiny-ImageNet. For example, our methods reduce robust generalization gap and overfitting by $34.44\\%$ and $4.02\\%$, with comparable robust/standard accuracy boosts and $87.83\\%$/$87.82\\%$ training/inference FLOPs savings on CIFAR-100 with ResNet-18. Besides, our approaches can be organically combined with existing regularizers, establishing new state-of-the-art results in AT. All codes are included."
  },
  {
    "title": "CrossMatch: Cross-Classifier Consistency Regularization for Open-Set Single Domain Generalization",
    "url": "/forum?id=48RBsJwGkJf",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Single Domain Generalization, Open-Set Recognition",
    "Abstract": "Single domain generalization (SDG) is a challenging scenario of domain generalization, where only one source domain is available to train the model. Typical SDG methods are based on the adversarial data augmentation strategy, which complements the diversity of source domain to learn a robust model. Existing SDG methods require the source and target domains to have the same label space. However, as target domains may contain novel categories unseen in source label space, this assumption is not practical in many real-world applications. In this paper, we propose a challenging and untouched problem: \\textit{Open-Set Single Domain Generalization} (OS-SDG), where target domains include unseen categories out of source label space. The goal of OS-SDG is to learn a model, with only one source domain, to classify a target sample with correct class if it belongs to source label space, or assign it to unknown classes. We design a \\textit{CrossMatch} approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. CrossMatch generates auxiliary samples out of source label space by using an adversarial data augmentation strategy. We also adopt a consistency regularization on generated auxiliary samples between multi-binary classifiers and the model trained by SDG methods, to improve the model\u2019s capability on unknown class identification. Experimental results on benchmark datasets prove the effectiveness of CrossMatch on enhancing the performance of SDG methods in the OS-SDG setting."
  },
  {
    "title": "Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning",
    "url": "/forum?id=baUQQPwQiAg",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "unlearnable examples, adversarial training, privacy",
    "Abstract": "The tremendous amount of accessible data in cyberspace face the risk of being unauthorized used for training deep learning models. To address this concern, methods are proposed to make data unlearnable for deep learning models by adding a type of error-minimizing noise. However, such conferred unlearnability is found fragile to adversarial training. In this paper, we design new methods to generate robust unlearnable examples that are protected from adversarial training. We first find that the vanilla error-minimizing noise, which suppresses the informative knowledge of data via minimizing the corresponding training loss, could not effectively minimize the adversarial training loss. This explains the vulnerability of error-minimizing noise in adversarial training. Based on the observation, robust error-minimizing noise is then introduced to reduce the adversarial training loss. Experiments show that the unlearnability brought by robust error-minimizing noise can effectively protect data from adversarial training in various scenarios. The code is available at \\url{https://github.com/fshp971/robust-unlearnable-examples}.",
    "One-sentence Summary": "This paper proposes an robust error-minimizing noise that can protect data from being learned under adversarial training."
  },
  {
    "title": "A NON-PARAMETRIC REGRESSION VIEWPOINT : GENERALIZATION OF OVERPARAMETRIZED DEEP RELU NETWORK UNDER NOISY OBSERVATIONS",
    "url": "/forum?id=bZJbzaj_IlP",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Overparametrized Deep Neural Network, Neural Tangent Kernel, Minimax, Non-parametric regression",
    "Abstract": "We study the generalization properties of the overparameterized deep neural network (DNN) with Rectified Linear Unit (ReLU) activations.\n        Under the non-parametric regression framework, it is assumed that the ground-truth function is from a reproducing kernel Hilbert space (RKHS) induced by a neural tangent kernel (NTK) of ReLU DNN, and a dataset is given with the noises. Without a delicate adoption of early stopping, we prove that the overparametrized DNN trained by vanilla gradient descent does not recover the ground-truth function. It turns out that the estimated DNN's $L_{2}$ prediction error is bounded away from $0$. As a complement of the above result, we show that the $\\ell_{2}$-regularized gradient descent enables the overparametrized DNN achieve the minimax optimal convergence rate of the $L_{2}$ prediction error, without early stopping. Notably, the rate we obtained is faster than $\\mathcal{O}(n^{-1/2})$ known in the literature.",
    "One-sentence Summary": "Study the generalization of overparametrized deep neural network with relu activation function with noisy dataset."
  },
  {
    "title": "Active Hierarchical Exploration with Stable Subgoal Representation Learning",
    "url": "/forum?id=sNuFKTMktcY",
    "date": "28 Sept 2021 (modified: 05 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Hierarchical Reinforcement Learning, Exploration, Representation Learning",
    "Abstract": "Goal-conditioned hierarchical reinforcement learning (GCHRL) provides a promising approach to solving long-horizon tasks. Recently, its success has been extended to more general settings by concurrently learning hierarchical policies and subgoal representations. Although GCHRL possesses superior exploration ability by decomposing tasks via subgoals, existing GCHRL methods struggle in temporally extended tasks with sparse external rewards, since the high-level policy learning relies on external rewards. As the high-level policy selects subgoals in an online learned representation space, the dynamic change of the subgoal space severely hinders effective high-level exploration. In this paper, we propose a novel regularization that contributes to both stable and efficient subgoal representation learning. Building upon the stable representation, we design measures of novelty and potential for subgoals, and develop an active hierarchical exploration strategy that seeks out new promising subgoals and states without intrinsic rewards. Experimental results show that our approach significantly outperforms state-of-the-art baselines in continuous control tasks with sparse rewards.",
    "One-sentence Summary": "We propose a regularization to stabilize subgoal representation learning in goal-conditioned HRL and develop an active exploration strategy upon this stable representation."
  },
  {
    "title": "Deep AutoAugment",
    "url": "/forum?id=St-53J9ZARf",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "automated machine learning, data augmentation",
    "Abstract": "While recent automated data augmentation methods lead to state-of-the-art results, their design spaces and the derived data augmentation strategies still incorporate strong human priors. In this work, instead of fixing a set of hand-picked default augmentations alongside the searched data augmentations, we propose a fully automated approach for data augmentation search named Deep AutoAugment (DeepAA). DeepAA progressively builds a multi-layer data augmentation pipeline from scratch by stacking augmentation layers one at a time until reaching convergence. For each augmentation layer, the policy is optimized to maximize the cosine similarity between the gradients of the original and augmented data along the direction with low variance. Our experiments show that even without default augmentations, we can learn an augmentation policy that achieves strong performance with that of previous works. Extensive ablation studies show that the regularized gradient matching is an effective search method for data augmentation policies. Our code is available at: https://github.com/MSU-MLSys-Lab/DeepAA .",
    "One-sentence Summary": "We propose Deep AutoAugment (DeepAA), a fully automated automated data augmentation methods that outperforms previous automated data augmentation methods."
  },
  {
    "title": "Temporal Alignment Prediction for Supervised Representation Learning and Few-Shot Sequence Classification",
    "url": "/forum?id=p3DKPQ7uaAi",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Temporal Alignment, Supervised Representation Learning, Few-shot Action Recognition, Alignment Prediction, Sequence Classification",
    "Abstract": "Explainable distances for sequence data depend on temporal alignment to tackle sequences with different lengths and local variances. Most sequence alignment methods infer the optimal alignment by solving an optimization problem under pre-defined feasible alignment constraints, which not only is time-consuming, but also makes end-to-end sequence learning intractable. In this paper, we propose a learnable sequence distance called Temporal Alignment Prediction (TAP). TAP employs a lightweight convolutional neural network to directly predict the optimal alignment between two sequences, so that only straightforward calculations are required and no optimization is involved in inference. TAP can be applied in different distance-based machine learning tasks. For supervised sequence representation learning, we show that TAP trained with various metric learning losses achieves completive performances with much faster inference speed. For few-shot action classification, we apply TAP as the distance measure in the metric learning-based episode-training paradigm. This simple strategy achieves comparable results with state-of-the-art few-shot action recognition methods.",
    "One-sentence Summary": "We propose a learnable sequence distance by predicting the temporal alignment and show its application in supervised representation learning for sequence data and few-shot action recognition."
  },
  {
    "title": "Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice",
    "url": "/forum?id=O476oWmiNNp",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep ViT, Spectral Analysis, Attention Collapse, Patch Diversity",
    "Abstract": "Vision Transformer (ViT) has recently demonstrated promise in computer vision problems. However, unlike Convolutional Neural Networks (CNN), it is known that the performance of ViT saturates quickly with depth increasing, due to the observed attention collapse or patch uniformity. Despite a couple of empirical solutions, a rigorous framework studying on this scalability issue remains elusive. In this paper, we first establish a  rigorous theory framework to analyze ViT features from the Fourier spectrum domain. We show that the self-attention mechanism inherently amounts to a low-pass filter, which indicates when ViT scales up its depth, excessive low-pass filtering will cause feature maps to only preserve their Direct-Current (DC) component. We then propose two straightforward yet effective techniques to mitigate the undesirable low-pass limitation. The first technique, termed AttnScale, decomposes a self-attention block into low-pass and high-pass components, then rescales and combines these two filters to produce an all-pass self-attention matrix. The second technique, termed FeatScale, re-weights feature maps on separate frequency bands to amplify the high-frequency signals. Both techniques are efficient and hyperparameter-free, while effectively overcoming relevant ViT training artifacts such as attention collapse and patch uniformity. By seamlessly plugging in our techniques to multiple ViT variants, we demonstrate that they consistently help ViTs benefit from deeper architectures, bringing up to 1.1% performance gains \"for free\" (e.g., with little parameter overhead). We publicly release our codes and pre-trained models at https://github.com/VITA-Group/ViT-Anti-Oversmoothing.",
    "One-sentence Summary": "In this paper, we investigate the scalability issue with ViT via Fourier domain analysis and propose two practical solutions by scaling different frequency components of attention and feature maps."
  },
  {
    "title": "Self-ensemble Adversarial Training for Improved Robustness",
    "url": "/forum?id=oU3aTsmeRQV",
    "date": "28 Sept 2021 (modified: 02 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial Example, Adversarial Training",
    "Abstract": "Due to numerous breakthroughs in real-world applications brought by machine intelligence, deep neural networks (DNNs) are widely employed in critical applications. However, predictions of DNNs are easily manipulated with imperceptible adversarial perturbations, which impedes the further deployment of DNNs and may result in profound security and privacy implications. By incorporating adversarial samples into the training data pool, adversarial training is the strongest principled strategy against various adversarial attacks among all sorts of defense methods. Recent works mainly focus on developing new loss functions or regularizers, attempting to find the unique optimal point in the weight space. But none of them taps the potentials of classifiers obtained from standard adversarial training, especially states on the searching trajectory of training. In this work, we are dedicated to the weight states of models through the training process and devise a simple but powerful \\emph{Self-Ensemble Adversarial Training} (SEAT) method for yielding a robust classifier by averaging weights of history models. This considerably improves the robustness of the target model against several well known adversarial attacks, even merely utilizing the naive cross-entropy loss to supervise. We also discuss the relationship between the ensemble of predictions from different adversarially trained models and the prediction of weight-ensembled models, as well as provide theoretical and empirical evidence that the proposed self-ensemble method provides a smoother loss landscape and better robustness than both individual models and the ensemble of predictions from different classifiers. We further analyze a subtle but fatal issue in the general settings for the self-ensemble model, which causes the deterioration of the weight-ensembled method in the late phases.",
    "One-sentence Summary": "This paper proposes an efficient self-ensemble method for adversarial trained classifiers and significantly improve their adversarial robustness"
  },
  {
    "title": "Do deep networks transfer invariances across classes?",
    "url": "/forum?id=Fn7i_r5rR0q",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "invariance, augmentation, nuisance transformation, imbalance, long tail",
    "Abstract": "In order to generalize well, classifiers must learn to be invariant to nuisance transformations that do not alter an input's class. Many problems have \"class-agnostic\" nuisance transformations that apply similarly to all classes, such as lighting and background changes for image classification. Neural networks can learn these invariances given sufficient data, but many real-world datasets are heavily class imbalanced and contain only a few examples for most of the classes. We therefore pose the question: how well do neural networks transfer class-agnostic invariances learned from the large classes to the small ones? Through careful experimentation, we observe that invariance to class-agnostic transformations is still heavily dependent on class size, with the networks being much less invariant on smaller classes. This result holds even when using data balancing techniques, and suggests poor invariance transfer across classes. Our results provide one explanation for why classifiers generalize poorly on unbalanced and long-tailed distributions. Based on this analysis, we show how a generative approach for learning the nuisance transformations can help transfer invariances across classes and improve performance on a set of imbalanced image classification benchmarks.",
    "One-sentence Summary": "Study how well classifiers learn invariances in the imbalanced setting, and methods for improvement."
  },
  {
    "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL",
    "url": "/forum?id=XOh5x-vxsrV",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, representation learning, self-supervised learning, procgen",
    "Abstract": "A highly desirable property of a reinforcement learning (RL) agent -- and a major difficulty for deep RL approaches -- is the ability to generalize policies learned on a few tasks over a high-dimensional observation space to similar tasks not seen during training. Many promising approaches to this challenge consider RL as a process of training two functions simultaneously: a complex nonlinear encoder that maps high-dimensional observations to a latent representation space, and a simple linear policy over this space. We posit that a superior encoder for zero-shot generalization in RL can be trained by using solely an auxiliary SSL objective if the training process encourages the encoder to map behaviorally similar observations to similar representations, as reward-based signal can cause overfitting in the encoder (Raileanu et al., 2021). We propose Cross-Trajectory Representation Learning (CTRL), a method that runs within an RL agent and conditions its encoder to recognize behavioral similarity in observations by applying a novel SSL objective to pairs of trajectories from the agent's policies. CTRL can be viewed as having the same effect as inducing a pseudo-bisimulation metric but, crucially, avoids the use of rewards and associated overfitting risks. Our experiments ablate various components of CTRL and demonstrate that in combination with PPO it achieves better generalization performance on the challenging Procgen benchmark suite (Cobbe et al., 2020).",
    "One-sentence Summary": "Cross-trajectory self-supervised learning for better zero-shot generalization in RL"
  },
  {
    "title": "On Covariate Shift of Latent Confounders in Imitation and Reinforcement Learning",
    "url": "/forum?id=w01vBAcewNX",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "imitation learning, reinforcement learning, expert data, hidden confounding, causal inference, covariate shift",
    "Abstract": "We consider the problem of using expert data with unobserved confounders for imitation and reinforcement learning. We begin by defining the problem of learning from confounded expert data in a contextual MDP setup. We analyze the limitations of learning from such data with and without external reward and propose an adjustment of standard imitation learning algorithms to fit this setup. In addition, we discuss the problem of distribution shift between the expert data and the online environment when partial observability is present in the data. We prove possibility and impossibility results for imitation learning under arbitrary distribution shift of the missing covariates. When additional external reward is provided, we propose a sampling procedure that addresses the unknown shift and prove convergence to an optimal solution. Finally, we validate our claims empirically on challenging assistive healthcare and recommender system simulation tasks.",
    "One-sentence Summary": "We use expert data with unobserved confounders for both imitation and reinforcement learning. Such hidden confounding is prone to a shifted distribution, which may severely hurt performance unless accounted for."
  },
  {
    "title": "RvS: What is Essential for Offline RL via Supervised Learning?",
    "url": "/forum?id=S874XAIpkR-",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, deep reinforcement learning, offline reinforcement learning",
    "Abstract": "Recent work has shown that supervised learning alone, without temporal difference (TD) learning, can be remarkably effective for offline RL. When does this hold true, and which algorithmic components are necessary? Through extensive experiments, we boil supervised learning for offline RL down to its essential elements. In every environment suite we consider, simply maximizing likelihood with a two-layer feedforward MLP is competitive with state-of-the-art results of substantially more complex methods based on TD learning or sequence modeling with Transformers. Carefully choosing model capacity (e.g., via regularization or architecture) and choosing which information to condition on (e.g., goals or rewards) are critical for performance. These insights serve as a field guide for practitioners doing Reinforcement Learning via Supervised Learning (which we coin RvS learning). They also probe the limits of existing RvS methods, which are comparatively weak on random data, and suggest a number of open problems.",
    "One-sentence Summary": "Experimentally evaluating when and why supervised learning solves offline RL"
  },
  {
    "title": "LEARNING GUARANTEES FOR GRAPH CONVOLUTIONAL NETWORKS ON THE STOCHASTIC BLOCK MODEL",
    "url": "/forum?id=dpXL6lz4mOQ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "An abundance of neural network models and algorithms for diverse tasks on graphs have been developed in the past five years. However, very few provable guarantees have been available for the performance of graph neural network models. This state of affairs is in contrast with the steady progress on the theoretical underpinnings of traditional dense and convolutional neural networks. In this paper we present the first provable guarantees for one of the best-studied families of graph neural network models, Graph Convolutional Networks (GCNs), for semi- supervised community detection tasks. We show that with high probability over the initialization and training data, a GCN will efficiently learn to detect communities on graphs drawn from a stochastic block model. Our proof relies on a fine-grained analysis of the training dynamics in order to overcome the complexity of a non-convex optimization landscape with many poorly-performing local minima."
  },
  {
    "title": "Learning Versatile Neural Architectures by Propagating Network Codes",
    "url": "/forum?id=KEQl-MZ5fg7",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multitask NAS, Task-Transferable Architecture, Neural Predictor, NAS Benchmark",
    "Abstract": "This work explores how to design a single neural network capable of adapting to multiple heterogeneous vision tasks, such as image segmentation, 3D detection, and video recognition. This goal is challenging because both network architecture search (NAS) spaces and methods in different tasks are inconsistent. We solve this challenge from both sides. We first introduce a unified design space for multiple tasks and build a multitask NAS benchmark (NAS-Bench-MR) on many widely used datasets, including ImageNet, Cityscapes, KITTI, and HMDB51. We further propose Network Coding Propagation (NCP), which back-propagates gradients of neural predictors to directly update architecture codes along the desired gradient directions to solve various tasks. In this way, optimal architecture configurations can be found by NCP in our large search space in seconds.\n        \n        Unlike prior arts of NAS that typically focus on a single task, NCP has several unique benefits. (1) NCP transforms architecture optimization from data-driven to architecture-driven, enabling joint search an architecture among multitasks with different data distributions. (2) NCP learns from network codes but not original data, enabling it to update the architecture efficiently across datasets. (3) In addition to our NAS-Bench-MR, NCP performs well on other NAS benchmarks, such as NAS-Bench-201. (4) Thorough studies of NCP on inter-, cross-, and intra-tasks highlight the importance of cross-task neural architecture design, i.e., multitask neural architectures and architecture transferring between different tasks. Code is available at https://github.com/dingmyu/NCP.",
    "One-sentence Summary": "An efficient NAS method by inverting neural predictors to directly update architectures and a multitask NAS benchmark for cross-task architecture design and analysis."
  },
  {
    "title": "Task-Induced Representation Learning",
    "url": "/forum?id=OzyXtIZAzFv",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "representation learning, reinforcement learning, transfer learning, visually complex observations",
    "Abstract": "In this work, we evaluate the effectiveness of representation learning approaches for decision making in visually complex environments. Representation learning is essential for effective reinforcement learning (RL) from high-dimensional in- puts. Unsupervised representation learning approaches based on reconstruction, prediction or contrastive learning have shown substantial learning efficiency gains. Yet, they have mostly been evaluated in clean laboratory or simulated settings. In contrast, real environments are visually complex and contain substantial amounts of clutter and distractors. Unsupervised representations will learn to model such distractors, potentially impairing the agent\u2019s learning efficiency. In contrast, an alternative class of approaches, which we call task-induced representation learning, leverages task information such as rewards or demonstrations from prior tasks to focus on task-relevant parts of the scene and ignore distractors. We investi- gate the effectiveness of unsupervised and task-induced representation learning approaches on four visually complex environments, from Distracting DMControl to the CARLA driving simulator. For both, RL and imitation learning, we find that representation learning generally improves sample efficiency on unseen tasks even in visually complex scenes and that task-induced representations can double learning efficiency compared to unsupervised alternatives.",
    "One-sentence Summary": "We introduce task-induced representation learning, which leverages task information in offline data from prior tasks to learn representations of visually complex scenes that model only task-relevant aspects and enable efficient learning of new tasks."
  },
  {
    "title": "Graph-based Nearest Neighbor Search in Hyperbolic Spaces",
    "url": "/forum?id=USIgIY6TNDe",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "similarity search, nearest neighbor search, hyperbolic space, graph-based nearest neighbor search",
    "Abstract": "The nearest neighbor search (NNS) problem is widely studied in Euclidean space, and graph-based algorithms are known to outperform other approaches for this task. However, hyperbolic geometry often allows for better data representation in various domains, including graphs, words, and images. In this paper, we show that graph-based approaches are also well suited for hyperbolic geometry. From a theoretical perspective, we rigorously analyze the time and space complexity of graph-based NNS, assuming that an $n$-element dataset is uniformly distributed within a $d$-dimensional ball of radius $R$ in the hyperbolic space of curvature $-1$. Under some conditions on $R$ and $d$, we derive the time and space complexity of graph-based NNS and compare the obtained results with known guarantees for the Euclidean case. Interestingly, in the dense setting ($d \\ll \\log n$) and under some assumptions on the radius $R$, graph-based NNS has lower time complexity in the hyperbolic space. This agrees with our experiments: we consider datasets embedded in hyperbolic and Euclidean spaces and show that graph-based NNS can be more efficient in the hyperbolic space. We also demonstrate that graph-based methods outperform other existing baselines for hyperbolic NNS. Overall, our theoretical and empirical analysis suggests that graph-based NNS can be considered a default approach for similarity search in hyperbolic spaces.",
    "One-sentence Summary": "Analyze graph-based NNS for hyperbolic spaces theoretically and empirically and show that this method outperforms other existing approaches."
  },
  {
    "title": "Generative Models as a Data Source for Multiview Representation Learning",
    "url": "/forum?id=qhAeZjs7dCL",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generative models, GANs, Contrastive Learning, Representation Learning",
    "Abstract": "Generative models are now capable of producing highly realistic images that look nearly indistinguishable from the data on which they are trained. This raises the question: if we have good enough generative models, do we still need datasets? We investigate this question in the setting of learning general-purpose visual representations from a black-box generative model rather than directly from data. Given an off-the-shelf image generator without any access to its training data, we train representations from the samples output by this generator. We compare several representation learning methods that can be applied to this setting, using the latent space of the generator to generate multiple \"views\" of the same semantic content. We show that for contrastive methods, this multiview data can naturally be used to identify positive pairs (nearby in latent space) and negative pairs (far apart in latent space). We find that the resulting representations rival or even outperform those learned directly from real data, but that good performance requires care in the sampling strategy applied and the training method. Generative models can be viewed as a compressed and organized copy of a dataset, and we envision a future where more and more \"model zoos\" proliferate while datasets become increasingly unwieldy, missing, or private. This paper suggests several techniques for dealing with visual representation learning in such a future. Code is available on our project page https://ali-design.github.io/GenRep/.",
    "One-sentence Summary": "State of the art visual representations are learned by aligning multiple \u2018views\u2019 of the training data; we show how GANs can be used to generate synthetic multiview data that yields effective visual representations."
  },
  {
    "title": "GiraffeDet: A Heavy-Neck Paradigm for Object Detection",
    "url": "/forum?id=cBu4ElJfneV",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Object Detection, fpn, space-to-depth, representation",
    "Abstract": "In conventional object detection frameworks, a backbone body inherited from image recognition models extracts deep latent features and then a neck module fuses these latent features to capture information at different scales. As the resolution in object detection is much larger than in image recognition, the computational cost of the backbone often dominates the total inference cost. This heavy-backbone design paradigm is mostly due to the historical legacy when transferring image recognition models to object detection rather than an end-to-end optimized design for object detection. In this work, we show that such  paradigm indeed leads to sub-optimal object detection models. To this end, we propose a novel heavy-neck paradigm, GiraffeDet, a giraffe-like network for efficient object detection. The GiraffeDet uses an extremely lightweight backbone and a very deep and large neck module which encourages dense information exchange among different spatial scales as well as different levels of latent semantics simultaneously. This design paradigm allows detectors to process the high-level semantic information and low-level spatial information at the same priority even in the early stage of the network, making it more effective in detection tasks.  Numerical evaluations on multiple popular object detection benchmarks show that GiraffeDet consistently outperforms previous SOTA models across a wide spectrum of resource constraints. The source code is available at\n        https://github.com/jyqi/GiraffeDet.",
    "One-sentence Summary": "we propose a novel heavy-neck paradigm(GiraffeDet) for detection task, which allows detectors to process the high-level categorical information and low-level spatial information uniformly, making it more effective in detection tasks."
  },
  {
    "title": "A Unified Wasserstein Distributional Robustness Framework for Adversarial Training",
    "url": "/forum?id=Dzpe9C1mpiv",
    "date": "28 Sept 2021 (modified: 27 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial Machine Learning, Distributional Robustness",
    "Abstract": "It is well-known that deep neural networks (DNNs) are susceptible to adversarial attacks, exposing a severe fragility of deep learning systems. As the result, adversarial training (AT) method, by incorporating adversarial examples during training, represents a natural and effective approach to strengthen the robustness of a DNN-based classifier. However, most AT-based methods, notably PGD-AT and TRADES, typically seek a pointwise adversary that generates the worst-case adversarial example by independently perturbing each data sample, as a way to ``probe'' the vulnerability of the classifier. Arguably, there are unexplored benefits in considering such adversarial effects from an entire distribution. To this end, this paper presents a unified framework that connects Wasserstein distributional robustness with current state-of-the-art AT methods. We introduce a new Wasserstein cost function and a new series of risk functions, with which we show that standard AT methods are special cases of their counterparts in our framework. This connection leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributional robustness AT-based algorithms. Extensive experiments show that our distributional robustness AT algorithms robustify further their standard AT counterparts in various settings.",
    "One-sentence Summary": "A Unified Wasserstein Distributional Robustness Framework for Adversarial Training"
  },
  {
    "title": "miniF2F: a cross-system benchmark for formal Olympiad-level mathematics",
    "url": "/forum?id=9ZPegFuFTFv",
    "date": "28 Sept 2021 (modified: 27 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural theorem proving, Benchmark dataset",
    "Abstract": "We present $\\textsf{miniF2F}$, a dataset of formal Olympiad-level mathematics problems statements intended to provide a unified cross-system benchmark for neural theorem proving. The $\\textsf{miniF2F}$ benchmark currently targets Metamath, Lean, Isabelle (partially) and HOL Light (partially) and consists of 488 problem statements drawn from the AIME, AMC, and the International Mathematical Olympiad (IMO), as well as material from high-school and undergraduate mathematics courses. We report baseline results using GPT-f, a neural theorem prover based on GPT-3 and provide an analysis of its performance. We intend for $\\textsf{miniF2F}$ to be a community-driven effort and hope that our benchmark will help spur advances in neural theorem proving."
  },
  {
    "title": "Towards Model Agnostic Federated Learning Using Knowledge Distillation",
    "url": "/forum?id=lQI_mZjvBxj",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, Knowledge Distillation, Model Agnostic Communication, Kernel Regression",
    "Abstract": "Is it possible to design an universal API for federated learning using which an ad-hoc group of data-holders (agents) collaborate with each other and perform federated learning? Such an API would necessarily need to be model-agnostic i.e. make no assumption about the model architecture being used by the agents, and also cannot rely on having representative public data at hand. Knowledge distillation (KD) is the obvious tool of choice to design such protocols. However, surprisingly, we show that most natural KD-based federated learning protocols have poor performance.\n            \n            To investigate this, we propose a new theoretical framework, Federated Kernel ridge regression, which can capture both model heterogeneity as well as data heterogeneity. Our analysis shows that the degradation is largely due to a fundamental limitation of knowledge distillation under data heterogeneity. We further validate our framework by analyzing and designing new protocols based on KD. Their performance on real world experiments using neural networks, though still unsatisfactory, closely matches our theoretical predictions.",
    "One-sentence Summary": "We develop a rich yet tractable framework for analyzing distillation based federated learning algorithms, using which we draw some surprising insights."
  },
  {
    "title": "Acceleration of Federated Learning with Alleviated Forgetting in Local Training",
    "url": "/forum?id=541PxiEKN3F",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated learning, non-i.i.d. data",
    "Abstract": "Federated learning (FL) enables distributed optimization of machine learning models while protecting privacy by independently training local models on each client and then aggregating parameters on a central server, thereby producing an effective global model. Although a variety of FL algorithms have been proposed, their training efficiency remains low when the data are not independently and identically distributed (non-i.i.d.) across different clients. We observe that the slow convergence rates of the existing methods are (at least partially) caused by the catastrophic forgetting issue during the local training stage on each individual client, which leads to a large increase in the loss function concerning the previous training data provided at other clients. Here, we propose FedReg, an algorithm to accelerate FL with alleviated knowledge forgetting in the local training stage by regularizing locally trained parameters with the loss on generated pseudo data, which encode the knowledge of previous training data learned by the global model. Our comprehensive experiments demonstrate that FedReg not only significantly improves the convergence rate of FL, especially when the neural network architecture is deep and the clients' data are extremely non-i.i.d., but is also able to protect privacy better in classification problems and more robust against gradient inversion attacks."
  },
  {
    "title": "Discovering Invariant Rationales for Graph Neural Networks",
    "url": "/forum?id=hGXij5rfiHw",
    "date": "28 Sept 2021 (modified: 30 Jan 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Interpretability, Graph Neural Networks, Causal Discovery, Invariant Learning",
    "Abstract": "Intrinsic interpretability of graph neural networks (GNNs) is to find a small subset of the input graph's features --- rationale --- which guides the model prediction. Unfortunately, the leading rationalization models often rely on data biases, especially shortcut features, to compose rationales and make predictions without probing the critical and causal patterns. Moreover, such data biases easily change outside the training distribution. As a result, these models suffer from a huge drop in interpretability and predictive performance on out-of-distribution data. In this work, we propose a new strategy of discovering invariant rationale (DIR) to construct intrinsically interpretable GNNs. It conducts interventions on the training distribution to create multiple interventional distributions. Then it approaches the causal rationales that are invariant across different distributions while filtering out the spurious patterns that are unstable. Experiments on both synthetic and real-world datasets validate the superiority of our DIR in terms of interpretability and generalization ability on graph classification over the leading baselines. Code and datasets are available at https://github.com/Wuyxin/DIR-GNN.",
    "One-sentence Summary": "We propose a novel invariant learning algorithm, Discovering Invariant Rationale (DIR), for intrinsically interpretable models."
  },
  {
    "title": "Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings",
    "url": "/forum?id=IYMuTbGzjFU",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "topic model, text mining, distribution matching",
    "Abstract": "A topic model is often formulated as a generative model that explains how each word of a document is generated given a set of topics and document-specific topic proportions.  It is focused on capturing the word co-occurrences in a document and hence often suffers from poor performance in analyzing short documents. In addition, its parameter estimation often relies on approximate posterior inference that is either not scalable or suffering from large approximation error. This paper introduces a new topic-modeling framework where each document is viewed as a set of word embedding vectors and each topic is modeled as an embedding vector in the same embedding space. Embedding the words and topics in the same vector space, we define a method to measure the semantic difference between the embedding vectors of the words of a document and these of the topics, and optimize the topic embeddings to minimize the expected difference over all documents. Experiments on text analysis demonstrate that the proposed method, which is amenable to mini-batch stochastic gradient descent based optimization and hence scalable to big corpora, provides competitive performance in discovering more coherent and diverse topics and extracting better document representations.",
    "One-sentence Summary": "A novel method to learn in the word embedding space a set of globally shared topic embedding vectors that are manifested differently in each document"
  },
  {
    "title": "Generative Modeling with Optimal Transport Maps",
    "url": "/forum?id=5JdLZg346Lw",
    "date": "28 Sept 2021 (modified: 05 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Optimal Transport Map, Generative Modeling, Unpaired Image Restoration",
    "Abstract": "With the discovery of Wasserstein GANs, Optimal Transport (OT) has become a powerful tool for large-scale generative modeling tasks. In these tasks, OT cost is typically used as the loss for training GANs. In contrast to this approach, we show that the OT map itself can be used as a generative model, providing comparable performance. Previous analogous approaches consider OT maps as generative models only in the latent spaces due to their poor performance in the original high-dimensional ambient space. In contrast, we apply OT maps directly in the ambient space, e.g., a space of high-dimensional images. First, we derive a min-max optimization algorithm to efficiently compute OT maps for the quadratic cost (Wasserstein-2 distance). Next, we extend the approach to the case when the input and output distributions are located in the spaces of different dimensions and derive error bounds for the computed OT map. We evaluate the algorithm on image generation and unpaired image restoration tasks. In particular, we consider denoising, colorization, and inpainting, where the optimality of the restoration map is a desired attribute, since the output (restored) image is expected to be close to the input (degraded) one.",
    "One-sentence Summary": "While optimal transport cost serves as the loss for popular generative models, we demonstrate that the optimal transport map can be used as the generative model itself."
  },
  {
    "title": "Focus on the Common Good: Group Distributional Robustness Follows",
    "url": "/forum?id=irARV_2VFs4",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "sub-population shift, robust optimization, domain generalization",
    "Abstract": "We consider the problem of training a classification model with group annotated training data. Recent work has established that, if there is distribution shift across different groups, models trained using the standard empirical risk minimization (ERM) objective suffer from poor performance on minority groups and that group distributionally robust optimization (Group-DRO) objective is a better alternative. The starting point of this paper is the observation that though Group-DRO performs better than ERM on minority groups for some benchmark datasets, there are several other datasets where it performs much worse than ERM. Inspired by ideas from the closely related problem of domain generalization, this paper proposes a new and simple algorithm that explicitly encourages learning of features that are shared across various groups. The key insight behind our proposed algorithm is that while Group-DRO focuses on groups with worst regularized loss, focusing instead, on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group-DRO. Empirically, we show that our proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and Group-DRO on standard benchmarks on both minority groups and across all groups.  Theoretically, we show that the proposed algorithm is a descent method and finds first order stationary points of smooth nonconvex functions.",
    "One-sentence Summary": "We propose a new and simple algorithm for the sub-population shift problem that enables learning of shared features and performed consistently well over several standard, and real-world, benchmarks of the problem."
  },
  {
    "title": "Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification",
    "url": "/forum?id=PDYs7Z2XFGv",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Time series classification",
    "Abstract": "The size of the receptive field has been one of the most important factors for One Dimensional Convolutional Neural Networks (1D-CNNs) on time series classification tasks. Large efforts have been taken to choose the appropriate receptive field size, for it has a huge influence on the performance and differs significantly for each dataset. In this paper, we propose an Omni-Scale block (OS-block) for 1D-CNNs, where the kernel sizes are set by a simple and universal rule. OS-block can efficiently cover the best size of the receptive field across different datasets. This set of kernel sizes consists of multiple prime numbers according to the length of the time series. We experimentally show 1D-CNNs built from OS-block can consistently achieve the state-of-the-art accuracy with a smaller model size on five time series benchmarks, including both univariate and multivariate data from multiple domains. Comprehensive analysis and ablation studies shed light on how our rule finds the best receptive field size and demonstrate the consistency of our OS-block for multiple 1D-CNN structures.",
    "One-sentence Summary": "To extract features from time series data in proper time scales, many complicated scales searching or weighting methods have been proposed, but we will show that this could have been done via a very simple structure."
  },
  {
    "title": "Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space",
    "url": "/forum?id=QJWVP4CTmW4",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Face Clustering, Graph Convolutional Networks (GCN), Computer Vision",
    "Abstract": "Face clustering has attracted rising research interest recently to take advantage of massive amounts of face images on the web. State-of-the-art performance has been achieved by Graph Convolutional Networks (GCN) due to their powerful representation capacity. However, existing GCN-based methods build face graphs mainly according to $k$NN relations in the feature space, which may lead to a lot of noise edges connecting two faces of different classes. The face features will be polluted when messages pass along these noise edges, thus degrading the performance of GCNs. In this paper, a novel algorithm named Ada-NETS is proposed to cluster faces by constructing clean graphs for GCNs. In Ada-NETS, each face is transformed to a new structure space, obtaining robust features by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. It significantly reduces the noise edges while maintaining the good ones to build a graph with clean yet rich edges for GCNs to cluster faces. Experiments on multiple public clustering datasets show that Ada-NETS significantly outperforms current state-of-the-art methods, proving its superiority and generalization. Code is available at https://github.com/damo-cv/Ada-NETS.",
    "One-sentence Summary": "A novel algorithm named Ada-NETS is proposed to construct the clean graph for GCNs to cluster faces in this paper."
  },
  {
    "title": "Decoupled Adaptation for Cross-Domain Object Detection",
    "url": "/forum?id=VNqaB1g9393",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Object Detection, Domain Adaptation, Object Localization, Deep Learning, Transfer Learning",
    "Abstract": "Cross-domain object detection is more challenging than object classification since multiple objects exist in an image and the location of each object is unknown in the unlabeled target domain. As a result, when we adapt features of different objects to enhance the transferability of the detector, the features of the foreground and the background are easy to be confused, which may hurt the discriminability of the detector. Besides, previous methods focused on category adaptation but ignored another important part for object detection, i.e., the adaptation on bounding box regression. To this end, we propose D-adapt, namely Decoupled Adaptation, to decouple the adversarial adaptation and the training of the detector. Besides, we fill the blank of regression domain adaptation in object detection by introducing a bounding box adaptor. Experiments show that \\textit{D-adapt} achieves state-of-the-art results on four cross-domain object detection tasks and yields 17\\%  and 21\\% relative improvement on benchmark datasets Clipart1k and Comic2k in particular.",
    "One-sentence Summary": "To deal with the challenges in cross-domain object detection, we propose D-adapt to decouple the adversarial adaptation and the training of the detector, and also decouple the category adaptation and the bounding box adaptation."
  },
  {
    "title": "Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework",
    "url": "/forum?id=3Pbra-_u76D",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "point cloud representation, local relation, mlp",
    "Abstract": "Point cloud analysis is challenging due to irregularity and unordered data structure. To capture the 3D geometries, prior works mainly rely on exploring sophisticated local geometric extractors, using convolution, graph, or attention mechanisms. These methods, however, incur unfavorable latency during inference and the performance saturates over the past few years. In this paper, we present an ovel perspective on this task. We find detailed local geometrical informationprobably is not the key to point cloud analysis \u2013 we introduce a pure residual MLP network, called PointMLP, which integrates no local geometrical extractors but still performs very competitively. Equipped with a proposed lightweight geometric-affine module to stabilize the training, PointMLP delivers the new state-of-the-art on multiple datasets. On the real-world ScanObjectNN dataset, our method even surpasses the prior best method by 3.3% accuracy. We emphasize PointMLP achieves this strong performance without any sophisticated operations, hence leading to a prominent inference speed. Compared to most recent CurveNet, PointMLP trains 2\u00d7 faster, tests 7\u00d7 faster, and is more accurate on ModelNet40 benchmark. We hope our PointMLP may help the community towards a better understanding of point cloud analysis. The code is available at https://github.com/ma-xu/pointMLP-pytorch.",
    "One-sentence Summary": "In this paper, we present a new design for point cloud analysis , dubbed as PointMLP, which delivers new state-of-the-art results on multiple benchmarks and exhibits gratifying inference speed."
  },
  {
    "title": "New Insights on Reducing Abrupt Representation Change in Online Continual Learning",
    "url": "/forum?id=N8MaByOzUfb",
    "date": "28 Sept 2021 (modified: 22 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "continual learning",
    "Abstract": "In the online continual learning paradigm, agents must learn from a changing distribution while respecting memory and compute constraints. Experience Replay (ER), where a small subset of past data is stored and replayed alongside new data, has emerged as a simple and effective learning strategy. In this work, we focus on the change in representations of observed data that arises when previously unobserved classes appear in the incoming data stream, and new classes must be distinguished from previous ones. We shed new light on this question by showing that applying ER causes the newly added classes\u2019 representations to overlap significantly with the previous classes, leading to highly disruptive parameter updates.  Based on this empirical analysis, we propose a new method which mitigates this issue by shielding the learned representations from drastic adaptation to accommodate new classes. We show that using an asymmetric update rule pushes new classes to adapt to the older ones (rather than the reverse), which is more effective especially at task boundaries, where much of the forgetting typically occurs. Empirical results show significant gains over strong baselines on standard continual learning benchmarks.",
    "One-sentence Summary": "We study how representations shift at task boundaries in the single-head online continual learning setting, leading to a simple high performance method"
  },
  {
    "title": "Demystifying Batch Normalization in ReLU Networks: Equivalent Convex Optimization Models and Implicit Regularization",
    "url": "/forum?id=6XGgutacQ0B",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "batch normalization, ReLU networks, deep networks, convex optimization, whitening, implicit regularization, algorithmic bias",
    "Abstract": "Batch Normalization (BN) is a commonly used technique to accelerate and stabilize training of deep neural networks. Despite its empirical success, a full theoretical understanding of BN is yet to be developed. In this work, we analyze BN through the lens of convex optimization. We introduce an analytic framework based on convex duality to obtain exact convex representations of weight-decay regularized ReLU networks with BN, which can be trained in polynomial-time. Our analyses also show that optimal layer weights can be obtained as simple closed-form formulas in the high-dimensional and/or overparameterized regimes. Furthermore, we find that Gradient Descent provides an algorithmic bias effect on the standard non-convex BN network, and we design an approach to explicitly encode this implicit regularization into the convex objective. Experiments with CIFAR image classification highlight the effectiveness of this explicit regularization for mimicking and substantially improving the performance of standard BN networks.",
    "One-sentence Summary": "We introduce an analytic framework based on convex duality to obtain exact and polynomial-time trainable convex representations of weight-decay regularized ReLU networks with BN."
  },
  {
    "title": "Associated Learning: an Alternative to End-to-End Backpropagation that Works on CNN, RNN, and Transformer",
    "url": "/forum?id=4N-17dske79",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "pipeline training, parallel training, backpropagation, associated learning",
    "Abstract": "This paper studies Associate Learning (AL), an alternative methodology to the end-to-end backpropagation (BP).  We introduce the workflow to convert a neural network into a proper structure such that AL can be used to learn the weights for various types of neural networks.  We compared AL and BP on some of the most successful types of neural networks -- Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer.  Experimental results show that AL consistently outperforms BP on various open datasets.  We discuss possible reasons for AL's success and its limitations.",
    "One-sentence Summary": "This paper studies Associate Learning, an alternative methodology to the end-to-end backpropagation"
  },
  {
    "title": "MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts",
    "url": "/forum?id=MTex8qKavoS",
    "date": "28 Sept 2021 (modified: 14 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "benchmark dataset, distribution shift, out-of-domain generalization",
    "Abstract": "Understanding the performance of machine learning models across diverse data distributions is critically important for reliable applications. Motivated by this, there is a growing focus on curating benchmark datasets that capture distribution shifts. While valuable, the existing benchmarks are limited in that many of them only contain a small number of shifts and they lack systematic annotation about what is different across different shifts. We present MetaShift\u2014a collection of 12,868 sets of natural images across 410 classes\u2014to address this challenge. We leverage the natural heterogeneity of Visual Genome and its annotations to construct MetaShift. The key construction idea is to cluster images using its metadata, which provides context for each image (e.g. \u201ccats with cars\u201d or \u201ccats in bathroom\u201d) that represent distinct data distributions. MetaShift has two important benefits: first, it contains orders of magnitude more natural data shifts than previously available. Second, it provides explicit explanations of what is unique about each of its data sets and a distance score that measures the amount of distribution shift between any two of its data sets. We demonstrate the utility of MetaShift in benchmarking several recent proposals for training models to be robust to data shifts. We find that the simple empirical risk minimization performs the best when shifts are moderate and no method had a systematic advantage for large shifts. We also show how MetaShift can help to visualize conflicts between data subsets during model training.",
    "One-sentence Summary": "We leverage annotated subsets within a heterogeneous dataset to evaluate the performance of learning algorithms to distribution shifts and to visualize training dynamics."
  },
  {
    "title": "FP-DETR: Detection Transformer Advanced by Fully Pre-training",
    "url": "/forum?id=yjMQuLLcGWK",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Object Detection, Detection Transformer, Pre-training, Visual Prompt",
    "Abstract": "Large-scale pre-training has proven to be effective for visual representation learning on downstream tasks, especially for improving robustness and generalization. However, the recently developed detection transformers only employ pre-training on its backbone while leaving the key component, i.e., a 12-layer transformer, being trained from scratch, which prevents the model from above benefits. This separated training paradigm is mainly caused by the discrepancy between the upstream and downstream tasks. To mitigate the issue, we propose FP-DETR, a new method that Fully Pre-Trains an encoder-only transformer and smoothly fine-tunes it for object detection via a task adapter. Inspired by the success of textual prompts in NLP, we treat query positional embeddings as visual prompts to help the model attend to the target area (prompting) and recognize the object. To this end, we propose the task adapter which leverages self-attention to model the contextual relation between object query embedding. Experiments on the challenging COCO dataset demonstrate that our FP-DETR achieves competitive performance. Moreover, it enjoys better robustness to common corruptions and generalization to small-size datasets than state-of-the-art detection transformers. Code will be made publicly available at $\\url{https://github.com/encounter1997/FP-DETR}$."
  },
  {
    "title": "Efficient and Differentiable Conformal Prediction with General Function Classes",
    "url": "/forum?id=Ht85_jyihxp",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "uncertainty quantification, conformal prediction, prediction sets",
    "Abstract": "Quantifying the data uncertainty in learning tasks is often done by learning a prediction interval or prediction set of the label given the input. Two commonly desired properties for learned prediction sets are \\emph{valid coverage} and \\emph{good efficiency} (such as low length or low cardinality). Conformal prediction is a powerful technique for learning prediction sets with valid coverage, yet by default its conformalization step only learns a single parameter, and does not optimize the efficiency over more expressive function classes.\n          In this paper, we propose a generalization of conformal prediction to multiple learnable parameters, by considering the constrained empirical risk minimization (ERM) problem of finding the most efficient prediction set subject to valid empirical coverage. This meta-algorithm generalizes existing conformal prediction algorithms, and we show that it achieves approximate valid population coverage and near-optimal efficiency within class, whenever the function class in the conformalization step is low-capacity in a certain sense. Next, this ERM problem is challenging to optimize as it involves a non-differentiable coverage constraint. We develop a gradient-based algorithm for it by approximating the original constrained ERM using differentiable surrogate losses and Lagrangians. Experiments show that our algorithm is able to learn valid prediction sets and improve the efficiency significantly over existing approaches in several applications such as prediction intervals with improved length, minimum-volume prediction sets for multi-output regression, and label prediction sets for image classification.",
    "One-sentence Summary": "We generalize conformal prediction to learning multiple parameters within a general function class, to obtain an improved efficiency subject to valid coverage."
  },
  {
    "title": "Safe Neurosymbolic Learning with Differentiable Symbolic Execution",
    "url": "/forum?id=NYBmJN4MyZ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Verified Learning, Neurosymbolic Programs, Safe Learning, Symbolic Execution",
    "Abstract": "We study the problem of learning verifiably safe parameters for programs that use neural networks as well as symbolic, human-written code. Such neurosymbolic programs arise in many safety-critical domains. However, because they need not be differentiable, it is hard to learn their parameters using existing gradient-based approaches to safe learning. Our method, Differentiable Symbolic Execution (DSE), samples control flow paths in a program, symbolically constructs worst-case \"safety loss\" along these paths, and backpropagates the gradients of these losses through program operations using a generalization of the REINFORCE estimator. We evaluate the method on a mix of synthetic tasks and real-world benchmarks. Our experiments show that DSE significantly outperforms the state-of-the-art DiffAI method on these tasks.",
    "One-sentence Summary": "We present DSE, the first approach to worst-case-safe parameter learning for potentially non-differentiable neurosymbolic programs where we bridge symbolic execution and stochastic gradient estimator to learn the loss of safety properties."
  },
  {
    "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision",
    "url": "/forum?id=GUrhfTuf_3",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Vision-Language Pretraining, Multimodal Language Model, Weak Supervision",
    "Abstract": "With recent progress in joint modeling of visual and textual representations, Vision-Language Pretraining (VLP) has achieved impressive performance on many multimodal downstream tasks. However, the requirement for expensive annotations including clean image captions and regional labels limits the scalability of existing approaches, and complicates the pretraining procedure with the introduction of multiple dataset-specific objectives. In this work, we relax these constraints and present a minimalist pretraining framework, named Simple Visual Language Model (SimVLM). Unlike prior work, SimVLM reduces the training complexity by exploiting large-scale weak supervision, and is trained end-to-end with a single prefix language modeling objective. Without utilizing extra data or task-specific customization, the resulting model significantly outperforms previous pretraining methods and achieves new state-of-the-art results on a wide range of discriminative and generative vision-language benchmarks, including VQA (+3.74% vqa-score), NLVR2 (+1.17% accuracy), SNLI-VE (+1.37% accuracy) and image captioning tasks (+10.1% average CIDEr score). Furthermore, we demonstrate that SimVLM acquires strong generalization and transfer ability, enabling zero-shot behavior including open-ended visual question answering and cross-modality transfer."
  },
  {
    "title": "Bundle Networks: Fiber Bundles, Local Trivializations, and a Generative Approach to Exploring Many-to-one Maps",
    "url": "/forum?id=aBXzcPPOuX",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "generative models, applications of topology to deep learning, many-to-one maps, invertible neural nets",
    "Abstract": "Many-to-one maps are ubiquitous in machine learning, from the image recognition model that assigns a multitude of distinct images to the concept of \u201ccat\u201d to the time series forecasting model which assigns a range of distinct time-series to a single scalar regression value. While the primary use of such models is naturally to associate correct output to each input, in many problems it is also useful to be able to explore, understand, and sample from a model's fibers, which are the set of input values $x$ such that $f(x) = y,$ for fixed $y$ in the output space. In this paper we show that popular generative architectures are ill-suited to such tasks. Motivated by this, we introduce a novel generative architecture, Bundle Networks, based on the concept of a fiber bundle from (differential) topology. BundleNets exploit the idea of a local trivialization wherein a space can be locally decomposed into a product space that cleanly encodes the many-to-one nature of the map. By enforcing this decomposition in BundleNets and by utilizing state-of-the-art invertible components, investigating a network's fibers becomes natural.",
    "One-sentence Summary": "We draw from the theory of fiber bundles in (differential) topology to create a principled approach to generative models that allow us to learn and sample from the \"fiber\" over a point in a many-to-one map."
  },
  {
    "title": "Privacy Implications of Shuffling",
    "url": "/forum?id=5i2f-aR6B8H",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "local differential privacy, shuffle DP model",
    "Abstract": "\\ldp deployments are vulnerable to inference attacks as an adversary can link the noisy responses to their identity and subsequently, auxiliary information using the \\textit{order} of the data. An alternative model, shuffle \\textsf{DP}, prevents this by shuffling the noisy responses uniformly at random.  However, this limits the data learnability -- only symmetric functions (input order agnostic) can be learned. In this paper, we strike a balance and show that systematic shuffling of the noisy responses can thwart specific inference attacks while retaining some meaningful data learnability. To this end, we propose a novel privacy guarantee, \\name-privacy, that captures the privacy of the order of a data sequence. \\name-privacy allows tuning the granularity at which the ordinal information is maintained, which formalizes the degree the resistance to inference attacks trading it off with data learnability.  Additionally, we propose a novel shuffling mechanism that can achieve \\name-privacy and demonstrate the practicality of our mechanism via evaluation on real-world datasets.",
    "One-sentence Summary": "a novel formalization of the privacy offered by shuffling"
  },
  {
    "title": "On the role of population heterogeneity in emergent communication",
    "url": "/forum?id=5Qkd7-bZfI",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Populations have often been perceived as a structuring component for language to emerge and evolve: the larger the population, the more systematic the language. While this observation is widespread in the sociolinguistic literature, it has not been reproduced in computer simulations with neural agents. In this paper, we thus aim to clarify this apparent contradiction. We explore emergent language properties by varying agent population size in the speaker-listener Lewis Game. After reproducing the experimental paradox, we challenge the simulation assumption that the agent community is homogeneous. We first investigate how speaker-listener asymmetry alters language structure to examine two potential diversity factors: training speed and network capacity. We find out that emergent language properties are only altered by the relative difference of factors between speaker and listener, and not by their absolute values. From then, we leverage this observation to control population heterogeneity without introducing confounding factors. We finally show that introducing such training speed heterogeneities naturally sort out the initial paradox: larger simulated communities start developing more systematic and structured languages.",
    "One-sentence Summary": "This paper discusses the role of population heterogeneities in structuring emergent languages, partially resolving an apparent contraction between the psycho-linguistic and AI literature."
  },
  {
    "title": "Hindsight is 20/20: Leveraging Past Traversals to Aid 3D Perception",
    "url": "/forum?id=qsZoGvFiJn1",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "3D object detection, perception with historical context",
    "Abstract": "Self-driving cars must detect vehicles, pedestrians, and other traf\ufb01c participants accurately to operate safely. Small, far-away, or highly occluded objects are particularly challenging because there is limited information in the LiDAR point clouds for detecting them. To address this challenge, we leverage valuable information from the past: in particular, data collected in past traversals of the same scene. We posit that these past data, which are typically discarded, provide rich contextual information for disambiguating the above-mentioned challenging cases. To this end, we propose a novel end-to-end trainable Hindsight framework to extract this contextual information from past traversals and store it in an easy-to-query data structure, which can then be leveraged to aid future 3D object detection of the same scene. We show that this framework is compatible with most modern 3D detection architectures and can substantially improve their average precision on multiple autonomous driving datasets, most notably by more than 300% on the challenging cases. Our code is available at https://github.com/YurongYou/Hindsight."
  },
  {
    "title": "Language-driven Semantic Segmentation",
    "url": "/forum?id=RriDjddCLN",
    "date": "28 Sept 2021 (modified: 22 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "language-driven, semantic segmentation, zero-shot, transformer",
    "Abstract": "We present LSeg, a novel model for language-driven semantic image segmentation. LSeg uses a text encoder to compute embeddings of descriptive input labels (e.g., ``grass'' or ``building'') together with a transformer-based image encoder that computes dense per-pixel embeddings of the input image. The image encoder is trained with a contrastive objective to align pixel embeddings to the text embedding of the corresponding semantic class. The text embeddings provide a flexible label representation in which semantically similar labels map to similar regions in the embedding space (e.g., ``cat'' and ``furry''). This allows LSeg to generalize to previously unseen categories at test time, without retraining or even requiring a single additional training sample. We demonstrate that our approach achieves highly competitive zero-shot performance compared to existing zero- and few-shot semantic segmentation methods, and even matches the accuracy of traditional segmentation algorithms when a fixed label set is provided. Code and demo are available at https://github.com/isl-org/lang-seg.",
    "One-sentence Summary": "We present a language-driven approach that enables synthesis of zero-shot semantic segmentation models from arbitrary label sets at test time."
  },
  {
    "title": "Image BERT Pre-training with Online Tokenizer",
    "url": "/forum?id=ydopy-e6Dg",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "online tokenizer, masked image modeling, vision transformer",
    "Abstract": "The success of language Transformers is primarily attributed to the pretext task of masked language modeling (MLM), where texts are first tokenized into semantically meaningful pieces.\n        In this work, we study masked image modeling (MIM) and indicate the necessity and challenges of using a semantically meaningful visual tokenizer.\n        We present a self-supervised framework iBOT that can perform masked prediction with an online tokenizer. \n        Specifically, we perform self-distillation on masked patch tokens and take the teacher network as the online tokenizer, along with self-distillation on the class token to acquire visual semantics.\n        The online tokenizer is jointly learnable with the MIM objective and dispenses with a multi-stage training pipeline where the tokenizer needs to be pre-trained beforehand.\n        We show the prominence of iBOT by achieving an 82.3% linear probing accuracy and an 87.8% fine-tuning accuracy evaluated on ImageNet-1K.\n        Beyond the state-of-the-art image classification results, we underline emerging local semantic patterns, which helps the models to obtain strong robustness against common corruptions and achieve leading results on dense downstream tasks, e.g., object detection, instance segmentation, and semantic segmentation.",
    "One-sentence Summary": "We present a self-supervised framework iBOT that can perform masked image modeling with an online tokenizer, achieving the state-of-the-art results in downstream tasks."
  },
  {
    "title": "Accelerated Policy Learning with Parallel Differentiable Simulation",
    "url": "/forum?id=ZSKRQMvttc",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Robot Control, Policy Learning, Differentiable Simulation, Reinforcement Learning",
    "Abstract": "Deep reinforcement learning can generate complex control policies, but requires large amounts of training data to work effectively. Recent work has attempted to address this issue by leveraging differentiable simulators. However, inherent problems such as local minima and exploding/vanishing numerical gradients prevent these methods from being generally applied to control tasks with complex contact-rich dynamics, such as humanoid locomotion in classical RL benchmarks. In this work we present a high-performance differentiable simulator and a new policy learning algorithm (SHAC) that can effectively leverage simulation gradients, even in the presence of non-smoothness. Our learning algorithm alleviates problems with local minima through a smooth critic function, avoids vanishing/exploding gradients through a truncated learning window, and allows many physical environments to be run in parallel. We evaluate our method on classical RL control tasks, and show substantial improvements in sample efficiency and wall-clock time over state-of-the-art RL and differentiable simulation-based algorithms. In addition, we demonstrate the scalability of our method by applying it to the challenging high-dimensional problem of muscle-actuated locomotion with a large action space, achieving a greater than $17\\times$ reduction in training time over the best-performing established RL algorithm. More visual results are provided at: https://short-horizon-actor-critic.github.io/.",
    "One-sentence Summary": "We propose an efficient policy learning method leveraging the recent advance of differentiable simulation, and our method outperforms state-of-the-art algorithms in both sample efficiency and wall clock time on multiple challenging control tasks."
  },
  {
    "title": "Do We Need Anisotropic Graph Neural Networks?",
    "url": "/forum?id=hl9ePdHO4_s",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "graph neural networks, efficiency, latency reduction, memory reduction, architecture design, benchmarking, hardware-aware",
    "Abstract": "Common wisdom in the graph neural network (GNN) community dictates that anisotropic models---in which messages sent between nodes are a function of both the source and target node---are required to achieve state-of-the-art performance. Benchmarks to date have demonstrated that these models perform better than comparable isotropic models---where messages are a function of the source node only. In this work we provide empirical evidence challenging this narrative: we propose an isotropic GNN, which we call Efficient Graph Convolution (EGC), that consistently outperforms comparable anisotropic models, including the popular GAT or PNA architectures by using spatially-varying adaptive filters. In addition to raising important questions for the GNN community, our work has significant real-world implications for efficiency. EGC achieves higher model accuracy, with lower memory consumption and latency, along with characteristics suited to accelerator implementation, while being a drop-in replacement for existing architectures. As an isotropic model, it requires memory proportional to the number of vertices in the graph ($\\mathcal{O}(V)$); in contrast, anisotropic models require memory proportional to the number of edges ($\\mathcal{O}(E)$). We demonstrate that EGC outperforms existing approaches across 6 large and diverse benchmark datasets, and conclude by discussing questions that our work raise for the community going forward. Code and pretrained models for our experiments are provided at https://github.com/shyam196/egc.",
    "One-sentence Summary": "We find that using a simple adaptive filtering approach for GNNs improves performance over SOTA, while reducing model memory consumption and latency."
  },
  {
    "title": "Is High Variance Unavoidable in RL? A Case Study in Continuous Control",
    "url": "/forum?id=9xhgmsNVHu",
    "date": "28 Sept 2021 (modified: 05 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, continuous control",
    "Abstract": "Reinforcement learning (RL) experiments have notoriously high variance, and minor details can have disproportionately large effects on measured outcomes. This is problematic for creating reproducible research and also serves as an obstacle when applying RL to sensitive real-world applications. In this paper, we investigate causes for this perceived instability. To allow for an in-depth analysis, we focus on a specifically popular setup with high variance -- continuous control from pixels with an actor-critic agent. In this setting, we demonstrate that poor outlier runs which completely fail to learn are an important source of variance, but that weight initialization and initial exploration are not at fault. We show that one cause for these outliers is unstable network parametrization which leads to saturating nonlinearities. We investigate several fixes to this issue and find that simply normalizing penultimate features is surprisingly effective. For sparse tasks, we also find that partially disabling clipped double Q-learning decreases variance. By combining fixes we significantly decrease variances, lowering the average standard deviation across 21 tasks by a factor >3 for a state-of-the-art agent. This demonstrates that the perceived variance is not necessarily inherent to RL. Instead, it may be addressed via simple modifications and we argue that developing low-variance agents is an important goal for the RL community.",
    "One-sentence Summary": "we study sources of variance in RL and propose methods to decrease it."
  },
  {
    "title": "Simple GNN Regularisation for 3D Molecular Property Prediction and Beyond",
    "url": "/forum?id=1wVvweK3oIb",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, GNNs, Deep Learning, Molecular Property Prediction",
    "Abstract": "In this paper we show that simple noisy regularisation can be an effective way to address oversmoothing. We first argue that regularisers ad-dressing oversmoothing should both penalise node latent similarity and encourage meaningful node representations. From this observation we derive \u201cNoisy Nodes\u201d,a simple technique in which we corrupt the input graph with noise, and add a noise correcting node-level loss.  The diverse node level loss encourages latent node diversity, and the denoising objective encourages graph manifold learning.  Our regulariser applies well-studied methods in simple, straightforward ways which allow even generic architectures to overcome oversmoothing and achieve state of the art results on quantum chemistry tasks such as QM9 and Open Catalyst, and improve results significantly on Open Graph Benchmark (OGB) datasets.  Our results suggest Noisy Nodes can serve as a complementary building block in the GNN toolkit.",
    "One-sentence Summary": "A simple regularisation technique for GNNs applied to 3D molecular property prediction & beyond."
  },
  {
    "title": "Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative",
    "url": "/forum?id=2bO2x8NAIMB",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "pre-training, multitask learning, meta-learning, deeplearning, end-task aware training, NLP",
    "Abstract": "In most settings of practical concern, machine learning practitioners know in advance what end-task they wish to boost with auxiliary tasks. However, widely used methods for leveraging auxiliary data like pre-training and its continued-pretraining variant are end-task agnostic: they rarely, if ever, exploit knowledge of the target task. We study replacing end-task agnostic continued training of pre-trained language models with end-task aware training of said models. We argue that for sufficiently important end-tasks, the benefits of leveraging auxiliary data in a task-aware fashion can justify forgoing the traditional approach of obtaining generic, end-task agnostic representations as with (continued) pre-training. On three different low-resource NLP tasks from two domains, we demonstrate that  multi-tasking the end-task and auxiliary objectives results in significantly better downstream task performance than the widely-used task-agnostic continued pre-training paradigm of Gururangan et al. (2020).\n        We next introduce an online meta-learning algorithm that learns  a set of multi-task weights to better balance among our multiple auxiliary objectives, achieving further improvements on end-task performance and data efficiency.",
    "One-sentence Summary": "When we know the end-task objective in advance, instead of pre-training on auxiliary objectives  and then fine-tuning, we advocate for it to be introduced directly in training with auxiliary objectives"
  },
  {
    "title": "Learning Super-Features for Image Retrieval",
    "url": "/forum?id=wogsFPHwftY",
    "date": "28 Sept 2021 (modified: 31 Jan 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "image retrieval, landmark retrieval, mid-level features",
    "Abstract": "Methods that combine local and global features have recently shown excellent performance on multiple challenging deep image retrieval benchmarks, but their use of local features raises at least two issues. First, these local features simply boil down to the localized map activations of a neural network, and hence can be extremely redundant. Second, they are typically trained with a global loss that only acts on top of an aggregation of local features; by contrast, testing is based on local feature matching, which creates a discrepancy between training and testing. In this paper, we propose a novel architecture for deep image retrieval, based solely on mid-level features that we call Super-features. These Super-features are constructed by an iterative attention module and constitute an ordered set in which each element focuses on a localized and discriminant image pattern. For training, they require only image labels. A contrastive loss operates directly at the level of Super-features and focuses on those that match across images. A second complementary loss encourages diversity. Experiments on common landmark retrieval benchmarks validate that Super-features substantially outperform state-of-the-art methods when using the same number of features, and only require a significantly smaller memory footprint to match their performance. Code and models are available at: https://github.com/naver/FIRe.",
    "One-sentence Summary": "A novel image retrieval framework that learns mid-level features performing better and more compact that standard local ones"
  },
  {
    "title": "Online Facility Location with Predictions",
    "url": "/forum?id=DSQHjibtgKR",
    "date": "28 Sept 2021 (modified: 27 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "online algorithms, facility location, prediction, learning-augmented",
    "Abstract": "We provide nearly optimal algorithms for online facility location (OFL) with predictions. In OFL, $n$ demand points arrive in order and the algorithm must irrevocably assign each demand point to an open facility upon its arrival. The objective is to minimize the total connection costs from demand points to assigned facilities plus the facility opening cost. We further assume the algorithm is additionally given for each demand point $x_i$ a natural prediction $f_{x_i}^{\\mathrm{pred}}$ which is supposed to be the facility $f_{x_i}^{\\mathrm{opt}}$ that serves $x_i$ in the offline optimal solution.\n        \n        Our main result is an $O(\\min\\{\\log {\\frac{n\\eta_\\infty}{\\mathrm{OPT}}}, \\log{n} \\})$-competitive algorithm where $\\eta_\\infty$ is the maximum prediction error (i.e., the distance between $f_{x_i}^{\\mathrm{pred}}$ and $f_{x_i}^{\\mathrm{opt}}$). Our algorithm overcomes the fundamental $\\Omega(\\frac{\\log n}{\\log \\log n})$ lower bound of OFL (without predictions) when $\\eta_\\infty$ is small, and it still maintains $O(\\log n)$ ratio even when $\\eta_\\infty$ is unbounded. Furthermore, our theoretical analysis is supported by empirical evaluations for the tradeoffs between $\\eta_\\infty$ and the competitive ratio on various real datasets of different types.",
    "One-sentence Summary": "We give a nearly optimal robust algorithm for online facility location with predictions."
  },
  {
    "title": "Few-Shot Backdoor Attacks on Visual Object Tracking",
    "url": "/forum?id=qSV5CuSaK_a",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Backdoor Attack, Visual Object Tracking, AI Security, Deep Learning",
    "Abstract": "Visual object tracking (VOT) has been widely adopted in mission-critical applications, such as autonomous driving and intelligent surveillance systems. In current practice, third-party resources such as datasets, backbone networks, and training platforms are frequently used to train high-performance VOT models. Whilst these resources bring certain convenience, they also introduce new security threats into VOT models. In this paper, we reveal such a threat where an adversary can easily implant hidden backdoors into VOT models by tempering with the training process. Specifically, we propose a simple yet effective few-shot backdoor attack (FSBA) that optimizes two losses alternately: 1) a \\emph{feature loss} defined in the hidden feature space, and 2) the standard \\emph{tracking loss}. We show that, once the backdoor is embedded into the target model by our FSBA, it can trick the model to lose track of specific objects even when the \\emph{trigger} only appears in one or a few frames. We examine our attack in both digital and physical-world settings and show that it can significantly degrade the performance of state-of-the-art VOT trackers. We also show that our attack is resistant to potential defenses, highlighting the vulnerability of VOT models to potential backdoor attacks.",
    "One-sentence Summary": "We propose a simple yet effective backdoor attack against visual object tracking, which is effective in both digital and physical-world scenarios even if the trigger only appears in a few frames and resistant to potential defenses."
  },
  {
    "title": "Backdoor Defense via Decoupling the Training Process",
    "url": "/forum?id=TySnJ-0RdKI",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Backdoor Defense, Backdoor Learning",
    "Abstract": "Recent studies have revealed that deep neural networks (DNNs) are vulnerable to backdoor attacks, where attackers embed hidden backdoors in the DNN model by poisoning a few training samples. The attacked model behaves normally on benign samples, whereas its prediction will be maliciously changed when the backdoor is activated. We reveal that poisoned samples tend to cluster together in the feature space of the attacked DNN model, which is mostly due to the end-to-end supervised training paradigm. Inspired by this observation, we propose a novel backdoor defense via decoupling the original end-to-end training process into three stages. Specifically, we first learn the backbone of a DNN model via \\emph{self-supervised learning} based on training samples without their labels. The learned backbone will map samples with the same ground-truth label to similar locations in the feature space. Then, we freeze the parameters of the learned backbone and train the remaining fully connected layers via standard training with all (labeled) training samples. Lastly, to further alleviate side-effects of poisoned samples in the second stage, we remove labels of some `low-credible' samples determined based on the learned model and conduct a \\emph{semi-supervised fine-tuning} of the whole model. Extensive experiments on multiple benchmark datasets and DNN models verify that the proposed defense is effective in reducing backdoor threats while preserving high accuracy in predicting benign samples. Our code is available at \\url{https://github.com/SCLBD/DBD}.",
    "One-sentence Summary": "We reveal that the hidden backdoors are embedded in the feature space mostly due to the end-to-end supervised training paradigm, based on which we propose a simple yet effective decoupling-based training method for backdoor defense."
  },
  {
    "title": "Learning to Complete Code with Sketches",
    "url": "/forum?id=q79uMSC6ZBT",
    "date": "28 Sept 2021 (modified: 31 Jan 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "sketch, generative model, ml4code",
    "Abstract": "Code completion is usually cast as a language modelling problem, i.e., continuing an input in a left-to-right fashion. However, in practice, some parts of the completion (e.g., string literals) may be very hard to predict, whereas subsequent parts directly follow from the context.\n        To handle this, we instead consider the scenario of generating code completions with \"holes\" inserted in places where a model is uncertain. We develop Grammformer, a Transformer-based model that guides the code generation by the programming language grammar, and compare it to a variety of more standard sequence models.\n        \n        We train the models on code completion for C# and Python given partial code context. To evaluate models, we consider both ROUGE as well as a new metric RegexAcc that measures success of generating completions matching long outputs with as few holes as possible.\n        In our experiments, Grammformer generates 10-50% more accurate completions compared to traditional generative models and 37-50% longer sketches compared to sketch-generating baselines trained with similar techniques.",
    "One-sentence Summary": "Autocomplete code sketches, placing holes where ambiguity prevents us predicting terminal tokens."
  },
  {
    "title": "Reverse Engineering of Imperceptible Adversarial Image Perturbations",
    "url": "/forum?id=gpp7cf0xdfN",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reverse Engineering of Deceptions, adversarial examples, denoising, neural networks, interpretability",
    "Abstract": "It has been well recognized that neural network based image classifiers are easily fooled by images with tiny perturbations crafted by an adversary. There has been a vast volume of research to generate and defend such adversarial attacks. However, the following problem is left unexplored: How to reverse-engineer adversarial perturbations from an adversarial image? This leads to a new adversarial learning paradigm\u2014Reverse Engineering of Deceptions (RED). If successful, RED allows us to estimate adversarial perturbations and recover the original images. However, carefully crafted, tiny adversarial perturbations are difficult to recover by optimizing a unilateral RED objective. For example, the pure image denoising method may overfit to minimizing the reconstruction error but hardly preserve the classification properties of the true adversarial perturbations.  To tackle this challenge, we formalize the RED problem and identify a set of principles crucial to the RED approach design. Particularly, we find that prediction alignment and proper data augmentation (in terms of spatial transformations) are two criteria to achieve a generalizable RED approach. By integrating these RED principles with image denoising, we propose a new Class-Discriminative Denoising based RED framework, termed CDD-RED. Extensive experiments demonstrate the effectiveness of CDD-RED under different evaluation metrics (ranging from the pixel-level, prediction-level to the attribution-level alignment) and a variety of attack generation methods (e.g., FGSM, PGD, CW, AutoAttack, and adaptive attacks).",
    "One-sentence Summary": "Reverse engineer adversarial image perturbations with a denoiser-based framework."
  },
  {
    "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
    "url": "/forum?id=oMI9PjOb9Jl",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Object detection, Transformer",
    "Abstract": "We present in this paper a novel query formulation using dynamic anchor boxes for DETR (DEtection TRansformer) and offer a deeper understanding of the role of queries in DETR. This new formulation directly uses box coordinates as queries in Transformer decoders and dynamically updates them layer by layer. Using box coordinates not only helps using explicit positional priors to improve the query-to-feature similarity and eliminate the slow training convergence issue in DETR, but also allows us to modulate the positional attention map using the box width and height information. Such a design makes it clear that queries in DETR can be implemented as performing soft ROI pooling layer by layer in a cascade manner. As a result, it leads to the best performance on the MS-COCO benchmark among the DETR-like detection models under the same setting, e.g., AP 45.7\\% using ResNet50-DC5 as backbone trained in 50 epochs. We also conducted extensive experiments to confirm our analysis and verify the effectiveness of our methods. Code is available at \\url{https://github.com/IDEA-opensource/DAB-DETR}.",
    "One-sentence Summary": "We present in this paper a novel query formulation using dynamic anchor boxes for DETR and offer a deeper understanding of the role of queries in DETR."
  },
  {
    "title": "On the Certified Robustness for Ensemble Models and Beyond",
    "url": "/forum?id=tUa4REjGjTf",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "robustness, ensemble, certified robustness",
    "Abstract": "Recent studies show that deep neural networks (DNN) are vulnerable to adversarial examples, which aim to mislead DNNs by adding perturbations with small magnitude. To defend against such attacks, both empirical and theoretical defense approaches have been extensively studied for a single ML model. In this work, we aim to analyze and provide the certified robustness for ensemble ML models, together with the sufficient and necessary conditions of robustness for different ensemble protocols. Although ensemble models are shown more robust than a single model empirically; surprisingly, we find that in terms of the certified robustness the standard ensemble models only achieve marginal improvement compared to a single model. Thus, to explore the conditions that guarantee to provide certifiably robust ensemble ML models, we first prove that diversified gradient and large confidence margin are sufficient and necessary conditions for certifiably robust ensemble models under the model-smoothness assumption. We then provide the bounded model-smoothness analysis based on the proposed Ensemble-before-Smoothing strategy. We also prove that an ensemble model can always achieve higher certified robustness than a single base model under mild conditions. Inspired by the theoretical findings, we propose the lightweight Diversity Regularized Training (DRT) to train certifiably robust ensemble ML models. Extensive experiments show that our DRT enhanced ensembles can consistently achieve higher certified robustness than existing single and ensemble ML models, demonstrating the state-of-the-art certified $L_2$-robustness on MNIST, CIFAR-10, and ImageNet datasets.",
    "One-sentence Summary": "Inspired by theoretical analysis, we propose Diversity Regularized Training to enhance the certified robustness of ensemble models and DRT significantly outperforms existing methods."
  },
  {
    "title": "Efficient Neural Causal Discovery without Acyclicity Constraints",
    "url": "/forum?id=eYciPrLuUhG",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Causal discovery, structure learning",
    "Abstract": "Learning the structure of a causal graphical model using both observational and interventional data is a fundamental problem in many scientific fields. A promising direction is continuous optimization for score-based methods, which, however, require constrained optimization to enforce acyclicity or lack convergence guarantees. In this paper, we present ENCO, an efficient structure learning method for directed, acyclic causal graphs leveraging observational and interventional data. ENCO formulates the graph search as an optimization of independent edge likelihoods, with the edge orientation being modeled as a separate parameter. Consequently, we provide for ENCO convergence guarantees under mild conditions, without having to constrain the score function with respect to acyclicity. In experiments, we show that ENCO can efficiently recover graphs with hundreds of nodes, an order of magnitude larger than what was previously possible, while handling deterministic variables and discovering latent confounders.",
    "One-sentence Summary": "We present ENCO, an efficient structure learning method that leverages observational and interventional data and scales to graphs with a thousand variables."
  },
  {
    "title": "Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint Localization",
    "url": "/forum?id=6Q52pZ-Th7N",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Keypoint Localization, Semi-Supervised Learning, Curriculum Learning",
    "Abstract": "Localizing keypoints of an object is a basic visual problem. However, supervised learning of a keypoint localization network often requires a large amount of data, which is expensive and time-consuming to obtain. To remedy this, there is an ever-growing interest in semi-supervised learning (SSL), which leverages a small set of labeled data along with a large set of unlabeled data. Among these SSL approaches, pseudo-labeling (PL) is one of the most popular. PL approaches apply pseudo-labels to unlabeled data, and then train the model with a combination of the labeled and pseudo-labeled data iteratively. The key to the success of PL is the selection of high-quality pseudo-labeled samples. Previous works mostly select training samples by manually setting a single confidence threshold. We propose to automatically select reliable pseudo-labeled samples with a series of dynamic thresholds, which constitutes a learning curriculum.Extensive experiments on five keypoint localization benchmark datasets demonstrate that the proposed approach significantly outperforms the previous state-of-the-art SSL approaches.",
    "One-sentence Summary": "The first work that explores automatic curriculum learning for semi-supervised keypoint localization"
  },
  {
    "title": "Signing the Supermask: Keep, Hide, Invert",
    "url": "/forum?id=e0jtGTfPihs",
    "date": "28 Sept 2021 (modified: 14 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Neural Networks, Supermask, Lottery Ticket Hypothesis, Pruning, Weight Initialization, Interpretation, Subnetworks",
    "Abstract": "The exponential growth in numbers of parameters of neural networks over the past years has been accompanied by an increase in performance across several fields. However, due to their sheer size, the networks not only became difficult to interpret but also problematic to train and use in real-world applications, since hardware requirements increased accordingly. \n        Tackling both issues, we present a novel approach that either drops a neural network's initial weights or inverts their respective sign. \n        Put simply, a network is trained by weight selection and inversion without changing their absolute values.\n        Our contribution extends previous work on masking by additionally sign-inverting the initial weights and follows the findings of the Lottery Ticket Hypothesis.\n        Through this extension and adaptations of initialization methods, we achieve a pruning rate of up to 99%, while still matching or exceeding the performance of various baseline and previous models.\n        Our approach has two main advantages.\n        First, and most notable, signed Supermask models drastically simplify a model's structure, while still performing well on given tasks.\n        Second, by reducing the neural network to its very foundation, we gain insights into which weights matter for performance. \n        The code is available on GitHub.",
    "One-sentence Summary": "We train neural networks by weight selection and sign inversion instead of optimizing the values of weights which achieves consistent pruning rates of up to 99% while maintaining competitive performance."
  },
  {
    "title": "Bootstrapping Semantic Segmentation with Regional Contrast",
    "url": "/forum?id=6u6N8WWwYSM",
    "date": "28 Sept 2021 (modified: 18 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "semi-supervised learning, semantic segmentation, contrastive learning",
    "Abstract": "We present ReCo, a contrastive learning framework designed at a regional level to assist learning in semantic segmentation. ReCo performs pixel-level contrastive learning on a sparse set of hard negative pixels, with minimal additional memory footprint. ReCo is easy to implement, being built on top of off-the-shelf segmentation networks, and consistently improves performance, achieving more accurate segmentation boundaries and faster convergence. The strongest effect is in semi-supervised learning with very few labels. With ReCo, we achieve high quality semantic segmentation model, requiring only 5 examples of each semantic class.",
    "One-sentence Summary": "We present a pixel-level contrastive learning framework to achieve a high-quality semantic segmeantation model trained with very few human annotations."
  },
  {
    "title": "Generative Principal Component Analysis",
    "url": "/forum?id=pgir5f7ekAL",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Principal component analysis, generative models, sparse principal component analysis, projected power methods, optimal statistical rates",
    "Abstract": "In this paper, we study the problem of principal component analysis with generative modeling assumptions, adopting a general model for the observed matrix that encompasses notable special cases, including spiked matrix recovery and phase retrieval. The key assumption is that the first principal eigenvector lies near the range of an $L$-Lipschitz continuous generative model with bounded $k$-dimensional inputs. We propose a quadratic estimator, and show that it enjoys a statistical rate of order $\\sqrt{\\frac{k\\log L}{m}}$, where $m$ is the number of samples. Moreover, we provide a variant of the classic power method, which projects the calculated data onto the range of the generative model during each iteration. We show that under suitable conditions, this method converges exponentially fast to a point achieving the above-mentioned statistical rate. This rate is conjectured in~\\citep{aubin2019spiked,cocola2020nonasymptotic} to be the best possible even when we only restrict to the special case of spiked matrix models. We perform experiments on various image datasets for spiked matrix and phase retrieval models, and illustrate performance gains of our method to the classic power method and the truncated power method devised for sparse principal component analysis.",
    "One-sentence Summary": "We study the problem of principal component analysis with generative modeling assumptions, and provide a corresponding efficient algorithm with provable guarantees."
  },
  {
    "title": "Pareto Policy Pool for Model-based Offline Reinforcement Learning",
    "url": "/forum?id=OqcZu8JIIzS",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "model-based offline RL, Pareto front, multi-objective optimization, policy pool, model return-uncertainty trade-off",
    "Abstract": "Online reinforcement learning (RL) can suffer from poor exploration, sparse reward, insufficient data, and overhead caused by inefficient interactions between an immature policy and a complicated environment. Model-based offline RL instead trains an environment model using a dataset of pre-collected experiences so online RL methods can learn in an offline manner by solely interacting with the model. However, the uncertainty and accuracy of the environment model can drastically vary across different state-action pairs so the RL agent may achieve high model return but perform poorly in the true environment. Unlike previous works that need to carefully tune the trade-off between the model return and uncertainty in a single objective, we study a bi-objective formulation for model-based offline RL that aims at producing a pool of diverse policies on the Pareto front performing different levels of trade-offs, which provides the flexibility to select the best policy for each realistic environment from the pool. Our method, ''Pareto policy pool (P3)'', does not need to tune the trade-off weight but can produce policies allocated at different regions of the Pareto front. For this purpose, we develop an efficient algorithm that solves multiple bi-objective optimization problems with distinct constraints defined by reference vectors targeting diverse regions of the Pareto front. We theoretically prove that our algorithm can converge to the targeted regions. In order to obtain more Pareto optimal policies without linearly increasing the cost, we leverage the achieved policies as initialization to find more Pareto optimal policies in their neighborhoods. On the D4RL benchmark for offline RL, P3 substantially outperforms several recent baseline methods over multiple tasks, especially when the quality of pre-collected experiences is low.",
    "One-sentence Summary": "We propose a model-based offline RL method that builds a diverse set of optimal policies on Pareto front providing different levels of model return-uncertainty trade-off and it significantly outperforms single-policy methods."
  },
  {
    "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks",
    "url": "/forum?id=kOu3-S3wJ7",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "graph neural networks, missing data, time series analysis, time series imputation",
    "Abstract": "Dealing with missing values and incomplete time series is a labor-intensive, tedious, inevitable task when handling data coming from real-world applications. Effective spatio-temporal representations would allow imputation methods to reconstruct missing temporal data by exploiting information coming from sensors at different locations. However, standard methods fall short in capturing the nonlinear time and space dependencies existing within networks of interconnected sensors and do not take full advantage of the available - and often strong - relational information. Notably, most state-of-the-art imputation methods based on deep learning do not explicitly model relational aspects and, in any case, do not exploit processing frameworks able to adequately represent structured spatio-temporal data. Conversely, graph neural networks have recently surged in popularity as both expressive and scalable tools for processing sequential data with relational inductive biases. In this work, we present the first assessment of graph neural networks in the context of multivariate time series imputation. In particular, we introduce a novel graph neural network architecture, named GRIN, which aims at reconstructing missing data in the different channels of a multivariate time series by learning spatio-temporal representations through message passing. Empirical results show that our model outperforms state-of-the-art methods in the imputation task on relevant real-world benchmarks with mean absolute error improvements often higher than 20%.",
    "One-sentence Summary": "We propose a graph neural network architecture for multivariate time series imputation and achieve state-of-the-art results on several benchmarks."
  },
  {
    "title": "An Unconstrained Layer-Peeled Perspective on Neural Collapse",
    "url": "/forum?id=WZ3yjh8coDg",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural collapse, uncostrained model, implicit regularization",
    "Abstract": "Neural collapse is a highly symmetric geometry of neural networks that emerges during the terminal phase of training, with profound implications on the generalization performance and robustness of the trained networks. To understand how the last-layer features and classifiers exhibit this recently discovered implicit bias, in this paper, we introduce a surrogate model called the unconstrained layer-peeled model (ULPM). We prove that gradient flow on this model converges to critical points of a minimum-norm separation problem exhibiting neural collapse in its global minimizer. Moreover, we show that the ULPM with the cross-entropy loss has a benign global landscape for its loss function, which allows us to prove that all the critical points are strict saddle points except the global minimizers that exhibit the neural collapse phenomenon. Empirically, we show that our results also hold during the training of neural networks in real-world tasks when explicit regularization or weight decay is not used.",
    "One-sentence Summary": "We investigate how the gradient flow converges to a neural collapse solution in an unconstrained model."
  },
  {
    "title": "Contrastive Clustering to Mine Pseudo Parallel Data for Unsupervised Translation",
    "url": "/forum?id=pN1JOdrSY9",
    "date": "28 Sept 2021 (modified: 14 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "machine translation, unsupervised machine translation, pseudo-parallel data, contrastive clustering, pretraining",
    "Abstract": "Modern unsupervised machine translation systems mostly train their models by generating synthetic parallel training data from large unlabeled monolingual corpora of different languages through various means, such as iterative back-translation. However, there may exist small amount of actual parallel data hidden in the sea of unlabeled data, which has not been exploited. We develop a new fine-tuning objective, called Language-Agnostic Constraint for SwAV loss, or LAgSwAV, which enables a pre-trained model to extract such pseudo-parallel data from the monolingual corpora in a fully unsupervised manner. We then propose an effective strategy to utilize the obtained synthetic data to augment unsupervised machine translation. Our method achieves the state of the art in the WMT'14 English-French, WMT'16 German-English and English-Romanian bilingual unsupervised translation tasks, with 40.2, 36.8, 37.0 BLEU, respectively. We also achieve substantial improvements in the FLoRes low-resource English-Nepali and English-Sinhala unsupervised tasks with 5.3 and 5.4 BLEU, respectively.",
    "One-sentence Summary": "We propose a fine-tuning loss that enables pre-trained model's ability to mine pseudo-parallel data for fully unsupervised machine translation."
  },
  {
    "title": "Multimeasurement Generative Models",
    "url": "/forum?id=QRX0nCX_gk",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "energy based models, Langevin MCMC, score matching, denoising autoencoders, empirical Bayes",
    "Abstract": "We formally map the problem of sampling from an unknown distribution with a density in $\\mathbb{R}^d$ to the problem of learning and sampling a smoother density in $\\mathbb{R}^{Md}$ obtained by convolution with a fixed factorial kernel: the new density is referred to as M-density and the kernel as multimeasurement noise model (MNM). The M-density in $\\mathbb{R}^{Md}$ is smoother than the original density in $\\mathbb{R}^d$, easier to learn and sample from, yet for large $M$ the two problems are mathematically equivalent since clean data can be estimated exactly given a multimeasurement noisy observation using the Bayes estimator. To formulate the problem, we derive the Bayes estimator for Poisson and Gaussian MNMs in closed form in terms of the unnormalized M-density. This leads to a simple least-squares objective for learning parametric energy and score functions. We present various parametrization schemes of interest including one in which studying Gaussian M-densities directly leads to multidenoising autoencoders\u2014this is the first theoretical connection made between denoising autoencoders and empirical Bayes in the literature.  Samples in $\\mathbb{R}^d$ are obtained by walk-jump sampling (Saremi & Hyvarinen, 2019) via underdamped Langevin MCMC (walk) to sample from M-density and the multimeasurement Bayes estimation (jump). We study permutation invariant Gaussian M-densities on MNIST, CIFAR-10, and FFHQ-256 datasets, and demonstrate the effectiveness of this framework for realizing fast-mixing stable Markov chains in high dimensions."
  },
  {
    "title": "Information Gain Propagation: a New Way to Graph Active Learning with Soft Labels",
    "url": "/forum?id=USC0-nvGPK",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Active Learning, Graph, Information Gain",
    "Abstract": "Graph Neural Networks (GNNs) have achieved great success in various tasks, but their performance highly relies on a large number of labeled nodes, which typically requires considerable human effort. GNN-based Active Learning (AL) methods are proposed to improve the labeling efficiency by selecting the most valuable nodes to label. Existing methods assume an oracle can correctly categorize all the selected nodes and thus just focus on the node selection. However, such an exact labeling task is costly, especially when the categorization is out of the domain of individual expert (oracle). The paper goes further, presenting a soft-label approach to AL on GNNs. Our key innovations are: i) relaxed queries where a domain expert (oracle) only judges the correctness of the predicted labels (a binary question) rather than identifying the exact class (a multi-class question), and ii) new criteria of maximizing information gain propagation for active learner with relaxed queries and soft labels. Empirical studies on public datasets demonstrate that our method significantly outperforms the state-of-the-art GNN-based AL methods in terms of both accuracy and labeling cost.",
    "One-sentence Summary": "A new way to graph active learning with soft labels"
  },
  {
    "title": "Constructing Orthogonal Convolutions in an Explicit Manner",
    "url": "/forum?id=Zr5W2LSRhD",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Convolutions with orthogonal input-output Jacobian matrix, i.e., orthogonal convolution,  have recently attracted substantial attention.  A convolution layer with an orthogonal Jacobian matrix is 1-Lipschitz  in the  2-norm, making the output robust to the perturbation in input. Meanwhile, an orthogonal Jacobian matrix preserves the gradient norm in back-propagation, which is critical for stable training deep networks. Nevertheless,  existing orthogonal convolutions are burdened by high computational costs for preserving orthogonality.\n        In this work, we exploit the relation between the singular values of the convolution layer's  Jacobian and the structure of the convolution kernel.  To achieve orthogonality, we explicitly construct the convolution kernel for enforcing all singular values of the convolution layer's Jacobian to be $1$s.   After training,  the explicitly constructed orthogonal (ECO) convolution is constructed only once, and their weights are stored. Then,  in evaluation, we only need to load the stored weights of the trained  ECO convolution, and the computational cost of ECO convolution is the same as the standard dilated convolution. It is more efficient than the recent state-of-the-art approach, skew orthogonal convolution (SOC) in evaluation.    Experiments on CIFAR-10 and CIFAR-100  demonstrate that the proposed ECO convolution is faster than SOC in evaluation while leading to competitive standard and certified robust accuracies."
  },
  {
    "title": "X-model: Improving Data Efficiency in Deep Learning with A Minimax Model",
    "url": "/forum?id=P3Bh01hBYTH",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Data Efficiency, Deep Learning, Minimax Model",
    "Abstract": "To mitigate the burden of data labeling, we aim at improving data efficiency for both classification and regression setups in deep learning. However, the current focus is on classification problems while rare attention has been paid to deep regression, which usually requires more human effort to labeling. Further, due to the intrinsic difference between categorical and continuous label space, the common intuitions for classification, \\textit{e.g.} cluster assumptions or pseudo labeling strategies, cannot be naturally adapted into deep regression. To this end, we first delved into the existing data-efficient methods in deep learning and found that they either encourage invariance to \\textit{data stochasticity} (\\textit{e.g.}, consistency regularization under different augmentations) or \\textit{model stochasticity} (\\textit{e.g.}, difference penalty for predictions of models with different dropout). To take the power of both worlds, we propose a novel \\Chi-model by simultaneously encouraging the invariance to {data stochasticity} and {model stochasticity}. Further, the \\Chi-model plays a minimax game between the feature extractor and task-specific heads to further enhance the invariance to model stochasticity. Extensive experiments verify the superiority of the \\Chi-model among various tasks, from a single-value prediction task of age estimation to a dense-value prediction task of keypoint localization, a 2D synthetic and a 3D realistic dataset, as well as a multi-category object recognition task.",
    "One-sentence Summary": "This paper proposes a novel X-Model for improving data efficiency in deep learning with a minimax model."
  },
  {
    "title": "Stein Latent Optimization for Generative Adversarial Networks",
    "url": "/forum?id=2-mkiUs9Jx7",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generative Adversarial Networks, Unsupervised Conditional GANs",
    "Abstract": "Generative adversarial networks (GANs) with clustered latent spaces can perform conditional generation in a completely unsupervised manner. In the real world, the salient attributes of unlabeled data can be imbalanced. However, most of existing unsupervised conditional GANs cannot cluster attributes of these data in their latent spaces properly because they assume uniform distributions of the attributes. To address this problem, we theoretically derive Stein latent optimization that provides reparameterizable gradient estimations of the latent distribution parameters assuming a Gaussian mixture prior in a continuous latent space. Structurally, we introduce an encoder network and novel unsupervised conditional contrastive loss to ensure that data generated from a single mixture component represent a single attribute. We confirm that the proposed method, named Stein Latent Optimization for GANs (SLOGAN), successfully learns balanced or imbalanced attributes and achieves state-of-the-art unsupervised conditional generation performance even in the absence of attribute information (e.g., the imbalance ratio). Moreover, we demonstrate that the attributes to be learned can be manipulated using a small amount of probe data.",
    "One-sentence Summary": "We propose a novel GAN method that performs unsupervised conditional generation robustly on real-world datasets with balanced or imbalanced attributes even in the absence of attribute information (e.g., the imbalance ratio)"
  },
  {
    "title": "Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity",
    "url": "/forum?id=RRGVCN8kjim",
    "date": "28 Sept 2021 (modified: 02 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Transformer Query Sparsification Mechanism, Efficient End-to-End Object Detection",
    "Abstract": "DETR is the first end-to-end object detector using a transformer encoder-decoder architecture and demonstrates competitive performance but low computational efficiency. The subsequent work, Deformable DETR, enhances the efficiency of DETR by replacing dense attention with deformable attention, which achieves 10x faster convergence and improved performance. Using the multiscale feature to ameliorate performance, however, the number of encoder queries increases by 20x compared to DETR, and the computation cost of the encoder attention remains a bottleneck. We observe that the encoder queries referenced by the decoder account for only 45% of the total, and find out the detection accuracy does not deteriorate significantly even if only the referenced queries are polished in the encoder block. Inspired by this observation, we propose Sparse DETR that selectively updates only the queries expected to be referenced by the decoder, thus help the model effectively detect objects. In addition, we show that applying an auxiliary detection loss on the selected queries in the encoder improves the performance while minimizing computational overhead. We validate that Sparse DETR achieves better performance than Deformable DETR even with only 10% encoder queries on the COCO dataset. Albeit only the encoder queries are sparsified, the total computation cost decreases by 38% and the frames per second (FPS) increases by 42% compared to Deformable DETR. Code will be released.",
    "One-sentence Summary": "Sparse DETR is an efficient end-to-end object detector that sparsifies encoder queries by using the learnable decoder attention map predictor. It achieves better performance than Deformable DETR even with only 10% encoder queries on the COCO dataset."
  },
  {
    "title": "Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs",
    "url": "/forum?id=HMJdXzbWKH",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Q Learning, RL with Function Approximation, Experience Replay, Online Target Learning",
    "Abstract": "Q-learning is a popular Reinforcement Learning (RL) algorithm which is widely used in practice with function approximation (Mnih et al., 2015). In contrast, existing theoretical results are pessimistic about Q-learning. For example, (Baird, 1995) shows that Q-learning does not converge even with linear function approximation for linear MDPs. Furthermore, even for tabular MDPs with synchronous updates, Q-learning was shown to have sub-optimal sample complexity (Li et al., 2021, Azar et al., 2013). The goal of this work is to bridge the gap between practical success of Q-learning and the relatively pessimistic theoretical results. The starting point of our work is the observation that in practice, Q-learning is used with two important modifications: (i) training with two networks, called online network and target network simultaneously (online target learning, or OTL) , and (ii) experience replay (ER) (Mnih et al., 2015). While they have been observed to play a significant role in the practical success of Q-learning, a thorough theoretical understanding of how these two modifications improve the convergence behavior of Q-learning has been missing in literature. By carefully combining the Q-learning with OTL and reverse experience replay (RER) (a form of experience replay), we present novel methods Q-Rex and Q-RexDaRe (Q-Rex+data reuse). We show that Q-Rex efficiently finds the optimal policy for linear MDPs and provide non-asymptotic bounds on sample complexity -- the first such result for a Q-learning method with linear MDPs. Furthermore, we demonstrate that Q-RexDaRe in fact achieves near optimal sample complexity in the tabular setting, improving upon the existing results for vanilla Q-learning."
  },
  {
    "title": "Differentially Private Fractional Frequency Moments Estimation with Polylogarithmic Space",
    "url": "/forum?id=7I8LPkcx8V",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Differential Privacy, Fractional Frequency Moments",
    "Abstract": "We prove that $\\mathbb{F}_p$ sketch, a well-celebrated streaming algorithm for frequency moments estimation, is differentially private as is when $p\\in(0, 1]$. $\\mathbb{F}_p$ sketch uses only polylogarithmic space, exponentially better than existing DP baselines and only worse than the optimal non-private baseline by a logarithmic factor. The evaluation shows that $\\mathbb{F}_p$ sketch can achieve reasonable accuracy with strong privacy guarantees. The code for evaluation is included in the supplementary material.",
    "One-sentence Summary": "We prove that $\\mathbb{F}_p$ sketch, a well-celebrated streaming algorithm for frequency moments estimation, is differentially private as is when $p\\in(0, 1]$."
  },
  {
    "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training",
    "url": "/forum?id=YpSxqy_RE84",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "low-precision training, meta-learning, Pareto frontier, error-memory tradeoff, active learning, matrix factorization",
    "Abstract": "Low-precision arithmetic trains deep learning models using less energy, less memory and less time. However, we pay a price for the savings: lower precision may yield larger round-off error and hence larger prediction error. As applications proliferate, users must choose which precision to use to train a new model, and chip manufacturers must decide which precisions to manufacture. We view these precision choices as a hyperparameter tuning problem, and borrow ideas from meta-learning to learn the tradeoff between memory and error. In this paper, we introduce Pareto Estimation to Pick the Perfect Precision (PEPPP). We use matrix factorization to find non-dominated configurations (the Pareto frontier) with a limited number of network evaluations. For any given memory budget, the precision that minimizes error is a point on this frontier. Practitioners can use the frontier to trade memory for error and choose the best precision for their goals.",
    "One-sentence Summary": "Given a dataset and a memory budget, we use matrix factorization and active learning to efficiently pick the perfect low-precision configuration for a neural network."
  },
  {
    "title": "In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications",
    "url": "/forum?id=rUwm9wCjURV",
    "date": "28 Sept 2021 (modified: 02 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep Reinforcement Learning, Out-Of-Distribution Generalisation, Temporal Logic",
    "Abstract": "We address the problem of building agents whose goal is to learn to execute out-of distribution (OOD) multi-task instructions expressed in temporal logic (TL) by using deep reinforcement learning (DRL). Recent works provided evidence that the agent's neural architecture is a key feature when DRL agents are learning to solve OOD tasks in TL. Yet, the studies on this topic are still in their infancy. In this work, we propose a new deep learning configuration with inductive biases that lead agents to generate latent representations of their current goal, yielding a stronger generalization performance. We use these latent-goal networks within a neuro-symbolic framework that executes multi-task formally-defined instructions and contrast the performance of the proposed neural networks against employing different state-of-the-art (SOTA) architectures when generalizing to unseen instructions in OOD environments.",
    "One-sentence Summary": "Inducing architectures to generate low-dimensional representations of their current goal processing observations and instructions together yields stronger out-of-distribution generalisation"
  },
  {
    "title": "Discrete Representations Strengthen Vision Transformer Robustness",
    "url": "/forum?id=8hWs60AZcWk",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "vision transformer, robustness, image recognition",
    "Abstract": "Vision Transformer (ViT) is emerging as the state-of-the-art architecture for image recognition. While recent studies suggest that ViTs are more robust than their convolutional counterparts, our experiments find that ViTs are overly reliant on local features (\\eg, nuisances and texture) and fail to make adequate use of global context (\\eg, shape and structure). As a result, ViTs fail to generalize to out-of-distribution, real-world data. To address this deficiency, we present a simple and effective architecture modification to ViT's input layer by adding discrete tokens produced by a vector-quantized encoder. Different from the standard continuous pixel tokens, discrete tokens are invariant under small perturbations and contain less information individually, which promote ViTs to learn global information that is invariant. Experimental results demonstrate that adding discrete representation on four architecture variants strengthens ViT robustness by up to 12\\% across seven ImageNet robustness benchmarks while maintaining the performance on ImageNet.",
    "One-sentence Summary": "We present a simple and effective architecture modification to ViT's input layer with discrete token representations."
  },
  {
    "title": "On the Convergence of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning",
    "url": "/forum?id=JzNB0eA2-M4",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, convergence of reinforcement learning algorithm, monte carlo exploring starts",
    "Abstract": "A simple and natural algorithm for reinforcement learning (RL) is Monte Carlo Exploring Starts (MCES), where the Q-function is estimated by averaging the Monte Carlo returns, and the policy is improved by choosing actions that maximize the current estimate of the Q-function. Exploration is performed by \"exploring starts\", that is, each episode begins with a randomly chosen state and action, and then follows the current policy to the terminal state. In the classic book on RL by Sutton & Barto (2018), it is stated that establishing convergence for the MCES algorithm is one of the most important remaining open theoretical problems in RL. However, the convergence question for MCES turns out to be quite nuanced. Bertsekas & Tsitsiklis (1996) provide a counter-example showing that the MCES algorithm does not necessarily converge. Tsitsiklis (2002) further shows that if the original MCES algorithm is modified so that the Q-function estimates are updated at the same rate for all state-action pairs, and the discount factor is strictly less than one, then the MCES algorithm converges. \n        In this paper we make headway with the original and more efficient MCES algorithm given in Sutton et al. (1998), establishing almost sure convergence for Optimal Policy Feed-Forward MDPs, which are MDPs whose states are not revisited within any episode when using an optimal policy. Such MDPs include a large class of environments such as all deterministic environments and all episodic environments with a timestep or any monotonically changing values as part of the state. Different from the previous proofs using stochastic approximations, we introduce a novel inductive approach, which is very simple and only makes use of the strong law of large numbers.",
    "One-sentence Summary": "We prove that the Monte Carlo Exploring Starts algorithm converges for optimal policy feed-forward MDPs."
  },
  {
    "title": "Concurrent Adversarial Learning for Large-Batch Training",
    "url": "/forum?id=rw1mZl_ss3L",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Distributed Machine Learnig, Large-Batch Training, Adversarial Learning",
    "Abstract": "Large-batch training has become a commonly used technique when training neural networks with a large number of GPU/TPU processors. As batch size increases, stochastic optimizers tend to converge to sharp local minima, leading to degraded test performance. Current methods usually use extensive data augmentation to increase the batch size, but we found the performance gain with data augmentation decreases as batch size increases, and data augmentation will become insufficient after certain point. In this paper, we propose to use adversarial learning to increase the batch size in large-batch training. Despite being a natural choice for smoothing the decision surface and biasing towards a flat region, adversarial learning has not been successfully applied in large-batch training since it requires at least two sequential gradient computations at each step, which will at least double the running time compared with vanilla training even with a large number of processors. To overcome this issue, we propose a novel Concurrent Adversarial Learning (ConAdv) method that decouple the sequential gradient computations in adversarial learning by utilizing staled parameters. Experimental results demonstrate that ConAdv can successfully  increase the batch size on both ResNet-50 and EfficientNet training on ImageNet while maintaining high accuracy. In particular, we show ConAdv along can achieve 75.3\\% top-1 accuracy on ImageNet ResNet-50 training with 96K batch size, and the accuracy can be further improved to 76.2\\% when combining ConAdv with data augmentation. This is the first work successfully scales ResNet-50 training batch size to 96K."
  },
  {
    "title": "Multiset-Equivariant Set Prediction with Approximate Implicit Differentiation",
    "url": "/forum?id=5K7RRqZEjoS",
    "date": "28 Sept 2021 (modified: 03 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "set prediction, permutation equivariance, implicit differentiation",
    "Abstract": "Most set prediction models in deep learning use set-equivariant operations, but they actually operate on multisets. We show that set-equivariant functions cannot represent certain functions on multisets, so we introduce the more appropriate notion of multiset-equivariance. We identify that the existing Deep Set Prediction Network (DSPN) can be multiset-equivariant without being hindered by set-equivariance and improve it with approximate implicit differentiation, allowing for better optimization while being faster and saving memory. In a range of toy experiments, we show that the perspective of multiset-equivariance is beneficial and that our changes to DSPN achieve better results in most cases. On CLEVR object property prediction, we substantially improve over the state-of-the-art Slot Attention from 8% to 77% in one of the strictest evaluation metrics because of the benefits made possible by implicit differentiation.",
    "One-sentence Summary": "We propose a better permutation-equivariance property for multisets and improve an existing set predictor that has this property with approximate implicit differentiation"
  },
  {
    "title": "Learned Simulators for Turbulence",
    "url": "/forum?id=msRBojTz-Nh",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "learned simulation, turbulence",
    "Abstract": "Turbulence simulation with classical numerical solvers requires  high-resolution grids to accurately resolve dynamics. Here we train learned simulators at low spatial and temporal resolutions to capture turbulent dynamics generated at high resolution. We show that our proposed model can simulate turbulent dynamics more accurately than classical numerical solvers at the comparably low resolutions across various scientifically relevant metrics. Our model is trained end-to-end from data and is capable of learning a range of challenging chaotic and turbulent dynamics at low resolution, including trajectories generated by the state-of-the-art Athena++ engine. We show that our simpler, general-purpose architecture outperforms various more specialized, turbulence-specific architectures from the learned turbulence simulation literature. In general, we see that learned simulators yield unstable trajectories; however, we show that tuning training noise and temporal downsampling solves this problem. We also find that while generalization beyond the training distribution is a challenge for learned models, training noise, added loss constraints, and dataset augmentation can help. Broadly, we conclude that our learned simulator outperforms traditional solvers run on coarser grids, and emphasize that simple design choices can offer stability and robust generalization.",
    "One-sentence Summary": "Learned simulators that outperform baselines in capturing turbulent dynamics at low resolution across multiple challenging turbulence domains."
  },
  {
    "title": "Modular Lifelong Reinforcement Learning via Neural Composition",
    "url": "/forum?id=5XmLzdslFNN",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "lifelong learning, continual learning, reinforcement learning, composition, modularity, compositionality",
    "Abstract": "Humans commonly solve complex problems by decomposing them into easier subproblems and then combining the subproblem solutions. This type of compositional reasoning permits reuse of the subproblem solutions when tackling future tasks that share part of the underlying compositional structure. In a continual or lifelong reinforcement learning (RL) setting, this ability to decompose knowledge into reusable components would enable agents to quickly learn new RL tasks by leveraging accumulated compositional structures. We explore a particular form of composition based on neural modules and present a set of RL problems that intuitively admit compositional solutions. Empirically, we demonstrate that neural composition indeed captures the underlying structure of this space of problems. We further propose a compositional lifelong RL method that leverages accumulated neural components to accelerate the learning of future tasks while retaining performance on previous tasks via off-line RL over replayed experiences.",
    "One-sentence Summary": "We explore the problem of lifelong RL of functionally composable knowledge, and develop an algorithm that demonstrates zero-shot and forward transfer, avoidance of forgetting, and backward transfer in discrete 2-D and robotic manipulation domains."
  },
  {
    "title": "Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks",
    "url": "/forum?id=7B3IJMM1k_M",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Spiking Neural Networks, ANN-SNN Conversion, Ultra-low Latency, Quantization Clip-floor-shift Activation",
    "Abstract": "Spiking Neural Networks (SNNs) have gained great attraction due to their distinctive properties of low power consumption and fast inference on neuromorphic hardware. As the most effective method to get deep SNNs, ANN-SNN conversion has achieved comparable performance as ANNs on large-scale datasets. Despite this, it requires long time-steps to match the firing rates of SNNs to the activation of ANNs. As a result, the converted SNN suffers severe performance degradation problems with short time-steps, which hamper the practical application of SNNs. In this paper, we theoretically analyze ANN-SNN conversion error and derive the estimated activation function of SNNs. Then we propose the quantization clip-floor-shift activation function to replace the ReLU activation function in source ANNs, which can better approximate the activation function of SNNs. We prove that the expected conversion error between SNNs and ANNs is zero, enabling us to achieve high-accuracy and ultra-low-latency SNNs. We evaluate our method on CIFAR-10/100 and ImageNet datasets, and show that it outperforms the state-of-the-art ANN-SNN and directly trained SNNs in both accuracy and time-steps. To the best of our knowledge, this is the first time to explore high-performance ANN-SNN conversion with ultra-low latency (4 time-steps). Code is available at https://github.com/putshua/SNN_conversion_QCFS",
    "One-sentence Summary": "An ANN-SNN conversion method enables high-accuracy and ultra-low-latency deep SNNs."
  },
  {
    "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision",
    "url": "/forum?id=fvLLcIYmXb",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Architecture Design, MLP, Classification, Detection, Segmentation",
    "Abstract": "An Axial Shifted MLP architecture (AS-MLP) is proposed in this paper. Different from MLP-Mixer, where the global spatial feature is encoded for information flow through matrix transposition and one token-mixing MLP, we pay more attention to the local features interaction. By axially shifting channels of the feature map, AS-MLP is able to obtain the information flow from different axial directions, which captures the local dependencies. Such an operation enables us to utilize a pure MLP architecture to achieve the same local receptive field as CNN-like architecture. We can also design the receptive field size and dilation of blocks of AS-MLP, \\emph{etc}, in the same spirit of  convolutional neural networks. With the proposed AS-MLP architecture, our model obtains 83.3\\% Top-1 accuracy with 88M parameters and 15.2 GFLOPs on the ImageNet-1K dataset. Such a simple yet effective architecture outperforms all MLP-based architectures and achieves competitive performance compared to the transformer-based architectures (\\emph{e.g.}, Swin Transformer) even with slightly lower FLOPs. In addition, AS-MLP is also the first MLP-based architecture to be applied to the downstream tasks (\\emph{e.g.}, object detection and semantic segmentation). The experimental results are also impressive. Our proposed AS-MLP obtains 51.5 mAP on the COCO validation set and 49.5 MS mIoU on the ADE20K dataset, which is competitive compared to the transformer-based architectures. Our AS-MLP establishes a strong baseline of MLP-based architecture. Code is available at \\url{https://github.com/svip-lab/AS-MLP}.",
    "One-sentence Summary": "We design the first MLP-based architecture for downstream tasks. It achieves competitive performance compared to the transformer-based architecture, which establishes a new strong baseline of MLP-based architecture."
  },
  {
    "title": "Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference",
    "url": "/forum?id=nrGGfMbY_qK",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "online, continual learning, task-free continual learning, any-time inference",
    "Abstract": "Despite rapid advances in continual learning, a large body of research is devoted to improving performance in the existing setups.\n        While a handful of work do propose new continual learning setups, they still lack practicality in certain aspects.\n        For better practicality, we first propose a novel continual learning setup that is online, task-free, class-incremental, of blurry task boundaries and subject to inference queries at any moment.\n        We additionally propose a new metric to better measure the performance of the continual learning methods subject to inference queries at any moment.\n        To address the challenging setup and evaluation protocol, we propose an effective method that employs a new memory management scheme and novel learning techniques.\n        Our empirical validation demonstrates that the proposed method outperforms prior arts by large margins. Code and data splits are available at https://github.com/naver-ai/i-Blurry.",
    "One-sentence Summary": "a novel continual learning set-up that is online and task-free, has new class distributions and focuses on any-time inference"
  },
  {
    "title": "Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations",
    "url": "/forum?id=TBWA6PLJZQm",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Learning with noisy labels, benchmark, real-world label noise, human annotations",
    "Abstract": "Existing research on learning with noisy labels mainly focuses on synthetic label noise. The synthetic noise, though has clean structures which greatly enabled statistical analyses, often fails to model the real-world noise patterns. The recent literature has observed several efforts to offer real-world noisy datasets, e.g., Food-101N, WebVision, and Clothing1M. Yet the existing efforts suffer from two caveats: firstly, the lack of ground-truth verification makes it hard to theoretically study the property and treatment of real-world label noise. Secondly, these efforts are often of large scales, which may result in unfair comparisons of robust methods within reasonable and accessible computation power. To better understand real-world label noise, it is important to establish controllable, easy-to-use, and moderate-sized real-world noisy datasets with both ground-truth and noisy labels. This work presents two new benchmark datasets, which we name as CIFAR-10N, CIFAR-100N (jointly we call them CIFAR-N), equipping the training datasets of CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels we collected from Amazon Mechanical Turk. We quantitatively and qualitatively show that real-world noisy labels follow an instance-dependent pattern rather than the classically assumed and adopted ones (e.g.,  class-dependent label noise). We then initiate an effort to benchmarking a subset of the existing solutions using  CIFAR-10N and CIFAR-100N. We further proceed to study the memorization of correct and wrong predictions, which further illustrates the difference between human noise and class-dependent synthetic noise. We show indeed the real-world noise patterns impose new and outstanding challenges as compared to synthetic label noise. These observations require us to rethink the treatment of noisy labels, and we hope the availability of these two datasets would facilitate the development and evaluation of future learning with noisy label solutions. The corresponding datasets and the leaderboard are available at http://noisylabels.com.",
    "One-sentence Summary": "In this paper, we revisit the problem of learning from noisy labels using human annotated CIFAR datasets we collected from Amazon Mechanical Turks."
  },
  {
    "title": "Optimization inspired Multi-Branch Equilibrium Models",
    "url": "/forum?id=nbC8iTTXIrk",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Works have shown the strong connections between some implicit models and optimization problems. However, explorations on such relationships are limited. Most works pay attention to some common mathematical properties, such as sparsity. In this work, we propose a new type of implicit model inspired by the designing of the systems' hidden objective functions, called the Multi-branch Optimization induced Equilibrium networks~(MOptEqs). The model architecture is designed based on modelling the hidden objective function for the multi-resolution recognition task. Furthermore, we also propose a new strategy inspired by our understandings of the hidden objective function. In this manner, the proposed model can better utilize the hierarchical patterns for recognition tasks and retain the abilities for interpreting the whole structure as trying to obtain the minima of the problem's goal. Comparing with the state-of-the-art models, our MOptEqs not only enjoys better explainability but are also superior to MDEQ with less parameter consumption and better performance on practical tasks. Furthermore, we also implement various experiments to demonstrate the effectiveness of our new methods and explore the applicability of the model's hidden objective function.",
    "One-sentence Summary": "A Multi-Branch DEQ model and its training strategy proposed by minimizing an objective function designed as our purpose."
  },
  {
    "title": "Learning to Annotate Part Segmentation with Gradient Matching",
    "url": "/forum?id=zNR43c03lRy",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "semi-supervised learning, part segmentation, semantic segmentation, generative models, gradient matching",
    "Abstract": "The success of state-of-the-art deep neural networks heavily relies on the presence of large-scale labelled datasets, which are extremely expensive and time-consuming to annotate. This paper focuses on tackling semi-supervised part segmentation tasks by generating high-quality images with a pre-trained GAN and labelling the generated images with an automatic annotator. In particular, we formulate the annotator learning as a learning-to-learn problem. Given a pre-trained GAN, the annotator learns to label object parts in a set of randomly generated images such that a part segmentation model trained on these synthetic images with their predicted labels obtains low segmentation error on a small validation set of manually labelled images. We further reduce this nested-loop optimization problem to a simple gradient matching problem and efficiently solve it with an iterative algorithm. We show that our method can learn annotators from a broad range of labelled images including real images, generated images, and even analytically rendered images. Our method is evaluated with semi-supervised part segmentation tasks and significantly outperforms other semi-supervised competitors when the amount of labelled examples is extremely limited.",
    "One-sentence Summary": "We propose a gradient-matching-based method to learn annotator which is able to label generated images with part segmentation by decoding the generator features into segmentation masks."
  },
  {
    "title": "Vector-quantized Image Modeling with Improved VQGAN",
    "url": "/forum?id=pfNyExj7z2",
    "date": "28 Sept 2021 (modified: 01 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "VQGAN, Vision Transformers, Vector-quantized Image Modeling",
    "Abstract": "Pretraining language models with next-token prediction on massive text corpora has delivered phenomenal zero-shot, few-shot, transfer learning and multi-tasking capabilities on both generative and discriminative language tasks. Motivated by this success, we explore a Vector-quantized Image Modeling (VIM) approach that involves pretraining a Transformer to predict rasterized image tokens autoregressively. The discrete image tokens are encoded from a learned Vision-Transformer-based VQGAN (ViT-VQGAN). We first propose multiple improvements over vanilla VQGAN from architecture to codebook learning, yielding better efficiency and reconstruction fidelity. The improved ViT-VQGAN further improves vector-quantized image modeling tasks, including unconditional, class-conditioned image generation and unsupervised representation learning. When trained on ImageNet at 256x256 resolution, we achieve Inception Score (IS) of 175.1 and Fr'echet Inception Distance (FID) of 4.17, a dramatic improvement over the vanilla VQGAN, which obtains 70.6 and 17.04 for IS and FID, respectively. Based on ViT-VQGAN and unsupervised pretraining, we further evaluate the pretrained Transformer by averaging intermediate features, similar to Image GPT (iGPT). This ImageNet-pretrained VIM-L significantly beats iGPT-L on linear-probe accuracy from 60.3% to 73.2% for a similar model size. ViM-L also outperforms iGPT-XL which is trained with extra web image data and larger model size.",
    "One-sentence Summary": "We propose the ViT-VQGAN and further explore a Vector-quantized Image Modeling (VIM) approach on both generative and discriminative tasks on images."
  },
  {
    "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation",
    "url": "/forum?id=R8sQPpGCv0",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Since the introduction of the transformer model by Vaswani et al. (2017), a fundamental question has yet to be answered: how does a model achieve extrapolation at inference time for sequences that are longer than it saw during training? We first show that extrapolation can be enabled by simply changing the position representation method, though we find that current methods do not allow for efficient extrapolation. We therefore introduce a simpler and more efficient position method, Attention with Linear Biases (ALiBi). ALiBi does not add positional embeddings to word embeddings;  instead, it biases query-key attention scores with a penalty that is proportional to their distance. We show that this method trains a 1.3 billion parameter model on input sequences of length 1024 that extrapolates to input sequences of length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but training 11% faster and using 11% less memory. ALiBi's inductive bias towards recency also leads it to outperform multiple strong position methods on the WikiText-103 benchmark.",
    "One-sentence Summary": "We show that our simple position method enables transformer LMs to efficiently and accurately perform inference on longer sequences than they were trained on."
  },
  {
    "title": "Learning Representation from Neural Fisher Kernel with Low-rank Approximation",
    "url": "/forum?id=J1rhANsCY9",
    "date": "28 Sept 2021 (modified: 03 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "In this paper, we study the representation of neural networks from the view of kernels. We first define the Neural Fisher Kernel (NFK), which is the Fisher Kernel applied to neural networks. We show that NFK can be computed for both supervised and unsupervised learning models, which can serve as a unified tool for representation extraction. Furthermore, we show that practical NFKs exhibit low-rank structures. We then propose an efficient algorithm that computes a low-rank approximation of NFK, which scales to large datasets and networks. We show that the low-rank approximation of NFKs derived from unsupervised generative models and supervised learning models gives rise to high-quality compact representations of data, achieving competitive results on a variety of machine learning tasks."
  },
  {
    "title": "Learning Temporally Causal Latent Processes from General Temporal Data",
    "url": "/forum?id=RDlLMjLJXdq",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Our goal is to recover time-delayed latent causal variables and identify their relations from measured temporal data. Estimating causally-related latent variables from observations is particularly challenging as the latent variables are not uniquely recoverable in the most general case. In this work, we consider both a nonparametric, nonstationary setting and a parametric setting for the latent processes and propose two provable conditions under which temporally causal latent processes can be identified from their nonlinear mixtures. We propose LEAP, a theoretically-grounded framework that extends Variational AutoEncoders (VAEs) by enforcing our conditions through proper constraints in causal process prior. Experimental results on various datasets demonstrate that temporally causal latent processes are reliably identified from observed variables under different dependency structures and that our approach considerably outperforms baselines that do not properly leverage history or nonstationarity information. This demonstrates that using temporal information to learn latent processes from their invertible nonlinear mixtures in an unsupervised manner, for which we believe our work is one of the first, seems promising even without sparsity or minimality assumptions.",
    "One-sentence Summary": "Propose two provable conditions and training framework with which temporally latent causal processes are identifiable from observed variables."
  },
  {
    "title": "The Rich Get Richer: Disparate Impact of Semi-Supervised Learning",
    "url": "/forum?id=DXPftn5kjQK",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "semi-supervised learning, fairness, disparate impact, Matthew effect, consistency regularization",
    "Abstract": "Semi-supervised learning (SSL) has demonstrated its potential to improve the model accuracy for a variety of learning tasks when the high-quality supervised data is severely limited. Although it is often established that the average accuracy for the entire population of data is improved, it is unclear how SSL fares with different sub-populations. Understanding the above question has substantial fairness implications when different sub-populations are defined by the demographic groups that we aim to treat fairly. In this paper, we reveal the disparate impacts of deploying SSL: the sub-population who has a higher baseline accuracy without using SSL (the \"rich\" one) tends to benefit more from SSL; while the sub-population who suffers from a low baseline accuracy (the \"poor\" one) might even observe a performance drop after adding the SSL module. We theoretically and empirically establish the above observation for a broad family of SSL algorithms, which either explicitly or implicitly use an auxiliary \"pseudo-label\". Experiments on a set of image and text classification tasks confirm our claims. We introduce a new metric, Benefit Ratio, and promote the evaluation of the fairness of SSL (Equalized Benefit Ratio). We further discuss how the disparate impact can be mitigated. We hope our paper will alarm the potential pitfall of using SSL and encourage a multifaceted evaluation of future SSL algorithms.",
    "One-sentence Summary": "We reveal the disparate impacts of deploying SSL: the \"rich\" sub-population (higher baseline accuracy without SSL) benefits more from SSL; while the \"poor\" sub-population (low baseline accuracy) might even observe a performance drop after SSL."
  },
  {
    "title": "Neural Relational Inference with Node-Specific Information",
    "url": "/forum?id=HBsJNesj2S",
    "date": "28 Sept 2021 (modified: 12 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Graph Neural Networks, Variational Inference, Trajectory Prediction",
    "Abstract": "Inferring interactions among entities is an important problem in studying dynamical systems, which greatly impacts the performance of downstream tasks, such as prediction. In this paper, we tackle the relational inference problem in a setting where each entity can potentially have a set of individualized information that other entities cannot have access to. Specifically, we represent the system using a graph in which the individualized information become node-specific information (NSI). We build our model in the framework of Neural Relation Inference (NRI), where the interaction among entities are uncovered using variational inference. We adopt NRI model to incorporate the individualized information by introducing private nodes in the graph that represent NSI. Such representation enables us to uncover more accurate relations among the agents and therefore leads to better performance on the downstream tasks. Our experiment results over real-world datasets validate the merit of our proposed algorithm.",
    "One-sentence Summary": "We use variational inference to uncover relations among agents in a multi-agent system, given that the agents can have access to some private information"
  },
  {
    "title": "Bregman Gradient Policy Optimization",
    "url": "/forum?id=ZU-zFnTum1N",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "In the paper, we design a novel Bregman gradient policy optimization framework for reinforcement learning based on Bregman divergences and momentum techniques. Specifically, we propose a Bregman gradient policy optimization (BGPO) algorithm based on the basic momentum technique and mirror descent iteration. Meanwhile, we further propose an accelerated Bregman gradient policy optimization (VR-BGPO) algorithm based on the variance reduced technique. Moreover, we provide a convergence analysis framework for our Bregman gradient policy optimization under the nonconvex setting. We prove that our BGPO achieves a  sample complexity of $O(\\epsilon^{-4})$ for finding $\\epsilon$-stationary policy only requiring one trajectory at each iteration, and our VR-BGPO reaches the best known sample complexity of $O(\\epsilon^{-3})$, which also only requires one trajectory at each iteration. In particular, by using different Bregman divergences, our BGPO framework unifies many existing policy optimization algorithms such as the existing (variance reduced) policy gradient algorithms such as natural policy gradient algorithm. Extensive experimental results on multiple reinforcement learning tasks demonstrate the efficiency of our new algorithms."
  },
  {
    "title": "A generalization of the randomized singular value decomposition",
    "url": "/forum?id=hgKtwSb4S2",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Low rank approximation, Randomized SVD, Hilbert--Schmidt operators, Gaussian processes",
    "Abstract": "The randomized singular value decomposition (SVD) is a popular and effective algorithm for computing a near-best rank $k$ approximation of a matrix $A$ using matrix-vector products with standard Gaussian vectors. Here, we generalize the theory of randomized SVD to multivariate Gaussian vectors, allowing one to incorporate prior knowledge of $A$ into the algorithm. This enables us to explore the continuous analogue of the randomized SVD for Hilbert--Schmidt (HS) operators using operator-function products with functions drawn from a Gaussian process (GP). We then construct a new covariance kernel for GPs, based on weighted Jacobi polynomials, which allows us to rapidly sample the GP and control the smoothness of the randomly generated functions. Numerical examples on matrices and HS operators demonstrate the applicability of the algorithm.",
    "One-sentence Summary": "The randomized SVD is generalized to multivariate Gaussian input vectors and Hilbert-Schmidt operators."
  },
  {
    "title": "Dropout Q-Functions for Doubly Efficient Reinforcement Learning",
    "url": "/forum?id=xCVJMsPv3RT",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement learning",
    "Abstract": "Randomized ensembled double Q-learning (REDQ) (Chen et al., 2021b) has recently achieved state-of-the-art sample efficiency on continuous-action reinforcement learning benchmarks. This superior sample efficiency is made possible by using a large Q-function ensemble. However, REDQ is much less computationally efficient than non-ensemble counterparts such as Soft Actor-Critic (SAC) (Haarnoja et al., 2018a). To make REDQ more computationally efficient, we propose a method of improving computational efficiency called DroQ, which is a variant of REDQ that uses a small ensemble of dropout Q-functions. Our dropout Q-functions are simple Q-functions equipped with dropout connection and layer normalization. Despite its simplicity of implementation, our experimental results indicate that DroQ is doubly (sample and computationally) efficient. It achieved comparable sample efficiency with REDQ, much better computational efficiency than REDQ, and comparable computational efficiency with that of SAC.",
    "One-sentence Summary": "We propose a doubly (sample and computationally) efficient RL method (Dr.Q) in which a small ensemble of dropout Q-functions is used."
  },
  {
    "title": "QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization",
    "url": "/forum?id=ySQH0oDyp7",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Recently, post-training quantization (PTQ) has driven much attention to produce efficient neural networks without long-time retraining. Despite the low cost, current PTQ works always fail under the extremely low-bit setting. In this study, we pioneeringly confirm that properly incorporating activation quantization into the PTQ reconstruction benefits the final accuracy. To deeply understand the inherent reason, a theoretical framework is established, which inspires us that the flatness of the optimized low-bit model on calibration and test data is crucial. Based on the conclusion, a simple yet effective approach dubbed as \\textsc{QDrop} is proposed, which randomly drops the quantization of activations during reconstruction. Extensive experiments on various tasks including computer vision (image classification, object detection) and natural language processing (text classification and question answering) prove its superiority. With \\textsc{QDrop}, the limit of PTQ is pushed to the 2-bit activation for the first time and the accuracy boost can be up to 51.49\\%. Without bells and whistles, \\textsc{QDrop} establishes a new state of the art for PTQ."
  },
  {
    "title": "You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction",
    "url": "/forum?id=POxF-LEqnF",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Feature Attribution, Shapley values, Trajectory Prediction, Causality",
    "Abstract": "Predicting the future trajectory of a moving agent can be easy when the past trajectory continues smoothly but is challenging when complex interactions with other agents are involved. Recent deep learning approaches for trajectory prediction show promising performance and partially attribute this to successful reasoning about agent-agent interactions.  However, it remains unclear which features such black-box models actually learn to use for making predictions. This paper proposes a procedure that quantifies the contributions of different cues to model performance based on a variant of Shapley values. Applying this procedure to state-of-the-art trajectory prediction methods on standard benchmark datasets shows that they are, in fact, unable to reason about interactions. Instead, the past trajectory of the target is the only feature used for predicting its future. For a task with richer social interaction patterns, on the other hand, the tested models do pick up such interactions to a certain extent, as quantified by our feature attribution method. We discuss the limits of the proposed method and its links to causality.",
    "One-sentence Summary": "We propose a Shapley value-based method for attributing trajectory prediction performance to different input features and show on common benchmark datasets that existing models do not use interaction information, contrary to their claims."
  },
  {
    "title": "Rethinking Class-Prior Estimation for Positive-Unlabeled Learning",
    "url": "/forum?id=aYAA-XHKyk",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Positive-Unlabeled Learning, Class-Prior Estimation",
    "Abstract": "Given only positive (P) and unlabeled (U) data, PU learning can train a binary classifier without any negative data. It has two building blocks: PU class-prior estimation (CPE) and PU classification; the latter has been well studied while the former has received less attention. Hitherto, the distributional-assumption-free CPE methods rely on a critical assumption that the support of the positive data distribution cannot be contained in the support of the negative data distribution. If this is violated, those CPE methods will systematically overestimate the class prior; it is even worse that we cannot verify the assumption based on the data. In this paper, we rethink CPE for PU learning\u2014can we remove the assumption to make CPE always valid? We show an affirmative answer by proposing Regrouping CPE (ReCPE) that builds an auxiliary probability distribution such that the support of the positive data distribution is never contained in the support of the negative data distribution. ReCPE can work with any CPE method by treating it as the base method. Theoretically, ReCPE does not affect its base if the assumption already holds for the original probability distribution; otherwise, it reduces the positive bias of its base. Empirically, ReCPE improves all state-of-the-art CPE methods on various datasets, implying that the assumption has indeed been violated here.",
    "One-sentence Summary": "Class-Prior Estimation for Positive-Unlabeled Learning"
  },
  {
    "title": "Learning Efficient Online 3D Bin Packing on Packing Configuration Trees",
    "url": "/forum?id=bfuGjlCwAq",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Bin Packing Problem, Online 3D-BPP, Reinforcement Learning",
    "Abstract": "Online 3D Bin Packing Problem (3D-BPP) has widespread applications in industrial automation and has aroused enthusiastic research interest recently. Existing methods usually solve the problem with limited resolution of spatial discretization, and/or cannot deal with complex practical constraints well. We propose to enhance the practical applicability of online 3D-BPP via learning on a novel hierarchical representation \u2013 packing configuration tree (PCT). PCT is a full-fledged description of the state and action space of bin packing which can support packing policy learning based on deep reinforcement learning (DRL). The size of the packing action space is proportional to the number of leaf nodes, making the DRL model easy to train and well-performing even with continuous solution space. During training, PCT expands based on heuristic rules, however, the DRL model learns a much more effective and robust packing policy than heuristic methods. Through extensive evaluation, we demonstrate that our method outperforms all existing online BPP methods and is versatile in terms of incorporating various practical constraints.",
    "One-sentence Summary": "We propose to enhance the practical applicability of online 3D-BPP via learning on a hierarchical packing configuration tree which makes the DRL model easy to deal with practical constraints and well-performing even with continuous solution space."
  },
  {
    "title": "Uncertainty Modeling for Out-of-Distribution Generalization",
    "url": "/forum?id=6HN7LHyzGgC",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "domain generalization, uncertainty modeling",
    "Abstract": "Though remarkable progress has been achieved in various vision tasks, deep neural networks still suffer obvious performance degradation when tested in out-of-distribution scenarios. We argue that the feature statistics (mean and standard deviation), which carry the domain characteristics of the training data, can be properly manipulated to improve the generalization ability of deep learning models. Common methods often consider the feature statistics as deterministic values measured from the learned features and do not explicitly consider the uncertain statistics discrepancy caused by potential domain shifts during testing. In this paper, we improve the network generalization ability by modeling the uncertainty of domain shifts with synthesized feature statistics during training. Specifically, we hypothesize that the feature statistic, after considering the potential uncertainties, follows a multivariate Gaussian distribution. Hence, each feature statistic is no longer a deterministic value, but a probabilistic point with diverse distribution possibilities. With the uncertain feature statistics, the models can be trained to alleviate the domain perturbations and achieve better robustness against potential domain shifts. Our method can be readily integrated into networks without additional parameters. Extensive experiments demonstrate that our proposed method consistently improves the network generalization ability on multiple vision tasks, including image classification, semantic segmentation, and instance retrieval.",
    "One-sentence Summary": "We for the first time treat feature statistics as uncertain distributions to improve the model generalization ability."
  },
  {
    "title": "Online Adversarial Attacks",
    "url": "/forum?id=bYGSzbCM_i",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Online Algorithms, Adversarial Attacks",
    "Abstract": "Adversarial attacks expose important vulnerabilities of deep learning models, yet little attention has been paid to settings where data arrives as a stream. In this paper, we formalize the online adversarial attack problem, emphasizing two key elements found in real-world use-cases: attackers must operate under partial knowledge of the target model, and the decisions made by the attacker are irrevocable since they operate on a transient data stream. We first rigorously analyze a deterministic variant of the online threat model by drawing parallels to the well-studied $k$-secretary problem in theoretical computer science and propose Virtual+, a simple yet practical online algorithm. Our main theoretical result shows Virtual+ yields provably the best competitive ratio over all single-threshold algorithms for $k<5$---extending the previous analysis of the $k$-secretary problem. We also introduce the \\textit{stochastic $k$-secretary}---effectively reducing online blackbox transfer attacks to a $k$-secretary problem under noise---and prove theoretical bounds on the performance of Virtual+ adapted to this setting. Finally, we complement our theoretical results by conducting experiments on MNIST, CIFAR-10, and Imagenet classifiers, revealing the necessity of online algorithms in achieving near-optimal performance and also the rich interplay between attack strategies and online attack selection, enabling simple strategies like FGSM to outperform stronger adversaries.",
    "One-sentence Summary": "We consider a new adversarial attack setting in which the data arrives as a stream and an adversary must pick top-k items to craft blackbox transfer attacks against an unkown target model."
  },
  {
    "title": "Anytime Dense Prediction with Confidence Adaptivity",
    "url": "/forum?id=kNKFOXleuC",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Efficient Inference, Anytime Inference, Semantic Segmentation, Dense Prediction, Computer Vision",
    "Abstract": "Anytime inference requires a model to make a progression of predictions which might be halted at any time. Prior research on anytime visual recognition has mostly focused on image classification.We propose the first unified and end-to-end approach for anytime dense prediction. A cascade of \"exits\" is attached to the model to make multiple predictions. We redesign the exits to account for the depth and spatial resolution of the features for each exit. To reduce total computation, and make full use of prior predictions, we develop a novel spatially adaptive approach to avoid further computation on regions where early predictions are already sufficiently confident. Our full method, named anytime dense prediction with confidence (ADP-C), achieves the same level of final accuracy, and meanwhile significantly reduces total computation. We evaluate our method on Cityscapes semantic segmentation and MPII human pose estimation: ADP-C enables anytime inference without sacrificing accuracy while also reducing the total FLOPs of its base models by 44.4% and 59.1%. We compare with anytime inference by deep equilibrium networks and feature-based stochastic sampling, showing that ADP-C dominates both across the accuracy-computation curve. Our code is available at https://github.com/liuzhuang13/anytime.",
    "One-sentence Summary": "First single-model anytime approach for pixel-level visual recognition; our model with redesigned exits and confidence adaptivity enables anytime inference, achieves the same level of final accuracy, and significantly reduces total computation."
  },
  {
    "title": "Declarative nets that are equilibrium models",
    "url": "/forum?id=q4HaTeMO--y",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep equilibrium models, deep declarative networks, implicit layers, kernel methods, generalised linear models",
    "Abstract": "Implicit layers are computational modules that output the solution to some problem depending on the input and the layer parameters. Deep equilibrium models (DEQs) output a solution to a fixed point equation. Deep declarative networks (DDNs) solve an optimisation problem in their forward pass, an arguably more intuitive, interpretable problem than finding a fixed point. We show that solving a kernelised regularised maximum likelihood estimate as an inner problem in a DDN yields a large class of DEQ architectures. Our proof uses the exponential family in canonical form, and provides a closed-form expression for the DEQ parameters in terms of the kernel. The activation functions have interpretations in terms of the derivative of the log partition function. Building on existing literature, we interpret DEQs as fine-tuned, unrolled classical algorithms, giving an intuitive justification for why DEQ models are sensible. We use our theoretical result to devise an initialisation scheme for DEQs that allows them to solve kGLMs in their forward pass at initialisation. We empirically show that this initialisation scheme improves training stability and performance over random initialisation.",
    "One-sentence Summary": "Choosing a kernelised generalised linear model as the inner problem of a DDN yields a DEQ with specific fixed weights."
  },
  {
    "title": "A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning",
    "url": "/forum?id=AcrlgZ9BKed",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "bandits, lower bound, reinforcement learning theory",
    "Abstract": "We study bandits and reinforcement learning (RL) subject to a conservative constraint where the agent is asked to perform at least as well as a given baseline policy. This setting is particular relevant in real-world domains including digital marketing, healthcare, production, finance, etc. In this paper, we present a reduction-based framework for conservative bandits and RL, in which our core technique is to calculate the necessary and sufficient budget obtained from running the baseline policy. For lower bounds, we improve the existing lower bound for conservative multi-armed bandits and obtain new lower bounds for conservative linear bandits, tabular RL and low-rank MDP, through a black-box reduction that turns a certain lower bound in the nonconservative setting into a new lower bound in the conservative setting.  For upper bounds, in multi-armed bandits, linear bandits and tabular RL, our new upper bounds tighten or match existing ones with significantly simpler analyses. We also obtain a new upper bound for conservative low-rank MDP.",
    "One-sentence Summary": "We give general framework that turns upper and lower bounds in non-conservative settings to bounds in conservative settings."
  },
  {
    "title": "Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models",
    "url": "/forum?id=MvO2t0vbs4-",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Ensemble, Cascade, Efficiency",
    "Abstract": "Committee-based models (ensembles or cascades) construct models by combining existing pre-trained ones. While ensembles and cascades are well-known techniques that were proposed before deep learning, they are not considered a core building block of deep model architectures and are rarely compared to in recent literature on developing efficient models. In this work, we go back to basics and conduct a comprehensive analysis of the efficiency of committee-based models. We find that even the most simplistic method for building committees from existing, independently pre-trained models can match or exceed the accuracy of state-of-the-art models while being drastically more efficient. These simple committee-based models also outperform sophisticated neural architecture search methods (e.g., BigNAS). These findings hold true for several tasks, including image classification, video classification, and semantic segmentation, and various architecture families, such as ViT, EfficientNet, ResNet, MobileNetV2, and X3D. Our results show that an EfficientNet cascade can achieve a 5.4x speedup over B7 and a ViT cascade can achieve a 2.3x speedup over ViT-L-384 while being equally accurate.",
    "One-sentence Summary": "A simple ensemble or cascade of off-the-shelf pre-trained models can match or exceed the accuracy of SOTA models while being drastically more efficient."
  },
  {
    "title": "Unsupervised Discovery of Object Radiance Fields",
    "url": "/forum?id=rwE8SshAlxw",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "object discovery, scene decomposition, 3D scene representations, object-centric learning",
    "Abstract": "We study the problem of inferring an object-centric scene representation from a single image, aiming to derive a representation that explains the image formation process, captures the scene's 3D nature, and is learned without supervision. Most existing methods on scene decomposition lack one or more of these characteristics, due to the fundamental challenge in integrating the complex 3D-to-2D image formation process into powerful inference schemes like deep networks. In this paper, we propose unsupervised discovery of Object Radiance Fields (uORF), integrating recent progresses in neural 3D scene representations and rendering with deep inference networks for unsupervised 3D scene decomposition. Trained on multi-view RGB images without annotations, uORF learns to decompose complex scenes with diverse, textured background from a single image. We show that uORF enables novel tasks, such as scene segmentation and editing in 3D, and it performs well on these tasks and on novel view synthesis on three datasets.",
    "One-sentence Summary": "Inferring object-centric factorized 3D scene representations from a single image, learned without 3D geometry or segmentation supervision."
  },
  {
    "title": "Gradient Step Denoiser for convergent Plug-and-Play",
    "url": "/forum?id=fPhKeld3Okz",
    "date": "28 Sept 2021 (modified: 21 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Plug-and-Play, Inverse Problem, Image Restoration, Denoising",
    "Abstract": "Plug-and-Play methods constitute a class of iterative algorithms for imaging problems where regularization is performed by an off-the-shelf denoiser. Although Plug-and-Play methods can lead to tremendous visual performance for various image problems, the few existing convergence guarantees are based on unrealistic (or suboptimal) hypotheses on the denoiser, or limited to strongly convex data terms. In this work, we propose a new type of Plug-and-Play methods, based on half-quadratic splitting, for which the denoiser is realized as a gradient descent step on a functional parameterized by a deep neural network. Exploiting convergence results for proximal gradient descent algorithms in the non-convex setting, we show that the proposed Plug-and-Play algorithm is a convergent iterative scheme that targets stationary points of an explicit global functional. Besides, experiments show that it is possible to learn such a deep denoiser while not compromising the performance in comparison to other state-of-the-art deep denoisers used in Plug-and-Play schemes. We apply our proximal gradient algorithm to various ill-posed inverse problems, e.g. deblurring, super-resolution and inpainting. For all these applications, numerical results empirically confirm the convergence results. Experiments also show that this new algorithm reaches state-of-the-art performance, both quantitatively and qualitatively.",
    "One-sentence Summary": "We propose a performant Plug-and-Play image restoration algorithm that theoretically converges with an exact gradient step deep denoiser."
  },
  {
    "title": "Surrogate Gap Minimization Improves Sharpness-Aware Training",
    "url": "/forum?id=edONMAnhLu-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "generalization, sharpness-aware minimization, surrogate gap, deep learning",
    "Abstract": "The recently proposed  Sharpness-Aware  Minimization  (SAM)  improves generalization by minimizing a perturbed loss defined as the maximum loss within a neighborhood in the parameter space. However, we show that both sharp and flat minima can have a low perturbed loss, implying that SAM does not always prefer flat minima. Instead, we define a surrogate gap, a measure equivalent to the dominant eigenvalue of Hessian at a local minimum when the radius of neighborhood (to derive the perturbed loss) is small.  The surrogate gap is easy to compute and feasible for direct minimization during training. Based on the above observations, we propose Surrogate Gap Guided Sharpness-Aware Minimization (GSAM), a novel improvement over SAM with negligible computation overhead.  Conceptually, GSAM consists of two steps:  1) a gradient descent like SAM to minimize the perturbed loss, and 2) an ascent step in the orthogonal direction (after gradient decomposition) to minimize the surrogate gap and yet not affect the perturbed loss. GSAM seeks a region with both small loss (by step 1) and low sharpness (by step 2), giving rise to a model with high generalization capabilities. Theoretically, we show the convergence of GSAM and provably better generalization than SAM.Empirically, GSAM consistently improves generalization (e.g., +3.2% over SAM and +5.4% over AdamW on ImageNet top-1 accuracy for ViT-B/32). Code is released at https://sites.google.com/view/gsam-iclr22/home",
    "One-sentence Summary": "We propose GSAM which seeks a region with both small loss and low sharpness, and improves generalization over SAM with negligible computation overhead."
  },
  {
    "title": "R4D: Utilizing Reference Objects for Long-Range Distance Estimation",
    "url": "/forum?id=MQ2sAGunyBP",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-driving, distance estimation, long-range objects",
    "Abstract": "Estimating the distance of objects is a safety-critical task for autonomous driving. Focusing on short-range objects, existing methods and datasets neglect the equally important long-range objects. In this paper, we introduce a challenging and under-explored task, which we refer to as Long-Range Distance Estimation, as well as two datasets to validate new methods developed for this task. We then proposeR4D, the first framework to accurately estimate the distance of long-range objects by using references with known distances in the scene. Drawing inspiration from human perception, R4D builds a graph by connecting a target object to all references. An edge in the graph encodes the relative distance information between a pair of target and reference objects. An attention module is then used to weigh the importance of reference objects and combine them into one target object distance prediction. Experiments on the two proposed datasets demonstrate the effectiveness and robustness of R4D by showing significant improvements compared to existing baselines. We\u2019re looking to make the proposed dataset, Waymo OpenDataset - Long-Range Labels, available publicly at waymo.com/open/download."
  },
  {
    "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
    "url": "/forum?id=YevsQ05DEN7",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "self-supervised learning, contrastive learning, implicit regularization, dimensional collapse",
    "Abstract": "Self-supervised visual representation learning aims to learn useful representations without relying on human annotations. Joint embedding approach bases on maximizing the agreement between embedding vectors from different views of the same image. Various methods have been proposed to solve the collapsing problem where all embedding vectors collapse to a trivial constant solution. Among these methods, contrastive learning prevents collapse via negative sample pairs. It has been shown that non-contrastive methods suffer from a lesser collapse problem of a different nature: dimensional collapse, whereby the embedding vectors end up spanning a lower-dimensional subspace instead of the entire available embedding space. Here, we show that dimensional collapse also happens in contrastive learning. In this paper, we shed light on the dynamics at play in contrastive learning that leads to dimensional collapse. Inspired by our theory,  we propose a novel contrastive learning method, called DirectCLR, which directly optimizes the representation space without relying on a trainable projector. Experiments show that DirectCLR  outperforms SimCLR with a trainable linear projector on ImageNet.",
    "One-sentence Summary": "We observe and theoretically explain the dimensional collapse in contrastive self-supervised learning. We also propose a novel SSL method that does not rely on a projector."
  },
  {
    "title": "FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning",
    "url": "/forum?id=d71n4ftoCBy",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated learning, Parameterization, Communication efficiency",
    "Abstract": "In this work, we propose a communication-efficient parameterization, $\\texttt{FedPara}$, for federated learning (FL) to overcome the burdens on frequent model uploads and downloads. Our method re-parameterizes weight parameters of layers using low-rank weights followed by the Hadamard product. Compared to the conventional low-rank parameterization, our $\\texttt{FedPara}$ method is not restricted to low-rank constraints, and thereby it has a far larger capacity. This property enables to achieve comparable performance while requiring 3 to 10 times lower communication costs than the model with the original layers, which is not achievable by the traditional low-rank methods. The efficiency of our method can be further improved by combining with other efficient FL optimizers. In addition, we extend our method to a personalized FL application, $\\texttt{pFedPara}$, which separates parameters into global and local ones. We show that $\\texttt{pFedPara}$ outperforms competing personalized FL methods with more than three times fewer parameters.",
    "One-sentence Summary": "New communication-efficient neural network parameterization for federated learning."
  },
  {
    "title": "RegionViT: Regional-to-Local Attention for Vision Transformers",
    "url": "/forum?id=T__V3uLix7V",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "vision transformer, image recognition, multi-scale feature",
    "Abstract": "Vision transformer (ViT) has recently shown its strong capability in achieving comparable results to convolutional neural networks (CNNs) on image classification. However, vanilla ViT simply inherits the same architecture from the natural language processing directly, which is often not optimized for vision applications. Motivated by this, in this paper, we propose a new architecture that adopts the pyramid structure and employ novel regional-to-local attention rather than global self-attention in vision transformers. More specifically, our model first generates regional tokens and local tokens from an image with different patch sizes, where each regional token is associated with a set of local tokens based on the spatial location. The regional-to-local attention includes two steps: first, the regional self-attention extracts global information among all regional tokens and then the local self-attention exchanges the information among one regional token and the associated local tokens via self-attention. Therefore, even though local self-attention confines the scope in a local region but it can still receive global information.\n        Extensive experiments on four vision tasks, including image classification, object and keypoint detection, semantics segmentation and action recognition, show that our approach outperforms or is on par with state-of-the-art ViT variants including many concurrent works. Our source codes and models are available at \\url{https://github.com/IBM/RegionViT}.",
    "One-sentence Summary": "A new architecture for vision transformer"
  },
  {
    "title": "Quadtree Attention for Vision Transformers",
    "url": "/forum?id=fR-EnKWL_Zb",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Vision Transformer, Efficient Transformer, Feature matching, Stereo, image classification, detection, 3D Vision",
    "Abstract": "Transformers have been successful in many vision tasks, thanks to their capability of capturing long-range dependency. However, their quadratic computational complexity poses a major obstacle for applying them to vision tasks requiring dense predictions, such as object detection, feature matching, stereo, etc. We introduce QuadTree Attention, which reduces the computational complexity from quadratic to linear. Our quadtree transformer builds token pyramids and computes attention in a coarse-to-fine manner. At each level, the top K patches with the highest attention scores are selected, such that at the next level, attention is only evaluated within the relevant regions corresponding to these top K patches. We demonstrate that quadtree attention achieves state-of-the-art performance in various vision tasks, e.g. with 4.0% improvement in feature matching on ScanNet, about 50% flops reduction in stereo matching, 0.4-1.5% improvement in top-1 accuracy on ImageNet classification, 1.2-1.8% improvement on COCO object detection, and 0.7-2.4% improvement on semantic segmentation over previous state-of-the-art transformers. The codes are available at https://github.com/Tangshitao/QuadtreeAttention.",
    "One-sentence Summary": "Reduce the computation of transformer by coarse-to-fine attention computation for feature matching/stereo/classification/detection tasks."
  },
  {
    "title": "Visual Correspondence Hallucination",
    "url": "/forum?id=jaLDP8Hp_gc",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "visual correspondence hallucination, camera pose estimation",
    "Abstract": "Given a pair of partially overlapping source and target images and a keypoint in the source image, the keypoint's correspondent in the target image can be either visible, occluded or outside the field of view. Local feature matching methods are only able to identify the correspondent's location when it is visible, while humans can also hallucinate its location when it is occluded or outside the field of view through geometric reasoning.  In this paper, we bridge this gap by training a network to output a peaked probability distribution over the correspondent's location, regardless of this correspondent being visible, occluded, or outside the field of view.  We experimentally demonstrate that this network is indeed able to hallucinate correspondences on pairs of images captured in scenes that were not seen at training-time.  We also apply this network to an absolute camera pose estimation problem and find it is significantly more robust than state-of-the-art local feature matching-based competitors.",
    "One-sentence Summary": "We learn to hallucinate visual correspondences."
  },
  {
    "title": "What\u2019s Wrong with Deep Learning in Tree Search for Combinatorial Optimization",
    "url": "/forum?id=mk0HzdqY7i1",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "deep learning, combinatorial optimization, maximum independent set",
    "Abstract": "Combinatorial optimization lies at the core of many real-world problems. Especially since the rise of graph neural networks (GNNs), the deep learning community has been developing solvers that derive solutions to NP-hard problems by learning the problem-specific solution structure. However, reproducing the results of these publications proves to be difficult. We make three contributions. First, we present an open-source benchmark suite for the NP-hard Maximum Independent Set problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. Second, using our benchmark suite, we conduct an in-depth analysis of the popular guided tree search algorithm by Li et al. [NeurIPS 2018], testing various configurations on small and large synthetic and real-world graphs. By re-implementing their algorithm with a focus on code quality and extensibility, we show that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. Instead, the tree search relies on algorithmic techniques like graph kernelization to find good solutions. Thus, the results from the original publication are not reproducible. Third, we extend the analysis to compare the tree search implementations to other solvers, showing that the classical algorithmic solvers often are faster, while providing solutions of similar quality. Additionally, we analyze a recent solver based on reinforcement learning and observe that for this solver, the GNN is responsible for the competitive solution quality.",
    "One-sentence Summary": "Using our open-source Maximum Independent Set benchmarking suite, we show that in tree search for combinatorial optimization, the GNN can be replaced by random values without performance decrease."
  },
  {
    "title": "Deep Attentive Variational Inference",
    "url": "/forum?id=T4-65DNlDij",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "variational inference, approximate inference, deep probabilistic models, deep probabilistic learning, variational autoencoder, probabilistic methods for deep learning, attention",
    "Abstract": "Stochastic Variational Inference is a powerful framework for learning large-scale probabilistic latent variable models. However, typical assumptions on the factorization or independence  of the latent variables can substantially restrict its capacity for inference and generative modeling. A major line of active research aims at building more expressive variational models by designing deep hierarchies of interdependent latent variables. Although these models exhibit superior performance and enable richer latent representations, we show that they incur diminishing returns: adding more stochastic layers to an already very deep model yields small predictive improvement while substantially increasing the inference and training time. Moreover, the architecture for this class of models favors local interactions among the latent variables between neighboring layers when designing the conditioning factors of the involved distributions. This is the first work that proposes attention mechanisms to build more expressive variational distributions in deep probabilistic models by explicitly modeling both local and global interactions in the latent space. Specifically, we propose deep attentive variational autoencoder and test it on a variety of established datasets. We show it achieves state-of-the-art log-likelihoods while using fewer latent layers and requiring less  training time than existing models. The proposed non-local inference reduces computational footprint by alleviating the need for deep hierarchies. Project code:\n        https://github.com/ifiaposto/Deep_Attentive_VI"
  },
  {
    "title": "ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity",
    "url": "/forum?id=CVfLvQq9gLo",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "An intuitive way to search for images is to use queries composed of an example image and a complementary text. While the first provides rich and implicit context for the search, the latter explicitly calls for new traits, or specifies how some elements of the example image should be changed to retrieve the desired target image. Current approaches typically combine the features of each of the two elements of the query into a single representation, which can then be compared to the ones of the potential target images. Our work aims at shedding new light on the task by looking at it through the prism of two familiar and related frameworks: text-to-image and image-to-image retrieval. Taking inspiration from them, we exploit the specific relation of each query element with the targeted image and derive light-weight attention mechanisms which enable to mediate between the two complementary modalities. We validate our approach on several retrieval benchmarks, querying with images and their associated free-form text modifiers. Our method obtains state-of-the-art results without resorting to side information, multi-level features, heavy pre-training nor large architectures as in previous works."
  },
  {
    "title": "Trivial or Impossible --- dichotomous data difficulty masks model differences (on ImageNet and beyond)",
    "url": "/forum?id=C_vsGwEIjAr",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "CNNs, Cognitive Science, Vision Science, Psychophysics, Neuroscience, Visual perception, Inductive bias, ImageNet, CIFAR, RSA, Representation similarity analysis, Error consistency, Datasets",
    "Abstract": "\"The power of a generalization system follows directly from its biases\" (Mitchell 1980). Today, CNNs are incredibly powerful generalisation systems---but to what degree have we understood how their inductive bias influences model decisions? We here attempt to disentangle the various aspects that determine how a model decides. In particular, we ask: what makes one model decide differently from another? In a meticulously controlled setting, we find that (1.) irrespective of the network architecture or objective (e.g. self-supervised, semi-supervised, vision transformers, recurrent models) all models end up with a similar decision boundary. (2.) To understand these findings, we analysed model decisions on the ImageNet validation set from epoch to epoch and image by image. We find that the ImageNet validation set, among others, suffers from dichotomous data difficulty (DDD): For the range of investigated models and their accuracies, it is dominated by 46.0% \"trivial\" and 11.5% \"impossible\" images (beyond label errors). Only 42.5%  of the images could possibly be responsible for the differences between two models' decision boundaries. (3.) Only removing the \"impossible\" and \"trivial\" images allows us to see pronounced differences between models. (4.) Humans are highly accurate at predicting which images are \"trivial\" and \"impossible\" for CNNs (81.4%). This implies that in future comparisons of brains, machines and behaviour, much may be gained from investigating the decisive role of images and the distribution of their difficulties.",
    "One-sentence Summary": "All CNNs make similar decisions since data difficulty is dichotomous."
  },
  {
    "title": "Group equivariant neural posterior estimation",
    "url": "/forum?id=u6s8dSporO8",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "simulation-based inference, likelihood-free inference, machine learning for science, equivariances, group transformations",
    "Abstract": "Simulation-based inference with conditional neural density estimators is a powerful approach to solving inverse problems in science. However, these methods typically treat the underlying forward model as a black box, with no way to exploit geometric properties such as equivariances. Equivariances are common in scientific models, however integrating them directly into expressive inference networks (such as normalizing flows) is not straightforward. We here describe an alternative method to incorporate equivariances under joint transformations of parameters and data. Our method---called group equivariant neural posterior estimation (GNPE)---is based on self-consistently standardizing the \"pose\" of the data while estimating the posterior over parameters. It is architecture-independent, and applies both to exact and approximate equivariances. As a real-world application, we use GNPE for amortized inference of astrophysical binary black hole systems from gravitational-wave observations. We show that GNPE achieves state-of-the-art accuracy while reducing inference times by three orders of magnitude.",
    "One-sentence Summary": "We describe a method to incorporate group equivariances into neural posterior estimation."
  },
  {
    "title": "Fast Differentiable Matrix Square Root",
    "url": "/forum?id=-AOEi-5VTU8",
    "date": "28 Sept 2021 (modified: 01 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Differentiabl Matrix Square Root, Differentiable Matrix Decomposition, Vision Transformers",
    "Abstract": "Computing the matrix square root or its inverse in a differentiable manner is important in a variety of computer vision tasks. Previous methods either adopt the Singular Value Decomposition (SVD) to explicitly factorize the matrix or use the Newton-Schulz iteration (NS iteration) to derive the approximate solution. However, both methods are not computationally efficient enough in either the forward pass or in the backward pass. In this paper, we propose two more efficient variants to compute the differentiable matrix square root. For the forward propagation, one method is to use Matrix Taylor Polynomial (MTP), and the other method is to use Matrix Pad\\'e Approximants (MPA). The backward gradient is computed by iteratively solving the continuous-time Lyapunov equation using the matrix sign function. Both methods yield considerable speed-up compared with the SVD or the Newton-Schulz iteration. Experimental results on the de-correlated batch normalization and second-order vision transformer demonstrate that our methods can also achieve competitive and even slightly better performances. The code is available at \\href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.",
    "One-sentence Summary": "We develop two fast methods to compute the differentiable matrix square root."
  },
  {
    "title": "SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation",
    "url": "/forum?id=JXhROKNZzOc",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Data-Free Quantization, Hessian Matrix, Approximation",
    "Abstract": "Quantization of deep neural networks (DNN) has been proven effective for compressing and accelerating DNN models. Data-free quantization (DFQ) is a promising approach without the original datasets under privacy-sensitive and confidential scenarios. However, current DFQ solutions degrade accuracy, need synthetic data to calibrate networks, and are time-consuming and costly. This paper proposes an on-the-fly DFQ framework with sub-second quantization time, called SQuant, which can quantize networks on inference-only devices with low computation and memory requirements. With the theoretical analysis of the second-order information of DNN task loss, we decompose and approximate the Hessian-based optimization objective into three diagonal sub-items, which have different areas corresponding to three dimensions of weight tensor: element-wise, kernel-wise, and output channel-wise. Then, we progressively compose sub-items and propose a novel data-free optimization objective in the discrete domain,  minimizing Constrained Absolute Sum of Error (or CASE in short), which surprisingly does not need any dataset and is even not aware of network architecture. We also design an efficient algorithm without back-propagation to further reduce the computation complexity of the objective solver. Finally, without fine-tuning and synthetic datasets, SQuant accelerates the data-free quantization process to a sub-second level with >30% accuracy improvement over the existing data-free post-training quantization works, with the evaluated models under 4-bit quantization. We have open-sourced the SQuant framework at https://github.com/clevercool/SQuant.",
    "One-sentence Summary": "A fast and accurate data-free quantization framework named SQuant."
  },
  {
    "title": "Neural Variational Dropout Processes",
    "url": "/forum?id=lyLVzukXi08",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Meta Learning, Few-shot Learning, Bayesian Neural Networks, Variatinoal Dropout",
    "Abstract": "Learning to infer the conditional posterior model is a key step for robust meta-learning. This paper presents a new Bayesian meta-learning approach called Neural Variational Dropout Processes (NVDPs). NVDPs model the conditional posterior distribution based on a task-specific dropout; a low-rank product of Bernoulli experts meta-model is utilized for a memory-efficient mapping of dropout rates from a few observed contexts. It allows for a quick reconfiguration of a globally learned and shared neural network for new tasks in multi-task few-shot learning. In addition, NVDPs utilize a novel prior conditioned on the whole task data to optimize the conditional dropout posterior in the amortized variational inference. Surprisingly, this enables the robust approximation of task-specific dropout rates that can deal with a wide range of functional ambiguities and uncertainties. We compared the proposed method with other meta-learning approaches in the few-shot learning tasks such as 1D stochastic regression, image inpainting, and classification. The results show the excellent performance of NVDPs.",
    "One-sentence Summary": "This paper presents a new model-based Bayesian meta-learning approach called NVDPs that combines a novel conditional dropout posterior with a new variational prior for the data-efficient learning and adaptation of deep neural networks."
  },
  {
    "title": "Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning",
    "url": "/forum?id=kQ2SOflIOVC",
    "date": "28 Sept 2021 (modified: 18 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Few shot learning, Histology Image, Knowledge Transferring",
    "Abstract": "Few-shot learning is an established topic in natural images for years, but few work is attended to histology images, which is of high clinical value since well-labeled datasets and rare abnormal samples are expensive to collect. Here, we facilitate the study of few-shot learning in histology images by setting up three cross-domain tasks that simulate real clinics problems. To enable label-efficient learning and better generalizability, we propose to incorporate contrastive learning (CL) with latent augmentation (LA) to build a few-shot system. CL learns useful representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. These two components fully exploit unlabeled training data and can scale gracefully to other label-hungry problems. In experiments, we find i) models learned by CL generalize better than supervised learning for histology images in unseen classes, and ii) LA brings consistent gains over baselines. Prior studies of self-supervised learning mainly focus on ImageNet-like images, which only present a dominant object in their centers. Recent attention has been paid to images with multi-objects and multi-textures. Histology images are a natural choice for such a study. We show the superiority of CL over supervised learning in terms of generalization for such data and provide our empirical understanding for this observation. The findings in this work could contribute to understanding how the model generalizes in the context of both representation learning and histological image analysis. Code is available."
  },
  {
    "title": "Distilling GANs with Style-Mixed Triplets for X2I Translation with Limited Data",
    "url": "/forum?id=QjOQkpzKbNk",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Transfer learning, image synthesis, limited data.",
    "Abstract": "Conditional image synthesis is an integral part of many X2I translation systems, including image-to-image, text-to-image and audio-to-image translation systems. Training these large systems generally requires huge amounts of training data. \n        Therefore, we investigate knowledge distillation to transfer knowledge from a high-quality unconditioned generative model (e.g., StyleGAN) to a conditioned synthetic image generation modules in a variety of systems. To initialize the conditional and reference branch (from a unconditional GAN)  we exploit the style mixing characteristics of high-quality GANs to generate an infinite supply of style-mixed triplets to perform the knowledge distillation. Extensive experimental results in a number of image generation tasks (i.e., image-to-image, semantic segmentation-to-image, text-to-image and audio-to-image) demonstrate qualitatively and quantitatively that our method successfully transfers knowledge to the synthetic image generation modules, resulting in more realistic images than previous methods as confirmed by a significant drop in the FID.",
    "One-sentence Summary": "One transfer learning method generalizes varying kinds of  conditional image synthesization tasks."
  },
  {
    "title": "Handling Distribution Shifts on Graphs: An Invariance Perspective",
    "url": "/forum?id=FQOC5u-1egI",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Representation Learning on Graphs, Out-of-Distribution Generalization, Domain Shift, Graph Structure Learning, Invariant Models",
    "Abstract": "There is increasing evidence suggesting neural networks' sensitivity to distribution shifts, so that research on out-of-distribution (OOD) generalization comes into the spotlight. Nonetheless, current endeavors mostly focus on Euclidean data, and its formulation for graph-structured data is not clear and remains under-explored, given two-fold fundamental challenges: 1) the inter-connection among nodes in one graph, which induces non-IID generation of data points even under the same environment, and 2) the structural information in the input graph, which is also informative for prediction. In this paper, we formulate the OOD problem on graphs and develop a new invariant learning approach, Explore-to-Extrapolate Risk Minimization (EERM), that facilitates graph neural networks to leverage invariance principles for prediction. EERM resorts to multiple context explorers (specified as graph structure editers in our case) that are adversarially trained to maximize the variance of risks from multiple virtual environments. Such a design enables the model to extrapolate from a single observed environment which is the common case for node-level prediction. We prove the validity of our method by theoretically showing its guarantee of a valid OOD solution and further demonstrate its power on various real-world datasets for handling distribution shifts from artificial spurious features, cross-domain transfers and dynamic graph evolution.",
    "One-sentence Summary": "We formulate out-of-distribution generalization problem for node-level prediction on graphs and propose a new learning approach based on invariant models"
  },
  {
    "title": "Automatic Loss Function Search for Predict-Then-Optimize Problems with Strong Ranking Property",
    "url": "/forum?id=hSktDu-h94",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Combinatorial optimization problems with parameters to be predicted from side information are commonly seen in a variety of problems during the paradigm shift from reactive decision making to proactive decision making. Due to the misalignment between the continuous prediction results and the discrete decisions in optimization problems, it is hard to achieve a satisfactory prediction result with the ordinary $l_2$ loss in the prediction phase. To properly connect the prediction loss with the optimization goal, in this paper we propose a total group preorder (TGP) loss and its differential version called approximated total group preorder (ATGP) loss for predict-then-optimize (PTO) problems with strong ranking property. These new losses are provably more robust than the usual $l_2$ loss in a linear regression setting and have great potential to extend to other settings. We also propose an automatic searching algorithm that adapts the ATGP loss to PTO problems with different combinatorial structures. Extensive experiments on the ranking problem, the knapsack problem, and the shortest path problem have demonstrated that our proposed method can achieve a significant performance compared to the other methods designed for PTO problems."
  },
  {
    "title": "Generalized Demographic Parity for Group Fairness",
    "url": "/forum?id=YigKlMJwjye",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Generalized demographic parity, estimation error analysis",
    "Abstract": "This work aims to generalize demographic parity to continuous sensitive attributes while preserving tractable computation. Current fairness metrics for continuous sensitive attributes largely rely on intractable statistical independence between variables, such as Hirschfeld-Gebelein-Renyi (HGR) and mutual information. Statistical fairness metrics estimation relying on either tractable bounds or neural network approximation, however, are not sufficiently trustful to rank algorithms prediction bias due to lack of estimation accuracy guarantee. \n        To make fairness metrics trustable, we propose \\textit{\\underline{G}eneralized \\underline{D}emographic \\underline{P}arity} (GDP), a group fairness metric for continuous and discrete attributes. We show the understanding of GDP from the probability perspective and theoretically reveal the connection between GDP regularizer and adversarial debiasing. To estimate GDP, we adopt hard and soft group strategies via the one-hot or the soft group indicator, representing the membership of each sample in different groups of the sensitive attribute. We provably and numerically show that the soft group strategy achieves a faster estimation error convergence rate. Experiments show the better bias mitigation performance of GDP regularizer, compared with adversarial debiasing, for regression and classification tasks in tabular and graph benchmarks.",
    "One-sentence Summary": "This work aims to generalize demographic parity to continuous sensitive attributes while preserving tractable computation."
  },
  {
    "title": "Closed-form Sample Probing for Learning Generative Models in Zero-shot Learning",
    "url": "/forum?id=ljxWpdBl4V",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "zero-shot learning, generative zero-shot learning, generative models",
    "Abstract": "Generative model based approaches have led to significant advances in zero-shot learning (ZSL) over the past few years. These approaches typically aim to learn a conditional generator that synthesizes training samples of classes conditioned on class definitions. The final zero-shot learning model is then obtained by training a supervised classification model over the real and/or synthesized training samples of seen and unseen classes, combined. Therefore, naturally, the generative model needs to produce not only relevant samples, but also those that are sufficiently rich for classifier training purposes, which is handled by various heuristics in existing works. In this paper, we introduce a principled approach for training generative models {\\em directly} for training data generation purposes. Our main observation is that the use of closed-form models opens doors to end-to-end training thanks to the differentiability of the solvers. In our approach, at each generative model update step, we fit a task-specific closed-form ZSL model from generated samples, and measure its loss on novel samples all within the compute graph, a procedure that we refer to as {\\em sample probing}. In this manner, the generator receives feedback directly based on the value of its samples for model training purposes. Our experimental results show that the proposed sample probing approach improves the ZSL results even when integrated into state-of-the-art generative models.",
    "One-sentence Summary": "We show how to train a conditional generative model in a way that directly maximizes the value of its samples for zero-shot model training purposes."
  },
  {
    "title": "DKM: Differentiable k-Means Clustering Layer for Neural Network Compression",
    "url": "/forum?id=J_F_qqCE3Z5",
    "date": "28 Sept 2021 (modified: 20 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deep learning, neural network, compression",
    "Abstract": "Deep neural network (DNN) model compression for efficient on-device inference is becoming increasingly important to reduce memory requirements and keep user data on-device. To this end, we propose a novel differentiable k-means clustering layer (DKM) and its application to train-time weight clustering-based DNN model compression. DKM casts k-means clustering as an attention problem and enables joint optimization of the DNN parameters and clustering centroids. Unlike prior works that rely on additional regularizers and parameters, DKM-based compression keeps the original loss function and model architecture fixed. We evaluated DKM-based compression on various DNN models for computer vision and natural language processing (NLP) tasks. Our results demonstrate that DKM delivers superior compression and accuracy trade-off on ImageNet1k and GLUE benchmarks. For example, DKM-based compression can offer 74.5% top-1 ImageNet1k accuracy on ResNet50 DNN model with 3.3MB model size (29.4x model compression factor). For MobileNet-v1, which is a challenging DNN to compress, DKM delivers 63.9% top-1 ImageNet1k accuracy with 0.72 MB model size (22.4x model compression factor). This result is 6.8% higher top-1accuracy and 33% relatively smaller model size than the current state-of-the-art DNN compression algorithms. Additionally, DKM enables compression of DistilBERT model by 11.8x with minimal (1.1%) accuracy loss on GLUE NLP benchmarks.",
    "One-sentence Summary": "We propose a novel model compression scheme based on differentiable K-means layer, and it delivers the state-of-the-art results."
  },
  {
    "title": "Fixed Neural Network Steganography: Train the images, not the network",
    "url": "/forum?id=hcMvApxGSzZ",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Recent attempts at image steganography make use of advances in deep learning to train an encoder-decoder network pair to hide and retrieve secret messages in images. These methods are able to hide large amounts of data, but they also incur high decoding error rates (around 20%). In this paper, we propose a novel algorithm for steganography that takes advantage of the fact that neural networks are sensitive to tiny perturbations. Our method, Fixed Neural Network Steganography (FNNS), yields significantly lower error rates when compared to prior state-of-the-art methods and achieves 0% error reliably for hiding up to 3 bits per pixel (bpp) of secret information in images. FNNS also successfully evades existing statistical steganalysis systems and can be modified to evade neural steganalysis systems as well. Recovering every bit correctly, up to 3 bpp, enables novel applications that requires encryption. We introduce one specific use case for facilitating anonymized and safe image sharing.  Our code is available at https://github.com/varshakishore/FNNS.",
    "One-sentence Summary": "A novel method for steganography based on adversarial perturbations."
  },
  {
    "title": "Steerable Partial Differential Operators for Equivariant Neural Networks",
    "url": "/forum?id=N9W24a4zU",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "partial differential operators, equivariance, deep learning, steerability",
    "Abstract": "Recent work in equivariant deep learning bears strong similarities to physics. Fields over a base space are fundamental entities in both subjects, as are equivariant maps between these fields. In deep learning, however, these maps are usually defined by convolutions with a kernel, whereas they are partial differential operators (PDOs) in physics. Developing the theory of equivariant PDOs in the context of deep learning could bring these subjects even closer together and lead to a stronger flow of ideas. In this work, we derive a $G$-steerability constraint that completely characterizes when a PDO between feature vector fields is equivariant, for arbitrary symmetry groups $G$. We then fully solve this constraint for several important groups. We use our solutions as equivariant drop-in replacements for convolutional layers and benchmark them in that role. Finally, we develop a framework for equivariant maps based on Schwartz distributions that unifies classical convolutions and differential operators and gives insight about the relation between the two.",
    "One-sentence Summary": "We present a framework for equivariant partial differential operators, generalizing existing approaches and narrowing the gap between PDOs and convolutions."
  },
  {
    "title": "Divergence-aware Federated Self-Supervised Learning",
    "url": "/forum?id=oVE1z8NlNe",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Federated Learning, Self-supervised Learning, Unsupervised representation learning",
    "Abstract": "Self-supervised learning (SSL) is capable of learning remarkable representations from centrally available data. Recent works further implement federated learning with SSL to learn from rapidly growing decentralized unlabeled images (e.g., from cameras and phones), often resulted from privacy constraints. Extensive attention has been paid to SSL approaches based on Siamese networks. However, such an effort has not yet revealed deep insights into various fundamental building blocks for the federated self-supervised learning (FedSSL) architecture. We aim to fill in this gap via in-depth empirical study and propose a new method to tackle the non-independently and identically distributed (non-IID) data problem of decentralized data. Firstly, we introduce a generalized FedSSL framework that embraces existing SSL methods based on Siamese networks and presents flexibility catering to future methods. In this framework, a server coordinates multiple clients to conduct SSL training and periodically updates local models of clients with the aggregated global model. Using the framework, our study uncovers unique insights of FedSSL: 1) stop-gradient operation, previously reported to be essential, is not always necessary in FedSSL; 2) retaining local knowledge of clients in FedSSL is particularly beneficial for non-IID data. Inspired by the insights, we then propose a new approach for model update, Federated Divergence-aware Exponential Moving Average update (FedEMA). FedEMA updates local models of clients adaptively using EMA of the global model, where the decay rate is dynamically measured by model divergence. Extensive experiments demonstrate that FedEMA outperforms existing methods by 3-4% on linear evaluation. We hope that this work will provide useful insights for future research.",
    "One-sentence Summary": "We propose a new approach, FedEMA, to address the non-IID data challenge in federated self-supervised learning (FedSSL), inspired by deep insights uncovered from in-depth empirical studies using a newly introduced FedSSL framework."
  },
  {
    "title": "Neural Spectral Marked Point Processes",
    "url": "/forum?id=0rcbOaoBXbg",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Self- and mutually-exciting point processes are popular models in machine learning and statistics for dependent discrete event data. To date, most existing models assume stationary kernels (including the classical Hawkes processes) and simple parametric models. Modern applications with complex event data require more general point process models that can incorporate contextual information of the events, called marks, besides the temporal and location information. Moreover, such applications often require non-stationary models to capture more complex spatio-temporal dependence. To tackle these challenges, a key question is to devise a versatile influence kernel in the point process model. In this paper, we introduce a novel and general neural network-based non-stationary influence kernel with high expressiveness for handling complex discrete events data while providing theoretical performance guarantees. We demonstrate the superior performance of our proposed method compared with the state-of-the-art on synthetic and real data."
  },
  {
    "title": "How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data",
    "url": "/forum?id=Bn09TnDngN",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "backdoor learning, weight perturbation, consistency",
    "Abstract": "Since training a large-scale backdoored model from scratch requires a large training dataset, several recent attacks have considered to inject backdoors into a trained clean model without altering model behaviors on the clean data. Previous work finds that backdoors can be injected into a trained clean model with Adversarial Weight Perturbation (AWP), which means the variation of parameters are small in backdoor learning. In this work, we observe an interesting phenomenon that the variations of parameters are always AWPs when tuning the trained clean model to inject backdoors. We further provide theoretical analysis to explain this phenomenon. We are the first to formulate the behavior of maintaining accuracy on clean data as the consistency of backdoored models, which includes both global consistency and instance-wise consistency. We extensively analyze the effects of AWPs on the consistency of backdoored models. In order to achieve better consistency, we propose a novel anchoring loss to anchor or freeze the model behaviors on the clean data, with a theoretical guarantee.",
    "One-sentence Summary": "We propose a novel logit anchoring approach for better global and instance-wise consistency in backdoor learning."
  },
  {
    "title": "A Biologically Interpretable Graph Convolutional Network to Link Genetic Risk Pathways and Imaging Phenotypes of Disease",
    "url": "/forum?id=Lwr8We4MIxn",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Imaging-genetics, Hierarchical Graph Convolution, Gene Ontology, Bayesian Feature Selection, Schizophrenia",
    "Abstract": "We propose a novel end-to-end framework for whole-brain and whole-genome imaging-genetics. Our genetics network uses hierarchical graph convolution and pooling operations to embed subject-level data onto a low-dimensional latent space. The hierarchical network implicitly tracks the convergence of genetic risk across well-established biological pathways, while an attention mechanism automatically identifies the salient edges of this network at the subject level. In parallel, our imaging network projects multimodal data onto a set of latent embeddings. For interpretability, we implement a Bayesian feature selection strategy to extract the discriminative imaging biomarkers; these feature weights are optimized alongside the other model parameters. We couple the imaging and genetic embeddings with a predictor network, to ensure that the learned representations are linked to phenotype. We evaluate our framework on a schizophrenia dataset that includes two functional MRI paradigms and gene scores derived from Single Nucleotide Polymorphism data. Using repeated 10-fold cross-validation, we show that our imaging-genetics fusion achieves the better classification performance than state-of-the-art baselines. In an exploratory analysis, we further show that the biomarkers identified by our model are reproducible and closely associated with deficits in schizophrenia.",
    "One-sentence Summary": "Biologically Informed Imaging-Genetics"
  },
  {
    "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners",
    "url": "/forum?id=ek9a0qIafW",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "prompt-tuning, pre-trained language model, few-shot learning",
    "Abstract": "Large-scale pre-trained language models have contributed significantly to natural language processing by demonstrating remarkable abilities as few-shot learners. However, their effectiveness depends mainly on scaling the model parameters and prompt design, hindering their implementation in most real-world applications. This study proposes a novel pluggable, extensible, and efficient approach named DifferentiAble pRompT (DART), which can convert small language models into better few-shot learners. The main principle behind this approach involves reformulating potential natural language processing tasks into the task of a pre-trained language model and differentially optimizing the prompt template as well as the target label with backpropagation. Furthermore, the proposed approach can be: (i) Plugged to any pre-trained language models; (ii) Extended to widespread classification tasks. A comprehensive evaluation of standard NLP tasks demonstrates that the proposed approach achieves a better few-shot performance.",
    "One-sentence Summary": "A differentiable prompt learning method for few-shot NLP with optimized prompt templates as well as labels."
  },
  {
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "url": "/forum?id=yfe1VMYAXa4",
    "date": "28 Sept 2021 (modified: 15 Jun 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "pre-trained language model, knowledge graph, protein representation",
    "Abstract": "Self-supervised protein language models have proved their effectiveness in learning the proteins representations. With the increasing computational power, current protein language models pre-trained with millions of diverse sequences can advance the parameter scale from million-level to billion-level and achieve remarkable improvement. However, those prevailing approaches rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better protein representations. We argue that informative biology knowledge in KGs can enhance protein representation with external knowledge. In this work, we propose OntoProtein, the first general framework that makes use of structure in GO (Gene Ontology) into protein pre-training models. We construct a novel large-scale knowledge graph that consists of GO and its related proteins, and gene annotation texts or protein sequences describe all nodes in the graph. We propose novel contrastive learning with knowledge-aware negative sampling to jointly optimize the knowledge graph and protein embedding during pre-training.  Experimental results show that OntoProtein can surpass state-of-the-art methods with pre-trained protein language models in TAPE benchmark and yield better performance compared with baselines in protein-protein interaction and protein function prediction.",
    "One-sentence Summary": "A general framework to integrate knowledge graph (gene ontology) into protein pre-training."
  },
  {
    "title": "Permutation Compressors for Provably Faster Distributed Nonconvex Optimization",
    "url": "/forum?id=GugZ5DzzAu",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "MARINA, distributed training, permutation compressor, correlated compressor, Hessian variance, communication complexity, nonconvex optimization",
    "Abstract": "In this work we study the MARINA method of Gorbunov et al (ICML, 2021) -- the current state-of-the-art distributed non-convex optimization method in terms of theoretical communication complexity. Theoretical superiority of this method can be largely attributed to two sources: a carefully engineered biased stochastic gradient estimator, which leads to a reduction in the number of communication rounds, and  the reliance on\n         {\\em independent} stochastic communication compression, which leads to a reduction in the number of  transmitted bits within each communication round. In this paper we  i) extend the theory of MARINA to support a much wider class of potentially {\\em correlated} compressors, extending the reach of the method beyond the classical independent compressors setting,  ii) show that a new quantity, for which we coin the name {\\em Hessian variance}, allows us to significantly refine the original analysis of MARINA without any additional assumptions, and iii) identify a special class of correlated compressors based on the idea of {\\em random  permutations}, for which we coin the term Perm$K$, the use of which leads to up to $O(\\sqrt{n})$ (resp. $O(1 + d/\\sqrt{n})$) improvement in the theoretical communication complexity of MARINA in the low Hessian variance regime when $d\\geq n$ (resp. $d \\leq n$), where $n$ is the number of workers and $d$ is the number of parameters describing the model we are learning. We corroborate our theoretical results with carefully engineered synthetic experiments with minimizing the average of nonconvex quadratics, and on autoencoder training with the MNIST dataset.",
    "One-sentence Summary": "In this paper, we present the novel compression scheme for distributed non-convex optimization."
  },
  {
    "title": "Few-shot Learning via Dirichlet Tessellation Ensemble",
    "url": "/forum?id=6kCiVaoQdx9",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Few-shot Learning, Computational Geometry, Dirichlet Tessellation, Voronoi Diagram, Ensemble Learning",
    "Abstract": "Few-shot learning (FSL) is the process of rapid generalization from abundant base samples to inadequate novel samples. Despite extensive research in recent years, FSL is still not yet able to generate satisfactory solutions for a wide range of real-world applications. To confront this challenge, we study the FSL problem from a geometric point of view in this paper. One observation is that the widely embraced ProtoNet model is essentially a Voronoi Diagram (VD) in the feature space. We retrofit it by making use of a recent advance in computational geometry called Cluster-induced Voronoi Diagram (CIVD). Starting from the simplest nearest neighbor model, CIVD gradually incorporates cluster-to-point and then cluster-to-cluster relationships for space subdivision, which is used to improve the accuracy and robustness at multiple stages of FSL. Specifically, we use CIVD (1) to integrate parametric and nonparametric few-shot classifiers; (2) to combine feature representation and surrogate representation; (3) and to leverage feature-level, transformation-level, and geometry-level heterogeneities for a better ensemble. Our CIVD-based workflow enables us to achieve new state-of-the-art results on mini-ImageNet, CUB, and tiered-ImagenNet datasets, with ${\\sim}2\\%{-}5\\%$ improvements upon the next best. To summarize, CIVD provides a mathematically elegant and geometrically interpretable framework that compensates for extreme data insufficiency, prevents overfitting, and allows for fast geometric ensemble for thousands of individual VD. These together make FSL stronger.",
    "One-sentence Summary": "We developed a novel geometric framework that greatly improves few-shot classification, based on Cluster-induced Voronoi Diagram (CIVD)."
  },
  {
    "title": "Deep Point Cloud Reconstruction",
    "url": "/forum?id=mKDtUtxIGJ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Computer Vision, 3D Geometry, Deep Learning based Point Cloud Understanding, Point Cloud Denoising, Point Cloud Upsampling",
    "Abstract": "Point cloud obtained from 3D scanning is often sparse, noisy, and irregular. To cope with these issues, recent studies have been separately conducted to densify, denoise, and complete inaccurate point cloud. In this paper, we advocate that jointly solving these tasks leads to significant improvement for point cloud reconstruction. To this end, we propose a deep point cloud reconstruction network consisting of two stages: 1) a 3D sparse stacked-hourglass network as for the initial densification and denoising, 2) a refinement via transformers converting the discrete voxels into continuous 3D points. In particular, we further improve the performance of the transformers by a newly proposed module called amplified positional encoding. This module has been designed to differently amplify the magnitude of positional encoding vectors based on the points' distances for adaptive refinements. Extensive experiments demonstrate that our network achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNet datasets. Moreover, we underline the ability of our network to generalize toward real-world and unmet scenes.",
    "One-sentence Summary": "We propose deep learning-based point cloud reconstruction algorithm"
  },
  {
    "title": "$\\beta$-Intact-VAE: Identifying and Estimating Causal Effects under Limited Overlap",
    "url": "/forum?id=q7n2RngwOM",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "VAE, variational autoencoder, balanced representation Learning, treatment effects, causal inference, identifiability, identification, CATE, ATE, weak overlap, limited overlap, Prognostic Model, Prognostic score",
    "Abstract": "As an important problem in causal inference, we discuss the identification and estimation of treatment effects (TEs) under limited overlap; that is, when subjects with certain features belong to a single treatment group. We use a latent variable to model a prognostic score which is widely used in biostatistics and sufficient for TEs; i.e., we build a generative prognostic model. We prove that the latent variable recovers a prognostic score, and the model identifies individualized treatment effects. The model is then learned as $\\beta$-Intact-VAE\u2013\u2013a new type of variational autoencoder (VAE). We derive the TE error bounds that enable representations balanced for treatment groups conditioned on individualized features. The proposed method is compared with recent methods using (semi-)synthetic datasets.",
    "One-sentence Summary": "See all these naturally in one: limited overlap, prognostic score, identifiable VAE, balanced representation Learning, CATE error bounds."
  },
  {
    "title": "Promoting Saliency From Depth: Deep Unsupervised RGB-D Saliency Detection",
    "url": "/forum?id=BZnnMbt0pW",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "RGB-D saliency detection, salient object detection, deep learning, unsupervised learning",
    "Abstract": "Growing interests in RGB-D salient object detection (RGB-D SOD) have been witnessed in recent years, owing partly to the popularity of depth sensors and the rapid progress of deep learning techniques. Unfortunately, existing RGB-D SOD methods typically demand large quantity of training images being thoroughly annotated at pixel-level. The laborious and time-consuming manual annotation has become a real bottleneck in various practical scenarios. On the other hand, current unsupervised RGB-D SOD methods still heavily rely on handcrafted feature representations. This inspires us to propose in this paper a deep unsupervised RGB-D saliency detection approach, which requires no manual pixel-level annotation during training. It is realized by two key ingredients in our training pipeline. First, a depth-disentangled saliency update (DSU) framework is designed to automatically produce pseudo-labels with iterative follow-up refinements, which provides more trustworthy supervision signals for training the saliency network. Second, an attentive training strategy is introduced to tackle the issue of noisy pseudo-labels, by properly re-weighting to highlight the more reliable pseudo-labels. Extensive experiments demonstrate the superior efficiency and effectiveness of our approach in tackling the challenging unsupervised RGB-D SOD scenarios. Moreover, our approach can also be adapted to work in fully-supervised situation. Empirical studies show the incorporation of our approach gives rise to notably performance improvement in existing supervised RGB-D SOD models.",
    "One-sentence Summary": "We propose the first deep unsupervised RGB-D saliency detection method, which achieves appealing performance and does not require any human efforts compared to fully-supervised learning."
  },
  {
    "title": "Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph",
    "url": "/forum?id=AXWygMvuT6Q",
    "date": "28 Sept 2021 (modified: 05 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Content-style decomposed representation, Zero-shot voice conversion, Style transfer, Transformer, Unsupervised learning",
    "Abstract": "This paper addresses the unsupervised learning of content-style decomposed representation. We first give a definition of style and then model the content-style representation as a token-level bipartite graph. An unsupervised framework, named Retriever, is proposed to learn such representations. First, a cross-attention module is employed to retrieve permutation invariant (P.I.) information, defined as style, from the input data. Second, a vector quantization (VQ) module is used, together with man-induced constraints, to produce interpretable content tokens. Last, an innovative link attention module serves as the decoder to reconstruct data from the decomposed content and style, with the help of the linking keys. Being modal-agnostic, the proposed Retriever is evaluated in both speech and image domains. The state-of-the-art zero-shot voice conversion performance confirms the disentangling ability of our framework. Top performance is also achieved in the part discovery task for images, verifying the interpretability of our representation. In addition, the vivid part-based style transfer quality demonstrates the potential of Retriever to support various fascinating generative tasks. Project page at https://ydcustc.github.io/retriever-demo/.",
    "One-sentence Summary": "We propose a model-agnostic and unsupervised framework to learn a novel token-level bipartite graph representation of content and style from structured input."
  },
  {
    "title": "Neural Markov Controlled SDE: Stochastic Optimization for Continuous-Time Data",
    "url": "/forum?id=7DI6op61AY",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "controlled stochastic differential equation, time-series prediction",
    "Abstract": "We propose a novel probabilistic framework for modeling stochastic dynamics with the rigorous use of stochastic optimal control theory. The proposed model called the neural Markov controlled stochastic differential equation (CSDE) overcomes the fundamental and structural limitations of conventional dynamical models by introducing the following two components: (1) Markov dynamic programming to efficiently train the proposed CSDE and (2) multi-conditional forward-backward losses to provide rich information for accurate inference and to assure theoretical optimality. We demonstrate that our dynamical model efficiently generates a complex time series in the data space without extra networks while showing comparable performance against existing model-based methods on several datasets.",
    "One-sentence Summary": "We propose a novel probabilistic framework for modelling stochastic dynamics with the rigorous use of optimal control theory."
  },
  {
    "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention",
    "url": "/forum?id=_PHymLIxuI",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "vision transformers, architecture",
    "Abstract": "Transformers have made great progress in dealing with computer vision tasks. However, existing vision transformers have not yet possessed the ability of building the interactions among features of different scales, which is perceptually important to visual inputs. The reasons are two-fold: (1) Input embeddings of each layer are equal-scale, so no cross-scale feature can be extracted; (2) to lower the computational cost, some vision transformers merge adjacent embeddings inside the self-attention module, thus sacrificing small-scale (fine-grained) features of the embeddings and also disabling the cross-scale interactions. To this end, we propose Cross-scale Embedding Layer (CEL) and Long Short Distance Attention (LSDA). On the one hand, CEL blends each embedding with multiple patches of different scales, providing the self-attention module itself with cross-scale features. On the other hand, LSDA splits the self-attention module into a short-distance one and a long-distance counterpart, which not only reduces the computational burden but also keeps both small-scale and large-scale features in the embeddings. Through the above two designs, we achieve cross-scale attention. Besides, we put forward a dynamic position bias for vision transformers to make the popular relative position bias apply to variable-sized images. Hinging on the cross-scale attention module, we construct a versatile vision architecture, dubbed CrossFormer, which accommodates variable-sized inputs. Extensive experiments show that CrossFormer outperforms the other vision transformers on image classification, object detection, instance segmentation, and semantic segmentation tasks."
  },
  {
    "title": "Adversarially Robust Conformal Prediction",
    "url": "/forum?id=9L1BsI4wP1H",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Conformal Prediction, Adversarial Robustness, Randomized Smoothing, Uncertainty Estimation, Calibration",
    "Abstract": "Conformal prediction is a model-agnostic tool for constructing prediction sets that are valid under the common i.i.d. assumption, which has been applied to quantify the prediction uncertainty of deep net classifiers. In this paper, we generalize this framework to the case where adversaries exist during inference time, under which the i.i.d. assumption is grossly violated. By combining conformal prediction with randomized smoothing, our proposed method forms a prediction set with finite-sample coverage guarantee that holds for any data distribution with $\\ell_2$-norm bounded adversarial noise, generated by any adversarial attack algorithm. The core idea is to bound the Lipschitz constant of the non-conformity score by smoothing it with Gaussian noise and leverage this knowledge to account for the effect of the unknown adversarial perturbation. We demonstrate the necessity of our method in the adversarial setting and the validity of our theoretical guarantee on three widely used benchmark data sets: CIFAR10, CIFAR100, and ImageNet.",
    "One-sentence Summary": "Multi-class calibration procedure that is provably robust to adversarial attacks"
  },
  {
    "title": "Hot-Refresh Model Upgrades with Regression-Free Compatible Training in Image Retrieval",
    "url": "/forum?id=HTp-6yLGGX",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Compatible Representation Learning, Image Retrieval, Model Regression",
    "Abstract": "The task of hot-refresh model upgrades of image retrieval systems plays an essential role in the industry but has never been investigated in academia before. Conventional cold-refresh model upgrades can only deploy new models after the gallery is overall backfilled, taking weeks or even months for massive data. In contrast, hot-refresh model upgrades deploy the new model immediately and then gradually improve the retrieval accuracy by backfilling the gallery on-the-fly. Compatible training has made it possible, however, the problem of model regression with negative flips poses a great challenge to the stable improvement of user experience. We argue that it is mainly due to the fact that new-to-old positive query-gallery pairs may show less similarity than new-to-new negative pairs. To solve the problem, we introduce a Regression-Alleviating Compatible Training (RACT) method to properly constrain the feature compatibility while reducing negative flips. The core is to encourage the new-to-old positive pairs to be more similar than both the new-to-old negative pairs and the new-to-new negative pairs. An efficient uncertainty-based backfilling strategy is further introduced to fasten accuracy improvements. Extensive experiments on large-scale retrieval benchmarks (e.g., Google Landmark) demonstrate that our RACT effectively alleviates the model regression for one more step towards seamless model upgrades.",
    "One-sentence Summary": "We for the first time study the model regression problem in hot-refresh model upgrades of image retrieval systems with compatible representation learning."
  },
  {
    "title": "Visual Representation Learning over Latent Domains",
    "url": "/forum?id=kG0AtPi6JI1",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "transfer learning, latent domains, computer vision",
    "Abstract": "A fundamental shortcoming of deep neural networks is their specialization to a single task and domain. While multi-domain learning enables the learning of compact models that span multiple visual domains, these rely on the presence of domain labels, in turn requiring laborious curation of datasets. This paper proposes a less explored, but highly realistic new setting called latent domain learning: learning over data from different domains, without access to domain annotations. Experiments show that this setting is challenging for standard models and existing multi-domain approaches, calling for new customized solutions: a sparse adaptation strategy is formulated which enhances performance by accounting for latent domains in data. Our method can be paired seamlessly with existing models, and benefits conceptually related tasks, e.g. empirical fairness problems and long-tailed recognition.",
    "One-sentence Summary": "A new setting for learning over data with multiple latent domains is introduced, alongside new methods for it."
  },
  {
    "title": "Chemical-Reaction-Aware Molecule Representation Learning",
    "url": "/forum?id=6sh3pIzKS-",
    "date": "28 Sept 2021 (modified: 23 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "molecule representation learning, graph neural networks, chemical reaction",
    "Abstract": "Molecule representation learning (MRL) methods aim to embed molecules into a real vector space. However, existing SMILES-based (Simplified Molecular-Input Line-Entry System) or GNN-based (Graph Neural Networks) MRL methods either take SMILES strings as input that have difficulty in encoding molecule structure information, or over-emphasize the importance of GNN architectures but neglect their generalization ability. Here we propose using chemical reactions to assist learning molecule representation. The key idea of our approach is to preserve the equivalence of molecules with respect to chemical reactions in the embedding space, i.e., forcing the sum of reactant embeddings and the sum of product embeddings to be equal for each chemical equation. This constraint is proven effective to 1) keep the embedding space well-organized and 2) improve the generalization ability of molecule embeddings. Moreover, our model can use any GNN as the molecule encoder and is thus agnostic to GNN architectures. Experimental results demonstrate that our method achieves state-of-the-art performance in a variety of downstream tasks, e.g., reaction product prediction, molecule property prediction, reaction classification, and graph-edit-distance prediction. The code is available at https://github.com/hwwang55/MolR.",
    "One-sentence Summary": "We make use of chemical reactions to improve the generalization ability of learned molecule embeddings"
  },
  {
    "title": "Skill-based Meta-Reinforcement Learning",
    "url": "/forum?id=jeLW-Fh9bV",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "meta-RL, meta-reinforcement learning, skill-based meta-reinforcement learning, meta-learning, skill-based RL",
    "Abstract": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks."
  },
  {
    "title": "InfinityGAN: Towards Infinite-Pixel Image Synthesis",
    "url": "/forum?id=ufGMqIM0a4b",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "generative modeling, image synthesis, generative adversarial networks, infinite-pixel synthesis, GANs",
    "Abstract": "We present InfinityGAN, a method to generate arbitrary-sized images. The problem is associated with several key challenges. First, scaling existing models to an arbitrarily large image size is resource-constrained, both in terms of computation and availability of large-field-of-view training data. InfinityGAN trains and infers patch-by-patch seamlessly with low computational resources. Second, large images should be locally and globally consistent, avoid repetitive patterns, and look realistic. To address these, InfinityGAN takes global appearance, local structure and texture into account. With this formulation, we can generate images with spatial size and level of detail not attainable before. Experimental evaluation supports that InfinityGAN generates images with superior global structure compared to baselines and features parallelizable inference. Finally, we show several applications unlocked by our approach, such as fusing styles spatially, multi-modal outpainting and image inbetweening at arbitrary input and output sizes.",
    "One-sentence Summary": "InfinityGAN learns to synthesize arbitrary-sized images with limited resources and enables multiple new applications."
  },
  {
    "title": "Shuffle Private Stochastic Convex Optimization",
    "url": "/forum?id=DrZXuTGg2A-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "shuffle privacy, stochastic convex optimization, differential privacy",
    "Abstract": "In shuffle privacy, each user sends a collection of randomized messages to a trusted shuffler, the shuffler randomly permutes these messages, and the resulting shuffled collection of messages must satisfy differential privacy. Prior work in this model has largely focused on protocols that use a single round of communication to compute algorithmic primitives like means, histograms, and counts. In this work, we present interactive shuffle protocols for stochastic convex optimization. Our optimization protocols rely on a new noninteractive protocol for summing vectors of bounded $\\ell_2$ norm. By combining this sum subroutine with techniques including mini-batch stochastic gradient descent, accelerated gradient descent, and Nesterov's smoothing method, we obtain loss guarantees for a variety of convex loss functions that significantly improve on those of the local model and sometimes match those of the central model.",
    "One-sentence Summary": "The first analysis of shuffle private stochastic convex optimization."
  },
  {
    "title": "Know Your Action Set: Learning Action Relations for Reinforcement Learning",
    "url": "/forum?id=MljXVdp4A3N",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, varying action space, relational reasoning",
    "Abstract": "Intelligent agents can solve tasks in various ways depending on their available set of actions. However, conventional reinforcement learning (RL) assumes a fixed action set. This work asserts that tasks with varying action sets require reasoning of the relations between the available actions. For instance, taking a nail-action in a repair task is meaningful only if a hammer-action is also available. To learn and utilize such action relations, we propose a novel policy architecture consisting of a graph attention network over the available actions. We show that our model makes informed action decisions by correctly attending to other related actions in both value-based and policy-based RL. Consequently, it outperforms non-relational architectures on applications where the action space often varies, such as recommender systems and physical reasoning with tools and skills. Results and code at https://sites.google.com/view/varyingaction .",
    "One-sentence Summary": "Learning action interdependence for reinforcement learning under a varying action space."
  },
  {
    "title": "On the Importance of Difficulty Calibration in Membership Inference Attacks",
    "url": "/forum?id=3eIrli0TwQ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "membership inference attack, privacy",
    "Abstract": "The vulnerability of machine learning models to membership inference attacks has received much attention in recent years. However, existing attacks mostly remain impractical due to having high false positive rates, where non-member samples are often erroneously predicted as members. This type of error makes the predicted membership signal unreliable, especially since most samples are non-members in real world applications. In this work, we argue that membership inference attacks can benefit drastically from difficulty calibration, where an attack's predicted membership score is adjusted to the difficulty of correctly classifying the target sample. We show that difficulty calibration can significantly reduce the false positive rate of a variety of existing attacks without a loss in accuracy.",
    "One-sentence Summary": "Membership inference attacks can greatly benefit from a technique called difficulty calibration, significantly improving their reliability."
  },
  {
    "title": "Entroformer: A Transformer-based Entropy Model for Learned Image Compression",
    "url": "/forum?id=VrjOFfcnSV8",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Image compression, Entropy Model, Global Dependencies",
    "Abstract": "One critical component in lossy deep image compression is the entropy model, which predicts the probability distribution of the quantized latent representation in the encoding and decoding modules. Previous works build entropy models upon convolutional neural networks which are inefficient in capturing global dependencies. In this work, we propose a novel transformer-based entropy model, termed Entroformer, to capture long-range dependencies in probability distribution estimation effectively and efficiently. Different from vision transformers in image classification, the Entroformer is highly optimized for image compression, including a top-k self-attention and a diamond relative position encoding. Meanwhile, we further expand this architecture with a parallel bidirectional context model to speed up the decoding process. The experiments show that the Entroformer achieves state-of-the-art performance on image compression while being time-efficient.",
    "One-sentence Summary": "In this work, we propose a novel transformer-based entropy model, termed Entroformer, to capture long-range dependencies in probability distribution estimation effectively and efficiently."
  },
  {
    "title": "Dual Lottery Ticket Hypothesis",
    "url": "/forum?id=fOsN52jn25l",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Dual Lottery Ticket Hypothesis, Sparse Network Training",
    "Abstract": "Fully exploiting the learning capacity of neural networks requires overparameterized dense networks. On the other side, directly training sparse neural networks typically results in unsatisfactory performance. Lottery Ticket Hypothesis (LTH) provides a novel view to investigate sparse network training and maintain its capacity. Concretely, it claims there exist winning tickets from a randomly initialized network found by iterative magnitude pruning and preserving promising trainability (or we say being in trainable condition). In this work, we regard the winning ticket from LTH as the subnetwork which is in trainable condition and its performance as our benchmark, then go from a complementary direction to articulate the Dual Lottery Ticket Hypothesis (DLTH): Randomly selected subnetworks from a randomly initialized dense network can be transformed into a trainable condition and achieve admirable performance compared with LTH --- random tickets in a given lottery pool can be transformed into winning tickets. Specifically, by using uniform-randomly selected subnetworks to represent the general cases, we propose a simple sparse network training strategy, Random Sparse Network Transformation (RST), to substantiate our DLTH. Concretely, we introduce a regularization term to borrow learning capacity and realize information extrusion from the weights which will be masked. After finishing the transformation for the randomly selected subnetworks, we conduct the regular finetuning to evaluate the model using fair comparisons with LTH and other strong baselines. Extensive experiments on several public datasets and comparisons with competitive approaches validate our DLTH as well as the effectiveness of the proposed model RST. Our work is expected to pave a way for inspiring new research directions of sparse network training in the future. Our code is available at https://github.com/yueb17/DLTH.",
    "One-sentence Summary": "We articulate a Dual Lottery Ticket Hypothesis (DLTH) with a proposed training strategy Random Sparse Network to validate DLTH."
  },
  {
    "title": "GNN is a Counter? Revisiting GNN for Question Answering",
    "url": "/forum?id=hzmQ4wOnSb",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "GNN, Question Answering, QA, Reasoning, ML",
    "Abstract": "Question Answering (QA) has been a long-standing research topic in AI and NLP fields, and a wealth of studies has been conducted to attempt to equip QA systems with human-level reasoning capability. To approximate the complicated human reasoning process, state-of-the-art QA systems commonly use pre-trained language models (LMs) to access knowledge encoded in LMs together with elaborately designed modules based on Graph Neural Networks (GNNs) to perform reasoning over knowledge graphs (KGs). However, many problems remain open regarding the reasoning functionality of these GNN-based modules. Can these GNN-based modules really perform a complex reasoning process? Are they under- or over-complicated for QA? To open the black box of GNN and investigate these problems, we dissect state-of-the-art GNN modules for QA and analyze their reasoning capability. We discover that even a very simple graph neural counter can outperform all the existing GNN modules on CommonsenseQA and OpenBookQA, two popular QA benchmark datasets which heavily rely on knowledge-aware reasoning. Our work reveals that existing knowledge-aware GNN modules may only carry out some simple reasoning such as counting. It remains a challenging open problem to build comprehensive reasoning modules for knowledge-powered QA.",
    "One-sentence Summary": "Counting is essential for reasoning and our simplistic graph neural counter is efficient and effective for QA tasks."
  },
  {
    "title": "IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes",
    "url": "/forum?id=OT3mLgR8Wg8",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Inter-object Functional Relationship, Learning Interactive Policy for Exploration, Interactive Perception, 3D Scene Understanding",
    "Abstract": "Building embodied intelligent agents that can interact with 3D indoor environments has received increasing research attention in recent years. While most works focus on single-object or agent-object visual functionality and affordances, our work proposes to study a novel, underexplored, kind of visual relations that is also important to perceive and model -- inter-object functional relationships (e.g., a switch on the wall turns on or off the light, a remote control operates the TV). Humans often spend no effort or only a little to infer these relationships, even when entering a new room, by using our strong prior knowledge (e.g., we know that buttons control electrical devices) or using only a few exploratory interactions in cases of uncertainty (e.g., multiple switches and lights in the same room). In this paper, we take the first step in building AI system learning inter-object functional relationships in 3D indoor environments with key technical contributions of modeling prior knowledge by training over large-scale scenes and designing interactive policies for effectively exploring the training scenes and quickly adapting to novel test scenes. We create a new dataset based on the AI2Thor and PartNet datasets and perform extensive experiments that prove the effectiveness of our proposed method.",
    "One-sentence Summary": "We formulate a novel problem of learning inter-object functional relationships in 3D indoor environments and propose a novel method that combines prior knowledge modeling and interactive policy learning to solve the task."
  },
  {
    "title": "VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects",
    "url": "/forum?id=iEx3PiooLy",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Visual Representation Learning for Robotics, Robotic Affordance and Trajectories, 3D Shape Understanding",
    "Abstract": "Perceiving and manipulating 3D articulated objects (e.g., cabinets, doors) in human environments is an important yet challenging task for future home-assistant robots. The space of 3D articulated objects is exceptionally rich in their myriad semantic categories, diverse shape geometry, and complicated part functionality. Previous works mostly abstract kinematic structure with estimated joint parameters and part poses as the visual representations for manipulating 3D articulated objects. In this paper, we propose object-centric actionable visual priors as a novel perception-interaction handshaking point that the perception system outputs more actionable guidance than kinematic structure estimation, by predicting dense geometry-aware, interaction-aware, and task-aware visual action affordance and trajectory proposals. We design an interaction-for-perception framework VAT-Mart to learn such actionable visual representations by simultaneously training a curiosity-driven reinforcement learning policy exploring diverse interaction trajectories and a perception module summarizing and generalizing the explored knowledge for pointwise predictions among diverse shapes. Experiments prove the effectiveness of the proposed approach using the large-scale PartNet-Mobility dataset in SAPIEN environment and show promising generalization capabilities to novel test shapes, unseen object categories, and real-world data.",
    "One-sentence Summary": "We propose a novel interaction-for-perception framework to learn visual actionable representations (i.e. affordance and action trajectory proposals) for robotic manipulation."
  },
  {
    "title": "Neural graphical modelling in continuous-time: consistency guarantees and algorithms",
    "url": "/forum?id=SsHBkfeRF9L",
    "date": "28 Sept 2021 (modified: 03 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Dynamical systems, graphical modelling, structure learning",
    "Abstract": "The discovery of structure from time series data is a key problem in fields of study working with complex systems. Most identifiability results and learning algorithms assume the underlying dynamics to be discrete in time. Comparatively few, in contrast, explicitly define dependencies in infinitesimal intervals of time, independently of the scale of observation and of the regularity of sampling. In this paper, we consider score-based structure learning for the study of dynamical systems. We prove that for vector fields parameterized in a large class of neural networks, least squares optimization with adaptive regularization schemes consistently recovers directed graphs of local independencies in systems of stochastic differential equations. Using this insight, we propose a score-based learning algorithm based on penalized Neural Ordinary Differential Equations (modelling the mean process) that we show to be applicable to the general setting of irregularly-sampled multivariate time series and to outperform the state of the art across a range of dynamical systems.",
    "One-sentence Summary": "We present algorithms and consistency guarantees for graphical modelling in dynamical systems."
  },
  {
    "title": "C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks",
    "url": "/forum?id=K2JfSnLBD9",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, planning, variational inference, curriculum learning, waypoints, subgoals",
    "Abstract": "Goal-conditioned reinforcement learning (RL) has shown great success recently at solving a wide range of tasks(e.g., navigation, robotic manipulation). However, learning to reach distant goals remains a central challenge to the field, and the task is particularly hard without any offline data, expert demonstrations, and reward shaping. In this paper, we propose to solve the distant goal-reaching task by using search at training time to generate a curriculum of intermediate states.  Specifically, we introduce the algorithm Classifier-Planning (C-Planning) by framing the learning of the goal-conditioned policies as variational inference. C-Planning naturally follows expectation maximization (EM): the E-step corresponds to planning an optimal sequence of waypoints using graph search, while the M-step aims to learn a goal-conditioned policy to reach those waypoints. One essential difficulty of designing such an algorithm is accurately modeling the distribution over way-points to sample from. In C-Planning, we propose to sample the waypoints using contrastive methods to learn a value function. Unlike prior methods that combine goal-conditioned RL with graph search, ours performs search only during training and not testing, significantly decreasing the compute costs of deploying the learned policy.  Empirically,  we demonstrate that our method not only improves the sample efficiency of prior methods but also successfully solves temporally extended navigation and manipulation tasks,  where prior goal-conditioned RL methods (including those based on graph search) fail to solve.",
    "One-sentence Summary": "An algorithm for goal-conditioned RL that uses an automatic curriculum of waypoints during exploration, derived from variational inference."
  },
  {
    "title": "NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy",
    "url": "/forum?id=0DLwqQLmqV",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "neural architecture search, AutoML",
    "Abstract": "The release of tabular benchmarks, such as NAS-Bench-101 and NAS-Bench-201, has significantly lowered the computational overhead for conducting scientific research in neural architecture search (NAS). Although they have been widely adopted and used to tune real-world NAS algorithms, these benchmarks are limited to small search spaces and focus solely on image classification. Recently, several new NAS benchmarks have been introduced that cover significantly larger search spaces over a wide range of tasks, including object detection, speech recognition, and natural language processing. However, substantial differences among these NAS benchmarks have so far prevented their widespread adoption, limiting researchers to using just a few benchmarks. In this work, we present an in-depth analysis of popular NAS algorithms and performance prediction methods across 25 different combinations of search spaces and datasets, finding that many conclusions drawn from a few NAS benchmarks do \\emph{not} generalize to other benchmarks. To help remedy this problem, we introduce \\nasbs, a comprehensive and extensible collection of NAS benchmarks, accessible through a unified interface, created with the aim to facilitate reproducible, generalizable, and rapid NAS research. Our code is available at https://github.com/automl/naslib.",
    "One-sentence Summary": "We show that you cannot get away only with NAS-Bench-101 and -201; to fix this, we release a unified NAS benchmark suite with 25 benchmarks."
  },
  {
    "title": "Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality",
    "url": "/forum?id=mhYUBYNoGz",
    "date": "28 Sept 2021 (modified: 01 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Numerical PDE, non-parametric statistics, computational physics",
    "Abstract": "In this paper, we study the statistical limits of deep learning techniques for solving elliptic partial differential equations (PDEs) from random samples using the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs). To simplify the problem, we focus on a prototype elliptic PDE: the Schr\\\"odinger equation on a hypercube with zero Dirichlet boundary condition, which has wide application in the quantum-mechanical systems. We establish upper and lower bounds for both methods, which improves upon concurrently developed upper bounds for this problem via a fast rate generalization bound. We discover that the current Deep Ritz Methods is sub-optimal and propose a modified version of it. We also prove that PINN and the modified version of DRM can achieve minimax optimal bounds over Sobolev spaces. Empirically, following recent work which has shown that the deep model accuracy will improve with growing training sets according to a power law, we supply computational experiments to show a similar behavior of dimension dependent power law for deep PDE solvers.",
    "One-sentence Summary": "We provided min-max optimal convergence bound for machine learning based PDE solvers and numerically verified the scaling law."
  },
  {
    "title": "Variational oracle guiding for reinforcement learning",
    "url": "/forum?id=pjqqxepwoMy",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "variational Bayes, oracle guiding, reinforcement learning, decision making, probabilistic modeling, game, Mahjong",
    "Abstract": "How to make intelligent decisions is a central problem in machine learning and artificial intelligence. Despite recent successes of deep reinforcement learning (RL) in various decision making problems, an important but under-explored aspect is how to leverage oracle observation (the information that is invisible during online decision making, but is available during offline training) to facilitate learning. For example, human experts will look at the replay after a Poker game, in which they can check the opponents' hands to improve their estimation of the opponents' hands from the visible information during playing. In this work, we study such problems based on Bayesian theory and derive an objective to leverage oracle observation in RL using variational methods. Our key contribution is to propose a general learning framework referred to as variational latent oracle guiding (VLOG) for DRL. VLOG is featured with preferable properties such as its robust and promising performance and its versatility to incorporate with any value-based DRL algorithm. We empirically demonstrate the effectiveness of VLOG in online and offline RL domains with tasks ranging from video games to a challenging tile-based game Mahjong. Furthermore, we publish the Mahjong environment and an offline RL dataset as a benchmark to facilitate future research on oracle guiding (https://github.com/Agony5757/mahjong).",
    "One-sentence Summary": "We propose a variational Bayes framework leveraging oracle (hindsight) information available in training to improve deep reinforcement learning."
  },
  {
    "title": "CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation",
    "url": "/forum?id=XGzk5OKWFFc",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from a labeled source domain to a different unlabeled target domain. Most existing UDA methods focus on learning domain-invariant feature representation, either from the domain level or category level, using convolution neural networks (CNNs)-based frameworks. One fundamental problem for the category level based UDA is the production of pseudo labels for samples in target domain, which are usually too noisy for accurate domain alignment, inevitably compromising the UDA performance.  With the success of Transformer in various tasks, we find that the cross-attention in Transformer is robust to the noisy input pairs for better feature alignment, thus in this paper Transformer is adopted for the challenging UDA task. Specifically, to generate accurate input pairs, we design a two-way center-aware labeling algorithm to produce pseudo labels for target samples. Along with the pseudo labels, a weight-sharing triple-branch transformer framework is proposed to apply self-attention and cross-attention for source/target feature learning and source-target domain alignment, respectively. \n        Such design explicitly enforces the framework to learn discriminative domain-specific and domain-invariant representations simultaneously. The proposed method is dubbed CDTrans (cross-domain transformer), and it provides one of the first attempts to solve UDA tasks with a pure transformer solution. Experiments show that our proposed method achieves the best performance on public UDA datasets, e.g. VisDA-2017 and DomainNet. Code and models are available at https://github.com/CDTrans/CDTrans."
  },
  {
    "title": "Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains",
    "url": "/forum?id=QkRV50TZyP",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "practice black-box attack, cross-domain transferability",
    "Abstract": "Adversarial examples have posed a severe threat to deep neural networks due to their transferable nature. Currently, various works have paid great efforts to enhance the cross-model transferability, which mostly assume the substitute model is trained in the same domain as the target model.\n        However, in reality, the relevant information of the deployed model is unlikely to leak.\n        Hence, it is vital to build a more practical black-box threat model to overcome this limitation and evaluate the vulnerability of deployed models.\n        In this paper, with only the knowledge of the ImageNet domain, we propose a Beyond ImageNet Attack (BIA) to investigate the transferability towards black-box domains (unknown classification tasks). Specifically, we leverage a generative model to learn the adversarial function for disrupting low-level features of input images. \n        Based on this framework, we further propose two variants to narrow the gap between the source and target domains from the data and model perspectives, respectively. Extensive experiments on coarse-grained and fine-grained domains demonstrate the effectiveness of our proposed methods. Notably,\n        our methods outperform state-of-the-art approaches by up to 7.71\\% (towards coarse-grained domains) and 25.91\\% (towards fine-grained domains) on average. Our code is available at \\url{https://github.com/Alibaba-AAIG/Beyond-ImageNet-Attack}.",
    "One-sentence Summary": "We propose an effective method that can craft adversarial examples for black-box domain."
  },
  {
    "title": "Learning to Schedule Learning rate with Graph Neural Networks",
    "url": "/forum?id=k7efTb0un9z",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "learning rate scheduling, graph neural networks",
    "Abstract": "Recent decades have witnessed great development of stochastic optimization in training deep neural networks. Learning rate scheduling is one of the most important factors that influence the performance of stochastic optimizers like Adam. Traditional methods seek to find a relatively proper scheduling among a limited number of pre-defined rules and might not accommodate a particular target problem. Instead, we propose a novel Graph-Network-based Scheduler (GNS), aiming at learning a specific scheduling mechanism without restrictions to existing principles. By constructing a directed graph for the underlying neural network of the target problem, GNS encodes current dynamics with a graph message passing network and trains an agent to control the learning rate accordingly via reinforcement learning. The proposed scheduler can capture the intermediate layer information while being able to generalize to problems of varying scales. Besides, an efficient reward collection procedure is leveraged to speed up training. We evaluate our framework on benchmarking datasets, Fashion-MNIST and CIFAR10 for image classification, and GLUE for language understanding. GNS shows consistent improvement over popular baselines when training CNN and Transformer models. Moreover, GNS demonstrates great generalization to different datasets and network structures.",
    "One-sentence Summary": "We propose a novel Graph-Network-based Scheduler (GNS), which is both informative to to encode rich information and generalizable to different architectures."
  },
  {
    "title": "SketchODE: Learning neural sketch representation in continuous time",
    "url": "/forum?id=c-4HSDAWua5",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Chirography, Sketch, Free-form, Neural ODE",
    "Abstract": "Learning meaningful representations for chirographic drawing data such as sketches, handwriting, and flowcharts is a gateway for understanding and emulating human creative expression. Despite being inherently continuous-time data, existing works have treated these as discrete-time sequences, disregarding their true nature. In this work, we model such data as continuous-time functions and learn compact representations by virtue of Neural Ordinary Differential Equations. To this end, we introduce the first continuous-time Seq2Seq model and demonstrate some remarkable properties that set it apart from traditional discrete-time analogues. We also provide solutions for some practical challenges for such models, including introducing a family of parameterized ODE dynamics & continuous-time data augmentation particularly suitable for the task. Our models are validated on several datasets including VectorMNIST, DiDi and Quick, Draw!.",
    "One-sentence Summary": "Modelling continuous time chirographic structures like handwriting, diagrams, sketches etc with Neural Ordinary Differential Equations."
  },
  {
    "title": "Measuring the Interpretability of Unsupervised Representations via Quantized Reversed Probing",
    "url": "/forum?id=HFPTzdwN39",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Representation learning, Computer vision, Interpretability",
    "Abstract": "Self-supervised visual representation learning has recently attracted significant research interest. While a common way to evaluate self-supervised representations is through transfer to various downstream tasks, we instead investigate the problem of measuring their interpretability, i.e. understanding the semantics encoded in raw representations. We formulate the latter as estimating the mutual information between the representation and a space of manually labelled concepts. To quantify this we introduce a decoding bottleneck: information must be captured by simple predictors, mapping concepts to clusters in representation space. This approach, which we call reverse linear probing, provides a single number sensitive to the semanticity of the representation. This measure is also able to detect when the representation contains combinations of concepts (e.g., \"red apple'') instead of just individual attributes (\"red'' and \"apple'' independently). Finally, we propose to use supervised classifiers to automatically label large datasets in order to enrich the space of concepts used for probing. We use our method to evaluate a large number of self-supervised representations, ranking them by interpretability, highlight the differences that emerge compared to the standard evaluation with linear probes and discuss several qualitative insights. Code at: https://github.com/iro-cp/ssl-qrp.",
    "One-sentence Summary": "We propose quantized reverse probing as a information-theoretic measure to assess the degree to which self-supervised visual representations align with human-interpretable concepts."
  },
  {
    "title": "GradMax: Growing Neural Networks using Gradient Information",
    "url": "/forum?id=qjN4h_wwUO",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "efficient training, efficient, computer vision, architecture search",
    "Abstract": "The architecture and the parameters of neural networks are often optimized independently, which requires costly retraining of the parameters whenever the architecture is modified. In this work we instead focus on growing the architecture without requiring costly retraining. We present a method that adds new neurons during training without impacting what is already learned, while improving the training dynamics. We achieve the latter by maximizing the gradients of the new weights  and  efficiently  find  the  optimal  initialization  by  means  of  the  singular value decomposition (SVD). We call this technique Gradient Maximizing Growth (GradMax) and demonstrate its effectiveness in variety of vision tasks and architectures. We open sourced our code at https://github.com/google-research/growneuron",
    "One-sentence Summary": "We present a method that adds new neurons during training without impacting what is already learned, while improving the training dynamics."
  },
  {
    "title": "Online Coreset Selection for Rehearsal-based Continual Learning",
    "url": "/forum?id=f9D-5WNG4Nv",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Continual Learning",
    "Abstract": "A dataset is a shred of crucial evidence to describe a task. However, each data point in the dataset does not have the same potential, as some of the data points can be more representative or informative than others. This unequal importance among the data points may have a large impact in rehearsal-based continual learning, where we store a subset of the training examples (coreset) to be replayed later to alleviate catastrophic forgetting. In continual learning, the quality of the samples stored in the coreset directly affects the model's effectiveness and efficiency. The coreset selection problem becomes even more important under realistic settings, such as imbalanced continual learning or noisy data scenarios. To tackle this problem, we propose Online Coreset Selection (OCS), a simple yet effective method that selects the most representative and informative coreset at each iteration and trains them in an online manner. Our proposed method maximizes the model's adaptation to a target dataset while selecting high-affinity samples to past tasks, which directly inhibits catastrophic forgetting. We validate the effectiveness of our coreset selection mechanism over various standard, imbalanced, and noisy datasets against strong continual learning baselines, demonstrating that it improves task adaptation and prevents catastrophic forgetting in a sample-efficient manner.",
    "One-sentence Summary": "We propose Online Coreset Selection (OCS), a simple yet effective method that selects the most representative and informative coreset at each iteration and trains them in an online manner."
  },
  {
    "title": "Switch to Generalize: Domain-Switch Learning for Cross-Domain Few-Shot Classification",
    "url": "/forum?id=H-iABMvzIc",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "This paper considers few-shot learning under the cross-domain scenario. The cross-domain setting imposes a critical challenge, i.e., using very few (support) samples to generalize the already-learned model to a novel domain. We hold a hypothesis, i.e., if a deep model is capable to fast generalize itself to different domains (using very few samples) during training, it will maintain such domain generalization capacity for testing. It motivates us to propose a novel Domain-Switch Learning (DSL) framework. DSL embeds the cross-domain scenario into the training stage in a ``fast switching'' manner. Specifically, DSL uses a single domain for a training iteration and switches into another domain for the following iteration. During the switching, DSL enforces two constraints: 1) the deep model should not over-fit the domain in the current iteration and 2) the deep model should not forget the already-learned knowledge of other domains. These two constraints jointly promote fast generalization across different domains. Experimental results confirm that the cross-domain generalization capacity can be inherited from the training stage to the testing stage, validating our key hypothesis. Consequentially, DSL significantly improves cross-domain few-shot classification and sets up new state of the art."
  },
  {
    "title": "Zero-CL: Instance and Feature decorrelation for negative-free symmetric contrastive learning",
    "url": "/forum?id=RAW9tCdVxLj",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self supervised learning, representation learning",
    "Abstract": "For self-supervised contrastive learning, models can easily collapse and generate trivial constant solutions. The issue has been mitigated by recent improvement on objective design, which however often requires square complexity either for the size of instances ($\\mathcal{O}(N^{2})$) or feature dimensions ($\\mathcal{O}(d)^2$). To prevent such collapse, we develop two novel methods by decorrelating on different dimensions on the instance embedding stacking matrix, i.e., \\textbf{I}nstance-wise (ICL) and \\textbf{F}eature-wise (FCL) \\textbf{C}ontrastive \\textbf{L}earning. The proposed two methods (FCL, ICL) can be combined synthetically, called Zero-CL, where ``Zero'' means negative samples are \\textbf{zero} relevant, which allows Zero-CL to completely discard negative pairs i.e., with \\textbf{zero} negative samples. Compared with previous methods, Zero-CL mainly enjoys three advantages: 1) Negative free in symmetric architecture. 2) By whitening transformation, the correlation of the different features is equal to zero, alleviating information redundancy. 3) Zero-CL remains original information to a great extent after transformation, which improves the accuracy against other whitening transformation techniques. Extensive experimental results on CIFAR-10/100 and ImageNet show that Zero-CL outperforms or is on par with state-of-the-art symmetric contrastive learning methods.",
    "One-sentence Summary": "We develop two contrastive learning methods to prevent collapses in symmetric architecture without negative pairs."
  },
  {
    "title": "Random matrices in service of ML footprint: ternary random features with no performance loss",
    "url": "/forum?id=qwULHx9zld",
    "date": "28 Sept 2021 (modified: 24 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Computationally efficient methods, kernel methods, random features, random matrix theory",
    "Abstract": "In this article, we investigate the spectral behavior of random features kernel matrices of the type ${\\bf K} = \\mathbb{E}_{{\\bf w}} \\left[\\sigma\\left({\\bf w}^{\\sf T}{\\bf x}_i\\right)\\sigma\\left({\\bf w}^{\\sf T}{\\bf x}_j\\right)\\right]_{i,j=1}^n$, with nonlinear function $\\sigma(\\cdot)$, data ${\\bf x}_1, \\ldots, {\\bf x}_n \\in \\mathbb{R}^p$, and random projection vector ${\\bf w} \\in \\mathbb{R}^p$ having i.i.d. entries. In a high-dimensional setting where the number of data $n$ and their dimension $p$ are both large and comparable, we show, under a Gaussian mixture model for the data, that the eigenspectrum of ${\\bf K}$ is independent of the distribution of the i.i.d.(zero-mean and unit-variance) entries of ${\\bf w}$, and only depends on $\\sigma(\\cdot)$ via its (generalized) Gaussian moments $\\mathbb{E}_{z\\sim \\mathcal N(0,1)}[\\sigma'(z)]$ and $\\mathbb{E}_{z\\sim \\mathcal N(0,1)}[\\sigma''(z)]$. As a result, for any kernel matrix ${\\bf K}$ of the form above, we propose a novel random features technique, called Ternary Random Features (TRFs), that (i) asymptotically yields the same limiting kernel as the original ${\\bf K}$ in a spectral sense and (ii) can be computed and stored much more efficiently, by wisely tuning (in a data-dependent manner) the function $\\sigma$ and the random vector ${\\bf w}$, both taking values in $\\{-1,0,1\\}$. The computation of the proposed random features requires no multiplication, and a factor of $b$ times less bits for storage compared to classical random features such as random Fourier features, with $b$ the number of bits to store full precision values. Besides, it appears in our experiments on real data that the substantial gains in computation and storage are accompanied with somewhat improved performances compared to state-of-the-art random features methods.",
    "One-sentence Summary": "A novel computational and storage efficient random features technique with no performance loss"
  },
  {
    "title": "Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games",
    "url": "/forum?id=gfwON7rAm4",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Multi-agent Reinforcement Learning, Markov Potential Games, Policy Gradient",
    "Abstract": "Potential games are arguably one of the most important and widely studied classes of normal form games. They define the archetypal setting of multi-agent coordination in which all agents utilities are perfectly aligned via a common potential function. Can this intuitive framework be transplanted in the setting of Markov games? What are the similarities and differences between multi-agent coordination with and without state dependence? To answer these questions, we study a natural class of Markov Potential Games (MPGs) that generalize prior attempts at capturing complex stateful multi-agent coordination. Counter-intuitively, insights from normal-form potential games do not carry over as MPGs involve settings where state-games can be zero-sum games. In the opposite direction, Markov games where every state-game is a potential game are not necessarily MPGs. Nevertheless, MPGs showcase standard desirable properties such as the existence of deterministic Nash policies. In our main technical result, we prove convergence of independent policy gradient and its stochastic counterpart to Nash policies (polynomially fast in the approximation error) by adapting recent gradient dominance property arguments developed for single-agent Markov decision processes to multi-agent learning settings.",
    "One-sentence Summary": "Convergence of policy gradient in a class of MDPs called Markov Potential Games in which cooperation is desired."
  },
  {
    "title": "Rethinking Adversarial Transferability from a Data Distribution Perspective",
    "url": "/forum?id=gVRhIEajG1k",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Adversarial Attack, Adversarial Transferability, Black-box Attack",
    "Abstract": "Adversarial transferability enables attackers to generate adversarial examples from the source model to attack the target model, which has raised security concerns about the deployment of DNNs in practice. In this paper, we rethink adversarial transferability from a data distribution perspective and further enhance transferability by score matching based optimization. We identify that some samples with injecting small Gaussian noise can fool different target models, and their adversarial examples under different source models have much stronger transferability. We hypothesize that these samples are in the low-density region of the ground truth distribution where models are not well trained. To improve the attack success rate of adversarial examples, we match the adversarial attacks with the directions which effectively decrease the ground truth density. We propose Intrinsic Adversarial Attack (IAA), which smooths the activation function and decreases the impact of the later layers of a given normal model, to increase the alignment of adversarial attack and the gradient of joint data distribution. We conduct comprehensive transferable attacks against multiple DNNs and show that our IAA can boost the transferability of the crafted attacks in all cases and go beyond state-of-the-art methods.",
    "One-sentence Summary": "In this paper, we rethink adversarial transferability from a data distribution perspective and further enhance transferability by score matching based optimization."
  },
  {
    "title": "Transformers Can Do Bayesian Inference",
    "url": "/forum?id=KSugKcbNf9",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Abstract": "Currently, it is hard to reap the benefits of deep learning for Bayesian methods, which allow the explicit specification of prior knowledge and accurately capture model uncertainty. We present Prior-Data Fitted Networks (PFNs). PFNs leverage large-scale machine learning techniques to approximate a large set of posteriors. The only requirement for PFNs to work is the ability to sample from a prior distribution over supervised learning tasks (or functions). Our method restates the objective of posterior approximation as a supervised classification problem with a set-valued input: it repeatedly draws a task (or function) from the prior, draws a set of data points and their labels from it, masks one of the labels and learns to make probabilistic predictions for it based on the set-valued input of the rest of the data points. Presented with a set of samples from a new supervised learning task as input, PFNs make probabilistic predictions for arbitrary other data points in a single forward propagation, having learned to approximate Bayesian inference. We demonstrate that PFNs can near-perfectly mimic Gaussian processes and also enable efficient Bayesian inference for intractable problems, with over 200-fold speedups in multiple setups compared to current methods. We obtain strong results in very diverse areas such as Gaussian process regression, Bayesian neural networks, classification for small tabular data sets, and few-shot image classification, demonstrating the generality of PFNs. Code and trained PFNs are released at https://github.com/automl/TransformersCanDoBayesianInference."
  },
  {
    "title": "Learning Discrete Structured Variational Auto-Encoder using Natural Evolution Strategies",
    "url": "/forum?id=JJCjv4dAbyL",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "structured prediction, derivative-free optimization, variational autoencoder",
    "Abstract": "Discrete variational auto-encoders (VAEs) are able to represent semantic latent spaces in generative learning. In many real-life settings, the discrete latent space consists of high-dimensional structures, and propagating gradients through the relevant structures often requires enumerating over an exponentially large latent space. Recently, various approaches were devised to propagate approximated gradients without enumerating over the space of possible structures. In this work, we use Natural Evolution Strategies (NES), a class of gradient-free black-box optimization algorithms, to learn discrete structured VAEs. The NES algorithms are computationally appealing as they estimate gradients with forward pass evaluations only, thus they do not require to propagate gradients through their discrete structures. We demonstrate empirically that optimizing discrete structured VAEs using NES is as effective as gradient-based approximations. Lastly, we prove NES converges for non-Lipschitz functions as appear in discrete structured VAEs."
  },
  {
    "title": "Learning Features with Parameter-Free Layers",
    "url": "/forum?id=bCrdi4iVvv",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "ImageNet, efficient network architecture, network design, image classification",
    "Abstract": "Trainable layers such as convolutional building blocks are the standard network design choices by learning parameters to capture the global context through successive spatial operations. When designing an efficient network, trainable layers such as the depthwise convolution is the source of efficiency in the number of parameters and FLOPs, but there was little improvement to the model speed in practice. This paper argues that simple built-in parameter-free operations can be a favorable alternative to the efficient trainable layers replacing spatial operations in a network architecture. We aim to break the stereotype of organizing the spatial operations of building blocks into trainable layers. Extensive experimental analyses based on layer-level studies with fully-trained models and neural architecture searches are provided to investigate whether parameter-free operations such as the max-pool are functional. The studies eventually give us a simple yet effective idea for redesigning network architectures, where the parameter-free operations are heavily used as the main building block without sacrificing the model accuracy as much. Experimental results on the ImageNet dataset demonstrate that the network architectures with parameter-free operations could enjoy the advantages of further efficiency in terms of model speed, the number of the parameters, and FLOPs. Code and ImageNet pretrained models are available at https://github.com/naver-ai/PfLayer.",
    "One-sentence Summary": "This paper introduces a new design paradigm rethinking a parameter-free operation as the main building block of network architecture."
  },
  {
    "title": "Denoising Likelihood Score Matching for Conditional Score-based Data Generation",
    "url": "/forum?id=LcF-EEt8cCC",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "score-based generative model, conditional sampling",
    "Abstract": "Many existing conditional score-based data generation methods utilize Bayes' theorem to decompose the gradients of a log posterior density into a mixture of scores. These methods facilitate the training procedure of conditional score models, as a mixture of scores can be separately estimated using a score model and a classifier. However, our analysis indicates that the training objectives for the classifier in these methods may lead to a serious score mismatch issue, which corresponds to the situation that the estimated scores deviate from the true ones. Such an issue causes the samples to be misled by the deviated scores during the diffusion process, resulting in a degraded sampling quality. To resolve it, we theoretically formulate a novel training objective, called Denoising Likelihood Score Matching (DLSM) loss, for the classifier to match the gradients of the true log likelihood density. Our experimental evidences show that the proposed method outperforms the previous methods on both Cifar-10 and Cifar-100 benchmarks noticeably in terms of several key evaluation metrics. We thus conclude that, by adopting DLSM, the conditional scores can be accurately modeled, and the effect of the score mismatch issue is alleviated.",
    "One-sentence Summary": "In this paper, we theoretically formulate a new training objective, called Denoising Likelihood Score Matching (DLSM) loss, for the classifier to match the gradients of the true log likelihood density."
  },
  {
    "title": "Memory Replay with Data Compression for Continual Learning",
    "url": "/forum?id=a7H7OucbWaU",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Continual Learning, Memory Replay, Data Compression",
    "Abstract": "Continual learning needs to overcome catastrophic forgetting of the past. Memory replay of representative old training samples has been shown as an effective solution, and achieves the state-of-the-art (SOTA) performance. However, existing work is mainly built on a small memory buffer containing a few original data, which cannot fully characterize the old data distribution. In this work, we propose memory replay with data compression to reduce the storage cost of old training samples and thus increase their amount that can be stored in the memory buffer. Observing that the trade-off between the quality and quantity of compressed data is highly nontrivial for the efficacy of memory replay, we propose a novel method based on determinantal point processes (DPPs) to efficiently determine an appropriate compression quality for currently-arrived training samples. In this way, using a naive data compression algorithm with a properly selected quality can largely boost recent strong baselines by saving more compressed data in a limited storage space. We extensively validate this across several benchmarks of class-incremental learning and in a realistic scenario of object detection for autonomous driving.",
    "One-sentence Summary": "We propose memory replay with data compression, which is an important yet neglected baseline and a promising direction for continual learning."
  },
  {
    "title": "MAML is a Noisy Contrastive Learner in Classification",
    "url": "/forum?id=LDAwu17QaJz",
    "date": "28 Sept 2021 (modified: 24 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Meta learning, contrastive learning, few shot learning",
    "Abstract": "Model-agnostic meta-learning (MAML) is one of the most popular and widely adopted meta-learning algorithms, achieving remarkable success in various learning problems. Yet, with the unique design of nested inner-loop and outer-loop updates, which govern the task-specific and meta-model-centric learning, respectively, the underlying learning objective of MAML remains implicit, impeding a more straightforward understanding of it. In this paper, we provide a new perspective of the working mechanism of MAML. We discover that MAML is analogous to a meta-learner using a supervised contrastive objective in classification. The query features are pulled towards the support features of the same class and against those of different classes. Such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, we reveal that vanilla MAML has an undesirable interference term originating from the random initialization and the cross-task interaction. We thus propose a simple but effective technique, the zeroing trick, to alleviate the interference. Extensive experiments are conducted on both mini-ImageNet and Omniglot datasets to validate the consistent improvement brought by our proposed method.",
    "One-sentence Summary": "The Model-agnostic meta learning (MAML) algorithm is a noisy supervised contrastive learner where the noise comes from random initialization and cross-task interference."
  },
  {
    "title": "RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning",
    "url": "/forum?id=afoV8W3-IYp",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "visual relational reasoning, representation learning, systematic generalization",
    "Abstract": "Reasoning about visual relationships is central to how humans interpret the visual world. This task remains challenging for current deep learning algorithms since it requires addressing three key technical problems jointly: 1) identifying object entities and their properties, 2) inferring semantic relations between pairs of entities, and 3) generalizing to novel object-relation combinations, i.e., systematic generalization. In this work, we use vision transformers (ViTs) as our base model for visual reasoning and make better use of concepts defined as object entities and their relations to improve the reasoning ability of ViTs. Specifically, we introduce a novel concept-feature dictionary to allow flexible image feature retrieval at training time with concept keys. This dictionary enables two new concept-guided auxiliary tasks: 1) a global task for promoting relational reasoning, and 2) a local task for facilitating semantic object-centric correspondence learning. To examine the systematic generalization of visual reasoning models, we introduce systematic splits for the standard HICO and GQA benchmarks. We show the resulting model, Concept-guided Vision Transformer (or RelViT for short) significantly outperforms prior approaches on HICO and GQA by 16% and 13% in the original split, and by 43% and 18% in the systematic split. Our ablation analyses also reveal our model's compatibility with multiple ViT variants and robustness to hyper-parameters.",
    "One-sentence Summary": "We propose a novel concept-feature dictionary to enable two new concept-guided auxiliary tasks, which largely improve the model performances on visual relational reasoning, especially for systematic generalization."
  },
  {
    "title": "Boosted Curriculum Reinforcement Learning",
    "url": "/forum?id=anbBFlX1tJ1",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "reinforcement learning, curriculum learning, boosting, residual learning",
    "Abstract": "Curriculum value-based reinforcement learning (RL) solves a complex target task by reusing action-values across a tailored sequence of related tasks of increasing difficulty. However, finding an exact way of reusing action-values in this setting is still a poorly understood problem. In this paper, we introduce the concept of boosting to curriculum value-based RL, by approximating the action-value function as a sum of residuals trained on each task. This approach, which we refer to as boosted curriculum reinforcement learning (BCRL), has the benefit of naturally increasing the representativeness of the functional space by adding a new residual each time a new task is presented. This procedure allows reusing previous action-values while promoting expressiveness of the action-value function. We theoretically study BCRL as an approximate value iteration algorithm, discussing advantages over regular curriculum RL in terms of approximation accuracy and convergence to the optimal action-value function. Finally, we provide detailed empirical evidence of the benefits of BCRL in problems requiring curricula for accurate action-value estimation and targeted exploration.",
    "One-sentence Summary": "A novel approach for curriculum RL that increases the representativeness of the functional space as new, increasingly complex, tasks from the curriculum are presented to the agent."
  },
  {
    "title": "ViDT: An Efficient and Effective Fully Transformer-based Object Detector",
    "url": "/forum?id=w4cXZDDib1H",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "object detection, vision transformer, detection transformer",
    "Abstract": "Transformers are transforming the landscape of computer vision, especially for recognition tasks. Detection transformers are the first fully end-to-end learning systems for object detection, while vision transformers are the first fully transformer-based architecture for image classification. In this paper, we integrate Vision and Detection Transformers (ViDT) to build an effective and efficient object detector. ViDT introduces a reconfigured attention module to extend the recent Swin Transformer to be a standalone object detector, followed by a computationally efficient transformer decoder that exploits multi-scale features and auxiliary techniques essential to boost the detection performance without much increase in computational load. Extensive evaluation results on the Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP and latency trade-off among existing fully transformer-based object detectors, and achieves 49.2AP owing to its high scalability for large models. We release the code and trained models at https://github.com/naver-ai/vidt.",
    "One-sentence Summary": "We integrate vision and detection transformers to build an efficient  and effective fully transformer-based object detector."
  },
  {
    "title": "BiBERT: Accurate Fully Binarized BERT",
    "url": "/forum?id=5xEgrl_5FAJ",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Network Binarization, Model Compression, BERT, NLP",
    "Abstract": "The large pre-trained BERT has achieved remarkable performance on Natural Language Processing (NLP) tasks but is also computation and memory expensive. As one of the powerful compression approaches, binarization extremely reduces the computation and memory consumption by utilizing 1-bit parameters and bitwise operations. Unfortunately, the full binarization of BERT (i.e., 1-bit weight, embedding, and activation) usually suffer a significant performance drop, and there is rare study addressing this problem. In this paper, with the theoretical justification and empirical analysis, we identify that the severe performance drop can be mainly attributed to the information degradation and optimization direction mismatch respectively in the forward and backward propagation, and propose BiBERT, an accurate fully binarized BERT, to eliminate the performance bottlenecks. Specifically, BiBERT introduces an efficient Bi-Attention structure for maximizing representation information statistically and a Direction-Matching Distillation (DMD) scheme to optimize the full binarized BERT accurately. Extensive experiments show that BiBERT outperforms both the straightforward baseline and existing state-of-the-art quantized BERTs with ultra-low bit activations by convincing margins on the NLP benchmark. As the first fully binarized BERT, our method yields impressive 56.3 times and 31.2 times saving on FLOPs and model size, demonstrating the vast advantages and potential of the fully binarized BERT model in real-world resource-constrained scenarios.",
    "One-sentence Summary": "Our BiBERT, for the first time, presents a promising route towards the accurate fully binarized BERT (with 1-bit weight, embedding, and activation) and gives impressive 56.3 times and 31.2 times saving on FLOPs and model size, respectively."
  },
  {
    "title": "Feature Kernel Distillation",
    "url": "/forum?id=tBIQEvApZK5",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Knowledge distillation, Neural Network (NN) Feature learning, ensembling NNs, Deep learning fundamentals, Image classification",
    "Abstract": "Trained Neural Networks (NNs) can be viewed as data-dependent kernel machines, with predictions determined by the inner product of last-layer representations across inputs, referred to as the feature kernel. We explore the relevance of the feature kernel for Knowledge Distillation (KD), using a mechanistic understanding of an NN\u2019s optimisation process. We extend the theoretical analysis of Allen-Zhu & Li (2020) to show that a trained NN\u2019s feature kernel is highly dependent on its parameter initialisation, which biases different initialisations of the same architecture to learn different data attributes in a multi-view data setting. This enables us to prove that KD using only pairwise feature kernel comparisons can improve NN test accuracy in such settings, with both single & ensemble teacher models, whereas standard training without KD fails to generalise. We further use our theory to motivate practical considerations for improving student generalisation when using distillation with feature kernels, which allows us to propose a novel approach: Feature Kernel Distillation (FKD). Finally, we experimentally corroborate our theory in the image classification setting, showing that FKD is amenable to ensemble distillation, can transfer knowledge across datasets, and outperforms both vanilla KD & other feature kernel based KD baselines across a range of standard architectures & datasets.",
    "One-sentence Summary": "A feature-learning perspective of (ensemble) Knowledge Distillation (KD) in Neural Networks to propose a new method (FKD), with both theoretical & experimental results demonstrating FKD's advantages over standard KD baselines."
  },
  {
    "title": "Representation-Agnostic Shape Fields",
    "url": "/forum?id=-ngwPqanCEZ",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "shape embedding, 3D deep learning, shape classification and segmentation",
    "Abstract": "3D shape analysis has been widely explored in the era of deep learning. Numerous models have been developed for various 3D data representation formats, e.g., MeshCNN for meshes, PointNet for point clouds and VoxNet for voxels. In this study, we present Representation-Agnostic Shape Fields (RASF), a generalizable and computation-efficient shape embedding module for 3D deep learning. RASF is implemented with a learnable 3D grid with multiple channels to store local geometry. Based on RASF, shape embeddings for various 3D shape representations (point clouds, meshes and voxels) are retrieved by coordinate indexing. While there are multiple ways to optimize the learnable parameters of RASF, we provide two effective schemes among all in this paper for RASF pre-training: shape reconstruction and normal estimation. Once trained, RASF becomes a plug-and-play performance booster with negligible cost. Extensive experiments on diverse 3D representation formats, networks and applications, validate the universal effectiveness of the proposed RASF. Code and pre-trained models are publicly available\\footnote{\\url{https://github.com/seanywang0408/RASF}}.",
    "One-sentence Summary": "We propose a  generalizable and computation-efficient shape embedding layer for 3D deep learning, named Representation-Agnostic Shape Fields (RASF), to improve performance across different representations, backbones and down-stream tasks"
  },
  {
    "title": "Learning Synthetic Environments and Reward Networks for Reinforcement Learning",
    "url": "/forum?id=C1_esHN6AVn",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Synthetic Environments, Synthetic Data, Meta-Learning, Reinforcement Learning, Evolution Strategies, Reward Shaping",
    "Abstract": "We introduce Synthetic Environments (SEs) and Reward Networks (RNs), represented by neural networks, as proxy environment models for training Reinforcement Learning (RL) agents. We show that an agent, after being trained exclusively on the SE, is able to solve the corresponding real environment. While an SE acts as a full proxy to a real environment by learning about its state dynamics and rewards, an RN is a partial proxy that learns to augment or replace rewards. We use bi-level optimization to evolve SEs and RNs: the inner loop trains the RL agent, and the outer loop trains the parameters of the SE / RN via an evolution strategy. We evaluate our proposed new concept on a broad range of RL algorithms and classic control environments. In a one-to-one comparison, learning an SE proxy requires more interactions with the real environment than training agents only on the real environment. However, once such an SE has been learned, we do not need any interactions with the real environment to train new agents. Moreover, the learned SE proxies allow us to train agents with fewer interactions while maintaining the original task performance. Our empirical results suggest that SEs achieve this result by learning informed representations that bias the agents towards relevant states. Moreover, we find that these proxies are robust against hyperparameter variation and can also transfer to unseen agents.",
    "One-sentence Summary": "We propose an evolution-based approach to meta-learn synthetic neural environments and reward neural networks for reinforcement learning."
  },
  {
    "title": "Who Is Your Right Mixup Partner in Positive and Unlabeled Learning",
    "url": "/forum?id=NH29920YEmj",
    "date": "28 Sept 2021 (modified: 05 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Positive and Unlabeled Learning, Mixup, Heuristic",
    "Abstract": "Positive and Unlabeled (PU) learning targets inducing a binary classifier from weak training datasets of positive and unlabeled instances, which arise in many real-world applications. In this paper, we propose a novel PU learning method, namely Positive and unlabeled learning with Partially Positive Mixup (P3Mix), which simultaneously benefits from data augmentation and supervision correction with a heuristic mixup technique. To be specific, we take inspiration from the directional boundary deviation phenomenon observed in our preliminary experiments, where the learned PU boundary tends to deviate from the fully supervised boundary towards the positive side. For the unlabeled instances with ambiguous predictive results, we select their mixup partners from the positive instances around the learned PU boundary, so as to transform them into augmented instances near to the boundary yet with more precise supervision. Accordingly, those augmented instances may push the learned PU boundary towards the fully supervised boundary, thereby improving the classification performance. Comprehensive experimental results demonstrate the effectiveness of the heuristic mixup technique in PU learning and show that P3Mix can consistently outperform the state-of-the-art PU learning methods.",
    "One-sentence Summary": "We propose a novel PU learning method named P3Mix which simultaneously benefits from instance augmentation and supervision correction with a heuristic mixup technique."
  },
  {
    "title": "Incremental False Negative Detection for Contrastive Learning",
    "url": "/forum?id=dDjSKKA5TP1",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Self-supervised learning, Contrastive learning, Representation learning, Clustering-based learning",
    "Abstract": "Self-supervised learning has recently shown great potential in vision tasks through contrastive learning, which aims to discriminate each image, or instance, in the dataset. However, such instance-level learning ignores the semantic relationship among instances and sometimes undesirably repels the anchor from the semantically similar samples, termed as \"false negatives\". In this work, we show that the unfavorable effect from false negatives is more significant for the large-scale datasets with more semantic concepts. To address the issue, we propose a novel self-supervised contrastive learning framework that incrementally detects and explicitly removes the false negative samples. Specifically, following the training process, our method dynamically detects increasing high-quality false negatives considering that the encoder gradually improves and the embedding space becomes more semantically structural. Next, we discuss two strategies to explicitly remove the detected false negatives during contrastive learning. Extensive experiments show that our framework outperforms other self-supervised contrastive learning methods on multiple benchmarks in a limited resource setup.",
    "One-sentence Summary": "This paper explores the effect of false negative samples in self-supervised contrastive learning and introduce a framework to incrementally detect and explicitly remove the false negatives."
  },
  {
    "title": "Multi-Critic Actor Learning: Teaching RL Policies to Act with Style",
    "url": "/forum?id=rJvY_5OzoI",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Reinforcement Learning, Multi-Style Learning, Multi-Task Learning, Actor-Critic",
    "Abstract": "Using a single value function (critic) shared over multiple tasks in Actor-Critic multi-task reinforcement learning (MTRL) can result in negative interference between tasks, which can compromise learning performance. Multi-Critic Actor Learning (MultiCriticAL) proposes instead maintaining separate critics for each task being trained while training a single multi-task actor. Explicitly distinguishing between tasks also eliminates the need for critics to learn to do so and mitigates interference between task-value estimates. MultiCriticAL is tested in the context of multi-style learning, a special case of MTRL where agents are trained to behave with different distinct behavior styles, and yields up to 56% performance gains over the single-critic baselines and even successfully learns behavior styles in cases where single-critic approaches may simply fail to learn. In a simulated real-world use case, MultiCriticAL enables learning policies that smoothly transition between multiple fighting styles on an experimental build of EA\u2019s UFC game.",
    "One-sentence Summary": "MultiCriticAL is a single-actor, multi-critic framework for multi-task reinforcement learning, where task-based critic separation provides explicit per-task value-function approximation and enables improved performance over single-critic frameworks."
  },
  {
    "title": "Clean Images are Hard to Reblur: Exploiting the Ill-Posed Inverse Task for Dynamic Scene Deblurring",
    "url": "/forum?id=kezNJydWvE",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Deblur, Reblur, Loss, Test-time adaptation, Self-supervised",
    "Abstract": "The goal of dynamic scene deblurring is to remove the motion blur in a given image. Typical learning-based approaches implement their solutions by minimizing the L1 or L2 distance between the output and the reference sharp image. Recent attempts adopt visual recognition features in training to improve the perceptual quality. However, those features are primarily designed to capture high-level contexts rather than low-level structures such as blurriness. Instead, we propose a more direct way to make images sharper by exploiting the inverse task of deblurring, namely, reblurring. Reblurring amplifies the remaining blur to rebuild the original blur, however, a well-deblurred clean image with zero-magnitude blur is hard to reblur. Thus, we design two types of reblurring loss functions for better deblurring. The supervised reblurring loss at training stage compares the amplified blur between the deblurred and the sharp images. The self-supervised reblurring loss at inference stage inspects if noticeable blur remains in the deblurred. Our experimental results on large-scale benchmarks and real images demonstrate the effectiveness of the reblurring losses in improving the perceptual quality of the deblurred images in terms of NIQE and LPIPS scores as well as visual sharpness.",
    "One-sentence Summary": "Reblurring, the inverse task of deblurring, is used for supervised/self-supervised learning of deblurring and improves the image sharpness."
  },
  {
    "title": "Learning Disentangled Representation by Exploiting Pretrained Generative Models:  A Contrastive Learning View",
    "url": "/forum?id=j-63FSNcO5a",
    "date": "28 Sept 2021 (modified: 05 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Latent space discovery, Disentangled representation learning, Generative models, Contrastive learning",
    "Abstract": "From the intuitive notion of disentanglement, the image variations corresponding to different generative factors should be distinct from each other, and the disentangled representation should reflect those variations with separate dimensions. To discover the generative factors and learn disentangled representation, previous methods typically leverage an extra regularization term when learning to generate realistic images. However, the term usually results in a trade-off between disentanglement and generation quality. For the generative models pretrained without any disentanglement term, the generated images show semantically meaningful variations when traversing along different directions in the latent space. Based on this observation, we argue that it is possible to mitigate the trade-off by (i) leveraging the pretrained generative models with high generation quality, (ii) focusing on discovering the traversal directions as generative factors for disentangled representation learning. To achieve this, we propose Disentaglement via Contrast (DisCo) as a framework to model the variations based on the target disentangled representations, and contrast the variations to jointly discover disentangled directions and learn disentangled representations. DisCo achieves the state-of-the-art disentangled representation learning and distinct direction discovering, given pretrained non-disentangled generative models including GAN, VAE, and Flow. Source code is at https://github.com/xrenaa/DisCo.",
    "One-sentence Summary": "DisCo is a new contrastive learning framework to leverage pretrained generative models to jointly learn disentangled representation and discover disentangled directions in the latent space."
  },
  {
    "title": "Towards Building A Group-based Unsupervised Representation Disentanglement Framework",
    "url": "/forum?id=YgPqNctmyd",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "Disentangled representation learning, Group theory, VAE",
    "Abstract": "Disentangled representation learning is one of the major goals of deep learning, and is a key step for achieving explainable and generalizable models. The key idea of the state-of-the-art VAE-based unsupervised representation disentanglement methods is to minimize the total correlation of the joint distribution of the latent variables. However, it has been proved that their goal can not be achieved without introducing other inductive biases. The Group Theory based definition of representation disentanglement mathematically connects the data transformations to the representations using the formalism of group. In this paper, built on the group-based definition and inspired by the \\emph{n-th dihedral group}, we first propose a theoretical framework towards achieving unsupervised representation disentanglement. We then propose a model based on existing VAE-based methods to tackle the unsupervised learning problem of the framework. In the theoretical framework, we prove three sufficient conditions on model, group structure, and data respectively in an effort to achieve, in an unsupervised way, disentangled representation per group-based definition. With these conditions, we offer an option, from the perspective of the group-based definition, for the inductive bias that existing VAE-based models lack. Experimentally, we train 1800 models covering the most prominent VAE-based methods on five datasets to verify the effectiveness of our theoretical framework. Compared to the original VAE-based methods, these Groupified VAEs consistently achieve better mean performance with smaller variances.",
    "One-sentence Summary": "In this paper, built on the group-based definition and inspired by the n-th dihedral group, we first propose a theoretical framework towards achieving unsupervised representation disentanglement."
  },
  {
    "title": "Learning Efficient Image Super-Resolution Networks via Structure-Regularized Pruning",
    "url": "/forum?id=AjGC97Aofee",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Poster",
    "Keywords": "image super-resolution",
    "Abstract": "Several image super-resolution (SR) networks have been proposed of late for efficient SR, achieving promising results. However, they are still not lightweight enough and neglect to be extended to larger networks. At the same time, model compression techniques, like neural architecture search and knowledge distillation, typically consume considerable computation resources. In contrast, network pruning is a cheap and effective model compression technique. However, it is hard to be applied to SR networks directly because filter pruning for residual blocks is well-known tricky. To address the above issues, we propose structure-regularized pruning (SRP), which imposes regularization on the pruned structure to ensure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, we select the filters of the same indices as unimportant filters. To transfer the expressive power in the unimportant filters to the rest of the network, we employ $L_2$ regularization to drive the weights towards zero so that eventually, their absence will cause minimal performance degradation. We apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN-Lite and a very deep one SRPN. We conduct extensive comparisons with both lightweight and larger networks. SRPN-Lite and SRPN perform favorably against other recent efficient SR approaches quantitatively and visually.",
    "One-sentence Summary": "Learning efficient compressed models for bother lightweight and large image super-resolution networks"
  },
  {
    "title": "Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream",
    "url": "/forum?id=g1SzIRLQXMM",
    "date": "29 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "computational neuroscience, primate visual ventral stream, convolutional neural networks, biologically plausible learning",
    "Abstract": "After training on large datasets, certain deep neural networks are surprisingly good models of the neural mechanisms of adult primate visual object recognition. Nevertheless, these models are considered poor models of the development of the visual system because they posit millions of sequential, precisely coordinated synaptic updates, each based on a labeled image.  While ongoing research is pursuing the use of unsupervised proxies for labels, we here explore a complementary strategy of reducing the required number of supervised synaptic updates to produce an adult-like ventral visual stream (as judged by the match to V1, V2, V4, IT, and behavior). Such models might require less precise machinery and energy expenditure to coordinate these updates and would thus move us closer to viable neuroscientific hypotheses about how the visual system wires itself up. Relative to standard model training on labeled images in ImageNet, we here demonstrate that the total number of supervised weight updates can be substantially reduced using three complementary strategies: First, we find that only 2% of supervised updates (epochs and images) are needed to achieve 80% of the match to adult ventral stream. Specifically, training benefits predictions of higher visual cortex the most whereas early visual cortex predictions only improve marginally over the course of training. Second, by improving the random distribution of synaptic connectivity, we find that 54% of the brain match can already be achieved \u201cat birth\" (i.e. no training at all). Third, we find that, by training only 5% of model synapses, we can still achieve nearly 80% of the match to the ventral stream. This approach further improves on ImageNet performance over previous attempts in computer vision of minimizing trained components without substantially increasing the relative number of trained parameters. These results reflect first steps in modeling not just primate adult visual processing during inference, but also how the ventral visual stream might be \"wired up\" by evolution (a model's \"birth\" state) and by developmental learning (a model's updates based on visual experience).",
    "One-sentence Summary": "We develop biologically-motivated initialization and training procedures to train models with 200x fewer synaptic updates (epochs x labeled images x weights) while maintaining 80% of brain predictivity on a set of neural and behavioral benchmarks."
  },
  {
    "title": "Dynamics-Aware Comparison of Learned Reward Functions",
    "url": "/forum?id=CALFyKVs87",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reward Learning, Inverse Reinforcement Learning, Reinforcement Learning, Comparing Reward Functions",
    "Abstract": "The ability to learn reward functions plays an important role in enabling the deployment of intelligent agents in the real world. However, comparing reward functions, for example as a means of evaluating reward learning methods, presents a challenge. Reward functions are typically compared by considering the behavior of optimized policies, but this approach conflates deficiencies in the reward function with those of the policy search algorithm used to optimize it. To address this challenge, Gleave et al. (2020) propose the Equivalent-Policy Invariant Comparison (EPIC) distance. EPIC avoids policy optimization, but in doing so requires computing reward values at transitions that may be impossible under the system dynamics. This is problematic for learned reward functions because it entails evaluating them outside of their training distribution, resulting in inaccurate reward values that we show can render EPIC ineffective at comparing rewards. To address this problem, we propose the Dynamics-Aware Reward Distance (DARD), a new reward pseudometric. DARD uses an approximate transition model of the environment to transform reward functions into a form that allows for comparisons that are invariant to reward shaping while only evaluating reward functions on transitions close to their training distribution. Experiments in simulated physical domains demonstrate that DARD enables reliable reward comparisons without policy optimization and is significantly more predictive than baseline methods of downstream policy performance when dealing with learned reward functions.",
    "One-sentence Summary": "We propose a method for quantifying the similarity of learned reward functions without performing policy learning and evaluation."
  },
  {
    "title": "Learning Hierarchical Structures with Differentiable Nondeterministic Stacks",
    "url": "/forum?id=5LXw_QplBiF",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "RNN, pushdown automata, nondeterminism, formal languages, language modeling",
    "Abstract": "Learning hierarchical structures in sequential data -- from simple algorithmic patterns to natural language -- in a reliable, generalizable way remains a challenging problem for neural language models. Past work has shown that recurrent neural networks (RNNs) struggle to generalize on held-out algorithmic or syntactic patterns without supervision or some inductive bias. To remedy this, many papers have explored augmenting RNNs with various differentiable stacks, by analogy with finite automata and pushdown automata (PDAs). In this paper, we improve the performance of our recently proposed Nondeterministic Stack RNN (NS-RNN), which uses a differentiable data structure that simulates a nondeterministic PDA, with two important changes. First, the model now assigns unnormalized positive weights instead of probabilities to stack actions, and we provide an analysis of why this improves training. Second, the model can directly observe the state of the underlying PDA. Our model achieves lower cross-entropy than all previous stack RNNs on five context-free language modeling tasks (within 0.05 nats of the information-theoretic lower bound), including a task on which the NS-RNN previously failed to outperform a deterministic stack RNN baseline. Finally, we propose a restricted version of the NS-RNN that incrementally processes infinitely long sequences, and we present language modeling results on the Penn Treebank.",
    "One-sentence Summary": "We present a new stack-augmented RNN with strong results on CFL language modeling tasks."
  },
  {
    "title": "Sampling with Mirrored Stein Operators",
    "url": "/forum?id=eMudnJsb1T5",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Stein's method, Sampling, Mirror descent, Natural gradient descent, Probabilistic inference, Bayesian inference, Post-selection inference, Stein operators",
    "Abstract": "We introduce a new family of particle evolution samplers suitable for constrained domains and non-Euclidean geometries. Stein Variational Mirror Descent and Mirrored Stein Variational Gradient Descent minimize the Kullback-Leibler (KL) divergence to constrained target distributions by evolving particles in a dual space defined by a mirror map. Stein Variational Natural Gradient exploits non-Euclidean geometry to more efficiently minimize the KL divergence to unconstrained targets. We derive these samplers from a new class of mirrored Stein operators and adaptive kernels developed in this work. We demonstrate that these new samplers yield accurate approximations to distributions on the simplex, deliver valid confidence intervals in post-selection inference, and converge more rapidly than prior methods in large-scale unconstrained posterior inference. Finally, we establish the convergence of our new procedures under verifiable conditions on the target distribution.",
    "One-sentence Summary": "We introduce multi-particle generalization of mirror descent for sampling in constrained domains and non-Euclidean geometries."
  },
  {
    "title": "Planning in Stochastic Environments with a Learned Model",
    "url": "/forum?id=X6D9bAHhBQ1",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "model-based reinforcement learning, deep reinforcement learning, tree based search, MCTS",
    "Abstract": "Model-based reinforcement learning has proven highly successful. However, learning a model in isolation from its use during planning is problematic in complex environments. To date, the most effective techniques have instead combined value-equivalent model learning with powerful tree-search methods. This approach is exemplified by MuZero, which has achieved state-of-the-art performance in a wide range of domains, from board games to visually rich environments, with discrete and continuous action spaces, in online and offline settings. However, previous instantiations of this approach were limited to the use of deterministic models. This limits their performance in environments that are inherently stochastic, partially observed, or so large and complex that they appear stochastic to a finite agent. In this paper we extend this approach to learn and plan with stochastic models. Specifically, we introduce a new algorithm, Stochastic MuZero, that learns a stochastic model incorporating afterstates, and uses this model to perform a stochastic tree search. Stochastic MuZero matched or exceeded the state of the art in a set of canonical single and multi-agent environments, including 2048 and backgammon, while maintaining the same performance as standard MuZero in the game of Go."
  },
  {
    "title": "RotoGrad: Gradient Homogenization in Multitask Learning",
    "url": "/forum?id=T8wHz4rnuGL",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "multitask learning, conflicting gradients, negative transfer",
    "Abstract": "Multitask learning is being increasingly adopted in applications domains like computer vision and reinforcement learning. However, optimally exploiting its advantages remains a major challenge due to the effect of negative transfer. Previous works have tracked down this issue to the disparities in gradient magnitudes and directions across tasks, when optimizing the shared network parameters. While recent work has acknowledged that negative transfer is a two-fold problem, existing approaches fall short as they only focus on either homogenizing the gradient magnitude across tasks; or greedily change the gradient directions, overlooking future conflicts. In this work, we introduce RotoGrad, an algorithm that tackles negative transfer as a whole: it jointly homogenizes gradient magnitudes and directions, while ensuring training convergence. We show that RotoGrad outperforms competing methods in complex problems, including multi-label classification in CelebA and computer vision tasks in the NYUv2 dataset. A Pytorch implementation can be found in https://github.com/adrianjav/rotograd.",
    "One-sentence Summary": "We propose an algorithm to simultaneously homogenize gradient magnitudes and directions across tasks in MTL."
  },
  {
    "title": "On Improving Adversarial Transferability of Vision Transformers",
    "url": "/forum?id=D6nH3719vZy",
    "date": "28 Sept 2021 (modified: 03 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Vision Transformers, Adversarial Perturbations",
    "Abstract": "Vision transformers (ViTs) process input images as sequences of patches via self-attention; a radically different architecture than convolutional neural networks (CNNs).  This makes it interesting to study the adversarial feature space of ViT models and their transferability. In particular, we observe that adversarial patterns found via conventional adversarial attacks show very \\emph{low} black-box transferability even for large ViT models. We show that this phenomenon is only due to the sub-optimal attack procedures that do not leverage the true representation potential of ViTs. A deep ViT is composed of multiple blocks, with a consistent architecture comprising of self-attention and feed-forward layers, where each block is capable of independently producing a class token. Formulating an attack using only the last class token (conventional approach) does not directly leverage the discriminative information stored in the earlier tokens, leading to poor adversarial transferability of ViTs.Using the compositional nature of ViT models, we enhance transferability of existing attacks by introducing two novel strategies specific to the architecture of ViT models.  \\emph{(i) Self-Ensemble:} We propose a method to find multiple discriminative pathways by dissecting a single ViT model into an ensemble of networks. This allows explicitly utilizing class-specific information at each ViT block. \\emph{(ii) Token Refinement:} We then propose to refine the tokens to further enhance the discriminative capacity at each block of ViT.Our token refinement systematically combines the class tokens with structural information preserved within the patch tokens. An adversarial attack when applied to such refined tokens within the ensemble of classifiers found in a single vision transformer has significantly higher transferability and thereby brings out the true generalization potential of the ViT's adversarial space. Code: https://t.ly/hBbW.",
    "One-sentence Summary": "Novel approach to improve transferability of adversarial perturbations found in vision transformers via self-ensemble and token refinement."
  },
  {
    "title": "On Predicting Generalization using GANs",
    "url": "/forum?id=eW5R4Cek6y6",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "generalization, generative adversarial network",
    "Abstract": "Research on generalization bounds for deep networks seeks to give ways to predict test error using just the training dataset and the network parameters. While generalization bounds can give many insights about architecture design, training algorithms etc., what they do not currently do is yield good predictions for actual test error. A recently introduced Predicting Generalization in Deep Learning competition aims to encourage discovery of methods to better predict test error. The current paper investigates a simple idea: can test error be predicted using {\\em synthetic data,} produced using a Generative Adversarial Network (GAN) that was trained on the same training dataset? Upon investigating several GAN models and architectures, we find that this turns out to be the case. \n        \n        In fact, using GANs pre-trained on standard datasets, the test error can be predicted without requiring any additional hyper-parameter tuning. This result is surprising because GANs have well-known limitations (e.g. mode collapse) and are known to not learn the data distribution accurately. Yet the generated samples are good enough to substitute for test data. Several additional experiments are presented to explore reasons why GANs do well at this task. In addition to a new approach for predicting generalization, the counter-intuitive phenomena presented in our work may also call for a better understanding of GANs' strengths and limitations."
  },
  {
    "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution",
    "url": "/forum?id=L3_SsSNMmy",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "local attention, depth-wise convolution, dynamic depth-wise convolution, weight sharing, dynamic weight",
    "Abstract": "Vision Transformer (ViT) attains state-of-the-art performance in visual recognition, and the variant, Local Vision Transformer, makes further improvements. The major component in Local Vision Transformer, local attention, performs the attention separately over small local windows. We rephrase local attention as a channel-wise locally-connected layer and analyze it from two network regularization manners, sparse connectivity and weight sharing, as well as dynamic weight computation. We point out that local attention resembles depth-wise convolution and its dynamic variants in sparse connectivity: there is no connection across channels, and each position is connected to the positions within a small local window. The main differences lie in (i) weight sharing - depth-wise convolution shares connection weights (kernel weights) across spatial positions and attention shares the connection weights across channels, and (ii) dynamic weight computation manners - local attention is based on dot-products between pairwise positions in the local window, and dynamic convolution is based on linear projections conducted on the center representation or the globally pooled representation. The connection between local attention and dynamic depth-wise convolution is empirically verified by the ablation study about weight sharing and dynamic weight computation in Local Vision Transformer and (dynamic) depth-wise convolution. We empirically observe that the models based on depth-wise convolution and the dynamic variants with lower computation complexity perform on-par with or slightly better than Swin Transformer, an instance of Local Vision Transformer, for ImageNet classification, COCO object detection and ADE semantic segmentation. Code is available at https://github.com/Atten4Vis/DemystifyLocalViT.",
    "One-sentence Summary": "We study the connection between local attention and dynamic depth-wise convolution in terms of sparse connectivity, weight sharing, and dynamic weight"
  },
  {
    "title": "Strength of Minibatch Noise in SGD",
    "url": "/forum?id=uorVGbWV5sw",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "stochastic gradient descent, minibatch noise, discrete-time SGD, noise and fluctuation, exact solvable models",
    "Abstract": "The noise in stochastic gradient descent (SGD), caused by minibatch sampling, is poorly understood despite its practical importance in deep learning. This work presents the first systematic study of the SGD noise and fluctuations close to a local minimum. We first analyze the SGD noise in linear regression in detail and then derive a general formula for approximating SGD noise in different types of minima. For application, our results (1) provide insight into the stability of training a neural network, (2) suggest that a large learning rate can help generalization by introducing an implicit regularization, (3) explain why the linear learning rate-batchsize scaling law fails at a large learning rate or at a small batchsize and (4) can provide an understanding of how discrete-time nature of SGD affects the recently discovered power-law phenomenon of SGD.",
    "One-sentence Summary": "We solve the strength and shape of the minibatch noise in SGD exactly."
  },
  {
    "title": "Learning more skills through optimistic exploration",
    "url": "/forum?id=cU8rknuhxc",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "intrinsic control, skill discovery, unsupervised skill learning, uncertainty estimation, optimistic exploration, variational information maximization",
    "Abstract": "Unsupervised skill learning objectives (Eysenbach et al., 2019; Gregor et al., 2016) allow agents to learn rich repertoires of behavior in the absence of extrinsic rewards. They work by simultaneously training a policy to produce distinguishable latent-conditioned trajectories, and a discriminator to evaluate distinguishability by trying to infer latents from trajectories. The hope is for the agent to explore and master the environment by encouraging each skill (latent) to reliably reach different states. However, an inherent exploration problem lingers: when a novel state is actually encountered, the discriminator will necessarily not have seen enough training data to produce accurate and confident skill classifications, leading to low intrinsic reward for the agent and effective penalization of the sort of exploration needed to actually maximize the objective. To combat this inherent pessimism towards exploration, we derive an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement. Our objective directly estimates the epistemic uncertainty that comes from the discriminator not having seen enough training examples, thus providing an intrinsic reward more tailored to the true objective compared to pseudocount-based methods (Burda et al., 2019). We call this exploration bonus discriminator disagreement intrinsic reward, or DISDAIN. We demonstrate empirically that DISDAIN improves skill learning both in a tabular grid world (Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we encourage researchers to treat pessimism with DISDAIN.",
    "One-sentence Summary": "Learn more skills by adding an information gain exploration bonus based on discriminator ensemble disagreement."
  },
  {
    "title": "Reinforcement Learning under a Multi-agent Predictive State Representation Model: Method and Theory",
    "url": "/forum?id=PLDOnFoVm4",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Multi-agent Reinforcement Learning, Predictive State Representation, Dynamic Interaction Graph",
    "Abstract": "We study reinforcement learning for partially observable multi-agent systems where each agent only has access to its own observation and reward and aims to maximize its cumulative rewards. To handle partial observations, we propose graph-assisted predictive state representations (GAPSR), a scalable multi-agent representation learning framework that leverages the agent connectivity graphs to aggregate local representations computed by each agent. In addition, our representations are readily able to incorporate dynamic interaction graphs and kernel space embeddings of the predictive states, and thus have strong flexibility and representation power. \n        Based on GAPSR, we propose an end-to-end  MARL algorithm that simultaneously infers the predictive representations and uses the representations as the input of a policy optimization algorithm. Empirically, we demonstrate the efficacy of the proposed algorithm provided on both a MAMuJoCo robotic learning experiment and a multi-agent particle learning environment.",
    "One-sentence Summary": "We propose a new algorithm for MARL under a multi-agent predictive state representation model, where we incorporate a dynamic interaction graph; we provide the theoretical guarantees of our model and run various experiments to support our algorithm."
  },
  {
    "title": "Adversarial Support Alignment",
    "url": "/forum?id=26gKg6x-ie",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "support alignment, distribution alignment, optimal transport, domain adaptation",
    "Abstract": "We study the problem of aligning the supports of distributions. Compared to the existing work on distribution alignment, support alignment does not require the densities to be matched. We propose symmetric support difference as a divergence measure to quantify the mismatch between supports. We show that select discriminators (e.g. discriminator trained for Jensen-Shannon divergence) are able to map support differences as support differences in their one-dimensional output space. Following this result, our method aligns supports by minimizing a symmetrized relaxed optimal transport cost in the discriminator 1D space via an adversarial process. Furthermore, we show that our approach can be viewed as a limit of existing notions of alignment by increasing transportation assignment tolerance. We quantitatively evaluate the method across domain adaptation tasks with shifts in label distributions. Our experiments show that the proposed method is more robust against these shifts than other alignment-based baselines.",
    "One-sentence Summary": "We study the problem of aligning the supports of distributions."
  },
  {
    "title": "GreaseLM: Graph REASoning Enhanced Language Models",
    "url": "/forum?id=41e9o6cQPj",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "language models, commonsense, question answering, knowledge graphs, KG augmentation",
    "Abstract": "Answering complex questions about textual narratives requires reasoning over both stated context and the world knowledge that underlies it. However, pretrained language models (LM), the foundation of most modern QA systems, do not robustly represent latent relationships between concepts, which is necessary for reasoning. While knowledge graphs (KG) are often used to augment LMs with structured representations of world knowledge, it remains an open question how to effectively fuse and reason over the KG representations and the language context, which provides situational constraints and nuances. In this work, we propose GreaseLM, a new model that fuses encoded representations from pretrained LMs and graph neural networks over multiple layers of modality interaction operations. Information from both modalities propagates to the other, allowing language context representations to be grounded by structured world knowledge, and allowing linguistic nuances (e.g., negation, hedging) in the context to inform the graph representations of knowledge. Our results on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA) and medical question answering (i.e., MedQA-USMLE) domains demonstrate that GreaseLM can more reliably answer questions that require reasoning over both situational constraints and structured knowledge, even outperforming models 8x larger.",
    "One-sentence Summary": "We propose GreaseLM, a new model that fuses encoded representations from pretrained LMs and GNNs over multiple layers of modality interaction operations, allowing both modalities to bidirectionally inform the representation of the other."
  },
  {
    "title": "Learning meta-features for AutoML",
    "url": "/forum?id=DTkEfj0Ygb8",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "AutoML, Meta-features, Hyper-parameter Optimization, Optimal Transport",
    "Abstract": "This paper tackles the AutoML problem, aimed to automatically select an ML algorithm and its hyper-parameter configuration most appropriate to the dataset at hand. The proposed approach, MetaBu, learns new meta-features via an Optimal Transport procedure, aligning the manually designed \\mf s with the space of distributions on the hyper-parameter configurations. MetaBu meta-features, learned once and for all, induce a topology on the set of datasets that is exploited to define a distribution of promising hyper-parameter configurations amenable to AutoML. Experiments on the OpenML CC-18 benchmark demonstrate that using MetaBu meta-features boosts the performance of state of the art AutoML systems, AutoSklearn (Feurer et al. 2015) and Probabilistic Matrix Factorization (Fusi et al. 2018). Furthermore, the inspection of MetaBu meta-features gives some hints into when an ML algorithm does well. Finally, the topology based on MetaBu meta-features enables to estimate the intrinsic dimensionality of the OpenML benchmark w.r.t. a given ML algorithm or pipeline. The source code is available at https://github.com/luxusg1/metabu.",
    "One-sentence Summary": "We propose a novel approach to learn dataset meta-features for AutoML."
  },
  {
    "title": "Latent Variable Sequential Set Transformers for Joint Multi-Agent Motion Prediction",
    "url": "/forum?id=Dup_dDqkZC5",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "trajectory prediction, motion forecasting, transformers, latent variable models",
    "Abstract": "Robust multi-agent trajectory prediction is essential for the safe control of robotic systems. A major challenge is to efficiently learn a representation that approximates the true joint distribution of contextual, social, and temporal information to enable planning. We propose Latent Variable Sequential Set Transformers which are encoder-decoder architectures that generate scene-consistent multi-agent trajectories. We refer to these architectures as \u201cAutoBots\u201d. The encoder is a stack of interleaved temporal and social multi-head self-attention (MHSA) modules which alternately perform equivariant processing across the temporal and social dimensions. The decoder employs learnable seed parameters in combination with temporal and social MHSA modules allowing it to perform inference over the\n        entire future scene in a single forward pass efficiently. AutoBots can produce either the trajectory of one ego-agent or a distribution over the future trajectories for all agents in the scene. For the single-agent prediction case, our model achieves top results on the global nuScenes vehicle motion prediction leaderboard, and produces strong results on the Argoverse vehicle prediction challenge. In the multi-agent setting, we evaluate on the synthetic partition of TrajNet++ dataset to showcase the model\u2019s socially-consistent predictions. We also demonstrate our model on general sequences of sets and provide illustrative experiments modelling the sequential structure of the multiple strokes that make up symbols in the Omniglot data. A distinguishing feature of AutoBots is that all models are trainable on a\n        single desktop GPU (1080 Ti) in under 48h.",
    "One-sentence Summary": "New Transformer-based architecture for socially consistent motion forecasting. Achieves SotA performance on NuScenes at a fraction of the compute of competing methods."
  },
  {
    "title": "Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective",
    "url": "/forum?id=5FUq05QRc5b",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Multiple views of data, both naturally acquired (e.g., image and audio) and artificially produced (e.g., via adding different noise to data samples), have proven useful in enhancing representation learning. Natural views are often handled by multiview analysis tools, e.g., (deep) canonical correlation analysis [(D)CCA], while the artificial ones are frequently used in self-supervised learning (SSL) paradigms, e.g., BYOL and Barlow Twins. Both types of approaches often involve learning neural feature extractors such that the embeddings of data exhibit high cross-view correlations. Although intuitive, the effectiveness of correlation-based neural embedding is mostly empirically validated. \n        This work aims to understand latent correlation maximization-based deep multiview learning from a latent component identification viewpoint. An intuitive generative model of multiview data is adopted, where the views are different nonlinear mixtures of shared and private components. Since the shared components are view/distortion-invariant, representing the data using such components is believed to reveal the identity of the samples effectively and robustly. Under this model, latent correlation maximization is shown to guarantee the extraction of the shared components across views (up to certain ambiguities). In addition, it is further shown that the private information in each view can be provably disentangled from the shared using proper regularization design. A finite sample analysis, which has been rare in nonlinear mixture identifiability study, is also presented. The theoretical results and newly designed regularization are tested on a series of tasks."
  },
  {
    "title": "Deconstructing the Inductive Biases of Hamiltonian Neural Networks",
    "url": "/forum?id=EDeVYpT42oS",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Physics-inspired neural networks (NNs), such as Hamiltonian or Lagrangian NNs, dramatically outperform other learned dynamics models by leveraging strong inductive biases. These models, however, are challenging to apply to many real world systems, such as those that don\u2019t conserve energy or contain contacts, a common setting for robotics and reinforcement learning. In this paper, we examine the inductive biases that make physics-inspired models successful in practice. We show that, contrary to conventional wisdom, the improved generalization of HNNs is the result of modeling acceleration directly and avoiding artificial complexity from the coordinate system, rather than symplectic structure or energy conservation. We show that by relaxing the inductive biases of these models, we can match or exceed performance on energy-conserving systems while dramatically improving performance on practical, non-conservative systems. We extend this approach to constructing transition models for common Mujoco environments, showing that our model can appropriately balance inductive biases with the flexibility required for model-based control."
  },
  {
    "title": "Memorizing Transformers",
    "url": "/forum?id=TrjbxzRcnf-",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Transformer, architecture, memorization.",
    "Abstract": "Language models typically need to be trained or finetuned in order to acquire new knowledge, which involves updating their weights.  \n        We instead envision language models that can simply read and memorize new data at inference time, thus acquiring new knowledge immediately. In this work, we extend language models with the ability to memorize the internal representations of past inputs. We demonstrate that an approximate kNN lookup into a non-differentiable memory of recent (key, value) pairs improves language modeling across various benchmarks and tasks, including generic webtext (C4), math papers (arXiv), books (PG-19), code (Github), as well as formal theorems (Isabelle). We show that the performance steadily improves when we increase the size of memory up to 262K tokens. \n        On benchmarks including code and mathematics, we find that the model is capable of making use of newly defined functions and theorems during test time.",
    "One-sentence Summary": "We propose to use an external memory module to allow instant utilization of newly acquired knowledge."
  },
  {
    "title": "Learning-Augmented k-means Clustering",
    "url": "/forum?id=X8cLTHexYyY",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "clustering, learning-augmented algorithms",
    "Abstract": "k-means clustering is a well-studied problem due to its wide applicability. Unfortunately, there exist strong theoretical limits on the performance of any algorithm for the k-means problem on worst-case inputs. To overcome this barrier, we consider a scenario where ``advice'' is provided to help perform clustering. Specifically, we consider the k-means problem augmented with a predictor that, given any point, returns its cluster label in an approximately optimal clustering up to some, possibly adversarial, error. We present an algorithm whose performance improves along with the accuracy of the predictor, even though na\\\"{i}vely following the accurate predictor can still lead to a high clustering cost. Thus if the predictor is sufficiently accurate, we can retrieve a close to optimal clustering with nearly optimal runtime, breaking known computational barriers for algorithms that do not have access to such advice. We evaluate our algorithms on real datasets and show significant improvements in the quality of clustering.",
    "One-sentence Summary": "We study the k-means problem augmented with a learning-based predictor that gives noisy information about true labels."
  },
  {
    "title": "On the Uncomputability of Partition Functions in Energy-Based Sequence Models",
    "url": "/forum?id=SsPCtEY6yCl",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "energy-based models, turing completeness, model capacity, sequence models, autoregressive models, partition function, parameter estimation, model selection",
    "Abstract": "In this paper, we argue that energy-based sequence models backed by expressive parametric families can result in uncomputable and inapproximable partition functions. Among other things, this makes model selection--and therefore learning model parameters--not only difficult, but generally _undecidable_. The reason is that there are no good deterministic or randomized estimates of partition functions. Specifically, we exhibit a pathological example where under common assumptions, _no_ useful importance sampling estimates of the partition function can guarantee to have variance bounded below a rational number. As alternatives, we consider sequence model families whose partition functions are computable (if they exist), but at the cost of reduced expressiveness. Our theoretical results suggest that statistical procedures with asymptotic guarantees and sheer (but finite) amounts of compute are not the only things that make sequence modeling work; computability concerns must not be neglected as we consider more expressive model parametrizations.",
    "One-sentence Summary": "EBMs over sequences have several theoretical limitations as learnable probabilistic sequence models."
  },
  {
    "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs",
    "url": "/forum?id=fILj7WpI-g",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Perceiver, BERT, natural language processing, optical flow, computer vision, multimodal, GLUE, ImageNet, StarCraft",
    "Abstract": "A central goal of machine learning is the development of systems that can solve many problems in as many data domains as possible. Current architectures, however, cannot be applied beyond a small set of stereotyped settings, as they bake in domain & task assumptions or scale poorly to large inputs or outputs. In this work, we propose Perceiver IO, a general-purpose architecture that handles data from arbitrary settings while scaling linearly with the size of inputs and outputs. Our model augments the Perceiver with a flexible querying mechanism that enables outputs of various sizes and semantics, doing away with the need for task-specific architecture engineering. The same architecture achieves strong results on tasks spanning natural language and visual understanding, multi-task and multi-modal reasoning, and StarCraft II. As highlights, Perceiver IO outperforms a Transformer-based BERT baseline on the GLUE language benchmark despite removing input tokenization and achieves state-of-the-art performance on Sintel optical flow estimation with no explicit mechanisms for multiscale correspondence.",
    "One-sentence Summary": "We propose Perceiver IO, a general-purpose architecture that handles data from arbitrary settings while scaling linearly with the size of inputs and outputs."
  },
  {
    "title": "DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization",
    "url": "/forum?id=POvMvLi91f",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Q-learning, offline RL, regularization",
    "Abstract": "Despite overparameterization, deep networks trained via supervised learning are surprisingly easy to optimize and exhibit excellent generalization. One hypothesis to explain this is that overparameterized deep networks enjoy the benefits of implicit regularization induced by stochastic gradient descent, which favors parsimonious solutions that generalize well on test inputs. It is reasonable to surmise that deep reinforcement learning (RL) methods could also benefit from this effect. In this paper, we discuss how the implicit regularization effect of SGD seen in supervised learning could in fact be harmful in the offline deep RL setting, leading to poor generalization and degenerate feature representations. Our theoretical analysis shows that when existing models of implicit regularization are applied to temporal difference learning, the resulting derived regularizer favors degenerate solutions with excessive aliasing, in stark contrast to the supervised learning case. We back up these findings empirically, showing that feature representations learned by a deep network value function trained via bootstrapping can indeed become degenerate, aliasing the representations for state-action pairs that appear on either side of the Bellman backup. To address this issue, we derive the form of this implicit regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicit regularizer. When combined with existing offline RL methods, DR3 substantially improves performance and stability, alleviating unlearning in Atari 2600 games, D4RL domains and robotic manipulation from images.",
    "One-sentence Summary": "We show that implicit regularization effects can lead to poor performance in value-based offline RL and propose an explicit regularizer to mitigate these effects."
  },
  {
    "title": "MT3: Multi-Task Multitrack Music Transcription",
    "url": "/forum?id=iMSjopcOn0p",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "music transcription, transformer, multi-task learning, low resource learning, music understanding, music information retrieval",
    "Abstract": "Automatic Music Transcription (AMT), inferring musical notes from raw audio, is a challenging task at the core of music understanding. Unlike Automatic Speech Recognition (ASR), which typically focuses on the words of a single speaker, AMT often requires transcribing multiple instruments simultaneously, all while preserving fine-scale pitch and timing information. Further, many AMT datasets are ``low-resource'', as even expert musicians find music transcription difficult and time-consuming. Thus, prior work has focused on task-specific architectures, tailored to the individual instruments of each task. In this work, motivated by the promising results of sequence-to-sequence transfer learning for low-resource Natural Language Processing (NLP), we demonstrate that a general-purpose Transformer model can perform multi-task AMT, jointly transcribing arbitrary combinations of musical instruments across several transcription datasets. We show this unified training framework achieves high-quality transcription results across a range of datasets, dramatically improving performance for low-resource instruments (such as guitar), while preserving strong performance for abundant instruments (such as piano). Finally, by expanding the scope of AMT, we expose the need for more consistent evaluation metrics and better dataset alignment, and provide a strong baseline for this new direction of multi-task AMT.",
    "One-sentence Summary": "Unified framework for music transcription, jointly training a single model on six multi-instrument datasets and establishing a new SOTA for low-resource music transcription."
  },
  {
    "title": "Does your graph need a confidence boost?  Convergent boosted smoothing on graphs with tabular node features",
    "url": "/forum?id=nHpzE7DqAnG",
    "date": "28 Sept 2021 (modified: 19 Apr 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Graph Neural Network, Boosting, Node classification, Tabular Data",
    "Abstract": "Many practical modeling tasks require making predictions using tabular data composed of heterogeneous feature types (e.g., text-based, categorical, continuous, etc.).  In this setting boosted decision trees and related ensembling techniques generally dominate real-world applications involving iid training/test sets.  However, when there are relations between samples and the iid assumption is no longer reasonable, it remains unclear how to incorporate these dependencies within existing boosting pipelines.  To this end, we propose a generalized framework for combining boosted trees and more general model ensembling techniques, with graph propagation layers that share  node/sample information across edges connecting related samples.  And unlike previous efforts to integrate graph-based models with boosting, our approach is anchored to a principled meta loss function such that provable convergence can be guaranteed under relatively mild assumptions. Across a variety of benchmarks involving non-iid graph data with tabular node features, our framework achieves comparable or superior performance.",
    "One-sentence Summary": "We develop a convergent method for combining boosting and graph propagation layers."
  },
  {
    "title": "Geometric and Physical Quantities improve E(3) Equivariant Message Passing",
    "url": "/forum?id=_xwr8gOBeV1",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "equivariant graph neural networks, steerable message passing, non-linear convolutions, molecular modeling, covariant information",
    "Abstract": "Including covariant information, such as position, force, velocity or spin is important in many tasks in computational physics and chemistry. We introduce Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise equivariant graph networks, such that node and edge attributes are not restricted to invariant scalars, but can contain covariant information, such as vectors or tensors. Our model, composed of steerable MLPs, is able to incorporate geometric and physical information in both the message and update functions.\n        Through the definition of steerable node attributes, the MLPs provide a new class of activation functions for general use with steerable feature fields. We discuss ours and related work through the lens of equivariant non-linear convolutions, which further allows us to pin-point the successful components of SEGNNs: non-linear message aggregation improves upon classic linear (steerable) point convolutions; steerable messages improve upon recent equivariant graph networks that send invariant messages. We demonstrate the effectiveness of our method on several tasks in computational physics and chemistry and provide extensive ablation studies.",
    "One-sentence Summary": "We generalise equivariant graph networks such that node and edge updates are able to leverage covariant information."
  },
  {
    "title": "SphereFace2: Binary Classification is All You Need for Deep Face Recognition",
    "url": "/forum?id=l3SDgUh7qZO",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "State-of-the-art deep face recognition methods are mostly trained with a softmax-based multi-class classification framework. Despite being popular and effective, these methods still have a few shortcomings that limit empirical performance. In this paper, we start by identifying the discrepancy between training and evaluation in the existing multi-class classification framework and then discuss the potential limitations caused by the \"competitive\" nature of softmax normalization. Motivated by these limitations, we propose a novel binary classification training framework, termed SphereFace2. In contrast to existing methods, SphereFace2 circumvents the softmax normalization, as well as the corresponding closed-set assumption. This effectively bridges the gap between training and evaluation, enabling the representations to be improved individually by each binary classification task. Besides designing a specific well-performing loss function, we summarize a few general principles for this \"one-vs-all\" binary classification framework so that it can outperform current competitive methods. Our experiments on popular benchmarks demonstrate that SphereFace2 can consistently outperform state-of-the-art deep face recognition methods.",
    "One-sentence Summary": "A novel deep face recognition framework"
  },
  {
    "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers",
    "url": "/forum?id=mHu2vIds_-b",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "adversarial robustness, certified robustness, randomized smoothing",
    "Abstract": "Randomized Smoothing (RS) is a promising method for obtaining robustness certi\ufb01cates by evaluating a base model under noise. In this work, we: (i) theoretically motivate why ensembles are a particularly suitable choice as base models for RS, and (ii) empirically con\ufb01rm this choice, obtaining state-of-the-art results in multiple settings. The key insight of our work is that the reduced variance of ensembles over the perturbations introduced in RS leads to signi\ufb01cantly more consistent classi\ufb01cations for a given input. This, in turn, leads to substantially increased certi\ufb01able radii for samples close to the decision boundary. Additionally, we introduce key optimizations which enable an up to 55-fold decrease in sample complexity of RS for predetermined radii, thus drastically reducing its computational overhead. Experimentally, we show that ensembles of only 3 to 10 classi\ufb01ers consistently improve on their strongest constituting model with respect to their average certi\ufb01ed radius (ACR) by 5% to 21% on both CIFAR10 and ImageNet, achieving a new state-of-the-art ACR of 0.86 and 1.11, respectively. We release all code and models required to reproduce our results at https://github.com/eth-sri/smoothing-ensembles.",
    "One-sentence Summary": "We show -- theoretically and empirically -- that ensembles reduce variance under randomized smoothing, yielding higher certified accuracy, leading to a new state-of-the-art on CIFAR-10 and ImageNet."
  },
  {
    "title": "SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning",
    "url": "/forum?id=t5EmXZ3ZLR",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Structured Pruning, Saliency-based Pruning, Network Compression, Hessian Approximation, Neural Architecture Search, Deep Learning, Computer Vision",
    "Abstract": "Pruning neural networks reduces inference time and memory costs. On standard hardware, these benefits will be especially prominent if coarse-grained structures, like feature maps, are pruned. We devise two novel saliency-based methods for second-order structured pruning (SOSP) which include correlations among all structures and layers. Our main method SOSP-H employs an innovative second-order approximation, which enables saliency evaluations by fast Hessian-vector products. SOSP-H thereby scales like a first-order method despite taking into account the full Hessian. We validate SOSP-H by comparing it to our second method SOSP-I that uses a well-established Hessian approximation, and to numerous state-of-the-art methods. While SOSP-H performs on par or better in terms of accuracy, it has clear advantages in terms of scalability and efficiency. This allowed us to scale SOSP-H to large-scale vision tasks, even though it captures correlations across all layers of the network. To underscore the global nature of our pruning methods, we evaluate their performance not only by removing structures from a pretrained network, but also by detecting architectural bottlenecks. We show that our algorithms allow to systematically reveal architectural bottlenecks, which we then remove to further increase the accuracy of the networks.",
    "One-sentence Summary": "We introduce a second-order structured pruning method which efficiently captures global correlations among structures of deep neural networks."
  },
  {
    "title": "Relational Multi-Task Learning: Modeling Relations between Data and Tasks",
    "url": "/forum?id=8Py-W8lSUgy",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Graph Neural Networks, Relational Representation Learning, Multi-task Learning, Meta Learning",
    "Abstract": "A key assumption in multi-task learning is that at the inference time the multi-task model only has access to a given data point but not to the data point\u2019s labels from other tasks. This presents an opportunity to extend multi-task learning to utilize data point\u2019s labels from other auxiliary tasks, and this way improves performance on the new task. Here we introduce a novel relational multi-task learning setting where we leverage data point labels from auxiliary tasks to make more accurate predictions on the new task. We develop MetaLink, where our key innovation is to build a knowledge graph that connects data points and tasks and thus allows us to leverage labels from auxiliary tasks. The knowledge graph consists of two types of nodes: (1) data nodes, where node features are data embeddings computed by the neural network, and (2) task nodes, with the last layer\u2019s weights for each task as node features. The edges in this knowledge graph capture data-task relationships, and the edge label captures the label of a data point on a particular task. Under MetaLink, we reformulate the new task as a link label prediction problem between a data node and a task node. The MetaLink framework provides flexibility to model knowledge transfer from auxiliary task labels to the task of interest. We evaluate MetaLink on 6 benchmark datasets in both biochemical and vision domains. Experiments demonstrate that MetaLink can successfully utilize the relations among different tasks, outperforming the state-of-the-art methods under the proposed relational multi-task learning setting, with up to 27% improvement in ROC AUC.",
    "One-sentence Summary": "We propose MetaLink to solve a variety of multi-task learning settings, by constructing a knowledge graph over data points and tasks."
  },
  {
    "title": "CoBERL: Contrastive BERT for Reinforcement Learning",
    "url": "/forum?id=sRZ3GhmegS",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement Learning, Contrastive Learning, Representation Learning, Transformer, Deep Reinforcement Learning",
    "Abstract": "Many reinforcement learning (RL) agents require a large amount of experience to solve tasks. We propose Contrastive BERT for RL (COBERL), an agent that combines a new contrastive loss and a hybrid LSTM-transformer architecture to tackle the challenge of improving data efficiency. COBERL enables efficient and robust learning from pixels across a wide variety of domains. We use bidirectional masked prediction in combination with a generalization of a recent contrastive method to learn better representations for RL, without the need of hand engineered data augmentations. We find that COBERL consistently improves data efficiency across the full Atari suite, a set of control tasks and a challenging 3D environment, and often it also increases final score performance.",
    "One-sentence Summary": "A new loss and an improved architecture to efficiently train attentional models in reinforcement learning."
  },
  {
    "title": "Optimal Transport for Causal Discovery",
    "url": "/forum?id=qwBK94cP1y",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "causal discovery, optimal transport, functional causal model",
    "Abstract": "To determine causal relationships between two variables, approaches based on Functional Causal Models (FCMs) have been proposed by properly restricting model classes; however, the performance is sensitive to the model assumptions, which makes it difficult to use. In this paper, we provide a novel dynamical-system view of FCMs and propose a new framework for identifying causal direction in the bivariate case. We first show the connection between FCMs and optimal transport, and then study optimal transport under the constraints of FCMs. Furthermore, by exploiting the dynamical interpretation of optimal transport under the FCM constraints, we determine the corresponding underlying dynamical process of the static cause-effect pair data. It provides a new dimension for describing static causal discovery tasks while enjoying more freedom for modeling the quantitative causal influences. In particular, we show that Additive Noise Models (ANMs) correspond to volume-preserving pressureless flows. Consequently, based on their velocity field divergence, we introduce a criterion for determining causal direction. With this criterion, we propose a novel optimal transport-based algorithm for ANMs which is robust to the choice of models and extend it to post-nonlinear models. Our method demonstrated state-of-the-art results on both synthetic and causal discovery benchmark datasets."
  },
  {
    "title": "On Bridging Generic and Personalized Federated Learning for Image Classification",
    "url": "/forum?id=I1hQbx10Kxn",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "federated learning, personalization, image classification",
    "Abstract": "Federated learning is promising for its capability to collaboratively train models with multiple clients without accessing their data, but vulnerable when clients' data distributions diverge from each other. This divergence further leads to a dilemma: \"Should we prioritize the learned model's generic performance (for future use at the server) or its personalized performance (for each client)?\" These two, seemingly competing goals have divided the community to focus on one or the other, yet in this paper we show that it is possible to approach both at the same time. Concretely, we propose a novel federated learning framework that explicitly decouples a model's dual duties with two prediction tasks. On the one hand, we introduce a family of losses that are robust to non-identical class distributions, enabling clients to train a generic predictor with a consistent objective across them. On the other hand, we formulate the personalized predictor as a lightweight adaptive module that is learned to minimize each client's empirical risk on top of the generic predictor. With this two-loss, two-predictor framework which we name Federated Robust Decoupling (Fed-RoD), the learned model can simultaneously achieve state-of-the-art generic and personalized performance, essentially bridging the two tasks."
  },
  {
    "title": "Value Gradient weighted Model-Based Reinforcement Learning",
    "url": "/forum?id=4-D6CZkRXxI",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "model-based reinforcement learning, reinforcment learning, objective mismatch, value function, sensitivity",
    "Abstract": "Model-based reinforcement learning (MBRL) is a sample efficient technique to obtain control policies, yet unavoidable modeling errors often lead performance deterioration. The model in MBRL is often solely fitted to reconstruct dynamics, state observations in particular, while the impact of model error on the policy is not captured by the training objective. This leads to a mismatch between the intended goal of MBRL, enabling good policy and value learning, and the target of the loss function employed in practice, future state prediction. Naive intuition would suggest that value-aware model learning would fix this problem and, indeed, several solutions to this objective mismatch problem have been proposed based on theoretical analysis. However, they tend to be inferior in practice to commonly used maximum likelihood (MLE) based approaches. In this paper we propose the Value-gradient weighted Model Learning (VaGraM), a novel method for value-aware model learning which improves the performance of MBRL in challenging settings, such as small model capacity and the presence of distracting state dimensions. We analyze both MLE and value-aware approaches and demonstrate how they fail to account for exploration and the behavior of function approximation when learning value-aware models and highlight the additional goals that must be met to stabilize optimization in the deep learning setting. We verify our analysis by showing that our loss function is able to achieve high returns on the Mujoco benchmark suite while being more robust than maximum likelihood based approaches.",
    "One-sentence Summary": "We propose the Value-gradient weighted Model loss, a method for value-aware model learning in challenging settings, such as small model capacity and the presence of distracting state dimensions."
  },
  {
    "title": "Fairness in Representation for Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling",
    "url": "/forum?id=-llS6TiOew",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "fairness, evaluation, multilingual NLP / multilinguality, representation learning for language data, statistical comparisons, Double Descent, conditional language modeling, data-centric approach, diversity in AI, morphology, Transformer, meta evaluation, visualization or interpretation of learned representations, character encoding, internationalization and localization, robustness, statistical science for NLP, science in the era of AI/DL (AIxScience), transdisciplinarity",
    "Abstract": "We perform systematically and fairly controlled experiments with the 6-layer Transformer to investigate  the hardness in conditional-language-modeling languages which have been traditionally considered morphologically rich (AR and RU) and poor (ZH). We evaluate through statistical comparisons across 30 possible language directions from the 6 languages of the United Nations Parallel Corpus across 5 data sizes on 3 representation levels --- character, byte, and word. Results show that performance is relative to the representation granularity of each of the languages, not to the language as a whole. On the character and byte levels, we are able to eliminate statistically significant performance disparity, hence demonstrating that a language cannot be intrinsically hard. The disparity that mirrors the morphological complexity hierarchy is shown to be a byproduct of word segmentation. Evidence from data statistics, along with the fact that word segmentation is qualitatively indeterminate, renders a decades-long debate on morphological complexity (unless it is being intentionally modeled in a word-based, meaning-driven context) irrelevant in the context of computing. The intent of our work is to help effect more objectivity and adequacy in evaluation as well as fairness and inclusivity in experimental setup in the area of language and computing so to uphold diversity in Machine Learning and Artificial Intelligence research. Multilinguality is real and relevant in computing not due to canonical, structural linguistic concepts such as morphology or \"words\" in our minds, but rather standards related to internationalization and localization, such as character encoding --- something which has thus far been sorely overlooked in our discourse and curricula.",
    "One-sentence Summary": "We investigate performance disparity in multilingual NLP with Transformer conditional LMs, and find, in the context of computing, morphological complexity to be a byproduct of word segmentation and disparity arising therefrom unwarranted."
  },
  {
    "title": "Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration",
    "url": "/forum?id=YJ1WzgMVsMt",
    "date": "28 Sept 2021 (modified: 13 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement Learning, Sparse Rewards, Learning from Demonstrations",
    "Abstract": "A major challenge in real-world reinforcement learning (RL) is the sparsity of reward feedback.  Often, what is available is an intuitive but sparse reward function that only indicates whether the task is completed partially or fully.  However, the lack of carefully designed, fine grain feedback implies that most existing RL algorithms fail to learn an acceptable policy in a reasonable time frame.  This is because of the large number of exploration actions that the policy has to perform before it gets any useful feedback that it can learn from.  In this work, we address this challenging problem by developing an algorithm that exploits the offline demonstration data generated by {a sub-optimal behavior policy} for faster and efficient online RL in such sparse reward settings.  The proposed algorithm, which we call the Learning Online with Guidance Offline (LOGO) algorithm, merges a policy improvement step with an additional policy guidance step by using the offline demonstration data.  The key idea is that by obtaining guidance from - not imitating - the offline {data}, LOGO orients its policy in the manner of the sub-optimal {policy}, while yet being able to learn beyond and approach optimality.  We provide a theoretical analysis of our algorithm, and provide a lower bound on the performance improvement in each learning episode.  We also extend our algorithm to the even more challenging incomplete observation setting, where the demonstration data contains only a censored version of the true state observation.  We demonstrate the superior performance of our algorithm over state-of-the-art approaches on a number of  benchmark environments with sparse rewards {and censored state}.  Further, we demonstrate the value of our approach via implementing LOGO on a mobile robot for trajectory tracking and obstacle avoidance, where it shows excellent performance.",
    "One-sentence Summary": "Reinforcement learning in sparse reward environments  using offline guidance."
  },
  {
    "title": "Linking Emergent and Natural Languages via Corpus Transfer",
    "url": "/forum?id=49A1Y6tRhaq",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Emergent Language, Emergent Communication, Transfer Learning",
    "Abstract": "The study of language emergence aims to understand how human languages are shaped by perceptual grounding and communicative intent. Computational approaches to emergent communication (EC) predominantly consider referential games in limited domains and analyze the learned protocol within the game framework. As a result, it remains unclear how the emergent languages from these settings connect to natural languages or provide benefits in real-world language processing tasks, where statistical models trained on large text corpora dominate. In this work, we propose a novel way to establish such a link by corpus transfer, i.e. pretraining on a corpus of emergent language for downstream natural language tasks, which is in contrast to prior work that directly transfers speaker and listener parameters. Our approach showcases non-trivial transfer benefits for two different tasks \u2013 language modeling and image captioning. For example, in a low-resource setup (modeling 2 million natural language tokens), pre-training on an emergent language corpus with just 2 million tokens reduces model perplexity by 24.6% on average across ten natural languages. We also introduce a novel metric to predict the transferability of an emergent language by translating emergent messages to natural language captions grounded on the same images. We find that our translation-based metric highly correlates with the downstream performance on modeling natural languages (for instance \u03c1=0.83 on Hebrew), while topographic similarity, a popular metric in previous works, shows surprisingly low correlation (\u03c1=0.003), hinting that simple properties like attribute disentanglement from synthetic domains might not capture the full complexities of natural language. Our findings also indicate potential benefits of moving language emergence forward with natural language resources and models.",
    "One-sentence Summary": "We find that pre-training on an emergent language corpus improves natural language tasks in a low resource setup, and propose a metric to predict such a transferability."
  },
  {
    "title": "TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting",
    "url": "/forum?id=wv6g8fWLX2q",
    "date": "28 Sept 2021 (modified: 02 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "topological data analysis, multipersistence, graph convolutional networks, supragraph diffusion, multivariate time series forecasting",
    "Abstract": "Graph Neural Networks (GNNs) are proven to be a powerful machinery for learning complex dependencies in multivariate spatio-temporal processes. However, most existing GNNs have inherently static architectures, and as a result, do not explicitly account for time dependencies of the encoded knowledge and are limited in their ability to simultaneously infer latent time-conditioned relations among entities. We postulate that such hidden time-conditioned properties may be captured by the tools of multipersistence, i.e, a emerging machinery in topological data analysis which allows us to quantify dynamics of the data shape along multiple geometric dimensions. \n         We make the first step toward integrating the two rising research directions, that is, time-aware deep learning and multipersistence, and propose a new model, Time-Aware Multipersistence Spatio-Supra Graph Convolutional Network (TAMP-S2GCNets). We summarize inherent time-conditioned topological properties of the data as time-aware multipersistence Euler-Poincar\\'e surface and prove its stability. We then construct a supragraph convolution module which simultaneously accounts for the extracted intra- and inter- spatio-temporal dependencies in the data. Our extensive experiments on highway traffic flow, Ethereum token prices, and COVID-19 hospitalizations demonstrate that TAMP-S2GCNets outperforms the state-of-the-art tools in multivariate time series forecasting tasks.",
    "One-sentence Summary": "We make the first step toward integrating two emerging directions, time-aware deep learning and multi-parameter persistence, allowing us to infer latent time-conditioned relations among entities in multivariate time series forecasting tasks."
  },
  {
    "title": "The MultiBERTs: BERT Reproductions for Robustness Analysis",
    "url": "/forum?id=K0E_F0gFDgA",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Pre-trained models, BERT, bootstrapping, hypothesis testing, robustness",
    "Abstract": "Experiments with pre-trained models such as BERT are often based on a single checkpoint. While the conclusions drawn apply to the artifact tested in the experiment (i.e., the particular instance of the model), it is not always clear whether they hold for the more general procedure which includes the architecture, training data, initialization scheme, and loss function. Recent work has shown that repeating the pre-training process can lead to substantially different performance, suggesting that an alternative strategy is needed to make principled statements about procedures. To enable researchers to draw more robust conclusions, we introduce MultiBERTs, a set of 25 BERT-Base checkpoints, trained with similar hyper-parameters as the original BERT model but differing in random weight initialization and shuffling of training data. We also define the Multi-Bootstrap, a non-parametric bootstrap method for statistical inference designed for settings where there are multiple pre-trained models and limited test data. To illustrate our approach, we present a case study of gender bias in coreference resolution, in which the Multi-Bootstrap lets us measure effects that may not be detected with a single checkpoint. The models and statistical library are available online, along with an additional set of 140 intermediate checkpoints captured during pre-training to facilitate research on learning dynamics.",
    "One-sentence Summary": "We introduce MultiBERTs, 25 BERT checkpoints trained with similar hyper-parameters but different random seeds, and the Multi-Bootstrap, a bootstrapping method for experimental settings that involve multiple models and limited test data."
  },
  {
    "title": "Message Passing Neural PDE Solvers",
    "url": "/forum?id=vSix3HPYKSU",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "neural PDE solvers, message passing, autoregressive models, zero-stability",
    "Abstract": "The numerical solution of partial differential equations (PDEs) is difficult, having led to a century of research so far. Recently, there have been pushes to build neural--numerical hybrid solvers, which piggy-backs the modern trend towards fully end-to-end learned systems. Most works so far can only generalize over a subset of properties to which a generic solver would be faced, including: resolution, topology, geometry, boundary conditions, domain discretization regularity, dimensionality, etc. In this work, we build a solver, satisfying these properties, where all the components are based on neural message passing, replacing all heuristically designed components in the computation graph with backprop-optimized neural function approximators. We show that neural message passing solvers representationally contain some classical methods, such as finite differences, finite volumes, and WENO schemes. In order to encourage stability in training autoregressive models, we put forward a method that is based on the principle of zero-stability, posing stability as a domain adaptation problem. We validate our method on various fluid-like flow problems, demonstrating fast, stable, and accurate performance across different domain topologies, discretization, etc. in 1D and 2D. Our model outperforms state-of-the-art numerical solvers in the low resolution regime in terms of speed, and accuracy.",
    "One-sentence Summary": "This paper introduces a message passing neural PDE solver that replaces all heuristically designed components in numerical PDE solvers with backprop-optimized neural function approximators."
  },
  {
    "title": "Multi-Stage Episodic Control for Strategic Exploration in Text Games",
    "url": "/forum?id=Ek7PSN7Y77z",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "reinforcement learning, language understanding, text-based games",
    "Abstract": "Text adventure games present unique challenges to reinforcement learning methods due to their combinatorially large action spaces and sparse rewards. The interplay of these two factors is particularly demanding because large action spaces require extensive exploration, while sparse rewards provide limited feedback. This work proposes to tackle the explore-vs-exploit dilemma using a multi-stage approach that explicitly disentangles these two strategies within each episode. Our algorithm, called eXploit-Then-eXplore (XTX), begins each episode using an exploitation policy that imitates a set of promising trajectories from the past, and then switches over to an exploration policy aimed at discovering novel actions that lead to unseen state spaces. This policy decomposition allows us to combine global decisions about which parts of the game space to return to with curiosity-based local exploration in that space, motivated by how a human may approach these games. Our method significantly outperforms prior approaches by 27% and 11% average normalized score over 12 games from the Jericho benchmark (Hausknecht et al., 2020) in both deterministic and stochastic settings, respectively. On the game of Zork1, in particular, XTX obtains a score of 103, more than a 2x improvement over prior methods, and pushes past several known bottlenecks in the game that have plagued previous state-of-the-art methods.",
    "One-sentence Summary": "We propose a multi-stage approach to playing text games that improves the score on Zork1 from around 40 to 103."
  },
  {
    "title": "Exploring the Limits of Large Scale Pre-training",
    "url": "/forum?id=V3C8p78sDa",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Scaling law, Pre-training, Transfer learning, Large Scale, Vision Transformer, Few Shot, Empirical Investigation",
    "Abstract": "Recent developments in large-scale machine learning suggest that by scaling up data, model size and training time properly, one might  observe that improvements in pre-training would transfer favorably to  most downstream tasks. In this work we systematically study this phenomena and establish that, as we increase the upstream accuracy, performance of downstream tasks \\emph{saturates}. In particular, we investigate more than 4800 experiments on Vision Transformers, MLP-Mixers and ResNets with number of parameters ranging from ten million to ten billion, trained on the largest scale of available image data (JFT, ImageNet21K) and evaluated on more than 20 downstream image recognition tasks. We propose a model for downstream performance  that reflects the saturation phenomena and captures the nonlinear relationship in performance of upstream and downstream tasks. Delving deeper to understand the reasons that give rise to these phenomena, we show that the observed saturation behavior is closely related to the way that representations evolve through the layers of the models. We showcase an even more extreme scenario where performance on upstream and downstream are at odds with each other. That is, in order to have a better downstream performance, we need to hurt upstream accuracy.",
    "One-sentence Summary": "We perform a systematic investigation of limits of  large scale pre-training for few-shot and transfer learning in image recognition with a wide range of downstream tasks."
  },
  {
    "title": "Universal Approximation Under Constraints is Possible with Transformers",
    "url": "/forum?id=JGO8CvG5S9",
    "date": "28 Sept 2021 (modified: 08 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Constrained Universal Approximation, Probabilistic Attention, Transformer Networks, Geometric Deep Learning, Measurable Maximum Theorem, Non-Affine Random Projections, Optimal Transport.",
    "Abstract": "Many practical problems need the output of a machine learning model to satisfy a set of constraints, K.  Nevertheless, there is no known guarantee that classical neural network architectures can exactly encode constraints while simultaneously achieving universality.  We provide a quantitative constrained universal approximation theorem which guarantees that for any non-convex compact set K and any continuous function f:Rn\u2192K, there is a probabilistic transformer F^ whose randomized outputs all lie in K and whose expected output uniformly approximates f.  Our second main result is a ``deep neural version'' of Berge's Maximum Theorem (1963).  The result guarantees that given an objective function L, a constraint set K, and a family of soft constraint sets, there is a probabilistic transformer F^ that approximately minimizes L and whose outputs belong to K; moreover, F^ approximately satisfies the soft constraints.  Our results imply the first universal approximation theorem for classical transformers with exact convex constraint satisfaction.  They also yield that a chart-free universal approximation theorem for Riemannian manifold-valued functions subject to suitable geodesically convex constraints.",
    "One-sentence Summary": "We provide the first universal approximation theorem with exact non-convex constraint satisfaction, and we introduce probabilistic transformer networks to do so."
  },
  {
    "title": "Scaling Laws for Neural Machine Translation",
    "url": "/forum?id=hR_SMu8cxCV",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Scaling Laws, Neural Machine Translation, NMT, Model Scaling",
    "Abstract": "We present an empirical study of scaling properties of encoder-decoder Transformer models used in neural machine translation (NMT). We show that cross-entropy loss as a function of model size follows a certain scaling law. Specifically (i) We propose a formula which describes the scaling behavior of cross-entropy loss as a bivariate function of encoder and decoder size, and show that it gives accurate predictions under a variety of scaling approaches and languages; we show that the total number of parameters alone is not sufficient for such purposes. (ii) We observe different power law exponents when scaling the decoder vs scaling the encoder, and provide recommendations for optimal allocation of encoder/decoder capacity based on this observation. (iii) We also report that the scaling behavior of the model is acutely influenced by composition bias of the train/test sets, which we define as any deviation from naturally generated text (either via machine generated or human translated text). We observe that natural text on the target side enjoys scaling, which manifests as successful reduction of the cross-entropy loss. (iv) Finally, we investigate the relationship between the cross-entropy loss and the quality of the generated translations. We find two different behaviors, depending on the nature of the test data. For test sets which were originally translated from target language to source language, both loss and BLEU score improve as model size increases. In contrast, for test sets originally translated from source language to target language, the loss improves, but the BLEU score stops improving after a certain threshold. We release generated text from all models used in this study.",
    "One-sentence Summary": "We provide (model) scaling laws for neural machine translation."
  },
  {
    "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
    "url": "/forum?id=8H5bpVwvt5",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Transfer RL, Graphical models, Efficient adaptation",
    "Abstract": "One practical challenge in reinforcement learning (RL) is how to make quick adaptations when faced with new environments. In this paper, we propose a principled framework for adaptive RL, called AdaRL, that adapts reliably and efficiently to changes across domains with a few samples from the target domain, even in partially observable environments. Specifically, we leverage a parsimonious graphical representation that characterizes structural relationships over variables in the RL system. Such graphical representations provide a compact way to encode what and where the changes across domains are, and furthermore inform us with a minimal set of changes that one has to consider for the purpose of policy adaptation. We show that by explicitly leveraging this compact representation to encode changes, we can efficiently adapt the policy to the target domain, in which only a few samples are needed and further policy optimization is avoided. We illustrate the efficacy of AdaRL through a series of experiments that vary factors in the observation, transition and reward functions for Cartpole and Atari games.",
    "One-sentence Summary": "Efficient policy adaptation across domains by learning a parsimonious graphical representation that encodes changes in a compact way."
  },
  {
    "title": "Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking",
    "url": "/forum?id=GQjaI9mLet",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "protein complexes, protein structure, rigid body docking, SE(3) equivariance, graph neural networks",
    "Abstract": "Protein complex formation is a central problem in biology, being involved in most of the cell's processes, and essential for applications, e.g. drug design or protein engineering. We tackle rigid body protein-protein docking, i.e., computationally predicting the 3D structure of a protein-protein complex from the individual unbound structures, assuming no conformational change within the proteins happens during binding. We design a novel pairwise-independent SE(3)-equivariant graph matching network to predict the rotation and translation to place one of the proteins at the right docked position relative to the second protein. We mathematically guarantee a basic principle: the predicted complex is always identical regardless of the initial locations and orientations of the two structures. Our model, named EquiDock, approximates the binding pockets and predicts the docking poses using keypoint matching and alignment, achieved through optimal transport and a differentiable Kabsch algorithm. Empirically, we achieve significant running time improvements and often outperform existing  docking software despite not relying on heavy candidate sampling, structure refinement, or templates.",
    "One-sentence Summary": "We perform rigid protein docking using a novel independent SE(3)-equivariant message passing mechanism that guarantees the same resulting protein complex independent of the initial placement of the two 3D structures."
  },
  {
    "title": "Towards a Unified View of Parameter-Efficient Transfer Learning",
    "url": "/forum?id=0RDcd5Axok",
    "date": "28 Sept 2021 (modified: 02 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "parameter-efficient transfer learning, unified view, natural language processing",
    "Abstract": "Fine-tuning large pretrained language models on downstream tasks has become the de-facto learning paradigm in NLP. However, conventional approaches fine-tune all the parameters of the pretrained model, which becomes prohibitive as the model size and the number of tasks grow. Recent work has proposed a variety of parameter-efficient transfer learning methods that only fine-tune a small number of (extra) parameters to attain strong performance. While effective, the critical ingredients for success and the connections among the various methods are poorly understood. In this paper, we break down the design of state-of-the-art parameter-efficient transfer learning methods and present a unified framework that establishes connections between them. Specifically, we re-frame them as modifications to specific hidden states in pretrained models, and define a set of design dimensions along which different methods vary, such as the function to compute the modification and the position to apply the modification. Through comprehensive empirical studies across machine translation, text summarization, language understanding, and text classification benchmarks, we utilize the unified view to identify important design choices in previous methods. Furthermore, our unified framework enables the transfer of design elements across different approaches, and as a result we are able to instantiate new parameter-efficient fine-tuning methods that tune less parameters than previous methods while being more effective, achieving comparable results to fine-tuning all parameters on all four tasks.",
    "One-sentence Summary": "We propose a unified framework for several state-of-the-art parameter-efficient tuning methods,"
  },
  {
    "title": "GNN-LM: Language Modeling based on Global Contexts via GNN",
    "url": "/forum?id=BS49l-B5Bql",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Inspired by the notion that \"it to copy is easier than to memorize\", in this work, we introduce GNN-LM, which extends vanilla neural language model (LM) by allowing to reference similar contexts in the entire training corpus. We build a directed heterogeneous graph between an input context and its semantically related neighbors selected from the training corpus, where nodes are tokens in the input context and retrieved neighbor contexts, and edges represent connections between nodes. Graph neural networks (GNNs) are constructed upon the graph to aggregate information from similar contexts to decode the token. This learning paradigm provides direct access to the reference contexts and helps improve a model's generalization ability. We conduct comprehensive experiments to validate the effectiveness of the GNN-LM: GNN-LM achieves a new state-of-the-art perplexity of 14.8 on WikiText-103 (a 3.9 point improvement over its counterpart of the vanilla  LM model), and shows substantial improvement on One Billion Word and Enwiki8 datasets against strong baselines. In-depth ablation studies are performed to understand the mechanics of GNN-LM. The code can be found at https://github.com/ShannonAI/GNN-LM."
  },
  {
    "title": "Continual Learning with Filter Atom Swapping",
    "url": "/forum?id=metRpM4Zrcb",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "continual learning",
    "Abstract": "Continual learning has been widely studied in recent years to resolve the catastrophic forgetting of deep neural networks. In this paper, we first enforce a low-rank filter subspace by decomposing convolutional filters within each network layer over a small set of filter atoms. Then, we perform continual learning with filter atom swapping. In other words, we learn for each task a new filter subspace for each convolutional layer, i.e., hundreds of parameters as filter atoms, but keep subspace coefficients shared across tasks. By maintaining a small footprint memory of filter atoms, we can easily archive models for past tasks to avoid forgetting. The effectiveness of this simple scheme for continual learning is illustrated both empirically and theoretically. The proposed atom swapping framework further enables flexible and efficient model ensemble with members selected within a task or across tasks to improve the performance in different continual learning settings. Being validated on multiple benchmark datasets with different convolutional network structures, the proposed method outperforms the state-of-the-art methods in both accuracy and scalability."
  },
  {
    "title": "Continual Learning with Recursive Gradient Optimization",
    "url": "/forum?id=7YDLgf9_zgm",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "continual learning, lifelong learning",
    "Abstract": "Learning multiple tasks sequentially without forgetting previous knowledge, called Continual Learning(CL), remains a long-standing challenge for neural networks. Most existing methods rely on additional network capacity or data replay. In contrast, we introduce a novel approach which we refer to as Recursive Gradient Optimization(RGO). RGO is composed of an iteratively updated optimizer that modifies the gradient to minimize forgetting without data replay and a virtual Feature Encoding Layer(FEL) that represents different long-term structures with only task descriptors. Experiments demonstrate that RGO has significantly better performance on popular continual classification benchmarks when compared to the baselines and achieves new state-of-the-art performance on 20-split-CIFAR100(82.22%) and 20-split-miniImageNet(72.63%). With higher average accuracy than Single-Task Learning(STL), this method is flexible and reliable to provide continual learning capabilities for learning models that rely on gradient descent.",
    "One-sentence Summary": "This paper proposes a novel method for continual learning in a fixed capacity network in the non-replay regime, which minimizes the loss on the current task while also minimizing an upper bound of loss increment on previous tasks."
  },
  {
    "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning",
    "url": "/forum?id=g8NJR6fCCl8",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Generalized Additive Model, Deep Learning Architecture, Interpretability",
    "Abstract": "Deployment of machine learning models in real high-risk settings (e.g. healthcare) often depends not only on the model's accuracy but also on its fairness, robustness, and interpretability. Generalized Additive Models (GAMs) are a class of interpretable models with a long history of use in these high-risk domains, but they lack desirable features of deep learning such as differentiability and scalability. In this work, we propose a neural GAM (NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that scale well and perform better than other GAMs on large datasets, while remaining interpretable compared to other ensemble and deep learning models. We demonstrate that our models find interesting patterns in the data. Lastly, we show that we are able to improve model accuracy via self-supervised pre-training, an improvement that is not possible for non-differentiable GAMs.",
    "One-sentence Summary": "We develop a deep-learning version of Generalized Additive Model (GAM) and GA2M that is accurate, scalable and interpretable."
  },
  {
    "title": "Learnability of convolutional neural networks for infinite dimensional input via mixed and anisotropic smoothness",
    "url": "/forum?id=dgxFTxuJ50e",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Among a wide range of success of deep learning, convolutional neural networks have been extensively utilized in several tasks such as speech recognition, image processing, and natural language processing, which require inputs with large dimensions.\n        Several studies have investigated function estimation capability of deep learning, but most of them have assumed that the dimensionality of the input is much smaller than the sample size. \n        However, for typical data in applications such as those handled by the convolutional neural networks described above, \n        the dimensionality of inputs is relatively high or even infinite. \n        In this paper, we investigate the approximation and estimation errors of the (dilated) convolutional neural networks when the input is infinite dimensional. \n        Although the approximation and estimation errors of neural networks are affected by the curse of dimensionality in the existing analyses for typical function spaces such as the \\Holder and Besov spaces, we show that, by considering anisotropic smoothness, they can alleviate exponential dependency on the dimensionality but they only depend on the smoothness of the target functions. \n        Our theoretical analysis supports the great practical success of convolutional networks.  \n        Furthermore, we show that the dilated convolution is advantageous when the smoothness of the target function has a sparse structure."
  },
  {
    "title": "Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100",
    "url": "/forum?id=tD7eCtaSkR",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "provable robustness, adversarial examples",
    "Abstract": "Training convolutional neural networks (CNNs) with a strict Lipschitz constraint under the $l_{2}$ norm is useful for provable adversarial robustness, interpretable gradients and stable training. While $1$-Lipschitz CNNs can be designed by enforcing a $1$-Lipschitz constraint on each layer, training such networks requires each layer to have an orthogonal Jacobian matrix (for all inputs) to prevent the gradients from vanishing during backpropagation. A layer with this property is said to be Gradient Norm Preserving (GNP). In this work, we introduce a procedure to certify the robustness of $1$-Lipschitz CNNs by relaxing the orthogonalization of the last linear layer of the network that significantly advances the state of the art for both standard and provable robust accuracies on CIFAR-100 (gains of $4.80\\%$ and $4.71\\%$, respectively). We further boost their robustness by introducing (i) a novel Gradient Norm preserving activation function called the Householder activation function (that includes every $\\mathrm{GroupSort}$ activation) and (ii) a certificate regularization. On CIFAR-10, we achieve significant improvements over prior works in provable robust accuracy ($5.81\\%$) with only a minor drop in standard accuracy ($-0.29\\%$). Code for reproducing all experiments in the paper is available at \\url{https://github.com/singlasahil14/SOC}.",
    "One-sentence Summary": "Improving provable robustness of 1 Lipschitz CNNs by relaxing orthogonalization of last layer, certificate regularization and a novel activation function."
  },
  {
    "title": "Transition to Linearity of Wide Neural Networks is an Emerging Property of Assembling Weak Models",
    "url": "/forum?id=CyKHoKyvgnp",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Assembling, linearity, Transition to linearity, wide neural networks",
    "Abstract": "Wide neural networks with linear output layer have been shown to be near-linear, and to have near-constant neural tangent kernel (NTK), in a region containing the optimization path of gradient descent. These findings seem counter-intuitive since in general neural networks are highly complex models. Why does a linear structure emerge when the neural networks become wide? \n        In this work, we provide a new perspective on this \"transition to linearity\" by considering a neural network as an assembly model recursively built from a set of sub-models corresponding to individual neurons. In this view, we show that the linearity of wide neural networks is, in fact, an emerging property of assembling a large number of diverse ``weak'' sub-models, none of which dominate the assembly.",
    "One-sentence Summary": "Transition to linearity of wide neural networks is an emerging property of assembling weak models corresponding to individual neurons"
  },
  {
    "title": "Looking Back on Learned Experiences  For Class/task Incremental Learning",
    "url": "/forum?id=RxplU3vmBx",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Deepl Learning, Class Incremental learning, Continual learning, Experiences",
    "Abstract": "Classical deep neural networks are limited in their ability to learn from emerging streams of training data. When trained sequentially on new or evolving tasks, their performance degrades sharply, making them inappropriate in real-world use cases. Existing methods tackle it by either storing old data samples or only updating a parameter set of deep neural networks, which, however, demands a large memory budget or spoils the flexibility of models to learn the incremented task distribution. In this paper, we shed light on an on-call transfer set to provide past experiences whenever a new task arises in the data stream. In particular, we propose a Cost-Free Incremental Learning (CF-IL) not only to replay past experiences the model has learned but also to perform this in a cost free manner. Towards this end, we introduced a memory recovery paradigm in which we query the network to synthesize past exemplars whenever a new task emerges. Thus, our method needs no extra memory for data buffering or network growing, besides calls the proposed memory recovery paradigm to provide past exemplars, named a transfer set in order to mitigate catastrophically forgetting the former tasks in the Incremental Learning (IL) setup. Moreover, in contrast with recently proposed methods, the suggested paradigm does not desire a parallel architecture since it only relies on the learner network. Compared to the state-of-the-art data techniques without buffering past data samples, CF-IL demonstrates significantly better performance on the well-known datasets whether a task oracle is available in test time (Task-IL) or not (Class-IL)."
  },
  {
    "title": "EntQA: Entity Linking as Question Answering",
    "url": "/forum?id=US2rTP5nm_",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Entity linking, open-domain question answering, dense retrieval, reading comprehension, information extraction, natural language processing",
    "Abstract": "A conventional approach to entity linking is to first find mentions in a given document and then infer their underlying entities in the knowledge base. A well-known limitation of this approach is that it requires finding mentions without knowing their entities, which is unnatural and difficult. We present a new model that does not suffer from this limitation called $\\textbf{EntQA}$, which stands for $\\mbox{\\textbf{Ent}ity}$ linking as $\\mbox{\\textbf{Q}uestion}$ $\\mbox{\\textbf{A}nswering}$. EntQA first proposes candidate entities with a fast retrieval module, and then scrutinizes the document to find mentions of each candidate with a powerful reader module. Our approach combines progress in entity linking with that in open-domain question answering and capitalizes on pretrained models for dense entity retrieval and reading comprehension. Unlike in previous works, we do not rely on a mention-candidates dictionary or large-scale weak supervision. EntQA achieves strong results on the GERBIL benchmarking platform.",
    "One-sentence Summary": "We frame entity linking as inverse open-domain question answering and solve the dilemma of having to predict mentions before entities."
  },
  {
    "title": "Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems",
    "url": "/forum?id=2_vhkAMARk",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Minimax, Nonconvex-Nonconcave, Variational inequilities, Saddle point problem, First-order methods, Limit cycles",
    "Abstract": "This paper introduces a new extragradient-type algorithm for a class of nonconvex-nonconcave minimax problems. It is well-known that finding a local solution for general minimax problems is computationally intractable. This observation has recently motivated the study of structures sufficient for convergence of first order methods in the more general setting of variational inequalities when the so-called weak Minty variational inequality (MVI) holds. This problem class captures non-trivial structures as we demonstrate with examples, for which a large family of existing algorithms provably converge to limit cycles. Our results require a less restrictive parameter range in the weak MVI compared to what is previously known, thus extending the applicability of our scheme. The proposed algorithm is applicable to constrained and regularized problems, and involves an adaptive stepsize allowing for potentially larger stepsizes. Our scheme also converges globally even in settings where the underlying operator exhibits limit cycles.",
    "One-sentence Summary": "Under weak MVI we introduce a new extragradient-type algorithm that avoids limit cycles"
  },
  {
    "title": "Compositional Attention: Disentangling Search and Retrieval",
    "url": "/forum?id=IwJPj2MBcIa",
    "date": "28 Sept 2021 (modified: 13 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "compositional attention, flexible search and retrieval, better generalization",
    "Abstract": "Multi-head, key-value attention is the backbone of transformer-like model architectures which have proven to be widely successful in recent years. This attention mechanism uses multiple parallel key-value attention blocks (called heads), each performing two fundamental computations: (1) search - selection of a relevant entity from a set via query-key interaction, and (2) retrieval - extraction of relevant features from the selected entity via a value matrix. Standard attention heads learn a rigid mapping between search and retrieval. In this work, we first highlight how this static nature of the pairing can potentially: (a) lead to learning of redundant parameters in certain tasks, and (b) hinder generalization. To alleviate this problem, we propose a novel attention mechanism,  called Compositional Attention, that replaces the standard head structure. The proposed mechanism  disentangles search and retrieval and composes them in a dynamic, flexible and context-dependent manner. Through a series of numerical experiments, we show that it outperforms standard multi-head attention on a variety of tasks, including some out-of-distribution settings. Through our qualitative analysis, we demonstrate that Compositional Attention leads to dynamic specialization based on the type of retrieval needed. Our proposed mechanism generalizes multi-head attention, allows independent scaling of search and retrieval and is easy to implement in a variety of established network architectures.",
    "One-sentence Summary": "Recombining search and retrieval mechanisms of multi-head attention in a disentangled and flexible manner for better representational capacity and generalization."
  },
  {
    "title": "Contrastive Fine-grained Class Clustering via Generative Adversarial Networks",
    "url": "/forum?id=XWODe7ZLn8f",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Unsupervised Fine-grained Class Clustering, Disentangled Representation Learning, Generative Adversarial Networks",
    "Abstract": "Unsupervised fine-grained class clustering is a practical yet challenging task due to the difficulty of feature representations learning of subtle object details. We introduce C3-GAN, a method that leverages the categorical inference power of InfoGAN with contrastive learning. We aim to learn feature representations that encourage a dataset to form distinct cluster boundaries in the embedding space, while also maximizing the mutual information between the latent code and its image observation. Our approach is to train a discriminator, which is also used for inferring clusters, to optimize the contrastive loss, where image-latent pairs that maximize the mutual information are considered as positive pairs and the rest as negative pairs. Specifically, we map the input of a generator, which was sampled from the categorical distribution, to the embedding space of the discriminator and let them act as a cluster centroid. In this way, C3-GAN succeeded in learning a clustering-friendly embedding space where each cluster is distinctively separable. Experimental results show that C3-GAN achieved the state-of-the-art clustering performance on four fine-grained image datasets, while also alleviating the mode collapse phenomenon. Code is available at https://github.com/naver-ai/c3-gan.",
    "One-sentence Summary": "We proposed a method for unsupervised fine-grained class clustering that leverages the information-theoretic regularization term based on contrastive loss."
  },
  {
    "title": "Learning Multimodal VAEs through Mutual Supervision",
    "url": "/forum?id=1xXvPrAshao",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Multimodal Variational Autoencoder, Variational Autoencoder",
    "Abstract": "Multimodal VAEs seek to model the joint distribution over heterogeneous data (e.g.\\ vision, language), whilst also capturing a shared representation across such modalities. Prior work has typically combined information from the modalities by reconciling idiosyncratic representations directly in the recognition model through explicit products, mixtures, or other such factorisations. Here we introduce a novel alternative, the MEME, that avoids such explicit combinations by repurposing semi-supervised VAEs to combine information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partially-observed data where some modalities can be entirely missing---something that most existing approaches either cannot handle, or do so to a limited extent. We demonstrate that MEME outperforms baselines on standard metrics across both partial and complete observation schemes on the MNIST-SVHN (image--image) and CUB (image--text) datasets. We also contrast the quality of the representations learnt by mutual supervision against standard approaches and observe interesting trends in its ability to capture relatedness between data.",
    "One-sentence Summary": "Here we re-purpose semi-supervised VAEs to leverage mutual supervision between encoding distributions, allowing us to learn multi-modal VAEs with partially obsereved data."
  },
  {
    "title": "When should agents explore?",
    "url": "/forum?id=dEwfxt14bca",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "exploration, mode-switching, reinforcement learning, Atari",
    "Abstract": "Exploration remains a central challenge for reinforcement learning (RL). Virtually all existing methods share the feature of a *monolithic* behaviour policy that changes only gradually (at best). In contrast, the exploratory behaviours of animals and humans exhibit a rich diversity, namely including forms of *switching* between modes. This paper presents an initial study of mode-switching, non-monolithic exploration for RL. We investigate different modes to switch between, at what timescales it makes sense to switch, and what signals make for good switching triggers. We also propose practical algorithmic components that make the switching mechanism adaptive and robust, which enables flexibility without an accompanying hyper-parameter-tuning burden. Finally, we report a promising initial study on Atari, using two-mode exploration and switching at sub-episodic time-scales.",
    "One-sentence Summary": "A fresh look at the question of *when* to switch into exploration mode, and for how long."
  },
  {
    "title": "Revisiting Design Choices in Offline Model Based Reinforcement Learning",
    "url": "/forum?id=zz9hXVhf40",
    "date": "28 Sept 2021 (modified: 18 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Model-Based Reinforcement Learning, Offline Reinforcement Learning, Uncertainty Quantification",
    "Abstract": "Offline reinforcement learning enables agents to leverage large pre-collected datasets of environment transitions to learn control policies, circumventing the need for potentially expensive or unsafe online data collection. Significant progress has been made recently in offline model-based reinforcement learning, approaches which leverage a learned dynamics model. This typically involves constructing a probabilistic model, and using the model uncertainty to penalize rewards where there is insufficient data, solving for a pessimistic MDP that lower bounds the true MDP. Existing methods, however, exhibit a breakdown between theory and practice, whereby pessimistic return ought to be bounded by the total variation distance of the model from the true dynamics, but is instead implemented through a penalty based on estimated model uncertainty. This has spawned a variety of uncertainty heuristics, with little to no comparison between differing approaches. In this paper, we compare these heuristics, and design novel protocols to investigate their interaction with other hyperparameters, such as the number of models, or imaginary rollout horizon. Using these insights, we show that selecting these key hyperparameters using Bayesian Optimization produces superior configurations that are vastly different to those currently used in existing hand-tuned state-of-the-art methods, and result in drastically stronger performance."
  },
  {
    "title": "NASPY: Automated Extraction of Automated Machine Learning Models",
    "url": "/forum?id=KhLK0sHMgXK",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "We present NASPY, an end-to-end adversarial framework to extract the networkarchitecture of deep learning models from Neural Architecture Search (NAS). Existing works about model extraction attacks mainly focus on conventional DNN models with very simple operations, or require heavy manual analysis with lots of domain knowledge.  In contrast, NASPY introduces seq2seq models to automatically identify novel and complicated operations (e.g., separable convolution,dilated convolution) from hardware side-channel sequences. We design two models (RNN-CTC and transformer), which can achieve only 3.2% and 11.3% error rates for operation prediction.  We further present methods to recover the model hyper-parameters and topology from the operation sequence .  With these techniques, NASPY is able to extract the complete NAS model architecture with high fidelity and automation, which are rarely analyzed before.",
    "One-sentence Summary": "We present NASPY, an end-to-end adversarial framework to extract the networkarchitecture of deep learning models from Neural Architecture Search (NAS)."
  },
  {
    "title": "COptiDICE: Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimation",
    "url": "/forum?id=FLA55mBee6Q",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Offline Reinforcement Learning, Offline Constrained Reinforcement Learning, Stationary Distribution Correction Estimation",
    "Abstract": "We consider the offline constrained reinforcement learning (RL) problem, in which the agent aims to compute a policy that maximizes expected return while satisfying given cost constraints, learning only from a pre-collected dataset. This problem setting is appealing in many real-world scenarios, where direct interaction with the environment is costly or risky, and where the resulting policy should comply with safety constraints. However, it is challenging to compute a policy that guarantees satisfying the cost constraints in the offline RL setting, since the off-policy evaluation inherently has an estimation error. In this paper, we present an offline constrained RL algorithm that optimizes the policy in the space of the stationary distribution. Our algorithm, COptiDICE, directly estimates the stationary distribution corrections of the optimal policy with respect to returns, while constraining the cost upper bound, with the goal of yielding a cost-conservative policy for actual constraint satisfaction. Experimental results show that COptiDICE attains better policies in terms of constraint satisfaction and return-maximization, outperforming baseline algorithms.",
    "One-sentence Summary": "We present an offline constrained RL algorithm, which estimates the stationary distribution corrections of the optimal policy with respect to returns, while constraining the cost upper bound."
  },
  {
    "title": "Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers",
    "url": "/forum?id=nhnJ3oo6AB",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement Learning, Robotics, Locomotion Control, Multi-Modal Transformer",
    "Abstract": "We propose to address quadrupedal locomotion tasks using Reinforcement Learning (RL) with a Transformer-based model that learns to combine proprioceptive information and high-dimensional depth sensor inputs. While learning-based locomotion has made great advances using RL, most methods still rely on domain randomization for training blind agents that generalize to challenging terrains. Our key insight is that proprioceptive states only offer contact measurements for immediate reaction, whereas an agent equipped with visual sensory observations can learn to proactively maneuver environments with obstacles and uneven terrain by anticipating changes in the environment many steps ahead. In this paper, we introduce LocoTransformer, an end-to-end RL method that leverages both proprioceptive states and visual observations for locomotion control. We evaluate our method in challenging simulated environments with different obstacles and uneven terrain. We transfer our learned policy from simulation to a real robot by running it indoor and in-the-wild with unseen obstacles and terrain. Our method not only significantly improves over baselines, but also achieves far better generalization performance, especially when transferred to the real robot. Our project page with videos is at https://rchalyang.github.io/LocoTransformer/.",
    "One-sentence Summary": "We introduce a novel end-to-end Reinforcement Learning approach called LocoTransformer, leveraging both visual inputs and proprioceptive states, for locomotion control in both simulation and with real robots."
  },
  {
    "title": "ViTGAN: Training GANs with Vision Transformers",
    "url": "/forum?id=dwg5rXg1WS_",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Recently, Vision Transformers (ViTs) have shown competitive performance on image recognition while requiring less vision-specific inductive biases. In this paper, we investigate if such performance can be extended to image generation. To this end, we integrate the ViT architecture into generative adversarial networks (GANs). For ViT discriminators, we observe that existing regularization methods for GANs interact poorly with self-attention, causing serious instability during training. To resolve this issue, we introduce several novel regularization techniques for training GANs with ViTs. For ViT generators, we examine architectural choices for latent and pixel mapping layers to faciliate convergence. Empirically, our approach, named ViTGAN, achieves comparable performance to the leading CNN- based GAN models on three datasets: CIFAR-10, CelebA, and LSUN bedroom."
  },
  {
    "title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees",
    "url": "/forum?id=AJsI-ymaKn_",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Imitation Learning, Interpretable ML, Clinical Decision Support, Sequential Decision-Making",
    "Abstract": "Building models of human decision-making from observed behaviour is critical to better understand, diagnose and support real-world policies such as clinical care. As established policy learning approaches remain focused on imitation performance, they fall short of explaining the demonstrated decision-making process. Policy Extraction through decision Trees (POETREE) is a novel framework for interpretable policy learning, compatible with fully-offline and partially-observable clinical decision environments -- and builds probabilistic tree policies determining physician actions based on patients' observations and medical history. Fully-differentiable tree architectures are grown incrementally during optimization to adapt their complexity to the modelling task, and learn a representation of patient history through recurrence, resulting in decision tree policies that adapt over time with patient information. This policy learning method outperforms the state-of-the-art on real and synthetic medical datasets, both in terms of understanding, quantifying and evaluating observed behaviour as well as in accurately replicating it -- with potential to improve future decision support systems.",
    "One-sentence Summary": "Policy Extraction through decision Trees (POETREE) is a novel framework for interpretable policy learning, compatible with fully-offline and partially-observable clinical decision environments."
  },
  {
    "title": "TRGP: Trust Region Gradient Projection for Continual Learning",
    "url": "/forum?id=iEvAf8i6JjO",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "trust region, gradient projection, scaled weight projection, continual learning, forward knowledge transfer, task correlation",
    "Abstract": "Catastrophic forgetting is one of the major challenges in continual learning. To address this issue, some existing methods put restrictive constraints on the optimization space of the new task for minimizing the interference to old tasks. However, this may lead to unsatisfactory performance for the new task, especially when the new task is strongly correlated with old tasks. To tackle this challenge, we propose Trust Region Gradient Projection (TRGP) for continual learning to facilitate the forward knowledge transfer based on an efficient characterization of task correlation. Particularly, we introduce a notion of 'trust region' to select the most related old tasks for the new task in a layer-wise and single-shot manner, using the norm of gradient projection onto the subspace spanned by task inputs. Then, a scaled weight projection is proposed to cleverly reuse the frozen weights of the selected old tasks in the trust region through a layer-wise scaling matrix. By jointly optimizing the scaling matrices and the model, where the model is updated along the directions orthogonal to the subspaces of old tasks,  TRGP can effectively prompt knowledge transfer without forgetting. Extensive experiments show that our approach achieves significant improvement over related state-of-the-art methods.",
    "One-sentence Summary": "We propose a novel continual learning approach to facilitate the forward knowledge transfer, based on an efficient characterization of task correlation using a novel notion of 'trust region'."
  },
  {
    "title": "Properties from mechanisms: an equivariance perspective on identifiable representation learning",
    "url": "/forum?id=g5ynW-jMq4M",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "representation learning, equivariance, independent component analysis, ICA, autoencoders",
    "Abstract": "A key goal of unsupervised representation learning is ``inverting'' a data generating process to recover its latent properties.  Existing work that provably achieves this goal relies on strong assumptions on relationships between the latent variables (e.g., independence conditional on auxiliary information). In this paper, we take a very different perspective on the problem and ask,  ``Can we instead identify latent properties by leveraging knowledge of the mechanisms that govern their evolution?'' We provide a complete characterization of the sources of non-identifiability as we vary knowledge about a set of possible mechanisms. In particular, we prove that if we know the exact mechanisms under which the latent properties evolve, then identification can be achieved up to any equivariances that are shared by the underlying mechanisms. We generalize this characterization to settings where we only know some hypothesis class over possible mechanisms, as well as settings where the mechanisms are stochastic. We demonstrate the power of this mechanism-based perspective by showing that we can leverage our results to generalize existing identifiable representation learning results. These results suggest that by exploiting inductive biases on mechanisms, it is possible to design a range of new identifiable representation learning approaches.",
    "One-sentence Summary": "Representation learning is identifiable up to any equivariances of the (known) mechanisms that govern an environment's evolution."
  },
  {
    "title": "Revisiting Over-smoothing in BERT from the Perspective of Graph",
    "url": "/forum?id=dUV91uaXm3",
    "date": "28 Sept 2021 (modified: 17 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "BERT, Over-smoothing, Transformer",
    "Abstract": "Recently over-smoothing phenomenon of Transformer-based models is observed in both vision and language fields. However, no existing work has delved deeper to further investigate the main cause of this phenomenon. In this work, we make the attempt to analyze the over-smoothing problem from the perspective of graph, where such problem was first discovered and explored. Intuitively, the self-attention matrix can be seen as a normalized adjacent matrix of a corresponding graph. Based on the above connection, we provide some theoretical analysis and find that layer normalization plays a key role in the over-smoothing issue of Transformer-based models. Specifically, if the standard deviation of layer normalization is sufficiently large, the output of Transformer stacks will converge to a specific low-rank subspace and result in over-smoothing. To alleviate the over-smoothing problem, we consider hierarchical fusion strategies, which combine the representations from different layers adaptively to make the output more diverse. Extensive experiment results on various data sets illustrate the effect of our fusion method.",
    "One-sentence Summary": "We theoretically analyze the over-smoothing phenomenon of transformer-based models (e.g., BERT) and propose a novel hierarchical fusion strategy to alleviate it."
  },
  {
    "title": "Training invariances and the low-rank phenomenon: beyond linear networks",
    "url": "/forum?id=XEW8CQgArno",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "deep learning, nonsmooth analysis, Clarke subdifferential, implicit regularization, low rank bias, alignment, training invariance",
    "Abstract": "The implicit bias induced by the training of neural networks has become a topic of rigorous study. In the limit of gradient flow and gradient descent with appropriate step size, it has been shown that when one trains a deep linear network with logistic or exponential loss on linearly separable data, the weights converge to rank-$1$ matrices. In this paper, we extend this theoretical result to the last few linear layers of the much wider class of nonlinear ReLU-activated feedforward networks containing fully-connected layers and skip connections.  Similar to the linear case, the proof relies on specific local training invariances, sometimes referred to as alignment, which we show to hold for submatrices where neurons are stably-activated in all training examples, and it reflects empirical results in the literature. We also show this is not true in general for the full matrix of ReLU fully-connected layers. Our proof relies on a specific decomposition of the network into a multilinear function and another ReLU network whose weights are constant under a certain parameter directional convergence.",
    "One-sentence Summary": "We extend theoretical results regarding the low-rank bias of deep linear neural networks trained with gradient-based algorithm to non-linear architectures, reflecting empirical results in the literature."
  },
  {
    "title": "Learning Long-Term Reward Redistribution via Randomized Return Decomposition",
    "url": "/forum?id=lpkGn3k2YdD",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement Learning, Long-Term Credit Assignment, Reward Redistribution, Return Decomposition",
    "Abstract": "Many practical applications of reinforcement learning require agents to learn from sparse and delayed rewards. It challenges the ability of agents to attribute their actions to future outcomes. In this paper, we consider the problem formulation of episodic reinforcement learning with trajectory feedback. It refers to an extreme delay of reward signals, in which the agent can only obtain one reward signal at the end of each trajectory. A popular paradigm for this problem setting is learning with a designed auxiliary dense reward function, namely proxy reward, instead of sparse environmental signals. Based on this framework, this paper proposes a novel reward redistribution algorithm, randomized return decomposition (RRD), to learn a proxy reward function for episodic reinforcement learning. We establish a surrogate problem by Monte-Carlo sampling that scales up least-squares-based reward redistribution to long-horizon problems. We analyze our surrogate loss function by connection with existing methods in the literature, which illustrates the algorithmic properties of our approach. In experiments, we extensively evaluate our proposed method on a variety of benchmark tasks with episodic rewards and demonstrate substantial improvement over baseline algorithms.",
    "One-sentence Summary": "We propose randomized return decomposition, a novel reward redistribution algorithm, which establishes a surrogate optimization problem to scale up learning in long-horizon tasks."
  },
  {
    "title": "What Happens after SGD Reaches Zero Loss? --A Mathematical Framework",
    "url": "/forum?id=siCt4xZn5Ve",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "SGD, implicit bias, generalization, deep learning, implicit regularization, manifold",
    "Abstract": "Understanding the implicit bias of Stochastic Gradient Descent (SGD) is one of the key challenges in deep learning, especially for overparametrized models, where the local minimizers of the loss function $L$ can form a manifold. Intuitively, with a sufficiently small learning rate $\\eta$, SGD tracks Gradient Descent (GD) until it gets close to such manifold, where the gradient noise prevents further convergence. In such regime, Blanc et al. (2020) proved that SGD with label noise locally decreases a regularizer-like term, the sharpness of loss, $\\text{tr}[\\nabla^2 L]$. The current paper gives a general framework for such analysis by adapting ideas from Katzenberger (1991). It allows in principle a complete characterization for the regularization effect of SGD around such manifold---i.e., the \"implicit bias\"---using a stochastic differential equation (SDE) describing the limiting dynamics of the parameters, which is determined jointly by the loss function and the noise covariance. This yields some new results: (1) a *global* analysis of the implicit bias valid for $\\eta^{-2}$ steps, in contrast to the local analysis of Blanc et al. (2020) that is only valid for $\\eta^{-1.6}$ steps and (2) allowing *arbitrary* noise covariance. As an application, we show with arbitrary large initialization, label noise SGD can always escape the kernel regime and only requires $O(\\kappa\\ln d)$ samples for learning an $\\kappa$-sparse overparametrized linear model in $\\mathbb{R}^d$ (Woodworth et al., 2020), while GD initialized in the kernel regime requires $\\Omega(d)$ samples. This upper bound is minimax optimal and improves the previous $\\widetilde{O}(\\kappa^2)$ upper bound (HaoChen et al., 2020).",
    "One-sentence Summary": "We propose a mathematical framework to study the implicit bias of SGD after reaching zero loss, based on which we prove label noise can help SGD escape the kernel regime and achieve optimal sample complexity for overparametrized linear model."
  },
  {
    "title": "Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series",
    "url": "/forum?id=45L_dgP48Vd",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Anomaly Detection, Normalizing Flow, DAG, Multiple Time Series",
    "Abstract": "Anomaly detection is a widely studied task for a broad variety of data types; among them, multiple time series appear frequently in applications, including for example, power grids and traffic networks. Detecting anomalies for multiple time series, however, is a challenging subject, owing to the intricate interdependencies among the constituent series. We hypothesize that anomalies occur in low density regions of a distribution and explore the use of normalizing flows for unsupervised anomaly detection, because of their superior quality in density estimation. Moreover, we propose a novel flow model by imposing a Bayesian network among constituent series. A Bayesian network is a directed acyclic graph (DAG) that models causal relationships; it factorizes the joint probability of the series into the product of easy-to-evaluate conditional probabilities. We call such a graph-augmented normalizing flow approach GANF and propose joint estimation of the DAG with flow parameters. We conduct extensive experiments on real-world datasets and demonstrate the effectiveness of GANF for density estimation, anomaly detection, and identification of time series distribution drift."
  },
  {
    "title": "Autoregressive Quantile Flows for Predictive Uncertainty Estimation",
    "url": "/forum?id=z1-I6rOKv1S",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Numerous applications of machine learning involve representing probability distributions over high-dimensional data. We propose autoregressive quantile flows, a flexible class of normalizing flow models trained using a novel objective based on proper scoring rules. Our objective does not require calculating computationally expensive determinants of Jacobians during training and supports new types of neural architectures, such as neural autoregressive flows from which it is easy to sample. \n            We leverage these models in quantile flow regression, an approach that parameterizes predictive conditional distributions with flows, resulting in improved probabilistic predictions on tasks such as time series forecasting and object detection.\n            Our novel objective functions and neural flow parameterizations also yield improvements on popular generation and density estimation tasks, and represent a step beyond maximum likelihood learning of flows.",
    "One-sentence Summary": "Using Quantile Flows for Predictive and Generative Data Modeling and Generation"
  },
  {
    "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification",
    "url": "/forum?id=DNRADop4ksB",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Few-shot Classification, Firth Regularization, MLE Bias",
    "Abstract": "Learning accurate classifiers for novel categories from very few examples, known as few-shot image classification, is a challenging task in statistical machine learning and computer vision. The performance in few-shot classification suffers from the bias in the estimation of classifier parameters; however, an effective underlying bias reduction technique that could alleviate this issue in training few-shot classifiers has been overlooked. In this work, we demonstrate the effectiveness of Firth bias reduction in few-shot classification. Theoretically, Firth bias reduction removes the $O(N^{-1})$ first order term from the small-sample bias of the Maximum Likelihood Estimator. Here we show that the general Firth bias reduction technique simplifies to encouraging uniform class assignment probabilities for multinomial logistic classification, and almost has the same effect in cosine classifiers. We derive an easy-to-implement optimization objective for Firth penalized multinomial logistic and cosine classifiers, which is equivalent to penalizing the cross-entropy loss with a KL-divergence between the predictions and the uniform label distribution. Then, we empirically evaluate that it is consistently effective across the board for few-shot image classification, regardless of (1) the feature representations from different backbones, (2) the number of samples per class, and (3) the number of classes. Furthermore, we demonstrate the effectiveness of Firth bias reduction on cross-domain and imbalanced data settings. Our implementation is available at https://github.com/ehsansaleh/firth_bias_reduction."
  },
  {
    "title": "Finite-Time Convergence and Sample Complexity of Multi-Agent Actor-Critic Reinforcement Learning with Average Reward",
    "url": "/forum?id=04pGUg0-pdZ",
    "date": "28 Sept 2021 (modified: 08 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "In this paper, we establish the first finite-time convergence result of the actor-critic algorithm for fully decentralized multi-agent reinforcement learning (MARL) problems with average reward. \n        In this problem, a set of $N$ agents work cooperatively to maximize the global average reward through interacting with their neighbors over a communication network.\n        We consider a practical MARL setting, where the rewards and actions of each agent are only known to itself, and the knowledge of joint actions of the agents is not assumed. \n        Toward this end, we propose a mini-batch Markovian sampled fully decentralized actor-critic algorithm and analyze its finite-time convergence and sample complexity.\n        We show that the sample complexity of this algorithm is $\\mathcal{O}(N^{2}/\\epsilon^{2}\\log(N/\\epsilon))$.\n        Interestingly, this sample complexity bound matches that of the state-of-the-art single-agent actor-critic algorithms for reinforcement learning."
  },
  {
    "title": "Towards Understanding the Data Dependency of Mixup-style Training",
    "url": "/forum?id=ieNJYujcGDO",
    "date": "28 Sept 2021 (modified: 19 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "mixup, deep learning, semi-supervised learning, empirical risk minimization, generalization, margin, counterexample",
    "Abstract": "In the Mixup training paradigm, a model is trained using convex combinations of data points and their associated labels. Despite seeing very few true data points during training, models trained using Mixup seem to still minimize the original empirical risk and exhibit better generalization and robustness on various tasks when compared to standard training. In this paper, we investigate how these benefits of Mixup training rely on properties of the data in the context of classification. For minimizing the original empirical risk, we compute a closed form for the Mixup-optimal classification, which allows us to construct a simple dataset on which minimizing the Mixup loss leads to learning a classifier that does not minimize the empirical loss on the data. On the other hand, we also give sufficient conditions for Mixup training to also minimize the original empirical risk. For generalization, we characterize the margin of a Mixup classifier, and use this to understand why the decision boundary of a Mixup classifier can adapt better to the full structure of the training data when compared to standard training. In contrast, we also show that, for a large class of linear models and linearly separable datasets, Mixup training leads to learning the same classifier as standard training.",
    "One-sentence Summary": "A theoretical analysis of data conditions under which mixup can perform worse, better, and identically when compared to empirical risk minimization."
  },
  {
    "title": "Self-Supervision Enhanced Feature Selection with Correlated Gates",
    "url": "/forum?id=oDFvtxzPOx",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Feature Selection, Feature Importance, Self-Supervised Learning",
    "Abstract": "Discovering relevant input features for predicting a target variable is a key scientific question. However, in many domains, such as medicine and biology, feature selection is confounded by a scarcity of labeled samples coupled with significant correlations among features. In this paper, we propose a novel deep learning approach to feature selection that addresses both challenges simultaneously. First, we pre-train the network using unlabeled samples within a self-supervised learning framework by solving pretext tasks that require the network to learn informative representations from partial feature sets. Then, we fine-tune the pre-trained network to discover relevant features using labeled samples. During both training phases, we explicitly account for the correlation structure of the input features by generating correlated gate vectors from a multivariate Bernoulli distribution. Experiments on multiple real-world datasets including clinical and omics demonstrate that our model discovers relevant features that provide superior prediction performance compared to the state-of-the-art benchmarks in practical scenarios where there is often limited labeled data and high correlations among features.",
    "One-sentence Summary": "We propose a novel DL-based feature selection method using self-supervised learning and multivariate Bernoulli distribution to address common challenges in feature selection: a scarcity of labeled samples and significant correlations among features."
  },
  {
    "title": "Score-Based Generative Modeling with Critically-Damped Langevin Diffusion",
    "url": "/forum?id=CzceR82CYc",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Score-based generative modeling, denoising diffusion models, image synthesis",
    "Abstract": "Score-based generative models (SGMs) have demonstrated remarkable synthesis quality. SGMs rely on a diffusion process that gradually perturbs the data towards a tractable distribution, while the generative model learns to denoise. The complexity of this denoising task is, apart from the data distribution itself, uniquely determined by the diffusion process. We argue that current SGMs employ overly simplistic diffusions, leading to unnecessarily complex denoising processes, which limit generative modeling performance. Based on connections to statistical mechanics, we propose a novel critically-damped Langevin diffusion (CLD) and show that CLD-based SGMs achieve superior performance. CLD can be interpreted as running a joint diffusion in an extended space, where the auxiliary variables can be considered \"velocities\" that are coupled to the data variables as in Hamiltonian dynamics. We derive a novel score matching objective for CLD and show that the model only needs to learn the score function of the conditional distribution of the velocity given data, an easier task than learning scores of the data directly. We also derive a new sampling scheme for efficient synthesis from CLD-based diffusion models. We find that CLD outperforms previous SGMs in synthesis quality for similar network architectures and sampling compute budgets. We show that our novel sampler for CLD significantly outperforms solvers such as Euler\u2013Maruyama. Our framework provides new insights into score-based denoising diffusion models and can be readily used for high-resolution image synthesis. Project page and code: https://nv-tlabs.github.io/CLD-SGM.",
    "One-sentence Summary": "In this work, we propose a novel diffusion process ideally suited for score-based generative models and provide new insights into score-based denoising diffusion models."
  },
  {
    "title": "Controlling Directions Orthogonal to a Classifier",
    "url": "/forum?id=DIjCrlsu6Z",
    "date": "28 Sept 2021 (modified: 29 Jan 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "orthogonal classifier, invariance",
    "Abstract": "We propose to identify directions invariant to a given classifier so that these directions can be controlled in tasks such as style transfer. While orthogonal decomposition is directly identifiable when the given classifier is linear, we formally define a notion of orthogonality in the non-linear case. We also provide a surprisingly simple method for constructing the orthogonal classifier (a classifier utilizing directions other than those of the given classifier). Empirically, we present three use cases where controlling orthogonal variation is important: style transfer, domain adaptation, and fairness. The orthogonal classifier enables desired style transfer when domains vary in multiple aspects, improves domain adaptation with label shifts and mitigates the unfairness as a predictor. The code is available at https://github.com/Newbeeer/orthogonal_classifier",
    "One-sentence Summary": "We develop a notion of orthogonality in classifier, and the corresponding construction and utility."
  },
  {
    "title": "R5: Rule Discovery with Reinforced and Recurrent Relational Reasoning",
    "url": "/forum?id=2eXhNpHeW6E",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "systematicity, graph reasoning",
    "Abstract": "Systematicity, i.e., the ability to recombine known parts and rules to form new sequences while reasoning over relational data, is critical to machine intelligence. A model with strong systematicity is able to train on small-scale tasks and generalize to large-scale tasks. In this paper, we propose R5, a relational reasoning framework based on reinforcement learning that reasons over relational graph data and explicitly mines underlying compositional logical rules from observations. R5 has strong systematicity and being robust to noisy data. It consists of a policy value network equipped with Monte Carlo Tree Search to perform recurrent relational prediction and a backtrack rewriting mechanism for rule mining. By alternately applying the two components, R5 progressively learns a set of explicit rules from data and performs explainable and generalizable relation prediction. We conduct extensive evaluations on multiple datasets. Experimental results show that R5 outperforms various embedding-based and rule induction baselines on relation prediction tasks while achieving a high recall rate in discovering ground truth rules."
  },
  {
    "title": "Representation Learning for Online and Offline RL in Low-rank MDPs",
    "url": "/forum?id=J4iSIR9fhY0",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Provably sample efficient Reinforcement Learning, PAC bounds, Representation learning, Low-rank MDP",
    "Abstract": "This work studies the question of Representation Learning in RL: how can we learn a compact low-dimensional representation such that on top of the representation we can perform RL procedures such as exploration and exploitation, in a sample efficient manner. We focus on the low-rank Markov Decision Processes (MDPs) where the transition dynamics correspond to a low-rank transition matrix. Unlike prior works that assume the representation is known (e.g., linear MDPs), here we need to learn the representation for the low-rank MDP. We study both the online RL and offline RL settings. For the online setting, operating with the same computational oracles used in FLAMBE (Agarwal et.al), the state-of-art algorithm for learning representations in low-rank MDPs, we propose an algorithm REP-UCB Upper Confidence Bound driven Representation learning for RL), which significantly improves the sample complexity from $\\widetilde{O}( A^9 d^7 / (\\epsilon^{10} (1-\\gamma)^{22}))$ for FLAMBE to $\\widetilde{O}( A^4 d^4 / (\\epsilon^2 (1-\\gamma)^{2})  )$ with $d$ being the rank of the transition matrix (or dimension of the ground truth representation), $A$ being the number of actions, and $\\gamma$ being the discounted factor. Notably, REP-UCB is simpler than FLAMBE, as it directly balances the interplay between representation learning, exploration, and exploitation, while FLAMBE is an explore-then-commit style approach and has to perform reward-free exploration step-by-step forward in time. For the offline RL setting, we develop an algorithm that leverages pessimism to learn under a partial coverage condition: our algorithm is able to compete against any policy as long as it is covered by the offline distribution.",
    "One-sentence Summary": "We study representation learning in low-rank MDP in both online setting and offline setting, and propose statistically and computationally efficient algorithms."
  },
  {
    "title": "Lossless Compression with Probabilistic Circuits",
    "url": "/forum?id=X_hByk2-5je",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Despite extensive progress on image generation, common deep generative model architectures are not easily applied to lossless compression. For example, VAEs suffer from a compression cost overhead due to their latent variables. This overhead can only be partially eliminated with elaborate schemes such as bits-back coding, often resulting in poor single-sample compression rates. To overcome such problems, we establish a new class of tractable lossless compression models that permit efficient encoding and decoding: Probabilistic Circuits (PCs). These are a class of neural networks involving $|p|$ computational units that support efficient marginalization over arbitrary subsets of the $D$ feature dimensions, enabling efficient arithmetic coding. We derive efficient encoding and decoding schemes that both have time complexity $\\mathcal{O} (\\log(D) \\cdot |p|)$, where a naive scheme would have linear costs in $D$ and $|p|$, making the approach highly scalable. Empirically, our PC-based (de)compression algorithm runs 5-40 times faster than neural compression algorithms that achieve similar bitrates. By scaling up the traditional PC structure learning pipeline, we achieve state-of-the-art results on image datasets such as MNIST. Furthermore, PCs can be naturally integrated with existing neural compression algorithms to improve the performance of these base models on natural image datasets. Our results highlight the potential impact that non-standard learning architectures may have on neural data compression."
  },
  {
    "title": "Understanding Domain Randomization for Sim-to-real Transfer",
    "url": "/forum?id=T8vZHIRTrY",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "domain randomization, sim-to-real transfer, learning theory",
    "Abstract": "Reinforcement learning encounters many challenges when applied directly in the real world. Sim-to-real transfer is widely used to transfer the knowledge learned from simulation to the real world. Domain randomization---one of the most popular algorithms for sim-to-real transfer---has been demonstrated to be effective in various tasks in robotics and  autonomous driving. Despite its empirical successes, theoretical understanding on why this simple algorithm works is largely missing. In this paper, we propose a  theoretical framework for sim-to-real transfers, in which the simulator is modeled as a set of MDPs with tunable parameters (corresponding to unknown physical parameters such as friction).  We provide sharp bounds on the sim-to-real gap---the difference between the value of policy returned by domain randomization and the value of an optimal policy for the real world. We prove that sim-to-real transfer can succeed under mild conditions without any real-world training samples. Our theory also highlights the importance of using memory (i.e., history-dependent policies) in domain randomization. Our proof is based on novel techniques that reduce the problem of bounding the sim-to-real gap to the problem of designing efficient learning algorithms for infinite-horizon MDPs, which we believe are of independent interest.",
    "One-sentence Summary": "We propose theoretical frameworks for sim-to-real transfer and domain randomization, and provide bounds on the sub-optimality gap of the policy returned by domain randomization."
  },
  {
    "title": "$\\mathrm{SO}(2)$-Equivariant Reinforcement Learning",
    "url": "/forum?id=7F9cOhdvfk_",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement Learning, Equivariance, Robotic Manipulation",
    "Abstract": "Equivariant neural networks enforce symmetry within the structure of their convolutional layers, resulting in a substantial improvement in sample efficiency when learning an equivariant or invariant function. Such models are applicable to robotic manipulation learning which can often be formulated as a rotationally symmetric problem. This paper studies equivariant model architectures in the context of $Q$-learning and actor-critic reinforcement learning. We identify equivariant and invariant characteristics of the optimal $Q$-function and the optimal policy and propose equivariant DQN and SAC algorithms that leverage this structure. We present experiments that demonstrate that our equivariant versions of DQN and SAC can be significantly more sample efficient than competing algorithms on an important class of robotic manipulation problems.",
    "One-sentence Summary": "This paper proposes equivariant DQN and equivariant SAC that significantly improve the sample efficiency of RL in robotic manipulation."
  },
  {
    "title": "Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption",
    "url": "/forum?id=CuV_qYkmKb3",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "self-supervised learning, tabular data, pre-training, contrastive learning, openML",
    "Abstract": "Self-supervised contrastive representation learning has proved incredibly successful in the vision and natural language domains, enabling state-of-the-art performance with orders of magnitude less labeled data. However, such methods are domain-specific and little has been done to leverage this technique on real-world \\emph{tabular} datasets. We propose \\textsc{Scarf}, a simple, widely-applicable technique for contrastive learning, where views are formed by corrupting a random subset of features. When applied to pre-train deep neural networks on the 69 real-world, tabular classification datasets from the OpenML-CC18 benchmark, \\textsc{Scarf} not only improves classification accuracy in the fully-supervised setting but does so also in the presence of label noise and in the semi-supervised setting where only a fraction of the available training data is labeled. We show that \\textsc{Scarf} complements existing strategies and outperforms alternatives like autoencoders. We conduct comprehensive ablations, detailing the importance of a range of factors.",
    "One-sentence Summary": "Scarf is a self-supervised, contrastive pre-training method for neural networks applied to tabular classification tasks that boosts performance, even when labeled data is limited or noisy."
  },
  {
    "title": "Responsible Disclosure of Generative Models Using Scalable Fingerprinting",
    "url": "/forum?id=sOK-zS6WHB",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Generative models, fingerprinting, responsible disclosure, deep fake detection and attribution",
    "Abstract": "Over the past years, deep generative models have achieved a new level of performance. Generated data has become difficult, if not impossible, to be distinguished from real data. While there are plenty of use cases that benefit from this technology, there are also strong concerns on how this new technology can be misused to generate deep fakes and enable misinformation at scale. Unfortunately, current deep fake detection methods are not sustainable, as the gap between real and fake continues to close. In contrast, our work enables a responsible disclosure of such state-of-the-art generative models, that allows model inventors to fingerprint their models, so that the generated samples containing a fingerprint can be accurately detected and attributed to a source. Our technique achieves this by an efficient and scalable ad-hoc generation of a large population of models with distinct fingerprints. Our recommended operation point uses a 128-bit fingerprint which in principle results in more than 10^{38} identifiable models. Experiments show that our method fulfills key properties of a fingerprinting mechanism and achieves effectiveness in deep fake detection and attribution. Code and models are available at https://github.com/ningyu1991/ScalableGANFingerprints.",
    "One-sentence Summary": "Our work enables a responsible disclosure of generative models, that allows model inventors to fingerprint their models, so that the generated samples containing a fingerprint can be accurately detected and attributed to a source."
  },
  {
    "title": "Path Auxiliary Proposal for MCMC in Discrete Space",
    "url": "/forum?id=JSR-YDImK95",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Energy-based Model (EBM) offers a powerful approach for modeling discrete structure, but both inference and learning of EBM are hard as it involves sampling from discrete distributions. Recent work shows Markov Chain Monte Carlo (MCMC) with the informed proposal is a powerful tool for such sampling. However, an informed proposal only allows local updates as it requires evaluating all energy changes in the neighborhood.\n        In this work, we present a path auxiliary algorithm that uses a composition of local moves to efficiently explore large neighborhoods. We also give a fast version of our algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. Empirically, we show that our path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning. Our method can also be used to train deep EBMs for high-dimensional discrete data."
  },
  {
    "title": "Possibility Before Utility: Learning And Using Hierarchical Affordances",
    "url": "/forum?id=7b4zxUnrO2N",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "RL, HRL, reinforcement learning, hierarchical reinforcement learning, affordances, hierarchical affordances",
    "Abstract": "Reinforcement learning algorithms struggle on tasks with complex hierarchical dependency structures. Humans and other intelligent agents do not waste time assessing the utility of every high-level action in existence, but instead only consider ones they deem possible in the first place. By focusing only on what is feasible, or \"afforded'', at the present moment, an agent can spend more time both evaluating the utility of and acting on what matters. To this end, we present Hierarchical Affordance Learning (HAL), a method that learns a model of hierarchical affordances in order to prune impossible subtasks for more effective learning. Existing works in hierarchical reinforcement learning provide agents with structural representations of subtasks but are not affordance-aware, and by grounding our definition of hierarchical affordances in the present state, our approach is more flexible than the multitude of approaches that ground their subtask dependencies in a symbolic history. While these logic-based methods often require complete knowledge of the subtask hierarchy, our approach is able to utilize incomplete and varying symbolic specifications. Furthermore, we demonstrate that relative to non-affordance-aware methods, HAL agents are better able to efficiently learn complex tasks, navigate environment stochasticity, and acquire diverse skills in the absence of extrinsic supervision---all of which are hallmarks of human learning.",
    "One-sentence Summary": "We introduce a method that achieves superior performance in complex hierarchical tasks by utilizing a notion of subtask dependency grounded in the present state."
  },
  {
    "title": "Interpretable Unsupervised Diversity Denoising and Artefact Removal",
    "url": "/forum?id=DfMqlB0PXjM",
    "date": "28 Sept 2021 (modified: 20 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Interpretable Unsupervised Image Restoration, Diversity Image Restoration, Unsupervised Image Denoising, Unsupervised Artefact Removal",
    "Abstract": "Image denoising and artefact removal are complex inverse problems admitting multiple valid solutions. Unsupervised diversity restoration, that is, obtaining a diverse set of possible restorations given a corrupted image, is important for ambiguity removal in many applications such as microscopy where paired data for supervised training are often unobtainable. In real world applications, imaging noise and artefacts are typically hard to model, leading to unsatisfactory performance of existing unsupervised approaches. This work presents an interpretable approach for unsupervised and diverse image restoration. To this end, we introduce a capable architecture called Hierarchical DivNoising (HDN) based on hierarchical Variational Autoencoder. We show that HDN learns an interpretable multi-scale representation of artefacts  and we leverage this interpretability to remove imaging artefacts commonly occurring in microscopy data. Our method achieves state-of-the-art results on twelve benchmark image denoising datasets while providing access to a whole distribution of sensibly restored solutions.\n        Additionally, we demonstrate on three real microscopy datasets that HDN removes artefacts without supervision, being the first method capable of doing so while generating multiple plausible restorations all consistent with the given corrupted image.",
    "One-sentence Summary": "This work proposes a new architecture for unsupervised, interpretable and diverse image restoration while achieving state-of-the-art results on numerous commonly used benchmarks across multiple image domains."
  },
  {
    "title": "Half-Inverse Gradients for Physical Deep Learning",
    "url": "/forum?id=HTx7vrlLBEj",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "physical simulation, partial differential equations, physical loss functions, optimization",
    "Abstract": "Recent works in deep learning have shown that integrating differentiable physics simulators into the training process can greatly improve the quality of results. Although this combination represents a more complex optimization task than usual neural network training, the same gradient-based optimizers are used to minimize the loss function. However, the integrated physics solvers have a profound effect on the gradient flow as manipulating scales in magnitude and direction is an inherent property of many physical processes. Consequently, the gradient flow is often highly unbalanced and creates an environment in which existing gradient-based optimizers perform poorly. In this work, we analyze the characteristics of both physical and neural network optimizations separately to derive a new method based on a half-inversion of the Jacobian. Our approach combines principles of both classical network and physics optimizers to solve the combined optimization task. Compared to state-of-the-art neural network optimizers, our method converges more quickly and to better solutions, which we demonstrate on three complex learning problems involving nonlinear oscillators, the Schroedinger equation and the Poisson problem.",
    "One-sentence Summary": "By proposing a novel Jacobian-based optimizer, we question the current practice of using the state-of-the-art gradient-based methods for the optimization of neural networks with physics objectives."
  },
  {
    "title": "EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits",
    "url": "/forum?id=X_ch3VrNSRg",
    "date": "28 Sept 2021 (modified: 09 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Contextual Bandits, Exploration Strategy, Neural Networks",
    "Abstract": "In this paper, we propose a novel neural exploration strategy in contextual bandits, EE-Net, distinct from the standard UCB-based and TS-based approaches. Contextual multi-armed bandits have been studied for decades with various applications. To solve the exploitation-exploration tradeoff in bandits, there are three main techniques: epsilon-greedy, Thompson Sampling (TS), and Upper Confidence Bound (UCB). In recent literature, linear contextual bandits have adopted ridge regression to estimate the reward function and combine it with TS or UCB strategies for exploration. However, this line of works explicitly assumes the reward is based on a linear function of arm vectors, which may not be true in real-world datasets. To overcome this challenge, a series of neural bandit algorithms have been proposed, where a neural network is used to learn the underlying reward function and TS or UCB are adapted for exploration. Instead of calculating a large-deviation based statistical bound for exploration like previous methods,  we propose \"EE-Net\", a novel neural-based exploration strategy. In addition to using a neural network (Exploitation network) to learn the reward function, EE-Net uses another neural network (Exploration network) to adaptively learn potential gains compared to the currently estimated reward for exploration. Then, a decision-maker is constructed to combine the outputs from the Exploitation and Exploration networks. We prove that EE-Net can achieve $\\mathcal{O}(\\sqrt{T\\log T})$ regret and show that EE-Net outperforms existing linear and neural contextual bandit baselines on real-world datasets."
  },
  {
    "title": "Spike-inspired rank coding for fast and accurate recurrent neural networks",
    "url": "/forum?id=iMH1e5k7n3L",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Biological spiking neural networks (SNNs) can temporally encode information in their outputs, e.g. in the rank order in which neurons fire, whereas artificial neural networks (ANNs) conventionally do not. As a result, models of SNNs for neuromorphic computing are regarded as potentially more rapid and efficient than ANNs when dealing with temporal input. On the other hand, ANNs are simpler to train, and usually achieve superior performance. Here we show that temporal coding such as rank coding (RC) inspired by SNNs can also be applied to conventional ANNs such as LSTMs, and leads to computational savings and speedups.\n        In our RC for ANNs, we apply backpropagation through time using the standard real-valued activations, but only from a strategically early time step of each sequential input example, decided by a threshold-crossing event. Learning then incorporates naturally also when to produce an output, without other changes to the model or the algorithm. Both the forward and the backward training pass can be significantly shortened by skipping the remaining input sequence after that first event. RC-training also significantly reduces time-to-insight during inference, with a minimal decrease in accuracy. The desired speed-accuracy trade-off is tunable by varying the threshold or a regularization parameter that rewards output entropy. We demonstrate these in two toy problems of sequence classification, and in a temporally-encoded MNIST dataset where our RC model achieves 99.19% accuracy after the first input time-step, outperforming the state of the art in temporal coding with SNNs, as well as in spoken-word classification of Google Speech Commands, outperforming non-RC-trained early inference with LSTMs.",
    "One-sentence Summary": "Learning to infer fast in LSTMs inspired by SNNs, and applied in speech recognition"
  },
  {
    "title": "How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective",
    "url": "/forum?id=W9G_ImpHlQd",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Zeroth-Order Optimization, Black-Box Defense, Gradient-Free, Adversarial Robustness, Certified Defense",
    "Abstract": "The lack of adversarial robustness has been recognized as an important issue for state-of-the-art machine learning (ML) models, e.g., deep neural networks (DNNs). Thereby, robustifying ML models against adversarial attacks is now a major focus of research. However, nearly all existing defense methods, particularly for robust training, made the white-box assumption that the defender has the access to the details of an ML model (or its surrogate alternatives if available), e.g., its architectures and parameters. Beyond existing works, in this paper we aim to address the problem of black-box defense: How to robustify a black-box model using just input queries and output feedback? Such a problem arises in practical scenarios, where the owner of the predictive model is reluctant to share model information in order to preserve privacy. To this end, we propose a general notion of defensive operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a \ufb01rst-order (FO) certi\ufb01ed defense technique. To allow the design of merely using model queries, we further integrate DS with the zeroth-order (gradient-free) optimization. However, a direct implementation of zeroth-order (ZO) optimization suffers a high variance of gradient estimates, and thus leads to ineffective defense. To tackle this problem, we next propose to prepend an autoencoder (AE) to a given (black-box) model so that DS can be trained using variance-reduced ZO optimization. We term the eventual defense as ZO-AE-DS. In practice, we empirically show that ZO-AE-DS can achieve improved accuracy, certi\ufb01ed robustness, and query complexity over existing baselines. And the effectiveness of our approach is justi\ufb01ed under both image classi\ufb01cation and image reconstruction tasks.",
    "One-sentence Summary": "We propose a general notion of defensive operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a first-order (FO) certified defense technique."
  },
  {
    "title": "RelaxLoss: Defending Membership Inference Attacks without Losing Utility",
    "url": "/forum?id=FEDfGWVZYIn",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "membership inference attack, defense",
    "Abstract": "As a long-term threat to the privacy of training data, membership inference attacks (MIAs) emerge ubiquitously in machine learning models.\n        Existing works evidence strong connection between the distinguishability of the training and testing loss distributions and the model's vulnerability to MIAs. Motivated by existing results, we propose a novel training framework based on a relaxed loss ($\\textbf{RelaxLoss}$) with a more achievable learning target, which leads to narrowed generalization gap and reduced privacy leakage. RelaxLoss is applicable to any classification model with added benefits of easy implementation and negligible overhead. Through extensive evaluations on five datasets with diverse modalities (images, medical data, transaction records), our approach consistently outperforms state-of-the-art defense mechanisms in terms of resilience against MIAs as well as model utility. Our defense is the first that can withstand a wide range of attacks while preserving (or even improving) the target model's utility.",
    "One-sentence Summary": "We propose a novel training scheme that is highly effective in protecting against membership inference attacks while preserving the utility of target models."
  },
  {
    "title": "Analyzing and Improving the Optimization Landscape of Noise-Contrastive Estimation",
    "url": "/forum?id=eBS-3YiaIL-",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "noise contrastive estimation, contrastive learning, unsupervised learning, theory",
    "Abstract": "Noise-contrastive estimation (NCE) is a statistically consistent method for learning unnormalized probabilistic models. It has been empirically observed that the choice of the noise distribution is crucial for NCE\u2019s performance. However, such observation has never been made formal or quantitative. In fact, it is not even clear whether the difficulties arising from a poorly chosen noise distribution are statistical or algorithmic in nature.\n        In this work, we formally pinpoint reasons for NCE\u2019s poor performance when an inappropriate noise distribution is used. Namely, we prove these challenges arise due to an ill-behaved (more precisely, flat) loss landscape.\n        To address this, we introduce a variant of NCE called \\emph{eNCE} which uses an exponential loss and for which \\emph{normalized gradient descent} addresses the landscape issues \\emph{provably} when the target and noise distributions are in a given exponential family.",
    "One-sentence Summary": "This work theoretically explains the difficulty of optimizing the NCE loss when the noise distribution is poor, and provides a provably efficient solution consisting of normalized gradient descent (NGD) combined with the proposed \\emph{eNCE} loss."
  },
  {
    "title": "Contact Points Discovery for Soft-Body Manipulations with Differentiable Physics",
    "url": "/forum?id=mmUA7_O9mjY",
    "date": "28 Sept 2021 (modified: 05 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "differentiable physics, soft body manipulation",
    "Abstract": "Differentiable physics has recently been shown as a powerful tool for solving soft-body manipulation tasks. However, the differentiable physics solver often gets stuck when the initial contact points of the end effectors are sub-optimal or when performing multi-stage tasks that require contact point switching, which often leads to local minima.\n        To address this challenge, we propose a  contact point discovery approach (CPDeform) that guides the stand-alone differentiable physics solver to deform various soft-body plasticines. The key idea of our approach is to integrate optimal transport-based contact points discovery into the differentiable physics solver to overcome the local minima from initial contact points or contact switching.\n        On single-stage tasks, our method can automatically find suitable initial contact points based on transport priorities. On complex multi-stage tasks, we can iteratively switch the contact points of end-effectors based on transport priorities. To evaluate the effectiveness of our method, we introduce PlasticineLab-M that extends the existing differentiable physics benchmark PlasticineLab to seven new challenging multi-stage soft-body manipulation tasks. Extensive experimental results suggest that: 1) on multi-stage tasks that are infeasible for the vanilla differentiable physics solver, our approach discovers contact points that efficiently guide the solver to completion; 2) on tasks where the vanilla solver performs sub-optimally or near-optimally, our contact point discovery method performs better than or on par with the manipulation performance obtained with handcrafted contact points.",
    "One-sentence Summary": "We propose a contact pose discovery method that guides the stand-alone differentiable physics solver to complete various soft-body manipulation tasks."
  },
  {
    "title": "Leveraging Automated Unit Tests for Unsupervised Code Translation",
    "url": "/forum?id=cmt-6KtR4c4",
    "date": "28 Sept 2021 (modified: 16 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "unsupervised, translation, code, self-training, pseudo-labelling, unit tests, programming languages, deep learning, transformer",
    "Abstract": "With little to no parallel data available for programming languages, unsupervised methods are well-suited to source code translation. However, the majority of unsupervised machine translation approaches rely on back-translation, a method developed in the context of natural language translation and one that inherently involves training on noisy inputs. Unfortunately, source code is highly sensitive to small changes; a single token can result in compilation failures or erroneous programs, unlike natural languages where small inaccuracies may not change the meaning of a sentence. To address this issue, we propose to leverage an automated unit-testing system to filter out invalid translations, thereby creating a fully tested parallel corpus. We found that fine-tuning an unsupervised model with this filtered data set significantly reduces the noise in the translations so-generated, comfortably outperforming the state-of-the-art for all language pairs studied. In particular, for Java\u2192Python and Python\u2192C++ we outperform the best previous methods by more than 16% and 24% respectively, reducing the error rate by more than 35%.",
    "One-sentence Summary": "We leverage automatically created multilingual unit tests to improve unsupervised machine translation methods for source code and substantially outperform the state-of-the-art on all the language pairs we consider."
  },
  {
    "title": "Scalable Sampling for Nonsymmetric Determinantal Point Processes",
    "url": "/forum?id=BB4e8Atc1eR",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "determinantal point processes, sampling",
    "Abstract": "A determinantal point process (DPP) on a collection of $M$ items is a model, parameterized by a symmetric kernel matrix, that assigns a probability to every subset of those items.  Recent work shows that removing the kernel symmetry constraint, yielding nonsymmetric DPPs (NDPPs), can lead to significant predictive performance gains for machine learning applications. However, existing work leaves open the question of scalable NDPP sampling. There is only one known DPP sampling algorithm, based on Cholesky decomposition, that can directly apply to NDPPs as well. Unfortunately, its runtime is cubic in $M$, and thus does not scale to large item collections. In this work, we first note that this algorithm can be transformed into a linear-time one for kernels with low-rank structure.  Furthermore, we develop a scalable sublinear-time rejection sampling algorithm by constructing a novel proposal distribution.  Additionally, we show that imposing certain structural constraints on the NDPP kernel enables us to bound the rejection rate in a way that depends only on the kernel rank. In our experiments we compare the speed of all of these samplers for a variety of real-world tasks.",
    "One-sentence Summary": "We propose the first scalable linear-time and sublinear-time sampling algorithms for nonsymmetric determinantal point processes."
  },
  {
    "title": "Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design",
    "url": "/forum?id=FRxhHdnxt1",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "molecular design, synthesis planning, tree generation, graph generation",
    "Abstract": "Molecular design and synthesis planning are two critical steps in the process of molecular discovery that we propose to formulate as a single shared task of conditional synthetic pathway generation. We report an amortized approach to generate synthetic pathways as a Markov decision process conditioned on a target molecular embedding. This approach allows us to conduct synthesis planning in a bottom-up manner and design synthesizable molecules by decoding from optimized conditional codes, demonstrating the potential to solve both problems of design and synthesis simultaneously. The approach leverages neural networks to probabilistically model the synthetic trees, one reaction step at a time, according to reactivity rules encoded in a discrete action space of reaction templates. We train these networks on hundreds of thousands of artificial pathways generated from a pool of purchasable compounds and a list of expert-curated templates. We validate our method with (a) the recovery of molecules using conditional generation, (b) the identification of synthesizable structural analogs, and (c) the optimization of molecular structures given oracle functions relevant to bioactivity and drug discovery.",
    "One-sentence Summary": "We propose a model that address synthesis planning and synthesizable molecular design simultaneously."
  },
  {
    "title": "Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design",
    "url": "/forum?id=LI2bhrE_2A",
    "date": "28 Sept 2021 (modified: 10 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Drug Discovery, Antibody Design, Generative Models, Graph Generation",
    "Abstract": "Antibodies are versatile proteins that bind to pathogens like viruses and stimulate the adaptive immune system. The specificity of antibody binding is determined by complementarity-determining regions (CDRs) at the tips of these Y-shaped proteins. In this paper, we propose a generative model to automatically design the CDRs of antibodies with enhanced binding specificity or neutralization capabilities. Previous generative approaches formulate protein design as a structure-conditioned sequence generation task, assuming the desired 3D structure is given a priori. In contrast, we propose to co-design the sequence and 3D structure of CDRs as graphs. Our model unravels a sequence autoregressively while iteratively refining its predicted global structure. The inferred structure in turn guides subsequent residue choices. For efficiency, we model the conditional dependence between residues inside and outside of a CDR in a coarse-grained manner. Our method achieves superior log-likelihood on the test set and outperforms previous baselines in designing antibodies capable of neutralizing the SARS-CoV-2 virus.",
    "One-sentence Summary": "We propose a new graph-based generative model for antibody design"
  },
  {
    "title": "Churn Reduction via Distillation",
    "url": "/forum?id=HbtFCX2PLq0",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "distillation, churn, constraints",
    "Abstract": "In real-world systems, models are frequently updated as more data becomes available, and in addition to achieving high accuracy, the goal is to also maintain a low difference in predictions compared to the base model (i.e. predictive churn). If model retraining results in vastly different behavior, then it could cause negative effects in downstream systems, especially if this churn can be avoided with limited impact on model accuracy. In this paper, we show an equivalence between training with distillation using the base model as the teacher and training with an explicit constraint on the predictive churn. We then show that distillation performs strongly for low churn training against a number of recent baselines on a wide range of datasets and model architectures, including fully-connected networks, convolutional networks, and transformers.",
    "One-sentence Summary": "We show distillation is a principled and practical solution to churn reduction."
  },
  {
    "title": "Learning Causal Models from Conditional Moment Restrictions by Importance Weighting",
    "url": "/forum?id=7twQI5VnC8",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Causal inference, Conditional moment restrictions",
    "Abstract": "We consider learning causal relationships under conditional moment restrictions. Unlike causal inference under unconditional moment restrictions, conditional moment restrictions pose serious challenges for causal inference. To address this issue, we propose a method that transforms conditional moment restrictions to unconditional moment restrictions through importance weighting using a conditional density ratio estimator. Then, using this transformation, we propose a method that successfully estimate a parametric or nonparametric functions defined under the conditional moment restrictions. We analyze the estimation error and provide a bound on the structural function, providing theoretical support for our proposed method. In experiments, we confirm the soundness of our proposed method.",
    "One-sentence Summary": "Learning causal relationships under conditional moment restrictions by importance weighting using the conditional density ratio function."
  },
  {
    "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation",
    "url": "/forum?id=hfU7Ka5cfrC",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Hyperparameter Optimisation",
    "Abstract": "Machine learning training methods depend plentifully and intricately on hyperparameters, motivating automated strategies for their optimisation. Many existing algorithms restart training for each new hyperparameter choice, at considerable computational cost. Some hypergradient-based one-pass methods exist, but these either cannot be applied to arbitrary optimiser hyperparameters (such as learning rates and momenta) or take several times longer to train than their base models. We extend these existing methods to develop an approximate hypergradient-based hyperparameter optimiser which is applicable to any continuous hyperparameter appearing in a differentiable model weight update, yet requires only one training episode, with no restarts. We also provide a motivating argument for convergence to the true hypergradient, and perform tractable gradient-based optimisation of independent learning rates for each model parameter. Our method performs competitively from varied random hyperparameter initialisations on several UCI datasets and Fashion-MNIST (using a one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a ResNet-18), in time only 2-3x greater than vanilla training.",
    "One-sentence Summary": "We develop a gradient-based hyperparameter optimisation algorithm, applicable to a wide range of continuous hyperparameters, and scaling to large numbers of hyperparameters, without dramatically increasing training time from the non-HPO baseline."
  },
  {
    "title": "Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation",
    "url": "/forum?id=vrW3tvDfOJQ",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Deep reinforcement learning, uncertainty estimation, inverse-variance, heteroscedastic",
    "Abstract": "In model-free deep reinforcement learning (RL) algorithms, using noisy value estimates to supervise policy evaluation and optimization is detrimental to the sample efficiency. As this noise is heteroscedastic, its effects can be mitigated using uncertainty-based weights in the optimization process. Previous methods rely on sampled ensembles, which do not capture all aspects of uncertainty. We provide a systematic analysis of the sources of uncertainty in the noisy supervision that occurs in RL, and introduce inverse-variance RL, a Bayesian framework which combines probabilistic ensembles and Batch Inverse Variance weighting. We propose a method whereby two complementary uncertainty estimation methods account for both the Q-value and the environment stochasticity to better mitigate the negative impacts of noisy supervision. Our results show significant improvement in terms of sample efficiency on discrete and continuous control tasks.",
    "One-sentence Summary": "The sample efficiency and performance of model-free DRL is improved by estimating the predictive uncertainty of the targets using probabilistic ensembles and down-weighting the uncertain samples using batch inverse-variance weighting."
  },
  {
    "title": "Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, And No Retraining",
    "url": "/forum?id=O1DEtITim__",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Pruning, Frank-Wolfe",
    "Abstract": "We present a novel framework to train a large deep neural network (DNN) for only $\\textit{once}$, which can then be pruned to $\\textit{any sparsity ratio}$ to preserve competitive accuracy $\\textit{without any re-training}$. Conventional methods often require (iterative) pruning followed by re-training, which not only incurs large overhead beyond the original DNN training but also can be sensitive to retraining hyperparameters. Our core idea is to re-cast the DNN training as an explicit $\\textit{pruning-aware}$ process: that is formulated with an auxiliary $K$-sparse polytope constraint, to encourage network weights to lie in a convex hull spanned by $K$-sparse vectors, potentially resulting in more sparse weight matrices. We then leverage a stochastic Frank-Wolfe (SFW) algorithm to solve this new constrained optimization, which naturally leads to sparse weight updates each time. We further note an overlooked fact that existing DNN initializations were derived to enhance SGD training (e.g., avoid gradient explosion or collapse), but was unaligned with the challenges of training with SFW. We hence also present the first learning-based initialization scheme specifically for boosting SFW-based DNN training. Experiments on CIFAR-10 and Tiny-ImageNet datasets demonstrate that our new framework named $\\textbf{SFW-pruning}$ consistently achieves the state-of-the-art performance on various benchmark DNNs over a wide range of pruning ratios. Moreover, SFW-pruning only needs to train once on the same model and dataset, for obtaining arbitrary ratios, while requiring neither iterative pruning nor retraining. All codes will be released to the public.",
    "One-sentence Summary": "We propose a novel and state-of-the-art one-shot pruning method, which can generate sparse networks at any pruning ratio in one pruning and without any retraining."
  },
  {
    "title": "Learning transferable motor skills with hierarchical latent mixture policies",
    "url": "/forum?id=qTHBE7E9iej",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Robotics, Reinforcement Learning, Hierarchical, Latent Variable Models, Skills, Transfer",
    "Abstract": "For robots operating in the real world, it is desirable to learn reusable abstract behaviours that can effectively be transferred across numerous tasks and scenarios.\n        We propose an approach to learn skills from data using a hierarchical mixture latent variable model.\n        Our method exploits a multi-level hierarchy of both discrete and continuous latent variables, to model a discrete set of abstract high-level behaviours while allowing for variance in how they are executed.\n        We demonstrate in manipulation domains that the method can effectively cluster offline data into distinct, executable behaviours, while retaining the flexibility of a continuous latent variable model.\n        The resulting skills can be transferred to new tasks, unseen objects, and from state to vision-based policies, yielding significantly better sample efficiency and asymptotic performance compared to existing skill- and imitation-based methods.\n        We also perform further analysis showing how and when the skills are most beneficial: they encourage directed exploration to cover large regions of the state space relevant to the task, making them most effective in challenging sparse-reward settings.",
    "One-sentence Summary": "An approach to learn reusable and transferable skills from data via a hierarchical latent mixture policy, which can significantly improve sample efficiency and asymptotic performance on downstream RL tasks"
  },
  {
    "title": "Compositional Training for End-to-End Deep AUC Maximization",
    "url": "/forum?id=gPvB4pdu_Z",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Compositional Training, Imbalanced Losses, AUC optimization, Deep Learning",
    "Abstract": "Recently, deep AUC maximization (DAM) has achieved great success in different domains (e.g., medical image classification). However, the end-to-end training for deep AUC maximization still remains a challenging problem. Previous studies employ an ad-hoc  two-stage approach that first trains the network by optimizing a traditional  loss (e.g., cross-entropy loss) and then finetunes the network by optimizing an AUC loss. This is because that training a deep neural network from scratch by maximizing an AUC loss usually does not yield a satisfactory performance. This phenomenon can be attributed to the degraded feature representations learned by maximizing the AUC loss from scratch. To address this issue, we propose a novel compositional training framework for end-to-end DAM, namely compositional DAM. The key idea of compositional training is to minimize a compositional objective function, where the outer function corresponds to an AUC loss and the inner function represents  a gradient descent step for minimizing a traditional loss, e.g., the cross-entropy (CE) loss. To optimize the non-standard compositional objective, we propose an efficient and provable stochastic optimization algorithm. The proposed algorithm enhances the capabilities  of  both robust feature learning and robust classifier learning  by alternatively taking a gradient descent step for the CE loss and for the AUC loss in a systematic way.  We conduct extensive empirical studies on imbalanced benchmark and medical image datasets, which unanimously verify the effectiveness of the proposed method.  Our results show that the compositional training approach dramatically improves both the feature representations and the testing AUC score compared with traditional deep learning approaches, and yields better performance than the two-stage approaches for DAM as well. The proposed method is implemented in our open-sourced library LibAUC (https://www.libauc.org) and code is available at https://github.com/Optimization-AI/LibAUC.",
    "One-sentence Summary": "We propose a novel end-to-end training framework with a provable stochastic algorithm for deep AUC maximization."
  },
  {
    "title": "Explanations of Black-Box Models based on Directional Feature Interactions",
    "url": "/forum?id=45Mr7LeKR9",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Explainability, Shapley values, Interpretability, Directional interaction, feature interaction",
    "Abstract": "As machine learning algorithms are deployed ubiquitously to a variety of domains, it is imperative to make these often black-box models transparent.  Several recent works explain black-box models by capturing the most influential features for prediction per instance; such explanation methods are univariate, as they characterize importance per feature.  We extend univariate explanation to a higher-order; this enhances explainability, as bivariate methods can capture feature interactions in black-box models, represented as a directed graph.  Analyzing this graph enables us to discover groups of features that are equally important (i.e., interchangeable), while the notion of directionality allows us to identify the most influential features.  We apply our bivariate method on Shapley value explanations, and experimentally demonstrate the ability of directional explanations to discover feature interactions. We show the superiority of our method against state-of-the-art on CIFAR10, IMDB, Census, Divorce, Drug, and gene data.",
    "One-sentence Summary": "We introduce a bivariate explainer to explain directional feature interactions in black box models."
  },
  {
    "title": "On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning",
    "url": "/forum?id=Fl3Mg_MZR-",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement Learning, Sparsity, Pruning, Lottery Ticket Hypothesis",
    "Abstract": "The lottery ticket hypothesis questions the role of overparameterization in supervised deep learning. But how is the performance of winning lottery tickets affected by the distributional shift inherent to reinforcement learning problems? In this work, we address this question by comparing sparse agents who have to address the non-stationarity of the exploration-exploitation problem with supervised agents trained to imitate an expert. We show that feed-forward networks trained with behavioural cloning compared to reinforcement learning can be pruned to higher levels of sparsity without performance degradation. This suggests that in order to solve the RL-specific distributional shift agents require more degrees of freedom. Using a set of carefully designed baseline conditions, we find that the majority of the lottery ticket effect in both learning paradigms can be attributed to the identified mask rather than the weight initialization. The input layer mask selectively prunes entire input dimensions that turn out to be irrelevant for the task at hand. At a moderate level of sparsity the mask identified by iterative magnitude pruning yields minimal task-relevant representations, i.e., an interpretable inductive bias. Finally, we propose a simple initialization rescaling which promotes the robust identification of sparse task representations in low-dimensional control tasks.",
    "One-sentence Summary": "We investigate the mechanisms underlying the lottery ticket effect in Deep RL and show that the derived mask extracts minimal task representations."
  },
  {
    "title": "Self-supervised Learning is More Robust to Dataset Imbalance",
    "url": "/forum?id=4AZz9osqrar",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "self-supervised learning, dataset imbalance, representation learning, long-tailed recognition",
    "Abstract": "Self-supervised learning (SSL) is a scalable way to learn general visual representations since it learns without labels. However, large-scale unlabeled datasets in the wild often have long-tailed label distributions, where we know little about the behavior of SSL. In this work, we systematically investigate self-supervised learning under dataset imbalance. First, we find via extensive experiments that off-the-shelf self-supervised representations are already more robust to class imbalance than supervised representations. The performance gap between balanced and imbalanced pre-training with SSL is significantly smaller than the gap with supervised learning, across sample sizes, for both in-domain and, especially, out-of-domain evaluation. Second, towards understanding the robustness of SSL, we hypothesize that SSL learns richer features from frequent data: it may learn label-irrelevant-but-transferable features that help classify the rare classes and downstream tasks. In contrast, supervised learning has no incentive to learn features irrelevant to the labels from frequent examples. We validate this hypothesis with semi-synthetic experiments as well as rigorous mathematical analyses on a simplified setting. Third, inspired by the theoretical insights, we devise a re-weighted regularization technique that  consistently improves the SSL representation quality on imbalanced datasets with several evaluation criteria, closing the small gap between balanced and imbalanced datasets with the same number of examples.",
    "One-sentence Summary": "We show that self-supervised pre-training yields representations more robust to dataset imbalance, because it captures more diverse features from the frequent classes, and can be improved further by re-weighting regularization."
  },
  {
    "title": "Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave Functions",
    "url": "/forum?id=apv504XsysP",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Graph Neural Networks, Computational Physics, Self-Generative Learning, Machine Learning for Science",
    "Abstract": "Solving the Schr\u00f6dinger equation is key to many quantum mechanical properties. However, an analytical solution is only tractable for single-electron systems. Recently, neural networks succeeded at modelling wave functions of many-electron systems. Together with the variational Monte-Carlo (VMC) framework, this led to solutions on par with the best known classical methods. Still, these neural methods require tremendous amounts of computational resources as one has to train a separate model for each molecular geometry. In this work, we combine a Graph Neural Network (GNN) with a neural wave function to simultaneously solve the Schr\u00f6dinger equation for multiple geometries via VMC. This enables us to model continuous subsets of the potential energy surface with a single training pass. Compared to existing state-of-the-art networks, our Potential Energy Surface Network (PESNet) speeds up training for multiple geometries by up to 40 times while matching or surpassing their accuracy. This may open the path to accurate and orders of magnitude cheaper quantum mechanical calculations.",
    "One-sentence Summary": "We introduce a PESNet, a new network architecture that solves the Schr\u00f6dinger equation for multiple geometries simultaneously."
  },
  {
    "title": "Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver",
    "url": "/forum?id=SidzxAb9k30",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "reward-free exploration, model-based reinforcement learning, learning theory",
    "Abstract": "Although model-based reinforcement learning (RL) approaches are considered more sample efficient, existing algorithms are usually relying on sophisticated planning algorithm to couple tightly with the model-learning procedure. Hence the learned models may lack the ability of being re-used with more specialized planners. In this paper we address this issue and provide approaches to learn an RL model efficiently without the guidance of a reward signal. In particular, we take a plug-in solver approach, where we focus on learning a model in the exploration phase and demand that \\emph{any planning algorithm} on the learned model can give a near-optimal policy. Specicially, we focus on the linear mixture MDP setting, where the probability transition matrix is a (unknown) convex combination of a set of existing models. We show that, by establishing a novel exploration algorithm, the plug-in approach learns a model by taking $\\tilde{O}(d^2H^3/\\epsilon^2)$ interactions with the environment and \\emph{any} $\\epsilon$-optimal planner on the model gives an $O(\\epsilon)$-optimal policy on the original model. This sample complexity matches lower bounds for non-plug-in approaches and is \\emph{statistically optimal}. We achieve this result by leveraging a careful maximum total-variance bound using Bernstein inequality and properties specified to linear mixture MDP.",
    "One-sentence Summary": "We propose near-optimal exploration algorithms for reward-free exploration with plug-in solver."
  },
  {
    "title": "Meta Discovery: Learning to Discover Novel Classes given Very Limited Data",
    "url": "/forum?id=MEpKGLsY8f",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "In novel class discovery (NCD), we are given labeled data from seen classes and unlabeled data from unseen classes, and we train clustering models for the unseen classes. However, the implicit assumptions behind NCD are still unclear. In this paper, we demystify assumptions behind NCD and find that high-level semantic features should be shared among the seen and unseen classes. Based on this finding, NCD is theoretically solvable under certain assumptions and can be naturally linked to meta-learning that has exactly the same assumption as NCD. Thus, we can empirically solve the NCD problem by meta-learning algorithms after slight modifications. This meta-learning-based methodology significantly reduces the amount of unlabeled data needed for training and makes it more practical, as demonstrated in experiments. The use of very limited data is also justified by the application scenario of NCD: since it is unnatural to label only seen-class data, NCD is sampling instead of labeling in causality. Therefore, unseen-class data should be collected on the way of collecting seen-class data, which is why they are novel and first need to be clustered."
  },
  {
    "title": "Constrained Policy Optimization via Bayesian World Models",
    "url": "/forum?id=PRZoSmCinhf",
    "date": "28 Sept 2021 (modified: 06 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement learning, Constrained Markov decision processes, Constrained policy optimization, Bayesian model-based RL",
    "Abstract": "Improving sample-efficiency and safety are crucial challenges when deploying reinforcement learning in high-stakes real world applications. We propose LAMBDA, a novel model-based approach for policy optimization in safety critical tasks modeled via constrained Markov decision processes. Our approach utilizes Bayesian world models, and harnesses the resulting uncertainty to maximize optimistic upper bounds on the task objective, as well as pessimistic upper bounds on the safety constraints. We demonstrate LAMBDA's state of the art performance on the Safety-Gym benchmark suite in terms of sample efficiency and constraint violation.",
    "One-sentence Summary": "Solving constrained Markov decision processes with Bayesian model-based reinforcement learning."
  },
  {
    "title": "VAE Approximation Error: ELBO and Exponential Families",
    "url": "/forum?id=OIs3SxU5Ynl",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "The importance of Variational Autoencoders reaches far beyond standalone generative models -- the approach is also used for learning latent representations and can be generalized to semi-supervised learning. This requires a thorough analysis of their commonly known shortcomings: posterior collapse and approximation errors. This paper analyzes VAE approximation errors caused by the combination of the ELBO objective and encoder models from conditional exponential families, including, but not limited to, commonly used conditionally independent discrete and continuous models.\n        We characterize subclasses of generative models consistent with these encoder families. We show that the ELBO optimizer is pulled away from the likelihood optimizer towards the consistent subset and study this effect experimentally. Importantly, this subset can not be enlarged, and the respective error cannot be decreased, by considering deeper encoder/decoder networks.",
    "One-sentence Summary": "VAEs have an inductive bias towards RBMs and generalized linear models"
  },
  {
    "title": "Generalized Decision Transformer for Offline Hindsight Information Matching",
    "url": "/forum?id=CAjxVodl_v",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Hindsight Information Matching, Decision Transformer, State-Marginal Matching, Hindsight Experience Replay, Reinforcement Learning",
    "Abstract": "How to extract as much learning signal from each trajectory data has been a key problem in reinforcement learning (RL), where sample inefficiency has posed serious challenges for practical applications. Recent works have shown that using expressive policy function approximators and conditioning on future trajectory information -- such as future states in hindsight experience replay (HER) or returns-to-go in Decision Transformer (DT) -- enables efficient learning of multi-task policies, where at times online RL is fully replaced by offline behavioral cloning (BC), e.g. sequence modeling. We demonstrate that all these approaches are doing hindsight information matching (HIM) -- training policies that can output the rest of trajectory that matches some statistics of future state information. We present Generalized Decision Transformer (GDT) for solving any HIM problem, and show how different choices for the feature function and the anti-causal aggregator not only recover DT as a special case, but also lead to novel Categorical DT (CDT) and Bi-directional DT (BDT) for matching different statistics of the future. For evaluating CDT and BDT, we define offline multi-task state-marginal matching (SMM) and imitation learning (IL) as two generic HIM problems, propose a Wasserstein distance loss as a metric for both, and empirically study them on MuJoCo continuous control benchmarks. Categorical DT, which simply replaces anti-causal summation with anti-causal binning in DT, enables arguably the first effective offline multi-task SMM algorithm that generalizes well to unseen (and even synthetic) multi-modal reward or state-feature distributions. Bi-directional DT, which uses an anti-causal second transformer as the aggregator, can learn to model any statistics of the future and outperforms DT variants in offline multi-task IL, i.e. one-shot IL. Our generalized formulations from HIM and GDT greatly expand the role of powerful sequence modeling architectures in modern RL.",
    "One-sentence Summary": "We generalize hindsight algorithms in RL, and propose Distributional Decision Transformer for information matching."
  },
  {
    "title": "Unifying Likelihood-free Inference with Black-box Optimization and Beyond",
    "url": "/forum?id=1HxTO6CTkz",
    "date": "28 Sept 2021 (modified: 06 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "biological sequence design, black-box optimization, likelihood-free inference, Bayesian inference",
    "Abstract": "Black-box optimization formulations for biological sequence design have drawn recent attention due to their promising potential impact on the pharmaceutical industry. In this work, we propose to unify two seemingly distinct worlds: likelihood-free inference and black-box optimization, under one probabilistic framework. In tandem, we provide a recipe for constructing various sequence design methods based on this framework. We show how previous optimization approaches can be \"reinvented\" in our framework, and further propose new probabilistic black-box optimization algorithms. Extensive experiments on sequence design application illustrate the benefits of the proposed methodology.",
    "One-sentence Summary": "We propose a framework to unify likelihood-free inference and black-box sequence design and further propose novel sequence design algorithms based on the framework."
  },
  {
    "title": "DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting",
    "url": "/forum?id=AJAR-JgNw__",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Periodic time series (PTS) forecasting plays a crucial role in a variety of industries to foster critical tasks, such as early warning, pre-planning, resource scheduling, etc. However, the complicated dependencies of the PTS signal on its inherent periodicity as well as the sophisticated composition of various periods hinder the performance of PTS forecasting. In this paper, we introduce a deep expansion learning framework, DEPTS, for PTS forecasting. DEPTS starts with a decoupled formulation by introducing the periodic state as a hidden variable, which stimulates us to make two dedicated modules to tackle the aforementioned two challenges. First, we develop an expansion module on top of residual learning to perform a layer-by-layer expansion of those complicated dependencies. Second, we introduce a periodicity module with a parameterized periodic function that holds sufficient capacity to capture diversified periods. Moreover, our two customized modules also have certain interpretable capabilities, such as attributing the forecasts to either local momenta or global periodicity and characterizing certain core periodic properties, e.g., amplitudes and frequencies. Extensive experiments on both synthetic data and real-world data demonstrate the effectiveness of DEPTS on handling PTS. In most cases, DEPTS achieves significant improvements over the best baseline. Specifically, the error reduction can even reach up to 20% for a few cases. All codes for this paper are publicly available."
  },
  {
    "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions",
    "url": "/forum?id=tBtoZYKd9n",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "graph generative models, model evaluation",
    "Abstract": "Graph generative models are a highly active branch of machine learning. Given the steady development of new models of ever-increasing complexity, it is necessary to provide a principled way to evaluate and compare them. In this paper, we enumerate the desirable criteria for such a comparison metric and provide an overview of the status quo of graph generative model comparison in use today, which predominantly relies on the maximum mean discrepancy (MMD). We perform a systematic evaluation of MMD in the context of graph generative model comparison, highlighting some of the challenges and pitfalls researchers inadvertently may encounter. After conducting a thorough analysis of the behaviour of MMD on synthetically-generated perturbed graphs as well as on recently-proposed graph generative models, we are able to provide a suitable procedure to mitigate these challenges and pitfalls. We aggregate our findings into a list of practical recommendations for researchers to use when evaluating graph generative models.",
    "One-sentence Summary": "We investigate the potential pitfalls of using MMD to evaluate graph generative models and propose recommendations for the practitioner on how to mitigate those challenges."
  },
  {
    "title": "Natural Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions",
    "url": "/forum?id=tV3N0DWMxCg",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Uncertainty, Exponential Family, Bayesian Update, Conjugate Prior",
    "Abstract": "Uncertainty awareness is crucial to develop reliable machine learning models. In this work, we propose the Natural Posterior Network (NatPN) for fast and high-quality uncertainty estimation for any task where the target distribution belongs to the exponential family. Thus, NatPN finds application for both classification and general regression settings. Unlike many previous approaches, NatPN does not require out-of-distribution (OOD) data at training time. Instead, it leverages Normalizing Flows to fit a single density on a learned low-dimensional and task-dependent latent space. For any input sample, NatPN uses the predicted likelihood to perform a Bayesian update over the target distribution. Theoretically, NatPN assigns high uncertainty far away from training data. Empirically, our extensive experiments on calibration and OOD detection show that NatPN delivers highly competitive performance for classification, regression and count prediction tasks."
  },
  {
    "title": "Learning Altruistic Behaviours in Reinforcement Learning without External Rewards",
    "url": "/forum?id=KxbhdyiPHE",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "reinforcement learning, altruistic behavior in AI, multi-agent systems",
    "Abstract": "Can artificial agents learn to assist others in achieving their goals without knowing what those goals are? Generic reinforcement learning agents could be trained to behave altruistically towards others by rewarding them for altruistic behaviour, i.e., rewarding them for benefiting other agents in a given situation. Such an approach assumes that other agents' goals are known so that the altruistic agent can cooperate in achieving those goals. However, explicit knowledge of other agents' goals is often difficult to acquire. In the case of human agents, their goals and preferences may be difficult to express fully; they might be ambiguous or even contradictory. Thus, it is beneficial to develop agents that do not depend on external supervision and learn altruistic behaviour in a task-agnostic manner. We propose to act altruistically towards other agents by giving them more choice and allowing them to achieve their goals better. Some concrete examples include opening a door for others or safeguarding them to pursue their objectives without interference. We formalize this concept and propose an altruistic agent that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. We evaluate our approach in three different multi-agent environments where another agent's success depends on altruistic behaviour. Finally, we show that our unsupervised agents can perform comparably to agents explicitly trained to work cooperatively, in some cases even outperforming them.",
    "One-sentence Summary": "We propose and investigate unsupervised training of agents to behave altruistically towards others by actively maximizing others' choice."
  },
  {
    "title": "Context-Aware Sparse Deep Coordination Graphs",
    "url": "/forum?id=wQfgfb8VKTn",
    "date": "28 Sept 2021 (modified: 07 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Multi-agent reinforcement learning, Sparse coordination graphs, Deep coordination graphs",
    "Abstract": "Learning sparse coordination graphs adaptive to the coordination dynamics among agents is a long-standing problem in cooperative multi-agent learning. This paper studies this problem and proposes a novel method using the variance of payoff functions to construct context-aware sparse coordination topologies. We theoretically consolidate our method by proving that the smaller the variance of payoff functions is, the less likely action selection will change after removing the corresponding edge. Moreover, we propose to learn action representations to effectively reduce the influence of payoff functions' estimation errors on graph construction. To empirically evaluate our method, we present the Multi-Agent COordination (MACO) benchmark by collecting classic coordination problems in the literature, increasing their difficulty, and classifying them into different types. We carry out a case study and experiments on the MACO and StarCraft II micromanagement benchmark to demonstrate the dynamics of sparse graph learning, the influence of graph sparseness, and the learning performance of our method.",
    "One-sentence Summary": "We propose a novel method for learning sparse coordination graphs that can be theoretically justified and can significantly reduce communication overhead and improve learning performance of deep coordination graphs."
  },
  {
    "title": "On the approximation properties of recurrent encoder-decoder architectures",
    "url": "/forum?id=xDIvIqQ3DXD",
    "date": "28 Sept 2021 (modified: 14 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "encoder-decoder, recurrent neural networks, approximation, temporal product",
    "Abstract": "Encoder-decoder architectures have recently gained popularity in sequence to sequence modelling, featuring in state-of-the-art models such as transformers. However, a mathematical understanding of their working principles still remains limited. In this paper, we study the approximation properties of recurrent encoder-decoder architectures. Prior work established theoretical results for RNNs in the linear setting, where approximation capabilities can be related to smoothness and memory of target temporal relationships. Here, we uncover that the encoder and decoder together form a particular \u201ctemporal product structure\u201d which determines the approximation efficiency. Moreover, the encoder-decoder architecture generalises RNNs with the capability to learn time-inhomogeneous relationships. Our results provide the theoretical understanding of approximation properties of the recurrent encoder-decoder architecture, which precisely characterises, in the considered setting, the types of temporal relationships that can be efficiently learned.",
    "One-sentence Summary": "Approximation properties of recurrent encoder-decoder architectures are given, where the formed temporal product structure further characterises temporal relationships able to be efficiently learned."
  },
  {
    "title": "Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models",
    "url": "/forum?id=Nfl-iXa-y7R",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Sparse training, butterfly, low-rank, Lottery Tickets, Block sparsity, Hashing, Transformer, ViT, MLP-Mixer",
    "Abstract": "Overparameterized neural networks generalize well but are expensive to train. Ideally one would like to reduce their computational cost while retaining their generalization benefits. Sparse model training is a simple and promising approach to achieve this, but there remain challenges as existing methods struggle with accuracy loss, slow training runtime, or difficulty in sparsifying all model components. The core problem is that searching for a sparsity mask over a discrete set of sparse matrices is difficult and expensive. To address this, our main insight is to optimize over a continuous superset of sparse matrices with a fixed structure known as products of butterfly matrices. As butterfly matrices are not hardware efficient, we propose simple variants of butterfly (block and flat) to take advantage of modern hardware. Our method (Pixelated Butterfly) uses a simple fixed sparsity pattern based on flat block butterfly and low-rank matrices to sparsify most network layers (e.g., attention, MLP). We empirically validate that Pixelated Butterfly is $3\\times$ faster than Butterfly and speeds up training to achieve favorable accuracy--efficiency tradeoffs. On the ImageNet classification and WikiText-103 language modeling tasks, our sparse models train up to 2.3$\\times$ faster than the dense MLP-Mixer, Vision Transformer, and GPT-2 small with no drop in accuracy.",
    "One-sentence Summary": "We propose a simple sparse training method, which can speed up model training in wall-clock time with no drop in accuracy."
  },
  {
    "title": "8-bit Optimizers via Block-wise Quantization",
    "url": "/forum?id=shpkpVXzo3h",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "language models, pretraining, finetuning, GPU memory",
    "Abstract": "Stateful optimizers maintain gradient statistics over time, e.g., the exponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past gradient values. This state can be used to accelerate optimization significantly, compared to plain stochastic gradient descent, but uses memory that might otherwise be allocated to model parameters, thereby limiting the maximum size of models trained in practice. In this paper, we develop the first optimizers that use 8-bit statistics while maintaining the performance levels of using 32-bit optimizer states. To overcome the resulting computational, quantization, and stability challenges, we develop block-wise dynamic quantization. Block-wise quantization divides input tensors into smaller blocks that are independently quantized. Each block is processed in parallel across cores, yielding faster optimization and high precision quantization. To maintain stability and performance, we combine block-wise quantization with two additional changes: (1) dynamic quantization, a form of non-linear optimization that is precise for both large and small magnitude values, and (2) a stable embedding layer to reduce gradient variance that comes from the highly non-uniform distribution of input tokens in language models. As a result, our 8-bit optimizers maintain 32-bit performance with a small fraction of the memory footprint on a range of tasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet classification, WMT'14 machine translation, MoCo v2 contrastive ImageNet pretraining+finetuning, and RoBERTa pretraining, without changes to the original optimizer hyperparameters. We open-source our 8-bit optimizers as a drop-in replacement that only requires a two-line code change.",
    "One-sentence Summary": "We develop 8-bit optimizers reduce the memory footprint of training and maintain 32-bit optimizer performance across NLP/CV benchmarks."
  },
  {
    "title": "Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks",
    "url": "/forum?id=yeP_zx9vqNm",
    "date": "28 Sept 2021 (modified: 08 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Peripheral Computation, Adversarial Robustness, Perceptual Invariance, Metamerism, Texture, Psychophysics",
    "Abstract": "Recent work suggests that feature constraints in the training datasets of deep neural networks (DNNs) drive robustness to adversarial noise (Ilyas et al., 2019). The representations learned by such adversarially robust networks have also been shown to be more human perceptually-aligned than non-robust networks via image manipulations (Santurkar et al., 2019, Engstrom et al., 2019). Despite appearing closer to human visual perception, it is unclear if the constraints in robust DNN representations match biological constraints found in human vision. Human vision seems to rely on texture-based/summary statistic representations in the periphery, which have been shown to explain phenomena such as crowding (Balas et al., 2009) and performance on visual search tasks (Rosenholtz et al., 2012). To understand how adversarially robust optimizations/representations compare to human vision, we performed a psychophysics experiment using a metamer task similar to Freeman \\& Simoncelli, 2011, Wallis et al., 2016 and Deza et al., 2019 where we evaluated how well human observers could distinguish between images synthesized to match adversarially robust representations compared to non-robust representations and a texture synthesis model of peripheral vision (Texforms a la Long et al., 2018).  We found that the discriminability of robust representation and texture model images decreased to near chance performance as stimuli were presented farther in the periphery.  Moreover, performance on robust and texture-model images showed similar trends within participants, while performance on non-robust representations changed minimally across the visual field.  These results together suggest that (1) adversarially robust representations capture peripheral computation better than non-robust representations and (2) robust representations capture peripheral computation similar to current state-of-the-art texture peripheral vision models. More broadly, our findings support the idea that localized texture summary statistic representations may drive human invariance to adversarial perturbations and that the incorporation of such representations in DNNs could give rise to useful properties like adversarial robustness.",
    "One-sentence Summary": "We suggest that the representations learned by an Adversarially Trained Network are aligned with Human Peripheral Computation"
  },
  {
    "title": "Omni-Dimensional Dynamic Convolution",
    "url": "/forum?id=DmpCfq6Mg39",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Convolutional Neural Networks, Dynamic Convolution, Attention, Image Classification",
    "Abstract": "Learning a single static convolutional kernel in each convolutional layer is the common training paradigm of modern Convolutional Neural Networks (CNNs). Instead, recent research in dynamic convolution shows that learning a linear combination of n convolutional kernels weighted with their input-dependent attentions can significantly improve the accuracy of light-weight CNNs, while maintaining efficient inference. However, we observe that existing works endow convolutional kernels with the dynamic property through one dimension (regarding the convolutional kernel number) of the kernel space, but the other three dimensions (regarding the spatial size, the input channel number and the output channel number for each convolutional kernel) are overlooked. Inspired by this, we present Omni-dimensional Dynamic Convolution (ODConv), a more generalized yet elegant dynamic convolution design, to advance this line of research. ODConv leverages a novel multi-dimensional attention mechanism with a parallel strategy to learn complementary attentions for convolutional kernels along all four dimensions of the kernel space at any convolutional layer. As a drop-in replacement of regular convolutions, ODConv can be plugged into many CNN architectures. Extensive experiments on the ImageNet and MS-COCO datasets show that ODConv brings solid accuracy boosts for various prevailing CNN backbones including both light-weight and large ones, e.g., 3.77%~5.71%|1.86%~3.72% absolute top-1 improvements to MobivleNetV2|ResNet family on the ImageNet dataset. Intriguingly, thanks to its improved feature learning ability, ODConv with even one single kernel can compete with or outperform existing dynamic convolution counterparts with multiple kernels, substantially reducing extra parameters. Furthermore, ODConv is also superior to other attention modules for modulating the output features or the convolutional weights. Code and models will be available at https://github.com/OSVAI/ODConv.",
    "One-sentence Summary": "This paper presents Omni-dimensional Dynamic Convolution (ODConv) to advance the research in dynamic convolution."
  },
  {
    "title": "EViT: Expediting Vision Transformers via Token Reorganizations",
    "url": "/forum?id=BjyvwnXXVn_",
    "date": "28 Sept 2021 (modified: 17 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Vision Transformers, multi-head self-attention, efficient inference",
    "Abstract": "Vision Transformers (ViTs) take all the image patches as tokens and construct multi-head self-attention (MHSA) among them. Complete leverage of these image tokens brings redundant computations since not all the tokens are attentive in MHSA. Examples include that tokens containing semantically meaningless or distractive image backgrounds do not positively contribute to the ViT predictions. In this work, we propose to reorganize image tokens during the feed-forward process of ViT models, which is integrated into ViT during training. For each forward inference, we identify the attentive image tokens between MHSA and FFN (i.e., feed-forward network) modules, which is guided by the corresponding class token attention. Then, we reorganize image tokens by preserving attentive image tokens and fusing inattentive ones to expedite subsequent MHSA and FFN computations. To this end, our method EViT improves ViTs from two perspectives. First, under the same amount of input image tokens, our method reduces MHSA and FFN computation for efficient inference. For instance, the inference speed of DeiT-S is increased by 50% while its recognition accuracy is decreased by only 0.3% for ImageNet classification. Second, by maintaining the same computational cost, our method empowers ViTs to take more image tokens as input for recognition accuracy improvement, where the image tokens are from higher resolution images. An example is that we improve the recognition accuracy of DeiT-S by 1% for ImageNet classification at the same computational cost of a vanilla DeiT-S. Meanwhile, our method does not introduce more parameters to ViTs. Experiments on the standard benchmarks show the effectiveness of our method. The code is available at https://github.com/youweiliang/evit",
    "One-sentence Summary": "We propose to reorganize attentive tokens in Vision Transformers to expedite inference speed."
  },
  {
    "title": "D-CODE: Discovering Closed-form ODEs from Observed Trajectories",
    "url": "/forum?id=wENMvIsxNN",
    "date": "28 Sept 2021 (modified: 19 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Symbolic Regression, Ordinary Differential Equation",
    "Abstract": "For centuries, scientists have manually designed closed-form ordinary differential equations (ODEs) to model dynamical systems. An automated tool to distill closed-form ODEs from observed trajectories would accelerate the modeling process. Traditionally, symbolic regression is used to uncover a closed-form prediction function $a=f(b)$ with label-feature pairs $(a_i, b_i)$ as training examples. However, an ODE models the time derivative $\\dot{x}(t)$ of a dynamical system, e.g. $\\dot{x}(t) = f(x(t),t)$, and the \"label\" $\\dot{x}(t)$ is usually *not* observed. The existing ways to bridge this gap only perform well for a narrow range of settings with low measurement noise, frequent sampling, and non-chaotic dynamics. In this work, we propose the Discovery of Closed-form ODE framework (D-CODE), which advances symbolic regression beyond the paradigm of supervised learning. D-CODE leverages a novel objective function based on the variational formulation of ODEs to bypass the unobserved time derivative. For formal justification, we prove that this objective is a valid proxy for the estimation error of the true (but unknown) ODE. In the experiments, D-CODE successfully discovered the governing equations of a diverse range of dynamical systems under challenging measurement settings with high noise and infrequent sampling."
  },
  {
    "title": "Spanning Tree-based Graph Generation for Molecules",
    "url": "/forum?id=w60btE_8T2m",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "molecule generation, tree generation, graph generation, deep generative model, de novo drug design",
    "Abstract": "In this paper, we explore the problem of generating molecules using deep neural networks, which has recently gained much interest in chemistry. To this end, we propose a spanning tree-based graph generation (STGG) framework based on formulating molecular graph generation as a construction of a spanning tree and the residual edges. Such a formulation exploits the sparsity of molecular graphs and allows using compact tree-constructive operations to define the molecular graph connectivity. Based on the intermediate graph structure of the construction process, our framework can constrain its generation to molecular graphs that satisfy the chemical valence rules. We also newly design a Transformer architecture with tree-based relative positional encodings for realizing the tree construction procedure. Experiments on QM9, ZINC250k, and MOSES benchmarks verify the effectiveness of the proposed framework in metrics such as validity, Frechet ChemNet distance, and fragment similarity. We also demonstrate the usefulness of STGG in maximizing penalized LogP value of molecules.",
    "One-sentence Summary": "We propose a new molecular graph generative model based on compact tree constructive operators."
  },
  {
    "title": "Policy improvement by planning with Gumbel",
    "url": "/forum?id=bERaNdoegnO",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "AlphaZero, MuZero, reinforcement learning",
    "Abstract": "AlphaZero is a powerful reinforcement learning algorithm based on approximate policy iteration and tree search. However, AlphaZero can fail to improve its policy network, if not visiting all actions at the root of a search tree. To address this issue, we propose a policy improvement algorithm based on sampling actions without replacement. Furthermore, we use the idea of policy improvement to replace the more heuristic mechanisms by which AlphaZero selects and uses actions, both at root nodes and at non-root nodes. Our new algorithms, Gumbel AlphaZero and Gumbel MuZero, respectively without and with model-learning, match the state of the art on Go, chess, and Atari, and significantly improve prior performance when planning with few simulations.",
    "One-sentence Summary": "We redesign AlphaZero to keep improving even when training with a small number of simulations."
  },
  {
    "title": "Learning Optimal Conformal Classifiers",
    "url": "/forum?id=t8O-4LKFVx",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "conformal prediction, conformal classification, uncertainty estimation",
    "Abstract": "Modern deep learning based classifiers show very high accuracy on test data but this does not provide sufficient guarantees for safe deployment, especially in high-stake AI applications such as medical diagnosis. Usually, predictions are obtained without a reliable uncertainty estimate or a formal guarantee. Conformal prediction (CP) addresses these issues by using the classifier's predictions, e.g., its probability estimates, to predict confidence sets containing the true class with a user-specified probability. However, using CP as a separate processing step after training prevents the underlying model from adapting to the prediction of confidence sets. Thus, this paper explores strategies to differentiate through CP during training with the goal of training model with the conformal wrapper end-to-end. In our approach, conformal training (ConfTr), we specifically \"simulate\" conformalization on mini-batches during training. Compared to standard training, ConfTr reduces the average confidence set size (inefficiency) of state-of-the-art CP methods applied after training. Moreover, it allows to \"shape\" the confidence sets predicted at test time, which is difficult for standard CP. On experiments with several datasets, we show ConfTr can influence how inefficiency is distributed across classes, or guide the composition of confidence sets in terms of the included classes, while retaining the guarantees offered by CP.",
    "One-sentence Summary": "Conformal training allows to train classifier and conformal predictor end-to-end, optimizing average confidence set size (inefficiency) or other application-specific losses defined on confidence sets."
  },
  {
    "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
    "url": "/forum?id=9Vrb9D0WI4",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Large language models have recently been shown to attain reasonable zero-shot generalization on a diverse set of tasks (Brown et al., 2020). It has been hypothesized that this is a consequence of implicit multitask learning in language models\u2019 pretraining (Radford et al., 2019). Can zero-shot generalization instead be directly induced by explicit multitask learning? To test this question at scale, we develop a system for easily mapping any natural language tasks into a human-readable prompted form. We convert a large set of supervised datasets, each with multiple prompts with diverse wording. These prompted datasets allow for benchmarking the ability of a model to perform completely unseen tasks specified in natural language. We fine-tune a pretrained encoder-decoder model (Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a wide variety of tasks. The model attains strong zero-shot performance on several datasets, often outperforming models 16\u00d7 its size. Further, our model attains strong performance on a subset of tasks from the BIG-Bench benchmark, outperforming models 6\u00d7 its size. All trained models are available at https://github.com/bigscience-workshop/t-zero, and all prompts are available at https://github.com/bigscience-workshop/promptsource."
  },
  {
    "title": "Continuous-Time Meta-Learning with Forward Mode Differentiation",
    "url": "/forum?id=57PipS27Km",
    "date": "28 Sept 2021 (modified: 02 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "meta-learning, few-shot learning, dynamical systems",
    "Abstract": "Drawing inspiration from gradient-based meta-learning methods with infinitely small gradient steps, we introduce Continuous-Time Meta-Learning (COMLN), a meta-learning algorithm where adaptation follows the dynamics of a gradient vector field. Specifically, representations of the inputs are meta-learned such that a task-specific linear classifier is obtained as a solution of an ordinary differential equation (ODE). Treating the learning process as an ODE offers the notable advantage that the length of the trajectory is now continuous, as opposed to a fixed and discrete number of gradient steps. As a consequence, we can optimize the amount of adaptation necessary to solve a new task using stochastic gradient descent, in addition to learning the initial conditions as is standard practice in gradient-based meta-learning. Importantly, in order to compute the exact meta-gradients required for the outer-loop updates, we  devise an efficient algorithm based on forward mode differentiation, whose memory requirements do not scale with the length of the learning trajectory, thus allowing longer adaptation in constant memory. We provide analytical guarantees for the stability of COMLN, we show empirically its efficiency in terms of runtime and memory usage, and we illustrate its effectiveness on a range of few-shot image classification problems.",
    "One-sentence Summary": "COMLN is a new meta-learning algorithm, where adaptation follows a gradient flow. It enables learning the amount of adaptation using SGD. We devise a novel efficient algorithm to compute the meta-gradients of COMLN, based on forward-mode diff."
  },
  {
    "title": "On the relation between statistical learning and perceptual distances",
    "url": "/forum?id=zXM0b4hi5_B",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "It has been demonstrated many times that the behavior of the human visual system is connected to the statistics of natural images. Since machine learning relies on the statistics of training data as well, the above connection has interesting implications when using perceptual distances (which mimic the behavior of the human visual system) as a loss function. In this paper, we aim to unravel the non-trivial relationships between the probability distribution of the data, perceptual distances, and unsupervised machine learning. To this end, we show that perceptual sensitivity is correlated with the probability of an image in its close neighborhood. We also explore the relation between distances induced by autoencoders and the probability distribution of the training data, as well as how these induced distances are correlated with human perception. Finally, we find perceptual distances do not always lead to noticeable gains in performance over Euclidean distance in common image processing tasks, except when data is scarce and the perceptual distance provides regularization. We propose this may be due to a double-counting effect of the image statistics, once in the perceptual distance and once in the training procedure."
  },
  {
    "title": "Implicit Bias of Projected Subgradient Method Gives Provable Robust Recovery of Subspaces of Unknown Codimension",
    "url": "/forum?id=vA7doMdgi75",
    "date": "28 Sept 2021 (modified: 16 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "representation learning, robust subspace recovery, dual principals component pursuit, outliers, model selection",
    "Abstract": "Robust subspace recovery (RSR) is the problem of learning a subspace from sample data points corrupted by outliers. Dual Principal Component Pursuit (DPCP) is a robust subspace recovery method that aims to find a basis for the orthogonal complement of the subspace by minimizing the sum of the distances of the points to the subspaces subject to orthogonality constraints on the basis. Prior work has shown that DPCP can provably recover the correct subspace in the presence of outliers as long as the true dimension of the subspace is known. In this paper, we show that if the orthogonality constraints --adopted in previous DPCP formulations-- are relaxed and random initialization is used instead of spectral one, DPCP can provably recover a subspace of \\emph{unknown dimension}. Specifically, we propose a very simple algorithm based on running multiple instances of a projected sub-gradient descent method (PSGM), with each problem instance seeking to find one vector in the null space of the subspace. We theoretically prove that under mild conditions this approach succeeds with high probability. In particular, we show that 1) all of the problem instances will converge to a vector in the nullspace of the subspace and 2) the ensemble of problem instance solutions will be sufficiently diverse to fully span the nullspace of the subspace thus also revealing its true unknown codimension. We provide empirical results that corroborate our theoretical results and showcase the remarkable implicit rank regularization behavior of the PSGM algorithm that allows us to perform RSR without knowing the subspace dimension",
    "One-sentence Summary": "We study the robust subspace recovery problem when subspace codimension is unknown."
  },
  {
    "title": "On the Optimal Memorization Power of ReLU Neural Networks",
    "url": "/forum?id=MkTPtnjeYTV",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Expressivness, Memorization, Theory, VC-dimension, Deep learning theory",
    "Abstract": "We study the memorization power of feedforward ReLU neural networks. We show that such networks can memorize any $N$ points that satisfy a mild separability assumption using $\\tilde{O}\\left(\\sqrt{N}\\right)$ parameters. Known VC-dimension upper bounds imply that memorizing $N$ samples requires $\\Omega(\\sqrt{N})$ parameters, and hence our construction is optimal up to logarithmic factors. We also give a generalized construction for networks with depth bounded by $1 \\leq L \\leq \\sqrt{N}$, for memorizing $N$ samples using $\\tilde{O}(N/L)$ parameters. This bound is also optimal up to logarithmic factors. Our construction uses weights with large bit complexity. We prove that having such a large bit complexity is both necessary and sufficient for memorization with a sub-linear number of parameters.",
    "One-sentence Summary": "We show that ReLU neural networks can memorize N samples using \\sqrt{N} parameters, and prove that up to logarithmic terms this is the optimal solution."
  },
  {
    "title": "Programmatic Reinforcement Learning without Oracles",
    "url": "/forum?id=6Tk2noBdvxt",
    "date": "28 Sept 2021 (modified: 10 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement Learning, Programmatic Reinforcement Learning, Compositional Reinforcement Learning, Program Synthesis, Differentiable Architecture Search",
    "Abstract": "Deep reinforcement learning (RL) has led to encouraging successes in many challenging control tasks. However, a deep RL model lacks interpretability due to the difficulty of identifying how the model's control logic relates to its network structure. Programmatic policies structured in more interpretable representations emerge as a promising solution. Yet two shortcomings remain: First, synthesizing programmatic policies requires optimizing over the discrete and non-differentiable search space of program architectures. Previous works are suboptimal because they only enumerate program architectures greedily guided by a pretrained RL oracle. Second, these works do not exploit compositionality, an important programming concept, to reuse and compose primitive functions to form a complex function for new tasks. Our first contribution is a programmatically interpretable RL framework that conducts program architecture search on top of a continuous relaxation of the architecture space defined by programming language grammar rules. Our algorithm allows policy architectures to be learned with policy parameters via bilevel optimization using efficient policy-gradient methods, and thus does not require a pretrained oracle. Our second contribution is improving programmatic policies to support compositionality by integrating primitive functions learned to grasp task-agnostic skills as a composite program to solve novel RL problems. Experiment results demonstrate that our algorithm excels in discovering optimal programmatic policies that are highly interpretable. The code of this work is available at https://github.com/RU-Automated-Reasoning-Group/pi-PRL.",
    "One-sentence Summary": "We present a differentiable program architecture search framework to synthesize interpretable, generalizable, and compositional programs for controlling reinforcement learning applications."
  },
  {
    "title": "When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
    "url": "/forum?id=LtKcMgGOeLt",
    "date": "28 Sept 2021 (modified: 11 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Vision Transformers, Optimization",
    "Abstract": "Vision Transformers (ViTs) and MLPs signal further efforts on replacing hand-wired features or inductive biases with general-purpose neural architectures. Existing works empower the models by massive data, such as large-scale pre-training and/or repeated strong data augmentations, and still report optimization-related problems (e.g., sensitivity to initialization and learning rates). Hence, this paper investigates ViTs and MLP-Mixers from the lens of loss geometry, intending to improve the models' data efficiency at training and generalization at inference. Visualization and Hessian reveal extremely sharp local minima of converged models. By promoting smoothness with a recently proposed sharpness-aware optimizer, we substantially improve the accuracy and robustness of ViTs and MLP-Mixers on various tasks spanning supervised, adversarial, contrastive, and transfer learning (e.g., +5.3\\% and +11.0\\% top-1 accuracy on ImageNet for ViT-B/16 and Mixer-B/16, respectively, with the simple Inception-style preprocessing). We show that the improved smoothness attributes to sparser active neurons in the first few layers. The resultant ViTs outperform ResNets of similar size and throughput when trained from scratch on ImageNet without large-scale pre-training or strong data augmentations. Model checkpoints are available at \\url{https://github.com/google-research/vision_transformer}."
  },
  {
    "title": "Online Hyperparameter Meta-Learning with Hypergradient Distillation",
    "url": "/forum?id=01AMRlen9wJ",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Hyperparameter Optimization, Meta-learning",
    "Abstract": "Many gradient-based meta-learning methods assume a set of parameters that do not participate in inner-optimization, which can be considered as hyperparameters. Although such hyperparameters can be optimized using the existing gradient-based hyperparameter optimization (HO) methods, they suffer from the following issues. Unrolled differentiation methods do not scale well to high-dimensional hyperparameters or horizon length, Implicit Function Theorem (IFT) based methods are restrictive for online optimization, and short horizon approximations suffer from short horizon bias. In this work, we propose a novel HO method that can overcome these limitations, by approximating the second-order term with knowledge distillation. Specifically, we parameterize a single Jacobian-vector product (JVP) for each HO step and minimize the distance from the true second-order term. Our method allows online optimization and also is scalable to the hyperparameter dimension and the horizon length. We demonstrate the effectiveness of our method on three different meta-learning methods and two benchmark datasets.",
    "One-sentence Summary": "We propose a gradient-based hyperparameter optimization method based on the idea of knowledge distillation, which is fully online and applicable to high-dimensional hyperparameters."
  },
  {
    "title": "Tighter Sparse Approximation Bounds for ReLU Neural Networks",
    "url": "/forum?id=LBvk4QWIUpm",
    "date": "28 Sept 2021 (modified: 12 Nov 2021)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "neural network, two-layer, infinite-width, approximation, sparse, Radon transform, Fourier transform, ReLU",
    "Abstract": "A well-known line of work (Barron, 1993; Breiman, 1993; Klusowski & Barron, 2018) provides bounds on the width $n$ of a ReLU two-layer neural network needed to approximate a function $f$ over the ball $\\mathcal{B}_R(\\mathbb{R}^d)$ up to error $\\epsilon$, when the Fourier based quantity $C_f = \\int_{\\mathbb{R}^d} \\|\\xi\\|^2 |\\hat{f}(\\xi)| \\ d\\xi$ is finite. More recently Ongie et al. (2019) used the Radon transform as a tool for analysis of infinite-width ReLU two-layer networks. In particular, they introduce the concept of Radon-based $\\mathcal{R}$-norms and show that a function defined on $\\mathbb{R}^d$ can be represented as an infinite-width two-layer neural network if and only if its $\\mathcal{R}$-norm is finite. In this work, we extend the framework of Ongie et al. (2019) and define similar Radon-based semi-norms ($\\mathcal{R}, \\mathcal{U}$-norms) such that a function admits an infinite-width neural network representation on a bounded open set $\\mathcal{U} \\subseteq \\mathbb{R}^d$ when its $\\mathcal{R}, \\mathcal{U}$-norm is finite. Building on this, we derive sparse (finite-width) neural network approximation bounds that refine those of Breiman (1993); Klusowski & Barron (2018). Finally, we show that infinite-width neural network representations on bounded open sets are not unique and study their structure, providing a functional view of mode connectivity.",
    "One-sentence Summary": "We show conditions under which a function can be represented by an infinite-width neural network on a bounded set, and refine sparse neural network approximation bounds."
  },
  {
    "title": "Long Expressive Memory for Sequence Modeling",
    "url": "/forum?id=vwj6aUeocyf",
    "date": "28 Sept 2021 (modified: 26 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "sequence modeling, long-term dependencies, multiscale ordinary differential equations, dynamical systems",
    "Abstract": "We propose a novel method called Long Expressive Memory (LEM) for learning long-term sequential dependencies. LEM is gradient-based, it can efficiently process sequential tasks with very long-term dependencies, and it is sufficiently expressive to be able to learn complicated input-output maps. To derive LEM, we consider a system of multiscale ordinary differential equations, as well as a suitable time-discretization of this system. For LEM, we derive rigorous bounds to show the mitigation of the exploding and vanishing gradients problem, a well-known challenge for gradient-based recurrent sequential learning methods. We also prove that LEM can approximate a large class of dynamical systems to high accuracy. Our empirical results, ranging from image and time-series classification through dynamical systems prediction to speech recognition and language modeling, demonstrate that LEM outperforms state-of-the-art recurrent neural networks, gated recurrent units, and long short-term memory models.",
    "One-sentence Summary": "A novel method for sequence modeling based on multiscale ODEs that is provably able to learn very long-term dependencies while being sufficiently expressive to outperform state-of-the-art recurrent sequence models."
  },
  {
    "title": "Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy",
    "url": "/forum?id=LzQQ89U1qm_",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Time series anomaly detection, Transformers, Anomaly attention, Association discrepancy",
    "Abstract": "Unsupervised detection of anomaly points in time series is a challenging problem, which requires the model to derive a distinguishable criterion. Previous methods tackle the problem mainly through learning pointwise representation or pairwise association, however, neither is sufficient to reason about the intricate dynamics. Recently, Transformers have shown great power in unified modeling of pointwise representation and pairwise association, and we find that the self-attention weight distribution of each time point can embody rich association with the whole series. Our key observation is that due to the rarity of anomalies, it is extremely difficult to build nontrivial associations from abnormal points to the whole series, thereby, the anomalies' associations shall mainly concentrate on their adjacent time points. This adjacent-concentration bias implies an association-based criterion inherently distinguishable between normal and abnormal points, which we highlight through the Association Discrepancy. Technically, we propose the Anomaly Transformer with a new Anomaly-Attention mechanism to compute the association discrepancy. A minimax strategy is devised to amplify the normal-abnormal distinguishability of the association discrepancy. The Anomaly Transformer achieves state-of-the-art results on six unsupervised time series anomaly detection benchmarks of three applications: service monitoring, space & earth exploration, and water treatment.",
    "One-sentence Summary": "This paper detects time series anomalies from a new association-based dimension. We find an inherently normal-abnormal distinguishable evidence as Association Discrepancy. Co-designed with this evidence, our model achieves the SOTA on six benchmarks."
  },
  {
    "title": "Progressive Distillation for Fast Sampling of Diffusion Models",
    "url": "/forum?id=TIdIXIpzhoI",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Diffusion Models, Generative Models, fast sampling",
    "Abstract": "Diffusion models have recently shown great promise for generative modeling, outperforming GANs on perceptual quality and autoregressive models at density estimation. A remaining downside is their slow sampling time: generating high quality samples takes many hundreds or thousands of model evaluations. Here we make two contributions to help eliminate this downside: First, we present new parameterizations of diffusion models that provide increased stability when using few sampling steps, compared to models in the literature. Second, we present a method to distill a trained deterministic diffusion sampler, using many steps, into a new diffusion model that takes half as many sampling steps. We then keep progressively applying this distillation procedure to our model, halving the number of required sampling steps each time. On standard image generation benchmarks like CIFAR-10, ImageNet, and LSUN, we start out with (near) state-of-the-art samplers taking 1024 or 8192 steps, and are able to distill down to models taking as little as 4 steps without losing much perceptual quality; achieving, for example, a FID of 3.0 on CIFAR-10 in 4 steps. Finally, we show that the full progressive distillation procedure does not take more time than it takes to train the original model, thus representing an efficient solution for generative modeling using diffusion at both train and test time.",
    "One-sentence Summary": "Diffusion models now need just 4 sampling steps to produce high quality samples."
  },
  {
    "title": "A General Analysis of Example-Selection for Stochastic Gradient Descent",
    "url": "/forum?id=7gWSJrP3opB",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Training example order in SGD has long been known to affect convergence rate. Recent results show that accelerated rates are possible in a variety of cases for permutation-based sample orders, in which each example from the training set is used once before any example is reused. In this paper, we develop a broad condition on the sequence of examples used by SGD that is sufficient to prove tight convergence rates in both strongly convex and non-convex settings. We show that our approach suffices to recover, and in some cases improve upon, previous state-of-the-art analyses for four known example-selection schemes: (1) shuffle once, (2) random reshuffling, (3) random reshuffling with data echoing, and (4) Markov Chain Gradient Descent. Motivated by our theory, we propose two new example-selection approaches. First, using quasi-Monte-Carlo methods, we achieve unprecedented accelerated convergence rates for learning with data augmentation. Second, we greedily choose a fixed scan-order to minimize the metric used in our condition and show that we can obtain more accurate solutions from the same number of epochs of SGD. We conclude by empirically demonstrating the utility of our approach for both convex linear-model and deep learning tasks. Our code is available at: https://github.com/EugeneLYC/qmc-ordering."
  },
  {
    "title": "Assessing Generalization of SGD via Disagreement",
    "url": "/forum?id=WvOGCEAQhxl",
    "date": "28 Sept 2021 (modified: 07 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Generalization, Deep Learning, Empirical Phenomenon, Accuracy Estimation, Stochastic Gradient Descent",
    "Abstract": "We empirically show that the test error of deep networks can be estimated by training the same architecture on the same training set but with two different runs of Stochastic Gradient Descent (SGD), and then measuring the disagreement rate between the two networks on unlabeled test data. This builds on -- and is a stronger version of -- the observation in Nakkiran&Bansal 20, which requires the runs to be on separate training sets. We further theoretically show that this peculiar phenomenon arises from the well-calibrated nature of ensembles of SGD-trained models. This finding not only provides a simple empirical measure to directly predict the test error using unlabeled test data, but also establishes a new conceptual connection between generalization and calibration.",
    "One-sentence Summary": "We provide a surprisingly simple technique to accurately estimate the test error of deep neural networks using unlabeled data and we prove that this works because SGD ensembles are naturally well-calibrated."
  },
  {
    "title": "Generative Planning for Temporally Coordinated Exploration in Reinforcement Learning",
    "url": "/forum?id=YZHES8wIdE",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Standard model-free reinforcement learning algorithms optimize a policy that generates the action to be taken in the current time step in order to maximize expected future return. While flexible, it faces difficulties arising from the inefficient exploration due to its single step nature. In this work, we present Generative Planning method (GPM), which can generate actions not only for the current step, but also for a number of future steps (thus termed as generative planning). This brings several benefits to GPM. Firstly,  since GPM is trained by maximizing value, the plans generated from it can be regarded as intentional action sequences for reaching high value regions. GPM can therefore leverage its generated multi-step plans for temporally coordinated exploration towards high value regions, which is potentially more effective than a sequence of actions generated by perturbing each action at single step level, whose consistent movement decays exponentially with the number of exploration steps. Secondly, starting from a crude initial plan generator, GPM can refine it to be adaptive to the task, which, in return, benefits future explorations. This is potentially more effective than commonly used action-repeat strategy, which is non-adaptive in its form of plans. Additionally, since the multi-step plan can be interpreted as the intent of the agent from now to a span of time period into the future, it offers a more informative and intuitive signal for interpretation. Experiments are conducted on several benchmark environments and the results demonstrated its effectiveness compared with several baseline methods.",
    "One-sentence Summary": "Temporally coordinated exploration in reinforcement learning using Generative Planning Method."
  },
  {
    "title": "Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning",
    "url": "/forum?id=Y4cs1Z3HnqL",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Pessimistic Bootstrapping, Bootstrapped Q-functions, Uncertainty Estimation, Offline Reinforcement Learning",
    "Abstract": "Offline Reinforcement Learning (RL) aims to learn policies from previously collected datasets without exploring the environment. Directly applying off-policy algorithms to offline RL usually fails due to the extrapolation error caused by the out-of-distribution (OOD) actions. Previous methods tackle such problem by penalizing the Q-values of OOD actions or constraining the trained policy to be close to the behavior policy. Nevertheless, such methods typically prevent the generalization of value functions beyond the offline data and also lack precise characterization of OOD data. In this paper, we propose Pessimistic Bootstrapping for offline RL (PBRL), a purely uncertainty-driven offline algorithm without explicit policy constraints. Specifically, PBRL conducts uncertainty quantification via the disagreement of bootstrapped Q-functions, and performs pessimistic updates by penalizing the value function based on the estimated uncertainty. To tackle the extrapolating error, we further propose a novel OOD sampling method. We show that such OOD sampling and pessimistic bootstrapping yields provable uncertainty quantifier in linear MDPs, thus providing the theoretical underpinning for PBRL. Extensive experiments on D4RL benchmark show that PBRL has better performance compared to the state-of-the-art algorithms.",
    "One-sentence Summary": "We propose pessimistic bootstrapping as a purely uncertainty-driven algorithm for offline Reinforcement Learning."
  },
  {
    "title": "Equivariant Subgraph Aggregation Networks",
    "url": "/forum?id=dFbKQaRk15w",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Graph Neural Networks, Expressive power, Equivariance, Weisfeiler-Leman",
    "Abstract": "Message-passing neural networks (MPNNs) are the leading architecture for deep learning on graph-structured data, in large part due to their simplicity and scalability. Unfortunately, it was shown that these architectures are limited in their expressive power. This paper proposes a novel framework called Equivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our main observation is that while two graphs may not be distinguishable by an MPNN, they often contain distinguishable subgraphs. Thus, we propose to represent each graph as a set of subgraphs derived by some predefined policy, and to process it using a suitable equivariant architecture. We develop novel variants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph isomorphism, and prove lower bounds on the expressiveness of ESAN in terms of these new WL variants. We further prove that our approach increases the expressive power of both MPNNs and more expressive architectures. Moreover, we provide theoretical results that describe how design choices such as the subgraph selection policy and equivariant neural architecture affect our architecture's expressive power. To deal with the increased computational cost, we propose a subgraph sampling scheme, which can be viewed as a stochastic version of our framework. A comprehensive set of experiments on real and synthetic datasets demonstrates that our framework improves the expressive power and overall performance of popular GNN architectures.",
    "One-sentence Summary": "We present a provably expressive graph learning framework based on representing graphs as multisets of subgraphs and processing them with an equivariant architecture."
  },
  {
    "title": "How Do Vision Transformers Work?",
    "url": "/forum?id=D78Go4hVcxO",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "vision transformer, self-attention, multi-head self-attention, loss landscape",
    "Abstract": "The success of multi-head self-attentions (MSAs) for computer vision is now indisputable. However, little is known about how MSAs work. We present fundamental explanations to help better understand the nature of MSAs. In particular, we demonstrate the following properties of MSAs and Vision Transformers (ViTs): (1) MSAs improve not only accuracy but also generalization by flattening the loss landscapes. Such improvement is primarily attributable to their data specificity, not long-range dependency. On the other hand, ViTs suffer from non-convex losses. Large datasets and loss landscape smoothing methods alleviate this problem; (2) MSAs and Convs exhibit opposite behaviors. For example, MSAs are low-pass filters, but Convs are high-pass filters. Therefore, MSAs and Convs are complementary; (3) Multi-stage neural networks behave like a series connection of small individual models. In addition, MSAs at the end of a stage play a key role in prediction. Based on these insights, we propose AlterNet, a model in which Conv blocks at the end of a stage are replaced with MSA blocks. AlterNet outperforms CNNs not only in large data regimes but also in small data regimes. The code is available at https://github.com/xxxnell/how-do-vits-work.",
    "One-sentence Summary": "We show that (1) multi-head self-attentions (MSAs) for computer vision flatten the loss landscapes, (2) MSAs are low-pass filters as opposed to Convs, and (3) MSAs at the end of a stage significantly improve the accuracy."
  },
  {
    "title": "Variational methods for simulation-based inference",
    "url": "/forum?id=kZ0UYdhqkNY",
    "date": "28 Sept 2021 (modified: 12 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "likelihood-free inference, simulation-based inference, variational inference, neural density estimation",
    "Abstract": "We present Sequential Neural Variational Inference (SNVI), an approach to perform Bayesian inference in models with intractable likelihoods. SNVI combines likelihood-estimation (or likelihood-ratio-estimation) with variational inference to achieve a scalable simulation-based inference approach. SNVI maintains the flexibility of likelihood(-ratio) estimation to allow arbitrary proposals for simulations, while simultaneously providing a functional estimate of the posterior distribution without requiring MCMC sampling. We present several variants of SNVI and demonstrate that they are substantially more computationally efficient than previous algorithms, without loss of accuracy on benchmark tasks. We apply SNVI to a neuroscience model of the pyloric network in the crab and demonstrate that it can infer the posterior distribution with one order of magnitude fewer simulations than previously reported. SNVI vastly reduces the computational cost of simulation-based inference while maintaining accuracy and flexibility, making it possible to tackle problems that were previously inaccessible.",
    "One-sentence Summary": "We combine likelihood-estimation with variational inference to achieve a scalable approach for simulation-based inference."
  },
  {
    "title": "Tackling the Generative Learning Trilemma with Denoising Diffusion GANs",
    "url": "/forum?id=JprM0p-q0Co",
    "date": "28 Sept 2021 (modified: 06 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "A wide variety of deep generative models has been developed in the past decade. Yet, these models often struggle with simultaneously addressing three key requirements including: high sample quality, mode coverage, and fast sampling. We call the challenge imposed by these requirements the generative learning trilemma, as the existing models often trade some of them for others. Particularly, denoising diffusion models have shown impressive sample quality and diversity, but their expensive sampling does not yet allow them to be applied in many real-world applications. In this paper, we argue that slow sampling in these models is fundamentally attributed to the Gaussian assumption in the denoising step which is justified only for small step sizes. To enable denoising with large steps, and hence, to reduce the total number of denoising steps, we propose to model the denoising distribution using a complex multimodal distribution. We introduce denoising diffusion generative adversarial networks (denoising diffusion GANs) that model each denoising step using a multimodal conditional GAN. Through extensive evaluations, we show that denoising diffusion GANs obtain sample quality and diversity competitive with original diffusion models while being 2000$\\times$ faster on the CIFAR-10 dataset. Compared to traditional GANs, our model exhibits better mode coverage and sample diversity. To the best of our knowledge, denoising diffusion GAN is the first model that reduces sampling cost in diffusion models to an extent that allows them to be applied to real-world applications inexpensively.",
    "One-sentence Summary": "To reduce the number of sampling steps in diffusion models, we propose to model the denoising distribution with conditional GANs. We show our model tackles the generative learning trilemma & achieves high sample quality, diversity & fast sampling."
  },
  {
    "title": "Imbedding Deep Neural Networks",
    "url": "/forum?id=yKIAXjkJc2F",
    "date": "28 Sept 2021 (modified: 15 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Neural ODEs, Optimal Control, Deep Neural Networks, Invariant Imbedding",
    "Abstract": "Continuous-depth neural networks, such as Neural ODEs, have refashioned the understanding of residual neural networks in terms of non-linear vector-valued optimal control problems. The common solution is to use the adjoint sensitivity method to replicate a forward-backward pass optimisation problem. We propose a new approach which explicates the network's `depth' as a fundamental variable, thus reducing the problem to a system of forward-facing initial value problems. This new method is based on the principal of `Invariant Imbedding' for which we prove a general solution, applicable to all non-linear, vector-valued optimal control problems with both running and terminal loss.\n        Our new architectures provide a tangible tool for inspecting the theoretical--and to a great extent unexplained--properties of network depth. They also constitute a resource of discrete implementations of Neural ODEs comparable to classes of imbedded residual neural networks. Through a series of experiments, we show the competitive performance of the proposed architectures for supervised learning and time series prediction.",
    "One-sentence Summary": "Invariant imbedding solution for (Bolza) optimal control problem derived and proved to yield new architectures of imbedded deep neural networks."
  },
  {
    "title": "Understanding and Preventing Capacity Loss in Reinforcement Learning",
    "url": "/forum?id=ZkC8wKoLbQ7",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Reinforcement learning, representation learning",
    "Abstract": "The reinforcement learning (RL) problem is rife with sources of non-stationarity that can destabilize or inhibit learning progress.\n        We identify a key mechanism by which this occurs in agents using neural networks as function approximators: \\textit{capacity loss}, whereby networks trained to predict a sequence of target values lose their ability to quickly fit new functions over time.\n        We demonstrate that capacity loss occurs in a broad range of RL agents and environments, and is particularly damaging to learning progress in sparse-reward tasks. We then present a simple regularizer, Initial Feature Regularization (InFeR), that mitigates this phenomenon by regressing a subspace of features towards its value at initialization, improving performance over a state-of-the-art model-free algorithm in the Atari 2600 suite. Finally, we study how this regularization affects different notions of capacity and evaluate other mechanisms by which it may improve performance.",
    "One-sentence Summary": "We show that RL agents experience representation collapse in sparse reward environments and propose an auxiliary task that prevents this from happening and outperforms the state of the art on the Atari benchmark."
  },
  {
    "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration",
    "url": "/forum?id=1JDiK_TbV4S",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Transfer learning, dataset shift, unsupervised domain adaptation, source-free domain adaptation",
    "Abstract": "Source-free domain adaptation (SFDA) aims to adapt a model trained on labelled data in a source domain to unlabelled data in a target domain without access to the source-domain data during adaptation. Existing methods for SFDA leverage entropy-minimization techniques which: (i) apply only to classification; (ii) destroy model calibration; and (iii) rely on the source model achieving a good level of feature-space class-separation in the target domain. We address these issues for a particularly pervasive type of domain shift called measurement shift which can be resolved by restoring the source features rather than extracting new ones. In particular, we propose Feature Restoration (FR) wherein we: (i) store a lightweight and flexible approximation of the feature distribution under the source data; and (ii) adapt the feature-extractor such that the approximate feature distribution under the target data realigns with that saved on the source. We additionally propose a bottom-up training scheme which boosts performance, which we call Bottom-Up Feature Restoration (BUFR). On real and synthetic data, we demonstrate that BUFR outperforms existing SFDA methods in terms of accuracy, calibration, and data efficiency, while being less reliant on the performance of the source model in the target domain.",
    "One-sentence Summary": "We identify a type of domain shift which can be resolved by restoring the *same* features and address it in the source-free setting by using softly-binned histograms to cheaply and flexibly align the marginal feature distributions."
  },
  {
    "title": "The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design",
    "url": "/forum?id=lnEaqbTJIRz",
    "date": "28 Sept 2021 (modified: 08 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Language Modeling, Pretraining, Self-attention, Transformers, Expressivity, Separation Rank, Sentence Embeddings",
    "Abstract": "Pretraining Neural Language Models (NLMs) over a large corpus involves chunking the text into training examples, which are contiguous text segments of sizes processable by the neural architecture. We highlight a bias introduced by this common practice: we prove that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segments that appeared in different training examples. This intuitive result has a twofold role. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine-tuning stages, which do not necessarily appear related at first glance. Second, our result clearly indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks. As an example, we propose ``kNN-Pretraining\": we show that including semantically related non-neighboring sentences in the same pretraining example yields improved sentence representations and open domain question answering abilities.\tThis theoretically motivated degree of freedom for pretraining example design indicates new training schemes for self-improving representations.",
    "One-sentence Summary": "We prove that pertained LMs model stronger dependencies between sentences that were shown in same training example, thus indicating benefits of better informed \"pretraining example design\""
  },
  {
    "title": "Emergent Communication at Scale",
    "url": "/forum?id=AUGBfDIV9rL",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "emergent communication, multi-agent reinforcement learning, representation learning",
    "Abstract": "Emergent communication aims for a better understanding of human language evolution and building more efficient representations. We posit that reaching these goals will require scaling up, in contrast to a significant amount of literature that focuses on setting up small-scale problems to tease out desired properties of the emergent languages. We focus on three independent aspects to scale up, namely the dataset, task complexity, and population size. We provide a first set of results for large populations solving complex tasks on realistic large-scale datasets, as well as an easy-to-use codebase to enable further experimentation. In more complex tasks and datasets, we find that RL training can become unstable, but responds well to established stabilization techniques.\n        We also identify the need for a different metric than topographic similarity, which does not correlate with the generalization performances when working with natural images. In this context, we probe ease-of-learnability and transfer methods to assess emergent languages. Finally, we observe that larger populations do not induce robust emergent protocols with high generalization performance, leading us to explore different ways to leverage population, through voting and imitation learning.",
    "One-sentence Summary": "This work argues the importance of scaling up the emergent communication framework and investigates the impact of three scaling up aspects, namely the dataset, task complexity, and population size."
  },
  {
    "title": "Superclass-Conditional Gaussian Mixture Model For Learning Fine-Grained Embeddings",
    "url": "/forum?id=vds4SNooOe",
    "date": "28 Sept 2021 (modified: 11 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Deep learning, represenation learning, generative model",
    "Abstract": "Learning fine-grained embeddings is essential for extending the generalizability of models pre-trained on \"coarse\" labels (e.g., animals). It is crucial to fields for which fine-grained labeling (e.g., breeds of animals) is expensive, but fine-grained prediction is desirable, such as medicine. The dilemma necessitates adaptation of a \"coarsely\" pre-trained model to new tasks with a few \"finer-grained\" training labels. However, coarsely supervised pre-training tends to suppress intra-class variation, which is vital for cross-granularity adaptation. In this paper, we develop a training framework underlain by a novel superclass-conditional Gaussian mixture model (SCGM). SCGM imitates the generative process of samples from hierarchies of classes through latent variable modeling of the fine-grained subclasses. The framework is agnostic to the encoders and only adds a few distribution related parameters, thus is efficient, and flexible to different domains. The model parameters are learned end-to-end by maximum-likelihood estimation via a principled Expectation-Maximization algorithm. Extensive experiments on benchmark datasets and a real-life medical dataset indicate the effectiveness of our method.",
    "One-sentence Summary": "We propose a training framework characterized by a novel superclass conditional Gaussian mixture (SCGM) based generative model for learning fine-grained representations for cross-granularity adaptation."
  },
  {
    "title": "SHINE: SHaring the INverse Estimate from the forward pass for bi-level optimization and implicit models",
    "url": "/forum?id=-ApAkox5mp",
    "date": "28 Sept 2021 (modified: 10 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "implicit models, bi-level optimization, quasi-newton methods",
    "Abstract": "In recent years, implicit deep learning has emerged as a method to increase the depth of deep neural networks. While their training is memory-efficient, they are still significantly slower to train than their explicit counterparts. In Deep Equilibrium Models~(DEQs), the training is performed as a bi-level problem, and its computational complexity is partially driven by the iterative inversion of a huge Jacobian matrix. In this paper, we propose a novel strategy to tackle this computational bottleneck from which many bi-level problems suffer. The main idea is to use the quasi-Newton matrices from the forward pass to efficiently approximate the inverse Jacobian matrix in the direction needed for the gradient computation. We provide a theorem that motivates using our method with the original forward algorithms. In addition, by modifying these forward algorithms, we further provide theoretical guarantees that our method asymptotically estimates the true implicit gradient. We empirically study this approach in many settings, ranging from hyperparameter optimization to large Multiscale DEQs applied to CIFAR and ImageNet. We show that it reduces the computational cost of the backward pass by up to two orders of magnitude. All this is achieved while retaining the excellent performance of the original models in hyperparameter optimization and on CIFAR, and giving encouraging and competitive results on ImageNet.",
    "One-sentence Summary": "Use the approximate Jacobian matrix computed in quasi-Newton methods to perform the inversion needed in the training of implicit models."
  },
  {
    "title": "Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality",
    "url": "/forum?id=ccWaPGl9Hq",
    "date": "28 Sept 2021 (modified: 03 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "reinforcement learning theory, deployment efficiency, linear MDP",
    "Abstract": "Deployment efficiency is an important criterion for many real-world applications of reinforcement learning (RL). Despite the community's increasing interest, there lacks a formal theoretical formulation for the problem. In this paper, we propose such a formulation for deployment-efficient RL (DE-RL) from an ''optimization with constraints'' perspective: we are interested in exploring an MDP and obtaining a near-optimal policy within minimal \\emph{deployment complexity}, whereas in each deployment the policy can sample a large batch of data. Using finite-horizon linear MDPs as a concrete structural model, we reveal the fundamental limit in achieving deployment efficiency by establishing information-theoretic lower bounds, and provide algorithms that achieve the optimal deployment efficiency. Moreover, our formulation for DE-RL is flexible and can serve as a building block for other practically relevant settings; we give ''Safe DE-RL'' and ''Sample-Efficient DE-RL'' as two examples, which may be worth future investigation.",
    "One-sentence Summary": "We propose a formal theoretical formulation for depolyment-efficient reinforcement learning; establish lower bounds for deployment complexity and study near-optimal deployment-efficient algorithms in linear MDP setting."
  },
  {
    "title": "Task Relatedness-Based Generalization Bounds for Meta Learning",
    "url": "/forum?id=A3HHaEdqAJL",
    "date": "28 Sept 2021 (modified: 01 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "Supposing the $n$ training tasks and the new task are sampled from the same environment, traditional meta learning theory derives an error bound on the expected loss over the new task in terms of the empirical training loss, uniformly over the set of all hypothesis spaces. However, there is still little research on how the relatedness of these tasks can affect the full utilization of all $mn$ training data (with $m$ examples per task). In this paper, we propose to address this problem by defining a new notion of task relatedness according to the existence of the bijective transformation between two tasks. A novel generalization bound of $\\mathcal{O}(\\frac{1}{\\sqrt{mn}})$ for meta learning is thus derived by exploiting the proposed task relatedness. Moreover, when investigating a special branch of meta learning that involves representation learning with deep neural networks, we establish spectrally-normalized bounds for both classification and regression problems. Finally, we demonstrate that the relatedness requirement between two tasks is satisfied when the sample space possesses the completeness and separability properties, validating the rationality and applicability of our proposed task-relatedness measure."
  },
  {
    "title": "IntSGD: Adaptive Floatless Compression of Stochastic Gradients",
    "url": "/forum?id=pFyXqxChZc",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "optimization, distributed optimization, compression, theory, parallel training, switchML",
    "Abstract": "We propose a family of adaptive integer compression operators for distributed Stochastic Gradient Descent (SGD) that do not communicate a single float. This is achieved by multiplying floating-point vectors with a number known to every device and then rounding to integers. In contrast to the prior work on integer compression for SwitchML by (Sapio et al., 2021), our IntSGD method is provably convergent and computationally cheaper as it estimates the scaling of vectors adaptively. Our theory shows that the iteration complexity of IntSGD matches that of SGD up to constant factors for both convex and non-convex, smooth and non-smooth functions, with and without overparameterization. Moreover, our algorithm can also be tailored for the popular all-reduce primitive and shows promising empirical performance.",
    "One-sentence Summary": "We propose the provably convergent and computationally cheap IntSGD algorithm for efficient distributed machine learning."
  },
  {
    "title": "PAC-Bayes Information Bottleneck",
    "url": "/forum?id=iLHOIDsPv1P",
    "date": "28 Sept 2021 (modified: 04 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "information bottleneck, representation learning, generalization",
    "Abstract": "Understanding the source of the superior generalization ability of NNs remains one of the most important problems in ML research. There have been a series of theoretical works trying to derive non-vacuous bounds for NNs. Recently, the compression of information stored in weights (IIW) is proved to play a key role in NNs generalization based on the PAC-Bayes theorem. However, no solution of IIW has ever been provided, which builds a barrier for further investigation of the IIW's property and its potential in practical deep learning. In this paper, we propose an algorithm for the efficient approximation of IIW. Then, we build an IIW-based information bottleneck on the trade-off between accuracy and information complexity of NNs, namely PIB. From PIB, we can empirically identify the fitting to compressing phase transition during NNs' training and the concrete connection between the IIW compression and the generalization. Besides, we verify that IIW is able to explain NNs in broad cases, e.g., varying batch sizes, over-parameterization, and noisy labels. Moreover, we propose an MCMC-based algorithm to sample from the optimal weight posterior characterized by PIB, which fulfills the potential of IIW in enhancing NNs in practice.",
    "One-sentence Summary": "We propose a novel PAC-Bayes bound guided information bottleneck for understanding and enhancing deep representation learning."
  },
  {
    "title": "Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing",
    "url": "/forum?id=jXKKDEi5vJt",
    "date": "28 Sept 2021 (modified: 04 May 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Federated learning, Distributed learning, Byzantine robust optimization, Heterogeneity (Non-IID)",
    "Abstract": "In Byzantine robust distributed or federated learning, a central server wants to train a machine learning model over data distributed across multiple workers. However, a fraction of these workers may deviate from the prescribed algorithm and send arbitrary messages. While this problem has received significant attention recently, most current defenses assume that the workers have identical data. For realistic cases when the data across workers are heterogeneous (non-iid), we design new attacks which circumvent current defenses, leading to significant loss of performance. We then propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. We also theoretically and experimentally validate our approach, showing that combining bucketing with existing robust algorithms is effective against challenging attacks. Our work is the first to establish guaranteed convergence for the non-iid Byzantine robust problem under realistic assumptions.",
    "One-sentence Summary": "Byzantine-robust distributed learning with heterogeneous data distribution"
  },
  {
    "title": "Understanding the Role of Self Attention for Efficient Speech Recognition",
    "url": "/forum?id=AvcfxqRy4Y",
    "date": "28 Sept 2021 (modified: 14 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "transformer, self attention, speech recognition",
    "Abstract": "Self-attention (SA) is a critical component of Transformer neural networks that have succeeded in automatic speech recognition (ASR). In this paper, we analyze the role of SA in Transformer-based ASR models for not only understanding the mechanism of improved recognition accuracy but also lowering the computational complexity. We reveal that SA performs two distinct roles: phonetic and linguistic localization. Especially, we show by experiments that phonetic localization in the lower layers extracts phonologically meaningful features from speech and reduces the phonetic variance in the utterance for proper linguistic localization in the upper layers. From this understanding, we discover that attention maps can be reused as long as their localization capability is preserved. To evaluate this idea, we implement the layer-wise attention map reuse on real GPU platforms and achieve up to 1.96 times speedup in inference and 33% savings in training time with noticeably improved ASR performance for the challenging benchmark on LibriSpeech dev/test-other dataset.",
    "One-sentence Summary": "We analyze the role of self attention in Transformer-based speech recognition and present a practical technique to design a model that accelerates the inference and improve the performance."
  },
  {
    "title": "Label Encoding for Regression Networks",
    "url": "/forum?id=8WawVDdKqlL",
    "date": "28 Sept 2021 (modified: 15 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Regression, Label encoding, Output codes",
    "Abstract": "Deep neural networks are used for a wide range of regression problems. However, there exists a significant gap in accuracy between specialized approaches and generic direct regression in which a network is trained by minimizing the squared or absolute error of output labels. Prior work has shown that solving a regression problem with a set of binary classifiers can improve accuracy by utilizing well-studied binary classification algorithms. We introduce binary-encoded labels (BEL), which generalizes the application of binary classification to regression by providing a framework for considering arbitrary multi-bit values when encoding target values. We identify desirable properties of suitable encoding and decoding functions used for the conversion between real-valued and binary-encoded labels based on theoretical and empirical study. These properties highlight a tradeoff between classification error probability and error-correction capabilities of label encodings. BEL can be combined with off-the-shelf task-specific feature extractors and trained end-to-end. We propose a series of sample encoding, decoding, and training loss functions for BEL and demonstrate they result in lower error than direct regression and specialized approaches while being suitable for a diverse set of regression problems, network architectures, and evaluation metrics. BEL achieves state-of-the-art accuracies for several regression benchmarks. Code is available at https://github.com/ubc-aamodt-group/BEL_regression.",
    "One-sentence Summary": "We propose binary-encoded labels (BEL) which improves regression by generalizing the application of binary classification."
  },
  {
    "title": "Equivariant Transformers for Neural Network based Molecular Potentials",
    "url": "/forum?id=zNHzqZ9wrRB",
    "date": "28 Sept 2021 (modified: 09 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Molecular Modeling, Quantum Chemistry, Attention, Transformers",
    "Abstract": "The prediction of quantum mechanical properties is historically plagued by a trade-off between accuracy and speed. Machine learning potentials have previously shown great success in this domain, reaching increasingly better accuracy while maintaining computational efficiency comparable with classical force fields. In this work we propose TorchMD-NET, a novel equivariant Transformer (ET) architecture, outperforming state-of-the-art on MD17, ANI-1, and many QM9 targets in both accuracy and computational efficiency. Through an extensive attention weight analysis, we gain valuable insights into the black box predictor and show differences in the learned representation of conformers versus conformations sampled from molecular dynamics or normal modes. Furthermore, we highlight the importance of datasets including off-equilibrium conformations for the evaluation of molecular potentials.",
    "One-sentence Summary": "We propose a novel equivariant Transformer architecture for the prediction of molecular potentials and provide insights into the molecular representation through extensive analysis of the model's attention weights."
  },
  {
    "title": "SGD Can Converge to Local Maxima",
    "url": "/forum?id=9XhPLAjjRB",
    "date": "28 Sept 2021 (modified: 13 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "stochastic gradient descent, saddle points, convergence, amsgrad, deep learning",
    "Abstract": "Previous works on stochastic gradient descent (SGD) often focus on its success. In this work, we construct worst-case optimization problems illustrating that, when not in the regimes that the previous works often assume, SGD can exhibit many strange and potentially undesirable behaviors. Specifically, we construct landscapes and data distributions such that (1) SGD converges to local maxima, (2) SGD escapes saddle points arbitrarily slowly, (3) SGD prefers sharp minima over flat ones, and (4) AMSGrad converges to local maxima. We also realize results in a minimal neural network-like example. Our results highlight the importance of simultaneously analyzing the minibatch sampling, discrete-time updates rules, and realistic landscapes to understand the role of SGD in deep learning.",
    "One-sentence Summary": "We show that it can be common for SGD to converge to saddle points and maxima."
  },
  {
    "title": "Hybrid Local SGD for Federated Learning with Heterogeneous Communications",
    "url": "/forum?id=H0oaWl6THa",
    "date": "28 Sept 2021 (modified: 02 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "Federated Learning, Communication Efficiency, Heterogeneity, Local SGD",
    "Abstract": "Communication is a key bottleneck in federated learning where a large number of edge devices collaboratively learn a model under the orchestration of a central server without sharing their own training data. While local SGD has been proposed to reduce the number of FL rounds and become the algorithm of choice for FL, its total communication cost is still prohibitive when each device needs to communicate with the remote server repeatedly for many times over bandwidth-limited networks. In light of both device-to-device (D2D) and device-to-server (D2S) cooperation opportunities in modern communication networks, this paper proposes a new federated optimization algorithm dubbed hybrid local SGD (HL-SGD) in FL settings where devices are grouped into a set of disjoint clusters with high D2D communication bandwidth. HL-SGD subsumes previous proposed algorithms such as local SGD and gossip SGD and enables us to strike the best balance between model accuracy and runtime. We analyze the convergence of HL-SGD in the presence of heterogeneous data for general nonconvex settings. We also perform extensive experiments and show that the use of hybrid model aggregation via D2D and D2S communications in HL-SGD can largely speed up the training time of federated learning."
  },
  {
    "title": "Increasing the Cost of Model Extraction with Calibrated Proof of Work",
    "url": "/forum?id=EAy7C1cgE1L",
    "date": "28 Sept 2021 (modified: 18 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "model extraction, model stealing, model functionality stealing, proof-of-work, adversarial machine learning, trustworthy machine learning, deep learning",
    "Abstract": "In model extraction attacks, adversaries can steal a machine learning model exposed via a public API by repeatedly querying it and adjusting their own model based on obtained predictions. To prevent model stealing, existing defenses focus on detecting malicious queries, truncating, or distorting outputs, thus necessarily introducing a tradeoff between robustness and model utility for legitimate users. Instead, we propose to impede model extraction by requiring users to complete a proof-of-work before they can read the model's predictions. This deters attackers by greatly increasing (even up to 100x) the computational effort needed to leverage query access for model extraction. Since we calibrate the effort required to complete the proof-of-work to each query, this only introduces a slight overhead for regular users (up to 2x). To achieve this, our calibration applies tools from differential privacy to measure the information revealed by a query. Our method requires no modification of the victim model and can be applied by machine learning practitioners to guard their publicly exposed models against being easily stolen.",
    "One-sentence Summary": "We propose to make model extraction more difficult by requiring users to complete a callibrated proof-of-work before they can read predictions from a machine learning model exposed via a public API."
  },
  {
    "title": "Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks",
    "url": "/forum?id=HFmAukZ-k-2",
    "date": "28 Sept 2021 (modified: 14 Mar 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "spatio-temporal, finite, elements, forecasting, continuous, partial, differential, equation, PDE, graph, gnn, time-series",
    "Abstract": "We propose a new method for spatio-temporal forecasting on arbitrarily distributed points. Assuming that the observed system follows an unknown partial differential equation, we derive a continuous-time model for the dynamics of the data via the finite element method. The resulting graph neural network estimates the instantaneous effects of the unknown dynamics on each cell in a meshing of the spatial domain. Our model can incorporate prior knowledge via assumptions on the form of the unknown PDE, which induce a structural bias towards learning specific processes. Through this mechanism, we derive a transport variant of our model from the convection equation and show that it improves the transfer performance to higher-resolution meshes on sea surface temperature and gas flow forecasting against baseline models representing a selection of spatio-temporal forecasting methods. A qualitative analysis shows that our model disentangles the data dynamics into their constituent parts, which makes it uniquely interpretable.",
    "One-sentence Summary": "A continuous-time graph neural network model for spatio-temporal forecasting that can structurally incorporate prior knowledge"
  },
  {
    "title": "Probabilistic Implicit Scene Completion",
    "url": "/forum?id=BnQhMqDfcKG",
    "date": "28 Sept 2021 (modified: 22 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Keywords": "3D shape completion, 3D generative model",
    "Abstract": "We propose a probabilistic shape completion method extended to the continuous geometry of large-scale 3D scenes. Real-world scans of 3D scenes suffer from a considerable amount of missing data cluttered with unsegmented objects. The problem of shape completion is inherently ill-posed, and high-quality result requires scalable solutions that consider multiple possible outcomes. We employ the Generative Cellular Automata that learns the multi-modal distribution and transform the formulation to process large-scale continuous geometry. The local continuous shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. We formally derive that our training objective for the sparse voxel embedding maximizes the variational lower bound of the complete shape distribution and therefore our progressive generation constitutes a valid generative model. Experiments show that our model successfully generates diverse plausible scenes faithful to the input, especially when the input suffers from a significant amount of missing data. We also demonstrate that our approach outperforms deterministic models even in less ambiguous cases with a small amount of missing data, which infers that probabilistic formulation is crucial for high-quality geometry completion on input scans exhibiting any levels of completeness.",
    "One-sentence Summary": "We propose a scalable generative model for multi-modal completion of 3D scenes in implicit representation."
  },
  {
    "title": "Improving Federated Learning Face Recognition via Privacy-Agnostic Clusters",
    "url": "/forum?id=7l1IjZVddDW",
    "date": "28 Sept 2021 (modified: 09 Feb 2022)",
    "acceptance_type": "ICLR 2022 Spotlight",
    "Abstract": "The growing public concerns on data privacy in face recognition can be partly relieved by the federated learning (FL) paradigm. However, conventional FL methods usually perform poorly  due to the particularity of the task, \\textit{i.e.},  broadcasting class centers among clients is essential for recognition performances but leads to privacy leakage. To resolve the privacy-utility paradox, this work proposes PrivacyFace, a framework largely improves the federated learning face recognition via communicating auxiliary and privacy-agnostic information among clients. PrivacyFace mainly consists of two components: First, a practical Differentially Private Local Clustering (DPLC) mechanism is proposed to distill sanitized clusters from local class centers. Second, a consensus-aware recognition loss subsequently encourages global consensuses among clients, which ergo leads to more discriminative features. The proposed schemes are mathematically proved to be differential private, introduce a lightweight overhead as well as yield prominent performance boosts (\\textit{e.g.}, +9.63\\% and +10.26\\% for TAR@FAR=1e-4 on IJB-B and IJB-C respectively). Extensive experiments and ablation studies on a large-scale dataset have demonstrated the efficacy and practicability of our method."
  }
]