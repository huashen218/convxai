{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Universal XAI API from ConvXAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tutorial of exploring the DSL(Domain Specific Language) of **ConvXAI**, which aims to build the universal APIs for a range of XAI methods. \n",
    "\n",
    "In this tutorial, we show the ConvXAI APIs with two examples:\n",
    "\n",
    "- Single turn interaction\n",
    "- Multi turn interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 02:36:51 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-11-26 02:36:51,157 - Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-11-26 02:36:51 INFO: Use device: gpu\n",
      "2022-11-26 02:36:51,182 - Use device: gpu\n",
      "2022-11-26 02:36:51 INFO: Loading: tokenize\n",
      "2022-11-26 02:36:51,184 - Loading: tokenize\n",
      "2022-11-26 02:36:55 INFO: Loading: pos\n",
      "2022-11-26 02:36:55,601 - Loading: pos\n",
      "2022-11-26 02:36:55 INFO: Loading: lemma\n",
      "2022-11-26 02:36:55,996 - Loading: lemma\n",
      "2022-11-26 02:36:56 INFO: Loading: depparse\n",
      "2022-11-26 02:36:56,054 - Loading: depparse\n",
      "2022-11-26 02:36:56 INFO: Loading: sentiment\n",
      "2022-11-26 02:36:56,541 - Loading: sentiment\n",
      "2022-11-26 02:36:56 INFO: Loading: constituency\n",
      "2022-11-26 02:36:56,970 - Loading: constituency\n",
      "2022-11-26 02:36:57 INFO: Loading: ner\n",
      "2022-11-26 02:36:57,480 - Loading: ner\n",
      "2022-11-26 02:36:58 INFO: Done loading processors!\n",
      "2022-11-26 02:36:58,051 - Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loads the packages.\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/hqs5468/hua/workspace/projects/convxai\")\n",
    "\n",
    "from convxai.writing_models.models import *\n",
    "from convxai_api.modules import *\n",
    "from convxai_api.xaiagent import ConvXAI\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with ConvXAI Agent (Single Turn Conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ask XAI request to the ConvXAI agent for different XAI questions and types.\n",
    "Below, we show how you can leverage `interact_single_turn` function to request 8 types AI explanations from ConvXAI class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 02:37:08,243 - \n",
      "Loading writing models to be explained......\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Instantiates a ConvXAI agent.\"\"\"\n",
    "convxai_agent = ConvXAI(intent_detection_algorithm=\"rule_based\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = meta-data\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: What data did the system learn from?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: Sure! We are comparing your writing with our collected <strong>CHI Paper Abstract</strong> dataset to generate the above review. The dataset includes <strong>21643 sentences</strong> in <strong>3235 papers</strong>. \n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "### interact with ConvXAI agent using different free-text XAI requests.\n",
    "### use `visualize` to decide visualization.\n",
    "\n",
    "explained_sentence = \"It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .\"\n",
    "target_label = \"background\"\n",
    "target_conference = \"CHI\"\n",
    "visualize=True\n",
    "\n",
    "# Data Explanation\n",
    "user_question_request = \"What data did the system learn from?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = meta-model\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: What kind of models are used?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: Of course! The <strong>Writing Structure Model</strong> is a <a class='post-link' href='https://arxiv.org/pdf/1903.10676.pdf' target='_blank'>SciBERT</a> based classifier finetuned with the <a class='post-link' href='https://arxiv.org/pdf/2005.02367.pdf' target='_blank'>CODA-19</a> dataset. Also, the <strong>Writing Style Model</strong> is a <a class='post-link' href='https://openai.com/blog/tags/gpt-2/' target='_blank'>GPT-2</a> based generative model finetuned with <strong>9935 abstracts</strong> from <a class='post-link' href='https://dl.acm.org/conference/chi' target='_blank'>CHI</a>, <a class='post-link' href='https://aclanthology.org/venues/acl/' target='_blank'>ACL</a> and <a class='post-link' href='https://iclr.cc/Conferences/2023' target='_blank'>ICLR</a> papers (click the terms to view more)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Model Explanation\n",
    "user_question_request = \"What kind of models are used?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = quality-score\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: What's the range of the style quality scores?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: \n",
       "        We use each sentence's <strong>Perplexity</strong> value (predicted by the GPT-2 model) to derive the <strong>Quality Score</strong>. Lower perplexity means your writing is more similar to the CHI papers.\n",
       "        <br>\n",
       "        We divide into five levels as below based on [20-th, 40-th, 60-th, 80-th] percentiles of the CHI papers' perplexity scores (i.e., [45, 57, 71, 92]).\n",
       "        \n",
       "        <br>\n",
       "        <style>\n",
       "            .demo {\n",
       "                border:1px solid #EDEDED;\n",
       "                border-collapse:separate;\n",
       "                border-spacing:2px;\n",
       "                padding:5px;\n",
       "            }\n",
       "            .demo th {\n",
       "                border:1px solid #EDEDED;\n",
       "                padding:5px;\n",
       "                background:#D6D6D6;\n",
       "            }\n",
       "            .demo td {\n",
       "                border:1px solid #EDEDED;\n",
       "                text-align:center;\n",
       "                padding:5px;\n",
       "                background:#F5F5F5;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <table class=\"demo\">\n",
       "            <caption><br></caption>\n",
       "            <thead>\n",
       "            <tr>\n",
       "                <th>Quality Score</th>\n",
       "                <th>Perplexity (PPL)</th>\n",
       "            </tr>\n",
       "            </thead>\n",
       "            <tbody>\n",
       "            <tr>\n",
       "                <td>1 (lowest)</td>\n",
       "                <td>92 &lt; PPL<br></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>2</td>\n",
       "                <td>71 &lt; PPL &lt;= 92&nbsp;</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>3</td>\n",
       "                <td>57 &lt; PPL &lt;= 71&nbsp;</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>4</td>\n",
       "                <td>45 &lt; PPL &lt;= 57&nbsp;</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>5 (highest)</td>\n",
       "                <td>PPL &lt;= 45&nbsp;</td>\n",
       "            </tr>\n",
       "            <tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Quality Score Explanation\n",
    "user_question_request = \"What's the range of the style quality scores?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = label-distribution\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: How are the structure labels distributed?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: We use the Research Aspects Model to generate <strong>aspect sequences</strong> of all 9935 paper abstracts. Then we cluster these sequences into <strong>five patterns</strong> as below. We compare your writing with these patterns for review.\n",
       "        <br>\n",
       "        <style>\n",
       "            .demo {\n",
       "                border:1px solid #EDEDED;\n",
       "                border-collapse:separate;\n",
       "                border-spacing:2px;\n",
       "                padding:5px;\n",
       "            }\n",
       "            .demo th {\n",
       "                border:1px solid #EDEDED;\n",
       "                padding:5px;\n",
       "                background:#D6D6D6;\n",
       "            }\n",
       "            .demo td {\n",
       "                border:1px solid #EDEDED;\n",
       "                text-align:center;\n",
       "                padding:5px;\n",
       "                background:#F5F5F5;\n",
       "            }\n",
       "        </style>\n",
       "         \n",
       "        <table class=\"demo\">\n",
       "            <caption><br></caption>\n",
       "            <thead>\n",
       "            <tr>\n",
       "                <th>Types</th>\n",
       "                <th>Patterns</th>\n",
       "            </tr>\n",
       "            </thead>\n",
       "            <tbody>\n",
       "            <tr>\n",
       "                <td>Pattern1</td>\n",
       "                <td>'background' (42.9%) -&gt; 'purpose' (14.3%)  -&gt; 'finding' (42.9%)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Pattern2&nbsp;</td>\n",
       "                <td>'background' (22.2%) -&gt; 'purpose' (11.2%) -&gt; 'method' (33.3%) -&gt; 'finding' (33.3%)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Pattern3&nbsp;</td>\n",
       "                <td>'background' (33.3%) -&gt; 'purpose' (16.7%) -&gt; 'method' (16.7%)  -&gt; 'finding' (33.3%)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Pattern4</td>\n",
       "                <td>'background' (33.3%) -&gt; 'method' (16.7%)  -&gt;  'finding' (50%)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Pattern5</td>\n",
       "                <td>'background' (20%)   -&gt; 'finding' (6.7%)  -&gt;  'background' (13.3%) -&gt; 'purpose' (6.7%) -&gt; 'background' (13.3%) -&gt; 'finding' (6.7%) -&gt; 'method' (6.7%) -&gt; 'finding' (26.7%)</td>\n",
       "            </tr>\n",
       "            <tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Label Distribution Explanation\n",
    "user_question_request = \"How are the structure labels distributed?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = sentence-length\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: What's the statistics of the sentence lengths?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: \n",
       "        The [mean-2*std, mean-std, mean, mean+std, mean+2*std] percentiles of the sentence lengths in the CHI conference are <strong>{'all': [4, 14, 25, 36, 46], 'background': [5, 14, 22, 31, 40], 'purpose': [6, 17, 27, 38, 49], 'method': [4, 15, 27, 39, 51], 'finding': [4, 15, 26, 37, 48], 'other': [-3, 0, 4, 7, 11]}</strong> words. \n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Sentence Length Explanation\n",
    "user_question_request = \"What's the statistics of the sentence lengths?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request,explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = confidence\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: How confident is this prediction?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: Given your selected sentence = <span class='text-info'>It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .</span>, the model predicts a <strong>'background' aspect</strong> label with <strong>confidence score = 0.8926</strong>. "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Model Confidence Explanation\n",
    "user_question_request = \"How confident is this prediction?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = example\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: What are some published sentences that look similar to mine semantically?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: The top-3 similar examples (i.e., of selected-sentence = '<i><span class='text-info'>It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .</span>') from the <strong>CHI</strong> dataset are (Conditioned on <strong>label=0</strong>):<br> <strong>sample-5392</strong> - <a class='post-link' href='https://doi.org/10.1145/3290605.3300547' target='_blank'>We contribute to the theoretical aspect of this research by presenting an ethnographic study on alternative farming practices, in which the farm is not so much a system but an assemblage characterized by multiple systems or rationalities always evolving and changing</a>.<br> <strong>sample-4793</strong> - <a class='post-link' href='https://doi.org/10.1145/3290605.3300446' target='_blank'>We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students</a>.<br> <strong>sample-1176</strong> - <a class='post-link' href='https://doi.org/10.1145/3173574.3173597' target='_blank'>Our natural tendency to be curious is increasingly important now that we are exposed to vast amounts of information</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Example Explanation\n",
    "user_question_request = \"What are some published sentences that look similar to mine semantically?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = attribution\n",
      "======> Conversational XAI Demonstration <======\n",
      "User: Which words in this sentence are most important for this prediction?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: The <strong>TOP-3</strong> important words are highlighted as below: <br><br>  <b><span style=\"font-weight: normal;\">[CLS]</span></b> <b><span style=\"font-weight: normal;\">it</span></b> <b><span style=\"font-weight: normal;\">is</span></b> <b><span style=\"font-weight: bold; background-color: #F9B261; border-radius: 5px;\">unclear</span></b> <b><span style=\"font-weight: normal;\">if</span></b> <b><span style=\"font-weight: normal;\">existing</span></b> <b><span style=\"font-weight: normal;\">interpretations</span></b> <b><span style=\"font-weight: normal;\">of</span></b> <b><span style=\"font-weight: normal;\">deep</span></b> <b><span style=\"font-weight: bold; background-color: #F9B261; border-radius: 5px;\">neural</span></b> <b><span style=\"font-weight: normal;\">network</span></b> <b><span style=\"font-weight: normal;\">models</span></b> <b><span style=\"font-weight: normal;\">respond</span></b> <b><span style=\"font-weight: normal;\">effectively</span></b> <b><span style=\"font-weight: normal;\">to</span></b> <b><span style=\"font-weight: normal;\">the</span></b> <b><span style=\"font-weight: bold; background-color: #F9B261; border-radius: 5px;\">needs</span></b> <b><span style=\"font-weight: normal;\">of</span></b> <b><span style=\"font-weight: normal;\">users</span></b> <b><span style=\"font-weight: normal;\">.</span></b> <b><span style=\"font-weight: normal;\">[SEP]</span></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Attribution Explanation\n",
    "user_question_request = \"Which words in this sentence are most important for this prediction?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 02:37:16,563 - Loading models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = counterfactual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 02:37:18,780 - Done loading predictor.\n",
      "2022-11-26 02:37:26,591 - Loading Editor weights from: /home/hqs5468/hua/workspace/projects/convxai/checkpoints/xai_models/xai_counterfactual_explainer_models/editors/diversity_model/checkpoints/best.pth\n",
      "2022-11-26 02:37:27,691 - Done loading models.\n",
      "2022-11-26 02:37:34,160 - Contrast label: finding\n",
      "2022-11-26 02:37:34,163 - Orig contrast prob: 0.07900000363588333\n",
      "2022-11-26 02:37:34,164 - Updating beam for: {input_cand}\n",
      "2022-11-26 02:37:34,165 - Edit round: 1 (1-indexed)\n",
      "2022-11-26 02:37:34,166 - Element 0 of beam\n",
      "2022-11-26 02:37:34,166 - Contrast label: finding\n",
      "2022-11-26 02:37:34,167 - Contrast prob: 0.07900000363588333\n",
      "2022-11-26 02:37:34,168 - Generating candidates...\n",
      "2022-11-26 02:37:34,889 - binary search mid: 0.275\n",
      "2022-11-26 02:37:34,894 - Running candidate generation for mask frac:                 0.275; max mask frac: 0.55\n",
      "2022-11-26 02:37:34,911 - Sub round: 0\n",
      "2022-11-26 02:37:34,912 - Input: 0 of 0\n",
      "2022-11-26 02:37:34,913 - Last sentinel: <extra_id_1>\n",
      "2022-11-26 02:37:34,915 - INPUT TO EDITOR: label: finding. input:<extra_id_0> interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users.\n",
      "2022-11-26 02:37:35,396 - first batch: <pad><extra_id_0> interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users.<extra_id_1>\n",
      "2022-11-26 02:37:36,062 - Post edit round, top contr prob: 0.43721163272857666\n",
      "2022-11-26 02:37:36,064 - Post edit round, top cand:  interpretations of deep neural network models respond effectively to the\n",
      "\t\t\t\t\t\tneeds of users. interpretations of deep neural network models respond effectively to the needs\n",
      "\t\t\t\t\t\tof users .\n",
      "2022-11-26 02:37:36,113 - Binary search # levels: 1\n",
      "2022-11-26 02:37:36,115 - Found cand: True\n",
      "2022-11-26 02:37:36,116 - binary search mid: 0.1375\n",
      "2022-11-26 02:37:36,117 - Running candidate generation for mask frac:                 0.1375; max mask frac: 0.55\n",
      "2022-11-26 02:37:36,128 - Sub round: 0\n",
      "2022-11-26 02:37:36,129 - Input: 0 of 0\n",
      "2022-11-26 02:37:36,130 - Last sentinel: <extra_id_2>\n",
      "2022-11-26 02:37:36,132 - INPUT TO EDITOR: label: finding. input: It<extra_id_0><extra_id_1> interpretations of deep neural\n",
      "\t\t\t\t\t\tnetwork models respond effectively to the needs of users.\n",
      "2022-11-26 02:37:36,870 - first batch: <pad><extra_id_0> interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users.<extra_id_1> Interpretations of deeper\n",
      "\t\t\t\t\t\tneural<extra_id_2><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "2022-11-26 02:37:37,505 - Post edit round, top contr prob: 0.6143888235092163\n",
      "2022-11-26 02:37:37,507 - Post edit round, top cand: It  interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users.: It interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users .\n",
      "2022-11-26 02:37:37,610 - Binary search # levels: 2\n",
      "2022-11-26 02:37:37,611 - Found cand: True\n",
      "2022-11-26 02:37:37,612 - binary search mid: 0.06875\n",
      "2022-11-26 02:37:37,612 - Running candidate generation for mask frac:                 0.06875; max mask frac: 0.55\n",
      "2022-11-26 02:37:37,620 - Sub round: 0\n",
      "2022-11-26 02:37:37,622 - Input: 0 of 0\n",
      "2022-11-26 02:37:37,622 - Last sentinel: <extra_id_2>\n",
      "2022-11-26 02:37:37,623 - INPUT TO EDITOR: label: finding. input: It<extra_id_0> unclear if<extra_id_1> interpretations of\n",
      "\t\t\t\t\t\tdeep neural network models respond effectively to the needs of users.\n",
      "2022-11-26 02:37:38,165 - first batch: <pad><extra_id_0> unclear if<extra_id_1> interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users.<extra_id_2><pad><pad><pad>\n",
      "2022-11-26 02:37:38,842 - Post edit round, top contr prob: 0.3748117983341217\n",
      "2022-11-26 02:37:38,846 - Post edit round, top cand: It  unclear if unclear if interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users. It interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users .\n",
      "2022-11-26 02:37:38,847 - Binary search # levels: 3\n",
      "2022-11-26 02:37:38,848 - Found cand: False\n",
      "2022-11-26 02:37:38,849 - binary search mid: 0.10312500000000001\n",
      "2022-11-26 02:37:38,850 - Running candidate generation for mask frac:                 0.10312500000000001; max mask frac: 0.55\n",
      "2022-11-26 02:37:38,860 - Sub round: 0\n",
      "2022-11-26 02:37:38,861 - Input: 0 of 0\n",
      "2022-11-26 02:37:38,861 - Last sentinel: <extra_id_2>\n",
      "2022-11-26 02:37:38,863 - INPUT TO EDITOR: label: finding. input: It<extra_id_0> if<extra_id_1> interpretations of deep neural\n",
      "\t\t\t\t\t\tnetwork models respond effectively to the needs of users.\n",
      "2022-11-26 02:37:39,596 - first batch: <pad><extra_id_0> if<extra_id_1> interpretations of deep neural network models respond\n",
      "\t\t\t\t\t\teffectively to the needs of users.<extra_id_2><pad><pad><pad>\n",
      "2022-11-26 02:37:40,286 - Post edit round, top contr prob: 0.45449578762054443\n",
      "2022-11-26 02:37:40,287 - Post edit round, top cand: It  if if interpretations of deep neural network models respond\n",
      "\t\t\t\t\t\teffectively to the needs of users. Similarly, interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users .\n",
      "2022-11-26 02:37:40,328 - Binary search # levels: 4\n",
      "2022-11-26 02:37:40,329 - Found cand: True\n",
      "2022-11-26 02:37:40,330 - Found edit at edit round: {num_rounds}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Conversational XAI Demonstration <======\n",
      "User: How can I revise the input to get a different prediction?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: The most likely counterfactual label is <strong>'finding'</strong>. You can get this label by revising from \n",
       "'<span class='text-info'>It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .</span>\n",
       "' into: \n",
       " <br>'<em><span class='text-secondary'>interpretations of deep neural network models respond effectively to the needs of users <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>interpretations</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>deep</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>neural</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>network</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>models</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>respond</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>effectively</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>to</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>the</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>needs</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>users</span></b> </span></em>'. <br>I'm confident with this revision with <strong>confidence score=0.4372</strong>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Counterfactual Explanation\n",
    "user_question_request = \"How can I revise the input to get a different prediction?\"\n",
    "response = convxai_agent.interact_single_turn(user_question_request, explained_sentence, target_label, target_conference, visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you can directly check the output from each of the three ConvXAI modules, including the `user_intent_detection`, `ai_explainer` and `natural_language_generation`.\n",
    "\n",
    "We provide two examples as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected User Input = counterfactual\n"
     ]
    }
   ],
   "source": [
    "#### Different user question requests direct to different XAI types.\n",
    "# user_question_request = \"What data did the system learn from?\"\n",
    "# user_question_request = \"What kind of models are used?\"\n",
    "# user_question_request = \"What's the range of the style quality scores?\"\n",
    "# user_question_request = \"How are the structure labels distributed?\"\n",
    "# user_question_request = \"What's the statistics of the sentence lengths?\"\n",
    "# user_question_request = \"How confident is this prediction?\"\n",
    "# user_question_request = \"What are some published sentences that look similar to mine semantically?\"\n",
    "# user_question_request = \"Which words in this sentence are most important for this prediction?\"\n",
    "user_question_request = \"How can I revise the input to get a different prediction?\"\n",
    "\n",
    "\n",
    "\n",
    "explained_sentence = \"It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .\"\n",
    "target_label = \"background\"\n",
    "target_conference = \"CHI\"\n",
    "visualize=False\n",
    "\n",
    "### Get User Intent\n",
    "user_intent = convxai_agent.nlu(user_question_request)\n",
    "print(f\"Detected User Input = {user_intent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 02:37:40,690 - Loading models...\n",
      "2022-11-26 02:37:43,347 - Done loading predictor.\n",
      "2022-11-26 02:37:48,726 - Loading Editor weights from: /home/hqs5468/hua/workspace/projects/convxai/checkpoints/xai_models/xai_counterfactual_explainer_models/editors/diversity_model/checkpoints/best.pth\n",
      "2022-11-26 02:37:49,949 - Done loading models.\n",
      "2022-11-26 02:37:56,305 - Contrast label: finding\n",
      "2022-11-26 02:37:56,307 - Orig contrast prob: 0.07900000363588333\n",
      "2022-11-26 02:37:56,309 - Updating beam for: {input_cand}\n",
      "2022-11-26 02:37:56,310 - Edit round: 1 (1-indexed)\n",
      "2022-11-26 02:37:56,310 - Element 0 of beam\n",
      "2022-11-26 02:37:56,311 - Contrast label: finding\n",
      "2022-11-26 02:37:56,312 - Contrast prob: 0.07900000363588333\n",
      "2022-11-26 02:37:56,312 - Generating candidates...\n",
      "2022-11-26 02:37:57,112 - binary search mid: 0.275\n",
      "2022-11-26 02:37:57,117 - Running candidate generation for mask frac:                 0.275; max mask frac: 0.55\n",
      "2022-11-26 02:37:57,125 - Sub round: 0\n",
      "2022-11-26 02:37:57,126 - Input: 0 of 0\n",
      "2022-11-26 02:37:57,127 - Last sentinel: <extra_id_1>\n",
      "2022-11-26 02:37:57,128 - INPUT TO EDITOR: label: finding. input:<extra_id_0> interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users.\n",
      "2022-11-26 02:37:57,518 - first batch: <pad><extra_id_0> interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users.<extra_id_1>\n",
      "2022-11-26 02:37:58,255 - Post edit round, top contr prob: 0.43721163272857666\n",
      "2022-11-26 02:37:58,257 - Post edit round, top cand:  interpretations of deep neural network models respond effectively to the\n",
      "\t\t\t\t\t\tneeds of users. interpretations of deep neural network models respond effectively to the needs\n",
      "\t\t\t\t\t\tof users .\n",
      "2022-11-26 02:37:58,277 - Binary search # levels: 1\n",
      "2022-11-26 02:37:58,278 - Found cand: True\n",
      "2022-11-26 02:37:58,279 - binary search mid: 0.1375\n",
      "2022-11-26 02:37:58,280 - Running candidate generation for mask frac:                 0.1375; max mask frac: 0.55\n",
      "2022-11-26 02:37:58,287 - Sub round: 0\n",
      "2022-11-26 02:37:58,288 - Input: 0 of 0\n",
      "2022-11-26 02:37:58,289 - Last sentinel: <extra_id_2>\n",
      "2022-11-26 02:37:58,290 - INPUT TO EDITOR: label: finding. input: It<extra_id_0><extra_id_1> interpretations of deep neural\n",
      "\t\t\t\t\t\tnetwork models respond effectively to the needs of users.\n",
      "2022-11-26 02:37:58,932 - first batch: <pad><extra_id_0> interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users.<extra_id_1> interpretation based on\n",
      "\t\t\t\t\t\tthe<extra_id_2><pad><pad><pad><pad><pad>\n",
      "2022-11-26 02:37:59,664 - Post edit round, top contr prob: 0.5227439999580383\n",
      "2022-11-26 02:37:59,667 - Post edit round, top cand: It  interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users.. The interpretations of deep neural network models respond effectively to\n",
      "\t\t\t\t\t\tthe needs of users .\n",
      "2022-11-26 02:37:59,770 - Binary search # levels: 2\n",
      "2022-11-26 02:37:59,772 - Found cand: True\n",
      "2022-11-26 02:37:59,773 - binary search mid: 0.06875\n",
      "2022-11-26 02:37:59,774 - Running candidate generation for mask frac:                 0.06875; max mask frac: 0.55\n",
      "2022-11-26 02:37:59,784 - Sub round: 0\n",
      "2022-11-26 02:37:59,786 - Input: 0 of 0\n",
      "2022-11-26 02:37:59,787 - Last sentinel: <extra_id_2>\n",
      "2022-11-26 02:37:59,788 - INPUT TO EDITOR: label: finding. input: It<extra_id_0> unclear if<extra_id_1> interpretations of\n",
      "\t\t\t\t\t\tdeep neural network models respond effectively to the needs of users.\n",
      "2022-11-26 02:38:00,513 - first batch: <pad><extra_id_0> unclear if<extra_id_1> interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users. Often,<extra_id_2>\n",
      "2022-11-26 02:38:01,241 - Post edit round, top contr prob: 0.3748118281364441\n",
      "2022-11-26 02:38:01,244 - Post edit round, top cand: It  unclear if unclear if interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users. It interpretations of deep neural network models\n",
      "\t\t\t\t\t\trespond effectively to the needs of users .\n",
      "2022-11-26 02:38:01,245 - Binary search # levels: 3\n",
      "2022-11-26 02:38:01,246 - Found cand: False\n",
      "2022-11-26 02:38:01,246 - binary search mid: 0.10312500000000001\n",
      "2022-11-26 02:38:01,247 - Running candidate generation for mask frac:                 0.10312500000000001; max mask frac: 0.55\n",
      "2022-11-26 02:38:01,255 - Sub round: 0\n",
      "2022-11-26 02:38:01,256 - Input: 0 of 0\n",
      "2022-11-26 02:38:01,257 - Last sentinel: <extra_id_2>\n",
      "2022-11-26 02:38:01,258 - INPUT TO EDITOR: label: finding. input: It<extra_id_0> if<extra_id_1> interpretations of deep neural\n",
      "\t\t\t\t\t\tnetwork models respond effectively to the needs of users.\n",
      "2022-11-26 02:38:01,745 - first batch: <pad><extra_id_0> if<extra_id_1> interpretations of deep neural network models respond\n",
      "\t\t\t\t\t\teffectively to the needs of users.<extra_id_2><pad>\n",
      "2022-11-26 02:38:02,476 - Post edit round, top contr prob: 0.4167466461658478\n",
      "2022-11-26 02:38:02,479 - Post edit round, top cand: It  if if interpretations of deep neural network models respond\n",
      "\t\t\t\t\t\teffectively to the needs of users. The interpretations of deep neural network models respond\n",
      "\t\t\t\t\t\teffectively to the needs of users .\n",
      "2022-11-26 02:38:02,511 - Binary search # levels: 4\n",
      "2022-11-26 02:38:02,512 - Found cand: True\n",
      "2022-11-26 02:38:02,513 - Found edit at edit round: {num_rounds}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Explanation Dictionary = {'counterfactual_exists': True, 'output': {'original_input': 'It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .', 'counterfactual_input': ' interpretations of deep neural network models respond effectively to the needs of users. interpretations of deep neural network models respond effectively to the needs of users .', 'counterfactual_label': 'finding', 'counterfactual_confidence': 0.43721163}, 'counterfactual_output': \"interpretations of deep neural network models respond effectively to the needs of users <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>interpretations</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>deep</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>neural</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>network</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>models</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>respond</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>effectively</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>to</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>the</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>needs</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>users</span></b> \"}\n"
     ]
    }
   ],
   "source": [
    "### Check the generated explanation variables\n",
    "explanation_dict = convxai_agent.explainer.generate_explanation(user_intent, explained_sentence, target_label, target_conference)\n",
    "print(f\"Generated Explanation Dictionary = {explanation_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template-based response = The most likely counterfactual label is <strong>'finding'</strong>. You can get this label by revising from \n",
      "'<span class='text-info'>It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .</span>\n",
      "' into: \n",
      " <br>'<em><span class='text-secondary'>interpretations of deep neural network models respond effectively to the needs of users <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>interpretations</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>deep</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>neural</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>network</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>models</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>respond</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>effectively</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>to</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>the</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>needs</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>users</span></b> </span></em>'. <br>I'm confident with this revision with <strong>confidence score=0.4372</strong>.\n"
     ]
    }
   ],
   "source": [
    "### Template-based response (in 'html' format)\n",
    "response = convxai_agent.nlg(user_intent, explanation_dict)\n",
    "print(f\"Template-based response = {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Conversational XAI Demonstration <======\n",
      "User: How can I revise the input to get a different prediction?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ConvXAI: The most likely counterfactual label is <strong>'finding'</strong>. You can get this label by revising from \n",
       "'<span class='text-info'>It is unclear if existing interpretations of deep neural network models respond effectively to the needs of users .</span>\n",
       "' into: \n",
       " <br>'<em><span class='text-secondary'>interpretations of deep neural network models respond effectively to the needs of users <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>interpretations</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>deep</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>neural</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>network</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>models</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>respond</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>effectively</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>to</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>the</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>needs</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>of</span></b> <b><span style='font-weight: bold; background-color: #F9B261; border-radius: 5px;'>users</span></b> </span></em>'. <br>I'm confident with this revision with <strong>confidence score=0.4372</strong>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Display the free-text explanations\n",
    "convxai_agent._visualize_single_turn_dialog(user_question_request, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with ConvXAI Agent (Multi-turn Conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('convxai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "347be804384a984e363a1c4c2bbc012e3ea81df9ffd4ff22b2702561db5c40b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
