{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for computing the data statistics.\n",
    "\n",
    "The result will be saved into the `global_explanations_data` dictionary of `xai_models/models/modules/explainers/ai_comment_statistics.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 18:54:01 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "2022-11-28 18:54:01,239 - Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e54a50d0d84a6c98665fdc0162cd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 18:54:03 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-11-28 18:54:03,246 - Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-11-28 18:54:03 INFO: Use device: gpu\n",
      "2022-11-28 18:54:03,269 - Use device: gpu\n",
      "2022-11-28 18:54:03 INFO: Loading: tokenize\n",
      "2022-11-28 18:54:03,271 - Loading: tokenize\n",
      "2022-11-28 18:54:07 INFO: Loading: pos\n",
      "2022-11-28 18:54:07,560 - Loading: pos\n",
      "2022-11-28 18:54:08 INFO: Loading: lemma\n",
      "2022-11-28 18:54:08,152 - Loading: lemma\n",
      "2022-11-28 18:54:08 INFO: Loading: depparse\n",
      "2022-11-28 18:54:08,200 - Loading: depparse\n",
      "2022-11-28 18:54:08 INFO: Loading: sentiment\n",
      "2022-11-28 18:54:08,497 - Loading: sentiment\n",
      "2022-11-28 18:54:09 INFO: Loading: constituency\n",
      "2022-11-28 18:54:09,104 - Loading: constituency\n",
      "2022-11-28 18:54:09 INFO: Loading: ner\n",
      "2022-11-28 18:54:09,707 - Loading: ner\n",
      "2022-11-28 18:54:10 INFO: Done loading processors!\n",
      "2022-11-28 18:54:10,613 - Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/data/hua/workspace/projects/convxai\")\n",
    "from convxai.xai_models.models.modules.explainers.example_explainer import ExampleExplainer\n",
    "from convxai.writing_models.models.diversity_model import diversity_model_label_mapping, label_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_explanations_data = {\n",
    "    \"ACL\": {\n",
    "        \"paper_count\": 0,\n",
    "        \"sentence_count\": 0,\n",
    "        \"sentence_length\": {},\n",
    "        \"sentence_score_range\": {},\n",
    "        \"abstract_score_range\": {},\n",
    "        \"Aspect_Patterns_dict\": {}\n",
    "    }, \n",
    "    \"CHI\": {\n",
    "        \"paper_count\": 0,\n",
    "        \"sentence_count\": 0,\n",
    "        \"sentence_length\": {},\n",
    "        \"sentence_score_range\": {},\n",
    "        \"abstract_score_range\": {},\n",
    "        \"Aspect_Patterns_dict\": {}\n",
    "    }, \n",
    "    \"ICLR\": {\n",
    "        \"paper_count\": 0,\n",
    "        \"sentence_count\": 0,\n",
    "        \"sentence_length\": {},\n",
    "        \"sentence_score_range\": {},\n",
    "        \"abstract_score_range\": {},\n",
    "        \"Aspect_Patterns_dict\": {}\n",
    "    }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'background', 1: 'purpose', 2: 'method', 3: 'finding', 4: 'other'}\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "acl_df = pd.read_csv(\"./ACL.csv\")\n",
    "chi_df = pd.read_csv(\"./CHI.csv\")\n",
    "iclr_df = pd.read_csv(\"./ICLR.csv\")\n",
    "\n",
    "acl_example_explainer = ExampleExplainer(\"ACL\")\n",
    "chi_example_explainer = ExampleExplainer(\"CHI\")\n",
    "iclr_example_explainer = ExampleExplainer(\"ICLR\")\n",
    "\n",
    "\n",
    "type = 'percentage'\n",
    "\n",
    "print(diversity_model_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholds(score_list, label_list=None, label = None, type='percentage', threshold_level = 0):  \n",
    "    \"\"\"Type = ['deviation', 'percentage'].\n",
    "    percentage: [0, 33, 50, 66, 99.9]\n",
    "    deviation_score: [-2, -1, 0, 1, 2]\n",
    "    threshold_level: [0,1,2,3,4]\n",
    "    \"\"\"\n",
    "    thresholds = {\n",
    "        # 'percentage': [1, 33, 50, 66, 99],\n",
    "        # 'percentage': [0, 33, 50, 66, 99.9],\n",
    "        'percentage': [20, 40, 50, 60, 80],\n",
    "        'deviation': [-2, -1, 0, 1, 2]\n",
    "    }\n",
    "    if label is not None:\n",
    "        if type == 'deviation':\n",
    "            return round(np.mean(np.nan_to_num(score_list)[np.where(label_list == label)[0]]) + thresholds[type][threshold_level] * np.std(score_list[np.where(label_list == label)[0]]), 4)\n",
    "        elif type == 'percentage':\n",
    "            return round(np.percentile(np.nan_to_num(score_list)[np.where(label_list == label)[0]], thresholds[type][threshold_level], axis=0), 4)\n",
    "    else:\n",
    "        if type == 'deviation':\n",
    "            return round(np.mean(np.nan_to_num(score_list)) + thresholds[type][threshold_level] * np.std(score_list), 4)\n",
    "        elif type == 'percentage':\n",
    "            return round(np.percentile(np.nan_to_num(score_list), thresholds[type][threshold_level], axis=0), 4)\n",
    "\n",
    "def save_statistics_to_dict(score_list, label_list=None, label = None, type = 'percentage', threshold_levels=[0, 1, 2, 3, 4]):\n",
    "    scores = [get_thresholds(score_list, label_list=label_list, label = label, type=type, threshold_level = threshold_level) for threshold_level in threshold_levels]\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distribution(score_list, n_bins = 24):\n",
    "    fig, axs = plt.subplots(1, 1, tight_layout=True)\n",
    "    axs.hist(score_list, bins=n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\#Paper Count | \\#Sentence Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======>>> ACL Paper Count =3221\n",
      "======>>> CHI Paper Count =3235\n",
      "======>>> ICLR Paper Count =3479\n",
      "==============================================================\n",
      "======>>> ACL Sentence Count =20744\n",
      "======>>> CHI Sentence Count =21643\n",
      "======>>> ICLR Sentence Count =25873\n",
      "==============================================================\n",
      "global_explanations_data: {'ACL': {'paper_count': 3221, 'sentence_count': 20744, 'sentence_length': {}, 'sentence_score_range': {}, 'abstract_score_range': {}, 'Aspect_Patterns_dict': {}}, 'CHI': {'paper_count': 3235, 'sentence_count': 21643, 'sentence_length': {}, 'sentence_score_range': {}, 'abstract_score_range': {}, 'Aspect_Patterns_dict': {}}, 'ICLR': {'paper_count': 3479, 'sentence_count': 25873, 'sentence_length': {}, 'sentence_score_range': {}, 'abstract_score_range': {}, 'Aspect_Patterns_dict': {}}}\n"
     ]
    }
   ],
   "source": [
    "acl_id = acl_df['id']\n",
    "chi_id = chi_df['id']\n",
    "iclr_id = iclr_df['id']\n",
    "print(f\"======>>> ACL Paper Count ={acl_id.max() + 1}\")\n",
    "print(f\"======>>> CHI Paper Count ={chi_id.max() + 1}\")\n",
    "print(f\"======>>> ICLR Paper Count ={iclr_id.max() + 1}\")\n",
    "\n",
    "print('==============================================================')\n",
    "print(f\"======>>> ACL Sentence Count ={len(acl_id)}\")\n",
    "print(f\"======>>> CHI Sentence Count ={len(chi_id)}\")\n",
    "print(f\"======>>> ICLR Sentence Count ={len(iclr_id)}\")\n",
    "\n",
    "\n",
    "\n",
    "global_explanations_data[\"ACL\"][\"paper_count\"] = acl_id.max() + 1\n",
    "global_explanations_data[\"CHI\"][\"paper_count\"] = chi_id.max() + 1\n",
    "global_explanations_data[\"ICLR\"][\"paper_count\"] = iclr_id.max() + 1\n",
    "\n",
    "global_explanations_data[\"ACL\"][\"sentence_count\"] = len(acl_id)\n",
    "global_explanations_data[\"CHI\"][\"sentence_count\"] = len(chi_id)\n",
    "global_explanations_data[\"ICLR\"][\"sentence_count\"] = len(iclr_id)\n",
    "print('==============================================================')\n",
    "print(f\"global_explanations_data:\", global_explanations_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_idx=0, label=background\n",
      "label_idx=1, label=purpose\n",
      "label_idx=2, label=method\n",
      "label_idx=3, label=finding\n",
      "label_idx=4, label=other\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACL': {'paper_count': 3221,\n",
       "  'sentence_count': 20744,\n",
       "  'sentence_length': {'all': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'background': [16.0, 20.0, 22.0, 24.0, 30.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 34.0],\n",
       "   'method': [18.0, 23.0, 25.0, 27.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 25.0, 27.0, 34.0],\n",
       "   'other': [2.0, 3.0, 3.5, 4.0, 5.4]},\n",
       "  'sentence_score_range': {},\n",
       "  'abstract_score_range': {},\n",
       "  'Aspect_Patterns_dict': {}},\n",
       " 'CHI': {'paper_count': 3235,\n",
       "  'sentence_count': 21643,\n",
       "  'sentence_length': {'all': [17.0, 21.0, 24.0, 26.0, 33.0],\n",
       "   'background': [15.0, 20.0, 22.0, 24.0, 29.0],\n",
       "   'purpose': [19.0, 24.0, 26.0, 28.0, 35.0],\n",
       "   'method': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'other': [2.0, 3.8, 6.5, 7.2, 10.0]},\n",
       "  'sentence_score_range': {},\n",
       "  'abstract_score_range': {},\n",
       "  'Aspect_Patterns_dict': {}},\n",
       " 'ICLR': {'paper_count': 3479,\n",
       "  'sentence_count': 25873,\n",
       "  'sentence_length': {'all': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'background': [17.0, 21.0, 24.0, 26.0, 32.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 35.0],\n",
       "   'method': [19.0, 24.0, 26.0, 29.0, 36.0],\n",
       "   'finding': [18.0, 23.0, 26.0, 29.0, 36.0],\n",
       "   'other': [3.0, 4.0, 5.0, 5.0, 7.0]},\n",
       "  'sentence_score_range': {},\n",
       "  'abstract_score_range': {},\n",
       "  'Aspect_Patterns_dict': {}}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acl_label_list = np.array(acl_df['aspect'])\n",
    "chi_label_list = np.array(chi_df['aspect'])\n",
    "iclr_label_list = np.array(iclr_df['aspect'])\n",
    "\n",
    "acl_token_count_list = acl_df['token_count']\n",
    "chi_token_count_list = chi_df['token_count']\n",
    "iclr_token_count_list = iclr_df['token_count']\n",
    "\n",
    "global_explanations_data[\"ACL\"][\"sentence_length\"][\"all\"] = save_statistics_to_dict(acl_token_count_list, type =type)\n",
    "global_explanations_data[\"CHI\"][\"sentence_length\"][\"all\"] = save_statistics_to_dict(chi_token_count_list, type =type)\n",
    "global_explanations_data[\"ICLR\"][\"sentence_length\"][\"all\"] = save_statistics_to_dict(iclr_token_count_list, type =type)\n",
    "\n",
    "for label_idx, label in diversity_model_label_mapping.items():\n",
    "    print(f\"label_idx={label_idx}, label={label}\")\n",
    "    global_explanations_data[\"ACL\"][\"sentence_length\"][label] = save_statistics_to_dict(acl_token_count_list, acl_label_list, label_idx, type =type)\n",
    "    global_explanations_data[\"CHI\"][\"sentence_length\"][label] = save_statistics_to_dict(chi_token_count_list, chi_label_list, label_idx, type = type)\n",
    "    global_explanations_data[\"ICLR\"][\"sentence_length\"][label] = save_statistics_to_dict(iclr_token_count_list, iclr_label_list, label_idx, type = type)\n",
    "\n",
    "global_explanations_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Score Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acl_ppl_range\n",
    "# visualize_distribution(acl_paper_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_idx=0, label=background\n",
      "label_idx=1, label=purpose\n",
      "label_idx=2, label=method\n",
      "label_idx=3, label=finding\n",
      "label_idx=4, label=other\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACL': {'paper_count': 3221,\n",
       "  'sentence_count': 20744,\n",
       "  'sentence_length': {'all': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'background': [16.0, 20.0, 22.0, 24.0, 30.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 34.0],\n",
       "   'method': [18.0, 23.0, 25.0, 27.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 25.0, 27.0, 34.0],\n",
       "   'other': [2.0, 3.0, 3.5, 4.0, 5.4]},\n",
       "  'sentence_score_range': {'all': [27.6981,\n",
       "    40.9609,\n",
       "    48.5276,\n",
       "    57.8652,\n",
       "    85.9444],\n",
       "   'background': [27.191, 39.669, 46.89, 56.4117, 83.9507],\n",
       "   'purpose': [27.6238, 38.2317, 43.4746, 50.4653, 70.827],\n",
       "   'method': [35.569, 49.9949, 57.9529, 66.9595, 98.9945],\n",
       "   'finding': [23.6077, 37.394, 45.3252, 54.585, 84.4604],\n",
       "   'other': [75.6189, 99.9501, 133.1788, 183.2107, 320.2562]},\n",
       "  'abstract_score_range': {},\n",
       "  'Aspect_Patterns_dict': {}},\n",
       " 'CHI': {'paper_count': 3235,\n",
       "  'sentence_count': 21643,\n",
       "  'sentence_length': {'all': [17.0, 21.0, 24.0, 26.0, 33.0],\n",
       "   'background': [15.0, 20.0, 22.0, 24.0, 29.0],\n",
       "   'purpose': [19.0, 24.0, 26.0, 28.0, 35.0],\n",
       "   'method': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'other': [2.0, 3.8, 6.5, 7.2, 10.0]},\n",
       "  'sentence_score_range': {'all': [42.2878,\n",
       "    61.4897,\n",
       "    72.3591,\n",
       "    85.7752,\n",
       "    131.7779],\n",
       "   'background': [38.6534, 56.7407, 67.1963, 80.2813, 120.997],\n",
       "   'purpose': [38.7053, 53.5934, 63.0394, 72.7738, 104.4246],\n",
       "   'method': [47.4223, 68.4169, 81.0372, 95.2569, 145.4662],\n",
       "   'finding': [46.0023, 65.6886, 77.9507, 92.5674, 146.4827],\n",
       "   'other': [13.2939, 45.8325, 106.1932, 144.5963, 536.4016]},\n",
       "  'abstract_score_range': {},\n",
       "  'Aspect_Patterns_dict': {}},\n",
       " 'ICLR': {'paper_count': 3479,\n",
       "  'sentence_count': 25873,\n",
       "  'sentence_length': {'all': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'background': [17.0, 21.0, 24.0, 26.0, 32.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 35.0],\n",
       "   'method': [19.0, 24.0, 26.0, 29.0, 36.0],\n",
       "   'finding': [18.0, 23.0, 26.0, 29.0, 36.0],\n",
       "   'other': [3.0, 4.0, 5.0, 5.0, 7.0]},\n",
       "  'sentence_score_range': {'all': [44.4078,\n",
       "    67.0809,\n",
       "    79.8273,\n",
       "    95.263,\n",
       "    147.0747],\n",
       "   'background': [41.1458, 62.9019, 75.3028, 89.1512, 139.4776],\n",
       "   'purpose': [40.274, 57.9098, 68.678, 80.0574, 119.0104],\n",
       "   'method': [53.5989, 77.6237, 91.607, 107.9586, 161.8594],\n",
       "   'finding': [43.8051, 67.2682, 80.5254, 97.1226, 151.8759],\n",
       "   'other': [35.5977, 60.0705, 81.7715, 96.6604, 169.3116]},\n",
       "  'abstract_score_range': {},\n",
       "  'Aspect_Patterns_dict': {}}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acl_ppl_range = acl_df['perplexity']\n",
    "chi_ppl_range = chi_df['perplexity']\n",
    "iclr_ppl_range = iclr_df['perplexity']\n",
    "\n",
    "global_explanations_data[\"ACL\"][\"sentence_score_range\"][\"all\"] = save_statistics_to_dict(acl_ppl_range, type =type)\n",
    "global_explanations_data[\"CHI\"][\"sentence_score_range\"][\"all\"] = save_statistics_to_dict(chi_ppl_range, type =type)\n",
    "global_explanations_data[\"ICLR\"][\"sentence_score_range\"][\"all\"] = save_statistics_to_dict(iclr_ppl_range, type =type)\n",
    "global_explanations_data\n",
    "\n",
    "\n",
    "\n",
    "for label_idx, label in diversity_model_label_mapping.items():\n",
    "    print(f\"label_idx={label_idx}, label={label}\")\n",
    "    global_explanations_data[\"ACL\"][\"sentence_score_range\"][label] = save_statistics_to_dict(acl_ppl_range, acl_label_list, label_idx, type = type)\n",
    "    global_explanations_data[\"CHI\"][\"sentence_score_range\"][label] = save_statistics_to_dict(chi_ppl_range, chi_label_list, label_idx, type = type)\n",
    "    global_explanations_data[\"ICLR\"][\"sentence_score_range\"][label] = save_statistics_to_dict(iclr_ppl_range, iclr_label_list, label_idx, type = type)\n",
    "\n",
    "global_explanations_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract Score Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACL': {'paper_count': 3221,\n",
       "  'sentence_count': 20744,\n",
       "  'sentence_length': {'all': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'background': [16.0, 20.0, 22.0, 24.0, 30.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 34.0],\n",
       "   'method': [18.0, 23.0, 25.0, 27.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 25.0, 27.0, 34.0],\n",
       "   'other': [2.0, 3.0, 3.5, 4.0, 5.4]},\n",
       "  'sentence_score_range': {'all': [27.6981,\n",
       "    40.9609,\n",
       "    48.5276,\n",
       "    57.8652,\n",
       "    85.9444],\n",
       "   'background': [27.191, 39.669, 46.89, 56.4117, 83.9507],\n",
       "   'purpose': [27.6238, 38.2317, 43.4746, 50.4653, 70.827],\n",
       "   'method': [35.569, 49.9949, 57.9529, 66.9595, 98.9945],\n",
       "   'finding': [23.6077, 37.394, 45.3252, 54.585, 84.4604],\n",
       "   'other': [75.6189, 99.9501, 133.1788, 183.2107, 320.2562]},\n",
       "  'abstract_score_range': [40.7945, 51.096, 56.5085, 62.6393, 80.277],\n",
       "  'Aspect_Patterns_dict': {}},\n",
       " 'CHI': {'paper_count': 3235,\n",
       "  'sentence_count': 21643,\n",
       "  'sentence_length': {'all': [17.0, 21.0, 24.0, 26.0, 33.0],\n",
       "   'background': [15.0, 20.0, 22.0, 24.0, 29.0],\n",
       "   'purpose': [19.0, 24.0, 26.0, 28.0, 35.0],\n",
       "   'method': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'other': [2.0, 3.8, 6.5, 7.2, 10.0]},\n",
       "  'sentence_score_range': {'all': [42.2878,\n",
       "    61.4897,\n",
       "    72.3591,\n",
       "    85.7752,\n",
       "    131.7779],\n",
       "   'background': [38.6534, 56.7407, 67.1963, 80.2813, 120.997],\n",
       "   'purpose': [38.7053, 53.5934, 63.0394, 72.7738, 104.4246],\n",
       "   'method': [47.4223, 68.4169, 81.0372, 95.2569, 145.4662],\n",
       "   'finding': [46.0023, 65.6886, 77.9507, 92.5674, 146.4827],\n",
       "   'other': [13.2939, 45.8325, 106.1932, 144.5963, 536.4016]},\n",
       "  'abstract_score_range': [61.8875, 77.8445, 86.2938, 95.7494, 124.9658],\n",
       "  'Aspect_Patterns_dict': {}},\n",
       " 'ICLR': {'paper_count': 3479,\n",
       "  'sentence_count': 25873,\n",
       "  'sentence_length': {'all': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'background': [17.0, 21.0, 24.0, 26.0, 32.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 35.0],\n",
       "   'method': [19.0, 24.0, 26.0, 29.0, 36.0],\n",
       "   'finding': [18.0, 23.0, 26.0, 29.0, 36.0],\n",
       "   'other': [3.0, 4.0, 5.0, 5.0, 7.0]},\n",
       "  'sentence_score_range': {'all': [44.4078,\n",
       "    67.0809,\n",
       "    79.8273,\n",
       "    95.263,\n",
       "    147.0747],\n",
       "   'background': [41.1458, 62.9019, 75.3028, 89.1512, 139.4776],\n",
       "   'purpose': [40.274, 57.9098, 68.678, 80.0574, 119.0104],\n",
       "   'method': [53.5989, 77.6237, 91.607, 107.9586, 161.8594],\n",
       "   'finding': [43.8051, 67.2682, 80.5254, 97.1226, 151.8759],\n",
       "   'other': [35.5977, 60.0705, 81.7715, 96.6604, 169.3116]},\n",
       "  'abstract_score_range': [67.6627, 85.276, 95.7696, 107.073, 140.8787],\n",
       "  'Aspect_Patterns_dict': {}}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Aspect List ######\n",
    "acl_paper_score = []\n",
    "for i in range(acl_id.max()+1):\n",
    "    acl_df_filter_ppl=acl_df.query(f\"id == {i}\")['perplexity']\n",
    "    acl_paper_score.append(np.mean(acl_df_filter_ppl))\n",
    "chi_paper_score = []\n",
    "for i in range(chi_id.max()+1):\n",
    "    chi_df_filter_ppl=chi_df.query(f\"id == {i}\")['perplexity']\n",
    "    chi_paper_score.append(np.mean(chi_df_filter_ppl))\n",
    "iclr_paper_score = []\n",
    "for i in range(iclr_id.max()+1):\n",
    "    iclr_df_filter_ppl=iclr_df.query(f\"id == {i}\")['perplexity']\n",
    "    iclr_paper_score.append(np.mean(iclr_df_filter_ppl))\n",
    "\n",
    "# def normalize(data):\n",
    "#     normalized_data = (data - np.min(data)) / (np.percentile(data, 99.9) - np.min(data))\n",
    "#     return normalized_data\n",
    "# acl_paper_score = normalize(acl_paper_score)\n",
    "# chi_paper_score = normalize(chi_paper_score)\n",
    "# iclr_paper_score = normalize(iclr_paper_score)\n",
    "\n",
    "\n",
    "global_explanations_data[\"ACL\"][\"abstract_score_range\"] = save_statistics_to_dict(acl_paper_score, type = type)\n",
    "global_explanations_data[\"CHI\"][\"abstract_score_range\"] = save_statistics_to_dict(chi_paper_score, type = type)\n",
    "global_explanations_data[\"ICLR\"][\"abstract_score_range\"] = save_statistics_to_dict(iclr_paper_score, type = type)\n",
    "global_explanations_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect_Patterns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACL': {'paper_count': 3221,\n",
       "  'sentence_count': 20744,\n",
       "  'sentence_length': {'all': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'background': [16.0, 20.0, 22.0, 24.0, 30.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 34.0],\n",
       "   'method': [18.0, 23.0, 25.0, 27.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 25.0, 27.0, 34.0],\n",
       "   'other': [2.0, 3.0, 3.5, 4.0, 5.4]},\n",
       "  'sentence_score_range': {'all': [27.6981,\n",
       "    40.9609,\n",
       "    48.5276,\n",
       "    57.8652,\n",
       "    85.9444],\n",
       "   'background': [27.191, 39.669, 46.89, 56.4117, 83.9507],\n",
       "   'purpose': [27.6238, 38.2317, 43.4746, 50.4653, 70.827],\n",
       "   'method': [35.569, 49.9949, 57.9529, 66.9595, 98.9945],\n",
       "   'finding': [23.6077, 37.394, 45.3252, 54.585, 84.4604],\n",
       "   'other': [75.6189, 99.9501, 133.1788, 183.2107, 320.2562]},\n",
       "  'abstract_score_range': [40.7945, 51.096, 56.5085, 62.6393, 80.277],\n",
       "  'Aspect_Patterns_dict': {'00122233': \"'background' (25%)   -&gt; 'purpose' (12.5%) -&gt; 'method'  (37.5%) -&gt; 'finding' (25%)\",\n",
       "   '001233': \"'background' (33.3%) -&gt; 'purpose' (16.7%) -&gt; 'method'  (16.7%) -&gt; 'finding' (33.3%)\",\n",
       "   '0002233': \"'background' (42.9%) -&gt; 'method'  (28.6%) -&gt; 'finding' (28.5%)\",\n",
       "   '000133': \"'background' (50%)   -&gt; 'purpose' (16.7%) -&gt; 'finding' (33.3%)\",\n",
       "   '00323333': \"'background' (25%)   -&gt; 'finding' (12.5%) -&gt; 'method'  (12.5%) -&gt; 'finding' (50%)\"}},\n",
       " 'CHI': {'paper_count': 3235,\n",
       "  'sentence_count': 21643,\n",
       "  'sentence_length': {'all': [17.0, 21.0, 24.0, 26.0, 33.0],\n",
       "   'background': [15.0, 20.0, 22.0, 24.0, 29.0],\n",
       "   'purpose': [19.0, 24.0, 26.0, 28.0, 35.0],\n",
       "   'method': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'finding': [17.0, 22.0, 24.0, 27.0, 33.0],\n",
       "   'other': [2.0, 3.8, 6.5, 7.2, 10.0]},\n",
       "  'sentence_score_range': {'all': [42.2878,\n",
       "    61.4897,\n",
       "    72.3591,\n",
       "    85.7752,\n",
       "    131.7779],\n",
       "   'background': [38.6534, 56.7407, 67.1963, 80.2813, 120.997],\n",
       "   'purpose': [38.7053, 53.5934, 63.0394, 72.7738, 104.4246],\n",
       "   'method': [47.4223, 68.4169, 81.0372, 95.2569, 145.4662],\n",
       "   'finding': [46.0023, 65.6886, 77.9507, 92.5674, 146.4827],\n",
       "   'other': [13.2939, 45.8325, 106.1932, 144.5963, 536.4016]},\n",
       "  'abstract_score_range': [61.8875, 77.8445, 86.2938, 95.7494, 124.9658],\n",
       "  'Aspect_Patterns_dict': {'0001333': \"'background' (42.9%) -&gt; 'purpose' (14.3%)  -&gt; 'finding' (42.9%)\",\n",
       "   '001222333': \"'background' (22.2%) -&gt; 'purpose' (11.2%) -&gt; 'method' (33.3%) -&gt; 'finding' (33.3%)\",\n",
       "   '001233': \"'background' (33.3%) -&gt; 'purpose' (16.7%) -&gt; 'method' (16.7%)  -&gt; 'finding' (33.3%)\",\n",
       "   '002333': \"'background' (33.3%) -&gt; 'method' (16.7%)  -&gt;  'finding' (50%)\",\n",
       "   '000300100323333': \"'background' (20%)   -&gt; 'finding' (6.7%)  -&gt;  'background' (13.3%) -&gt; 'purpose' (6.7%) -&gt; 'background' (13.3%) -&gt; 'finding' (6.7%) -&gt; 'method' (6.7%) -&gt; 'finding' (26.7%)\"}},\n",
       " 'ICLR': {'paper_count': 3479,\n",
       "  'sentence_count': 25873,\n",
       "  'sentence_length': {'all': [18.0, 23.0, 25.0, 28.0, 35.0],\n",
       "   'background': [17.0, 21.0, 24.0, 26.0, 32.0],\n",
       "   'purpose': [19.0, 23.0, 26.0, 28.0, 35.0],\n",
       "   'method': [19.0, 24.0, 26.0, 29.0, 36.0],\n",
       "   'finding': [18.0, 23.0, 26.0, 29.0, 36.0],\n",
       "   'other': [3.0, 4.0, 5.0, 5.0, 7.0]},\n",
       "  'sentence_score_range': {'all': [44.4078,\n",
       "    67.0809,\n",
       "    79.8273,\n",
       "    95.263,\n",
       "    147.0747],\n",
       "   'background': [41.1458, 62.9019, 75.3028, 89.1512, 139.4776],\n",
       "   'purpose': [40.274, 57.9098, 68.678, 80.0574, 119.0104],\n",
       "   'method': [53.5989, 77.6237, 91.607, 107.9586, 161.8594],\n",
       "   'finding': [43.8051, 67.2682, 80.5254, 97.1226, 151.8759],\n",
       "   'other': [35.5977, 60.0705, 81.7715, 96.6604, 169.3116]},\n",
       "  'abstract_score_range': [67.6627, 85.276, 95.7696, 107.073, 140.8787],\n",
       "  'Aspect_Patterns_dict': {'001233': \"'background' (33.3%) -&gt; 'purpose' (16.7%) -&gt; 'method' (16.7%) -&gt; 'finding' (33.3%)\",\n",
       "   '23333': \"'Method' (20%) -&gt; 'finding' (80%)\",\n",
       "   '0001333': \"'background' (42.9%) -&gt; 'purpose' (14.2) -&gt; 'finding' (42.9%)\",\n",
       "   '00000232333': \"'background' (45.5%) -&gt; 'method' (9.1%) -&gt; 'finding' (9.1%) -&gt; 'method' (9.1%) -&gt; 'finding' (27.3%)\",\n",
       "   '001222333': \"'Background' (22.2%) -&gt; 'purpose' (11.1%) -&gt; 'method' (33.3%) -&gt; 'finding' (33.4%)\"}}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_explanations_data[\"ACL\"][\"Aspect_Patterns_dict\"] = {\n",
    "                    \"00122233\": \"'background' (25%)   -&gt; 'purpose' (12.5%) -&gt; 'method'  (37.5%) -&gt; 'finding' (25%)\",\n",
    "                    \"001233\": \"'background' (33.3%) -&gt; 'purpose' (16.7%) -&gt; 'method'  (16.7%) -&gt; 'finding' (33.3%)\",\n",
    "                    \"0002233\": \"'background' (42.9%) -&gt; 'method'  (28.6%) -&gt; 'finding' (28.5%)\",\n",
    "                    \"000133\": \"'background' (50%)   -&gt; 'purpose' (16.7%) -&gt; 'finding' (33.3%)\",\n",
    "                    \"00323333\": \"'background' (25%)   -&gt; 'finding' (12.5%) -&gt; 'method'  (12.5%) -&gt; 'finding' (50%)\",\n",
    "                }\n",
    "\n",
    "global_explanations_data[\"CHI\"][\"Aspect_Patterns_dict\"] = {\n",
    "                    \"0001333\": \"'background' (42.9%) -&gt; 'purpose' (14.3%)  -&gt; 'finding' (42.9%)\",\n",
    "                    \"001222333\": \"'background' (22.2%) -&gt; 'purpose' (11.2%) -&gt; 'method' (33.3%) -&gt; 'finding' (33.3%)\",\n",
    "                    \"001233\": \"'background' (33.3%) -&gt; 'purpose' (16.7%) -&gt; 'method' (16.7%)  -&gt; 'finding' (33.3%)\",\n",
    "                    \"002333\": \"'background' (33.3%) -&gt; 'method' (16.7%)  -&gt;  'finding' (50%)\",\n",
    "                    \"000300100323333\": \"'background' (20%)   -&gt; 'finding' (6.7%)  -&gt;  'background' (13.3%) -&gt; 'purpose' (6.7%) -&gt; 'background' (13.3%) -&gt; 'finding' (6.7%) -&gt; 'method' (6.7%) -&gt; 'finding' (26.7%)\"\n",
    "                }\n",
    "\n",
    "global_explanations_data[\"ICLR\"][\"Aspect_Patterns_dict\"] = {\n",
    "                    \"001233\": \"'background' (33.3%) -&gt; 'purpose' (16.7%) -&gt; 'method' (16.7%) -&gt; 'finding' (33.3%)\",\n",
    "                    \"23333\": \"'Method' (20%) -&gt; 'finding' (80%)\",\n",
    "                    \"0001333\": \"'background' (42.9%) -&gt; 'purpose' (14.2) -&gt; 'finding' (42.9%)\",\n",
    "                    \"00000232333\": \"'background' (45.5%) -&gt; 'method' (9.1%) -&gt; 'finding' (9.1%) -&gt; 'method' (9.1%) -&gt; 'finding' (27.3%)\",\n",
    "                    \"001222333\": \"'Background' (22.2%) -&gt; 'purpose' (11.1%) -&gt; 'method' (33.3%) -&gt; 'finding' (33.4%)\",\n",
    "                }\n",
    "global_explanations_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def np_encoder(object):\n",
    "    if isinstance(object, np.generic):\n",
    "        return object.item()\n",
    "\n",
    "with open(f'ai_comment_statistics_{type}.json', 'w') as fp:\n",
    "    json.dump(global_explanations_data, fp, indent=2, default=np_encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('convxai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "347be804384a984e363a1c4c2bbc012e3ea81df9ffd4ff22b2702561db5c40b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
