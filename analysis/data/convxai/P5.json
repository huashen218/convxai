[
  {
    "_id": "639123cd8c15db04700de5ef",
    "user_id": "P5",
    "time": "2022-12-07 23:37:49.228000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .Our findings show that generalizing to new document templates is very challenging , models have difficulty dealing with nested fields such as line-items in an invoice , and there is plenty of room for improvement in few-shot performance .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "save"
  },
  {
    "_id": "639123c88c15db04700de5ee",
    "user_id": "P5",
    "time": "2022-12-07 23:37:44.280000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .Our findings show that generalizing to new document templates is very challenging , models have difficulty dealing with nested fields such as line-items in an invoice , and there is plenty of room for improvement in few-shot performance .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639123a78c15db04700de5ed",
    "user_id": "P5",
    "time": "2022-12-07 23:37:11.771000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .Our findings show that generalizing to new document templates is very challenging , models have difficulty dealing with nested fields such as line-items in an invoice , and there is plenty of room for improvement in few-shot performance .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639123728c15db04700de5ec",
    "user_id": "P5",
    "time": "2022-12-07 23:36:18.084000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .Our findings show that generalizing to new document templates is very challenging , models have difficulty dealing with nested fields such as line-items in an invoice , and there is plenty of room for improvement in few-shot performance .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639123658c15db04700de5e9",
    "user_id": "P5",
    "time": "2022-12-07 23:36:05.656000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .Our\u00a0findings\u00a0show\u00a0that generalizing to new document templates is very\u00a0challenging,\u00a0models\u00a0have\u00a0difficulty dealing\u00a0with nested fields such as line-items in an\u00a0invoice,and\u00a0there\u00a0is\u00a0plenty\u00a0of\u00a0room\u00a0for\u00a0improvement\u00a0in\u00a0few-shot performance.We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639123618c15db04700de5e8",
    "user_id": "P5",
    "time": "2022-12-07 23:36:01.387000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .Our\u00a0findings\u00a0show\u00a0that generalizing to new document templates is very\u00a0challenging,\u00a0models\u00a0have\u00a0difficulty dealing\u00a0with nested fields such as line-items in an\u00a0invoice,and\u00a0there\u00a0is\u00a0plenty\u00a0of\u00a0room\u00a0for\u00a0improvement\u00a0in\u00a0few-shot performance.We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "639122e98c15db04700de5e2",
    "user_id": "P5",
    "time": "2022-12-07 23:34:01.754000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We find that generalizing to new document templates is very challenging , models struggle with nested fields such as line-items in an invoice , and few-shot performance has a lot of headroom .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639122d88c15db04700de5df",
    "user_id": "P5",
    "time": "2022-12-07 23:33:44.933000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We find that generalizing to new document templates is very challenging , models struggle with nested fields such as line-items in an invoice, and few-shot performance has a lot of headroom .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "639122ac8c15db04700de5dd",
    "user_id": "P5",
    "time": "2022-12-07 23:33:00.821000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We find that generalizing to new document templates is very challenging , and models struggle with nested fields such as line-items in an invoice .Also , few-shot performance has a lot of headroom .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6391229b8c15db04700de5da",
    "user_id": "P5",
    "time": "2022-12-07 23:32:43.358000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We find that generalizing to new document templates is very challenging, and models struggle with nested fields such as line-items in an invoice. Also, few-shot performance has a lot of headroom.We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "639122958c15db04700de5d8",
    "user_id": "P5",
    "time": "2022-12-07 23:32:37.644000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We find that generalizing to new document templates is very challenging, and models struggle with nested fields such as line-items in an invoice. Also, few-shot performance has a lot of headroom.We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639122788c15db04700de5d7",
    "user_id": "P5",
    "time": "2022-12-07 23:32:08.045000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We find that generalizing to new document templates is very challenging, models struggle with nested fields such as line-items in an invoice, and few-shot performance has a lot of headroom.We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6391223e8c15db04700de5d6",
    "user_id": "P5",
    "time": "2022-12-07 23:31:10.332000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We find that generalizing to new document templates is very challenging, and models struggle with nested fields such as line-items in an invoice.\nAlso, few-shot performance has a lot of headroom.We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639121528c15db04700de5d5",
    "user_id": "P5",
    "time": "2022-12-07 23:27:14.917000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639121458c15db04700de5d2",
    "user_id": "P5",
    "time": "2022-12-07 23:27:01.261000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639121418c15db04700de5d1",
    "user_id": "P5",
    "time": "2022-12-07 23:26:57.635000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "639120e88c15db04700de5cb",
    "user_id": "P5",
    "time": "2022-12-07 23:25:28.434000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .The evaluation of extraction results was conducted in few-shot and conventional experiment settings along with a carefully designed matching algorithm .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639120958c15db04700de5ca",
    "user_id": "P5",
    "time": "2022-12-07 23:24:05.841000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639120848c15db04700de5c7",
    "user_id": "P5",
    "time": "2022-12-07 23:23:48.455000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "639120398c15db04700de5c3",
    "user_id": "P5",
    "time": "2022-12-07 23:22:33.316000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6391201f8c15db04700de5c2",
    "user_id": "P5",
    "time": "2022-12-07 23:22:07.418000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911f8b8c15db04700de5b9",
    "user_id": "P5",
    "time": "2022-12-07 23:19:39.639000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU : 1 ) rich schema including diverse data types as well as nested entities , and 2 ) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911f7b8c15db04700de5b6",
    "user_id": "P5",
    "time": "2022-12-07 23:19:23.404000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU: 1) rich schema including diverse data types as well as nested entities, and 2) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911f7a8c15db04700de5b5",
    "user_id": "P5",
    "time": "2022-12-07 23:19:22.097000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU: 1) rich schema including diverse data types as well as nested entities, and 2) complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "63911f538c15db04700de5b3",
    "user_id": "P5",
    "time": "2022-12-07 23:18:43.541000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU: 1) rich schema including diverse data types as well as nested entities rich schema including diverse data types as well as nested entities , and the other is complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911ea68c15db04700de5ac",
    "user_id": "P5",
    "time": "2022-12-07 23:15:50.583000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We construct two datasets representing several challenges for VRDU .One is rich schema including diverse data types as well as nested entities , and the other is complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911e9b8c15db04700de5a9",
    "user_id": "P5",
    "time": "2022-12-07 23:15:39.854000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We\u00a0construct\u00a0two datasets\u00a0representing\u00a0several challenges\u00a0for\u00a0VRDU. One is rich schema including diverse data types as well as nested entities , and the other is complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911e958c15db04700de5a8",
    "user_id": "P5",
    "time": "2022-12-07 23:15:33.450000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We\u00a0construct\u00a0two datasets\u00a0representing\u00a0several challenges\u00a0for\u00a0VRDU. One is rich schema including diverse data types as well as nested entities , and the other is complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "63911e668c15db04700de5a6",
    "user_id": "P5",
    "time": "2022-12-07 23:14:46.419000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .We contruct VRDU contains two datasets:  rich schema including diverse data types as well as nested entities , and the other is complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911e598c15db04700de5a5",
    "user_id": "P5",
    "time": "2022-12-07 23:14:33.185000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .VRDU contains two datasets:  rich schema including diverse data types as well as nested entities , and the other is complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911da18c15db04700de5a0",
    "user_id": "P5",
    "time": "2022-12-07 23:11:29.515000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .VRDU contains two datasets that represent several challenges .One is rich schema including diverse data types as well as nested entities , and the other is complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911d908c15db04700de59d",
    "user_id": "P5",
    "time": "2022-12-07 23:11:12.267000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .VRDU contains two datasets that represent several challenges. One is rich schema including diverse data types as well as nested entities, and the other is complex templates including tables and multi-column layouts, and diversity of differ- ent layouts (templates) within a single docu- ment type.We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "63911d878c15db04700de59b",
    "user_id": "P5",
    "time": "2022-12-07 23:11:03.858000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .VRDU contains two datasets that represent several challenges. One is rich schema including diverse data types as well as nested entities, and the other is complex templates including tables and multi-column layouts, and diversity of differ- ent layouts (templates) within a single docu- ment type.We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911d308c15db04700de59a",
    "user_id": "P5",
    "time": "2022-12-07 23:09:36.947000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .VRDU contains two datasets that represent several challenges: rich schema in- cluding diverse data types as well as nested en- tities, complex templates including tables and multi-column layouts, and diversity of differ- ent layouts (templates) within a single docu- ment type.We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911cc88c15db04700de599",
    "user_id": "P5",
    "time": "2022-12-07 23:07:52.519000",
    "text": "Recent research and industry efforts have focused onunderstanding visually-rich business documents to extract structured data and automate business workflows .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .Multimodal pre-training with text , layout , and imagehas made significant progress for Visually RichDocument Understanding ( VRDU ) , especially the fixed-layout documents such as scanned document images .VRDU contains two datasets that represent several challenges , including rich schema with diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts within a single document type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911cb68c15db04700de596",
    "user_id": "P5",
    "time": "2022-12-07 23:07:34.928000",
    "text": "Recent\u00a0research\u00a0and\u00a0industry\u00a0efforts\u00a0have\u00a0focused\u00a0onunderstanding\u00a0visually-rich business\u00a0documents\u00a0to extract structured data and\u00a0automate\u00a0business workflows.Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .Multimodal\u00a0pre-training\u00a0with\u00a0text,\u00a0layout,\u00a0and\u00a0imagehas\u00a0made\u00a0significant\u00a0progress\u00a0for\u00a0Visually\u00a0RichDocument\u00a0Understanding\u00a0(VRDU),\u00a0especially\u00a0the\u00a0fixed-layout\u00a0documents\u00a0such\u00a0as\u00a0scanned\u00a0document\u00a0images. VRDU contains two datasets that represent several\u00a0challenges,\u00a0including\u00a0rich schema\u00a0with\u00a0diverse data types as well as nested\u00a0entities,\u00a0complex templates including tables and multi-column\u00a0layouts,\u00a0and diversity of\u00a0different\u00a0layouts within a single\u00a0document\u00a0type.We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "63911cb48c15db04700de594",
    "user_id": "P5",
    "time": "2022-12-07 23:07:32.194000",
    "text": "Recent\u00a0research\u00a0and\u00a0industry\u00a0efforts\u00a0have\u00a0focused\u00a0onunderstanding\u00a0visually-rich business\u00a0documents\u00a0to extract structured data and\u00a0automate\u00a0business workflows.Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .Multimodal\u00a0pre-training\u00a0with\u00a0text,\u00a0layout,\u00a0and\u00a0imagehas\u00a0made\u00a0significant\u00a0progress\u00a0for\u00a0Visually\u00a0RichDocument\u00a0Understanding\u00a0(VRDU),\u00a0especially\u00a0the\u00a0fixed-layout\u00a0documents\u00a0such\u00a0as\u00a0scanned\u00a0document\u00a0images. VRDU contains two datasets that represent several\u00a0challenges,\u00a0including\u00a0rich schema\u00a0with\u00a0diverse data types as well as nested\u00a0entities,\u00a0complex templates including tables and multi-column\u00a0layouts,\u00a0and diversity of\u00a0different\u00a0layouts within a single\u00a0document\u00a0type.We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911ca28c15db04700de593",
    "user_id": "P5",
    "time": "2022-12-07 23:07:14.498000",
    "text": "Recent\u00a0research\u00a0and\u00a0industry\u00a0efforts\u00a0have\u00a0focused\u00a0onunderstanding\u00a0visually-rich business\u00a0documents\u00a0to extract structured data and\u00a0automate\u00a0business workflows.Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .Multimodal\u00a0pre-training\u00a0with\u00a0text,\u00a0layout,\u00a0and\u00a0imagehas\u00a0made\u00a0significant\u00a0progress\u00a0for\u00a0Visually\u00a0RichDocument\u00a0Understanding\u00a0(VRDU),\u00a0especially\u00a0the\u00a0fixed-layout\u00a0documents\u00a0such\u00a0as\u00a0scanned\u00a0document\u00a0images. VRDU contains two datasets that represent several\u00a0challenges,\u00a0including\u00a0rich schema\u00a0with\u00a0diverse data types as well as nested\u00a0entities,\u00a0complex templates including tables and multi-column\u00a0layouts,\u00a0and diversity of\u00a0different\u00a0layouts within a single\u00a0document\u00a0typeWe design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911b1c8c15db04700de58a",
    "user_id": "P5",
    "time": "2022-12-07 23:00:44.275000",
    "text": "Recent\u00a0research\u00a0and\u00a0industry\u00a0efforts\u00a0have\u00a0focused\u00a0onunderstanding\u00a0visually-rich business\u00a0documents\u00a0to extract structured data and\u00a0automate\u00a0business workflows.Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .VRDU contains two datasets that represent several challenges : rich schema in-cluding diverse data types as well as nested en-tities , complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911a9f8c15db04700de581",
    "user_id": "P5",
    "time": "2022-12-07 22:58:39.196000",
    "text": "Understanding visually-rich business docu-ments to extract structured data and auto-mate business workflows has been receiving attention both in academia and industry .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we propose a comprehensive benchmark called Visually Rich Document Understanding ( VRDU ) and identify the desiderata for it .VRDU contains two datasets that represent several challenges : rich schema in-cluding diverse data types as well as nested en-tities , complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "63911a8e8c15db04700de57e",
    "user_id": "P5",
    "time": "2022-12-07 22:58:22.272000",
    "text": "Understanding visually-rich business docu-ments to extract structured data and auto-mate business workflows has been receiving attention both in academia and industry .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In\u00a0this\u00a0work,\u00a0we\u00a0propose\u00a0a\u00a0comprehensive\u00a0benchmark called\u00a0Visually\u00a0Rich\u00a0Document\u00a0Understanding\u00a0(VRDU) and\u00a0identify the desiderata for\u00a0it.VRDU contains two datasets that represent several challenges : rich schema in-cluding diverse data types as well as nested en-tities , complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-1",
    "conversation_id": "639119a08c15db04700de56e"
  },
  {
    "_id": "63911a7e8c15db04700de57c",
    "user_id": "P5",
    "time": "2022-12-07 22:58:06.768000",
    "text": "Understanding visually-rich business docu-ments to extract structured data and auto-mate business workflows has been receiving attention both in academia and industry .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In\u00a0this\u00a0work,\u00a0we\u00a0propose\u00a0a\u00a0comprehensive\u00a0benchmark called\u00a0Visually\u00a0Rich\u00a0Document\u00a0Understanding\u00a0(VRDU) and\u00a0identify the desiderata for\u00a0it.VRDU contains two datasets that represent several challenges : rich schema in-cluding diverse data types as well as nested en-tities , complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639119c78c15db04700de573",
    "user_id": "P5",
    "time": "2022-12-07 22:55:03.661000",
    "text": "Understanding visually-rich business docu-ments to extract structured data and auto-mate business workflows has been receiving attention both in academia and industry .Al-though recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the com-plexity of real documents seen in industry .In this work , we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understand-ing ( VRDU ) .VRDU contains two datasets that represent several challenges : rich schema in-cluding diverse data types as well as nested en-tities , complex templates including tables and multi-column layouts , and diversity of differ-ent layouts ( templates ) within a single docu-ment type .We design few-shot and conven-tional experiment settings along with a care-fully designed matching algorithm to evalu-ate extraction results .We report the perfor-mance of strong baselines and three observa-tions : ( 1 ) generalizing to new document tem-plates is very challenging , ( 2 ) few-shot perfor-mance has a lot of headroom , and ( 3 ) mod-els struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting struc-tured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "639119b58c15db04700de570",
    "user_id": "P5",
    "time": "2022-12-07 22:54:45.908000",
    "text": "Understanding visually-rich business docu- ments to extract structured data and auto- mate business workflows has been receiving attention both in academia and industry. Al- though recent multi-modal language models have achieved impressive results, we find that existing benchmarks do not reflect the com- plexity of real documents seen in industry. In this work, we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understand- ing (VRDU). VRDU contains two datasets that represent several challenges: rich schema in- cluding diverse data types as well as nested en- tities, complex templates including tables and multi-column layouts, and diversity of differ- ent layouts (templates) within a single docu- ment type. We design few-shot and conven- tional experiment settings along with a care- fully designed matching algorithm to evalu- ate extraction results. We report the perfor- mance of strong baselines and three observa- tions: (1) generalizing to new document tem- plates is very challenging, (2) few-shot perfor- mance has a lot of headroom, and (3) mod- els struggle with nested fields such as line- items in an invoice. We plan to open source the benchmark and the evaluation toolkit. We hope this helps the community make progress on these challenging tasks in extracting struc- tured data from visually rich documents.\n",
    "type": "task",
    "writing_model": "",
    "conversation_id": "639119a08c15db04700de56e"
  }
]