[
  {
    "_id": "6390feacb41eedf55b556678",
    "user_id": "P4",
    "time": "2022-12-07 20:59:24.878000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .VRDU contains two datasets that represent several challenges : rich schema including diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single document type .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "save"
  },
  {
    "_id": "6390fdb2b41eedf55b556673",
    "user_id": "P4",
    "time": "2022-12-07 20:55:14.979000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .VRDU contains two datasets that represent several challenges : rich schema including diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single document type .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390fd9fb41eedf55b556670",
    "user_id": "P4",
    "time": "2022-12-07 20:54:55.853000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .VRDU contains two datasets that represent several challenges : rich schema including diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single document type .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-2",
    "conversation_id": "6390fc79b41eedf55b55665c"
  },
  {
    "_id": "6390fd72b41eedf55b55666e",
    "user_id": "P4",
    "time": "2022-12-07 20:54:10.882000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .VRDU contains two datasets representing various challenges such as rich schema with diverse data types and nested entities , complex templates including tables and multi-column layouts , and diversity of different layout ( templates ) within a single document type .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390fd43b41eedf55b55666d",
    "user_id": "P4",
    "time": "2022-12-07 20:53:23.164000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .VRDU contains two datasets representing various challenges such as rich schema with diverse data types and nested entities , complex templates including tables and multi-column layouts , and diversity of different layout ( templates ) within a single document type .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390fd33b41eedf55b55666a",
    "user_id": "P4",
    "time": "2022-12-07 20:53:07.641000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .\nVRDU contains two datasets representing various challenges such as rich schema with diverse data types and nested entities, complex templates including tables and multi-column layouts, and diversity of different layout (templates) within a single document type.We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-2",
    "conversation_id": "6390fc79b41eedf55b55665c"
  },
  {
    "_id": "6390fd1bb41eedf55b556666",
    "user_id": "P4",
    "time": "2022-12-07 20:52:43.482000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding ( VRDU VRDU contains two dataset representing various challenges such as rich schema with diverse data types and nested entities, complex templates including tables and multi-column layouts, and diversity of different layout (templates) within a single document type We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "type": "task",
    "writing_model": "model-writing-2",
    "conversation_id": "6390fc79b41eedf55b55665c"
  },
  {
    "_id": "6390fc9db41eedf55b556664",
    "user_id": "P4",
    "time": "2022-12-07 20:50:37.686000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding ( VRDU ) .VRDU contains two datasets that represent several challenges : rich schema including diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single document type .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390fc8cb41eedf55b55665f",
    "user_id": "P4",
    "time": "2022-12-07 20:50:20.195000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry. Although recent multi-modal language models have achieved impressive results, we find that existing benchmarks do not reflect the complexity of real documents seen in industry. In this work, we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding (VRDU). VRDU contains two datasets that represent several challenges: rich schema including diverse data types as well as nested entities, complex templates including tables and multi-column layouts, and diversity of different layouts (templates) within a single document type. We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results. We report the performance of strong baselines and three observations: (1) generalizing to new document templates is very challenging, (2) few-shot performance has a lot of headroom, and (3) models struggle with nested fields such as line-items in an invoice. We plan to open source the benchmark and the evaluation toolkit. We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents.\n\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390fc83b41eedf55b55665e",
    "user_id": "P4",
    "time": "2022-12-07 20:50:11.033000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry. Although recent multi-modal language models have achieved impressive results, we find that existing benchmarks do not reflect the complexity of real documents seen in industry. In this work, we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding (VRDU). VRDU contains two datasets that represent several challenges: rich schema including diverse data types as well as nested entities, complex templates including tables and multi-column layouts, and diversity of different layouts (templates) within a single document type. We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results. We report the performance of strong baselines and three observations: (1) generalizing to new document templates is very challenging, (2) few-shot performance has a lot of headroom, and (3) models struggle with nested fields such as line-items in an invoice. We plan to open source the benchmark and the evaluation toolkit. We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents.\n\n",
    "type": "task",
    "writing_model": "",
    "conversation_id": "6390fc79b41eedf55b55665c"
  },
  {
    "_id": "6390fb3bb41eedf55b556647",
    "user_id": "P4",
    "time": "2022-12-07 20:44:43.476000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding ( VRDU ) .VRDU contains two datasets that represent several challenges : rich schema including diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single document type .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390fb1bb41eedf55b556646",
    "user_id": "P4",
    "time": "2022-12-07 20:44:11.266000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding ( VRDU ) .VRDU contains two datasets that represent several challenges : rich schema including diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single document type .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390f8cdb41eedf55b55663f",
    "user_id": "P4",
    "time": "2022-12-07 20:34:21.553000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry .Although recent multi-modal language models have achieved impressive results , we find that existing benchmarks do not reflect the complexity of real documents seen in industry .In this work , we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding ( VRDU ) .VRDU contains two datasets that represent several challenges : rich schema including diverse data types as well as nested entities , complex templates including tables and multi-column layouts , and diversity of different layouts ( templates ) within a single document type .We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results .We report the performance of strong baselines and three observations : ( 1 ) generalizing to new document templates is very challenging , ( 2 ) few-shot performance has a lot of headroom , and ( 3 ) models struggle with nested fields such as line-items in an invoice .We plan to open source the benchmark and the evaluation toolkit .We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents .\n",
    "event_type": "auto-save"
  },
  {
    "_id": "6390f8bdb41eedf55b55663c",
    "user_id": "P4",
    "time": "2022-12-07 20:34:05.843000",
    "text": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry. Although recent multi-modal language models have achieved impressive results, we find that existing benchmarks do not reflect the complexity of real documents seen in industry. In this work, we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding (VRDU). VRDU contains two datasets that represent several challenges: rich schema including diverse data types as well as nested entities, complex templates including tables and multi-column layouts, and diversity of different layouts (templates) within a single document type. We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results. We report the performance of strong baselines and three observations: (1) generalizing to new document templates is very challenging, (2) few-shot performance has a lot of headroom, and (3) models struggle with nested fields such as line-items in an invoice. We plan to open source the benchmark and the evaluation toolkit. We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents.\n\n",
    "type": "task",
    "writing_model": "",
    "conversation_id": "6390f89eb41eedf55b556639"
  },
  {
    "_id": "6390f8b8b41eedf55b55663a",
    "user_id": "P4",
    "time": "2022-12-07 20:34:00.475000",
    "text": "Understanding visually-rich business documents to extract structured data and auto-\nmate business workflows has been receiving\nattention both in academia and industry. Al-\nthough recent multi-modal language models\nhave achieved impressive results, we find that\nexisting benchmarks do not reflect the complexity of real documents seen in industry. In\nthis work, we identify the desiderata for a more\ncomprehensive benchmark and propose one\nwe call Visually Rich Document Understand-\ning (VRDU). VRDU contains two datasets that\nrepresent several challenges: rich schema in-\ncluding diverse data types as well as nested en-\ntities, complex templates including tables and\nmulti-column layouts, and diversity of differ-\nent layouts (templates) within a single docu-\nment type. We design few-shot and conven-\ntional experiment settings along with a care-\nfully designed matching algorithm to evalu-\nate extraction results. We report the perfor-\nmance of strong baselines and three observa-\ntions: (1) generalizing to new document tem-\nplates is very challenging, (2) few-shot perfor-\nmance has a lot of headroom, and (3) mod-\nels struggle with nested fields such as line-\nitems in an invoice. We plan to open source\nthe benchmark and the evaluation toolkit. We\nhope this helps the community make progress\non these challenging tasks in extracting struc-\ntured data from visually rich documents.\n",
    "event_type": "auto-save"
  }
]